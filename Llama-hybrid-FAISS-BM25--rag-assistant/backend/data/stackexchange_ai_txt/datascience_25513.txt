[site]: datascience
[post_id]: 25513
[parent_id]: 25359
[tags]: 
Why don’t you just put the data with pay_2 40k and 45k into two additional rows? Additionally, you could add an indicator variable loc_1_2 and set it to 1 or 2 depending on the location. In general, dummy encoding might be dangerous. Instead you could convert your addresses or locations into physical coordinates (latitude and longitude) or just distance from, let’s say, centre of the city or center of the country (depending on your data). Edit Ok, I see now that putting the data with pay_2 into additional rows will not work. But since it is a classification problem, it seems pertinent for the sake of numerical stability to standardise the salary data (pay2) to have values similar to a standard gaussian. For your information: not all classification algorithms need standardised data, e.g. you may want to consider random forest or GBMs. If you stick to SVMs, regularised logistic regression or similar then I agree, it’d make sense to standardise. Thus, I could not set the NaNs to zero for the lower-dimensional observations as zero would be a meaningful value. The standard approach you asked about, would depend on the properties of your classifier. I’m aware of the following options: If you classifier can handle NaNs (NAs), e.g. R version of xgboost, then you can just use the data as you show in your table above. If you have to standardise the data, then you can use mean-imputation. The average and standard deviation that are used for the standardisation should be estimated on non-NaN data, of course, (pay_2 column excl NaNs). In general, in order to prevent data leakage you should not use the data from holdout data subset (or “test”, “validation” or whatever you call it) for calculating the mean and standard deviation. If your classifier doesn’t require standardisation, you can put some numerical sentinel values instead of NaNs, e.g. -1, 0, or -9999. If you pick option 2 or 3, you’ll need to add a binary predictor indicating whether pay2 column was modified or not (NaN or not). Re dummy encoding: You haven’t asked about it explicitly and it’s difficult to suggest anything concrete without knowing the cardinality of your nominal variables, so I just put here the link to my answer about impact coding
