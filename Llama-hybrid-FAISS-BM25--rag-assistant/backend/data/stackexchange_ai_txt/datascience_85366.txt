[site]: datascience
[post_id]: 85366
[parent_id]: 
[tags]: 
Math behind 2D convolution for RGB images

I read many threads discussing why 2D convolutional layer is typically used for RGB images in neural network. I read that it is possible to use 3D conv layer. What I do not understand is the math behind it. Say your image is 300 by 300, and the kernel_size = (3, 3) and filter = 16 for the Conv2D layer. Input_shape would be (300, 300, 3) because there are 3 channels(RGB). Since the kernel is 2D, the convolution can only be done at 1 channel at a time. Is that correct? Are the same kernel applied/convolved for the 3 channels? If so there should be 3 output but the dimension of the output would be (298, 298, 16). Is it averaged over the 3 channels?
