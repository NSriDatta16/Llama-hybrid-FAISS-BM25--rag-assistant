[site]: crossvalidated
[post_id]: 398830
[parent_id]: 398764
[tags]: 
The boundary between estimating expectations and producing simulations is rather vague in the sense that, once given an importance sampling sample $$(x_1,\omega_1),\ldots,(x_T,\omega_T)\qquad\omega_t=f(x_t)/g(x_t)$$ estimating $\mathbb E_f[h(X)]$ by $$\frac{1}{T}\,\sum_{t=1}^T \omega_t h(x_t)$$ and estimating the cdf $F(\cdot)$ by $$\hat F(x)=\frac{1}{T}\,\sum_{t=1}^T\omega_t \Bbb I_{x\le x_t}$$ is of the same nature. Simulating from $\hat F$ is easily done by inversion and is also the concept at the basis of weighted bootstrap. In the case where the density $f$ is not properly normalised, as in most Bayesian settings, renormalising the $\omega_t$ 's by their sum is also a converging approximation. $\qquad\qquad$ The field of particle filters and sequential Monte Carlo (SMC) is taking advantage of this principle to handle sequential targets and state-space models. As in the illustrations above and below : $\qquad\qquad$
