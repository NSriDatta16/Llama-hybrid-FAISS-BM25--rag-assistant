[site]: crossvalidated
[post_id]: 146317
[parent_id]: 
[tags]: 
When should one use Coordinate descent vs. gradient descent?

I was wondering what the different use cases are for the two algorithms, Coordinate Descent and Gradient Descent . I know that coordinate descent has problems with non-smooth functions but it is used in popular algorithms like SVM and LASSO. Gradient descent however is I think used more widely, especially with the resurgence of ANNs, and for many other machine learning tasks. My question is: What type of problems fit one but not the other, and in that respect what makes coordinate descent fitting for SVMs and LASSO, but gradient descent fitting for ANNs? How should one choose between the two when choosing an optimization algorithm?
