[site]: crossvalidated
[post_id]: 302380
[parent_id]: 
[tags]: 
Classifying new objects: build a classification model or simply assign to the closest cluster?

Doing research on how to approach a problem I'm working on with text data. The gist of online advise I encountered was to cluster my corpus to create labels and then to build a classifier such as e.g. XGBoost based on the newly created labels from clustering. I sensed it was frowned upon to use the cluster object to classify by determining the closest centroid. I picked up on this after a Google search for the phrase "r predict with kmeans cluster object". Many of the posts recommended flexclust package however the tone I picked up was that you should not use the clustering object to classify e.g. here . Why is that? Why would it ever be "bad" to use a e.g. a previously built kmeans() cluster object to assign a new datapoint to a cluster by measuring the distance to the closest centroid? As opposed to using a classifier to determine the cluster? Afterthought since posting. In the context of my current data problem I'm working with text data. It occurred to me that new data might have new tokens/words which would translate into new features and that in this case a classifier might return an error. Whereas, using a previously defined kmeans object would not throw an error, I could still calculate the distance of new data point to the nearest centroid. In this case surely it's actually better to NOT build a classifier if I want to assign labels to new data where the labels are a previously determined set of clusters.
