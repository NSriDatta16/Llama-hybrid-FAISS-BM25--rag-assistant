[site]: crossvalidated
[post_id]: 188932
[parent_id]: 63134
[tags]: 
These are classical challenges in any Big Data Machine Learning problems. Most categories should have a lot of values that repeat themselves over and over and very few that appear very rarely. For categorical features where you have this occurs, you can use one-hot encoding to create additional features. few interval data items (real numbers, less than 5 such items) For interval data items you can encode it using label encoders. If any business insights can be drawn like mean, median, mode, frequency etc. then the same should be reflected in your approach. Some categories are also overcategories of others (like country and city). The outcome of each data is either 1 if the event occured or 0 if it did not occur. Since these dependent variables already cleanly reflect the independent variable there is little to be done here. I don't see a way to separate the features into hierarchy either. What machine learning approaches and statistical models will perform well on such a task? My initial thoughts are logarithmic regression and support vector machines (with extensions like random forest) You can start with logistic regression. However since your data is big you might be able to find some distribution to the input feature vectors. In that case using Gaussian Discriminant Analysis might help. You can model p(y) as a Bernoulli random variable and predict p(x|y=0) and p(x|y=1) as Normal distribution. SVM algorithm can also be used but the training time will be high. Also, we don't know the best choice of the kernel before looking at the performance on learning curve. What is your evaluation measure through? Is it accuracy or precision/recall? If it is latter then using Random Forest will not work, instead you can go by simple decision trees.
