[site]: crossvalidated
[post_id]: 312424
[parent_id]: 
[tags]: 
What is the "capacity" of a machine learning model?

I'm studying this Tutorial on Variational Autoencoders by Carl Doersch . In the second page it states: One of the most popular such frameworks is the Variational Autoencoder [1, 3], the subject of this tutorial. The assumptions of this model are weak, and training is fast via backpropagation. VAEs do make an approximation, but the error introduced by this approximation is arguably small given high-capacity models . These characteristics have contributed to a quick rise in their popularity. I've read in the past these sort of claims about high-capacity models , but I don't seem to find any clear definition for it. I also found this related stackoverflow question but to me the answer is very unsatisfying. Is there a definition for the capacity of a model? Can you measure it?
