[site]: crossvalidated
[post_id]: 421697
[parent_id]: 421536
[tags]: 
If you impose the constraint that the student must avoid re-estimation, then you can think of a solution like the following. I don't know whether this will actually fit your needs, so think about it, I do not pretend it is the best possible solution for your problem, so take it as an additional simple idea. Also because I don't know what your network purpose actually is (i.e. you have a binomial/multinomial model, or you are trying to predict a numerical variable, etc..). My answer is referred to the case of the numerical variable. Since the network will take into account the non-linearity in the relationship between the model and the dependent variable, then you could apply a log to the dependent variable, leaving the series of predictors unchanged. This will likely mean that there will exist a new model with new parameters that will fit the new transformed variable better than the existing textbook solutions calibrated on the non-transformed variable. Since the new model estimated will predict the log of the dependent variable, then, applying the exponential to the prediction of the model and the dependent variable, you will likely see that the exponential of the scores will fit the exponential of the log of the original dependent variable. this will allow you to oblige the students to fit a new model from scratch to find the new optimal parameters for the transformed dataset where the dependent variable has been transformed (via a non-linear albeit monotonic transformation). At the same time, it is convenient because you can revert back by applying the exp to both the sides of the model and dependent variable. You can also use more complex (BUT INVERTIBLE) transformations on the dependent variable. If you also wish to change the predictors and add a noise to the dataset, here the things get more involved. For example, you can obfuscate the data by multiplying everything by a white noise variable (suppose normally distributed, with a low variance, suppose 1 but you can use even lower values if you want to avoid too many simulations later). Then you have transformed/obfuscated predictors, but the obfuscation is just random and small, so it should disappear in repeated simulations. In that case, you can show that on average, simulating the whole process n times, for n high enough, the average model accuracy will converge to the accuracy of the textbook examples. The same more or less should hold if you obfuscate each predictor with an independent white noise, but I would skip too many overcomplications. In any case, the advice I give you, is that you should try this method numerically before, just to check whether it also works in practice and for which n compared to the variance of the noise.
