[site]: datascience
[post_id]: 63786
[parent_id]: 
[tags]: 
Formulation of a reward structure

I am new to reinforcement learning and experimenting with training of RL agents. I have a doubt about reward formulation, from a given state if a agent takes a good action i give a positive reward, and if the action is bad, i give a negative reward. So if i give the agent very high positive rewards when it takes a good action, like 100 times positive value as compared to negative rewards, will it help agent during the training? Intuitively I feel, it will help the agent training, but will there be any drawbacks of such skewed reward structure?
