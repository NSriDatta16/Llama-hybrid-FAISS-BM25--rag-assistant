[site]: crossvalidated
[post_id]: 50460
[parent_id]: 50436
[tags]: 
Logistic regression doesn't attempt to maximize classification accuracy. The problem of trying to find coefficients that maximize classification accuracy is actually NP-hard, so in general it's not possible. Instead of maximizing accuracy, logistic regression finds coefficients that minimize the cross-entropy cost, which is convex and hence easy to minimize, and sort of approximates classification accuracy. In particular, if $t_i$ is the actual class label of instance i (0 or 1) and $y_i$ is the predicted probability of being in class 1, logistic regression will find coefficients that minimize $-\sum_0^n [t_i * ln(y_i) + (1-t_i)*ln(1-y_i)]$ If you plug in the "always class 1" solution (i.e. $y_i = 1$ for all $i$), you get a $ln(0)$ in the second term, and a cost of infinity, so it will never choose that answer. Instead you'll get a solution that always gives some positive probability to every class that it has seen in the training data.
