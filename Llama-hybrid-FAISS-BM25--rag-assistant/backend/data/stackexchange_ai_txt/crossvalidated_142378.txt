[site]: crossvalidated
[post_id]: 142378
[parent_id]: 142363
[tags]: 
It really depends what you mean by "problematic". Your approach is more theoretical than mine (I'm pragmatic). In your frame of reference, the question is (I think) how the number of observations per estimated parameter (for any particular subset, e.g. for firm-effect parameters or year-effect parameters) scales with the total number of observations. It depends on what observational/experimental design you're assuming: if you assume that your asymptotic sample is composed of an increasing number of yearly samples for a fixed number of firms, then year effects would be estimated consistently (and firms would not, as in your example). if you assume that you sample an increasing number of firms for a fixed set of years, then the opposite is true. if you assume that you can take increasing numbers of samples per firm per year (and that this makes sense), then both could be estimated consistently. I would ask the question differently, considering (1) whether shrinkage estimates are useful; (2) whether you want to be able to generalize beyond your sample of years and firms. (If you assume smooth trends and no year effects, you can generalize to other years; if you assume fixed year effects (either with or without a trend model) then you can't; if you assume random year effects (with or without) then you can. You could also, as is common in econometrics, try a Durbin-Wu-Hausman test , which theoretically is asking whether the random-effects estimator is consistent or not, but which practically speaking is (I think) asking whether you have enough information to reject the assumption of the random-effects estimator that the conditional modes (year effects, firm effects, etc.) are actually Normally distributed. Hope that helps.
