[site]: stackoverflow
[post_id]: 1731193
[parent_id]: 1731102
[tags]: 
Reading car_names.txt will save you a piddling amount of memory (really really tiny by today's standards;-) but it absolutely won't be any faster than slurping it down at one gulp (best case it will be exactly the same speed, probably even a little bit slower unless your underlying operating system and storage system do a great job at read-lookahead caching / buffering). So I suggest: import fileinput carnames = open('car_names.txt').readlines() carnamit = iter(carnames) skip = False for line in fileinput.input(['car_descriptions.txt'], True, '.bak'): if not skip: print line, if '@CAR_NAME' in line: print next(carnamit), skip = True else: skip = False So measure the speed of this, and an alternative that does carnamit = open('car_names.txt') at the start instead of reading all lines over a list like my first version -- I bet that the first version (in as much as there's any measurable and repeatable difference) will prove to be faster. BTW, the fileinput module of the standard library is documented here , and it's truly a convenient way to perform "virtual rewriting in-place" of text files (typically keeping the old version as a backup, just in case -- but even if the machine should crash in the middle of the operation the old version of the data will still be there, so in a sense the "rewriting" operates atomically with respect to machine crashes, a nice little touch;-).
