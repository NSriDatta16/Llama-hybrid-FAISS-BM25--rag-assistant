[site]: crossvalidated
[post_id]: 503029
[parent_id]: 503026
[tags]: 
The development set, in other words, validation set or holdout set is like executing cross-validation for one fold only. It's faster, therefore cheaper. Typically, cross-validation is more robust because the performance is averaged across several tests instead of one. This might make sense when dealing with smaller datasets. When, data is not a problem, their performances should converge. When the training is expensive, like in deep neural nets, it'd be impractical to use cross-validation because we'll train the neural net over and over for each fold.
