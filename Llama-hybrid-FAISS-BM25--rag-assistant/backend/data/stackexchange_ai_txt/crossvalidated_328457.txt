[site]: crossvalidated
[post_id]: 328457
[parent_id]: 328451
[tags]: 
The statement seems to be true for distributions whose lower tail of the CDF is approximately linear. This is a proof for a distribution that is restricted to the domain from 0 to $a$ with $a$ finite , The restricted domain is for simplicity, but I believe it can be extended to any finite lower bound and infinite upper bounds (in this way it relates to Whuber's conjecture that it looks like it might be true for continuous distributions with finite lower bounds.): $$\begin{array}\\ \left & = \int_{0}^{a} x P(x=x_{min}) dx \\ & = \int_{0}^a n x f(x) (1-F(x))^{n-1} dx\\ &= -x(1-F(x))^n\vert_{0}^{a} + \int_{0}^{a}(1-F(x))^n dx\\ &=\int_{0}^{a}(1-F(x))^n dx \\ \end{array}$$ Some more elegant shortcut to get to the above result would be to use the CDF for the minimal value $F_{min}=1-(1-F(x))^n$ as starting point, along with $E(X_{min}) = \int (1-F_{min}(x))dx$. But I happened to have started with this more clumsy, but more direct, derivation and I like it. now I am taking a bit of an intuitive step but you can imagine that, when n goes to infinity, the integral is determined by the slope of $1-F(x)$ at $x=0$ (where $1-F(x)$ is closest to 1 and diminishes the least for growing $n \to \infty$). So, let the taylor expansion of $F(x)$ be $$ F(x) = b_1x + b_2x^2+b_3x^3+...$$ and the integral is then approximately (where I admit I have no strong argument) : $$ \left = \int_0^a (1-F(x))^n = \int_0^a (1- b_1x - b_2x^2-b_3x^3+...)^n \simeq \frac{1}{b_1n} \qquad \text{ for } n\to \infty $$ and $$P\left( X \right) = F\left( \left \right) \simeq F \left( \frac{1}{b_1n} \right) = b_1\frac{1}{b_1n} + b_2 \left( \frac{1}{b_1n} \right)^2+... \simeq \frac{1}{n} $$ I believe that a proof could go according to these lines. I have marked two sentences in bold where I haven't been precise. The first one about 'the limitation of the domain' is, I believe, not such a big deal but requires some more nasty descriptions of the integrals and the algebra. (but if we try to make the lower bound infinite then this method of proof doesn't work and this makes sense with Whuber's comments that '$P(X The second one about 'the integral being defined by the slope' is more difficult and I used intuition but could not turn it into a formal proof. Note!: I assumed the Taylor expansion to be: $$ F(x) = b_1x + b_2x^2+b_3x^3+...$$ with non-zero coefficient $b_1$. This is a strong requirement. For instance if $F(x) = x^2$ from 0 to 1 then: $$\begin{array}\\ \left &=\int_{0}^{1}(1-x^2)^n dx = \frac{\sqrt{\pi} \Gamma \left( n+1 \right)}{2 \Gamma \left( n+\frac{3}{2} \right)} \\ \end{array}$$ and if you plug that into $F(x)=x^2$ $$\begin{array}\\ F(\left ) = \left(\frac{\sqrt{\pi} \Gamma \left( n+1 \right)}{2 \Gamma \left( n+\frac{3}{2} \right)}\right)^2 = \frac{\pi}{4n} + \mathcal{O} \left( \left( \frac{1}{n} \right)^2 \right) \\ \end{array}$$ So we can say that it is only true if F(x) is approximately linear near the lower bound an intuition is that if the distribution of the minimum value is not continuous (linear F(x)), in the limit, then you will sample relatively lower values when you are below $\frac{1}{n}$ than high values when you are above $\frac{1}{n}$. Imagine that the $x_{min}$ will be equally often above and below the $\frac{1}{n}$-th percentile but the values sampled below will 'count relatively stronger' and 'push' the $\left $ a bit below the $\frac{1}{n}$-th percentile. It is a bit similar to why mean and modus are not the same. In this case you shrink the concept of mean and modus to the lower end of percentile by taking the limit of the minimum of $n$ variables, and if the distribution is not linear then your "1/n-th modus" and "1/n-th mean" won't agree.
