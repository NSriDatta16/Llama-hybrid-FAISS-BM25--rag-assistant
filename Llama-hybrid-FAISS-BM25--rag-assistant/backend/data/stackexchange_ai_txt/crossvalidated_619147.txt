[site]: crossvalidated
[post_id]: 619147
[parent_id]: 
[tags]: 
Did I lose precision when I applied inverse normalization and inverse standarization when I predict the new data in a regression problem?

Let's suppose that I'm trying to predict a stochastic forecast with machine learning models, and I don't have missing, null/NaN values and outliers. Also suppose that there is an error for the predictive model which decreases if I normalize and standardize the data: a) I put the raw data in the machine learning model b I use normalization and standarization. Let's call f the normalization function and g de standarization function: For case b) , now my data is inside a normalized and standardized space, so it's not my actual values. To return to have the real value I must apply the inverse functions. Mathematically I'm moving between spaces, like this: Question : In b), will the accuracy have a value of 97% once the inverse functions are applied? If the answer is yes, why are the values ​​obtained in a space transferred to the original?
