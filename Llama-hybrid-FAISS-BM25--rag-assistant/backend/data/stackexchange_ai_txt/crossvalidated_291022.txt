[site]: crossvalidated
[post_id]: 291022
[parent_id]: 
[tags]: 
High-Level algorithm for schema matching

I would like to match two schemas coming from different sources (DB). For this I would like to try some machine learning algorithm to come up with a process to decided which column in a table could correspond to the same key. For example it's very likely that FName and FirstName should be a match and correspond both to the same "real world key" First Name . I would therefore do the following: For each column (key) extract certain features. Some of them may be based only on the key itself, others may use actual values of that key to generate certain features. I thought I will define features based on their data type, i.e. have certain feature extraction for strings, for numeric etc. Once I've generated all the feature for each column I can train a classifier. Once I have a trained model I can use it to predict for other schema if there is a match Does the above algorithm make sense? There is one point which confuses me. I'm only interested in matching certain schema like core personal data. To training such a classifier I do need to have some test data. Is the test data in this case different schemas? That would mean I need many schemas about personal data which could be very difficult to find. Or how else could I train the model with just a few (say less than 10) schemas at hand?
