[site]: stackoverflow
[post_id]: 3513348
[parent_id]: 3513098
[tags]: 
Currently you have a quarter of a gig of data. You envisage it doubling (half a gig) this year. Is it 1997? No it is 2010 and people have gigabytes of data on their phones . So the question is, what problam are you trying to solve? It cannot be storage, because that is a trivial amount of data. If it's performance then I think splitting into multiple databases is likely to make things worse unles syou're envisaging a server per database. There is an argument for separate databases from a security perspective, but there are different ways of addressing those concerns. Do you have problems with your current environment? Or at least trends which suggests you may have problems in twelve months time? If no, then just sit tight. If yes, formulate them clearly and then figure out how 300 databases will solve those problems, and whether they will be worth the inevitable grief. Then recalibrate that grief to account for 10000 users and ask the question again. There may be some questions to which the best answer is "ten thousand databases" but not very many. "Our biggest client adds about 12000 records per year. " In other words about one record every ten working minutes (assuming an eight hour day). This doesn't seem like a large write load. "The idea is rather then a client go through all the data, it just accesses their data." But it's not a lot of data, and certainly nothing that a decent indexing strategy can't fix. I still don't understand whether you have an actual real problem now or you're just thinking about something which might be a problem at some point in the future.
