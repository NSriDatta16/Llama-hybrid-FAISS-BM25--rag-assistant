[site]: datascience
[post_id]: 88667
[parent_id]: 88651
[tags]: 
Well, if it is a good results or bad results is decided by the task you are performing. But so far, it looks like good results. Coming to the metrics, precision, recall and F1 can be learnt from wikipedia here . However, the interpretation of your results goes like this: The left most extreme 0 or 1 indicates the class (in your binary classification task). And the values 0.92 , 1.00 , 0.96 corresponds to precision, recall, and F1 of the class 0 respectively. Likewise, the next line indicates precision, recall, and F1 for class 1 . support indicates support count , which in simple terms is the number of samples for a given class in the test set. Macro average precision/recall/f1-score is the average precision/recall/f1-score for all classes. Weighted average precision/recall/f1-score is the weighted average precision/recall/f1-score for all classes, here the support count is used as weights.
