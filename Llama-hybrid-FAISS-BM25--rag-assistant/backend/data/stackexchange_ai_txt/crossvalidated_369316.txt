[site]: crossvalidated
[post_id]: 369316
[parent_id]: 
[tags]: 
Classification model on a highly unbalanced dataset

I’m dealing with a highly unbalanced dataset where 20% of data belongs to class A and 80% belongs to class B. It’s very hard for us to produce synthetic class A data. Just wondering if the below approach is a sensible thing to do: Total data points: 100 Class A : 20 Class B : 80 How about splitting the dataset into 4 separate samples consisting of 20 A’s and 20 B’s. In other words, I’m mixing the 20 A’s with different samples of 20 B’s. We’d have 4 models (say random forest or so) and finally the decision is taken from what the majority of these 4 models predict?
