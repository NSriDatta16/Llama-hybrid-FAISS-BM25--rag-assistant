[site]: crossvalidated
[post_id]: 171887
[parent_id]: 171859
[tags]: 
How is this vocabulary created? Since you use 1-out-of-K to encode words to sparse vectors, you cannot input a word outside your vocabulary. To handle such cases, it is common to initialise you vocabulary with an open-source dictionary you can find online. New words By adding a new column in L you need to retrain your whole network as the weight matrices $W_enc$ for encoding have changed from $N_L \times N_{emb}$ to $N_L +1 \times N_{emb}$. It is also possible to fine-tune instead of full retraining. In terms of conceptual explanation of where the vector would be close, it is impossible to translate it exactly to human terms as the embeddings are just numbers. However, you would still need to retrain your network for the new column in the matrices to come to any conclusions. Sentences of variable length In case you use RNNs, you will not have a problem as you input one word at a time, and backpropagate through a defined number of steps (e.x. 20 words). Therefore, you can either limit the backpropagation or use a special padding word (e.x. "000000") to fill up the missing words. Given that you use LSTMs, it will learn to ignore it. If you use Conv Nets, then you definitely need padding to fill the missing words, while the input size is defined by your largest sentence.
