[site]: crossvalidated
[post_id]: 614175
[parent_id]: 
[tags]: 
Dynamic Programming truncated state space

When I dealing with a infinite horizon average cost DP problem with infinite state space｛-inf..-2.-1.0.1.2..inf｝，with some discrete control and noise space，Im trying to truncate the state space and find the average cost J and differential cost h(x) using bellman equation .It turns out that when I truncate the state space ,the dynamic of the system may bring me out of the truncated state space how can I deal with this case?
