[site]: crossvalidated
[post_id]: 525634
[parent_id]: 525239
[tags]: 
Suppose that you are trying to optimize something like $y = f(x_1, x_2, x_3, x_4, x_5, x_6)$ , and $f$ is linear on $(x_1,x_2,x_3)$ and non-linear on $(x_4,x_5,x_6)$ . As you can imagine, it does not have anything to do with the kernel (Matern, square exponential, etc.), but rather the global mean/trend function in the underlying GP. For efficiency, you can improve by setting the polynomial order of the global trend to 1, so that it includes linear terms. Ignoring the first one is fine, GP is supposed to approximate pretty well for a 6d problem. If the BO does not converge, probably it has something to do with either (1) optimal criteria for convergence or (2) fitting GP. In principle, your application should be well solved by Bayesian optimization. You can try a different implementation to see if a better result can be obtained.
