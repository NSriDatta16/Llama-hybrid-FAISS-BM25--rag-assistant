[site]: crossvalidated
[post_id]: 457982
[parent_id]: 457973
[tags]: 
Logistic regression has one canonical parameter, the log odds. So if you use GLM as a maximum likelihood procedure, the linear model for the response is: $$ \text{logit} \left( Pr(Y = 1) = \mu\right) = \beta_0 + \beta_1 X_1 + \ldots + \beta_p X_p$$ Where $g(\mu) = \text{logit}(\mu) = \log(\mu/(1-\mu))$ is called the "link function". Consequently the mean-variance relationship is given by $V = \frac{\partial}{\partial \mu} g^{-1}(\mu)$ which in this case is $\mu(1-\mu)$ , the readily recognizable variance of Bernoulli random variable. GLMs are estimated by Fisher Scoring. A scale family of distributions is any family of probability densities where given $X$ being a member of that family, $Y = \phi X$ is still a member of that same family (someone correct me with a formal definition here). The most famous example is the normal distribution. The Bernoulli density is not a scale family. That means if you want to estimate a generalization of the logistic model where the linear model for the response is still given by: $$ \text{logit} \left( \mu \right) = \beta_0 + \beta_1 X_1 + \ldots + \beta_p X_p$$ but the variance is given by: $$ V = \phi^2 \mu (1-\mu)$$ you need to use non-standard GLM estimation, or you need to use quasilikelihood and calculate the dispersion parameter $\phi$ as a nuissance parameter, using the deviance residuals. This estimating equation is no longer a maximum likelihood procedure, but has many MLE-like properties. Wedderbern consequently coined the process one of quasilikelihood in 1973.
