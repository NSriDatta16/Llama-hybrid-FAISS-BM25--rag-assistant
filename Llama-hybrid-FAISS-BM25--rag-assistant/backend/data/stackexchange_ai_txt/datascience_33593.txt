[site]: datascience
[post_id]: 33593
[parent_id]: 
[tags]: 
Collection of several learners

I have few questions for which I could not extract answers from text books and online tutorials. Therefore, will be extremely grateful if the following points are clarified. 1) If I want to apply SVM, MLP and decision trees and combine the prediction results from these learners. So, I will have a mixture of ensemble of SVM, MLP and Decision trees OR I can use one learner only and have an ensemble of decision trees, an ensemble of SVMS and an ensemble of MLPs. Is my understanding correct? How do I combine the prediction results from different models? 2) In ensemble learning be it homogeneous and heterogeneous, each of the learner is trained on the same data set? Is this technique known as Bagging or simply ensemble learning? Would I be using the same subset of data for training each learner or different? 2) I have read in many tutorials that bagging and boosting is performed on similar learners. But ensemble learning can be homogeneous and heterogeneous. As a result, can bagging and boosting be performed on different learner types? 3) In Boosting, the learners are trained sequentially and therefore often only a learner of one kind is used as it is probably difficult to know if the sequence influences the learning procedure. Am I correct? 4) How is stacking different from the rest?
