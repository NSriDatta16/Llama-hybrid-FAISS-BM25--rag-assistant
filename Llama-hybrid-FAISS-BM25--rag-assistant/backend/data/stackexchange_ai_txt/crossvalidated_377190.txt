[site]: crossvalidated
[post_id]: 377190
[parent_id]: 376920
[tags]: 
a simple linear regression is essentially a causal model Here's an example I came up with where a linear regression model fails to be causal. Let's say a priori that a drug was taken at time 0 ( t=0 ) and that it has no effect on the rate of heart attacks at t=1 . Heart attacks at t=1 affect heart attacks at t=2 (i.e. previous damage makes the heart more susceptible to damage). Survival at t=3 only depends on whether or not people had a heart attack at t=2 -- heart attack at t=1 realistically would affect survival at t=3 , but we won't have an arrow, for the sake of simplicity. Here's the legend: Here's the true causal graph: Let's pretend that we don't know that heart attacks at t=1 are independent of taking the drug at t=0 so we construct a simple linear regression model to estimate the effect of the drug on heart attack at t=0 . Here our predictor would be Drug t=0 and our outcome variable would be Heart Attack t=1 . The only data we have is people who survive at t=3 , so we'll run our regression on that data. Here's the 95% Bayesian credible interval for coefficient of Drug t=0 : Much of the probability as we can see is greater than 0, so it looks like there's an effect! However, we know a priori that there is 0 effect. The mathematics of causation as developed by Judea Pearl and others make it much easier to see that there will be bias in this example (due to conditioning on a descendant of a collider). Judea's work implies that in this situation, we should use the full data set (i.e. don't look at the people who only survived), which will remove the biased paths: Here's the 95% Credible Interval when looking at the full data set (i.e. not conditioning on those who survived). . It is densely centered at 0, which essentially shows no association at all. In real-life examples, things might not be so simple. There may be many more variables that might cause systematic bias (confounding, selection bias, etc.). What to adjust for in analyses has been mathematized by Pearl; algorithms can suggest which variable to adjust for, or even tell us when adjusting is not enough to remove systematic bias. With this formal theory set in place, we don't need to spend so much time arguing about what to adjust for and what not to adjust for; we can quickly reach conclusions as to whether or not our results are sound. We can design our experiments better, we can analyze observational data more easily. Here's a freely-available course online on Causal DAGs by Miguel Hern√†n. It has a bunch of real-life case studies where professors / scientists / statisticians have come to opposite conclusions about the question at hand. Some of them might seem like paradoxes. However, you can easily solve them via Judea Pearl's d-separation and backdoor-criterion . For reference, here's code to the data-generating process and the code for credible intervals shown above: import numpy as np import pandas as pd import statsmodels as sm import pymc3 as pm from sklearn.linear_model import LinearRegression %matplotlib inline # notice that taking the drug is independent of heart attack at time 1. # heart_attack_time_1 doesn't "listen" to take_drug_t_0 take_drug_t_0 = np.random.binomial(n=1, p=0.7, size=10000) heart_attack_time_1 = np.random.binomial(n=1, p=0.4, size=10000) proba_heart_attack_time_2 = [] # heart_attack_time_1 increases the probability of heart_attack_time_2. Let's say # it's because it weakens the heart and makes it more susceptible to further # injuries # # Yet, take_drug_t_0 decreases the probability of heart attacks happening at # time 2 for drug_t_0, heart_attack_t_1 in zip(take_drug_t_0, heart_attack_time_1): if drug_t_0 == 0 and heart_attack_t_1 == 0: proba_heart_attack_time_2.append(0.1) elif drug_t_0 == 1 and heart_attack_t_1 == 0: proba_heart_attack_time_2.append(0.1) elif drug_t_0 == 0 and heart_attack_t_1 == 1: proba_heart_attack_time_2.append(0.5) elif drug_t_0 == 1 and heart_attack_t_1 == 1: proba_heart_attack_time_2.append(0.05) heart_attack_time_2 = np.random.binomial( n=2, p=proba_heart_attack_time_2, size=10000 ) # people who've had a heart attack at time 2 are more likely to die by time 3 proba_survive_t_3 = [] for heart_attack_t_2 in heart_attack_time_2: if heart_attack_t_2 == 0: proba_survive_t_3.append(0.95) else: proba_survive_t_3.append(0.6) survive_t_3 = np.random.binomial( n=1, p=proba_survive_t_3, size=10000 ) df = pd.DataFrame( { 'survive_t_3': survive_t_3, 'take_drug_t_0': take_drug_t_0, 'heart_attack_time_1': heart_attack_time_1, 'heart_attack_time_2': heart_attack_time_2 } ) # we only have access to data of the people who survived survive_t_3_data = df[ df['survive_t_3'] == 1 ] survive_t_3_X = survive_t_3_data[['take_drug_t_0']] lr = LinearRegression() lr.fit(survive_t_3_X, survive_t_3_data['heart_attack_time_1']) lr.coef_ with pm.Model() as collider_bias_model_normal: alpha = pm.Normal(name='alpha', mu=0, sd=1) take_drug_t_0 = pm.Normal(name='take_drug_t_0', mu=0, sd=1) summation = alpha + take_drug_t_0 * survive_t_3_data['take_drug_t_0'] sigma = pm.Exponential('sigma', lam=1) pm.Normal( name='observed', mu=summation, sd=sigma, observed=survive_t_3_data['heart_attack_time_1'] ) collider_bias_normal_trace = pm.sample(2000, tune=1000) pm.plot_posterior(collider_bias_normal_trace['take_drug_t_0']) with pm.Model() as no_collider_bias_model_normal: alpha = pm.Normal(name='alpha', mu=0, sd=1) take_drug_t_0 = pm.Normal(name='take_drug_t_0', mu=0, sd=1) summation = alpha + take_drug_t_0 * df['take_drug_t_0'] sigma = pm.Exponential('sigma', lam=1) pm.Normal( name='observed', mu=summation, sd=sigma, observed=df['heart_attack_time_1'] ) no_collider_bias_normal_trace = pm.sample(2000, tune=2000) pm.plot_posterior(no_collider_bias_normal_trace['take_drug_t_0'])
