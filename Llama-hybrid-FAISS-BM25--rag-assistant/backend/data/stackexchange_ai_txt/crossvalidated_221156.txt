[site]: crossvalidated
[post_id]: 221156
[parent_id]: 219825
[tags]: 
You should learn about easier-to-code state space models and closed-form filtering first (i.e. kalman filters, hidden markov models). Matthew Gunn is correct that you can get surprisingly far with simple concepts, but in my humble opinion, you should make this an intermediate goal because: 1.) Relatively speaking, there are more moving parts in state space models. When you learn SSMs or hidden markov models, there is a lot of notation. This means there are more things to keep in your working memory while you play around with verifying things. Personally, when I was learning about Kalman filters and linear-Gaussian SSMs first, I was basically thinking "eh this is all just properties of multivariate normal vectors...I just have to keep track of which matrix is which." Also, if you're switching between books, they often change notation. Afterwards I thought about it like "eh, this is all just Bayes' rule at every time point." Once you think of it this way you understand why conjugate families are nice, as in the case of the Kalman filter. When you code up a hidden markov model, with its discrete state space, you see why you don't have to calculate any likelihood, and filtering/smoothing is easy. (I think I am deviating from the convential hmm jargon here.) 2.) Cutting your teeth on coding a lot of these up will make you realize how general the definition of a state space model is. Pretty soon you'll be writing down models you want to use, and at the same time seeing why you can't. First you will eventually see that you just can't write it down in one of these two forms that you're used to. When you think about it a little more, you write down Bayes' rule, and see the problem is your inability to calculate some sort of likelihood for the data. So you will eventually fail at being able to calculate these posterior distributions (smoothing or filtering distributions of the states). To take care of this, there are a lot of approximate filtering stuff out there. Particle filtering is just one of them. The main takeaway of particle filtering: you simulate from these distributions because you can't calculate them. How do you simulate? Most algorithms are just some variant of importance sampling. But it does get more complicated here as well. I recommend that tutorial paper by Doucet and Johansen ( http://www.cs.ubc.ca/~arnaud/doucet_johansen_tutorialPF.pdf ). If you get how closed form filtering works, they introduce the general idea of importance sampling, then the general idea of monte carlo method, and then show you how to use these two things to get started with a nice financial time series example. IMHO, this is the best tutorial on particle filtering that I have come across. In addition to adding two new ideas to the mix (importance sampling and the monte carlo method), there's more notation now. Some densities you're sampling from now; some you're evaluating, and when you evaluate them, you're evaluating at samples. The result, after you code it all up, are weighted samples, deemed particles. They change after every new observation. It would be very hard to pick all of this up at once. I think it's a process. I apologize if I'm coming across as cryptic, or handwavy. This is just the timeline for my personal familiarity with the subject. Matthew Gunn's post probably more directly answers your question. I just figured I would toss out this response.
