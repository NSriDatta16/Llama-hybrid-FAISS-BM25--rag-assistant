[site]: crossvalidated
[post_id]: 642593
[parent_id]: 
[tags]: 
Bayesian inference - Bayes formula

I'm studying Bayesian inference with the famous Bayes formula. To calculate the posterior, we need prior, likelihood and (sometimes) evidence. When I say "sometimes" it's because there are cases for which we don't need this normalization constant and we make the assumption that the posterior distribution can be approximated by the prior multiplied by the likelihood. Why do we make this assumption when there are methods (mcmc) for calculating this integral? Is it because there are sometimes conjugate priors and so we already know approximately the posterior distribution without needing to calculate the evidence? Thank you for your help
