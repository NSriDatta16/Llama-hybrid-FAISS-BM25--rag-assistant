[site]: crossvalidated
[post_id]: 118164
[parent_id]: 97921
[tags]: 
You can think of this in terms of learning a feature of an ensemble in machine learning. Normally an ensemble would say have 5 models all trained to predict W and then the ensemble model would combine these models to make a better prediction on W. Normally by something simple like a vote. But there is no reason why these 5 predictions could not be combined in a more complex way using any ML algorithm. Now you want to learn a model to predict Y and then use this as a feature to predict W. Nothing wrong in that. You are using one model -Y as an input feature to model W. I think this is also related to semi supervised learning, where you can use proxy measures- To predict the measure you want. For example in an image classification you train one model to predict sea(Your labelled Y for example), another to predict sand (another model say Z, where you have labels) and then combine these models to predict beach. (Your W where you have limited labelled data). Where W would be a model built out of Y and Z.
