[site]: crossvalidated
[post_id]: 585908
[parent_id]: 585065
[tags]: 
Your first question : Your answer is correct, the hidden states form a first-order Markov chain. If one is only interested in conditional independencies (CIs), then indeed, in Markov networks you simply remove the observed nodes with all incident edges and then consider the connected components. However, it sometimes makes sense to keep the observed points but shade them differently like this: That way it is emphasized that you have selection bias: The probabilities of the hidden states $h_i$ are different for different ("selections" of) observations $v_i$ . Also, note that marginalization is what is really associated with removing nodes, but then the edges are handled differently. Your second question : Your answer is correct. You have a Markov network that consists of a single connected component, thus you cannot deduce any independencies. (And the whole point of HMMs is that the states form a Markov chain and thus depend on each other.) Your third question : In your case, you should do ancestral sampling , which is faster than e.g. Gibbs. Just start with sampling from $p(h_1|v_1)$ , then use the $h_1$ -sample to sample from $p(h_2|h_1, v_2)$ , and so forth. And then note that the observations $v_i$ influence the conditional probabilities of the hidden states $h_i$ , which you get reminded of when leaving the conditioned (i.e. observed) variables in the graph as shown above. For the sampling from the conditional probabilities $p(h_i| h_{i-1}, v_i)$ you might have to use MCMC, depending on the type of distribution.
