[site]: crossvalidated
[post_id]: 619322
[parent_id]: 618446
[tags]: 
To find the maximum likelihood estimates of the parameters we need the probability density function, $f(x)$ , for $X=Z_1+Z_2$ : $$f(x)=\int_0^\infty \frac{\exp \left(-\frac{(x- z_1-\mu_2)^2}{2 \sigma_2^2}-\frac{(\log (z_1)-\mu_1)^2}{2 \sigma_1^2}\right)}{2 \pi \sigma_1 \sigma_2 z_1}dz_1$$ So with (likely) no nice closed-form for this integral we need to evaluate it numerically. And as @whuber more than hints at in a comment a direct attack results in numerical instability because of underflow while evaluating the integrand. We can avoid this and end up with a reasonable approximation of the density by determining the limits of integration not associated with underflow and even avoiding areas where the integrand is "close enough to zero." Some R code below gives functions for the maximum likelihood estimates along with estimates of the associated standard errors. Note that to get all parameters roughly the same order of magnitude I'm using $\log(\sigma_1)$ and $\log(\sigma_2)$ rather than $\sigma_1$ and $\sigma_2$ , respectively, which also automatically enforces the restriction that the estimates of $\sigma_1$ and $\sigma_2$ will be positive. f $value == 0) { result$value value } logL To use those functions consider the OP's two examples: # Generate a random sample n $mle, c(par[1], exp(par[2]), par[3], exp(par[4]))) # [1] -2.987227e+00 2.974923e+00 -4.195435e-05 1.006057e-03 # Standard errors of mu1, logsigma1, mu2, and logsigma2 results1$ sd # [1] 0.0311040500 0.0089383883 0.0000552333 0.0445809578 # Generate a random sample n I have taken the liberty to use the true values of the parameters for starting values. Your mileage may vary. If either amount of computer time is larger than needed (as opposed to desired), then one can take advantage of the fact that the pdf of $X$ is relatively smooth. One could use interpolation from a subset of values in the first 90% of the data and a regression with another subset of the upper 10% of the data (with the regression being of the form $a_0+a_1 \log(x) + a_2 (\log(x))^2$ ). That would considerably reduce the number of calls to the numerical integration routine.
