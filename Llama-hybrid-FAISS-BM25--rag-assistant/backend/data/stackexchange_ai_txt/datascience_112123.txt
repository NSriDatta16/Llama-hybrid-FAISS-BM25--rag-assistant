[site]: datascience
[post_id]: 112123
[parent_id]: 
[tags]: 
Choosing Right Optimiser and Data Scaling

The choice of optimiser and how data is scaled are both very important things in machine learning, yet they are not hyperparameters (as far as I am aware). It is also not necessarily obvious which scaling is best. Should we trial a simple or same version of the model we wish to train over all optimisers and data scalings to figure which one is best, then use this scaling and optimiser to perform training, hyperparameter optimisation and final testing? i.e. would the 'best optimiser and scaling' generally hold across choice of hyperparameters? And if not, are there formal ways to go about these choices (beyond no scaling yielding data of different magnitudes and scaling roughly sorting out that problem), or should we just use a general intuition/strategy of choice based on our specific problem, more as above?
