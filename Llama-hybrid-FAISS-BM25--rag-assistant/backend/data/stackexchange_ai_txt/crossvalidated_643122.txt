[site]: crossvalidated
[post_id]: 643122
[parent_id]: 
[tags]: 
Methods for discriminating between Markov kernels

I'm interested in problems of the following form, which I've deliberately specified a bit vaguely. I would like to know if problems of this kind have been studied, and if so what they're called and what's known about their optimal solutions. There is a machine that takes inputs in some set $X$ and gives outputs in some set $Y$ . The machine's output is sampled from a distribution that depends on its input and is independent of all previous inputs and outputs, so it's behaviour can be specified by a Markov kernel from $X$ to $Y$ . I don't know which Markov kernel specifies the behaviour of this particular machine, but I have some set of possible choices (maybe just two or maybe an infinite set - I'm interested in either). I'm allowed to use the machine some large number $n$ of times, and I would like to choose which inputs to give to the machine in order to maximise my "ability to discriminate" between the given possibilities. The vagueness is that I don't know exactly what "ability to discriminate" should mean here. I'm interested in any principled approach to that, whether it be Bayesian or classical. Addionally, we could either say I have to choose all my inputs to the machine beforehand, so that my choice essentially comes down to choosing a distribution over $X$ , or we could say that I can make a new decision at each time step, potentially depending on previous outputs that I've received from the machine. I'm interested in either of these. This setup has some similarity to "multi-armed bandits" (espeially if I'm allowed to make my choices based on previous observations), except that the goal here is not to maximise a reward function but to distinguish between multiple possible response distributions. I'm also interested in the generalisation where the machine's output is no longer independent of past inputs and outputs, so that it can depend on all of them, if anything has been written on that.
