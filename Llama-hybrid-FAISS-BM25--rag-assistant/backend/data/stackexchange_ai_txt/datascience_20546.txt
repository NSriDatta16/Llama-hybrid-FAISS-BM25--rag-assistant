[site]: datascience
[post_id]: 20546
[parent_id]: 
[tags]: 
How to generate image using deep learning

There are lots of examples of classifier using deep learning techniques with CIFAR-10 datasets. The way it works is that, train thousands of images of cat, dog, plane etc and then classify an image as dog, plane or cat. But I want to do the reverse thing. I want to train dog, cat, planes and it should output images. Here is my idea Group similar/clear images of cat as value 1, a less similar/blur images as 1.1 and so on. Similarly, group similar images of dog as value 2 and less similar images as 2.1 and so on ... Do the same for all types of images. Generated dataset should look like this input output 1 pixels(24*24) of a cat images(clear) 1 pixels(24*24) of a cat images(clear) . . 1.1 pixels(24*24) of another cat images(blur) 1.1 pixels(24*24) of another cat images(blur) . . and so on Now train values of input and label of images as output. Input will be just 1 dimensional, may be I will think of some other data. Output layer will have 24*24 i.e 576 units or neurons. At the end of training, I want something like this, if I give a input for example 1.15 it should output a new image since we trained with values 1.1 and 1.2 but we didn't train with 1.11 or 1.115. Please give me some idea how can I do this? Any link to example or papers would be nice.
