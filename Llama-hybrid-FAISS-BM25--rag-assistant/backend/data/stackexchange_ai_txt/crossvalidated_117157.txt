[site]: crossvalidated
[post_id]: 117157
[parent_id]: 114385
[tags]: 
I can't tell you much about RBMs, but autoencoders and CNNs are two different kinds of things. An autoencoder is a neural network that is trained in an unsupervised fashion. The goal of an autoencoder is to find a more compact representation of the data by learning an encoder, which transforms the data to their corresponding compact representation, and a decoder, which reconstructs the original data. The encoder part of autoencoders (and originally RBMs) have been used to learn good initial weights of a deeper architecture, but there are other applications. Essentially, an autoencoder learns a clustering of the data. In contrast, the term CNN refers to a type of neural network which uses the convolution operator (often the 2D convolution when it is used for image processing tasks) to extract features from the data. In image processing, filters, that are convoluted with images, are learned automatically to solve the task at hand, e.g. a classification task. Whether the training criterion is a regression/classification (supervised) or a reconstruction (unsupervised) is unrelated to idea of convolutions as an alternative to affine transformations. You can also have a CNN-autoencoder.
