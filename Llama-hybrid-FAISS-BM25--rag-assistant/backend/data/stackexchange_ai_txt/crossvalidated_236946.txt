[site]: crossvalidated
[post_id]: 236946
[parent_id]: 
[tags]: 
Can parameter distributions be estimated well for a nonlinear model using penalized MLE?

I have measured a spectrum with a line shape that obeys a known parametric model $f$, given by a physical theory. Assuming the responses $y_i$ are given by $y_i=f(x_i;\{\theta_n\}) + \varepsilon_i, \quad \text{with} \quad \varepsilon_i \sim N(0,\sigma^2I),$ the objective is to perform MLE in order to determine the probability distribution of the parameters $\{\theta_n\}$, including confidence intervals. Conventional nonlinear regression calls for OLS. I used Metropolis-Hastings MCMC to determine parameter confidence intervals according to changes in $\chi^2$. This procedure gives reasonable estimates for $\{\theta_n\}$, but unreasonably small confidence intervals . In this situation OLS estimation has broken down because there is a small contribution to the experimental line shape from uninteresting nuisance factors which cannot be characterized well. This manifests in the residuals as a correlation, as illustrated in the figure below (my actual data is two-dimensional, but this demonstrates the principle). I found one article that thoroughly describes this situation , but it advocates either Monte Carlo or $\chi^2$ scaling as solutions, which seem wrong. Revised approach: Consider nonparametrically modeling the residual correlation: $y_i= f(x_i;\{\theta_n\}) + g(x_i) + \varepsilon_i, \quad \text{with} \quad \varepsilon_i \sim N(0,\sigma^2I).$ and using a penalized likelihood function for MLE. Such a procedure consumes the surplus dof in the residuals (I have $i$ up to ~2000 but $f$ has only ~10 model parameters) to construct a reasonably smooth function $g(x_i)$, which should 1) reduce bias in the estimation of $\{\theta_n\}$, and 2) expand the confidence intervals to more reasonable values, via a larger $\hat{\sigma}^2$. P-splines seem to be an attractive way to build $g(x_i)$ and construct the penalized likelihood function ( overview ). Once done, MCMC can sample the (penalized) likelihood function and gather statistics on $\{\theta_n\}$, as it was done for the OLS based regression. Can anyone provide any insight into the validity of this approach? Are there any alternatives for achieving my objective for this type of modeling failure?
