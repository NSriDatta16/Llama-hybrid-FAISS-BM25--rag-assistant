[site]: crossvalidated
[post_id]: 401660
[parent_id]: 
[tags]: 
Joint AR(1) posterior distribution explicit under conjugate prior

I have encountered a problem in my textbook ' The Bayesian Choice ' by Christian P. Robert. It goes something like this: $"$ For a particular case of AR(1) model, $(x_t)_{1\leq t\leq T}$ . Where $x_t = \rho x_{t-1}+\epsilon_t$ , $\epsilon_t$ i.i.d. $\mathcal{N}(0,\sigma^2)$ . Given a sequence of observations till time $T-1$ , $x_{1:(T-1)} = (x_1,\dots,x_{(T-1)})$ . The predictive distribution of $x_T$ is then $$x_T\mid x_{1:(T-1)}\sim \int\dfrac{1}{\sqrt{2\pi}}\sigma^{-1}\exp(-(x_T-\rho x_{(T-1)})^2/2\sigma^2)\pi(\rho,\sigma\mid x_{1:(T-1)})d\rho d\sigma.$$ Show that, in this scenario, the joint distribution $\pi(\rho,\sigma^2\mid x_{1:(T-1)})$ is explicit under the conjugate prior, $$\rho\sim\mathcal{N}(0,k\sigma^2),\quad \sigma^2\sim\mathcal{IG}(\alpha,\beta)."$$ Now my problem here is how do I show this? Can I show it without calculationg the joint posterior? I'm assuming this is not possible, so how do I calculate the joint posterior here? (Can I just take the product of the two posteriors? And on that note, how do I know when I can and cannot do this?) From what I've understood, one can only calculate the joint posterior by the product of each posterior if we know that they are not dependent on each other. In this case it seems like this is what is meant to be done. However, I have not been successful in finding more information on wheter or not this is how you would go about this calculation. Nor have I been able to establish that my interpretation of the requirements for deriving the joint posterior is correct.
