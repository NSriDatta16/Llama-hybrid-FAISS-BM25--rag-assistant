[site]: crossvalidated
[post_id]: 105453
[parent_id]: 104889
[tags]: 
This is extension of the suggestion by Frank in the comments. Dr. Harrel please correct if I am wrong (appreciate corrections). Your data: #random population of 200 subjects with 1000 variables M Install rms package and load it. require(rms) ols function is used for Linear Model Estimation Using Ordinary Least Squares where can specify penalty term. As suggested below in comments I added petrace function. This function trace AIC and BIC vs Penalty. # using holdout (50% of the data) cross validation training.id Important note I could not use all 1000 of the variables as the program complains if number of variable exceeds 100. Also y~. type formula designation did not work. So see above way of doing same creating formula object frm f "For an ordinary unpenalized fit from lrm or ols and for a vector or list of penalties, fits a series of logistic or linear models using penalized maximum likelihood estimation, and saves the effective degrees of freedom, Akaike Information Criterion (AIC), Schwarz Bayesian Information Criterion (BIC), and Hurvich and Tsai's corrected AIC (AIC_c). Optionally pentrace can use the nlminb function to solve for the optimum penalty factor or combination of factors penalizing different kinds of terms in the model." from rms package manual. calibrate function is for Resampling Model Calibration and Uses bootstrapping or cross-validation to get bias-corrected (overfitting- corrected) estimates of predicted vs. observed values based on subsetting predictions into intervals. The validate function does resampling validation of a regression model, with or without backward step-down variable deletion. B = number of repetitions. For method="crossvalidation", is the number of groups of omitted observations cal You can use Predict function to compute predicted values and confidence limits. I am not sure I this works in test situation.
