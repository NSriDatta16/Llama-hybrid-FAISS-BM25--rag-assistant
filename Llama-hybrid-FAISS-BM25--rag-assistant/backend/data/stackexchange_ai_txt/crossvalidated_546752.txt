[site]: crossvalidated
[post_id]: 546752
[parent_id]: 545834
[tags]: 
Before I begin, the most important thing for you to do is log-transform density in your model. That's because density is bounded at zero, and has a very heavy right tail: Furthermore, the Q-Q plot of your model residuals reveals very heavy tails: This is an absolutely clear example of needing a log transformation. It happens to resolve these problems in your case. Moving on to answer your question Repeated measures ANOVA is fine here (so would be mixed-effect modeling). This is the way. You would get the same result if you rewrote the error term as Error( experiment ) . This tells aov() to partition the residual error into two parts for the analysis of variance: differences between experiments, and differences within experiments. The "within experiments" part is the sum of squared differences between the observed and fitted values for each day's density. The "between experiments" part is the sum of squared differences between the observed vs fitted mean density of the experiments. The equivalent ezANOVA() call is: ezANOVA( exp.data3, dv= "density", wid=experiment, within=day, between=c("protein", "condition") ) Your aov() and lme() models are not exactly the same, but they are very similar. They're so similar because the design is balanced and the variance is quite equal between experiments. If the design was unbalanced or the variance was not so equal, then the partial pooling of residual error by lme() would become more important. In order to get results from glht() you need to assign its result to a variable, and then summarize that variable: tmp = glht(lme.model, linfct=mcp(protein="Tukey", condition="Tukey")) summary( tmp ) Simultaneous Tests for General Linear Hypotheses Multiple Comparisons of Means: Tukey Contrasts Fit: lme.formula(fixed = log(density) ~ protein * condition * day, data = exp.data, random = ~1 | experiment) Linear Hypotheses: Estimate Std. Error z value Pr(>|z|) protein: DEF - ABC == 0 0.80355 0.12817 6.269 Now it is easier to see the comparisons being made, as well as the standard error for the comparisons and the resulting z-statistic and p-value. That said, I prefer to use emmeans() over glht() because to me it is more explicit about what values are used for the other factors in the comparison. But I am not totally sure how their computations differ (I haven't dug that deeply into the code, myself). > emmeans(aov.model, pairwise ~ protein + condition) Note: re-fitting model with sum-to-zero contrasts NOTE: Results may be misleading due to involvement in interactions $contrasts contrast estimate SE df t.ratio p.value ABC jk - DEF jk -1.29127 0.0945 54 -13.668 Results are averaged over the levels of: day Results are given on the log (not the response) scale. P value adjustment: tukey method for comparing a family of 27 estimates I hope this helps!
