[site]: datascience
[post_id]: 100147
[parent_id]: 100089
[tags]: 
"An overfitted model is a statistical model that contains more parameters than can be justified by the data" This is an idea that is well past it's ``best before date''. In the early days of computational statistics, the most common way of controlling the complexity of a model was to limit the number of parameters (e.g. feature selection for linear models). But that hasn't been true for a long time. The early 1970s saw the introduction of ridge-regression, which introduced the idea of regularisation to control the capacity of a model. It adds a penalty term to the training criterion that penalises large magnitudes of weights. This is mathematically equivalent to placing an upper bound on the squared norm of the weight vector. This implements a simple form of "structural risk minimisation" (c.f. SVM) - if we increase the bound slightly, the model can do anything that it could do before, plus a few other things. So the regularisation parameter forms a set of nested model classes of increasing complexity. This means we can have over-parameterised model that don't over-fit, and indeed that is pretty much what modern machine learning algorithms are all about. So one thing that would reduce the confusion is not to comflate over-fitting (fitting the data too closely) with over-parameterisation (having more parameters than strictly necessary to represent the underlying structure of the data). When we "fit" a model, we generally mean we adjust the parameters of the model so that it's output more closely resembles the calibration data according to some criterion that measures the data "misfit". So over-fitting basically means reducing the value "data-misfit" function too much. How much is "too much"? If it makes generalisation performance worse, that is "too much". If you can make generalisation performance better by using a more complex model (or training it for longer) then your model is currently "underfitting" the data. Over/under-fitting is not defined in terms of bias or variance, it is defined in terms of the value of the training error (the data misfit) and the generalsiation properties of the model. Bias and variance are useful terms for understanding the consequences of over- and under-fitting. The diagrams help though.
