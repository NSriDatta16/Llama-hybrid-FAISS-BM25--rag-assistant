[site]: datascience
[post_id]: 102181
[parent_id]: 
[tags]: 
How much data augmentation is required on an imbalanced dataset?

Imagine I have a dataset with positive and negative sentences, and I need to train a transformer (Like BERT) to do the binary classification. The problem is that there are 100 negative sentences and 2000 positive sentences. There are libraries for NLP data augmentation like this one: https://github.com/makcedward/nlpaug But how many new instances should I add to the minor class? Since my dataset is highly imbalanced, should I try to add 1900 instances to the minor class so that both classes have an equal population? In order to make the imbalance ratio 1 in a highly imbalanced dataset such as mine, I have to use each sentence to generate 19 new sentences. If several of them are too alike, my model will end up overfitted.
