[site]: crossvalidated
[post_id]: 428611
[parent_id]: 428286
[tags]: 
I can only speak for SGD-variants typically used for neural networks. Typically it's the average over a small number (1-10) of random seeds. Usually if one optimizer is actually better than another, then it will be extremely apparent after just a single run, and the inter-run variance is typically very small, so a larger number of random runs is not useful.
