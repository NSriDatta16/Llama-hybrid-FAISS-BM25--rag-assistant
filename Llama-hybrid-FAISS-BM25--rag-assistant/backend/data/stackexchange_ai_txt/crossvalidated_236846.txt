[site]: crossvalidated
[post_id]: 236846
[parent_id]: 
[tags]: 
ROC Area Under Curve (AUC) in SVM - different results between R functions

I have two questions relating to ROC AUC values in SVM training and testing. After training and testing an SVM in caret I've found differences between the AUC values calculated by caret , pROC and the ggplot2 extension plotROC . The max AUC from training in caret is less than either AUC from testing. Is this normal? Intuitively I would have thought that testing AUC would be lower than in training because of some level of poor fitting to unseen data. Does anyone have an explanation for the differences between AUC from pROC and the ggplot2 extension plotROC that are both calculated on the testing prediction? I've had a look at the documentation for both pROC and plotROC (and the code for plotROC 's calculate_roc function) but haven't been able to determine a reason. Or have I made a coding error in calculating the AUCs? Reproducible example: Load the GermanCredit dataset that has 2 classes and various feature variables. data("GermanCredit") # Remove zero variance variables (prior knowledge) gc % select(-Purpose.Vacation, -Personal.Female.Single) Training/testing partition. set.seed(71) gc_i OPTIONAL: For parallel processing, set the number of cores (workers) and set seeds within resampling as running parallel processing. registerDoMC(cores = 2) # Set seeds for reproducibility ## In this case B = (5 repeats of 5-Fold CV) +1 = 51; M = 1 (only one parameter combination being used) set.seed(456) seeds1 Training gc_ctrl1 Using train1 best model to test. # Confusion matrix using `caret::confusionMatrix` gc_pred % select(-Class), type = "raw") gc_CM ROC and AUC using pROC # ROC using pROC gc_prob % select(-Class), type = "prob") gc_pROC ROC and AUC using plotROC (ggplot2 extension) # ROC using plotROC (ggplot2 extension) gc_prob_ex % select(-Class)) gc_ggROC
