[site]: crossvalidated
[post_id]: 197635
[parent_id]: 
[tags]: 
stacking complex models that are prone to overfitting

I am working on a CNN (convolutional neural net) model to classify certain songbirds. I am using one CNN to classsify images of the bird, and one CNN to classify audio sounds of the birds. I would like to combine the predictions made by both models. I however realize, even with usage of a validation set for both models and regularization, that either model might be prone to some overfitting. What is best practice to stack such models? Should one use a simple averaging to counter the inevitable overfitting of one of the models, or is best practice to use a seperate hold out set to tune the parameters of the stacked model? Any insight much appreciated.
