[site]: datascience
[post_id]: 123545
[parent_id]: 
[tags]: 
Variational Autoencoder Multi-Class Interpolation

I'm working on a variational autoencoder (VAE) with 20 different classes in my training data. I've successfully trained the VAE and can sample from the latent space to generate data points. However, I have a specific requirement: I want to generate samples from the latent space that somehow combines the properties of all 20 classes, rather than just falling somewhere in between two classes. In other words, I want to generate output images that exhibit features and characteristics that are representative of all 20 classes simultaneously. Is this possible with a VAE, and if so, how can I modify the sampling process or the latent space to achieve this goal? Many of the approaches I see (for example in MNIST) shows the morphing from one digit to another, but this is only between 2 classes. I understand that the VAE is designed to generate data points that are similar to the training data, but I'm interested in exploring ways to synthesize data that embodies a blend of characteristics from multiple classes. Any insights or guidance on how to approach this task would be greatly appreciated.
