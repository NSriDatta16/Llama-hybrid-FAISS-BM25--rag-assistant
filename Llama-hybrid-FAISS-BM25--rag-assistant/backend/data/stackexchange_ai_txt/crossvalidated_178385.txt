[site]: crossvalidated
[post_id]: 178385
[parent_id]: 
[tags]: 
Multivariate Bayesian Testing with an F-test

In Bayesian statistics a standard way to perform a Lindley significance test for the hypothesis $\theta=\theta_0$, where $\theta_0$ is the suggested value for $\theta$ at the $\alpha$ level of significane would be to construct an interval such that $Pr(c_l this question. Lets assume I want to investigate the hypothesis that $\beta=\beta_0$ in this case. I understand that I can perform a Bayesian F-test by computing: $$\zeta=\frac{1}{N-1}(\hat{\beta}-\beta_0)'\hat{\Sigma}^{-1}(\hat{\beta}-\beta_0)$$ Now I can check whether $\zeta$ is smaller than the $1-\alpha$ quantile of the $F(N,T)$ distribution. If this is the case the null hypothesis is not rejected. Is this way correct? Why can I do not compute credible regions for each of the elements of $\beta$ individually and reject the $H_0$ if one of the elements $\beta_{0,i}$ falls outside the region? To me this sounds more straightforward, but I do not find the argument that proofs me wrong. Looking forward to each and every comment.
