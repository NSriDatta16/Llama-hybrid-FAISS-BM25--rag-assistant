[site]: crossvalidated
[post_id]: 555582
[parent_id]: 
[tags]: 
How to optimally choose winsorization thresholds for different metrics in large scale A/B testing platform

I work on our A/B testing platform where we have implemented one-sided winsorization broadly across all continuous variables (capped at 95th percentile). While that's a common cut-off, some of our metrics exhibit very interesting behavior. Two examples: low adoption for a given feature, thus revenue at that 95th percentile is 0 and revenue at the 95th percentile are perhaps too restrictive (ie maybe we should winsorize at the 99% percentile) I haven't found much research on this specific topic but curious if there are techniques available to determine an optimal winsorization threshold, such that we can still meaningfully measure differences in control vs treatment, across various metrics that exhibit these behaviors. We also don't want to allow these to be individually configurable because, as you can imagine, this could encourage cherry picking thresholds, impacts to our site wide impact calculations, etc. Lastly, maybe this idea is totally irresponsible and we should just ignore the requests but hoping to hear some opinions!
