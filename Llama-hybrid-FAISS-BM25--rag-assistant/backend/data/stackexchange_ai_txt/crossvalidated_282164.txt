[site]: crossvalidated
[post_id]: 282164
[parent_id]: 
[tags]: 
Approximating SVM using Perceptron

Suppose that we have a set of linearly separable data and this pseudocode of Perceptron: Input: (xi, yi), i=1,...,n, w = 0, k = 0 Repeat: k = (k + 1) mod n if(sign(yi) != sign(traspose(w)*xi) then w = w + yi*xi end if until(every point is not misclasified) Is there a way to modify this code to get a separator hyperplane as optimal as possible? In other words, is there a way to modify this code to obtain a new algorithm that learns an hyperplane as similar as possible to the hyperplane that SVM algorithm obtains? Maybe iterating first on the most misclassified data, or changing the if condition to be more restrictive?
