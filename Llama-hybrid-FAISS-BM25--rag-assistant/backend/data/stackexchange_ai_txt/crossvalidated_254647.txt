[site]: crossvalidated
[post_id]: 254647
[parent_id]: 254641
[tags]: 
The reason that the variable importance is overall and not per class is a result of the way that importance is calculated. The importance assigned to a variable is the mean decrease in impurity averaged over all nodes where that variable was used to split the node. Certainly, the nodes are impure before splitting and often afterwards, so there would be no clear class to assign this change to. A quick example may help. Suppose that you have a node that has 40 points - 10 of each of 4 classes. You use a variable to split the node into two children. Each child has 20 points - ten from each of two classes. This would be a pretty useful split, but there is no way to assign credit to just one of the classes. The change in impurity is a statement about how the whole population was subdivided. This "example" was about one node. The measure is just the average of these changes over all nodes using the given attribute. But the change in impurity is a statement about how well the feature did at simplifying the population, not about how well it worked to identify a particular class. I think that you are also asking if there is a way to get a per-class importance. If you need such a measure, you could (with some work) get a measure of the importance of a variable in identifying a particular class by recoding the class variable into a binary variable. Given a specific value of the class to be predicted, class=A, you could create the binary variable classA which is 1 if class=A and 0 otherwise. Then compute the variable importance in predicting this feature. That should be useful in tying variables to a specific class. I doubt that there could be any useful comparisons of these measures across the different values of the class, that is, I don't think that you can compare the importance of a variable based on classA with the importance base on classB, but still for each class it would tell you something.
