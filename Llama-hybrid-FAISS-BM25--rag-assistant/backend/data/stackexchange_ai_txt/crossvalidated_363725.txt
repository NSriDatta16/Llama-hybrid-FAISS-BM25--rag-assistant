[site]: crossvalidated
[post_id]: 363725
[parent_id]: 363666
[tags]: 
The p-value is a statistic used in frequentist methodology, and its proper interpretation is fixed by its definition. Since the p-value is not a posterior probability, Bayesians would tend not to bother using this quantity at all. (If they decided to use if for some reason, it would have the same interpretation as a frequentist would give it ---i.e., the correct interpretation.) Within Bayesian statistics, competing hypotheses about the model parameters are generally tested by comparing the posterior probability of competing parametric hypotheses under a given prior.$^\dagger$ This is usually done using Bayes factor to write the ratio of posterior probabilities for a given ratio of priors. Given observed data $\mathbf{x}$ and disjoint parametric hypotheses $\theta \in \Theta_0$ and $\theta \in \Theta_A$ we have: $$\frac{\mathbb{P}(\theta \in \Theta_0|\mathbf{x})}{\mathbb{P}(\theta \in \Theta_A|\mathbf{x})} = \underbrace{\frac{p(\mathbb{x}|\theta \in \Theta_0)}{p(\mathbb{x}|\theta \in \Theta_A)}}_{\text{Bayes factor}} \cdot \frac{\mathbb{P}(\theta \in \Theta_0)}{\mathbb{P}(\theta \in \Theta_A)}$$ Bayes factor can be calculated from the likelihood $L_\mathbf{x}$ and prior $\pi$ as: $$BF_\mathbf{x} \equiv BF_\mathbf{x}(\Theta_0,\Theta_A) \equiv \frac{p(\mathbb{x}|\theta \in \Theta_0)}{p(\mathbb{x}|\theta \in \Theta_A)} = \frac{\int_{\Theta_0} L_\mathbf{x}(\theta) \pi(\theta) d\theta}{\int_{\Theta_A} L_\mathbf{x}(\theta) \pi(\theta) d\theta} \cdot \frac{\int_{\Theta_A} \pi(\theta) d\theta}{\int_{\Theta_0} \pi(\theta) d\theta}.$$ Once you have calculated Bayes factor for your parametric hypotheses, you can easily obtain the posterior probability ratio that obtains from any given prior probabilities for those parameters. If we take $\alpha = \mathbb{P}(\theta \in \Theta_0)$ to be the prior probability of the null hypothesis, and we assume that there are only two possible hypotheses (i.e., the null and alternative parameter spaces partition the whole parameter space), then we have the posterior probability: $$\mathbb{P}(\theta \in \Theta_0|\mathbf{x}) = \frac{\alpha BF_\mathbf{x}}{(1-\alpha) + \alpha BF_\mathbf{x}}.$$ This result allows you to substitute any prior probability $0 \leqslant \alpha \leqslant 1$ for the null hypothesis and get the corresponding posterior probability of that hypothesis. $^\dagger$ There are some papers that explore "Bayesian p-values" which are quantities that are somewhat similar to the frequentist p-values except that they are calculated as posterior quantities (see e.g., Meng 1994 , Gelman 2003 and Gelman 2012 ). These are less commonly used than the standard posterior parametric comparison using Bayes factor.
