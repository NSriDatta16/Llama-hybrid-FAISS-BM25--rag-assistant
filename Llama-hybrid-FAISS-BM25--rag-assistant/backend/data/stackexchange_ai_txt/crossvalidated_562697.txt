[site]: crossvalidated
[post_id]: 562697
[parent_id]: 562683
[tags]: 
I think it is as expected. This is a result of seasonal differencing. The effects of the MA, SAR and SMA components die out over time, and the forecast converges to one where each season has its own constant forecast. Asymptotically (in terms of a growing forecast horizon), it is as if your time series consists of $m$ independent random walks where $m$ is the number of seasons. The optimal forecast for each of them is the last observed value. These constants alternate as the seasons do. I would consider a model without seasonal differencing instead. If you want to maintain some seasonal variation in the forecast, consider regression with ARMA errors where the regressors are seasonal dummies or Fourier terms. That would give you something similar to your original forecast but smoother (in case of Fourier terms) and on a different level. Perhaps relevant: Rob J. Hyndman "Forecasting with long seasonal periods" (2010).
