[site]: crossvalidated
[post_id]: 639045
[parent_id]: 421935
[tags]: 
A lot of these posts are super technical, but I think make grasping the general idea difficult. So, I'm going to give a non-technical explanation. (If you want a technical explanation, this piece dives into more of the complexities.) I'm going to use an analogy with dating apps. You have... A man who is trying to figure out how to improve his dating profile. (This man is the query .) A woman on the app. (This woman is the key .) That woman's ideal partner (someone she would want to match with immediately). (Her ideal partner is the value .) Now, note that a dating profile is a representation of you. So, the man's goal is to improve his own representation. The attention mechanism is a special app that can automatically improve the man's profile by taking into account who he wants to match with and turning his profile into a fusion of their ideal partners. The attention mechanism app works by learning to do the following: Given a particular man (the query ), generate a new profile for that man that will be used to find women he might want to match with. (This function is called applying query weights .) Given a particular woman (the key ), generate a new profile for that woman that will be used to find men that might want to match with her. (This function is called applying key weights .) Given the key woman's ideal partner (the value ), generate a profile for that ideal partner. (This function is called applying value weights .) Now, the attention mechanism app doesn't learn how to perform these tasks by being given the best-performing human-designed profiles and learning how to copy or imitate them. Instead, men will use the profiles from the app, and the results of whether they get more matches or not will help determine small tweaks the app can make to do better next time. (This is gradient descent .) Given that these are the three things the attention app can improve at, here's how the app goes about coming up with suggestions for an improved profile for a given man: Step 1. Generate a new profile for the man that will be used to find women he might want to match with. (Apply the query weights to the query .) Step 2. For every woman on the app, generate a profile for them that will be used to find men that might want to match with her. (Apply the key weights to each key .) Step 3. Compare the man's generated profile to each of the women's generated profiles. We assume that the more similar they are to each other, the more the man likely wants to match with her, so it's really important that step 1 and 2 are done well. (Generate attention scores .) Step 4. Given the ideal partner for every woman on the app, generate a profile for each of the ideal partners. (Apply the value weights to each value to get a new value representation .) Step 5. Take all the ideal profiles from step 4 and combine them into a new final profile suggestion for the man, but weight how much each woman's ideal partner profile influences the man's final suggested profile based on how likely it is that the man wants to match with her. (Output a weighted sum of the new value representations based on the attention scores .) And that's it! That's how the attention mechanism works. Now, you may be thinking "this is a great analogy, but how is attention applied in practice?" Great question! I come from a natural language processing background, so I'll explain how it's used in my field. Those of us in natural language processing work with text, and so for us, queries, keys, and values are all words (technically tokens ). We use attention to come up with better representations for the query words based on the key/value words. Often this is used in translation systems where the (query) word in the translated language may be a translation of multiple (key/value) words in the input language. The process of creating male and female profiles with similarities to see who the man wants to appeal to is analogous to creating new query and key vectors via the learned weights to represent the query and key/value words such that vectors pointing in the same direction indicate that the translation query word should be heavily impacted by that input key/value word. Then, just like how the suggested male profile was a weighted sum of all the generated ideal profiles, the representation of the translated query word becomes a weighted sum of all of the generated (via the learned value weight matrix) value vectors of the key/value words. Now, you may also be wondering "What's the difference between attention and self-attention?" Notice how men and women were split up in this example? It was only men ( decoder tokens ) who were trying to improve their profiles, and they were only trying to improve them for women ( encoder tokens ). Self-attention is when everyone is trying to improve their profiles for everyone (better representations for all input tokens )! It's the same technique, but now everyone is a key and everyone's ideal partner is a value. So now everyone can create better representations of themselves that help them do what they want to do. Hopefully this helps explain how transformers work in a way that's a bit more easy to understand. I'm hopeful that having a model like this in your head will help a lot of the math to make more sense. (A sidenote for those of you who are planning to dive into the math: depending on the text, "query", "key", and "value" can either refer to the original encodings, the learned weight matrices that multiply the encodings, or the value of the original encodings multiplied by the weights. Usually $Q$ , $K$ and $V$ either refer to the original encodings (as I have done here) or the encodings multiplied by the weights (as the transformer paper does), and $W^Q$ , $W^K$ , $W^V$ refer to the learned weight matrices, but you often have to figure it out by context. There's also some tricks that people use like normalization and heads etc., but you can also find those details explained well here .) (And last, but certainly not least, my sincere apologies if it hurts (personally or systematically) to read yet another pretty classicly cishet example as an explainer; I unfortunately decided to prioritize this explanation's clarity over its inclusivity by including these gender and preference stereotypes to help readers keep track of the analogy. If you have a suggestion of how to improve the inclusivity without degrading the clarity, I would greatly appreciate it. Or if you just want to indicate that I should do better, a downvote will do that just fine. I'm not happy about the tradeoff either.)
