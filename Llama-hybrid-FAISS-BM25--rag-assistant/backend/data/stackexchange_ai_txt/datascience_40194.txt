[site]: datascience
[post_id]: 40194
[parent_id]: 29893
[tags]: 
When a machine learning model has high training accuracy and very low validation then this case is probably known as over-fitting. The reasons for this can be as follows: The hypothesis function you are using is too complex that your model perfectly fits the training data but fails to do on test/validation data. The number of learning parameters in your model is way too big that instead of generalizing the examples , your model learns those examples and hence the model performs badly on test/validation data. To solve the above problems a number of solutions can be tried depending on your dataset: Use a simple cost and loss function. Use regulation which helps in reducing over-fitting i.e Dropout. Reduce the number of learning parameters in your model. These are the 3 solutions that are most likely to improve the validation accuracy of your model and still if these don't work check your inputs whether they have the right shapes and sizes.
