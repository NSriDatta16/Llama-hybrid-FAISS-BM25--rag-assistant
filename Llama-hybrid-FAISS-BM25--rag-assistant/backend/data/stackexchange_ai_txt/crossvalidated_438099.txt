[site]: crossvalidated
[post_id]: 438099
[parent_id]: 
[tags]: 
How to perform multiple tests of contingency tables with more power: Fisher's / Barnard's test vs Logistic regression

I have a sample of answers to Yes / No questions: \begin{array} {c | c c c c} \hline \text{Case} & X_1 & X_2 & X_3 & X_4 \\ \hline 1 & 1 & 1 & 1 & 1 \\ 2 & 0 & 1 & 0 & 0 \\ . & . & . & . & . \\ . & . & . & . & . \\ 40 & 1 & 1 & 0 & 1 \\ \end{array} from, we assume randomly chosen, $n=40$ medical institutions from population of $N = 250$ institutions. Out of ${4\choose 2}=6$ possible dependencies between two variables, I am interested in testing 3 hypotheses: $H_0:$ $X_2$ and $X_1$ are independent; $H_0:$ $X_3$ and $X_1$ are independent; $H_0:$ $X_4$ and $X_2$ are independent. First question: I do not know if we should treat this data as paired? Second question: Could you please recommend me some good approach to test this hypotheses? I considered the following: Using Fisher's exact test where there are no fixed margins can lead to lower power comparing to Barnard's test; as described in this book . So I would rather not perform Fisher's exact test if better approach is possible. Could I use Barnard's test to test independence? If yes, can we assume pooled variance? Since all the data are binary and there are overlapping variables, could I just use logistic regression; eg. in R: glm(X4~X2+X1, data = data1, family = binomial) glm(X3~X1, data = data1, family = binomial) where this is the only meaningful direction of dependance.
