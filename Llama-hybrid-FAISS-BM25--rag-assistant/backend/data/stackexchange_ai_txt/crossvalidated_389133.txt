[site]: crossvalidated
[post_id]: 389133
[parent_id]: 256808
[tags]: 
I had a similar issue on another platform (PySpark), and I think it's independent of the coding because it's a data issue. Try reframing the data either with logical quantiles, or by removing high-leverage points ( One approach using linear models ). The concept behind this - if your data are crime rates by city, a city with a very high auto theft rate may form its own cluster, and the KMeans algorithm, in trying to maximize distance between clusters while minimizing distance between same-cluster points, will be reluctant to split up a much larger cluster with less variation. The high-leverage points can be pushed into their own cluster, allowing the algorithm to try to split up the much larger cluster. I've personally seen Quantiling take a KMeans solution in which one of the factors dominates and turn it into a solution in which all factors are valid. The quantiles artificially standardize variation by reducing the number of possible values that a cluster can be fit upon. Do you know which of your features has the highest variance or seems to be driving most of the cluster solutions?
