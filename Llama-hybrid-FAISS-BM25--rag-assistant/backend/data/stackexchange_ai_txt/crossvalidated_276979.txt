[site]: crossvalidated
[post_id]: 276979
[parent_id]: 
[tags]: 
Multi-input, multi-output time series regression loss using MASE

I have a time series regression that, given a set of lagged values, predicts all of the values from one step ahead to a given horizon. I'm trying to calculate the MASE for this, but am having a problem understanding how to apply it. My understanding is that the MASE is the ratio of the MSE to a scaling factor, equal to the 'naive forecast'. The problem I have with this is that doing a 'naive' forecast for multiple-output seems difficult to quantify 'naively'. For instance, if I have a set of values $1,2,..,n$, I may take in the first two $(1, 2)$ and want to output the series $3,..,n$. If this is the case then how can I use the "previous value" since this won't be available to the initial forecast? For instance, if I subtract the difference between: $$\{4,5,..,n+1\} - \{3,4,..,n\}$$ Then sum them up, this "naive" forecast will have more information to forecast on than my learning algorithm would have, so it's not 'naive' at all. If, instead I simply take the previous value and project it out, then it seems like I may overstate the error of the naive forecast, especially for a long horizon. I'm weighting the outputs of my forecast, so I've considered doing the same here, but it still seems like this could be result in overly generous error results. Is there any better way to apply MASE to multi-output time series regression?
