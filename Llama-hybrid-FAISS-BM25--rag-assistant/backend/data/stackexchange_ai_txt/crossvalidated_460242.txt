[site]: crossvalidated
[post_id]: 460242
[parent_id]: 108466
[tags]: 
I feel the current answers to this question do not really answer the questions, which were "What are differences or advantages of baysian (sic) lasso vs regular lasso?" and "are they the same?" First, they are not the same. The key difference is: The Bayesian lasso attempts to sample from the full posterior distribution of the parameters, under a Laplace prior, whereas lasso is attempting to find the posterior mode (also under a Laplace prior). In practice the full posterior distribution from Bayesian lasso is usually summarized by the posterior mean, so in practice this boils down to this: The Bayesian lasso attempts to find the posterior mean under a Laplace prior whereas the lasso attempts to find the posterior mode under a Laplace prior The advantage of the posterior mean vs the posterior mode is that the posterior mean will produce better prediction accuracy (assuming mean squared loss) if the Laplace prior is actually a true reflection of the distribution of the regression coefficients. However, this advantage is dubious in practice since in many applications the Laplace prior is not a true reflection of the distribution of the coefficients (and in general this is difficult to check!) The advantages of the posterior mode include that it is computationally much easier to find (it is a convex optimization problem). You may notice that I did not answer "when should I go for one or other methods". That is because this is a hard question to answer in general. My answer would be that generally there are better methods than either of these. But full discussion of this would require a lengthier post.
