[site]: datascience
[post_id]: 100387
[parent_id]: 33444
[tags]: 
As it is already mentioned in the comments, in tokenizing and NLP when you see UNK token, it is to indicate unknown word with a hight chance. for example, if you want to predict a missing word in a sentence. how would you feed your data to it? you definitely need a token for showing that where is the missing word. so if the "house" is our missing word, after tokenizing it will be like: 'my house is big' -> ['my', 'UNK', 'is', 'big']
