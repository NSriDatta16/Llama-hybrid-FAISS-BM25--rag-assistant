[site]: crossvalidated
[post_id]: 548445
[parent_id]: 548434
[tags]: 
You don't need deep learning for that. You have a list of keywords and need to match them. The problem is that they may be misspelled. Another problem is that sometimes you need to match a keyword with a different value ( small red fruit -> strawberry ). The first thing to notice is that those are two distinct problems. If you have misspelled keywords, you can just use one of the many available spellchecking algorithms, just use them against your list of keywords instead of the generic language-specific lists. Another option is to use a fuzzy search algorithm, there are also many available implementations, depending on your preferences in Python , Go , and other languages. This is mostly about calculating edit distance between strings. If you want to use an out-of-the-box, scalable solution, ElasticSearch has a fuzzy search build-in . Yes, you could use deep learning instead, but there are many reasons why this should be your last resort. For a neural network, you would need a lot of data such as the pairs you presented. We are talking of hundreds of thousands if not millions. You would need to train it, tune, debug, maintain it. That's a lot of work. Deep learning algorithm is a black-box algorithm, you don't know why and how exactly it makes its classifications. You have no guarantees that it doesn't invent some kind of crazy, overfitting rules that have nothing to do with your data. Neural network would be considerably slower and more computationally intensive, hence more expensive. A neural network would basically be learning to mimic what the fuzzy search algorithms are already doing: finding substrings with the smallest distance to the target keywords or will memorize your data and become a computationally inefficient lookup table. Why re-inventing the wheel? Finally, if you had a simple algorithm that works but misses edge cases, you could use it for the majority of the data and then focus on building a machine learning solution just for the edge cases. As for matching keywords with some other value, you can treat this as a two-step algorithm. In the first step, you do the fuzzy matching for the keywords. In the second step, you just use a hash table to map keywords to different values if needed. This is $O(1)$ complexity problem vs computationally intensive solution with deep learning. If you still insisted on using deep learning, I'd recommend having two different models: the first one learning to correct misspelled words and the second one doing a classification.
