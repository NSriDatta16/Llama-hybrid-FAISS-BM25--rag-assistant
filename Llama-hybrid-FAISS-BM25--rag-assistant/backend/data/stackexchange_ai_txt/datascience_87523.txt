[site]: datascience
[post_id]: 87523
[parent_id]: 87510
[tags]: 
@Media has given a great answer. I would only like to elaborate a few points here on the same. In order to use transfer learning on text, there are few amazing models that you can be using such as RoBERTa , BERT etc, which are easily available at huggingface's transformers library . You can train them as follows: Just initialize the models with pre-trained weights and freeze their weights. Change the last classification layer as per your classes and then train the classification layer with your dataset. (Just make sure you are using the right learning rate in order to train the classifier.) Well there is no clearly defined rule for how much data is required for training the neural network. But as a good rule of thumb, it is clearly a good practice to have at least 10 times data of the number of the classes. So in your case, it should be at least around 100 datapoints each class.
