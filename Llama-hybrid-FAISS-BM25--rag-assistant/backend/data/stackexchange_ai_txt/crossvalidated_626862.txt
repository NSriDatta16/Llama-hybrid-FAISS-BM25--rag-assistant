[site]: crossvalidated
[post_id]: 626862
[parent_id]: 
[tags]: 
Computing the variance explained by a predictor variable in logistic regression

I'm keen to know how to compute the variance explained by a particular predictor variable in the model (say component specific R squared). I went through Calculate variance explained by each predictor in multiple regression using R but I'm not clear about the explanation. For simplicity, let me give an example and raise the question in terms of the example. > y x1 x2 m1 summary(m1) Call: glm(formula = y ~ x1 + x2, family = binomial(link = "logit")) Deviance Residuals: Min 1Q Median 3Q Max -0.8905 -0.6764 -0.5979 -0.4634 2.1806 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -1.5240 0.2713 -5.617 1.94e-08 *** x1 0.2023 0.2431 0.832 0.405 x2 -0.3284 0.2451 -1.340 0.180 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 97.245 on 99 degrees of freedom Residual deviance: 94.624 on 97 degrees of freedom AIC: 100.62 Number of Fisher Scoring iterations: 4 Simply, I want to quantify the contribution (as a proportion of variance explained) of x2, to the model. What I know is, in the event where y is continuous, x2 is scaled, then the square of the regression coefficient of x2 is a close enough approximation to the proportion of variance explained by x2. In the event of binary logistic, I know that R squared of x2 is not the square of -0.3284. If not that, then what? I need to know how to compute this quantity in logistic regression situation.
