[site]: datascience
[post_id]: 126703
[parent_id]: 112397
[tags]: 
I'm having trouble even finding a list of all known abbreviations. Well, that doesn't matter to you, as you already have a list of the relevant ones, the abbreviations appearing in your dataset. The U.S. Postal Service maintains a list of ZIP codes and valid street addresses, plus standards such as valid abbreviations . There's a whole industry built up around answering the question "is the address on this letter a deliverable address?", for efficient mass mailings with few returned pieces. The U.S. Census Bureau maintains a list of CDPs, Census Designated Places. It seems to track pretty closely with the set of valid postal destinations, which I imagine is what you're interested in. In python you can conveniently access it with import uszipcode . It uses a sqlite database on the inside, so you can issue SELECT ... ORDER BY queries to your heart's content. Some U.S. post offices use modified address conventions, such as in Puerto Rico, but your use case perhaps is only concerned with fifty states plus the District. Upon encountering hyphenated names, you may find it convenient to turn - hyphen into SPACE, yielding a pair of words. It turns out that U.S. town names are mercifully short. Four words seems to be the max, e.g. Carmel By The Sea, in California. You have a canonical list of place names, and you also have more than one "dirty" datasets which include abbreviated names. Canonicalize all names by upcasing. Let us focus on an abbreviated initial word, such as "MT". Produce a list of canonical names, ordered by second word (with first word breaking ties). Produce a list of potentially abbreviated names, ordered the same way. Perform a two-way merge of these lists. Many of the result entries will be exact matches, which are uninteresting and may be ignored. Results that survive that filter correspond to abbreviations or typos, conveniently arranged for you in sorted order. Either eye-ball them to produce a list of abbreviations, or get a program or NLP model to do that for you. Produce a "refined" output list of names, which is now partly canonicalized. Now repeat for other word positions. Actually, tackling "last word" might be the biggest low-hanging fruit that remains, since New Jersey municipalities are often called TWNSHP, TSHP, TWP, and other amusing variants. Publish the URL of your resulting GitHub repo here, as an answer.
