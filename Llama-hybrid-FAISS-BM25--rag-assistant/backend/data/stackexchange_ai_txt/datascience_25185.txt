[site]: datascience
[post_id]: 25185
[parent_id]: 
[tags]: 
The Gradient descent different between in Ng coursera and Michael A. Nielsen book

I am learning the neural networking from NG machine learning course in coursera and the book neural networking and deep learning by Nielson. I have a little confusion about the understanding of the Gradient Descent. I see two different formals to update weight by the Gradient Descent between NG and Nielson. from Nielson: the chapter Two, section The backpropagation algorithm from NG: both of them are used to update weights after forwarding pass in the backpropagation algorithm. in Neil version, it seems there is a learning rating -Î· in NG version, it does not have any learning rating, and it more like the learning rating is +1. I am very confused on this. is there anyone can help me to understand it?
