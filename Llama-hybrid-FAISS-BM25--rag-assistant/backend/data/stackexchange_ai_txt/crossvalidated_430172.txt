[site]: crossvalidated
[post_id]: 430172
[parent_id]: 408604
[tags]: 
The two models that you mention in your comment are not at all the same thing: statsmodels.nonparametric.kernel_regression.KernelReg I think refers to Nadaraya-Watson kernel regression , where $$\hat y(x) = \frac{\sum_{i=1}^n k(X_i, x) y_i}{\sum_{i=1}^n k(X_i, x)}.$$ Exactly what $k$ they use is indeed underdocumented in statsmodels. The source has some references for _est_loc_linear that I haven't looked at, but they presumably establish what the locally linear method is; I also haven't dug through the code to understand what it's doing. _est_loc_constant doesn't have any references. It seems that they're using econometrics terminology I'm not familiar with; presumably this is all clear to the person who wrote it, but I don't know. scikit-learn's SVR is a totally different model, based on a regression-based support vector machine using the kernel trick . They're really not very comparable. Part of the reason SVR is so much faster is that it uses the optimized LIBSVM library, whereas statsmodels is (I think) all written in not-particularly-optimized Python. There are also some algorithmic differences; SVR can throw away the non-"support vectors," while statsmodels's KernReg is probably computing all pairwise differences. But, also, SVR is not doing any bandwidth tuning unless you explicitly tell it to (with some technique in sklearn.model_selection ), whereas I think KernelReg does bandwidth selection automatically.
