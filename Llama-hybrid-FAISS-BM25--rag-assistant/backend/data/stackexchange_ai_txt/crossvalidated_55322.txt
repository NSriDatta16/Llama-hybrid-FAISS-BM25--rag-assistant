[site]: crossvalidated
[post_id]: 55322
[parent_id]: 
[tags]: 
How to calculate the percentage of a sample that is delayed

I'm working on a thesis and I'm using a bit statistics to process the data. I have a certain population and in one sample (N=250) I measure the time it takes to reach a goal. Then I change something in the population that delays that time. I take another sample (N=250) and compare those two. I use a T test to get the difference between the averages of the two samples. So I know how much the average delay is. Now I'd also like to know how much percentage of the second sample has a delay. Is it possible to calculate this? And how? EDIT We are simulating a swarm of robots. One of them, the searcher, has to find a target by using the information of the surrounding robots. We do this 250 times and record the time it takes for the searcher to get to the target. This is our reference data. Then we add an enemy who sabotages the searcher and delays the time. We again run this 250 times and record the data. We are sure that some times the searcher gets to the target before the enemy can sabotage it because of the algorithm.
