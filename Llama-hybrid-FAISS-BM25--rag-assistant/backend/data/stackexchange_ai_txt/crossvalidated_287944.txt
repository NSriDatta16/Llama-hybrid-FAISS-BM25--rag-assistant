[site]: crossvalidated
[post_id]: 287944
[parent_id]: 
[tags]: 
What does fixing residual variance in MCMCglmm do?

When I fit relatively simple models with MCMCglmm, MCMC sampling usually shows good mixing, or at least if there is some extent of autocorrelation, it is usually easly resolved by specifying priors with a bit more care. However, in some cases - especially when fitting categorical models - MCMC chains look terribly, and no matter how I specify the priors, the chains remain ugly and the effective sample size is embarrasingly low. Nevertheless, in some cases this seems to be solved, by simply fixing residual variance at an arbitrary number (usually to 1). My questions are: Why does fixing residual variance solve autocorrelation and poor mixing in the MCMC chains? What does residual variance really stand for in the case of Bayesian regressions? I mean, are they functionally the same as in frequentist regression models? What does fixing resudial variance really mean for the model I'm fitting (in terms of reliability, validity, etc.)? So far as I can see, it is really hard for non-statisticians to educate themselves about how MCMCglmm works, as lots of the information is too technical, and in most cases, mining informations from forums or mailing lists do not provide full answers. Any help would be appreciated! Cheers, ZR
