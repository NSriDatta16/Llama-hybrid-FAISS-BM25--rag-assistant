[site]: crossvalidated
[post_id]: 460310
[parent_id]: 
[tags]: 
Single point estimate of joint posterior distribution

This is a very basic Bayesian beginner question about what to do when one does not want a full parameter distribution but only a single set of parameters. Example: Let's say we have a number of points and we want to draw a regression line. MCMC provides a large number of plausible combinations of intercepts and slopes but only one pair of intercept and slope can be used to draw one regression line. Worked R example. First, generate example data: set.seed(1404) x Bayesian linear regression can be done multiple ways (this is not a software question), let's keep it simple using rstanarm : library(rstanarm) mod1 That will sample a huge number of more or less plausible combinations of coefficients and print descriptive statistics of those: Estimates: mean sd 10% 50% 90% (Intercept) 155.1 94.8 34.9 153.9 277.0 x 58.6 1.0 57.2 58.6 59.9 sigma 442.5 32.0 403.0 440.1 484.1 These are however mean and quantiles of each parameter of its own. If I wanted to draw one single regression line in the above plot then I needed exactly one Intercept and one x-coefficient. In the simple linear case I could probably just take the mean of the Intercepts and the x-coefficients in the posterior distribution. In more complicated situations: Do we know that the mean of the coefficients makes sense in the joint distribution? If we did a more complicated regression, knowing the data generation process, maybe mod2 is it still sensible, to use each coefficient's single-point estimate and assume those single-point estimates combine to a sensible joint estimate? In my example, the posterior means form a decent regression line but my question is, whether we can always assume that or what would be a good way to find a joint single point estimate of the coefficients.
