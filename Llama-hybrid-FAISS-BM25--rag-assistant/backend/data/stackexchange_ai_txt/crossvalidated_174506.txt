[site]: crossvalidated
[post_id]: 174506
[parent_id]: 144897
[tags]: 
Might be a bit late... But. 1 - sklearn's Random Forest supports multithreading . GradientBoostingClassifier does not. This can be responsible for a 8 times speed up. 2 - sklearn's Random Forest works on a subset of the total number of features (at least, by default) whereas GradientBoostingClassifier uses all the features to grow each each tree. If you set the argument max_features for GBC, you can observe a huge speed-up (but different results). From sklearn documentation : max_features : int, float, string or None, optional (default=None) The number of features to consider when looking for the best split: If int, then consider max_features features at each split. If float, then max_features is a percentage and int(max_features * n_features) features are considered at each split. If “auto”, then max_features=sqrt(n_features). If “sqrt”, then max_features=sqrt(n_features). If “log2”, then max_features=log2(n_features). If None, then max_features=n_features. Choosing max_features Option 2 is a matter of choice/performance. As for option 1, an implementation of GBC supporting multithreading is now available: xgboost , https://github.com/dmlc/xgboost . I used it with R, but the python implementation seems even easier to use. Edit. Regarding the training time of various algorithm, you may be interested in learning more about complexities of machine learning methods .
