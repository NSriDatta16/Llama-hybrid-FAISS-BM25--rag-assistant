[site]: crossvalidated
[post_id]: 323341
[parent_id]: 323273
[tags]: 
I agree with everything said in amoeba's answer which provides a great summary of the current discussion on this issue. I will try to add a few additional points and otherwise refer to the handout of my recent mixed model course which also summarizes these points. Suppressing the correlation parameters (options 2 and 3 in amoeba's answer) via || works only for numerical covariates in lmer and not for factors. This is discussed in some detail with code by Reinhold Kliegl . However, my afex package provides the functionality to suppress the correlation also among factors if argument expand_re = TRUE in the call to mixed() (see also function lmer_alt() ). It essentially does so by implementing the approach discussed by Reinhold Kliegl (i.e., transfomring the factors into numerical covariates and specify the random-effects structure on those). A simple example: library("afex") data("Machines", package = "MEMSS") # same data as in Kliegl code # with correlation: summary(lmer(score ~ Machine + (Machine | Worker), data=Machines)) # Random effects: # Groups Name Variance Std.Dev. Corr # Worker (Intercept) 16.6405 4.0793 # MachineB 34.5467 5.8776 0.48 # MachineC 13.6150 3.6899 -0.37 0.30 # Residual 0.9246 0.9616 # Number of obs: 54, groups: Worker, 6 ## crazy results: summary(lmer(score ~ Machine + (Machine || Worker), data=Machines)) # Random effects: # Groups Name Variance Std.Dev. Corr # Worker (Intercept) 0.2576 0.5076 # Worker.1 MachineA 16.3829 4.0476 # MachineB 74.1381 8.6103 0.80 # MachineC 19.0099 4.3600 0.62 0.77 # Residual 0.9246 0.9616 # Number of obs: 54, groups: Worker, 6 ## as expected: summary(lmer_alt(score ~ Machine + (Machine || Worker), data=Machines)) # Random effects: # Groups Name Variance Std.Dev. # Worker (Intercept) 16.600 4.0743 # Worker.1 re1.MachineB 34.684 5.8894 # Worker.2 re1.MachineC 13.301 3.6471 # Residual 0.926 0.9623 # Number of obs: 54, groups: Worker, 6 For those not knowing afex , the main functionality for mixed models is to provide p-values for the fixed effects, e.g.,: (m1 Dale Barr from the Barr et al. (2013) paper is more cautious in recommending reducing the random-effects structure than presented in amoeba's answer. In a recent twitter exchange he wrote: "reducing the model introduces unknown risk of anticonservativity, and should be done with caution, if at all." and "My main concern is that people understand risks associated with model reduction and that minimizing this risk requires a more conservative approach than is commonly adopted (eg each slope tested at .05)." So caution is advised. As one of the reviewers I can also provide some insight on why we the Bates et al. (2015) paper remained unpublished. Me and the other two reviewers (which signed, but will remain unnamed here) had some criticism with the PCA approach (seems unprincipled and there is no evidence that it is superior in terms of power). Furthermore, I believe all three criticized that the paper did not focus on the issue of how to specify the random-effects structure, but also tries to introduce GAMMs. Thus, the Bates et al (2015) paper morphed into the Matuschek et al. (2017) paper which addresses the issue of the random-effects structure with simulations and the Baayen et al. (2017) paper introducing GAMMs. My full review of the Bates et al. draft can be found here . IIRC, the other reviews had kind of similar main points.
