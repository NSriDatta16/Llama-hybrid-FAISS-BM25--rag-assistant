[site]: crossvalidated
[post_id]: 461050
[parent_id]: 460974
[tags]: 
I would look at this problem by assuming the error distribution associated with the model: $$ Y_i = \alpha \beta^2 X_i^3 \ \ \text{for $i$ in $1, \ldots, N$} $$ has a multiplicative error (so lognormal). Then, upon apply a log transform, the error distribution is normal. So, now you have a standard linear model (in the transformed variables and coefficients) that can be viewed in the context of Bayesian linear regression. In particular, the conditional prior distribution is Normal and the posterior can be expressed as the Normal distribution times an Inverse-gamma distribution (see https://en.wikipedia.org/wiki/Bayesian_linear_regression ). Note, when you derive the Bayesian counterpart to a confidence interval for the mean expected value of ln(Beta), be mindful on applying the inverse transform (Exp(ln(Beta)), the interval now relates to the median of the original log-normal error distribution.
