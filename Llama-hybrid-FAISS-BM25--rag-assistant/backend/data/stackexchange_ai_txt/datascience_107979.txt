[site]: datascience
[post_id]: 107979
[parent_id]: 107976
[tags]: 
You can convert your data to float32 and feed it to an stack of LSTM Autoencoder with linear activation function. The following architecture works, but you an fine tune it: input_data = np.array([[[4, 3, 8, 6], [1, 1, 2, 2], [24, 18, 32, 24], [6, 6, 8, 8]]]).astype(np.float32) model = tf.keras.Sequential([ tf.keras.layers.LSTM(4, return_sequences=True, activation="linear"), tf.keras.layers.LSTM(2, return_sequences=True, activation="linear"), tf.keras.layers.LSTM(1, return_sequences=True, activation="linear"), tf.keras.layers.LSTM(2, return_sequences=True, activation="linear"), tf.keras.layers.LSTM(4, return_sequences=True, activation="linear"), ]) model.compile(optimizer="Adam", loss="MAE", metrics=["MSE"]) model.fit(input_data, input_data, epochs=200000) What I have got after 200,000 epochs!: [[[ 3.9911306 2.9956746 7.989547 5.9939675 ] [ 0.9976706 0.99182177 2.0006196 1.9999651 ] [23.9897 17.996624 31.995388 24.006733 ] [ 6.0549197 5.9584255 8.023056 8.003849 ]]]
