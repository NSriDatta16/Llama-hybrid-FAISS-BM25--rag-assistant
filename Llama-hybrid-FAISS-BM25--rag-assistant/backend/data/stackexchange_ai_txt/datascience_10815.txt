[site]: datascience
[post_id]: 10815
[parent_id]: 10803
[tags]: 
Effectively, Word2Vec/Doc2Vec is based on distributional hypothesis where the context for each word is its nearby words. Similarly, LSA takes the entire document as the context. Both techniques solve the word embedding problem - embed words into a continuous vector space while keeping semantically related words close together. On the other hand, LDA isn't made to solve the same problem. They deal with a different problem called topic modeling , which is finding latent topics in a set of documents.
