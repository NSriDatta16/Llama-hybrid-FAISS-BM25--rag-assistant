[site]: crossvalidated
[post_id]: 335801
[parent_id]: 63460
[tags]: 
The issues you point out are correct. Moreover, if one tries to artificially impose a total ordering on $\mathbb{R}^2$ (or more generally $\mathbb{R}^n$ with $n\geq 2$ ) then it would be unstable with respect to perturbations (this is because the Euclidean topology is not orderable for $n\geq2$ ). For example, if $\mathbb{R}^2$ was lexicographically ordered we'd have $(1,0) but $(1,0)>(1-\epsilon,200)$ for any $\epsilon>0$ . The paper Deep Sets provides a few ways to achieve what you are looking for in a deep learning framework. I'll assume the labels $p_i\in\mathbb R$ for now. One idea is to express your desired function as $$ f(d_i) = \rho\left( \sum_{(x,y)\in d_i} \phi(x,y) \right) $$ where $\rho$ and $\phi$ are suitable real-valued functions. This is manifestly permutation invariant and well-defined for sets of arbitrary finite cardinality. Since neural networks are universal approximators we choose to have $\rho$ and $\phi$ to be (deep) neural networks. Let $\theta$ represent the combined parameters of $\rho$ and $\phi$ . The game is now to minimize the mean-square-error $\frac{1}{N}\sum_{i=1}^N(f(d_i)-p_i)^2$ by adjusting $\theta$ via backpropagation. Edit: PointNet is another neural network architecture that can learn over point clouds (mainly used for $\mathbb{R}^3$ ). For your problem you may need to make modifications, but the main trick (in your setup) is to create the features by computing max's over your set with respect to some function $h$ and then feeding those $m$ features into some function $g$ . This can be written as, $$ f(d_i) = g\left( \max_{(x,y)\in d_i} h(x,y) \right) $$ where $g:\mathbb{R}^m\to \mathbb{R}$ , $h:\mathbb{R}^2\to\mathbb{R}^m$ and the max is taken component-wise. Once again, this is clearly permutation-invariant. As in Deep Sets, we would model the functions $g$ and $h$ as neural networks and then use backpropagation to minimize $\frac{1}{N}\sum_i (f(d_i)-p_i)^2$ .
