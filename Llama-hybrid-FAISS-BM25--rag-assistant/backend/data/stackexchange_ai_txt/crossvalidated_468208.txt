[site]: crossvalidated
[post_id]: 468208
[parent_id]: 466789
[tags]: 
Okay... I made a stupid mistake... During validation I wrote: # Move data to default device lookback = lookback.to(device) attention = attention.to(device) openSta = openSta.to(device) currentopen = openSta.to(device) promo = promo.to(device) labels = openSta.to(device) where there are multiple value mis-assigned... correct on should be: lookback = lookback.to(device) attention = attention.to(device) openSta = openSta.to(device) currentopen = currentopen .to(device) promo = promo.to(device) labels = labels.to(device) After the correction, the validation loss drop along with training loss. So I'll guess, except data issue, the valdation loss should always goes down with training loss within the first epoch...
