[site]: crossvalidated
[post_id]: 187036
[parent_id]: 187028
[tags]: 
The problem you are describing is related to doomsday argument and sunrise problem . Estimating something from ignorance in this case relates to Bayesian estimation with uniform prior . In basically any inference problem you have some data $D$ and some parameter $\theta$ that you want to learn about using your data. There are multiple different methods that can be applied to such problems and Bayesian approach is one of them. The general idea is that you can use your prior knowledge about $\theta$ , data and Bayes theorem to learn something about $\theta$ (i.e. posterior ): $$ \underbrace{P(\theta|D)}_\text{posterior} \propto \underbrace{P(D|\theta)}_\text{likelihood} \times \underbrace{P(\theta)}_\text{prior} $$ The basic idea is that you plug-in your prior into this formula and then check which of your prior expectations are likely given the data you have. Prior is some distribution for $\theta$ that is assumed a priori , that is, before seeing the data. You can make different assumptions about $\theta$ based on your actual problem and your subjective judgment. One simple choice that can be made is to assume that you have no knowledge whatsoever about $\theta$ just that it lies in some $[a,b]$ interval (so in fact you have some knowledge and make assumptions ). In such case you use uniform distribution $\mathcal{U}(a,b)$ for $\theta$ and assume a priori that all the values in this interval are equally likely. Next, you update your assumptions by confronting them with the data. In this case ignorance-prior is used to make assumptions about $\theta$ that are to be tested and verified against the data. This is helpful because it gives you method of finding candidate values of $\theta$ . Rephrasing it differently, you know nothing about $\theta$ , but still you start with something to plug-in in the place the unknown to learn about it. Notice that when using uniform priors this approach is coherent with maximum likelihood estimation , but when using non-uniform priors it can lead to different results that are influenced less or more by the prior. Bayesian approach could be also helpful in situations like the one described in your quote, where we do not have much data about problem of interest, where priors help to overcome those limitations by including out-of-data information in our statistical model. J. Richard Gotts (1993) example is pretty simple and it needs only few assumptions and some basic algebra to understand it. Imagine that you have some point $x$ that lies on the line $[a, b]$ , but you do not know exactly where it lies. For a moment let's forget what value does exactly have the beginning of the line $a$ and the end $b$ , but let's think of them as $0\%$ and $100\%$ of total length $b-a$ . Let's assume that $x$ can lie anywhere on the line, i.e. $X$ is a random variable uniformly distributed over $[a,b]$ interval. Making this assumptions lead us to conclusion that we have $0.95$ probability that $x$ is somewhere in the $95\%$ middle part of the line (recall that for uniform distribution $P(X ). So if we are in the $95\%$ middle region of the line, than $x$ is at least $0.025(b-a)$ or at most $0.975(b-a)$ . Gott, J. R. (1993). Implications of the Copernican principle for our future prospects. Nature, 363 (6427), 315-319.
