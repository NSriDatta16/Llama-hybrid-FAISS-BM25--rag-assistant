[site]: datascience
[post_id]: 54442
[parent_id]: 54352
[tags]: 
Shamoon! If you want to do it in a right way. You need to think as well about an amount of time your model will work with 20Kx300 feature values. So start with data preprocessing. Encode your categorical data (e.g. one-hot encoding) Reduce amount of dimensions ( here is a nice notebook for this) And then consider your data again. You can try the popular Random Forest and SVM. The best method depends on the way how the feature values are distributed. Good luck!
