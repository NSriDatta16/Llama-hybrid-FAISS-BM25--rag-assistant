[site]: crossvalidated
[post_id]: 441475
[parent_id]: 
[tags]: 
Why is Rademacher complexity defined the way it is?

For reference, this is the definition of empirical Rademacher complexity from Foundations of Machine Learning (page 30): Let $\mathcal{G}$ be a family of functions mapping from $\mathcal{Z}$ to $[a, b]$ , and $S=(z_1,z_2,\ldots,z_m)$ a fixed sample of size $m$ with elements in $\mathcal{Z}$ . Then, the empirical Rademacher complexity of $\mathcal{G}$ with respect to the sample $S$ is defined as: $$ \hat{R}_S=\mathbb{E}_{\overrightarrow{\sigma}}\left[\sup_{g\in\mathcal{G}}\frac{1}{m}\sum_{i=1}^{m}\sigma_ig(z_i)\right] $$ where $\overrightarrow{\sigma}=[\sigma_1,\sigma_2,\ldots,\sigma_m]^T$ , with $\sigma_i$ s independent uniform random variables taking values in $\{-1,1\}$ . The random variables $\sigma_i$ are called Rademacher variables. Previously, $\mathcal{G}$ was described, in the context of learning, as a family of functions which map $(x,y)$ to $L(h(x), y)$ , with $x$ being an example, $y$ its target value, $h$ a hypothesis from the hypothesis space and $L$ the chosen loss function. In that regard, wouldn't it make more sense for $\sigma_i$ s to be defined over $[a, b]$ in order to have the same range as $g(z)$ , rather than $\{-1, 1\}$ ? Since the expression under the supremum measures correlation between the random noise and performance of $h$ , does the empirical Rademacher complexity tell us how well a hypothesis space can fit the given sample to an arbitrary level of performance ?
