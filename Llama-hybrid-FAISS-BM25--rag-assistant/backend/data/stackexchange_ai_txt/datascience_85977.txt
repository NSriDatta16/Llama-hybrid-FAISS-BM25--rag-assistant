[site]: datascience
[post_id]: 85977
[parent_id]: 85948
[tags]: 
I understand that feature scaling is required to bring features in different magnitudes on a common scale so the model is not biased towards features with higher magnitudes. But if there is only a single feature in a feature set. For example, I have a quantity (events over time) on a time series and I'm forecasting for the future. In this case, do I need feature scaling (normalization or standardization?) or will it be unnecessary? Usually we would try to do feature scalling although the idea is to remove the dependence of absolute magnitiude in affecting convergence. it will help if the distribution is made gaussian with zero mean and unit variance. Since the gradient will be lower the stochastic descent will be a lot smoother.
