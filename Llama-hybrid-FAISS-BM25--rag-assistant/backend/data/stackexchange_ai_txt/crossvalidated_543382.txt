[site]: crossvalidated
[post_id]: 543382
[parent_id]: 543379
[tags]: 
I think concatenating the two arrays won't work with either architecture as the time dimension would not be separated from the data point itself, making it difficult for the network to learn from these two different aspects. Let's say a single training example from your description has a shape (1, 10) . If I understood correctly, if you want to add another one of the same size, but representing a single previous time step of the first array, i.e., if you have two arrays of (1, 10) , let $x_0$ and $x_1$ respectively, then $x_1(0)$ is a previous time step of $x_0(0)$ and so on. One option is that you can stack them and have a two-dimensional example (1, 10, 2) . Then, let's say you define a batch of 64 , you will then have a shape of (64, 10, 2), This can be fed to either CNN or LSTM, given that you define the layers with the proper hyperparameters (in CNN the number of channels, and LSTM the number of units). Hope it helps.
