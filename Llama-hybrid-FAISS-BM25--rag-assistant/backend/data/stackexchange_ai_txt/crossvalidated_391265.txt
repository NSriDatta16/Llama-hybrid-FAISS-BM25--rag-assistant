[site]: crossvalidated
[post_id]: 391265
[parent_id]: 
[tags]: 
Can double dipping be reasonable?

I found a paper where the authors used bayesian methods to estimate asymmetric effects in impulse response functions. In short the estimation procedure is: Calculate a VAR and Impulse responses (no matter what identification strategy). Express this IRFÂ´s as a a set of gaussian basis function. (This reduces the number of parameter) Use this estimates as the initial guess (=prior?) of a Metropolis-Hastings Algorithm. All steps use the same data. I'm a bit confused if it makes sense to extract the prior information from the same data where the MCMC algorithm will be used in the next step? I learned that "double dipping" is a problem in bayesian statistics. Since it is a relatively well-known paper, I assume that there is an explanation for this point, but I don't get it.
