[site]: crossvalidated
[post_id]: 497939
[parent_id]: 497935
[tags]: 
+1 to Thomas' answer . That said, this is not always a bad idea. For instance, in forecasting, we frequently have a large number of noisy time series that we can reasonably expect to share some common dynamics. In such cases, it's common practice to estimate these common dynamics on an aggregate level and then impose them on the separate series we are interested in. A common example is the impact of yearly seasonality on retail sales: you see the seasonality on, say, ice cream well enough if you aggregate over multiple stock keeping units (SKUs) and stores, but often not on the disaggregate SKU $\times$ store level. So people will aggregate total sales, estimate seasonality and push this down to the disaggregate series. This approach typically helps forecasting accuracy. In the end, this is again a case of the bias-variance tradeoff: this idea will inject some bias into the lower level models, but reduce variance, compared to estimating (say) seasonality on the lower levels. But then again, not including seasonality on the lower levels will do exactly the same. Either approach may be better than modeling seasonality on the disaggregate level - or they may both be worse, depending on the situation.
