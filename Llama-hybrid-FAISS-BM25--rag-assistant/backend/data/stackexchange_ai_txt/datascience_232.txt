[site]: datascience
[post_id]: 232
[parent_id]: 231
[tags]: 
There are a few ways to achieve your "master confusion matrix". Sum all the confusion matrices together: Like you suggested, summing this results in a confusion matrix. The problem with this is you can not interpret totals. Average the entries. This method is the same as number one, but you divide each entry by the number of trials (~400 in your case). This would be my preferred method because then you can actually translate each category to a (mean) +- (an error measurement) and actually see which categories are the most volatile or stable. Careful with interpreting this 'error measurement' though. Report a problem specific measurement of the confusion numbers. For example, if your numbers have outliers, medians would preferred over means. There are other statistics that are possible to report as well. You can redo the method to keep track of individual classifications. Then we can say other important stats like '% of classifications that stay the same and are accurate', etc...
