[site]: stackoverflow
[post_id]: 499135
[parent_id]: 497591
[tags]: 
You can also try to look into Latent Semantic Analysis and vector space models, with the problem that you have to limit the maximum string length. Your dimensions are the product of the elements of your alphabet and the positions in the string. Given the alphabet ("a", "b", "c", "t") and a maximum length of 3, the dimensions are (a:1, b:1, c:1, t:1, ..., a:3, b:3, c:3, t:3) As an example, "cat" becomes (0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1). This is of course a huge dataset, but you can use dimensionality reduction techniques (like SVD ) to cut down the number of dimensions. This should work well, because there are many recurring patterns in words. You can tweak the number of output dimensions to suit your needs. The similarity between two words can be computed by cosine similarity between the word vectors. You can also store the transformation vectors of the SVD to get the reduced vector for words, even previously unseen ones.
