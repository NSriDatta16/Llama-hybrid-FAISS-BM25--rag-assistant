[site]: crossvalidated
[post_id]: 637505
[parent_id]: 
[tags]: 
The Bing Tibetan Glitch Emoji Problem

Here's a very interesting mathematical statistics puzzle that I randomly stumbled into while using Bing. This turned out to be deep enough that I spent quite some time thinking how one could solve it! Even though the backstory is relatively entertaining, it seems like it is probably a very general (well-known?) statistics problem. Pardon the length, but I thought the backstory was interesting enough to share :) The puzzle: Bing's new AI language model has a very peculiar bug. If you send it a single emoji, from some list of unknown "glitch emojis," it will randomly respond with nonsense in Tibetan. For instance, here is its response to : The goal is to characterize all emojis which cause this response. Since there are 3782 emojis, sending one message with each would take hours. But here's the interesting thing. If you send Bing a message with only those emojis which have this "glitch" property, it will respond with Tibetan nonsense. But, if you send even one emoji that doesn't have it, it'll respond normally. Here's an example of both, where are glitch emojis and isn't: So, one can "batch test" emojis and potentially reduce the number of messages needed to characterize the set. Large batches are riskier, in that if you're lucky enough to have chosen all glitch emojis, you get tons of information right away, but if not, you don't know much except that at least one emoji was not a glitch emoji. Question : what is the best strategy to characterize the entire set of glitch emojis in the least amount of messages? For simplicity's sake, here are the mathematical assumptions we can make: All emojis are equally likely to be glitch emojis. There is no particular pattern regarding which emojis are glitch tokens and which aren't. The various emojis' glitch/not glitch statuses are all conditionally independent of one another. In particular, if we know that some emoji is or is not a glitch emoji, we assume this has no bearing on the probability for, e.g. neighboring glitch emojis, or any other emoji. We are given access to a black-box function that takes as input some subset set of emojis, and returns TRUE if and only if every single emoji is a glitch emoji. Then the question, really, is: if you, as a staunch frequentist/Bayesian/whatever, were required to solve this problem and maximize your chances of doing so in as few queries as possible, in some provably optimal matter (relative to whatever you view as 'optimal') how would you go about it? It seems likely to me that there are multiple notions of "best" here, and Bayesians and frequentists may have different views on this. One person may try to look at the expected value of the number of messages sent; another may look at the likelihood function, etc. So, I've left it open. I will post my partial solution below.
