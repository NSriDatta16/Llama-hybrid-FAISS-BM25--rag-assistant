[site]: datascience
[post_id]: 126756
[parent_id]: 
[tags]: 
Using Transformers on a seq2seq task with sparse labels

I'm new to the ML world and would like to ask for architecture advice for a project I'm building. I want to detect a certain event throughout an audio. For example, if the audio is divided into 10 MFCC bins, then the labels look like: [1, 0, 0, 0, 1, 0, 0, 0, 0, 1] . The labels are very sparse (ratio of 1 s > 0.97). I currently have ~500 audio files with corresponding 0/1 labels. Each audio is 1-5 mins long; ground truth labels are provided at 30 fps, so I have to divide audio into 1800-9000 bins. Each bin contains 20 MFCC features. I am currently using a very simple Transformer architecture: Embedding: I did not use an input embedding since the audio input cannot be tokenized. Transformer: 2 heads, 2 encoder layers Linear projection, then sigmoid to obtain a 0~1 label Loss: I tried both BCELoss (for 0/1 labels) and MSELoss (for 0~1 smoothed labels) My questions are: The model converges to a local minimum very quickly which is to predict all 0 s for all frames. This is likely due to the sparsity of 1 s in the labels. How does one usually design the architecture to overcome this? (On a subset of the dataset (~25 audio) I was able to use focal loss to put emphasis on 1 s more and overfit on the data, but of course the validation accuracy is terrible, and this didn't work when there are more data.) Is it appropriate to add decoders to this architecture? It seems like I can incorporate them if I reformulate the problem as "predict whether the event will happen in the next frame based on audio this frame", but I am not sure if I should just stick with an encoder-only architecture. My labels are rather human preferences other than "ground truths", which I suspect could also be a reason why the model is not learning. Instead of "a dog barks on this frame", my labels are more like "this frame is a good moment to take a deep breath while singing this song". Would augmenting data such as generating more data using sliding window help the model generalize, or problems like this are fundamentally difficult for Transformer-based architecture due to a small dataset? Any other feedback would be really appreciated as well. Thanks!
