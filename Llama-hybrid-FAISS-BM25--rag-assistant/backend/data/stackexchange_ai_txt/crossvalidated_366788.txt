[site]: crossvalidated
[post_id]: 366788
[parent_id]: 
[tags]: 
Alternatives to Neuronal Nets and Gradient Boosting for undifferentiable objectives

It may occur that one has to solve a ML problem but wants to achieve the best result w.r.t a metric that may not be differentiated. This directly implies that such a metric may not be passed to popular frameworks like tensorflow or xgboost . I it may be an alternative to train on a similar metric and then use a less sophisticated machine learning framework on the final layers of a neuronal net. This would require a machine learning framework that may be optimized for non-differentiable objective values. My question is which frameworks might work here? e.g. Quadratic Cohen Kappa, like in this challenge: kaggle.com/c/diabetic-retinopathy-detection
