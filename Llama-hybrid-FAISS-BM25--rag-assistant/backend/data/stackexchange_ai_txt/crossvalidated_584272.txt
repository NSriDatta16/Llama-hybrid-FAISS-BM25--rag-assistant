[site]: crossvalidated
[post_id]: 584272
[parent_id]: 
[tags]: 
how is it possible to fit parameters as exponents in bayesian linear regression

I have seen several examples of people performing bayesian linear regression in python packages such as stan or pymc3 where they have the parameters/distributions as exponents w.r.t the variables. e.g def transform(x, ec, slope): return 1 / (1 + (x / ec)**(-slope)) Where slope follows lets say an normal distribution with some mean and sd. This is clearly not linear w.r.t to the parameters and i am wondering how it is possible that we can derive the posterior from this since bayesian linear regression assumes linearity w.r.t to parameters? I have clearly missed an vital and basic part of bayesian linear regression. Can someone point it out?
