[site]: crossvalidated
[post_id]: 291690
[parent_id]: 291684
[tags]: 
Supose the posterior distribution is denoted by $\pi$ defined on a subset of $\mathbb{R}^d$. Then the Markov chain that samples from this distribution is a general state space Markov chain. Here are the conditions needed for a Markov chain to be ergodic (the definitions are simplified). $\pi$ is the stationary distribution of the Markov chain the Markov chain is aperiodic, i.e., it does not get stuck in a deterministic cycle of sets in $\mathbb{R}^d$. the Markov chain is irreducible, i.e., in some number of steps it can potentially go from any part of the space to any other part of the space. the Markov chain is Harris recurrent, i.e., it does the above infinitely often So any Markov chain constructed for general state spaces must satisfy the above properties to ensure Monte Carlo averages converge. If all full conditionals of distribution are well behaved (non-negative pdfs etc), then the Gibbs sampler will be ergodic, even though they may not be reversible. The right stationary distribution comes from the fact that each full conditional yields a Markov chain with stationary distribution $\pi$. Thus, a convolution (although non reversible), has stationary distribution $\pi$. All Metropolis-Hastings samplers are ergodic as long as the proposal distributions are well-defined. Hamiltonian Monte Carlo is a M-H sampler with an unusual proposal distribution which turns out to be well-behaved. So it is ergodic. The right stationary distribution comes from the fact that M-H are reversible with respect to $\pi$. Ergodicity guarantees convergence of the Markov chain. However, the tricky part is trying to choose a Markov chain that converges at a fast rate. Rates of convergence of Markov chain is much more difficult to establish. Main reference for all the above: Roberts and Rosenthal (2004)
