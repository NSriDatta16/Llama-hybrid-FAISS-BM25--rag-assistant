[site]: crossvalidated
[post_id]: 447438
[parent_id]: 447343
[tags]: 
Although this seems to be primarily a question about code in a specific package (off topic on this site), there is enough general statistical content to address briefly. Most of your general questions about deviance in cross-validation of a binomial/logistic model are answered quite well on this page . There is no fundamental difference from using cross-validation for an ordinary least squares model: what you evaluate is the performance averaged over the hold-out sets. The performance in this case is gauged by the deviance. Open source code makes it fairly easy to get as deep as you want into the implementation. In this case, the trick is to recognize that the object produced by glmnet() for a binomial model is of class "lognet" so that the work is done by the function cv.lognet() . The code for that function will be printed if the package is loaded and you type cv.lognet at the R prompt. With respect to the specific questions: The manual page for cv.glmnet specifies that the $glmnet.fit component of its returned object is "a fitted glmnet object for the full data." As you increase the penalty $\lambda$ the increasing penalization on the coefficient magnitudes necessarily means that the fitted model will match the data less closely and explain less of the deviance. As already noted, performance is evaluated on the held-out data in the cross-validation. Your second plot is based on the cross-validated averaged deviance values themselves, not the deviance ratio as in your first question and first plot; see the page linked above for the normalization apparently applied to the values. As noted in the answer to question (1) the $glmnet.fit component is for the full data, so its sub-component $nulldev will also be for the full data. One could adapt the code to report details for individual folds for each value of $\lambda$ , but it's not clear what practical advantage using pseudo R-squared values would provide over the deviance for finding an optimal value of $\lambda$ (whether that "optimal" is defined as the $\lambda$ value giving the minimum or the largest $\lambda$ within 1 standard error of the minimum.).
