[site]: datascience
[post_id]: 27756
[parent_id]: 27153
[tags]: 
What you have are predicted class probabilities. Since you are doing binary classification, each output is the probability of the first class for that test example. To convert these to class labels you can take a threshold: import numpy as np probas = np.array([[0.4],[0.7],[0.2]]) labels = (probas For multiclass classification where you want to assign one class from multiple possibilities you can use argmax : probas = np.array([[0.4, 0.1, 0.5],[0.7, 0.2, 0.1],[0.3, 0.4, 0.3]]) labels = np.argmax(probas, axis=-1) print(labels) [2 0 1] And to get these as one-hot encoded arrays you can use LabelBinarizer : from sklearn import preprocessing lb = preprocessing.LabelBinarizer() lb.fit_transform(labels) array([[0, 0, 1], [1, 0, 0], [0, 1, 0]]) And for multilabel classification where you can have multiple output classes per example you can use thresholding again: probas = np.array([[0.6, 0.1, 0.7],[0.7, 0.2, 0.1],[0.8, 0.9, 0.6]]) labels = (probas > 0.5).astype(np.int) print(labels) [[1 0 1] [1 0 0] [1 1 1]] Some packages provide separate methods for getting probabilities and labels, so there is no need to do this manually, but it looks like you are using Keras which only gives you probabilities. As a sidenote, this is not called "normalization" for neural networks. Normalization typically describes scaling your input data to fit in a nice range like [-1,1].
