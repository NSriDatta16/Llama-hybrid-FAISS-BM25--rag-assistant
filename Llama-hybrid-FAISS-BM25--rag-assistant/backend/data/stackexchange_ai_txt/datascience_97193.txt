[site]: datascience
[post_id]: 97193
[parent_id]: 103
[tags]: 
I guess you are refering to "similarity-based clustering", which is Clustering, which only uses the similarities between objects but does not require to represent the objects via feature vectors, is called similarity-based clustering. There are 3 approaches: Aspect model [... ]Hofmann and Puzicha [1999], Hofmann et al. [1999], considers discrete data, where observations are pairs (x, y) taht are counted. That means the number of occurrences of x together with y are counted. Such data appear if relations like “person x buys product y” or “person x participates in y” are counted. Applications are found in information retrieval by document-word relations or in bioinformatics by sample-gene relations. Affinity Propagation [...] Frey and Dueck [2006, 2007], Givoni and Frey [2009]. Affinity propagation is both a similarity-based and an exemplar-based clustering method. The similarities between object i and object k are given by s(i, k). The values s(k, k) are called “preferences” and used to determine how likely object k becomes an exemplar. The larger s(k, k), the more likely object k becomes an exemplar. Similarity-based Mixture Models [...] The similarity between object i and object j is considered as the conditional probability p(xj | xi). This idea was already introduced in stochastic neighbor embedding (SNE), where this was the probability that xi would pick xj as its neighbor. Another interpretation is: the more xj is similar to xi , the less modifications are necessary to obtain xj from xi , the higher is the probability to obtain xj (randomly) from xi . In contrast to SNE, we now assume that the p(xj | xi) are given to allow for similarity-based clustering. Source Machine Learning: Unsupervised Techniques, 2014, Sepp Hochreiter, Lecture Notes Bioinformatics Johannes Kepler University Linz
