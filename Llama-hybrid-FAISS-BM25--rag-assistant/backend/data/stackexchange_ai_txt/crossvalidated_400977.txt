[site]: crossvalidated
[post_id]: 400977
[parent_id]: 188087
[tags]: 
To add something: Whether the algorithm converges or not also depends on your stop criterion. If you stop the algorithm once the cluster assignments do not change any more, then you can actually prove that the algorithm does not necessarily converge (provided that the cluster assignment does not have a deterministic tie breaker in case multiple centroids have the same distance). Here you have 8 data-points (dots) and two centroids (red crosses). Now the green-data points have same distance to both the left and the right centroid. The same holds for the blue data-points. Let us assume that the assignment function is not deterministic in this case. Further we assume that at iteration 1 the green dots get assigned to the left cluster and the blue dots get assigned to the right cluster. Then we update the centroids. It turns out that they in fact stay in the same spot. (this is an easy calculation. For the left centroid you average the coordinates of the two left black dots and the two green dots -> (0, 0.5). Same for the right centroid). Then at iteration 2 the situation looks again the same, but now we assume that our (in case of ties) non-deterministic assignment function assigns the green dots to the right cluster and the blue dots to the left cluster. Again the centroids won't change. Iteration 3 is again the same as iteration 1. Thus we have a case where the cluster assignments continuously change and the algorithm (with this stop criterion) does not converge. Essentially we only have a guarantee that each step in k-means reduces the cost or keeps it the same (i.e. $\leq$ instead of $\lt$ ). This allowed me to construct a case where the cost stays the same through iterates, even though the assignment still changes.
