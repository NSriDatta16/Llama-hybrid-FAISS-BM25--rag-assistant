[site]: crossvalidated
[post_id]: 79170
[parent_id]: 68793
[tags]: 
Probability and statistics are essential. Some keywords are hypothesis test, multivariate normal distribution, Bayesian inference (joint probability, conditional probability), mean, variance, covariance, Kullback-Leibler divergence, ... Basic linear algebra is essential for machine learning. Topics that you could learn are Eigen decomposition and singular value decomposition. (Of course you should know how to compute a matrix product.) As TooTone already mentioned: optimization is important. You should know what gradient descent is and maybe have a look at Newton's method, Levenberg-Marquardt, Broyden-Fletcher-Goldfarb-Shanno. Calculus is not that important but it might be useful to know how to compute the partial derivatives of functions (Jacobi matrix, Hesse matrix, ...) and you should know what an integral is.
