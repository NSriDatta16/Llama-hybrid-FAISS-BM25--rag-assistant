[site]: crossvalidated
[post_id]: 493862
[parent_id]: 493579
[tags]: 
On the Bayesian side of things, loss functions are certainly important: If the cost of a false negative is high, eg, in adverse events for a vaccine trial, then you tend to not do classical multiple comparisons. Indeed, you don't even do regular (unadjusted) statistical inference; the current COVID-19 vaccine trial haltings are an excellent case in point. But one must not overlook priors, as they have an enormous impact upon whether one should perform classical multiple comparisons. In the case where there is prior reason to believe that many or all of the null models are all (nearly) true, then there is good reason to believe that unadjusted testing will yield false positives. For example, there is a cottage industry in manufacturing "me too" drugs in the pharmaceutical world: One company patents a molecule that works, then others rush in to patent other molecules that are similar with the exception of a moved atom here or there. It is a different chemical, but the moved atom may have no substantive effect. So in a (pre-clinical) screening experiment involving several such compounds, there is good reason to expect that one or more of such chemicals will give an incorrect indication of improvement over the standard, unless multiple comparisons adjustments are applied. The problem with some very prominent Bayesians' approach to this problem is that they completely dismiss the plausibility of near nulls. Instead, they opt for convenient hierarchical priors, usually normal, and blithely assume that shrinkage solve the problem. Such priors automatically assume that there is near zero plausibility for the near nulls. This practice violates not only Bayesian principles, but it also violates scientific principles, and it can easily lead to incorrect inferences. I won't name names, but you know who you are. As a matter of fact, if there is prior plausibility on the collection of (near) null models, then the Bayesian posterior probabilities behave like Bonferroni adjusted p-values; see Westfall, P.H., Johnson, W.O. and Utts, J.M.(1997). A Bayesian Perspective on the Bonferroni Adjustment, Biometrika 84, 419â€“427.
