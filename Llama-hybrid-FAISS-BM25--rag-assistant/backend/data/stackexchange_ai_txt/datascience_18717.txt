[site]: datascience
[post_id]: 18717
[parent_id]: 18713
[tags]: 
The problem is that training data will positionally biased by the fact that the probability of a click is correlated to the old model's prediction. It should be the case that many of your input variables are correlated in some way with the output, otherwise your model could not work. The main difference here is you are expecting a strong correlation from a single feature. This is not a problem - you could think of it as a complex form of feature engineering. You are essentially stacking the old model with some new variables which you hope are predictive. You should probably in this case include all the existing/old variables so that the new model can more easily spot mistakes made by the old model. My plan is to introduce a penalty factor on the original model's prediction to ensure that it doesn't dominate the new model I doubt this would be useful. However the correct way to assess this plan is to try it and measure the performance compared to the simpler version without any penalty.
