[site]: crossvalidated
[post_id]: 160564
[parent_id]: 149231
[tags]: 
I think those notes are slightly confusing. The rewards should be designed by you to encourage your RL agent to optimise the behaviour you want to see. The transitions between states are given by the enviroment and will often be estimated from data. I think what Andrew is refering to is a situation where from state A you could transition to state B which you give reward x or state C which you give reward y. If states B and C are identical except for the differences in reward, you would often eliminate states B and C and give state A a reward estimated from data which shows how often you transition to B or C from A.
