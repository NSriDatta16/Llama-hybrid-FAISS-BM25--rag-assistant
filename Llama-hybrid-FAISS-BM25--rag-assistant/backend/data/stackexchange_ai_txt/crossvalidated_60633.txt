[site]: crossvalidated
[post_id]: 60633
[parent_id]: 60626
[tags]: 
1) Your data look to be paired. You shouldn't ignore this 2) The usual proportions test assumes a constant 'success' rate across observations (the things you're testing the algorithms on). This doesn't sound like it will be the case. You might want to consider the test cases as randomly chosen from the population of possible ones that you want to extend your inference to - to treat the test sets as random effects in a mixed model. If your success rate is constant, you could maybe do a two-sample (possibly one-tailed) proportions test (though if the sample size is small you might consider doing it as exact binomial rather than the normal approximation, since the approximation may not be good). If you condition on the test sets but they have different success rates, then you have something that could perhaps be done as a chi-square (though you could work out a one-tailed test if you really need that). If you do treat the impact of the data sets you test on as a random effect, you'll need a mixed-model logistic regression (i.e. a GLMM ).
