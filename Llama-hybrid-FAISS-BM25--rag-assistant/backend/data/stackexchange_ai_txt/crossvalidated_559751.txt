[site]: crossvalidated
[post_id]: 559751
[parent_id]: 559744
[tags]: 
"Because it is not convex, we cannot optimize a model." It is not true that you can't optimize a non-convex function, it just means there is no guarantee of a unique global minimum and that there may be local minima. This isn't actually as much of a problem as often we don't want to find the global minimum (especially for an unregularised neural network) as it would almost certainly horribly overfit the data. It is possible that these local minima are actually beneficial. For a multi-layer perceptron type network, you will get multiple local minima just by permuting the hidden layer neurons, and by negating the input-to-hidden and hidden-to-output weights (for a network with one hidden layer). These modifications do not change the function of the network but give different weight matrices, demonstrating that these local minima are functionally equivalent and therefore not problematic. In practice, there are also likely to be local minima that are not functionally equivalent. The solution to this is normally to train the MLP several times, starting from different random initialisations of the weights, and retain the network that gives the best performance (e.g. using a validation set). Note that convexity is often given as an advantage of kernel learning methods, such as the support vector machine. However these methods tend to have kernel and regularisation hyper-parameters that are often optimised by cross-validation. The cross-validation loss that is being optimised is unlikely to be a convex function of the hyper-parameters, so kernel learning method are not truly convex either.
