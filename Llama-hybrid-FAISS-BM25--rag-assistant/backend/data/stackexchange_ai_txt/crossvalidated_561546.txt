[site]: crossvalidated
[post_id]: 561546
[parent_id]: 
[tags]: 
Log Naive Bayes NLP dropping the denominator

I'm learning about the the Naive Bayes classification and I don't get what the squiggly alpha sign means and what it means that "Denominator remains constant for given input." Is it because we're comparing different y inputs? Especially when we do log of this don't we subtract probabilities which makes the values more negative and potentially a negative classification instead of positive? $$ \boxed{ P(y|x_1,\ldots,x_n) = \frac{P(y)\prod_{i=1}^nP(x_i|y)}{P(x_1)\cdot P(x_2)\cdots P(x_n)}\\ \\ \textrm{Now as the denominator remains constant for a given input, we can remove that term:}\\ \\ P(y|x_1,\ldots,x_n) \propto P(y)\prod_{i=1}^nP(x_i|y) } $$
