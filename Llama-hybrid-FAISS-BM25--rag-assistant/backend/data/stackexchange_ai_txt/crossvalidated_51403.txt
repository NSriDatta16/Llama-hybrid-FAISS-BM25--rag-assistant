[site]: crossvalidated
[post_id]: 51403
[parent_id]: 
[tags]: 
Is the square root of a positive semi-definite matrix a unique result?

I am trying to decompose a time series of $n$ observations $\bf{\mathrm{v_c}}$ into the $n \times n$ variance-covariance structure $\sum$ and a random series $\bf{\mathrm{v}}$. So, I can derive the variance-covariance matrix $\sum$ from the autocorrelation function of $\bf{\mathrm{v_c}}$. This will be a Toeplitz matrix, which is positive semidefinite. Therefore, I am able to compute a suitable matrix $\sum^{-\frac{1}{2}}$ to transform my correlated series into a random signal. $\bf{\mathrm{v}} = \sum^{-\frac{1}{2}}\bf{\mathrm{v_c}}$ I am able to do this using the sqrt(m) function in MATLAB, but can also find a Cholesky factorisation of the variance-covariance matrix and use this to induce the correlations. However, I get different (but somewhat similar) results for the random series using the sqrtm and Cholesky methods. I have read through several texts to determine how I might ascertain the square root of various matrices, and have looked at eigenvalue decomposition methods and so on. I see there are only unique solutions under certain prescribed conditions - but I presume that these unique solutions are still only one of many roots? My question is this: is there any way to argue that one particular square root is preferable over another. If not, is there a way to extract all possible solutions, such that all possible random functions may be obtained?
