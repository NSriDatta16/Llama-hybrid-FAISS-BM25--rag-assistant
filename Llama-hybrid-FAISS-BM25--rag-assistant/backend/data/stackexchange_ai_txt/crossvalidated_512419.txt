[site]: crossvalidated
[post_id]: 512419
[parent_id]: 
[tags]: 
Is this approach appropriate? (bias towards minorities)

I am conducting an analysis to see whether stop and searches in the UK have bias towards minorities. The data looks like the following: ethnicity actionTaken Black Action taken White Action taken Asian No action taken Other No action taken There are 200k entries in my data and there are also other metrics like age, gender, location, etc. The action taken variable has 14 different levels, like: cautioned , arrested , court summoned , no action taken , so I divided these into two levels as shown above: action taken and no action taken . The reason I did this is to create a logistic regression model. My (first) method is to determine whether there exists bias via "hit rates" ( which is taken from this paper ). Hit rate is calculated by the amount of successful stop and searches divided by the total amount of hit rates. Lower hit rates means lower standards of suspicion are applied when deciding to conduct a stop and search procedure. The first thing I do is I calculate the hit rates of each ethnicity and then via Chi-squared tests for Homogeneity I determine whether there are significant differences in the hit rates. When it comes to Others (ethnicities), I have the following table: table = as.table(rbind(c(1925,476),c(721,233))) names(dimnames(table)) = c("Ethnicity","Outcome") rownames(table) = c("White","Other") colnames(table) = c("Successful", "Unsuccessful") chisq.test(table) Which produces the following output: Pearson's Chi-squared test with Yates' continuity correction data: table X-squared = 8.3882, df = 1, p-value = 0.003777 So, this means that there is a significant difference in proportion (i.e. hit rates), so this means that there is a tendency towards bias for police officers to apply lower standards of suspicion to Others, compared to White. (Just for reference, the hit rate for Whites is 80% and for others it is 75%). Back to the logistic regression: I create a model and I get the following output: Call: glm(formula = OutcomeClassFac ~ ethnicity, family = "binomial", data = df[df$Force == "nottinghamshire", ]) Deviance Residuals: Min 1Q Median 3Q Max -1.9660 0.5593 0.6648 0.7319 0.7484 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) 1.39726 0.05119 27.296 And I explain the coefficients in the following way: The odds of having a successful stop and search for the police on Asian people over the odds of having a successful stop and search for the police on White people is $\exp(-0.378)=1.46$ . In terms of percent change, we can say that the odds for Asians are 46% higher than the odds for Whites, clearly indicating that there are no lower standards of suspicion applied to Asians. Following the same method as above the odds for Black people over White people are $\exp(-0.216)=0.80$ , i.e 20% lower than the odds for Whites, which could indicate bias. For Other people the odds over White people are $\exp(0.267)=.76$ , i.e 24% lower than the odds for Whites, which could indicate bias. I then do hypothesis testing to see whether Blacks and Others are indeed getting disparate treatment: # Testing whether the coefficients of White and Blacks are significantly different. We will not set the Whites as a reference so that we can use their coefficient when conducting the hypothesis df$ethnicity The test for Others returns: Wald test: ---------- Chi-squared test: X2 = 8.6, df = 1, P(> X2) = 0.0033 So this indicates that the coefficients are statistically significant and hence there's Bias towards Others. Hence, this modelling coincides with the results I get from the method I read in the paper linked above. Questions: Would this be an appropriate method? Am I doing anything wrong with the modelling part?
