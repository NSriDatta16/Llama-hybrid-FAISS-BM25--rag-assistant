[site]: datascience
[post_id]: 122125
[parent_id]: 
[tags]: 
What do averaged word vectors represent?

Assume you have high-dimensional word embeddings (d > 100) for a large number of words (|V| > 100,000) calculated over a huge non-specialized natural language corpus. Assume you have taken the average of all vectors of words referring to animals (like family and species names and common words like "cat"). Would one say this averaged vector represents the "prototypical animal"? Would one expect this vector to be similar to the vectors of "animal" and "animal-like"? How would the averaged vector probably look like? Will for example many dimensions be cancelled out by averaging, and only a small number of non-vanishing dimensions remain? Will this characteristic "spectrum" be said to represent "animal-likeness"? Or won't there be something characteristic to be found? (I could try to find out by myself by using available word embeddings , but I have no idea how to extract the words referring to animals from some several 100,000 words.)
