[site]: datascience
[post_id]: 18197
[parent_id]: 18177
[tags]: 
Let's recall the rating prediction of restaurant $ x $ and user $i$ as a weighted sum according to the similarity: $$r_{x,i} = \frac{\sum_{j\in N(i,x)} s_{i,j} \cdot r_{x,j}} {\sum_{j'\in N(i,x)} s_{i,j'}} $$ were $ s_{i,j}$ is the similarity between user $i$ and user $j$ and $N(i,x)$ is the set of all restaurants that were both similar to restaurant $x$ and were rated by user $x$. This set can be found by applying knn and finding $k$ similar users to user $i$ (i.e. the collaborative in collaborative filtering). Now given more prior knowledge, such as geographical location, we can tweak our formula to account for those biases. Generally speaking, when you see a user rates a restaurant, you should account the habits rating of that user (how much does he usually rates above or below the mean) and the restaurant affect (how the restaurant is rated in respect to the mean rating). Denoting the total rating mean as $\mu $, the user mean rating as $\bar{r_i}$ and the restaurant average rating as $\bar{r_x}$, we can break down the rating to it's biases (deviances from the mean) as such: $$b_{x,i} = \mu + \underset{b_i}{\underbrace{(\bar{r_i} - \mu)}}+ \underset{b_x}{\underbrace{(\bar{r_x} - \mu)}}$$ Now the prediction will look as follows: $$r_{xi} = b_{x,i} + \frac{\sum_{j\in N(i,x)} s_{i,j} \cdot (r_{x,j}-b_{x,j})} {\sum_{j'\in N(i,x)} s_{i,j'}} $$ Now this was quite general, just in order for us to speak in terms of biases. Once at hand we can apply them as we see fit. The most simple way I can think of (you're welcome to share more elaborate ones) is to take the restaurant bias $b_x$ and instead of calculating it over the whole data (using the general $\mu$), you can do as follows: Take all your lats and longs, project them onto some 2D sheet or 3D ellipsoid (Depends on the accuracy you wish to achieve. What projection to use is somewhat an art for it self, there's vast literature, but usually simpler method work good enough). Cluster the restaurants into some $H$ clusters. Those will be geographically related. (Again, Euclidean distance will do, but there are more sophisticated ones ) For every cluster $h\in H$ you calculate it's own $\mu^{(h)}$, and now for all the restaurants $x^{(h)}$ related to cluster $h$ you calculate it's own bias term: $$b_{x^{(h)},i} = \mu^{(h)} + \underset{b_i}{\underbrace{(\bar{r_i} - \mu^{(h)})}}+ \underset{b_{x^{(h)}}}{\underbrace{(\bar{r_{x^{(h)}}} - \mu^{(h)})}}$$ So, basically, you broke down your general rating data into $H$ geographically close datasets that capture some spatial locality. I'll be happy to elaborate more if needed.
