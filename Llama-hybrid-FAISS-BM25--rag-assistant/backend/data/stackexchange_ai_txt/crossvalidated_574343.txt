[site]: crossvalidated
[post_id]: 574343
[parent_id]: 
[tags]: 
Does PCA centering guarantee projection optimality onto an affine set subject to dimensionality constraint?

Say I have $m$ points in $R^n$ , not necessarily with sum 0, and I want to project them onto an affine set $S$ with $\dim(S)=d$ for a given $d$ so as to minimize the sum of the squared distances between the $m$ points and their corresponding projections. If I were looking for the optimum vector subspace of dimension $d$ , then Eckart-Young theorem would guarantee that taking the subspace spanned by the $d$ principal components is optimal. Note that the difference is that the latter restricts the affine set to pass through the origin. Normally, when we perform PCA, we center the data and then look for a subspace, thus actually looking for an affine set passing through the mean of the $m$ points. So my question is: is there any proof that the answer to my initial question always passes through the mean value? Can one prove that minimizing the sum of squared distances from points to their projections onto $S$ subject to $S$ being an affine set of dimension $d$ is reached for some $S$ that passes through the mean value? Or, equivalently, is it that centering the data guarantees optimal projection cost? Here by affine set I mean an $S \subseteq R^n$ s.t. for any $a, b \in S$ and any $\lambda \in R$ , we also have that $\lambda a + (1-\lambda)b \in S$ , which is basically a vector subspace + translation.
