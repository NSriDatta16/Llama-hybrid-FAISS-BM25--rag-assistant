[site]: crossvalidated
[post_id]: 275953
[parent_id]: 
[tags]: 
How to do weight normalization in VGG network for style transfer?

We're doing a re-implementation of the style transfer algorithm in Gatys et al. Image Style Transfer Using Convolutional Neural Networks . There are many example implementations out there but except for the authors almost everyone goes with the standard network with pretrained weights. In section 2 - Deep Image Representations there is the following passage: We normalized the network by scaling the weights such that the mean activation of each convolutional Ô¨Ålter over images and positions is equal to one. Such re-scaling can be done for the VGG network without changing its output, because it contains only rectifying linear activation functions and no normalization or pooling over feature maps. I'm wondering what that means in practice - is that capturing the activation maps for all images in imagenet (training set) and then adjust the relu weights based on those sums across all images, all positions for each filter element? Not sure how to interpret this if it's not related to training data at all.
