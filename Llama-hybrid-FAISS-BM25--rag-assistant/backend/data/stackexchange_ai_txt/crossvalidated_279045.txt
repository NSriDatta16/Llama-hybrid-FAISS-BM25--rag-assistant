[site]: crossvalidated
[post_id]: 279045
[parent_id]: 
[tags]: 
Stationarity & Macroeconomic Forecasting

I'm working with a time series of macroeconomic data (independent variables) and bank loss rates (dependent variable) to show how bank losses vary based on the state of the economy. What I'm doing is two-fold: I need to identify the most predictive economic indicators for my model and then I need to regress those variables against bank losses using OLS. The ultimate application of this is to forecast loss rates in varying economic climates. One topic that has been coming up over and over again in terms of my model structure is regarding the stationarity of the data. As most on this board know, time series of economic data rarely pass stationarity tests. My question to everyone is how I should proceed in the event that my model does not satisfy stationarity test results. Let's assume for the example below that I have a simply univariate model where Loss = a + B*UnemploymentRate + e . Please note that the univariate model is only for example - when I'm constructing the actual model, I use multiple economic variables in my regression. Below is an example of my model construction process, and was hoping for feedback on what's wrong with my process 1: Cleaning the dependent data using decompose() in R Because I'm using quarterly data, I want to remove seasonality as well as remove noise. I use the decompose() function to do this. My final dependent variable is the trend series shown in the plot below: I don't clean the economic variable because I'm using the seasonally adjusted unemployment rate that's provided by Bureau of Labor Statistics. 2: Regress the variables When I regress unemployment rate against bank losses, I get the following regression output: Estimate Std. Error t value Pr(>|t|) (Intercept) -1.236e-03 2.077e-04 -5.954 4.96e-08 *** Unemployment Rate 3.762e-04 3.077e-05 12.225 The fitted results (red) vs. dependent variable (black) is plotted below. For a single factor model, the fitted results mostly capture the trend in my data: 3: Validate the Results Finally, I perform validation tests by testing my model residuals for a unit root using the PP test. As shown by the test below, the residuals have a unit root. However, if I were to perform a multivariate regression with more than one economic variable, I would greatly reduce the size of the residuals and mostly eliminate the autocorrelation of the residuals. Phillips-Perron Unit Root Test data: na.omit(varDiff$residuals) Dickey-Fuller Z(alpha) = -11.018, Lag parameter = 3, p-value = 0.47033 Third Party Feedback When having internal reviewers evaluate my model, the review teams are latching on to the non-stationarity of my independent and dependent variables. Both variables show a clear presence of a unit root (when testing them using ADF.test or pp.test), and fail all test measures for stationarity. My question is two fold: 1) does the non-stationarity of my model variable's render these models void? 2) If so, what measures should I take to correct for the non stationarity? I've thought about the second point a bit, and the two solutions I keep reading are cointegration and differencing. I've tried cointegration and these economic factors are not passing cointegration tests. On the differencing side of the spectrum, below are the OLS results when I difference both the dependent and indendent variable: diff(Loss) = a + B*diff(UnemploymentRate) + e Estimate Std. Error t value Pr(>|t|) (Intercept) 3.011e-06 1.530e-05 0.197 0.844 diff(Unemployment Rate) 3.055e-04 4.439e-05 6.883 7.93e-10 *** Multiple R-squared: 0.3474, Adjusted R-squared: 0.34 As you can see, the variable is still highly significant, but the R-squared drops to unacceptable levels. From a review standpoint, differencing solves the stationarity issue but creates a new finding as the reviewers would jump on the low fit statistics. Given everything I've layed out, I want to see what modeling techniques I should consider moving forward?
