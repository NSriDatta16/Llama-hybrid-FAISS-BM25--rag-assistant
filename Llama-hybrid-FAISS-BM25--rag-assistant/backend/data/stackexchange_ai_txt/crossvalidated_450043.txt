[site]: crossvalidated
[post_id]: 450043
[parent_id]: 
[tags]: 
Can you recycle posterior probability distributions into the same model and experiment?

Suppose I have some classifier which is reasonably good at discriminating classes. I have a new dataset which I know has a very unbalanced class distribution, but I don’t know anything about this distribution, so I use a uniform prior distribution for my classifier. Because my classifier is a good discriminator, the output posterior distribution is much closer to the actual distribution of the dataset than the uniform distribution that I originally assumed. My understanding is that in the next experiment with similar parameters, I can use this posterior distribution as the prior to improve the classification output. My question is: can I also use this posterior distribution with the original dataset to improve the output? I’ve actually done this using a neural network as a classifier with thresholding according to Bayes’ theorem (essentially, prediction thresholds are proportional to the given prior distribution). Running prediction with uniform priors to get a posterior probability distribution, and then re-running prediction with that new distribution as the priors yields much better results compared to using just the uniform distribution. In fact, doing this over and over again recursively until predictions converge yields the best results, and comes extremely close to predicting the actual class distribution of the dataset. I hope this question makes sense — I’m fairly new to probability theory so I’m mainly concerned with whether or not this approach is valid, or if my results are somehow spurious.
