[site]: datascience
[post_id]: 90441
[parent_id]: 
[tags]: 
How does the Transformer predict n steps into the future?

I have barely been able to find an implementation of the Transformer (that is not bloated nor confusing), and the one that I've used as reference was the PyTorch implementation. However, the Pytorch implementation requires you to pass the input ( src ) and the target ( tgt ) tensors for every step, rather than encoding the input once and keep on iterating for n steps to generate the full output. Am I missing something here? My first guesses were that the Transformer isn't technically a seq2seq model, that I have not understood how I'm supposed to implement it, or that I've just been implementing seq2seq models incorrectly for the last few years :)
