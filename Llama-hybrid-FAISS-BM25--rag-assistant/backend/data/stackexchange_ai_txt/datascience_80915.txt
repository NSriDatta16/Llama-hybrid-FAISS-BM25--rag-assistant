[site]: datascience
[post_id]: 80915
[parent_id]: 
[tags]: 
PCA and SVD main difference

I have spent multiple days trying to grasp the concept of the PCA and SVD. But I still have a couple of confusion about the difference between SVD and PCA. I watched Steve Brunton Youtube SVD playlist to learn about PCA and SVD. In the video, he said that the formula for SVD is matrix $X = U \Sigma V^T$ . And $U$ captures most variance for each column while $V^T$ captures most variance for each row (Please correct me if I am wrong). And the example he used for SVD each training example is a column vector. Then when he talked about PCA, he said PCA is built on top of SVD, a couple of differences he also said that all the training examples for PCA is a row vector. Is that a true difference between PCA and SVD or the data representation is not important? Then another difference is the purpose of PCA, since for each matrix we can do a SVD to get the U matrix and V transpose matrix and to find out the vector or direction that gives out the biggest variance, then why do we take more time to do the PCA?
