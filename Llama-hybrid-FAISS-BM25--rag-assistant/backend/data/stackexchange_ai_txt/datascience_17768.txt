[site]: datascience
[post_id]: 17768
[parent_id]: 10025
[tags]: 
For automatic speech recognition (ASR), filter bank features perform as good as CNN on spectrograms Table 1 . You can train a DBN-DNN system on fbank for classifying animals sounds. In practice longer speech utterances are divided into shorter utterances since Viterbi decoding doesn't work well for longer utterances. You could do the same. You can divide the longer utterances into smaller utterances of fixed length. Dividing the longer utterances into smaller is easy. The problem comes in increasing the length the smaller utterances to reach fixed length. You could warp the frequency axis of the spectrogram for augmenting the smaller utterances. This data augmentation has been shown to improve ASR performance data augumentation . For a longer utterance with multiple sounds in it, you could use music segmentation algorithms to divide it into multiple utterances. These utterances can be made of fixed length either by division or augmentation.
