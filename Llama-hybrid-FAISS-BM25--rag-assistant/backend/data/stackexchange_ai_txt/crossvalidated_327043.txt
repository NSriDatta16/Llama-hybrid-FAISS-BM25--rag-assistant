[site]: crossvalidated
[post_id]: 327043
[parent_id]: 327030
[tags]: 
In terms of evaluating the performance of your neural network, you typically want to use some kind of estimate for a generalisation error, like hold-out validation (testing on a separate dataset) or K-fold cross-validation. Assuming you use a separate dataset for comparison, the reasonable thing to do is to use the loss function you have used for training your neural network as an evaluation metric. The most common choices for loss functions are the mean squared error and cross-entropy. Mean squared error is a typical choice for regression problems: $$ MSE = \frac{1}{N} \sum_{i=1}^N (Y_i - \hat{Y}_i )^2 $$ where $Y_i$ is the true regression value and $\hat{Y_i}$ is your neural network's prediction. While the cross-entropy is used for classification problems: $$ C = - \sum_{i=1}^N y_{o,c} \log p_{o,c} $$ where $y_{o,c} $ is a binary indicator of correct classification, and $p_{o,c}$ is the predicted probability for that class. If you used the above two as an error metric, I would take the average of the errors on each histogram and choose the minimum. Otherwise, I would calculate the value the loss functions on your separate dataset, and choose the neural network which gives the minimal error.
