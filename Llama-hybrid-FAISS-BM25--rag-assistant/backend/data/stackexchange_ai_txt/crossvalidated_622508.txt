[site]: crossvalidated
[post_id]: 622508
[parent_id]: 
[tags]: 
Writing MCMC Sampling Code by Hand

I am trying to understand the steps involved in the Metropolis-Hastings Algorithm and trying to learn how to implement it myself . As an example, suppose I am interested in estimating the "probability of success" (p) in a Binomial Distribution. I decide to use Bayesian Estimation - that is, I can define the Posterior Probability Distribution of "p" as a function (proportional) of the Binomial Likelihood and some Prior Probability Distribution (e.g. the Beta Distribution): $$\text{Posterior} = \text{Pr}(p | x) = \frac{ p^{\sum_{i=1}^n x_i + \alpha - 1} \cdot (1-p)^{n - \sum_{i=1}^n x_i + \beta - 1}}{\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \cdot \frac{\Gamma(\sum_{i=1}^n x_i + \alpha)\Gamma(n - \sum_{i=1}^n x_i + \beta)}{\Gamma(n + \alpha + \beta)}} = \frac{ p^{\sum_{i=1}^n x_i + \alpha - 1} \cdot (1-p)^{n - \sum_{i=1}^n x_i + \beta - 1}}{\frac{\Gamma(\sum_{i=1}^n x_i + \alpha)\Gamma(n - \sum_{i=1}^n x_i + \beta)}{\Gamma(n + \alpha + \beta)}}$$ I am aware that the Binomial Distribution and the Beta Distribution have the "Conjugacy Property" ( https://en.wikipedia.org/wiki/Conjugate_prior ) - result in a "closed-form solution" for the Posterior Distribution and not requiring to use the Metropolis-Hastings Algorithm. However, I am interested in learning how to write the steps of the Metropolis-Hastings Algorithm to take random samples from the Posterior Distribution as an educational exercise (e.g. I could then take the average of these samples to obtain the "Bayes Estimator" for "p"). As I understand, here are the steps necessary in the Metropolis-Hastings Algorithm: (Step 1) Define P-Current : A single random number generated from a Uniform(0,1) Distribution (Step 2): Define P-Proposed: A single random number generated from a Normal Distribution with Mean = P-Current and some Standard Deviation. This Normal Distribution is considered as the "Candidate Distribution" (note: I heard there is some flexibility in defining the Candidate Distribution) (Step 3): Define Rule: IF P-Proposed > 1 THEN P-Proposed = 1. IF P-Proposed (Step 4) Define the Acceptance Ratio: (Likelihood(P-Proposed)* Prior(P-Proposed)) / (Likelihood(P-Current) * Prior(P-Current)) (Step 5) : Generate a single random number from a Binomial Distribution with p = min(1, Acceptance Ratio). (note: The Binomial Distribution used in Step 5 is has nothing to do with the fact that we are interested in estimating the parameter of a Binomial Distribution - this step would be present regardless of the problem) (Step 6) Criteria: IF Step 5 = 1 THEN P-Current = P-Proposed ELSE P-Current = P-Current As a real example, suppose I observe 20 successes out of 50 trial. I assume a Prior Beta Distribution with alpha = beta = 2. I use a Normal Distribution as a Candidate Distribution and define the Standard Distribution as 0.1 (arbitrary choice). Using the R programming language, I tried to implement the Metropolis-Hastings algorithm myself (5000 random samples): # Define the binomial likelihood function binom_likelihood 1, 1, p_proposed) acceptance_ratio I got the following output: I am not sure if I have done this correctly - can someone please confirm? Thanks!
