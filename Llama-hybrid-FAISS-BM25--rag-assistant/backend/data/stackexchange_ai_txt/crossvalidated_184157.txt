[site]: crossvalidated
[post_id]: 184157
[parent_id]: 
[tags]: 
Classification with confidence scores: is regression ok?

Say you have a binary classification problem, but you'd like to have a sense of how confident the classifier is by using a numerical score and then using a threshold for the binarization. This can be done by reaching into the model and using it's scoring function, but that's not always available in library implementations. Many ML libraries have regression equivalents to classifiers, like SVR of Random Forest Regressors. Is it ok to use regression on labels as a proxy for a classifier confidence score? Are they different? By this I mean, say I have $n$ samples $X_1, ..., X_n$ and class labels $y_1,...,y_n$ with $y_i \in \{0,1\}$. I could train a binary classifier on these, or I could pretend that the $y_i \in \mathbb{R}$ and the labels happen to be 1.0 or 0.0. If I train a regressor on this formulation, what is wrong with using the outputs as surrogates for classifier scores, and then evaluating the model with ROC and AUC?
