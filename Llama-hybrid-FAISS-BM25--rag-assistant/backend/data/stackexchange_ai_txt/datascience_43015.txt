[site]: datascience
[post_id]: 43015
[parent_id]: 
[tags]: 
Approximate Text compression by training model?

I have a key-value form of dataset. Basically two sets of integers in many-to-one mapping. Like f(123) corresponds to 4652, f(24) corresponds to 12 and so on. Size of this dataset is say around upto 10^7. This is too large. So my Idea is to train this dataset on some model and store trained model's parameters only, so when I have to answer say f(24), I can pass 24 as input to my model and print model's output. My thinking was overfitting some model on the dataset could possibly result in high accuracy of say greater than 99%. I strictly want size of parameters to be less than 50,000 bytes. I tried making vanilla neural network but error percentage is way too high. I found an interesting blog trying same approach as mine. Kindly let me know if something is unclear to you in comments. Concrete Example Problem To give you a concrete example of what I am trying. Here is the DataSet , ith line stores f(i) in this file. I am trying to make a code which is of 50k bytes and can answer queries f(i). Ofcourse while training there are no limits, but after training it should be a file of 50k length at max.
