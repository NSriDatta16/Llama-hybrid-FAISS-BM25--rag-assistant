[site]: crossvalidated
[post_id]: 617369
[parent_id]: 580316
[tags]: 
Consider the example below. set.seed(2023) N Here, there are three possible variables ( x1 , x2 , x3 ) to predict the outcome ( y ). The correlation between each predictor variable and y is close to zero and would be eliminated by your proposed method of screening out variables that have a low correlation with y . However, squaring x3 is a perfect predictor of y . If you have a flexible model that can catch these kinds of nonlinear functions of the original data, you are depriving the model of data that could be highly predictive when used the right way (which a good model should figure out). For instance, a neural network is able to detect the nonlinear relationship between x3 and y without being explicitly programmed to look for such a relationship, yet screening based on the correlation would deprive such a model of that crucial x3 variable. library(nnet) L (Yes, there are alternatives to the Pearson correlation used here. Spearman correlation could be an alternative, though the Spearman correlations here are all quite low, too, and would not be particularly helpful.) Is it ok to employ linear correlation to dismiss some variables because of their LINEAR relationship to then use a model which not necessarily models a linear relationship? The example above hopefully demonstrates how such an approach can do serious harm to your analysis.
