[site]: crossvalidated
[post_id]: 237091
[parent_id]: 
[tags]: 
Understanding Cross Validation

I have a few gaps in my understanding of K fold CV. What I understand: K fold CV is meant to be a model validation technique, the idea is that you subset your data into K subsets, train your data on K-1 of those subsets and test on the Kth subset, repeating this process K times. The final result is the average error over each trial, the CV error. K fold CV is NOT meant to compare different instances of the same model. For example, if the model to be fit is linear, then you cannot compare linear model 1 with 4 coefficients to linear model 2 with 5 coefficients. You can however compare a linear model CV error with a glm CV error. If that is the case, then I am confused about fitting a model. Lets say I want to fit a poisson GLM. I use 5 fold CV. On each fold the result of training the model gives me differing choices of parameters and differing numbers of parameters. For example, on the first fold, the GLM chooses $X_1, X_2$, on the second fold, it chooses $X_2,X_3,X_4$. So at the end of the process, which model do i actually choose?
