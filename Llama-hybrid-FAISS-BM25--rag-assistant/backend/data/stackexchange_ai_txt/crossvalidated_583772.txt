[site]: crossvalidated
[post_id]: 583772
[parent_id]: 
[tags]: 
Standardizing neural network inputs with a linear layer?

I'm contributing to a ML software project and noticed something weird in the code: They perform standardization by introducing a linear layer right after the inputs. This linear layer has the same number of nodes as the inputs. I've never heard of such a practice... How does this standardize the inputs? The only comment in the code regarding this says: We disguise standardization in the first linear layer to keep it seamlessly in a sequential PyTorch object. But I do not understand how this is considered "standardization".
