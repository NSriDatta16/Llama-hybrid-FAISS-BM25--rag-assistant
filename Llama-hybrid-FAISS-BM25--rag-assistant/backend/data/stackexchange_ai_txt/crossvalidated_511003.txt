[site]: crossvalidated
[post_id]: 511003
[parent_id]: 
[tags]: 
Analyzing quantized results from a varying probability

There is an event which occurs every second, and will always be in one of precisely two states (let's say "Up" and "Down"). The only data available to us is the stream of events; the goal is to ascertain, as accurately as possible, the actual probability p of an Up event. Wrinkle: This probablity can change over time. So far, my best ideas are (1) an actual rolling average ("of the most recent 60 events, 54 were Up and 6 were Down, so judge that p = 0.9"), and (2) an exponentially weighted average, such that recent events influence it more than older ones do. There is a clear tradeoff in the length of the averaging window (more accurate vs more responsive to change), and that's an easy tweakable. The question is: What actual formula/algorithm/technique should be used here, for the most useful results? (If anyone's curious, I'm trying to analyze a flaky connection by measuring packet loss.)
