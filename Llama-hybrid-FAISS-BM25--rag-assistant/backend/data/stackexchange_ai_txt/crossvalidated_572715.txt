[site]: crossvalidated
[post_id]: 572715
[parent_id]: 
[tags]: 
How to estimate joint probability or conditional probability using marginal ones?

I have 2 datasets: The 1st one gives us the probability that $m$ events occur on $n$ observations ( $m$ columns for $n$ rows) The 2nd one tells us if the event occurred (1 if occurred, 0 else ; always $m$ columns for $n$ rows) My goal is to predict all the combinations of joint events for future observations of $m$ probabilities. First, I wanted to train a multioutput classification model using a discriminative model: $$P(X_k \cap X_j|X) = f(X)$$ But the number of combinations tending towards infinity if we wish to predict more than 2 joint events, this solution does not seem possible. Then, to keep the dimension of my target $y$ , I thought of using the formula of conditional probabilities: $$P(X_k \cap X_j) = P(X_k|X_j) \times P(X_j)$$ Because I have $P(X_j)$ , I just have to predict $P(X_k|X_j)$ , and the dimension of the target $y$ stays constant ( $m$ ). First, I tried to use discriminative model, changing the probability of the conditional event to 1 but the results are not good enough. I also tried to use generative model, like Bayesian networks, but in the same way, the results are not good enough. Do you have a trick or a smart idea to address this issue please ? FYI: I also thought about the use of copulas, but they seem to me more useful to propose probability distributions than for a predictions.
