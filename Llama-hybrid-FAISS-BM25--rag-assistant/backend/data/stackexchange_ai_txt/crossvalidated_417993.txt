[site]: crossvalidated
[post_id]: 417993
[parent_id]: 229855
[tags]: 
Sandeep S. Sandhu has provided a great answer. As for your case, I think your model has not converged yet for those small learning rates. In my experience, when using learning rate as small as 0.001 on gradient boosting tree, you need about 100,000 of boost stages (or trees) to reach the minimum. So if you increase the boost rounds to ten times more, you should be able to see the smaller learning rate perform better than large one. You can also check the website by Laurae++ for a great description of each parameters of Lightgbm/XGBoost ( https://rdrr.io/github/Laurae2/LauraeDS/man/Laurae.xgb.train.html , navigate to "learn_shrink"). Here is the most important quote about learning rate: Beliefs Once your learning rate is fixed, do not change it. It is not a good practice to consider the learning rate as a hyperparameter to tune. Learning rate should be tuned according to your training speed and performance tradeoff. Do not let an optimizer tune it. One must not expect to see an overfitting learning rate of 0.0202048. Details Each iteration is supposed to provide an improvement to the training loss. Such improvement is multiplied with the learning rate in order to perform smaller updates. Smaller updates allow to overfit slower the data, but requires more iterations for training. For instance, doing 5 iteations at a learning rate of 0.1 approximately would require doing 5000 iterations at a learning rate of 0.001, which might be obnoxious for large datasets. Typically, we use a learning rate of 0.05 or lower for training, while a learning rate of 0.10 or larger is used for tinkering the hyperparameters.
