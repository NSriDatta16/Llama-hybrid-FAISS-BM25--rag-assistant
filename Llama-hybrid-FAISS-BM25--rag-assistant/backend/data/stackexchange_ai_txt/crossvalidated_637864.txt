[site]: crossvalidated
[post_id]: 637864
[parent_id]: 
[tags]: 
How can model overconfidence coincide with accurate classifications?

Guo et al (ICML 2017) state the following. During training, after the model is able to correctly classify (almost) all training samples, NLL can be further minimized by increasing the confidence of predictions. Increased model capacity will lower training NLL, and thus the model will be more (over)confident on average. ( "NLL" refers to the binomial or multinomial negative log-likelihood , binary and categorical crossentropy loss, respectively, in some circles.) I am struggling to understand this. If the categories are easy to distinguish on the available features, measured by the fact that the classification accuracy (at some threshold) is high, then the predicted probabilities should be high. With this in mind, shouldn't the "overconfident" predictions be justifiably confident? REFERENCES Guo, Chuan, et al. "On calibration of modern neural networks." International Conference on Machine Learning. PMLR, 2017.
