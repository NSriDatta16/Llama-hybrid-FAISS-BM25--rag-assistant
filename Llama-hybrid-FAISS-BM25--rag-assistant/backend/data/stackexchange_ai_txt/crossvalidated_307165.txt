[site]: crossvalidated
[post_id]: 307165
[parent_id]: 
[tags]: 
Regressors vs. conditioning variables in glmtree

I have a dataset with ~800K samples, ~300 features and I'm trying to predict a binary outcome. I've started with sklearn's SGDClassifier (using log loss and l1 penalty), and I got a nice 0.67 auc score on my validation set; now I'm trying to improve this. I have a reason to believe that different subspaces of features space "behave" differently, so I thought fitting a glmtree would make sense (splitting the features space to different subspaces and fitting a logistic regression in each of them). However, when trying to write the formula, I don't have any prior knowledge regarding which features should be used as predictors for the glm, and which should be used as conditioning variables. Is there any automated way to select which is which?
