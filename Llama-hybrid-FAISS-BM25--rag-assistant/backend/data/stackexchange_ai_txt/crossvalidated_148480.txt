[site]: crossvalidated
[post_id]: 148480
[parent_id]: 148454
[tags]: 
In theory, yes, but you should avoid drawing conclusions from a single tree. Trees have low bias, but high variance, meaning that the addition or removal of a few observations only from your training set can change the first split, and modify the entire tree structure in a cascading fashion. On the other hand, ensemble methods such as Random Forests and Stochastic Gradient Boosting allow more variables to play an important role in determining tree structure (by considering only a random subset of predictors as candidates at each split), and by combining the output from many trees, they generate way more reliable variable importance measures. I would advise reading the Hastie for more details.
