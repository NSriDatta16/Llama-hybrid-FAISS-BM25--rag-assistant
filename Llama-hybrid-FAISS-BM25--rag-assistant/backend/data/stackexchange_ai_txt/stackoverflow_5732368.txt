[site]: stackoverflow
[post_id]: 5732368
[parent_id]: 5730044
[tags]: 
Like each technology decision, the answer depends on the goal to reach. Information about the OpenCL capabilities of GPUs can be found on the vendor pages. Pay attention: Not all GPUs support OpenCL and not all GPUs supporting OpenCL support double precision. You also might think about your customers/ client which might not have a OpenCL capable environment. GPGPU programming (OpenCL and CUDA) are suitable for (almost) all kinds of Linear Algebra problems. These problems are quite easy to parallelize and fit therefore easily on a parallel environment like GPUs. All problems which shall go on the GPU need to be not too complex and parallel designed. This really depends on you problem domain. On the other side you need to pay attentions to some payoffs of OpenCL. One needs to copy some data around from RAM to GPU and back, which leads to some delays. You should do some time measurements of different problem sizes on CPU and GPU. You will easily see when the break even is reached. I tried a matrix multiplication with ATLAS library on CPU Opteron X64 2x2600 and GPU Geforce 8600GTS. The matrix multiplication was just two matrices with dimensions NxN. The break evens was for N roughly around 100. This result heavily depends on the CPU and GPU used and might be totally different on other hardware.
