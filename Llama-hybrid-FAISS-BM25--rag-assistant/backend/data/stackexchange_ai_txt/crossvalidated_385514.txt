[site]: crossvalidated
[post_id]: 385514
[parent_id]: 385509
[tags]: 
Note on interpretation: It is not entirely clear what you mean by the "arithmetic mean" of the random variable $X$ . If you are referring to the sample mean of a bunch of samples of $X$ then your question is trivial, and is answered correctly by jbowman in the comments. In order to make sense of your question, I'm going to assume that by "arithmetic mean" in this context, you are referring to the average of all values in the support of the distribution. (Note that this is only well-defined for distributions with finite support.) That interpretation would make "arithmetic mean" a property of the distribution of a single random variable $X$ , which is how you have framed your question. Note that this is an unusual question, so you should consider whether it is really what you are seeking to ask. Definition: Consider a random variable $X$ with a distribution that has finite support $\mathscr{X}$ . For purposes of this answer we will define the arithmetic mean of this distribution as the value: $$\mathbb{A}(X) \equiv \frac{1}{|\mathscr{X}|} \sum_{x \in \mathscr{X}} x.$$ Theorem: Consider a random variable $X$ with a distribution that has finite support $\mathscr{X}$ and has probability mass function $p_X$ over that support. Let $\mathbf{x}$ denote the vector of values in the support (in any order) and let $\mathbf{p}$ denote the corresponding probability mass values (in the same order). If $|\mathscr{X}| = 1$ then $\mathbb{A}(X) = \mathbb{E}(X)$ , and if $|\mathscr{X}| > 1$ then we have: $$\mathbb{A}(X) = \mathbb{E}(X) \quad \quad \quad \iff \quad \quad \quad r(\mathbf{x}, \mathbf{p}) = 0,$$ where $r$ denotes the formula for the sample correlation of two vectors. Proof: If $|\mathscr{X}| = 1$ then $\mathbb{A}(X) = \mathbb{E}(X)$ follows trivially. We therefore proceed for the non-trivial case where $|\mathscr{X}| > 1$ (for which the sample correlation is well-defined). Let $C(\mathbf{x}, \mathbf{p})$ denote the sample covariance between $\mathbf{x}$ and $\mathbf{p}$ . We have: $$\begin{equation} \begin{aligned} (|\mathscr{X}|-1) C(\mathbf{x}, \mathbf{p}) &= \sum_{x \in \mathscr{X}} (x - \mathbb{A}(X)) \Big( p_X(x) - \frac{1}{|\mathscr{X}|} \Big) \\[6pt] &= \sum_{x \in \mathscr{X}} x \Big( p_X(x) - \frac{1}{|\mathscr{X}|} \Big) - \mathbb{A}(X) \sum_{x \in \mathscr{X}} \Big( p_X(x) - \frac{1}{|\mathscr{X}|} \Big) \\[6pt] &= \sum_{x \in \mathscr{X}} x \Big( p_X(x) - \frac{1}{|\mathscr{X}|} \Big) - \mathbb{A}(X) (1-1) \\[6pt] &= \sum_{x \in \mathscr{X}} x \Big( p_X(x) - \frac{1}{|\mathscr{X}|} \Big) \\[6pt] &= \sum_{x \in \mathscr{X}} x \cdot p_X(x) - \frac{1}{|\mathscr{X}|} \sum_{x \in \mathscr{X}} x \\[6pt] &= \mathbb{E}(X) - \mathbb{A}(X). \\[6pt] \end{aligned} \end{equation}$$ This establishes that $C(\mathbf{x}, \mathbf{p}) = 0$ if and only if $\mathbb{E}(X) = \mathbb{A}(X)$ . Since $C(\mathbf{x}, \mathbf{p}) = 0$ if and only if $r(\mathbf{x}, \mathbf{p}) = 0$ the result follows by transitivity. $\blacksquare$ From the above theorem, we can see that the requirement for equivalence is satisfied if and only if the vector of values in the support $\mathscr{X}$ is uncorrelated with the corresponding vector of probabilities. This gives us a simple test that can be applied to any distribution with finite support to see if its expected value is equal to its "arithmetic mean" (as defined here). There are and infinite number of discrete distributions in which this equation will hold. Example: Consider the discrete distribution with: $$p_X(0) = 0.4 \quad \quad \quad p_X(1) = 0.2 \quad \quad \quad p_X(2) = 0.4.$$ This distribution satisfies the requirement that the probability vector is uncorrelated with the vector of values in its support (defined so that the elements correspond). For this distribution we have "arithmetic mean": $$\frac{1}{|\mathscr{X}|} \sum_{x \in \mathscr{X}} x = \frac{1}{3} (0+1+2) = \frac{3}{3} = 1,$$ and expected value: $$\sum_{x \in \mathscr{X}} x \cdot p_X(x) = (0 \cdot 0.4 + 1 \cdot 0.2 + 2 \cdot 0.4) = 0.2+0.8 = 1.$$
