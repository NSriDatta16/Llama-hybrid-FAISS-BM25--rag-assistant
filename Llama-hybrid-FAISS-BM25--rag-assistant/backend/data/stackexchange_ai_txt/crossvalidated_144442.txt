[site]: crossvalidated
[post_id]: 144442
[parent_id]: 
[tags]: 
Gibbs sampling for reducible chain

I am new to Gibbs sampling and I ran into a problem with irreducibility. For the Gibbs sampler to work the Markov chain has to be irreducible. But that assumption is not satisfied in my probability distribution. Is there a way to overcome this problem and still do sampling ? If I explain this in an example. Assume I have a Markov model and my state vector is a binary vector. Let $X_t$ be the state vector at time $t$ and $x_{t,i}$ is the $i^{th}$ element of state vector at time $t$. In my transition probabilities, probability of going from 0 to 1 is equal to the number of ones in previous time step divided by total elements. For example, if $X_{t-1}=[0,0,1,0]$, in next time step each element can go to 1 with a probability of 0.25. All element can go from 1 to 0 with some probability say $\gamma$. Assuming transition probabilities are independent given the previous state, I can write follows. $P(X_t\vert X_{t-1})= \prod_\limits{i=1}^4P(x_{t,i}\vert X_{t-1})$ I am drawing samples from this model. I am sampling in the increasing order of time and $i$. First the first element of $X_1$, next the second element of $X_1$ and so on. Now assume at a particular sample I got the following samples for $t-1,t,t+1$. $X_{t-1}=[0,0,1,0]$, $X_{t}=[1,0,0,0]$,$X_{t+1}=[0,0,1,0]$ Now assume I am drawing the next sample given these values, and let's say the 1 in $X_{t-1}$ (3rd element) flipped back to 0 (This can happen if $\gamma > 0$). Then assume I am sampling the 1st element at time $t$. This probability can be given as follows, $P(x_{t,1}\vert X_{t-1},x_{t,2},x_{t,3},x_{t,4},X_{t+1})\propto P(x_{t,1} \vert X_{t-1})P(X_{t+1}\vert x_{t,1},x_{t,2},x_{t,3},x_{t,4}) = P(x_{t,1} \vert X_{t-1})\prod_\limits{i=1}^4P(x_{t+1,i}\vert x_{t,1},x_{t,2},x_{t,3},x_{t,4})$ Since there are no ones in new sample at time $t-1$ the value $P(x_{t,1} \vert X_{t-1})$ will be non-zero only if $x_{t,1}=0$. But in the next product term $P(x_{t+1,3}|x_{t,1},x_{t,2},x_{t,3},x_{t,4})$ will become zero since $x_{t+1,3}=1$ (this is given from previous sample) and all the elements in previous time step is zero, when $x_{t,1}=0$. Because of this situation I can't sample $x_{t,1}$. Since $P(x_{t,1}=0)=0$ and $P(x_{t,1}=1)=0$ omitting conditioning variables. I think this is due to non-irreducibility of my model. (There's no way to go to state 1 if all the elements in previous state is zero). According to Xi'an do I have to change the transition model if I were to use Gibbs sampling ? Or is there any work around for this ? I have a long sequance of $X_t$'s with at least about 100 components. So I think for example to take MAP estimate I have to maximize over about $2^{100*T}$, which is impossible. That's why I moved to Gibbs sampling. I am glad to hear if there's any other suggestions to do a inference in this type of a distribution. FYI,In addition to this there is a observation model on top of this more like a HMM.
