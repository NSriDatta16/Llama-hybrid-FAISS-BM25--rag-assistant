[site]: datascience
[post_id]: 48927
[parent_id]: 48893
[tags]: 
Human activity recognition generally tends to classify various activities from data collected through sensors. As @Eric stated, RNNs and LSTMs can do the best job since, they can handle temporal data or time series. But, they lack the ability of extracting useful hierarchical features from the data. Here comes 1 Dimensional Convolutional networks. They are similar to ones which are used in image classification but they work on a single dimension. They can efficiently parse the features of the sequential data of the sensors. But, they lack the temporal feature. Why can't we fuse both the CNN and LSTM together? Yes, this is the correct solution. We can first stack the Convolutional and maxpooling layers and then reshape the output. This output could be fed to the LSTM which will handle the temporal part. You can read this and this . Hence, good feature extraction is accompanied with temporal data handling.
