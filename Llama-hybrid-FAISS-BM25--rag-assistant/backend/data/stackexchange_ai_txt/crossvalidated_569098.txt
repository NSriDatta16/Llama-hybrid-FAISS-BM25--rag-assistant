[site]: crossvalidated
[post_id]: 569098
[parent_id]: 488939
[tags]: 
Yes, this is based on my answer for a very similar question from the Data Science SE Yes, the classifier will expect the relative class frequencies in operation to be the same as those in the training set. This means that if you over-sample the minority class in the training set, the classifier is likely to over-predict that class in operational use. To see why it is best to consider probabilistic classifiers, where the decision is based on the posterior probability of class membership p(C_i|x), but this can be written using Bayes' rule as $p(C_i|x) = \frac{p(x|C_i)p(C_i)}{p(x)}\qquad$ where $\qquad p(x) = \sum_j p(x|C_j)p(c_j)$ , so we can see that the decision depends on the prior probabilities of the classes, $p(C_i)$ , so if the prior probabilities in the training set are different than those in operation, the operational performance of our classifier will be sub-optimal, even if it is optimal for the training set conditions. Some classifiers have a problem learning from imbalanced datasets, so one solution is to oversample the classes by just the right amount to ameliorate this bias in the classifier. However, this is really difficult, because this tends to be a problem only when the data are very scarce, which unfortunately means you don't have enough data to estimate the amount of correction required. Fortunately this bias tends to go away rapidly as the size of the dataset increases, so if you have lots of data, you don't need to do anything . If you have a balanced training set you can post-process the output to compensate for the difference in training set and operational priors. We take the output of the classifier trained on an oversampled dataset and multiply by the ratio of operational and training set prior probabilities, $q_o(C_i|x) \propto p_t(x|C_i)p_t(C_i) \times \frac{p_o(C_i)}{p_t(C_i} = p_t(x|C_i)p_o(C_i)$ Quantities with the o subscript relate to operational conditions and those wit the t subscript relate to training set conditions. I have written this as $q_o(C_i|x)$ as it is an un-normalised probability, but it is straight forward to renormalise them by dividing by the sum of $q_o(C_i|x)$ over all classes. If you are using logistic regression, then resampling the data probably has no benefits over just changing the threshold (which should depend on the false-positive and false-negative misclassification costs, and the degree of imbalance is entirely irrelevant). TLDR; Resampling is not necessary if you have lots of data, unless you are using a classifier that doesn't support cost-sensitive learning, or if the dataset is very small. If you are going to resample, then the amount of resampling should depend on the false-positive and false-negative costs, rather than the degree of imbalance.
