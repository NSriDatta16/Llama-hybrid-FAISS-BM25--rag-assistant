[site]: crossvalidated
[post_id]: 439398
[parent_id]: 
[tags]: 
What is the resulting distribution of a data set that was originally normally distributed but has been quantized and had all negative values removed?

I am trying to benchmark a seasonal forecasting model and calculate not just the point forecasts but the forecast densities from the model. To do this, I generated a simulated data set in the following fashion: Generate a sine wave with the same frequency as my target seasonality. add one to the signal to keep the values non negative. Add Gaussian noise to the sine wave. Rounded down all float values to the integer value just below them because the business metric I am trying to forecast can't take fractional values. The code for the simulated time series: x = np.array(range(0,seq_length)) noise = np.random.normal(0, 0.15, seq_length) data = np.maximum(10 * (np.sin(np.pi * x / 12) + 1 + noise),0).astype(int) I could use some non-parametric approach to estimate the forecast densities, by calculating the difference between the simulated data with noise and without noise, but I'm wondering if there is an analytical way of going from the initial normal distribution to what the distribution after clipping and quantization?
