[site]: crossvalidated
[post_id]: 595489
[parent_id]: 
[tags]: 
Statistical significance of change between two periods of time

I have data on a group of individuals who have been given a new tool to trial on to help with reducing the average time needed to perform certain task. There are two metrics we look at to measure performance, overall reduction in average time performing a task, and the percent accuracy of the completed task. The overall goal is to reduce the amount of time needed to complete the task without significantly impacting accuracy rate of the completed tasks. Prior to the trial period, on average the individuals are given 1,500 tasks to complete per month, with the average time of completion around 35 mins, and accuracy rate of 90%. With the new tool, the average time of completion has improved to average of 30 mins to complete a task. But the accuracy rate has dropped to 88%. I was asked to give recommendation if we should continue with the tool, however Iâ€™m not certain how to determine if the performance difference is statistically significant. What is the appropriate test or calculation I can use to determine this?
