[site]: crossvalidated
[post_id]: 267323
[parent_id]: 
[tags]: 
variable selection and bias-variance tradeoff for linear regression

I can understand bias-variance tradeoff for the $k$-nearest neighbor method. (Please correct me if I'm wrong.) Small values of $k$ lead to a flexible model with the $E[Y|X]$ estimate, having small bias and large variance. With large value of $k$, we have to average many neighbors, so the $E[Y|X]$ estimate tends to have larger bias and smaller variance. So to choose $k$, we tradeoff between bias and variance. However, I don't quite see how this tradeoff manifest itself in the variable selection of linear regression. Are there known rules about when or if using a subset of the input variables will reduce the test error for linear regression? Does using fewer variables lead to lower variance and higher bias in this case? And how to justify/prove them? Thanks a lot!
