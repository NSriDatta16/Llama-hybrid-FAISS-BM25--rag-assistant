[site]: crossvalidated
[post_id]: 551339
[parent_id]: 
[tags]: 
Does data augmentation with white noise improve accuracy of deep learning models?

I was reading Aurélien Géron 's Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow . There, on the 14th chapter I read something on data augmentation which I could not be sure of its validity. The author was saying that the images for the data augmentation should be generated in a way that humans should have the difficulty whether the images are generated or not. He further continues that the modifications should be learnable , therefore should not be white noise , as he says white noise is not learnable. I could not really be sure of this, because I know that there are jittering methods out there to be used in the data augmentation step. So, do they really not work? Is adding noise in the data really meaningless, or is there something that I am missing? Can you also demonstrate some cases with examples?
