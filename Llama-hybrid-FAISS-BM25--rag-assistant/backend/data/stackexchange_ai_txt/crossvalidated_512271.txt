[site]: crossvalidated
[post_id]: 512271
[parent_id]: 
[tags]: 
Understanding the set of latent variables $Z$ in variational inference

I have been trying to understand variational inference (in a Bayesian context) where we’re trying to approximate $p(Z|X)$ where $Z$ is the set of latent variables and $X$ is the set of observable variables/data points, and I am not exactly sure what $Z$ means. In Bishop’s book (PRML Chp10, p463), $Z=(z_1,…,z_n)$ is the same size as the observable variable set $X=(x_1,…,x_n)$ , suggesting one latent variable is associated with one observable variable; but Bishop also says that the parameters are absorbed in Z. (in what way exactly?) In Blei’s tutorial ( https://arxiv.org/pdf/1601.00670.pdf ), $X_{1:n}$ and $Z_{1:m}$ don’t have the same dimensions, suggesting Z does not depend on data size. I also found this answer by Murphy ( https://www.quora.com/What-makes-model-parameters-vs-latent-variables ). It says ‘there is no real difference between parameters and other kinds of latent variables’ and clarifies that parameters are fixed in size whereas latent variables grow with data points (1 per data point). But it then proceeds to explain the relationships between parameter, latent var., and observable var. with these arrows I don’t understand. I think a distinction between the generative and discriminative case was made.
