[site]: crossvalidated
[post_id]: 444333
[parent_id]: 444327
[tags]: 
You can do it no matter where the parameter is. For instance, this is done in neural networks, where the layer weights are highly nonlinearly related to the target value. In general, when the parameters are linearly related to the target, you just have an advantage on parameter scaling so that regularization objective treats each one equally, when feature scaling is performed.
