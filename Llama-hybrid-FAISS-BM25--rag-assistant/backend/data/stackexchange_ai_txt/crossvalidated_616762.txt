[site]: crossvalidated
[post_id]: 616762
[parent_id]: 
[tags]: 
question on the computation of the predictive uncertainty in bayesian neural networks

I was reading Yarin gal's Phd thesis regarding the use of dropout as a technique to turn a neural network in a bayesian neural network. at page 32 of the pdf (18 for the thesis) he writes that the probability distribution for the output $y^* $ for a new input point $x^*$ can be obtained by integrating over the space of the parameters, i.e. the weights of the neural network: $$ p(y^*|x^*,D)= \int_w p(y^*|x^*,w) p(w|D) \mathrm{d} w ;$$ and he calls this procedure simply inference. but what's the precise name of this procedure? some says bnns rely on model averaging , other sources says that they marginalize over the weight. So what's the correct definition? I think that BNNs approximate numerically the expected a posteriori estimator but i am not sure that's correct.
