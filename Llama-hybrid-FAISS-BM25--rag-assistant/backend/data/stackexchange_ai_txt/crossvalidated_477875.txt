[site]: crossvalidated
[post_id]: 477875
[parent_id]: 477785
[tags]: 
Shortest confidence interval is an ambiguous term There is no such thing as the shortest confidence interval. This is because the confidence interval is a function of the data $X$ . And while you can make the confidence interval shorter for some particular observation, this comes at the cost of increasing the size of intervals for other possible observations. Only when you define some way to apply some weighted average over all the observations, then you could possibly (but I believe not certainly or at least not easily) construct some confidence interval with the 'shortest' length. Conditioning on observation versus conditioning on the parameter: Contrast with credible intervals, where shortest interval makes more sense. This contrasts with credible intervals. Confidence intervals relate to the probability that the parameter is inside the interval conditional on the parameter . Credible intervals relate to the probability that the parameter is inside the interval conditional on the observation . For credible intervals you can construct a shortest interval for each observation individually (by choosing the interval that encloses the highest density of the posterior ). Changing the interval for one observation does not influence the intervals for other observations. For confidence intervals you could make the intervals smallest in a sense that these intervals relate to hypothesis tests. Then you can make the shortest decision boundaries/intervals (which are functions of the parameters, the hypotheses). Some related questions In this question... The basic logic of constructing a confidence interval ..the topic was to get a 'shortest interval' but there is no unambiguous solution when 'shortest' is not unambiguously defined. That same question also clarifies something about the 'relative tail sizes'. What we can control are the tails of the distribution of the observation conditional on the parameter. Often this coincides with the confidence interval*, and we can think of the confidence interval as distribution around the point estimate of the parameter. However, this symmetry may not need to be, as we can see in the case like the following: let's consider the observation/sample $\hat{\theta}$ from a distribution parameterized by $\theta$ following $${\hat\theta \sim \mathcal{N}(\mu=\theta, \sigma^2=1+\theta^2/3)}$$ You see this in the image below (for details see the particular question). In that image the red and green lines depict the confidence interval boundaries as a function of the observed $\hat{\theta}$ . But you can consider them also as a function of $\theta$ , and it is actually in that view how the boundaries are determined (see the projected conditional pdf's and how the boundaries enclose symmetrically the highest $\alpha\%$ of those pdf's but do not provide a symmetric confidence interval, and some boundaries may even become infinite). In this question... Are there any examples where Bayesian credible intervals are obviously inferior to frequentist confidence intervals ... you see a comparison between credible intervals and confidence interval. For a given observation, credible intervals, when they are the highest density posterior interval, are (often) shorter than confidence intervals. This is because confidence intervals do not need to coincide with the highest density interval conditional on the observation. On the other hand, note that in the vertical direction (for a given true parameter) the boundaries of the confidence interval are enclosing a shortest interval. *(often this coincides with the confidence interval) We see an example in this question... Differences between a frequentist and a Bayesian density prediction where we see a sketch for an (prediction) interval based on a t-distribution. There is a certain duality to the construction of the interval: We can construct a frequentist prediction interval with the interpretation that No matter what the value of $\mu$ and $\sigma$ is, the value $X_{n+1}$ will be $x\%$ of the time inside the prediction interval. but also: Given a hypothetical predicted value $\tilde{X}_{n+1}$ in the prediction range, the observations $\bar{X}$ and $s$ (the sample mean and sample deviation) will be occuring within some range that occurs $x$ percent of the time. (That means we will only include those values in the prediction range for which we make our observations $x\%$ of the time, such that we will never fail more than $x\%$ of the time) So instead of considering the distribution of $X_{n+1}$ given the data $\bar{X}$ and $s$ , we consider the other way around, we consider the distribution of the data $\bar{X}$ and $s$ given $X_{n+1}$ . In the image we see the interval boundaries around the observed mean (in the example, which is about prediction interval instead of confidence interval, observed additional point $X_{n+1}$ ). But the boundaries should actually be considered the other way around. It is the hypothetical observation that is inside the boundaries of a hypothesis test related to each of the parameters inside the confidence interval (in the example it is a prediction interval).
