[site]: crossvalidated
[post_id]: 553301
[parent_id]: 
[tags]: 
Regression When All Variables Are Considered as "Random"

This is a question that recently occurred to me: In the traditional context of regression, only the response variable is considered to be "random". The covariates in a regression model can assume different values, but (as far as I understand) they are considered as "non-random". That means, we are assumed to have some control on them. However, we do assume that the "effects" that the covariates have on the response variable can be considered as random. For example, we want to make a regression model that predicts how quickly similar rods made with the same type of metal break when exposed to different values of temperature and weight. Although there might be micro variations when we try to repeatedly expose the metal rods to the same heat/weight loads, we still assume that "heat" and "weight" are non-random variables and the only random variable is the "time" when the metal rod breaks. My Question: How does the supporting theory and framework behind regression (or rather, all statistical models that assume that covariates are non-random variables) change, in situations when the covariates may not necessarily be considered as "non-random"? I have a feeling that in the real world, we are not always able to control the covariates and at times they can in part behave as random. For example, if we want to make a model that predicts the age of a giraffe based on the height and weight of a giraffe. When we collect data, there might be plenty of ways in which the height and weight variables could be considered as "random": For instance, we might reasonably believe that in a certain wildlife reserve there is only one species of giraffe - when in reality there are actually several species of giraffes. Each species might have different height and weight distributions - but since we do not know that other species exist, we might include the variation in these variables from different species into our data. This might not be the best example to illustrate my point, but I think that it's possible that in the real world, covariates might behave in part as random variables. Thus: When covariates are no longer considered to be fully non-random, how much does this affect the theoretical framework of statistical models? Does this even matter? Are there any statistical models that allow for both the covariates and the response to be a random variable (e.g. Copulas)? Do non-parametric models (e.g decision trees, random forest) also require the covariates to be non-random? Thanks! Note: On first glance, it seems that Copula Models estimate a joint distribution for all the variables in your dataset and might allow them all to be random variables: However, once you start to use a Copula Model in the context of Regression (and are required to estimate Beta Regression Parameters via Maximum Likelihood), I am not sure the requirement on the covariates being random is relaxed: Thanks! References: https://en.wikipedia.org/wiki/Copula_(probability_theory) https://www.jstatsoft.org/article/view/v077i08
