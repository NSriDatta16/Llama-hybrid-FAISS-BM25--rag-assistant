[site]: crossvalidated
[post_id]: 54819
[parent_id]: 54794
[tags]: 
@gung has given the OLS estimate. That's what you were seeking. However, when dealing with physical quantities where the line must go through the origin, it's common for the scale of the error to vary with the x-values (to have, roughly, constant relative error). In that situation, ordinary unweighted least squares would be inappropriate. In that situation, one approach (of several possibilities) would be to take logs, subtract the x's from the y's and estimate the log-slope (of the original variables) by the mean of the differences. Alternatively, weighted least squares could be used. In the case of constant relative error, it would reduce to using the estimator $\hat{\beta}=\frac{1}{N}\sum_{i=1}^N \frac{y_i}{x_i}$ (the average of all the slopes through the origin). There are other approaches (GLMs for example), but if you're doing it on a calculator, I'd lean toward my first suggestion. You should also consider the appropriateness of any assumptions you make. I thought it might be instructive to add the derivation of the WLS line through the origin and then my "average of slopes" and gungs OLS are special cases: The model is $y_i=\beta x_i+\varepsilon_i\,,$ where $\text{Var}(\varepsilon_i)=w_i\sigma^2$ We want to minimize $S = \sum_i w_i(y_i-\beta x_i)^2$ $\frac{\partial S}{\partial \beta} = -\sum_i 2x_i.w_i(y_i-\beta x_i)$ Setting equal to zero to obtain the LS solution $\hat{\beta}$ we obtain $\sum w_ix_iy_i = \hat{\beta} \sum w_ix_i^2$ , or $\hat{\beta}=\frac{\sum w_ix_iy_i}{\sum w_ix_i^2}$ . When $w_i\propto 1$ for all $i$ , this yields gung's OLS solution. When $w_i \propto 1/x_i^2$ (which is optimum for the case where spread increases with mean), this yields the above "average of slopes" solution.
