[site]: datascience
[post_id]: 71360
[parent_id]: 
[tags]: 
How to select the best features for Support Vector Classification

I have a feature set that contains approximately 2 dozen features of technical analysis indicators. My own domain knowledge tells me that some of these features are better than others for predicitive power. But what methodical processes do I follow other than 'just a hunch', to go about refining the feature set to ones that matter the most? At the moment, I'm just using sklearns preprocessing package and I just throw all the features in, but I know that there must be a better way. min_max_scaler = preprocessing.MinMaxScaler() df[['MACD', 'MFI', 'ROC', 'RSI', 'Ultimate Oscillator', 'Williams %R', 'Awesome Oscillator', 'KAMA', 'Stochastic Oscillator', 'TSI', 'Volume Accumulator', 'ADI', 'CMF', 'EoM', 'FI', 'VPT','ADX', 'ADX Negative', 'ADX Positive', 'EMA', 'CRA']] = min_max_scaler.fit_transform(df[['MACD', 'MFI', 'ROC', 'RSI', 'Ultimate Oscillator', 'Williams %R', 'Awesome Oscillator', 'KAMA', 'Stochastic Oscillator', 'TSI', 'Volume Accumulator', 'ADI', 'CMF', 'EoM', 'FI', 'VPT','ADX', 'ADX Negative', 'ADX Positive', 'EMA', 'CRA']]) I'm quite new to machine learning and would love some feedback. I am using Pandas and Sklearn as well.
