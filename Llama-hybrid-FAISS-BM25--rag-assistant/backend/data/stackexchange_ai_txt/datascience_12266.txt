[site]: datascience
[post_id]: 12266
[parent_id]: 12265
[tags]: 
First of all, I think that your accuracy is already very high for text classification. I want to provide some ideas for additional features and approaches though. Topic models Topic models such as Latent Dirichlet Allocation (LDA) are quite frequently used when studying text corpora. You already wrote that you used LDA for coming up with cosine similarities. What you could also do though is to use the latent topics as additional features for individual documents, and use the probabilistic assignments as values. Sentiment analysis As you work with loans and injurences, it might also be useful to use sentiment features in your classification. For example, you could use a dictionary based approach on valence, arousal and dominance and include these features into your classification; you can find information in the relevant paper . Another approach would be to use SentiStrength . Word2Vec Recent text analysis approaches have heavily focused on neural network approaches such as Word2Vec that finds word embeddings. Then, a simple approach could be to average the vectors over all words in a document and use these as features. There are also approaches that use the vectors as features in convolutional neural networks . E-Mail features Did you think about using further e-mail features, such as the domain, or simply the text length. Might be worth a try to look into that. Also, the domain of e-mail spam classification might give you some further insights. Feature/classifier tuning Bag of word/tfidf feature generation is sometimes quite sensitive. You might want to try to tune this by altering the parameters in some form of grid search optimization; for instance, sometimes it is useful to use minimum number of document thresholds for features or things like sublinear scaling. Also, you can try to combine your classifiers in an ensemble approach which might lead to higher accuracy.
