[site]: datascience
[post_id]: 39775
[parent_id]: 39758
[tags]: 
Try increasing your batch size. I think it could be because you specify a batch size of 35 and the validation will be tested on a batch_size of 32 by default. Testing a batch of 32 on the weights that were just reached the epoch might indeed lead to a slightly better average performance as all samples in the batch get the newest and best current weights. If the samples in your train and validation set are extremely similar, I would expect the validation curve to always slightly beat the train score, given you use similar batch sizes (35 vs. 32). You can see that the train and validation curves do indeed level out over time.
