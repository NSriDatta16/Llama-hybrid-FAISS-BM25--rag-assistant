[site]: crossvalidated
[post_id]: 447760
[parent_id]: 
[tags]: 
Is DQN Q-Learning update really stochastic gradient descent?

In the Deepmind DQN paper, the authors mention that familiar Q Learning can be recovered by updating weights of target network at every step so if $\theta_i^-=\theta_i$ in the first loss equation, does the gradient still hold and will the update still be called stochastic gradient descent? I am very confused because don't we need to differentiate $\theta$ with max part too?
