[site]: crossvalidated
[post_id]: 275224
[parent_id]: 
[tags]: 
How can I deal with the mismatch between the vocabularies of questions and answers in a closed domain QA system?

I am building a question answering system that given a legal document attempts to answer questions related to the document. For example a tenancy agreement is given to the system and the user asks questions about the agreement. I am splitting the legal document into small segments and try to find the most similar segment to each question. I am using a combination of tf-idf and word-embeddings based similarity measures. The problem I have at the moment is the questions are asked by non-legal experts and almost entirely are in everyday language, therefore there is a huge mismatch between terms used in the questions and the answers (segments). Because I do not have access to a huge collection of legal documents, I am using the prebuilt GloVe vectors . Even if I manage to estimate the word embeddings based on relevant legal documents the mismatch problem would still remain. How can I deal with this problem? Is there a method to augment the word embeddings to fit a certain domain, like this ?
