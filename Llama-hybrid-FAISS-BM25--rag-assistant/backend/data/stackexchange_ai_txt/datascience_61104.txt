[site]: datascience
[post_id]: 61104
[parent_id]: 61100
[tags]: 
The argument metrics is meant to define your criterion for training evaluation. Let me make an example: if you are training a classifier, you want to evaluate your model based on how accurate (in percentage) it is. Therefore, your metric is accuracy (experessed as a float in the [0, 1] range). The higher the accuracy, the lower the loss, the better the model. metrics must not be confused with loss . The loss function is something you need in order to "punish" your model when it makes mistakes. The loss function is at the basics of backpropagation and of weight update, it's the loss object what Neural Networks use to learn . Metrics instead is something that humans watch to understand how good a model is and communicate it. The definition of some metrics is optional, you can evaluate a model based on the loss value only if you want. Sometimes you don't need to specify it. For example in regression tasks, i.e. when you have to predict continuous outputs, you speecify a loss (usually MSE or RMSE) and also evaluate your model based on that.
