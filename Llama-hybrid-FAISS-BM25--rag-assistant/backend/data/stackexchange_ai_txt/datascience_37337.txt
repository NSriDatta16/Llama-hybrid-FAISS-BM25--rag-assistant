[site]: datascience
[post_id]: 37337
[parent_id]: 
[tags]: 
Detect multicollinearity in real-life, non-normally distributed data

I am currently trying to figure out whether my data (consisting of thousands of rows, some is numerical, and some are categorical, and some are ordinal) has multicollinearities or not. One thing I have noticed is that my data is not normally distributed, based on the Shapiro-Wilk test. As is the case with mostly (if not all) real world data, as answered here But based on several posts, including this one , many suggests the ANOVA (Categorical vs Numerical) or the Chi-Squared (Categorical vs Categorical ) tests to detect whether or not there are multicollinearities, without implying (at least not specifically) to ensure the data has normal distribution. My questions are: Can we actually use these methods parametric methods for non-normally distributed data? Other than statistical tests, is there a computational model/algorithm to detect multicollinearities in data, parametric or non-parametric? I've read that decision trees algorithms like Random Forests and XGBoost disregards multicollinearities and can also give feature importance information.
