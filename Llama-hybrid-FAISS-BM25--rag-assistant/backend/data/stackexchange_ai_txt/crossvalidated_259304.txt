[site]: crossvalidated
[post_id]: 259304
[parent_id]: 
[tags]: 
Why is Coordinate Descent not used to solve Least Absolute Deviation?

I have recently been looking into why Least Absolute Deviation (LAD) is not used in place of OLS for machine learning, and it appears the primary reason is due to difficulty in computing a solution for the linear programming type problem that LAD presents - namely the Klee-Minty Cube. However, Lasso is also a linear programming problem and is often solved using coordinate descent, so I am curious why coordinate descent cannot be used to solve LAD and LAD Lasso. I have searched online and there seems to be no research about coordinate descent and LAD regression, although there is a decent amount of research for coordinate descent and support vector machines, which is another type of linear programming problem. It seems that if coordinate descent could be used to solve LAD, then there is little reason to use OLS instead of LAD, as LAD is more robust and intuitive.
