[site]: crossvalidated
[post_id]: 287056
[parent_id]: 
[tags]: 
Strange training loss and validation loss patterns

I have a subset of data from the MovieLens database and have verified its accuracy. Essentially, I have a list of pairs. I want to be able to predict the rating some user will give to some movie but WITHOUT storing any information about the user (so no user embeddings or user vector information). The model will read a list of movies and their scores that some user gave, then it will try to predict the rating the user will give to some other movie, based on the ratings it gave to those movies. The architecture is as follows: A sequence of movie_id s and ratings a user gave For each movie_id , get the associated embedding vector for it Now we have a list of and we will try to predict the user_watch_vector . The core of this is passing in the list of into stacked Convolutional layers and getting a 30 dimensional vector from it Use that vector and concatenate it with the unknown movie embedding vector and connect them to 4 stacked Dense layers to predict the rating. 512 -> 264 -> 128 -> 1. I am using mean-squared error as a loss function. This is what the training loss and validation loss look like: The validation loss always starts lower. Moreover, no matter what model architecture I play with (even if I do categorical_crossentropy as a loss function and predict classes of ratings), the validation loss is ALWAYS lower than the training loss at the beginning. Furthermore, the model always converges to a constant loss very quickly (~20 iterations) before it stops learning. Has anyone seen a particular example of data like this? Why is this and how can I get it to learn properly? Why is the validation loss always lower? Training on about 30 million ratings where each user has given on average, 90 ratings.
