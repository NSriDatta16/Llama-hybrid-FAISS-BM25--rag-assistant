[site]: crossvalidated
[post_id]: 51753
[parent_id]: 51718
[tags]: 
The difficulty with using histograms to infer shape While histograms are often handy and mostly useful, they can be misleading. Their appearance can alter quite a lot with changes in the locations of the bin boundaries. This problem has long been known*, though perhaps not as widely as it should be -- you rarely see it mentioned in elementary-level discussions (though there are exceptions). * for example, Paul Rubin[1] put it this way: " it's well known that changing the endpoints in a histogram can significantly alter its appearance ". . I think it's an issue that should be more widely discussed when introducing histograms. I'll give some examples and discussion. Why you should be wary of relying on a single histogram of a data set Take a look at these four histograms: That's four very different looking histograms. If you paste the following data in (I'm using R here): Annie Then you can generate them yourself: opar Now look at this strip chart: x (If it's still not obvious, see what happens when you subtract Annie's data from each set: head(matrix(x-Annie,nrow=40)) ) The data has simply been shifted left each time by 0.25. Yet the impressions we get from the histograms - right skew, uniform, left skew and bimodal - were utterly different. Our impression was entirely governed by the location of the first bin-origin relative to the minimum. So not just 'exponential' vs 'not-really-exponential' but 'right skew' vs 'left skew' or 'bimodal' vs 'uniform' just by moving where your bins start. Edit: If you vary the binwidth, you can get stuff like this happen: That's the same 34 observations in both cases, just different breakpoints, one with binwidth $1$ and the other with binwidth $0.8$ . x Nifty, eh? Yes, those data were deliberately generated to do that... but the lesson is clear - what you think you see in a histogram may not be a particularly accurate impression of the data. What can we do? Histograms are widely used, frequently convenient to obtain and sometimes expected. What can we do to avoid or mitigate such problems? As Nick Cox points out in a comment to a related question : The rule of thumb always should be that details robust to variations in bin width and bin origin are likely to be genuine; details fragile to such are likely to be spurious or trivial . At the least, you should always do histograms at several different binwidths or bin-origins, or preferably both. Alternatively, check a kernel density estimate at not-too-wide a bandwidth. One other approach that reduces the arbitrariness of histograms is averaged shifted histograms , (that's one on that most recent set of data) but if you go to that effort, I think you might as well use a kernel density estimate. If I am doing a histogram (I use them in spite of being acutely aware of the issue), I almost always prefer to use considerably more bins than typical program defaults tend to give and very often I like to do several histograms with varying bin width (and, occasionally, origin). If they're reasonably consistent in impression, you're not likely to have this problem, and if they're not consistent, you know to look more carefully, perhaps try a kernel density estimate, an empirical CDF, a Q-Q plot or something similar. While histograms may sometimes be misleading, boxplots are even more prone to such problems; with a boxplot you don't even have the ability to say "use more bins". See the four very different data sets in this post , all with identical, symmetric boxplots, even though one of the data sets is quite skew. [1]: Rubin, Paul (2014) "Histogram Abuse!", Blog post, OR in an OB world , Jan 23 2014 link ... (alternate link)
