[site]: crossvalidated
[post_id]: 296488
[parent_id]: 
[tags]: 
Cluster non-vector data based on similarity rating

I have a list $S$ of $N$ non-vector elements (in this case words or concepts), and I'd like to partition them into k subsets of similar words. For each pair $(a,b)$ with $a,b \in S$, I have a number $p_{a,b}\in [0,1]$ representing a noisy probability that $a$ and $b$ are in the same class (I asked my respondents to group them into $k$ subsets for various values of $k$, so $p_{a,b}$ is how often users put them in the same class, averaged over all $k$). The standard approach seems to be, for given $k$, to find $f:S\to\{1,...,k\}$ minimizing $$\displaystyle\sum_{c=1}^k \sum_{f(a)=f(b)=c} cost(p_{a,b})$$ for some proper choice of $cost$. However all algortihms I find require the elements to be vectors of data. Here, I really only have this user-based similarity rating, and that is for each pair $(a,b)$; I have no meaningful data for the actual words/sentences $a$ and $b$. Do any known clustering algorithms take data purely about the pairs, without needing the elements to be numerical/vectorial?
