[site]: crossvalidated
[post_id]: 240371
[parent_id]: 
[tags]: 
Training performance jumps up after epoch, Dev performance jumps down

I train a neural network on some data using minibatches. I evaluate it as follows: for the training set, I check the performance only on the current minibatch. For the Dev (or test) set, I check the performance on the entire set. I get two phenomena (image attached, each point is the evaluation after a minibatch finishes, red arrows denote start of new epochs): For the training error, at the start of each new epoch I get a serious 'bump' up in performance (i.e. overfitting). I assume this is because of my incomplete evaluation - I don't evaluate the entire training set each minibatch but only the current minibatch. For the Dev error - which is my real concern - I get some deterioration after immediately at the start of the second epoch (and the phenomena repeats itself on future epochs). While I know that the Dev performance should indeed diminish at some point, I don't understand why it happens exactly on the start of an epoch. Is this reasonable (especially item 2.)? or do I have some bug in my code? Thanks.
