[site]: crossvalidated
[post_id]: 577782
[parent_id]: 577778
[tags]: 
No actual sample of games will be ever infinite. Even if you perform a billion games and compute the average. The outcome of the games will follow some distribution with $\lim_{X \to \infty} P(x>X) = 0$ . The infinity relates to the expectation of the distribution being unbounded (but the average of a sample from this distribution will not have an infinite value). Below is a computation of the cumulative probability distribution of the average win of a sample up to size 30 games (darkest = sample size 1, lightest = sample size 30). I can imagine that there is some limiting distribution for this (it should be some alpha stable distribution and it appears like a LÃ©vy distribution) and one might try to compute this, but I guess that this illustration already shows sufficiently that it it not weird that some computation with a large sample might result in a finite or relatively low average amount of profit. The infinity of the expectation is only in the extremely long tail, but to get this tail you have a very tiny probability. In the above graph $k$ , depicted on the x-axis, is the average sum of money won in $n$ games (where we changed $n$ from $0$ to $30$ ). For example. If we play two games, then the probability to win on average 1 is when we win 1 in each of the games (probability 0.5*0.5 = 0.25) the probability to win on average 1.5 is when we win 1 in one game and 2 in the other game (probability 0.5*0.25 + 0.25*0.5 = 0.25) the cumulative probability to win on average 1.5 or less is the probability to win either 1.5 or 1 and is the sum of the previous two results. This cumulative probability is what is shown along the y-axis in the graph. R-code n = 30 # sample size n2 = 10000 # range of money for which we define and compute the probability distribution # for sample size n=30 we end up with the range n2/n^2 ### compute/define the initial distribution for a single game k = 1:n2 p = k*0 for (i in k) { ### if the value i is a power of 2 ### then assign 1/i as probability if (log(i,2) %% 1 == 0) { p[i] = 1/i/2 } } #### function to compute convolution #### with this we can compute the distribution of the win in multiple games fconvolve = function(p1,p2) { p_out = p1*0 p_out[1] = 0 for (i in 2:length(p1)) { p_out[i] = sum(p1[1:(i-1)]*rev(p2[1:(i-1)])) } return(p_out) } ### plot defined distribution pn = p plot(k,cumsum(pn), type ='l', xlim = c(0,n2/n^2), ylim = c(0,1)) ### compute and plot distribution of average amount of win for multiple games for (l in 1:n) { pn = fconvolve(pn,p) lines(k/(l+1),cumsum(pn), col = rgb(l/n/2,l/n/2,l/n/2)) }
