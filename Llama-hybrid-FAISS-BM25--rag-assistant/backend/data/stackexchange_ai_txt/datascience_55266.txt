[site]: datascience
[post_id]: 55266
[parent_id]: 55261
[tags]: 
Typically XGBoost does not require many parameters to be tuned to get good performances. I would start with optimizing the n_estimators, max_depth and min_child_weight parameters only. This should already bring you close enough. Another thing you can do to speed-up the process is to prefer Random Search over Grid Search, since in most cases is as or more effective. You could also have a look at the LightGBM implementation, which is faster (and needs less memory ) than XGBoost.
