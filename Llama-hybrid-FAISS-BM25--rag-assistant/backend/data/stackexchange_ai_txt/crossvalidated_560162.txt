[site]: crossvalidated
[post_id]: 560162
[parent_id]: 560142
[tags]: 
Update This answer is wrong, but the reason for my mistake is illustrative enough that I think it's worth leaving up and explaining. In short, I believe that McNemar's test has the null hypothesis $P(r_1 = y\ \&\ r_2 = n) = P(r_1 = n\ \&\ r_2 = y)$ , while the logistic model has the null $P(r_1 = y | r_2 = n) = P(r_1 = n | r_2 = y)$ . library(tidyverse) # Probabilities # Initial probabilities (e.g. 80% say yes initially) # (Tests should have the same outcome if p0 $y = p0$ n = .5?) p0 = list(y = .8, n = .2) # Changes (eg. y2n is the probabilty of changing from yes to no) p = list( y2y = .9, y2n = .1, n2y = .4, n2n = .6 ) prob_table = matrix(t(p), nrow = 2, dimnames = list(To = c('Y', 'N'), From = c('Y', 'N'))) prob_table ## From ## To Y N ## Y 0.9 0.4 ## N 0.1 0.6 N = 100 counts = N * c( p0 $y * p$ y2y, p0 $y * p$ y2n, p0 $n * p$ n2y, p0 $n * p$ n2n ) obs_table = matrix(t(counts), nrow = 2, dimnames = list(t2=c('Yes', 'No'), t1=c('Yes', 'No'))) obs_table ## t1 ## t2 Yes No ## Yes 72 8 ## No 8 12 # Logistic regression tests # if P(t2 = y | t1 = n) = P(t2 = n | t1 = y) # In this example... # P(t2 = y | t1 = n) = .1 # P(t2 = n | t1 = y) = .4 data = epitools::expand.table(obs_table) %>% mutate(has_changed = ifelse(t1 == t2, 1, 0)) m = glm(has_changed ~ t1, data = data, family = binomial) summary(m) ## Estimate Std. Error z value Pr(>|z|) ## (Intercept) 2.1972 0.3726 5.896 3.72e-09 *** ## t1No -1.7918 0.5892 -3.041 0.00236 ** # McNemar tests # if P(t2 = y & t1 = n) = P(t2 = n & t1 = y) # In this example... # P(t2 = y & t1 = n) = 8/100 # P(t2 = n & t1 = y) = 8/100 mcnemar.test(obs_table) ## ## McNemar's Chi-squared test ## ## data: obs_table ## McNemar's chi-squared = 0, df = 1, p-value = 1 Original response In the model sex_changed ~ 1 , the null hypothesis is that the log-odds of sex changing are equal to zero, corresponding to a probability of 0.5. This isn't what you want. You want the model sex_changed ~ 1 + pre_intervention . A significant effect of pre_intervention here would mean that the probability of change for cases that start out as male is signigantly different from the probability for those that start out as female. Note, however, that logistic regression has a perfect separation issue when all of the outcomes are the same in one of the groups, so will not give sensible results for your example data. I hope you have more than 10 cases! data = data.frame(pre = rep(c('M', 'F'), each = 5)) data$change = c(0,0,0,0,1,0,0,0,0,0) m = glm(change ~ 1 + pre, data = data, family = binomial) summary(m) Call: glm(formula = change ~ 1 + pre, family = binomial, data = data) Deviance Residuals: Min 1Q Median 3Q Max -1.35373 -0.00008 -0.00008 0.75806 1.01077 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -19.57 4809.34 -0.004 0.997 preM 19.97 4809.34 0.004 0.997 (Dispersion parameter for binomial family taken to be 1) Null deviance: 12.2173 on 9 degrees of freedom Residual deviance: 6.7301 on 8 degrees of freedom AIC: 10.73 Number of Fisher Scoring iterations: 18 ```
