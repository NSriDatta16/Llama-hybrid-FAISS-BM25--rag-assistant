[site]: crossvalidated
[post_id]: 398055
[parent_id]: 398049
[tags]: 
Personally, I would venture a few guesses: (1) Bayesian statistics saw a huge uptick in popularity in the last couple decades. Part of this was due to advancements in MCMC and improvements in computational resources. Bayesian statistics went from being theoretically really nice but only applicable to toy problems to an approach that could be more universally applied. This means that several years ago, saying you worked on Bayesian statistics probably did make you a very competitive hire. Now, I would say that Bayesian statistics is still a plus, but so is working on interesting problems without using Bayesian methods. A lack of background in Bayesian statistics would certainly be a minus to most hiring committees, but getting a PhD in statistics without sufficient training in Bayesian methods would be pretty surprising. (2) Bayesian statisticians will mention "Bayesian" on their CV. Frequentists will usually not put "Frequentist" on their CV, but much more typically the the area they work in (i.e., survival analysis, predictive modeling, forecasting, etc.). As an example, a lot of my work is writing optimization algorithms, which I'd guess implies you would say means I do Frequentist work. I've also written a fair chunk of Bayesian algorithms, but it's certainly in the minority of my work. Bayesian statistics is on my CV, Frequentist statistics is not. (3) To an extent, what you've said in your question also holds truth as well. Efficient general Bayesian computation has more open problems in it than the Frequentist realm. For example, Hamiltonian Monte Carlo has recently become a very exciting algorithm for generically sampling from Bayesian models. There's not a lot of room for improvement of generic optimization these days; Newton Raphson, L-BFGS and EM algorithms cover a lot of bases. If you want to improve on these methods, you generally have to specialize a lot to the problem. As such, you're more like to say "I work on high-dimensional optimization of geo-spatial models" rather than "I work on high-dimensional Maximum Likelihood Estimation". The machine learning world is a bit of an exception to that, as there's a lot of excitement in finding out new stochastic optimization methods (i.e., SGD, Adam, etc.), but that's a slightly different beast for a few reasons. Similarly, there's work to be done on coming up with good priors for models. Frequentist methods do have an equivalent to this (coming up with good penalties, i.e., LASSO, glmnet) but there's probably more fertile ground for priors over penalties. (4) Finally, and this is definitely more of a personal opinion, a lot of people associate Frequentist with p-values. Given the general misuse of p-values observed in other fields, lots of statisticians would love to distance themselves as far as possible from current misuses of p-values.
