[site]: datascience
[post_id]: 123454
[parent_id]: 
[tags]: 
Sum of vector sentence embeddings vs. paragraph embedding

I have been experimenting with the all-MiniLM-L6-v2 model for computing 384-dimensional vector embeddings for text paragraphs. The following code compares the embedding computed for a paragraph with the sum of embeddings of the constituent sentences: import re def split_into_sentences(text): # Split using regular expression to preserve punctuation at the end of sentences sentences = re.split(r'(? I get the output: [0.677, 0.462, 0.526, 0.701, 0.586, 0.797, 0.544, 0.697, 0.163, 0.336, 0.32, 0.575, 0.697] 0.8497203877599846 The first line compares each of the sentences with the whole paragraph. The second line compares the sum of sentence embeddings with the embedding for the whole paragraph. It strikes me as unexpected that the sum of all sentence embeddings (~0.85) does not do much better than the sixth sentence alone (~0.80). Why is that the case?
