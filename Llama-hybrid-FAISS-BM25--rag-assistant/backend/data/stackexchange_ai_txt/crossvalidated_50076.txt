[site]: crossvalidated
[post_id]: 50076
[parent_id]: 50052
[tags]: 
You need to add their random effect also, otherwise you are looking only on the mean response, excluding information/influence from the grouping of the data; St√©phane's post gives some reasons why you would like to do that. Coming back to a more general case: Are you using one of the standard packages in R (lme4, nlme, MCMCglmm)? Usually they do have an in-build function to return fitted values. Otherwise you need to calculate a vector holding the realization of your random effects and add the appropriate displacement (in your model it appears you are just having random intercepts and not slopes) to your "mean" prediction. Roughly speaking those realization of the random effects coefficients $\gamma$ are : $\hat{\gamma_i} = [Z_i^T Z_i + \sigma^2 \Psi_{\theta}^{-1}]^{-1} Z_i^T r_i$, where $r_i = (y_i - X_i \beta)$ is the residuals vector, $Z_i$ the random-effects design matrix, $\Psi_\theta$ is the general covariance matrix and $\sigma$ is your residual (measurement error) variance parameter. (I used $\gamma$ instead of $\delta$ cause sometimes $\delta$ is reserved for indicator functions) A lot of standard references on linear mixed effects models give this formula on how to calculate the realization of the group-specific vector $\gamma$. I used the paper "Estimation for High-Dimensional Linear Mixed-Effects Models Using $l$1-Penalization" by Schelldorfer et al. as reference but that was just because it happened to be one I was working on recently. Textbooks should have it also.
