[site]: crossvalidated
[post_id]: 590340
[parent_id]: 
[tags]: 
What parameters of a neural network should be changed when increasing the number of training samples?

I was testing a DL model (GNN with two GCN layers and one linear layer) on a small dataset for a regression purpose, the resulted MAE and the scatter plot showed some really good results. However, when I applied the same model for a 10x dataset, the results (especially the scatter plot) showed random with low range outputs. With having the first training results that good and the second training that bad, I assumed that with increasing the number of subjects some parameters must be changed. Note that I have a high number of epochs with early stop (and the training is in both cases ended with early stop). Any suggestions?
