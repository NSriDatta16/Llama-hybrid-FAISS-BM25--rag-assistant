[site]: crossvalidated
[post_id]: 422404
[parent_id]: 
[tags]: 
Time series predictions look suspiciously good

I am working on a time series forecasting problem. For this, I am training a recurrent neural network in Keras (mostly following the guidelines from this blog post by Jason Brownlee). My problem comes when predicting on test data. The model seems to perform well in every situation : if trained on real data and tested on real data (which is what I am expecting after all) if trained on a random walk and tested on real data (which is suspicious to me) if trained on real data and tested on a random walk (which is suspicious again) When I say "the model performs well", I mean several things : the inferred values follow the rapid changes in the test values, and it gets better with model complexity (RNN depth, RNN breadth, number of epochs, etc.). all comparison metrics (RMSE, MAE, MAPE) are consistently better with the trained model than with the baseline persistence model, even with very shallow and under-trained networks How is this possible ? Is there an error in my code ? Or are RNN that good at predicting ? Code is available on this Colab notebook for testing. Thank you in advance for your guidance !
