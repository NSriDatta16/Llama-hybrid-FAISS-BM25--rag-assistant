[site]: datascience
[post_id]: 64467
[parent_id]: 64444
[tags]: 
Why are the vector similarities so high for unrelated words for the embedding? For the specific example you give, I would argue that it makes sense that car and plant have high similarity. This is likely due to phrases such as car manufacturing plant Also I am able to get vectors for non-words like "asdfasfdasfd" or "zzz123Y!/Â§zzzZz", and they differ from each other. How is this possible? For your specific case, since you use the en_trf_xlnetbasecased_lg , the answer is straightforward. Embeddings provided by XLNet are contextual, meaning that even if the word itself isn't a word, you'll get an embedding given the words in its context. Also, it is likely that HuggingFace's implementation uses Byte-Pair Encoding as tokens, making it much more robust to out-of-vocabulary situations.
