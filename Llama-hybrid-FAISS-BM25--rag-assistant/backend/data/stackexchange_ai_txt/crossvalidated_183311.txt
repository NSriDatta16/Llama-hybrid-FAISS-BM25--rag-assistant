[site]: crossvalidated
[post_id]: 183311
[parent_id]: 
[tags]: 
Shouldn't the root mean square error (RMSE) be called root mean square residual?

As far as I understand, estimating the error of a model, say an artificial neural network, requires to know the "true" model. Wikipedia says in its article "Errors and residuals": "The error (or disturbance) of an observed value is the deviation of the observed value from the (unobservable) true value of a quantity of interest". While "the residual of an observed value is the difference between the observed value and the estimated value". However, to know the true value is in practice commonly not possible. Therefore, shouldn't the root mean square error, which evaluates the mean square deviation of the observed values from the predicted values, be called root mean square residual, because it evaluates the difference between observed value (the measurement) and estimated value (the model output)?
