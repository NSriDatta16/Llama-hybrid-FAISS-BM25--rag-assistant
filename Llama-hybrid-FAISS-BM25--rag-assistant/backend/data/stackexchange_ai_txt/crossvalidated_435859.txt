[site]: crossvalidated
[post_id]: 435859
[parent_id]: 
[tags]: 
Make predictor/variable less important in Neural Network

I have a question regarding my Neural Network. So, my data contains multiple users who filled in Likert-scale surveys regarding their happiness level (ordinal data). I am testing multiple ways to encode ordinal data. In this case i am using One-Hot encoding for the target variable, so it is a classification & supervised learning problem One of my predictors is the happiness level from the last filled in survey. In my opinion it's an informative predictor as it is very unlikely that if last-hapiness value is 0, next hapiness value is 5, but more likely a 1/2/3. But what happens is that my model recognizes that last-hapiness level is most of the times the same as the next hapiness level: last-value variable= 5, prediction = 5, last-value variable= 2, prediction = 2 The table below shows the predictions of the model on the test set. 'Same level' means previous-value variable == real value 'Different level' == not the same as real value How can I make this predictor less important/informative so the model will pay more attention to my other predictors. Or how can I penalise the model in a way that he is better in predicting the 'different level'. Working with Python + Keras.
