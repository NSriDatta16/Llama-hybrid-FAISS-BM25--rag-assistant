[site]: stackoverflow
[post_id]: 1470286
[parent_id]: 406760
[tags]: 
QA can be done well, over the long haul, without exploring all forms of testing Lots of places seem to have an "approach", how "we do it". This seems to implicitly exclude other approaches. This is a serious problem over the long term, because the primary function of QA is to file bugs -and- get them fixed. You cannot do this well if you are not finding as many bugs as possible. When you exclude methodologies, for example, by being too black-box dependent, you start to ignore entire classes of discoverable coding errors. That means, by implication, you are making entire classes of coding errors unfixable, except when someone else stumbles on it. The underlying problem often seems to be management + staff. Managers with this problem seem to have narrow thinking about the computer science and/or the value proposition of their team. They tend to create teams that reflect their approach, and a whitelist of testing methods. I am not saying you can or should do everything all the time. Lets face it, some test methods are simply going to be a waste of time for a given product. And some methodologies are more useful at certain levels of product maturity. But what I think is missing is the ability of testing organizations to challenge themselves to learn new things, and apply that to their overall performance. Here's a hypothetical conversation that would sum it up: Me: You tested that startup script for 10 years, and you managed to learn NOTHING about shell scripts and how they work?! Tester: Yes. Me: Permissions? Tester: The installer does that Me: Platform, release-specific dependencies? Tester: We file bugs for that Me: Error handling? Tester: when errors happen to customer support sends us some info. Me: Okay...(starts thinking about writing post in stackoverflow...)
