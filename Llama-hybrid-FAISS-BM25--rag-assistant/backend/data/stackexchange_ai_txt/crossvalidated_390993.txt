[site]: crossvalidated
[post_id]: 390993
[parent_id]: 
[tags]: 
verifying a posterior is proper

There's a homework problem in a textbook that asks to verify propriety of a certain posterior distribution, and I'm having a little trouble with it. The setup is you have a logistic regression model with one predictor, and you have an improper uniform prior over $\mathbb{R}^2$ . Specifically, we assume for $i=1,\ldots,k$ that $$ y_i \mid \alpha, \beta,x_i \sim \text{Binomial}(n,\text{invlogit}(\alpha + \beta x_i)), $$ so the likelihood is $$ p(y \mid \alpha, \beta, x ) = \prod_{i=1}^k [\text{invlogit}(\alpha + \beta x_i)]^{y_i}[1-\text{invlogit}(\alpha + \beta x_i)]^{n-y_i}. $$ The trouble is that I suspect that this posterior is actually improper. For the specific situation where $k=1$ , if we use the change of variables $s_1 = \text{invlogit}(\alpha + \beta x)$ and $s_2 = \beta$ , then we can see that \begin{align*} \iint_{\mathbb{R}^2}p(y \mid \alpha, \beta, x ) \text{d}\alpha \text{d}\beta &= \iint_{\mathbb{R}^2}[\text{invlogit}(\alpha + \beta x)]^{y}[1-\text{invlogit}(\alpha + \beta x)]^{n-y} \text{d}\alpha \text{d}\beta \\ &= \int_{-\infty}^{\infty}\int_0^1 s_1^{y-1}(1-s_1)^{n-y-1} \text{d}s_1 \text{d}s_2 \\ &= B(y,n-y) \int_{-\infty}^{\infty} 1 \text{d}s_2 \tag{*}\\ &= \infty. \end{align*} In the line with the asterisk we assume that $0 , but if it doesn't, then we end up with the same thing. Am I doing something silly here? Or is this an improper posterior?
