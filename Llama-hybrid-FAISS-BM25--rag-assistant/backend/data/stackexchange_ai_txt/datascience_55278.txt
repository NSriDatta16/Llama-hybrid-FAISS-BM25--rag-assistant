[site]: datascience
[post_id]: 55278
[parent_id]: 55162
[tags]: 
Actually the first plot is still better! The first point to mention is that in 2d you lose a vast amount of information i.e. none of these plots are necessarily telling you something. If the 2d plot is good you can be happy but if not, you should not necessarily get disappointed! I strongly recommend you to see the performance of your dimensionality reduction by evaluating your regression model. For 100 dimensions I would first try to find correlation/dependence of features and target (try not to use linear correlation without visualization!). Then, out of all features remove non informative ones. On the remaining features try different dimensionality reduction algorithms (not only PCA, for example NMF if values are all non-negative and/or LLE) with more dimensions. Evaluate your results on your validation set.
