[site]: crossvalidated
[post_id]: 343106
[parent_id]: 
[tags]: 
Worse accuracy with input normalization (NNs)

I am training a neural network for audio classification. My inputs are "1-channel images" of size 60x130x1. Surprisingly, I always get better accuracy when training the model with the original data, instead of with the normalized input data (mean = 0 , variance = 1). This is how I normalize it: mean = np.mean(X_train, axis = 0) std = np.std(X_train, axis = 0) X_train = (X_train-mean)/std X_test = (X_test-mean)/std X_val = (X_val-mean)/std ---------------------------------------------------------EDIT 1 ---------------------------------------------------------------- Some relevant values of my training data are: Min and Max values (across training examples): 0.0 , 1954.4 Min and Max values of the mean (across training examples): 0.0023, 6.7611 Min and Max values of the std (across training examples): 0.0204 , 39.0361 ---------------------------------------------------------EDIT 1 ---------------------------------------------------------------- Does this makes any sense, or normalized inputs should always give better results? (The purple line corresponds to the normalized data) Training accuracy / per_epoch_per_minibatch
