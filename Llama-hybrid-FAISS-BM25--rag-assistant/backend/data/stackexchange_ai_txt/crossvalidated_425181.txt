[site]: crossvalidated
[post_id]: 425181
[parent_id]: 423246
[tags]: 
Practically speaking, I don't think so in general. Suppose the GAN maps some $z\sim\mathcal{N}(0,\sigma I)$ to producing some images $I = G(z)$ . Unlike generative models with diffeomorphic mappings like RealNVP and Glow (which are even more constrained actually), the GAN mapping $G$ is usually neither injective nor surjective. You can see this from the common problem of mode collapse: if the resulting distribution over images $p_G(I)$ is a Dirac Delta then it cannot hold any information about the input distribution. More formally, recall what happens to a density function as you pass (samples from) the random variable through a sequence of transforms (i.e., the probabilistic change of variables law). I.e. as $z$ goes through a single layer of $G$ , to $z_1 = G_1(z)$ , it's density is related to that of $z$ by scaling with the inverse transform's Jacobian . But here the Jacobian may be singular and/or the inverse may not exist! So at least some of the information about the density will (or at least can) be irreversibly destroyed. Of course, if you add some constraints and we consider the issue abstractly, there may be a way to do this, theoretically.
