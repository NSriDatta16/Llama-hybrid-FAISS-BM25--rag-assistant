[site]: datascience
[post_id]: 64924
[parent_id]: 45033
[tags]: 
For next Phrase prediction, using RNNs to train a model on your own data would be more beneficial than using pre-trained models. And vice versa for Next Word prediction. This might help: [here][ https://towardsdatascience.com/gmail-style-smart-compose-using-char-n-gram-language-models-a73c09550447] For understanding what will be X and Y for training, read about teacher forcing technique: [Teacher enforcing technique][ https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/] I would also suggest you to use multiple models to get desired results, which would include Next Word Prediction Model, Next phrase prediction model and possibly a Word/Phrase Completion model. A combination of these models can achieve great results. There are various models with high accuracy(low perplexity) for next word prediction which can be used in there native form. Also refer [Tranformers from Hugging Face][ https://github.com/huggingface/transformers] , it might be of great help.
