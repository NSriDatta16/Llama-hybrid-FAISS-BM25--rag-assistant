[site]: crossvalidated
[post_id]: 546660
[parent_id]: 546641
[tags]: 
You are doing $k$ -fold cross-validation , so $k$ times you train a model on different train set and validate on different test set. After each such run, you calculate an error metric, in this case RMSE. So, you end up with $k$ values of RMSE, the table shows average RMSE and standard deviation of the metric. Standard deviation tells you how variable, or spread, are the values. Preferably, you would like the standard deviation to be ac close to zero as possible, since if the metric varies a lot depending on the training and testing set, this means that it is harder to judge the exact performance of the model on unseen data.
