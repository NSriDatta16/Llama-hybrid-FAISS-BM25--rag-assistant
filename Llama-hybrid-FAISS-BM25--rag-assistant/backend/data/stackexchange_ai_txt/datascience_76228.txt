[site]: datascience
[post_id]: 76228
[parent_id]: 76222
[tags]: 
I've tried 2 several times but it has never proved better than 1. I think the reason is, the more data you feed to a model, the better. The disadvantage of 2 is that the models that are trained use less data than the model in 1. In addition, some features might be independent of the group. For instance, when modelling property prices, being in the city centre always increases the price, both for residential and industrial. Let me discuss two of the main models used for tabular data: Tree based models will already do the feature engineering that you described in your first point. The model will already do a split residential/industrial if it contributes to the gain and then it will keep doing particular splits for each group. Linear models: a generalization of general linear models are mixed models, that kind of does what you mentioned on the second point, but keeping some structure that allows it to acknowledge that the city center is more expensive. That being said, if you have very different categories, it might be worth splitting the dataset, it's just a matter of trying.
