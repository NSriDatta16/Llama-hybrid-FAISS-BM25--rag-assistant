[site]: crossvalidated
[post_id]: 557440
[parent_id]: 
[tags]: 
The different usage of ROC between diagnotic tests and machine learning

I am currently very confused about the ROC usage in diagnostic tests and machine learning. In the scenario of medical diagnostic studies, many tutorial does not mention the data split procedure as often highlighted in machine learning courses, and generally draw the ROC with all the available data to assess the diagnotic performance of a specific clinical test. However, when the data analysts attempts to assess the model performance of several models, the analysts often perform the data split/cross validation and the ROC/AUC is often only applied for the test data only. What is the difference between the two scenarios and why the researches performed the ROC/AUC analysis in different ways? Hope anyone can help me with this question. Thanks in advance!
