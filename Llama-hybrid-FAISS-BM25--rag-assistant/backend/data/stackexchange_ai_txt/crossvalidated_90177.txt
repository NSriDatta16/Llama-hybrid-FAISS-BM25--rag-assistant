[site]: crossvalidated
[post_id]: 90177
[parent_id]: 90102
[tags]: 
Here is what might be a decent solution: Given two vectors $x^i$ and $x^j$ as in the question, the difference $x_i-x_j$ is a noise vector distributed according to $\mathcal{N} \left( x,\mathbb{1} \cdot \left(\sigma_i^2 + \sigma_j^2 \right) \right)$. Note that the base vector $x$ cancelled out. Now we can get a decent estimate for $\sigma_i^2 + \sigma_j^2$ by just measuring the empirical standard deviation of $x^i-x^j$. We can thus write $\binom{k}{2}$ approximate equations in $k$ variables, get a decent solution (since if $n \gg k$ each of the equations separately is a pretty good approximation), and once approximate values for the $\sigma_i$'s are obtained, we can solve the problem in a standard way, probably by taking a weighted average of the $x^i$'s.
