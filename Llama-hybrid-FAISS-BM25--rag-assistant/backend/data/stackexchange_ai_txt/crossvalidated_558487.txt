[site]: crossvalidated
[post_id]: 558487
[parent_id]: 
[tags]: 
Feature engineering zero-inflated distributions for Neural Networks

I am trying to fit a neural network on a set of various features. For most of the features I've followed some common rule of thumbs, so as to get nicely distributed features. Not so imbalanced binary features, standardizing continuous features, taking some logs to get closer to normal gaussian... and so on. I am a bit stuck with zero inflated feature, that is features for which the distribution is nice overall excpet for a unique spike, generally in 0 ('zero inflation'). I mainly have two kinds of distributions: spike and slab (some gaussian + zero inflation) and what look like half gaussian + zero inflation. The latter seems to be interpretable as a compounded poisson process, where the zero are due to a lack of event. I wonder if there is some trick or general rule of thumbs to deal with such features. My first idea was to build an indicator (or +1/-1) of the feature being zero or not. But I don't know what to do for the magnitude of the features. Is there a good approach to deal with such features ?
