[site]: crossvalidated
[post_id]: 147514
[parent_id]: 
[tags]: 
When should I be worried about the Jeffreys-Lindley paradox in Bayesian model choice?

I am considering a large (but finite) space of models of varying complexity which I explore using RJMCMC . The prior on the parameter vector for each model is fairly informative. In what cases (if any) should I be worried about the Jeffreys-Lindley paradox favoring simpler models when one of the more complex models would be more suitable? Are there any simple examples which highlight the problems of the paradox in Bayesian model choice? I have read a few articles, namely Xi'an's blog and Andrew Gelman's blog , but I still don't quite understand the problem.
