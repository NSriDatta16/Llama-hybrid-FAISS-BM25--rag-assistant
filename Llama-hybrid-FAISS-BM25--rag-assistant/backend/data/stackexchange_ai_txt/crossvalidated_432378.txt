[site]: crossvalidated
[post_id]: 432378
[parent_id]: 428902
[tags]: 
There are some elements to answer your question in Section 16.5 of the Deep Learning book by Ian Goodfellow and al.: A good generative model needs to accurately capture the distribution over the observed or “visible” variables $v$ . Often the different elements of $v$ are highly dependent on each other. In the context of deep learning, the approach most commonly used to model these dependencies is to introduce several latent or “hidden” variables, $h$ . The model can then capture dependencies between any pair of variables $v_i$ and $v_j$ indirectly, via direct dependencies between $v_i$ and $h$ , and direct dependencies between $h$ and $v_j$ . The section also opposes the approach of adding latent variable to that of trying to model $p(v)$ without any latent variable: A good model of v which did not contain any latent variables would need to have very large numbers of parents per node in a Bayesian network or very large cliques in a Markov network. Just representing these higher order interactions is costly. [...] As an approach to discover such relevant (and computationaly tractable) interactions between the visible variables, the concept of structure learning is introduced. In general, modeling a fixed structure with latent variables avoids the need of structure learning between the visible variables. The book seems to imply that the former is easier than the latter. Indeed, we find later on this sentence: Using simple parameter learning techniques we can learn a model with a fixed structure that imputes the right structure on the marginal $p( v )$ . Edit (thanks to carlo's comment): Going further in the analysis of structures with latent variables, we come accross the notion of interpretability. Jumping to Section 16.7, we can read: When latent variables are used in the context of traditional graphical models, they are often designed with some specific semantics in mind—the topic of a document, the intelligence of a student, the disease causing a patient’s symptoms, etc. These models are often much more interpretable by human practitioners and often have more theoretical guarantees [...]
