[site]: crossvalidated
[post_id]: 159048
[parent_id]: 158834
[tags]: 
It totally depends on the nature of your data and the inner correlations, there is no rule of thumb. However, given that you have a large amount of data a 2-layer LSTM can model a large body of time series problems / benchmarks. Furthermore, you don't backpropagate-through-time to the whole series but usually to (200-300) last steps. To find the optimal value you can cross-validate using grid search or bayesian optimisation. Furthermore, you can have a look at the parameters here: https://github.com/wojzaremba/lstm/blob/master/main.lua . So, the sequence length doesn't really affect your model training but it's like having more training examples, that you just keep the previous state instead of resetting it.
