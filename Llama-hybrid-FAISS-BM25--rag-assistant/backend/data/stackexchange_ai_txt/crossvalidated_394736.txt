[site]: crossvalidated
[post_id]: 394736
[parent_id]: 
[tags]: 
Machine Learning - How to diagnose if my dataset is limiting my results?

I am working in a Machine Learning research group on a project related to cancer treatment. My dataset has 149 rows, 19 variables and the dependent variable has 2 possible classes (0 or 1). Also, it is important to notice that exists discrete and continuous features in the dataset. The problem is that I have tested many different algorithms - such as XGB, Random Forests, Logistic Regression, ANN's - combined with many scaling and variable selection techniques. Nevertheless, none of them is able to get past the barrier of ~73% ROC's AUC, even though for each one of the listed ML algs is possible to get a "best" model with AUC around ~71%. My hypothesis is that I am probably being limited by my dataset, because, when I plot the scatter plot of the dataset projections onto the 2 most relevant PCA components, some points of different classes almost partly overlap. Therefore, making it impossible even for me to draw by hand a decision boundary. So, how can I mathematically diagnose if my dataset is limiting my performance?
