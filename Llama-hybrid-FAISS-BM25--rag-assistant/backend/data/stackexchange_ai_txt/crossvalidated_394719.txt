[site]: crossvalidated
[post_id]: 394719
[parent_id]: 
[tags]: 
Randomization in Cross Validation

I have made some researches about cross validation for machine learning. I faced two types of randomization techniques used for splitting the dataset into K-folds. First Technique: The data samples are shuffled, which means their positions are changed. I will give an example. Data Samples: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 Shuffling: 4, 7, 1, 3, 2, 9, 8, 10, 6, 5 After shuffle operation is performed, training and testing folds are constructed sequentially in each iteration. First Iteration: Testing(4, 7), Training(1, 3, 2, 9, 8, 10, 6, 5) Second Iteration: Testing (1, 3), Training(4, 7, 2, 9, 8, 10, 6, 5) Third Iteration: Testing(2, 9), Training(4, 7, 1, 3, 8, 10, 6, 5) Fourth Iteration: Testing(8, 10), Training(4, 7, 1, 3, 2, 9, 6, 5) Fifth Iteration: Testing(6, 5), Training(4, 7, 1, 3, 2, 9, 8, 10) Second Technique: The order of data samples are preserved. Instead, random indices are produced to choose the samples. For example, in first iteration, the index vector [1, 0, 0, 1, 0, 0, 0, 0, 0, 0] is created. The index value 1 is used to choose testing samples, while the index value 0 is used to choose training samples. Totally, five different index vectors are produced during cross validation. In both technique, anchoring randomization is preferred to get same models for each execution of the cross validation code. (Shuffling and indices vector are preserved same in each execution of the code.) Which technique is better ? Which one is more preferable ?
