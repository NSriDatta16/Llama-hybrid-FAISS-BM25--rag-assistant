[site]: crossvalidated
[post_id]: 596851
[parent_id]: 
[tags]: 
How does class balancing via reweighting affect logistic regression?

When developing machine learning classifiers, some people upsample or upweight the minority class to achieve a 50-50 balance, claiming that this improves performance. Some statisticians have questioned this practice, but there do seem to be some potential benefits , such as covariate shift adaptation . The practice is very widespread, generating so many questions on this site that CV Meta has raised concerns about consolidating the influx . There also seems to be a popular belief that class imbalance is a "problem" that data scientists must "fix" or address whenever it presents itself in the data. Some data scientists apply class reweighting to logistic regression . This is especially surprising to me because it's such a simple traditional model and, pre-ML era, there was no tradition of boosting performance with reweighting (to the best of my knowledge). It is also puzzling because geometrically, it seems like it wouldn't affect the decision boundary between positive and negative samples, only the overall intercept of the model. If only the intercept changes, the rank order of predicted probabilities does not change, and popular evaluation metrics like AUROC and AUPRC which depend only on this rank order are also unchanged. But I have colleagues who tell me that they routinely increase the AUC of logistic regression models by upweighting the minority class. For them, the value of this practice is settled and uncontroversial. Questions Can class reweighting affect more than the intercept of an unregularized logistic regression model? What initution or analysis can be used to predict the impacts? Are there good toy examples? Do the answers to these questions shed any light on when and why class balancing is "actually good"?
