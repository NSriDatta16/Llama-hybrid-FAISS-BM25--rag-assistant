[site]: crossvalidated
[post_id]: 314802
[parent_id]: 314714
[tags]: 
Do not use $t$-SNE as predictor variables ( in general ). As it has been pointed out in a previous answer in a best-case scenario using all the data to compute the $t$-SNE representation is a bad practice even if one holds out the response variable. In addition using $t$-SNE directly also renders the original modelling procedure useless when presented with new data (as the OP correctly comments too) because we cannot reconstruct a new embedding. As a work-around I think it is worth exploring the option of a deep auto-encoder . This will allow use to readily map new data on our "interesting representation". Deep auto-encoders can learn highly non-linear representations of a dataset. We will train the auto-encoder on our training folds (similar to what we would do with PCA) and then project new data accordingly. amoeba's answer on " Building an autoencoder in Tensorflow to surpass PCA " is an excellent resource to get you started. In specific cases , one might be able to build a deep neural network to replicate the output of $t$-SNE on a new sample. This option will take care of the above issues (data reuse, no generalisation to unseen data). I do not think it is a substantially different approach from using a deep auto-encoder in the first place though and conceptually I find it more convoluted. Plus the auto-encoder literature has many extensions (eg. denoising auto-encoders ) that might come handy. Regarding the exact phenomenon of 10%+ performance boost reported: Assuming that the response variable is not accidentally used, I suspect that the data might have an non-linear embedding that the RF classifier cannot easily detect. Random forests (or any other model for that matter) do not guarantee that any non-linear association will be discovered. I would suggest examining the $t$-SNE output itself. Maybe some of the patterns are not so hard to explain and a bit of clever/educated features engineering from your part can give you a decent boost. I hope you see that, somewhat anti-climatically, using $t$-SNE output directly is not very straight-forward. $t$-SNE is a very helpful tool; nevertheless as many great tools, it is easy for us to misuse it as a hammer when we just have screws.
