[site]: crossvalidated
[post_id]: 46037
[parent_id]: 
[tags]: 
What do I need to know about Bernoulli distributions to build a Naive Bayesian classifier?

I'm building a naive bayesian classifier for a binary classification. Right now I have an estimator for Bernoulli distributions, and real distributions (using a kernel mixture distribution). I can build my distributions nicely, and take the PDF's from my distribution and samples. But when I combine the probabilities together, my bernoulli probabilities simply overwhelm all other evidence. Even for datasets I know have zero chance of being members of some class, they end up having probabilities in the 90-99% range. I think I'm being naive (hah!) here, am I missing something? EDIT: This is a little long for a comment, so I've attached it to my question. My data looks like a Needle in a haystack problem - Very few in my True class (about 3-5%), most in the false class. So my false probability is fire-walled, which is fine. But my True class is also overestimating, which is bad. I'm okay with NBC not being accurate wrt probabilities - just the overall classification. I get these extreme results when I start including my boolean values. Which is what's bothering me. Perhaps I'm missing some understanding of how to implement this. To give some idea on my training set, I've got 20,000 training samples, 10,000 in the true class, 10,000 in the false class. I'm predicted around 400K rows. If I use a simple probtrue > probfalse estimate, I get 126 out of 400K as being in the true class (true value is a little more than 10,000). If I simply us probtrue > 0.99, that shrinks down to about 84K. an improvement, But still not what I was expecting. If I can shrink this set down to 40K, I'll be ecstatic. FYI: I was previously using Prior Knowledge's prediction engine using which I was able to get down to a reasonable accuracy. Then they got bought up by Salesforce and made their CEO Director of predictive analytics.
