[site]: datascience
[post_id]: 93225
[parent_id]: 
[tags]: 
Probability that ensemble model is correct based on accuracies of its classifiers

I'm trying to understand what I did wrong when trying to answer this question. The exact question is: Assume that we have 3 trained prediction models, and each model outputs either -1 or 1. We then tested the accuracies of these models and obtained the following outcomes: Model Accuracy m 1 0.60 m 2 0.55 m 3 0.45 Let M be the ensemble model that outputs a plurality vote of these three models. If we assume that the errors of the models m 1 , m 2 , and m 3 are independent, what is the probability that M( x ) would be correct on a test instance x ? I thought that because this was a plurality vote, and the classification errors are independent of each other, I could simply take the weighted average of the accuracy of the three classifiers: $ \begin{align*} P(X) &= \sum_{all\ models\ M_j} P(C_i|x,M_j)P(M_j) \\ &= \frac{1}{L} \sum_{all\ models\ M_j} P(C_i|x,M_j) \\ &= \frac{1}{3}(0.60+0.55+0.45)\\ &= 0.53 \end{align*} $ But I was told that this is incorrect (with no context as to why). Can someone explain why this is incorrect? If this is a plurality vote (which to me assumes that the votes of each classifier are equal), why can I not simply take the weighted average?
