[site]: crossvalidated
[post_id]: 563235
[parent_id]: 
[tags]: 
Is the Markov property important in the Metropolis algorithm?

I’m taking a class in Bayesian statistics, and we’re learning about the Metropolis algorithm. Suppose for simplicity that we just have one parameter we’re trying to estimate: $\theta$ . According to the algorithm, if we’re at some $\theta_{current}$ , and we generate a new parameter $\theta_{proposed}$ from the proposal distribution, we move to the new parameter with probability $$min \left(1, \frac{prior(\theta_{proposed}) \times likelihood(\theta_{proposed})}{prior(\theta_{current}) \times likelihood(\theta_{current})}\right)$$ In words, we compare the (unnormalized) posterior value for the current parameter with the posterior value for the proposed parameter. My question is: why make the comparison between current and proposed in the first place? (which is what the title of the question is alluding to, the Markov property). Why not just decide to accept the new parameter based on the value of $${prior(\theta_{proposed}) \times likelihood(\theta_{proposed})}$$ (either by considering it to be a probability or taking some function of it). One thing I could think of is that we would not be normalizing the posterior, but if we’re always not normalizing, why does it matter? And are there other reasons we need the Markov property?
