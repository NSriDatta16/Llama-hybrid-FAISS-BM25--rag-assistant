[site]: crossvalidated
[post_id]: 285902
[parent_id]: 285894
[tags]: 
I have written a proof that most financial returns cannot have a first moment and in subsequent papers replaced most of the math of financial modeling. This isn't well known and I keep getting desk rejected because "our readers would not be interested." Sorry, personal frustration. You can find my working papers at https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=1541471 . The short answer as to why is to consider the Markowitzian model's intertemporal budget constraint on an asset by asset basis. That is the movement of future wealth by time. In a CAPM construction this would be $$\tilde{w}=R\bar{w}+\varepsilon.$$ This is one of three ways to approach this problem. The others are to solve the returns as the ratio of future value divided by present value minus one and to approximate a solution by finding the difference of the logarithms of the future value and the present value. Although obviously related, it turns out they have very different solutions. For the above equation, Mann and Wald showed in 1943 that the estimator for R is the least squares estimator for all distributions of $\varepsilon$ centered on zero and with non-zero, defined variance. White showed that the sampling distribution of $R$ is the Cauchy distribution. Because the least squares estimator is a version of a sample mean and the Cauchy distribution has no population mean, this implies that for likelihood-based methods, no solution to CAPM models exists. For Pearson and Neyman Frequentists a solution does exist, but it abandons mean-variance finance. Obviously the method of least squares is gone, but Theil's regression still survives; unfortunately, what you would end up with is median-interquartile range finance without a covariance structure. The only way to solve mean-variance finance in Frequentist methods is to abandon it. Fortunately, the method White used to show the limiting distribution has a Bayesian interpretation. He multiplied the square root of Fisher information by the likelihood, which in Bayesian terms is the same as multiplying the Jeffrey's prior by the likelihood. While this gives you the posterior distribution of a mean, if $\tilde{x}$ is drawn from a Cauchy distribution of $$\frac{1}{\pi}\frac{\sigma}{\sigma^2+(x-\mu)^2},$$ then $\bar{x}$ is drawn from $$\frac{1}{\pi}\frac{\sigma}{\sigma^2+(\bar{x}-\mu)^2},$$ which is precisely the same distribution. So the posterior of $R$ should be the Cauchy distribution and the likelihood should be the Cauchy distribution. The relationship between the likelihood and the density is that if $$\frac{1}{\pi}\frac{\sigma}{\sigma^2+(x-\mu)^2},\forall\{\mu,\sigma\}\in\Theta$$ is your likelihood then $$\frac{1}{\pi}\frac{\sigma}{\sigma^2+(x-\mu)^2},\forall{x}\in\chi$$ is your density. If you do not use regression, but instead take the ratio then the answer is less clear. It depends upon the number of actors buying and selling, the rules in the auction, whether or not you are in equilibrium, the independence or dependence of errors, the terminal state of the asset, liquidity constraints, and other constraints in the system such as information asymmetry. For the logarithmic case, the distribution is the hyperbolic secant distribution in the simple case. As the hyperbolic secant distribution lacks anything resembling a covariance structure, you cannot have a CAPM or Fama-French style model. The easiest way to think about this is to consider the ratio case of $p_{t+1}/p_t$. Returns are not data; prices are data. Returns are the transformation of data. If prices have a random component then returns must follow a ratio distribution. In the Markowitz case, the distribution of the shock to prices must be normal. If you view this in the error space rather than price space so that in equilibrium errors are located at (0,0) and derive the distribution, the returns are the ratio of two independent, normal variates. This implies that returns follow a Cauchy distribution. For firms not merging out of existence or going bankrupt, this is very close to the empirical truth once you truncate the distribution at -100%. I argue the difference is from the intertemporal budget constraint, but that is to be argued by others later. EDIT The reason that conditional normality is assumed, even though the original GARCH paper states that stocks strongly violate the assumptions of GARCH, is that one way to get leptokurtic distributions is to assume a mixture of normals where the mean is moving around. The problem with this is that White's proof above shows that those models go to the Cauchy distribution as time becomes arbitrarily large. The perception is that if the field can remain inside normality in some manner, then it can use a math that is well understood. In a separate paper, I show that there does not exist a non-Bayesian estimator that is admissible and so that Frequentist decision theory is excluded. This excludes almost all of macroeconomics and financial economics. The short form of the argument goes like this: The distributions involved lack statistics sufficient for the parameter The Bayesian likelihood function is always minimally sufficient It follows that for purposes of projection, but not necessarily inference, that non-Bayesian methods will lose information and their sampling distributions will be noisier than is necessary. The Bayesian estimator will stochastically dominate the non-Bayesian estimator Standard tools such as Ito calculus or optimal control theory won't be available. It is very sensible to try to preserve normality because without a distribution that is at least in the exponential family, the tool loss will be fantastic. If you go back and read the initial papers following Markowitz, you will see that they were non-rigorous. The first paper by Markowitz is non-rigorous. This is problematic because no one notices this. A normal or normal-like distribution is essential for Markowitz to be valid. Because of this, a variety of tools have been developed on an ad hoc basis to try and preserve some form of normality so that a covariance matrix can be preserved. If a covariance matrix cannot exist, and it cannot exist, then so much vanishes. Diversification is no longer inherently prudent. There is no such thing as "systematic" risk versus "idiosyncratic" risk. While it may exist, no one knows what those phrases mean now. Based on my work on option pricing, idiosyncratic risk has to be priced. OLS, GLS, FGLS and so forth are useless. The list goes on. It is very reasonable to try and preserve some relationship either to normality or at least to the exponential family of distributions. I wont' work, but it does make sense.
