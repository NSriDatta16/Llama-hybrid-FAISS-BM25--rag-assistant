[site]: crossvalidated
[post_id]: 26251
[parent_id]: 13031
[tags]: 
I assume that you have $n$ time series, with no temporal dependencies, with enough data to compute the covariance of any pair of variables, but not enough data to compute the whole variance matrix. For instance, you could have 3 time series of daily values, A with values in 2009 and 2010, B with values in 2009 and 2011 and C with values in 2010 and 2011: to compute the variance matrix, you would have to remove 2011 (to include A), 2010 (to include B) and 2009 (to include C) -- there would be no data left. Some people just compute the matrix $C$ of pairwise correlations and, since it is not guaranteed to be positive semi-definite, try to fix it afterwards. For instance, one could diagonalize the matrix and set the negative eigenvalues to zero (or some small positive value). One could also shrink the matrix towards some positive definite matrix, e.g., find the smallest $\lambda$ so that $(1-\lambda)C + \lambda I$ be positive definite. It is possible to solve the problem rigorously, i.e., find the closest symmetric positive semi-definite matrix, for the $L^2$ norm, but it is more complicated: see this question . However, this assumes that there is enough overlap between your time series: if it is not the case, the EM approach mentionned by @Maverick1 should still work, provided the algorithm is implemented properly.
