[site]: crossvalidated
[post_id]: 7118
[parent_id]: 7112
[tags]: 
Although terminology is a contentious topic, I prefer to call "explanatory" variables, "predictor" variables. When to standardise the predictors: A lot of software for performing multiple linear regression will provide standardised coefficients which are equivalent to unstandardised coefficients where you manually standardise predictors and the response variable (of course, it sounds like you are talking about only standardising predictors). My opinion is that standardisation is a useful tool for making regression equations more meaningful. This is particularly true in cases where the metric of the variable lacks meaning to the person interpreting the regression equation (e.g., a psychological scale on an arbitrary metric). It can also be used to facilitate comparability of the relative importance of predictor variables (although other more sophisticated approaches exist for assessing relative importance; see my post for a discussion ). In cases where the metric does have meaning to the person interpreting the regression equation, unstandardised coefficients are often more informative. I also think that relying on standardised variables may take attention away from the fact that we have not thought about how to make the metric of a variable more meaningful to the reader. Andrew Gelman has a fair bit to say on the topic. See his page on standardisation for example and Gelman (2008, Stats Med, FREE PDF) in particular. Prediction based on standarisation: I would not use standardised regression coefficients for prediction. You can always convert standardised coefficients to unstandardised coefficients if you know the mean and standard deviation of the predictor variable in the original sample.
