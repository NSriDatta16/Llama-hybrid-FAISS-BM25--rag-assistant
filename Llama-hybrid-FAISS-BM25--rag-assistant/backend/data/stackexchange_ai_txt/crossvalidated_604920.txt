[site]: crossvalidated
[post_id]: 604920
[parent_id]: 604914
[tags]: 
Edited Post Before going any further, I should mention that you seem still unclear of what you want to do . Indeed, you have several questions in your post mobilizing very different concepts . I will try to address them as clear as possible, presenting different use case: Just to clarify one thing, power analysis refers to as simulation studies. In this case you want to assess whether your model is good to detect signal (rejecting the null hypothesis). Typically, we will simulate a large number of replicates, playing on different parameters. Traditionally, we like to play with beta parameters (the association level between variables and my outcome), number of variables, nature of variables, and number of individuals. It is worth noting that the number of replicates is different from your number of individuals. The former is independent of your model (it permits you to test the "asymptotic" performance of your model) while the latter directly depends on your model. In your context, "How many individuals I need to have a certain level of power?" for example . Here your power level is not specified a priori. However, when you want to have the "optimal" sample size, you must specify your target power. In practice we want power greater than 0.8 but it depends on your context. If I am correct you cannot use pwr package. It was developed only for linear models. Others packages can do power analyses for logistic regressions. Please be aware of the hypotheses (continuous predictors for example). Finally, here it depends on what you want to do. I provided a brief example to illustrate how to do power analysis with logistic regression exploiting the different notions you mentioned in your post. In my code I illustrated very simple applications of simulation studies, such as, power (how many I rejected the null association), bias calculation (How my estimates differs from my ground truth (true values)?) or model performance. For the latter you can use any metric you believe is relevant in your context. #Let's simulate data by ourselves #We simulated 1000 replicates and we want to assess power (Beta1 $coefficients[2,4] coefficients[2,1]) R2.vec = c(R2.vec, 1-(sm $deviance/sm$ null.deviance)) } #The power (here rejecting the null for beta 1 depends on the number of individuals) sum(power.vec)/n #The bias is reducing when increasing the number of individuals mean(abs(bias.vec)) #Mean pseudo R2 mean(R2.vec) #Sample size calculation library(WebPower) #p0 is probability of Y = 1 when X = 0: You should change this parameter #p1 is probability of Y=1 when X=1: You should change this parameter #alpha: your significance threshold #power is the target power #family: the nature of your predictor WebPower::wp.logistic(n=NULL, p0=0.10, p1=0.20, alpha=0.05, power=0.8, alternative = "two.sided", family="normal") To conclude you can play on every parameters, e.g., number of individuals, effect measure, number of predictors, type of predictors etc.... For sample size calculations, I added an example from: https://med.und.edu/research/daccota/_files/pdfs/berdc_resource_pdfs/sample_size_r_module.pdf . Reducing the target power for the same probabilities and the same significance threshold will lead to smaller needed sample sizes. I will let you play with this. Hope this helps.
