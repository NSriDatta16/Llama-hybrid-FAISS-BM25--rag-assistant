[site]: crossvalidated
[post_id]: 565213
[parent_id]: 
[tags]: 
Good performance on both training set and validation set, but poor performance on the test set

I'm building a CNN to classify the American Sing Language fingerprints. During training and validation it works very well, with accuracy going up to 95% and loss down to 10% on both. However, when it comes to the test set, even though the accuracy is still pretty good (80%) the loss is very high. I was wondering how could that be possible? Also, I tried to implement the same model with 20 epochs and 50 epochs, and on the test set they get the same exact accuracy and loss. train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, validation_split = 0.2) test_datagen = ImageDataGenerator(rescale = 1./255) training_generator = train_datagen.flow_from_directory( 'asl_alphabet_train', target_size=(64,64), batch_size = 10, color_mode = 'grayscale', class_mode = 'categorical') test_generator = test_datagen.flow_from_directory( 'asl_alphabet_test', target_size = (64,64), batch_size = 10, color_mode = 'grayscale', class_mode = 'categorical') validation_generator = train_datagen.flow_from_directory( 'asl_alphabet_train', target_size = (64,64), batch_size = 10, class_mode = 'categorical', color_mode = 'grayscale', subset = 'validation') #Found 87000 images belonging to 29 classes. #Found 116 images belonging to 29 classes. #Found 17400 images belonging to 29 classes. thirdExperiment = classifier.fit( training_generator, steps_per_epoch = training_generator.samples // 10, validation_data = validation_generator, validation_steps = validation_generator.samples // 10, shuffle = True, epochs = 20) I'd like to add that the structure of the directories 'asl_alphabet_test' and 'asl_alphabet_train' is the same. These are the accuracy and loss graphs: Then if I call test_loss, test_acc = classifier.evaluate(test_generator) I get: 4/4 [==============================] - 0s 27ms/step - loss: 4.7849 - accuracy: 0.8000 Do you guys have any idea why this is happening? edit: I should clarify that the dataset consists of around 30000 pictures for the training set and around 100 pictures for the test set. Could it be this huge dimension gap causing the problem?
