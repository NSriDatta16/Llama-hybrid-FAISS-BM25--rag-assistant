[site]: crossvalidated
[post_id]: 404679
[parent_id]: 
[tags]: 
How to standardize data with low variance?

I have quarterly data of federal fund rate (test set), e.g.: [2.18, 2.18, 2.18, 2.18, 2.18, 2.18, 2.18, 2.18, 2.18, 2.18, 2.18, 2.18, 2.19, 2.19, 2.19, 2.19, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 2.19, 2.2, 2.2, 2.2, 2.2, 2.19, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 2.2, 2.19, 2.2, 2.2, 2.19, 2.2, 2.19, 2.19, 2.19, 2.19, 2.2, 2.2, 2.2, 2.4, 2.4, 2.4] Train data description is: Mean: 1.003916 Variance: 0.203896 Std: 0.4514 I want to use this data as an input feature for the LSTM model. For this, I apply standardization, as follows: I am forced to use training data mean and variance, since I need to avoid look ahead bias at dev and test sets. However, after applying it turns out that the data standardizes to even larger values. This can't be used as an input to neural network, since it causes some features to be more weighted than others. Moreover, rest of features are within -1, 1 range. I have also tried using Min-Max normalization, but in this case NN does not converge on some data points. What should I do in this case?
