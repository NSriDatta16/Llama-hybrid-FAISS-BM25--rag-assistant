[site]: crossvalidated
[post_id]: 253048
[parent_id]: 252965
[tags]: 
(This is out of my area of expertise, so the answer by Jeremy Miles may be more reliable.) Here is one idea. First, imagine there is no confidence level. Then for each patient $i=1\ldots{N}$, they either have cancer or not $c_i\in\{0,1\}$, and each doctor $j=1\ldots{m}$ either diagnosed them with cancer or not, $d_{ij}\in\{0,1\}$. A simple approach is to assume that, while the doctors may agree or disagree on a given patient's diagnosis, if we know the patient's true status, then each doctor's diagnosis can be treated as independent. That is, the $d_{ij}$ are conditionally independent given $c_i$. This results in a well defined classifier known as Naive Bayes , with parameters that are easy to estimate. In particular, the primary parameters are the base rate, $p[c]\approx\tfrac{1}{N}\sum_ic_i$, and the conditional diagnosis likelihoods $$p\big[d_j|c\big]\approx\frac{\sum_id_{ij}c_i}{\sum_ic_i}$$ Note that this latter parameter is a weighted average of the diagnoses for doctor $j$, where the weights are the true patient conditions $c_i$. Now if this model is reasonable, then one way to incorporate the confidence levels is to adjust the weights. Then the conditional likelihoods would become $$p\big[d_j|c,w_j\big]\approx\frac{\sum_id_{ij}w_{ij}c_i}{\sum_iw_{ij}c_i}$$ Here $w_{ij}\geq{0}$ is a weight that accounts for the confidence level of $d_{ij}$. Note that if your weights are cast as probabilities $w\in[0,1]$, then you can use the " Bernoulli shortcut" formula $$p\big[d\mid{w}\big]=d^w(1-d)^{1-w}$$ to account for the $d=0$ case appropriately. Note: This requires that your software give 0^0=1 rather than 0^0=NaN , which is common but worth checking! Alternatively you can ensure $w\in(0,1)$, e.g. if confidence is $k\in\{1\ldots{K}\}$ then $w=k/(K+1)$ would work.
