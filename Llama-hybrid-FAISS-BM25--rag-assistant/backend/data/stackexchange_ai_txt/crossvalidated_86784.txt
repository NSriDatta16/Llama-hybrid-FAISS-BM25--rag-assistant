[site]: crossvalidated
[post_id]: 86784
[parent_id]: 86769
[tags]: 
As often, writing down the different models is clearer than talking about them. If your model is $$\operatorname{E} Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_{12} \left(x_1x_2\right)$$ & you decide to centre & scale some predictors using constants $a,b,c,d$ (which can be means, standard deviations of the predictors, or whatever), the new model is $$\operatorname{E} Y = \beta_0^* + \beta_1^* (x_1 -a) + \beta_2^* (x_2-b) + \beta_{12}^* \frac{x_1x_2 - c}{d}\\ =\beta_0^* -a\beta_1^*-b\beta_2^*-\frac{c\beta_{12}^*}{d}+\beta_1^*x_1 + \beta_2^* (x_2-b) + \frac{\beta_{12}^*}{d} (x_1x_2)$$ But this is just a reëxpression of the old model, with: $$\beta_0=\beta_0^* -a\beta_1^*-b\beta_2^*-\frac{c\beta_{12}^*}{d}\\ \beta_1=\beta_1^*\\ \beta_2=\beta_2^*\\ \beta_{12}=\frac{\beta_{12}^*}{d}\\ $$ The predictions & prediction intervals are exactly the same; you've just changed the units the predictors & coefficients are measured in. On the other hand $$\operatorname{E} Y = \beta_0' + \beta_1' (x_1 -a) + \beta_2' (x_2-b) + \beta_{12}' \left(\frac{x_1x_2 - c}{d}\right)^2$$ is a brand new model with an $(x_1x_2)^2$ term where before you had only $x_1x_2$. It will make different predictions; moreover, as @Peter pointed out, those predictions will depend on the units the predictors are measured in—e.g. Celsius vs Fahrenheit—if you don't include the lower-level terms as well, so you'd better be sure you really want that. The form of the interaction is unusual: when $x_2=0$, the response is linearly related to $x_1$; as $x_2$ increases in absolute magnitude the relation becomes a tighter parabola, with a maximum or minimum depending on the sign of $\beta'_{12}$—it's hard to imagine this is what you had in mind. It's sometimes said such models violate the marginality principle : see Venables (1998), "Exegeses on linear models", S-Plus Users' Conference, Washington DC . Collinearity is a red herring here—it's not a problem when it's a matter of how the predictors are defined (sometimes called structural collinearity) because you're never going to have to predict responses for predictor patterns that aren't exhibiting exactly the same collinearity. NB You hear different views about centring & scaling predictors, discussion of which often drags in collinearity. It's important to realize that these concern ease of interpretation only (or occasionally accuracy of calculation—not an issue with algorithms used by modern software, as @Frank said).
