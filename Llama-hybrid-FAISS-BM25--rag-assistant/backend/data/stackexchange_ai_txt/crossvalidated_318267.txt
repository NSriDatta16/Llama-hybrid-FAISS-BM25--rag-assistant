[site]: crossvalidated
[post_id]: 318267
[parent_id]: 
[tags]: 
Training in one step vs multiple steps

I'm about 5 minutes in to learning about machine learning (using the Tensorflow MNIST tutorial) and have already managed to confuse myself. No big surprise there. But Google isn't giving me any good answers, so I was hoping someone here could. Why does training this example model in multiple smaller batches produce such better results than training the model in one batch? And if thats always going to be the case, is there a rule of thumb for training batch size and number of batches? It appeared that in the example 1000 and 100 were just chosen arbitrarily. For example, here is the tutorial file. I replaced: # Train for _ in range(1000): batch_xs, batch_ys = mnist.train.next_batch(100) sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys}) With a single training step on the whole data: sess.run(train_step, feed_dict={x: mnist.test.images, y_: mnist.test.labels})) And the accuracy dropped from 0.91 to 0.66.
