[site]: datascience
[post_id]: 43933
[parent_id]: 
[tags]: 
Why some ML models can't take advantage of text ordering information?

On this google tutorial ( https://developers.google.com/machine-learning/guides/text-classification/step-4 ) it is said: > Build n-gram model [Option A] We refer to models that process the tokens independently (not taking into account word order) as n-gram models. Simple multi-layer perceptrons (including logistic regression), gradient boosting machines and support vector machines models all fall under this category; they cannot leverage any information about text ordering. > Then > Build sequence model [Option B] We refer to models that can learn from the adjacency of tokens as sequence models. This includes CNN and RNN classes of models. Data is pre-processed as sequence vectors for these models > Why some ML model (Simple multi-layer perceptrons, gradient boosting machines and support vector machines models) cannot leverage any information about text ordering? Is it because they can't accept floats on their input? (Not sure if those ML models accept floats on their input. I am guessing they can't.)
