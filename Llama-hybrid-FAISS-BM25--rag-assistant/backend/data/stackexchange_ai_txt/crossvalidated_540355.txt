[site]: crossvalidated
[post_id]: 540355
[parent_id]: 
[tags]: 
RandomForest with VST data

I used the randomForest() function in R for bagging without a training data set to identify the important features characterizing the members of groups A and B (binary testing). I get the following output from a scaled dataset: Type of random forest: classification Number of trees: 80 No. of variables tried at each split: 11 OOB estimate of error rate: 14.94% Confusion matrix: A B class.error A 35 6 0.14 B 7 39 0.15 If I repeat the random forest analysis with the exact same data frame but variance-stabilised transformed (VST) data, I get: Type of random forest: classification Number of trees: 80 No. of variables tried at each split: 11 OOB estimate of error rate: 0% Confusion matrix: A B class.error A 41 0 0 B 0 46 0 I know that in either case, bagging is resulting in very optimistic outcomes. However, why is the VST run so different from the version above where I did also not have highly skewed data? Also, if I look directly into the votes of the VST random forest run and set all the values set to one as "yes", I get a predicted probability of 0.85. How can this be explained in consideration of an OOB estimate of error rate of 0 %? I mean 0.97 is quite close to 1. What would be a better cut-off value? > rf$votes A B Group Yes_NO 01 1.0000000 0.00000000 A Yes 02 1.0000000 0.00000000 A Yes 03 1.0000000 0.00000000 A Yes 04 1.0000000 0.00000000 A Yes 05 0.9677419 0.03225806 A No 06 0.9600000 0.04000000 A No 07 1.0000000 0.00000000 A Yes 08 0.9310345 0.06896552 A No 09 1.0000000 0.00000000 A Yes 10 1.0000000 0.00000000 A Yes ... > table(rf $votes$ Yes_NO) No Yes 6 35 > 35/41 [1] 0.8536585
