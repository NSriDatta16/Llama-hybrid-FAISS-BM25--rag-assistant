[site]: crossvalidated
[post_id]: 225338
[parent_id]: 225163
[tags]: 
The basic question is pretty much covered already, so I won't belabour that beyond a brief mention -- but I have some additional comments. Briefly, then, we see that significance is based on looking at the distribution of test statistics when the null is true. So in this situation you can use the standard error under the null (i.e. you can use $p_0$ in the standard error), and then you can directly use the normal approximation to the (scaled) binomial numerator to derive an asymptotically normal test. This should be fully efficient as $n\to\infty$. On the other hand, it would also be sensible (and valid) to replace the standard error computed under the null by some asymptotically efficient estimate, such as the MLE -- as long as we can (i) compute an approximate distribution for this statistic under the null, and (ii) as long as the properties of the resulting test are reasonable. One (small) advantage is that it would then make the hypothesis test consistent with the large-sample confidence interval (the decision rule in the hypothesis test at level $\alpha$ would correspond to whether or not the null value was in a confidence interval of coverage $1-\alpha$. The issue then is one of how to deal with this test statistic. It should be asymptotically normal via Slutsky's theorem and the CLT. In small samples the exact distribution under the null can be obtained from the binomial itself. Using such a statistic is recommended in some texts. Often those texts recommend using a t-approximation for this statistic, and examining the behaviour in small samples this seems as if it may perform quite well.
