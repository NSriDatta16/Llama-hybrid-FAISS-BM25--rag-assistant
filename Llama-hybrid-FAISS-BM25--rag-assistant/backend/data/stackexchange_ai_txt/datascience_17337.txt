[site]: datascience
[post_id]: 17337
[parent_id]: 17321
[tags]: 
I'm not sure what you already know, so I'll answer how I'd do it. If you do not understand things, or already know some things I say, please leave a comment. I would tackle it as a multi-class problem if your output is categorical, hence indeed only $10\%$, $25\%$ and so on. If you want to treat it as a regression problem, I'd say you need continuous deltas of popularity, so you need all kinds of values as the delta, and not only a fixed number of them. The training data should dictate how you approach the problem. Note that you can always reduce the regression to a multi-class problem (which asks for an instance which of the deltas it should assign) by bucketing to intervals. For argument's sake let's assume you have multi-class data. One document has one of the classes, i.e. $10\%$. You then go ahead and encode these classes into a binary vector, which probably even is a part of the library you're using. You'd then go ahead and split your data with the hold-out method to have some vlalidation examples set aside to see how your model actually works. You then go ahead and train some model, say a random forest. With the validation data you calculate some measure of error and see if it is enough. If not you go ahead and choose other models to train, other features to add and so on. I'd suggest to try use another approach than bag-of-words such as word2vec or GloVe. You can also add the sentiment classifiers values as feature columns. You could then compare the different features and see how it performs. Let me know if this helps you or if I misunderstood your question.
