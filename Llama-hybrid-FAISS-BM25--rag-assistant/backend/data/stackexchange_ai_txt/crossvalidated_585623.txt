[site]: crossvalidated
[post_id]: 585623
[parent_id]: 352036
[tags]: 
Curriculum Learning Curriculum learning is a formalization of @h22's answer . The essential idea of curriculum learning is best described in the abstract of the previously linked paper by Bengio et al.: Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them “curriculum learning”. In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions). One way for implementing curriculum learning is to rank the training examples by difficulty. Of course, this can be cumbersome. Instead, several authors have proposed easier methods, such as Curriculum by Smoothing , where the output of each convolutional layer in a convolutional neural network (CNN) is smoothed using a Gaussian kernel. Make sure that each part of the net can be trained A standard neural network is composed of layers. Before checking that the entire neural network can overfit on a training example, as the other answers suggest, it would be a good idea to first check that each layer, or group of layers, can overfit on specific targets. For example, let $\alpha(\cdot)$ represent an arbitrary activation function, such that $f(\mathbf x) = \alpha(\mathbf W \mathbf x + \mathbf b)$ represents a classic fully-connected layer, where $\mathbf x \in \mathbb R^d$ and $\mathbf W \in \mathbb R^{k \times d}$ . Before combining $f(\mathbf x)$ with several other layers, generate a random target vector $\mathbf y \in \mathbb R^k$ . Then, let $\ell (\mathbf x,\mathbf y) = (f(\mathbf x) - \mathbf y)^2$ be a loss function. Try to adjust the parameters $\mathbf W$ and $\mathbf b$ to minimize this loss function. If the loss decreases consistently, then this check has passed. Alternatively, rather than generating a random target as we did above with $\mathbf y$ , we could work backwards from the actual loss function to be used in training the entire neural network to determine a more realistic target. As a simple example, suppose that we are classifying images, and that we expect the output to be the $k$ -dimensional vector $\mathbf y = \begin{bmatrix}1 & 0 & 0 & \cdots & 0\end{bmatrix}$ . Suppose that the softmax operation was not applied to obtain $\mathbf y$ (as is normally done), and suppose instead that some other operation, called $\delta(\cdot)$ , that is also monotonically increasing in the inputs, was applied instead. If we do not trust that $\delta(\cdot)$ is working as expected, then since we know that it is monotonically increasing in the inputs, then we can work backwards and deduce that the input must have been a $k$ -dimensional vector where the maximum element occurs at the first element. We can then generate a similar target to aim for, rather than a random one.
