[site]: crossvalidated
[post_id]: 258024
[parent_id]: 
[tags]: 
Why does the jackknife-after-bootstrap estimation of variance give an overestimate?

The jackknife-after-bootstrap method is used to find the an error estimate (for example variance) to a bootstrap estimate. A typical setting is: (1) From a sample of a population, find an estimate $\hat{\theta}$ of the mean\median\something else. (2) Use the bootstrap method to find an estimate $\hat{e}_B(\hat{\theta})$ of the standard error\confidence interval\etc of $\hat{\theta}$. (3) Use jackknife-after-bootstrap to find an estimate $\hat{e}_{JK}(\hat{e}_B)$ of the variance\confidence interval\etc of $\hat{e}_B$. My (little) experience with jackknife-after-bootstrap shows that when we try to estimate the variance of $\hat{e}_B$, the estimation seems to be a biassed estimate of the true variance of $\hat{e}_B$, and the bias seems to be positive, which means that we overestimate the variance. Questions: Why does jackknife-after-bootstrap give an overestimation of the variance? Is there an easy way to fix the jackknife-after-bootstrap estimation to reduce the bias (in absolute value)? Edit1: I realized that what I was referring to here as "jackknife-after-bootstrap" is in fact not the straight-forward application of jackknife for bootstrap, but rather a method with reduced computational cost, described in [1], where instead of taking $n$ jackknife samples and for each performing a new bootstrap estimate, and aggregating the results over all $n$ jackknife samples, we take $n$ jackknife samples and for each one of them use the already-existing bootstrap samples (drawing from them only the ones that could have been sampled by for this jackknife sample). Experimenting with both methods seems to suggest to me that both give an overestimate. I'm interested in answers for my questions relating to both methods please. [1] Efron, Bradley, and Robert J. Tibshirani. An introduction to the bootstrap . CRC press, 1994.Chapter 19.
