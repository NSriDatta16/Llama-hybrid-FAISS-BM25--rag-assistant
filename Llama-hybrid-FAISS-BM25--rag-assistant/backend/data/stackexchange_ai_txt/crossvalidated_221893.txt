[site]: crossvalidated
[post_id]: 221893
[parent_id]: 221771
[tags]: 
Your question is pretty broad - I'll assume you are focusing on predictive modelling and try to give a short top-level overview to point you towards those "buzzwords" that you can use to look up anything unclear: Over the years, many different model types have been researched/created that can be used for predictive modelling. Though some of them work very different they sometimes give results astonishing close to each other. So you might often solve the same problem using different models and even obtain relatively similar results from them. Artificial neural networks (ANN) are one of those models: it might solve your problem, but you might solve the same problem using different models as well. There is not "one superior model" for all our problems ( no free lunch theorem ). A subset of those model types can be used on time series / sequence prediction directly. Note that using feature (pre)processing and derivation, technically all models could be used on time series - but the required feature transformation tends to be very specific to each problem for this. Models that ended up frequently being used with sequence prediction are e.g. Hidden Markov Models (HMM) and Recurrent Neural Networks (RNN). Note that many different forms exist of both, especially when including new findings from deep learning, like the long-short-term-memory (LSTM) model and related models. Most such models are created and tuned for a specific purpose, like one specific prediction in the financial sector - so this is a bit different from what tensorflow currently offers. But you might as well use another model altogether for the same task: there is no direct need for using an ANN/RNN/tensorflow, but it could happen that using an RNN in the end turns out to perform better than other model types on this task (referring to the success of those in such tasks in the past years, and assuming that one has the calculation power and coding capabilities, as most RNN packages/implementations are not yet off-the-shelf-ready-to-use when it comes to the details). So, if a company like Google - which is a pretty big player in deep learning and RNNs with DeepMind and their last papers - creates some well performing model for a highly sophisticated sequence prediction task, there is a high chance of them using something non-standard altogether (far beyond tensorflow), which requires quite some time to create and compute, and which combines non-RNN and RNN models/model aspects to achieve the goal. But in the end, there is no definition that such have to be used, it's likely just because they are currently able to get best results using this construct, but that might change again over time. If you are interested in the details, try searching and reading into the corresponding papers: Google usually discloses quite some information about which research concepts are behind their latest success in such tasks.
