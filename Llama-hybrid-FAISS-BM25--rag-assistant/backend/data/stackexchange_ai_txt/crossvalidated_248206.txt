[site]: crossvalidated
[post_id]: 248206
[parent_id]: 
[tags]: 
Fit a V-curve into a model

I have data which consists of number of impressions for an advertisement, position of ad in the break and total number of ads in a break . Typically, if the channels are not synchronized, people switch to other channels during break and watch the program in that channel. So if I plot Impressions vs position of ad in the break , I get a v-curve with a steep fall and slow rise. That is because, as soon as the break starts, people switch to other channels and slowly come back to the channel after some time to catchup. However, this also depends on the total ads in the break since viewership of ad in position 10 is not the same for total number of ads being 11 and total number of ads being 30. So, the impressions definitely depend on both position as well as total number of ads . I need to model this V-curve (rather a tick mark kind of curve) to predict ad viewership. I am extremely new to data science and would greatly appreciate some pointers. NOTE: I looked at linear modelling but I got a 0.03 R-squared value which I believe is very bad. I am thinking getting 2 linear models for the fall part and rise parts of the V and combining them will be a good thing to do. But I am not sure how I can do it.
