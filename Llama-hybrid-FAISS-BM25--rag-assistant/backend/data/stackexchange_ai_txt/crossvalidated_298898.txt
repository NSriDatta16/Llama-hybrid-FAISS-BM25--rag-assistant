[site]: crossvalidated
[post_id]: 298898
[parent_id]: 
[tags]: 
Saturated function

I have come across the term "saturation" in the context of neural networks and I can't find a straightforward definition for it. for instance: Because linear units do not saturate, they pose little difficulty for gradient- based optimization algorithms Does someone have a good definition for "saturation"?
