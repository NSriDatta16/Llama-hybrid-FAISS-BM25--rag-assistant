[site]: crossvalidated
[post_id]: 431885
[parent_id]: 
[tags]: 
How to compare two PCAs

I am working on a deep learning research and came across the following problem: I have a network (let's call it A ) that performs a certain task with X% performance, and another (say B ) with Y% (where X >> Y ). So A performs significantly better. There is only one little difference between these two architectures but a huge performance improvement in return. I would like to compare why they perform differently. So, I compared the weights of CNN layers, etc. After reshaping the first layer, it became (25*32) size. I got the PCA of this layer for both A and B and compared them. Below is the PCA plot of A (good performing network) using imshow. So the values are the magnitudes of the output of PCA function. For example, the first column in the figure is the first eigenvector. whereas the same of the second network, B , is as follows: Then I got 10 eigenvectors of each network and normalized their variances with respect to the 10th. The resulting plot is as follows: (i.e., vars = variance of each ev , vars = vars/vars[-1] ) From these results, I can infer that only 2-3 eigenvectors are enough to represent A whereas more components needed for B . red , green and blue are the A which perform well and the others magenta and cyan are B . (I ran A 3 times, and B 2 times) So, my question is how should I interpret these results? I mean why would a filter needing only a few eigenvectors would work better than the one requiring more.
