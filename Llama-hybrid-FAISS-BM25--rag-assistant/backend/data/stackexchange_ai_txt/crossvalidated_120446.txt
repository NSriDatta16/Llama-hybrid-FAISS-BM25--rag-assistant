[site]: crossvalidated
[post_id]: 120446
[parent_id]: 
[tags]: 
Different results from several "passes" of Random Forest on same dataset

I've been playing around with the German Credit dataset available in Kuhn & Johnson's caret package for R . First, I build a very simple model (I'm not using CV to simplify the code; this is taken from their examples in the AppliedPredictiveModeling package): library(caret) library(randomForest) data(GermanCredit) GermanCredit Now, if I predict the outcome Class on the test set, and do this several times: credit.pred1 and compare the predictions: credit.pred1 == credit.pred2 credit.pred2 == credit.pred3 credit.pred1 == credit.pred3 I see that the same model, on the same dataset, makes slightly different decisions. Why is this? I understand this is normal when building a model using cross-validation (or not, as we unfortunately see all too often), but I thought that when a model was built, it would be making the exact same decisions on a certain test set every time you run it? EDIT: I tried again as asked, and still have the same problem. Here's the output from sessionInfo() : R version 3.1.1 (2014-07-10) Platform: x86_64-w64-mingw32/x64 (64-bit) locale: [1] LC_COLLATE=English_United States.1252 LC_CTYPE=English_United States.1252 LC_MONETARY=English_United States.1252 [4] LC_NUMERIC=C LC_TIME=English_United States.1252 attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] randomForest_4.6-10 pmml_1.2.30 XML_3.98-1.1 caret_6.0-35 ggplot2_1.0.0 lattice_0.20-29 loaded via a namespace (and not attached): [1] BradleyTerry2_1.0-5 brglm_0.5-9 car_2.0-21 codetools_0.2-8 colorspace_1.2-4 digest_0.6.4 [7] foreach_1.4.2 grid_3.1.1 gtable_0.1.2 gtools_3.4.1 iterators_1.0.7 lme4_1.1-7 [13] MASS_7.3-33 Matrix_1.1-4 minqa_1.2.4 munsell_0.4.2 nlme_3.1-117 nloptr_1.0.4 [19] nnet_7.3-8 plyr_1.8.1 proto_0.3-10 Rcpp_0.11.3 reshape2_1.4 scales_0.2.4 [25] splines_3.1.1 stringr_0.6.2 tools_3.1.1 EDIT 2: This is unbelievable. When I copy the code I posted on CrossValidated for the website, the model produces the same results. But when I copy the code from my code editor (Sublime Text 2.0.2 with the Enhanced-R plugin) into RStudio, I run into the same problem I've described! Here's the address to the Gist I created, it reproduces the problem: https://gist.github.com/anonymous/32b3c8194362d2e10527
