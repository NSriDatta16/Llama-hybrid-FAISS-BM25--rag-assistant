[site]: crossvalidated
[post_id]: 177030
[parent_id]: 176840
[tags]: 
You will have a 'burn-in' period for the first time points before t1 , when you generate descriptors' looking t1 time backwards. Also if you forecast interval is t2 , you will have a 'burn-out' period t2 of the the last time points. To build a fair RF model you will probably need 150-5000 samples depending on how difficult the task is. Then burning some few time points in either end does not matter much. If your model only has ~30 time points, strongly consider other forecasting priciples: linear regression, auto-regresion, ARIMA etc. I don't think your future prediction performance will improve by imputing NAs. Bonus advice: If your time series is not stationary, consider computing the first derivative (change/time) and model this instead. Otherwise your model will end up forecasting the next value as something very close to the last value. Such predictions are trivial and often useless. disclaimer : I'm only a "time series hobbyist" :)
