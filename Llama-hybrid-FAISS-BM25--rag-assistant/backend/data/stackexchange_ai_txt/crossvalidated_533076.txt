[site]: crossvalidated
[post_id]: 533076
[parent_id]: 532988
[tags]: 
If you are open to a Bayesian approach and willing to specify at least weakly informative proper prior distributions for the model parameters, then using the brms R package should make this relatively straightforward. This is basically a logistic regression - I assume this is what you meant by a logit-model, if you are modeling logit-transformed probabilities that you observe instead of Bernoulli trials, not much changes below except that you'd e.g. use beta-regression - with a non-linear function of the predictors, which is a feature that package implements easily . Taking a Bayesian approach also helps with over-parameterized models: if you specify not-too-weak priors, these will to some extent resolve issues with model parameters being not identified or only poorly identified. Something along the lines below should let you fit this model with a bit of experimentation. I've put in some placeholder prior distributions, but I have no idea whether those make any sense in your context (who knows, maybe some model parameters should even have joint priors). library(brms) brmfit1 = brm( family="bernoulli", bf( y ~ alpha + beta * ( q0 * d^(t-1) + ... ) / ( d^(t-1) + d^(t-2) + ... + 1 ), nl = TRUE, alpha ~ 1, beta ~ 1, q0 ~ 1, d ~ 1), # assumes the t and x_it are observed covariates prior=c(prior(normal(0,1), nlpar="alpha"), prior(normal(0,1), nlpar="beta"), prior(normal(0,1), nlpar="q0"), prior(lognormal(0,1), nlpar="d")), control=list(adapt_delta=0.99)) prior_summary(brmfit1 summary(brmfit1) stancode(brmfit1) # if you want to see the Stan code generated by brms, that way you could modify it yourself and then use it with rstan
