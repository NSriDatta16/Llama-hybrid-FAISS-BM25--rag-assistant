[site]: crossvalidated
[post_id]: 229156
[parent_id]: 229154
[tags]: 
The Accuracy (or the area under the ROC curve) depends on the sample used to construct the ROC curve (see, e.g., How to interpret 95% confidence interval for Area Under Curve of ROC? ). So if you use this ROC to optimise the threshold there is a risk of overfitting to the sample. You can indeed "calibrate" a threshold using a hold-out data set. You might also use k-fold cross validation. The link with the ROC-curve is the fact that that there exists a link between the area under the ROC-curve and the accuracy ratio ( $AR=2AUC-1$ ). The Area under the ROC (AUROC or AUC) is linked to the accuracy ratio. The area under the curve can be interpreted as follows: of all possible pairs with one subject of class 1 and one subject of class 2, there is a fraction equal to AUC for which the subject in class 1 will have a better score. This interpretation is the same when you use a random forest. You can find more on all this in, e.g., this paper
