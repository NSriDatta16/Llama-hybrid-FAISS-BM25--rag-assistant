[site]: crossvalidated
[post_id]: 179394
[parent_id]: 
[tags]: 
Fitting an analytic distribution

I am performing a Bayesian model comparison and attempting to ensure that the priors for the two models are "fair". Unfortunately there is no direct one-to-one mapping between the model parameters for the two models. However there does exist a analytic relation. For example, if model $A$ has a parameter $W$, then I can relate it to a parameter $\rho$ in model $B$ via: $$ \rho = \frac{\chi}{\upsilon} W + \theta $$ where $\chi$, $\upsilon$ and $\theta$ are also random variables of model $B$ (which have a fixed prior). Now I specify a prior for $W$, then want to choose the corresponding prior for $\rho$ (so that neither model is favoured by the prior). To do this I have used monte-carlo method to simulate the $\rho$ distribution by drawing from the (known) priors on the right-hand-side. The exact expression is a bit more complicated than the one I have provided, but this contains all the essential features (addition of rvs, and product/division). This occurs for two different parameters and I get the following plots: I have fitted these with a Cauchy distribution as the ratio of the two rvs appears to dominate (the blue line). However, as you can see this fit is not perfect. So what I would really like to know is: is there any other distributions I should try and fit (I have tried normal and laplace). Or better yet, is there some mechanism to fit many different ones and determine which fits best? Also, are the fits in these plots bad or good? The reason I want an analytic approximation, is that I use pass these to an MCMC procedure which draws from them. In theory I suppose I could use a KDE, or just pass the samples? But I am unsure if this is practical, so the easiest thing for now is just to get an analytic fit.
