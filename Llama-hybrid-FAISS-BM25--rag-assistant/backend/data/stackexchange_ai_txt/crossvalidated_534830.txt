[site]: crossvalidated
[post_id]: 534830
[parent_id]: 
[tags]: 
hyperparameter search with unknown test set distribution

I'm training a 3-class neural network classifier (conv layers and softmax at the end, nothing special). Let's say, in the test set I will have N1 examples of the 1st class, N2 examples of the 2nd class and N3 examples of the 3rd class. The train set is balanced but the true test set proportion N1:N2:N3 is unknown as the test set is still being prepared by another group. The metric I'm interested in is the f1-score for the 1st class. If I find a set of hyperparameters that optimizes this metric for class proportions 1:1:1, will it also be the optimal set for any N1:N2:N3? I guess this holds for binary classification as maximizing f1-score over the hyperparameter search space also maximizes precision and recall. This becomes clear when we take the derivative of the f1-score w.r.t. the optimized parameters: it's zero when both precision P and recall R derivatives are also zero (P'=R'=0)(or in another case when R'P^2+P'R^2=0, but it looks unlikely to satisfy). So, for a given PRC threshold, the maximum of f1-score coincides with precision maximum and recall maximum as a function of model parameters. Though the optimal PRC threshold is dataset-dependent... But what about multiclass classification, when we have different class cross-contamination and classes 2 and 3 will contribute differently to false positives for class 1 as the proportion N2:N3 will change?
