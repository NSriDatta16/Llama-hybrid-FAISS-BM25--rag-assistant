[site]: crossvalidated
[post_id]: 368133
[parent_id]: 
[tags]: 
Reinforcement Learning: definition of expected discounted return in Sutton and Barto's book

I am going through Sutton and Barto's book on reinforcement learning http://incompleteideas.net/book/bookdraft2017nov5.pdf In the book pg 44 equation 3.8, the authors define expected discounted return as $G_t = R_{t+1} + \gamma R_{t+2} + \ldots$ Why is it called "expected" return? Does it have anything to do with expectation? i.e., can I rewrite $G_t$ in terms of expectation? Is $R_{t+1}$ a random variable? (the authors defined on page 38, top of the page near the diagram, that $R_{t+1}$ is a real number, but a random variable is a function, no?) Why does the expected discounted return start with $t+1$ ? In my opinion, this causes a problem later on when the authors define the optimal Q value in terms of the "Bellman optimality equation", pg 51, equation 3.20 $q^\star(s,a) = \mathbb{E}[R_{t+1} + r \max_{a^\prime} q^\star(S_{t+1}, a^\prime)| S_t = s, A_t = a]$ The optimal q value should have the intuitive definition as the reward at the CURRENT time step $t$ plus the optimal expected discounted reward. So that $R_{t+1}$ should be re-written as $R_{t}$ should it not?
