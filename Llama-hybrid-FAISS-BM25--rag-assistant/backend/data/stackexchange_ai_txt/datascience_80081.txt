[site]: datascience
[post_id]: 80081
[parent_id]: 
[tags]: 
Can Shapley/Lime values be used for unsupervised learning?

One thing that is really useful when trying to understand what a machine learning model does, is seeing why some instances got predicted. For that Shapley Values and Lime are really usefull. But can they be used with unsupervised learning? Let's say we are doing anomaly detection with tabular data and we run some algorithm like Isolation Forest (or any other). Is it conceptually right to use Shapley or Lime to try to give a local explanation of the results when using unsupervised learning?
