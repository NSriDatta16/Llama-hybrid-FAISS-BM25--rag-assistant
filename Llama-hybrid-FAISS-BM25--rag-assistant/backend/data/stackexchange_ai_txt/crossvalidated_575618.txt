[site]: crossvalidated
[post_id]: 575618
[parent_id]: 575549
[tags]: 
The task of having a machine learning algorithm learn how to label unlabeled images is an active area of research. I happen to have two examples handy, but there's a number of alternative approaches. The citations in this paper will provide other approaches. Here's an example of a recent paper; this might be overkill for what is essentially an unsupervised OCR task. " Self-labeling via simultaneous clustering and representation learning " by Yuki M. Asano Christian Rupprecht Andrea Vedaldi (2020). Combining clustering and representation learning is one of the most promising approaches for unsupervised learning of deep neural networks. However, doing so naively leads to ill posed learning problems with degenerate solutions. In this paper, we propose a novel and principled learning formulation that addresses these issues. The method is obtained by maximizing the information between labels and input data indices. We show that this criterion extends standard cross-entropy minimization to an optimal transport problem, which we solve efficiently for millions of input images and thousands of labels using a fast variant of the Sinkhorn-Knopp algorithm. The resulting method is able to self-label visual data so as to train highly competitive image representations without manual labels. Our method achieves state of the art representation learning performance for AlexNet and ResNet-50 on SVHN, CIFAR-10, CIFAR-100 and ImageNet and yields the first self-supervised AlexNet that outperforms the supervised Pascal VOC detection baseline. Code and models are available. Piotr Bojanowski, Armand Joulin. " Unsupervised Learning by Predicting Noise " Proceedings of the 34th International Conference on Machine Learning, PMLR 70:517-526, 2017. Convolutional neural networks provide visual features that perform remarkably well in many computer vision applications. However, training these networks requires significant amounts of supervision; this paper introduces a generic framework to train such networks, end-to-end, with no supervision. We propose to fix a set of target representations, called Noise As Targets (NAT), and to constrain the deep features to align to them. This domain agnostic approach avoids the standard unsupervised learning issues of trivial solutions and collapsing of the features. Thanks to a stochastic batch reassignment strategy and a separable square loss function, it scales to millions of images. The proposed approach produces representations that perform on par with the state-of-the-arts among unsupervised methods on ImageNet and Pascal VOC. The common thread in these papers is that the task is composed of a convolutional neural network (because these tend to be a good choice for image tasks) and an unsupervised optimization procedure to group the feature vectors to a latent class.
