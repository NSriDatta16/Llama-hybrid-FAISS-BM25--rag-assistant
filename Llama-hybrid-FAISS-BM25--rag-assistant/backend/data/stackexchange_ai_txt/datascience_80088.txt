[site]: datascience
[post_id]: 80088
[parent_id]: 65311
[tags]: 
While all the answers here are on point, I'd like to add a new perspective to this. You can view common data augmentation techniques as rounding out your data's distribution curve. That is to say - if some feature of your data set should look like a gaussian curve, but does not just yet, data augmentation techniques would help increase the data samples and the variance to shape the curve towards its ideal, naturally occurring, or statistically expected form. So your starting point is more data samples, and you end at a better-looking more-desirable (based on your application) distribution curve. Generative Adversarial Networks, on the other hand, start at the distribution curve that you already have and generate data samples that are in line with (or agree to) the already established distribution curve. Similar to a random number generator with a predefined distribution to conform by - uniform, gaussian, Raleigh etc. So here is a general guideline (not always applicable) that you could use to frame this discussion. Use data augmentation techniques when you do not see the expected statistical properties within your data. This could be due to a lack of variance and/or a shortage of data. Traditional data augmentation techniques might be what you need. Once you have the ideal (or closest to ideal) distribution within your data, OR you know what the ideal distribution of your data should be, use GANs to synthetically generate more data for semi-supervised learning, further training and improving model generalization and robustness. For more information on data augmentation, check out our blog here .
