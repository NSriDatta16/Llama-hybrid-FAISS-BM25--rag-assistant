[site]: crossvalidated
[post_id]: 604176
[parent_id]: 
[tags]: 
Interpretation in Predictive Modeling (XGBoost)

I am currently trying to solve a binary classification problem with models. I am running into a bit of trouble with my models. I have tried a number of various ways to go about my code, including classification trees, logistic regression, as well as an xgboosted tree. All of the models have ran, and had various levels of success. My question is that I have a great xgboosted model. However, I am struggling because I have no idea how/where to go to interpret the model. I have done all of the accuracy, sensitivity, specificity, as well as created a ROC Curve already. What I am confused on is if there is a way to interpret classification tree models the same was logistic regression works where we can see independent variables and coefficients for each variable going into the model. Or is there an easier way to actually digest the tree to see what variables are impacting the model? Any advice would greatly be appreicated. If it isn't possible, would the recommendation for predicting the future be to just do a logistic regression model and try and tune it as best as possible even if it isn't as accurate as one of the more advanced tree models. I know how to run the models but I think my understanding is leading to a disconnect as to how the practical approach to use the model to predict the future of the binary result is missing somewhere
