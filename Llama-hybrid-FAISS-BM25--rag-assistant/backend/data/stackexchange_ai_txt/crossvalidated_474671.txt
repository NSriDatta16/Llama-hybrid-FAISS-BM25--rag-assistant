[site]: crossvalidated
[post_id]: 474671
[parent_id]: 474667
[tags]: 
The typical procedure is to choose the best hyperparameters, which OLS doesn't have, based on cv performance and train the model on the entire training set (as you expected to be). The procedure that the student employs is actually choosing a dataset. And, it increases the variance because if any of the folds have a bad partition, you may end up choosing that one as your model. Instead of an averaged performance, it relies on a specific dataset partition. This is especially why we'd generally prefer cross-validation while tuning HPs instead of a holdout set if not computationally expensive.
