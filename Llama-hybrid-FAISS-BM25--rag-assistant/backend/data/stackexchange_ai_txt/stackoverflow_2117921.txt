[site]: stackoverflow
[post_id]: 2117921
[parent_id]: 2117658
[tags]: 
In C (or C++) you have fine-grained control over the exact size of each data structure. You also have the possibility of fine-grained control over storage allocation. You can, after all, extend the new method, use malloc directly and otherwise structure memory to create spatial locality. In most dynamic languages (like Python) you have no control at all over the exact size of anything, much less it's location. In Python you may have some temporal locality, but you have little or no spatial locality. Temporal locality might be enhanced through simple memoization of results. This is such a common speed-up that people often include a memoization decorator to uncouple the memoization (temporal locality) from the core algorithm. I don't think that C or C++ cache-oblivious implementations translate to dynamic languages because I don't think you have enough control. Instead, just exploit memoization for speed-ups. http://wiki.python.org/moin/PythonDecoratorLibrary#Memoize
