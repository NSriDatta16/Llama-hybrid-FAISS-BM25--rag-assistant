[site]: crossvalidated
[post_id]: 101057
[parent_id]: 100819
[tags]: 
(Upadte May 6 2014: The answer now actually addresses the question. I left the original answer as a possibly interesting variant). I post this answer because I thought of a simple (or just naive?) way to analyze the problem at hand, in the hope of generating some corrective comments. The sequence $\{X_n\}$ is not a subject matter of the Weak Law of Large Numbers (and it doesn't converge anyway), so I guess what the OP means is to examine the case for the average sum $\frac 1n S_n \equiv \frac 1n \sum_{i=1}^nX_i$. We are looking at independent non-identical dichotomous random variables. The constant term $-\sqrt 3$ is just a distraction. So we center the r.v.'s and we examine $$X_i =\cases{i\qquad &p=1/2\\ \\ -i\qquad &p=1/2} \;\;\;\;i=1,...,n$$ We easily calculate that $E[X_i] = 0$, free of $i$, while $\operatorname {Var}(X_i) = i^2$. So these random variables have common and finite expected value, but different variance which increases as the index increases. We also have that $E[\frac 1nS_n] = 0$, while $\operatorname {Var}(\frac 1nS_n) = \frac{1}{n^2}\sum_{i=1}^n i^2 = (n+1)(2n+1)/(6n)$ (thanks whuber), which diverges as the index increases. So, with non-identical r.v.'s, which have larger and larger variance to infinity, and a sequence whose additional elements have support that tends to $\{\pm \infty\}$, we should be careful regarding convergence. An approach to the matter is as follows: We denote $A_n$ the subject of indices $i$ for which $X_i = i$. Then we can write $X_i$ using indicator functions as $$X_i = i\cdot \mathbf 1\{i\in A_n\} -i\cdot (1-\mathbf 1\{i\in A_n\}) = i\cdot\big(2\cdot \mathbf 1\{i\in A_n\}-1\big)$$ We also can write $$\frac 1{n+1}S_{n+1} = \frac 1{n+1}\sum_{i=1}^{n+1}X_i = \frac n{n+1}\left(\frac 1{n}S_n\right) + \frac 1{n+1}X_{n+1}$$ $$= \frac n{n+1}\left(\frac 1{n}S_n\right) + \frac 1{n+1}(n+1)\cdot\big(2\cdot \mathbf 1\{i\in A_n\}-1\big) \\ = \frac n{n+1}\left(\frac 1{n}S_n\right) + 2\cdot \mathbf 1\{n+1\in A_n\}-1$$ if we consider the probability limits of the two sides of this equation we have $$\operatorname{plim}\left(\frac 1{n+1}S_{n+1}\right) = \operatorname{plim}\left(\frac n{n+1}\right) \cdot \operatorname{plim}\left(\frac 1{n}S_{n}\right) + \operatorname{plim}\left(2\cdot \mathbf 1\{n+1\in A_n\}\right)-1$$ $$\Rightarrow \operatorname{plim}\left(\frac 1{n+1}S_{n+1}\right) = \operatorname{plim}\left(\frac 1{n}S_{n}\right)+ 2\operatorname{plim}\left(\mathbf 1\{n+1\in A_n\}\right)-1$$ But the indicator function does not converge in probability -it always takes the values $0$ or $1$ irrespective of the value of the index. So we arrive at $$\Rightarrow \operatorname{plim}\left(\frac 1{n+1}S_{n+1}\right) = \operatorname{plim}\left(\frac 1{n}S_{n}\right) \pm 1$$ which I believe tells us that $\frac 1{n}S_{n}$ does not converge in probability. This result essentially comes from the fact that each additional element of the sum equals in absolute value the index divisor with certainty , and so it cancels it out. A VARIANT Consider the following variant $$X_i =\cases{n\qquad &p=1/2\\ \\ -n\qquad &p=1/2} \;\;\;\;i=1,...,n$$ Here, the r.v's comprising the sum are identically distributed, and they are different for each different index. The expected value remains $0$ as before, but the variance now is $\operatorname {Var}(\frac 1nS_n) = n$. Since the r.v.'s are dichotomous, we can set $n_a$ to be the number of r.v.'s obtaining the value $n$ and $n_b$ the number of r.v.'s obtaining the value $-n$, $n_a+n_b=n$. Then we can write $$\frac 1nS_n = \frac 1n \big[n_a\cdot n-n_b\cdot n)\big] = n_a-n_b$$ To check whether the Weak Law of Large Numbers holds, we need to examine whether $$\lim_{n\rightarrow \infty}\mathrm{Pr}\left(\left|\frac 1n S_n \right|>\varepsilon\right)=?\;\;0,\qquad \forall \varepsilon >0$$ $$\Rightarrow \lim_{n\rightarrow \infty}\mathrm{Pr}\left(\left|n_a-n_b \right|>\varepsilon\right)=?\;\;0,\qquad \forall \varepsilon >0$$ We note that $n_a$ and $n_b$ are integers. So their difference will be an integer too. The condition for the WLLN is that the above probability goes to zero $\forall \varepsilon >0$ and so also $\forall \;0 But although $\operatorname{plim}(n_b/n)= \operatorname{plim}(n_a/n) =1/2$, this is not the same as saying that $\lim_{n\rightarrow \infty}\mathrm{Pr}\left(n_a=n_b \right)=1$. The event $\{n_a=n_b\}$ will not hold with probability $1$, even at the limit. So neither here $\frac 1nS_n$ appears to converge in probability to its expected value.
