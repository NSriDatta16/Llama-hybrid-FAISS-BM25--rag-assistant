[site]: datascience
[post_id]: 54856
[parent_id]: 
[tags]: 
Does it make sense to train an Autoencoder for Dimensionality Reduction using Mini-Batch Gradient Descent?

I want to reduce the dimensionality of a dataset using a stacked Autoencoder. The size of the dataset and the computing power at my disposal make it very difficult to train the Network using simple, full-batch Gradient Descent. Does it make sense to use Mini-Batch Gradient Descent for this kind fo task? I guess that would generate a noisy reduction of dimensionality?
