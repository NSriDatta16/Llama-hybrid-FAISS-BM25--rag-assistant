[site]: crossvalidated
[post_id]: 46358
[parent_id]: 46345
[tags]: 
The default error family for a glm model in (the language) R is Gaussian, so with the code submitted you are getting ordinary linear regression where $R^2$ is a widely accepted measure of "goodness of fit". The R glm function doesn't report the Nagelkerke-pseudo-"$R^2$" but rather the AIC (Akaike Information Criterion). In the case of an OLS model, the Nagelkerke GOF measure will be roughly the same as the $R^2$. $$R^2_{\mathrm{GLM}}=1-\frac{(\sum_id_{i,\mathrm{model}}^2)^{2/N} }{(\sum_id_{i,\mathrm{null}}^2)^{2/N}} ~~~~~~~~.=.~~~~~~~~ 1-\frac{\mathit{SSE}/n[\mathrm{model}]}{\mathit{SST}/n[\mathrm{total}]} = R^2_{\mathrm{OLS}}$$ There is some debate about how such a measure on the LHS gets interpreted, but only when the models depart from the simpler Gaussian/OLS situation. But in GLMs where the link function may not be "identity", as was here, and the "squared error" may not have the same clear interpretation, so the Akaike Information Criterion is also reported because it appears to be more general. There are several other contenders in the GLM GOF sweepstakes with no clear winner. You might want to consider not reporting a GOF measure if you are going to be using GLMs with other error structures: Which pseudo-$R^2$ measure is the one to report for logistic regression (Cox & Snell or Nagelkerke)?
