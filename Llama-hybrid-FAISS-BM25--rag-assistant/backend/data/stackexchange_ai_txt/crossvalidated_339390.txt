[site]: crossvalidated
[post_id]: 339390
[parent_id]: 
[tags]: 
Loss function and activation function for categorical AND multi-label classification in neural network?

I am training a neural network to classify a set of objects into n-labels, each label with m different category. E.g. for n = 5, and m = 3, an example output is [0,2,0,2,1]. I can also transform the output into a 2-D matrix, for example [0,2,0,2,1] = [[1,0,0], [0,0,1], [1,0,0], [0,0,1], [0,1,0]] Where each row represent a label and each column represent the probability of that label in category 0,1 or 2. But this is where I am stuck. I understand that for multiclass classification, I should use softmax and categorical cross-entropy as the loss function since the probability should sum up to 1. For multilabel classification, I should use sigmoids and binary cross entropy since each label has a probability from 0 to 1, independent of other labels. But how about this case? Each row is a multiclass classification and each column is a multilabel classification.
