[site]: crossvalidated
[post_id]: 511427
[parent_id]: 
[tags]: 
Why macro F1 measure can't be calculated from macro precision and recall?

I'm interested in calculating macro f1-score by macro precision and recall manually. But the results aren't equal. What is the difference in the final formula between f1 and f1_new in code? Would you explain by formula exactly? from sklearn.metrics import precision_score, recall_score, f1_score y_true = [0, 1, 0, 1, 0 , 1, 1, 0] y_pred = [0, 1, 0, 0, 1 , 1, 0, 0] p = precision_score(y_true, y_pred, average='macro') r = recall_score(y_true, y_pred, average='macro') f1_new = (2 * p * r) / (p + r) f1 = f1_score(y_true, y_pred, average='macro') print(f1_new == f1) # False
