[site]: crossvalidated
[post_id]: 368688
[parent_id]: 
[tags]: 
Random Forests interpretability

I have been using the sklearn RandomForestClassifier to solve a binary classification problem. For a particular sample prediction, I would like to be able to know how to change the features values to make the prediction change. E.g. let's say I have an entry with [size = 15, width = 8, height = 13] and the model gives me a probability = 0.9 to be of class 1 . What I would like to be able to say is "change size from 15 to 10 " and then your probability=0.1 for example. Then optimally, what I would like is the smallest "gradient" in the features values to pass from one class to another (or the one that gives the most change in probability). Maybe I'm wrong, but from what I've read the packages LIME and treeinterpreter do not provide this kind of information.
