[site]: crossvalidated
[post_id]: 512550
[parent_id]: 511918
[tags]: 
Problem: the challenge is to know if "person X" would take item EXPENSIVE instead of CHEAP Going by the base rates you report in your question, Person X might not want to buy anything; probably this should be accounted for in the model. Have you considered aggregating the two datasets, fitting a model for a multinomial (or ordered) outcome (no buy, vs. cheap buy, vs. expensive buy)? Then you get predicted probabilities for each possible outcome. I'm assuming that the two datasets are samples from the same population. If not, it might not make a lot of sense to fit one model on the two datasets, or to compare the probabilities from two models fitted on the separate datasets anyway. Then you would best stick to evaluating the probability for a buy vs. not using only one of the models. Assuming the same population, the suggested model A / model B approach seems sensible, but the default RF classification approach might not be optimal: For probability estimation, a regression RF will likely perform better than a classification RF. In a classification RF, classifications of the individual trees are averaged over to obtain a 'probability'. This 'probability' performs well for classification, but might not be a good estimator of the probability; they tend to be more extreme. With e.g., very noisy data and very low base rate of buys, all trees might predict 'no buy': the 'probability' predicted by the RF might be 0, while the proportion of buys in each of the terminal nodes in which the new observation fell were above 0 (but below .5). In a regression RF (where one would model the binary outcome as a 0-1 variable), the predictions of each tree are a proportion (proportion of buys in the respective terminal node), and the final prediction of the RF is an average over that. That might make for a better estimator of probabilities. See for example: Malley, J. D., Kruppa, J., Dasgupta, A., Malley, K. G., & Ziegler, A. (2012). Probability machines: consistent probability estimation using nonparametric learning machines. Methods of Information in Medicine, 51 (1), 74. https://doi.org/10.3414/ME00-01-0052 Sage, A. J., Genschel, U., & Nettleton, D. (2020). Tree aggregation for random forest class probability estimation. Statistical Analysis and Data Mining: The ASA Data Science Journal, 13 (2), 134-150. https://doi.org/10.1002/sam.11446
