[site]: crossvalidated
[post_id]: 324972
[parent_id]: 285594
[tags]: 
As a general rule, if you want to test a hypothesis $H_0$ against $H_A$, you must specify a model that encapsulates both possibilities and then use that model to try to infer which of the hypotheses is correct. So if you think your observed time-series data might have some form of auto-correlation, and you want to test this, it is no good modelling them as IID. You need to use a model that allows for auto-correlation, but also allows independence as a special case, so that these competing hypotheses can be tested from within the model. You are correct that the standard AR(1) auto-correlation structure for a continuous variable is no good in this case. You will instead need to formulate some kind of model that is suitable for a sequence of Bernoulli trials. For a sequence of Bernoulli trials, a stationary Markov chain for this process would have two parameters $0 $$\begin{matrix} X_1 \sim \text{Bern} \left( \frac{\theta_0}{1+\theta_0-\theta_1} \right) & & & X_{t+1} | X_t \sim \text{Bern}(\theta_{X_t}). \end{matrix}$$ This gives a general stationary Markov chain, where the probability in the Bernoulli trial depends on the previous outcome. It can be shown that $\mathbb{Corr}(X_{t+1}, X_t) = \theta_1 - \theta_0$ within this model, so if you want to test for independence, you would be testing the hypotheses: $$\begin{matrix} H_0: \theta_1 = \theta_0 & & H_A: \theta_1 \neq \theta_0. \end{matrix}$$ It should be possible to fit this model to your data, estimate the parameters of the model, and test the hypothesis of independence. This could be done using classical or Bayesian methods.
