[site]: crossvalidated
[post_id]: 174668
[parent_id]: 
[tags]: 
Relation between decision tree Depth and number of Attributes

In Machine Learning libraries such as weka, we can set a tree to be of infinite Depth with maxDepth = -1. I am curious to know what would happen if trees were set to a depth far higher than the number of attributes/features available. In other words, what if we went on reverse-pruning spree? Would it lead to overfitting the data or would it cause the tree to perform much better?
