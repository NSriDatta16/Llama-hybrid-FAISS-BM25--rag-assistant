[site]: crossvalidated
[post_id]: 450360
[parent_id]: 449818
[tags]: 
Definitions Definition 1: If $\mathcal F \subseteq \mathcal G$ are two $\sigma$ -fields, and $X$ a $\mathcal G$ -measurable integrable random variable, then $\mathbb E[X | \mathcal F]$ is defined as any $\mathcal F$ -measurable random variable $Y$ , such that $\mathbb E[Y;A]=\mathbb E[X;A]$ for every $A \in \mathcal F$ . Here $\mathbb E[X;A]$ is a notation for $\int_AX\,d\mathbb P$ . Definition 2: We define conditional probability as $\mathbb P(A | \mathcal F)= \mathbb E[1_A|\mathcal F]$ . https://math.stackexchange.com/questions/2373097/condition-on-sigma-algebra/2373105#2373105 $X_n\sim Unif(0,X_{n-1})$ it means $X_n|X_{n-1}\sim Unif(0,X_{n-1})$ it also means $X_n|X_{n-1}=t\sim Unif(0,t)$ rigorously it is a conditional probability. How it define? It define bayed on conditional Expectation , http://www2.stat.duke.edu/courses/Fall17/sta711/lec/wk-10.pdf , on the Other hand $$P(X_n\leq a|X_{n-1})=E(1_{X_n\leq a}|X_{n-1})=E(1_{X_n\leq a}|\sigma(X_{n-1}))$$ This type of conditional probability is unified definition that other definitions( continues variable, discrete variables, events,mixture variables) are a special case of this. (like a patch for old definition, $P(A|B)=\frac{P(AB)}{P(B)}$ , problem with continues variable, like in this situation, $B=\{X_{n-1}=t\}$ so $P(B)=0$ ). we saw this (define a variable conditioned another variable) before in Bayesian approach, $$X|\mu \sim N(\mu , 1)$$ , that conditioned based a variable $\mu\sim N(0,1)$ , and in Metropolis-Hastings Method that conditioned based on previous observation. "Does it mean that for every $\omega \in \Omega$ $X_n(\omega)∼Unif(0,X_{n−1}(\omega))$ ?" Only enough for almost sure of them. $$E(X_{n+1}|A_n) = E(X_{n+1}|\sigma(X_1,\cdots ,X_n)) = E(X_{n+1}|X_1,\cdots ,X_n)= E(X_{n+1}|X_n)= \frac{X_n}{2}$$ all other question solve similar.
