[site]: crossvalidated
[post_id]: 333735
[parent_id]: 
[tags]: 
Chances a forecasting model exceeds/deceeds a specified threshold

I am interested in determining the confidence of a forecasting model with applications to quantitative finance. I have the following multivariate data $X$: \begin{align} X(t) \sim F_{X}(t) \end{align} where $X \in \mathbb{R}^{T, d}$ for $T$ timesteps in $d$ dimensions. I am interested in a forecasting problem: \begin{align} \begin{split} & \textrm{Given: } X = \{x_{i,:}\}_{i=0}^{T-1} \textrm{ timeseries data} \\ & \textrm{Determine: } X^f = \{x_{{i, :}}\}_{i > T-1} \textrm{ the values of the timeseries at future timesteps} \end{split} \end{align} To answer this question, I am interested in using multivariate ARMA (as well as AR and MA)-type models, GARCH models, LSTM (long-short term memory ANN), or BNN (bayesian neural network), and am open to "more suitable" approaches. I am particularly interested in quantifying the confidence at which a given prediction for one feature in my timeseries exceeding/deceeding/equaling a specified value. Mathematically, the following quantity: \begin{align} \mathbb{P}\left\{R\left(\mathbb{P}\left\{X^f_{:, q}, i > T-1\right\}, c\right)\right\} \end{align} at some point in $X^f$ the timeseries for feature $q$ exceeds/deceeds $c$ in the future arbitrarily, -or- \begin{align} \mathbb{P}\left\{R\left(\mathbb{P}\left\{x_{i, q}, i > T-1\right\}, c\right)\right\} \end{align} the chances that a specific $x_i$ at timepoint $i$ in the future for feature $q$ exceeds/deceeds $c$. where $R(a, b)$ is a relation on $a, b$ and can be either greater than ($R(a, b) := \mathbb{I}\left\{a>b\right\}$) or less than ($R(a, b) := \mathbb{I}\left\{a Does anybody know how this can be effectively done analytically for the given models specified? Is there a simple, easily-generalizable to parametrized (or possibly less-interpretable models like a RNN) this could be done empirically through simulation? If there is good literature on the topic, that would work too. I've researched around a bit but haven't yet found anything quite worthwhile. One possible empirical way to do it that I've thought up so far is to jitter the values sensibly to form the null. For example, construct a volatility model on the variance of inputs which produces an estimate of the variance based on the past-history at a given point in time, and jitter the inputs by the time-varying estimates of variance. Or something like that. Then, through simulation generate a synthetic range of forecasts from models individually trained on the jittered input. Output confidence as the number of times the forecast on jittered data exceeds/deceeds a user-defined quantity. Are there any better models that could be used for this problem? I am an R/python programmer, so implementation links would be appreciated too!
