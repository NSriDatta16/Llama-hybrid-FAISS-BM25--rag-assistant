[site]: crossvalidated
[post_id]: 372922
[parent_id]: 372897
[tags]: 
In your situation, it seems that you are interested in how gender affects the probability p of being a full/associate professor, after controlling for time since graduation and whether or not one has a PhD. (I doubt one can become a professor without a PhD, but that's another story.) So the binary logistic regression model you would fit to the data would look like this: log(p/(1-p)) = beta0 + beta1*Gender + beta2*Time + beta3*PhD where log() denotes the log-transformation and p/(1-p) denotes the odds of being a full/associate professor. The expression log(p/(1-p)) is called the logit transform of p. (Note that a multinomial logistic regression would require your dependent variable to have 3 or more categories.) Controlling for Time and PhD in your model allows you to study the effect of Gender on the probability p of being a full/associate professor (appropriately transformed via the logit transformation) among subjects in your target population for whom the time since graduation is the same and who share the same type of degree (e.g., they either all have a PhD or don't have a PhD). There is no need to improve the model, since you are interested in the effect of Gender on the probability p controlling for the effects of Time and PhD. All you need to do is focus on the effect of Gender reported for your model and present the corresponding effect estimate, 95% confidence interval and p-value. (Note that you may need to exponentiate the reported effect to express it as an odds ratio, unless SPSS does it for you.) As an example, let's say that you estimated the effect of Gender - expressed as an odds ratio - to be 1.45 (95% CI: 1.20 to 1.75; p-value = 0.001). Then you would conclude something along these lines: Controlling for amount of time since graduation and whether or not one holds a PhD degree, the odds of being a full/associate professor were estimated to be 1.45 times higher in males compared to females (95% CI: 1.20 to 1.75). This finding indicated that gender has a statistically significant effect on the probability of being a full/associate professor (p-value = 0.001). The above interpretation assumes that the Gender variable was coded so that 1 = Males; 0 = Females. There is also no need to compare your model against the simpler model which includes just an intercept - instead, focus on the original model as that is the model which will help you answer the question you are interested in. However, you do want to see what the explanatory power of the model is by computing perhaps a pseudo R squared measure. Most control variables are included in the model based on substantive grounds so they are kept in the model even if their associated p-values are not statistically significant. The software you use - in this case, SPSS - will know how to treat each type of control variable. For example, a categorical control variable with 2 categories - A and B - will be coded in the model as a dummy variable with values 0 for category A and 1 for category B. A categorical control variable with 3 categories - A, B and C - will be coded in the model via two dummy variables. The first dummy variable will take the value 1 for category B and 0 for all others. The second dummy variable will take the value 1 for category C and 0 for all others. As the analyst, you get to choose which category you will treat as the reference against which the remaining categories will be compared. In these two examples, A was treated as the reference. Your model was formulated based on the question you needed to answer. However, the model relies on certain assumptions which need to be verified from the data. So you should look into and check model diagnostics for your binary logistic regression model to ensure the data verify these assumptions. Because the control variables are not of direct interest to you, the interpretation focus should be on the effect of gender.
