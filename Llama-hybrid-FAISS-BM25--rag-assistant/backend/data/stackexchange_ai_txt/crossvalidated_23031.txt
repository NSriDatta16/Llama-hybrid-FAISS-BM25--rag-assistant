[site]: crossvalidated
[post_id]: 23031
[parent_id]: 6652
[tags]: 
You are asking about the Frequentist confidence interval . The definition (note that none of your 2 citation is a definition! Just statements, which both are correct) is: If I had repeated this experiment a big number of times, given this fitted model with this parameter values , in 95% of experiments the estimated value of a parameter would fall within this interval. So you have a model (built using your observed data) and its estimated parameters. Then if you generated some hypothetical data sets according to this model and parameters, the estimated parameters would fall inside the confidence interval. So in fact, this frequentist approach takes the model and estimated parameters as fixed, as given, and treats your data as uncertain - as a random sample of many many other possible data. This is really hard to interpret and this is often used as an argument for Bayesian statistics ( which I think can be sometimes little disputable . The bayesian statistics on the other hand takes your data as fixed and treats parameters as uncertain. The bayesian credible intervals are then actually intuitive, as you'd expect: bayesian credible intervals are intervals where with 95% the real parameter value lies. But in practice many people interpret the frequentist confidence intervals in the same way as Bayesian credible intervals and many statisticians don't consider this a big issue - though they all know, it is not 100% correct. Also in practice, the frequentist and bayesian confidence/credible intervals won't differ much, when using bayesian uninformative priors .
