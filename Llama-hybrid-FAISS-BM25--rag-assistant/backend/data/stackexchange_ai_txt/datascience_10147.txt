[site]: datascience
[post_id]: 10147
[parent_id]: 
[tags]: 
How do MS-TDNNs work?

Multi-State Time Delay Neural Networks (MS-TDNNs) were introduced in Haffner, Patrick and Waibel, Alex: Multi-state time delay networks for continuous speech recognition . In Advances in neural information processing systems, 1992. They are an extension of TDNNs. TDNNs are convolutional neural networks for automatic speech recognition (ASR), where the convolution happens over the time. The aim of MS-TDNNs seems to be to get rid of the hybrid approach in ASR, where you need dynamic programming / HMMs to chunk the audio stream and then neural networks to recognize the phonemes. Somehow MS-TDNNs seem to do the segmentation as well. I don't understand how. Could somebody please explain it to me? (Related side questions: Are MS-TDNNs recurrent networks? Where exactly does the name "multi-state" come from?)
