[site]: stackoverflow
[post_id]: 3399825
[parent_id]: 
[tags]: 
How to efficiently query large multi-polygons with PostGIS

I am working with radio maps that seem to be too fragmented to query efficiently. The response time is 20-40 seconds when I ask if a single point is within the multipolygon (I have tested "within"/"contains"/"overlaps"). I use PostGIS, with GeoDjango to abstract the queries. The multi-polygon column has a GiST index, and I have tried VACUUM ANALYZE. I use PostgreSQL 8.3.7. and Django 1.2. The maps stretch over large geographical areas. They were originally generated by a topography-aware radio tool, and the radio cells/polygons are therefore fragmented . My goal is to query for points within the multipolygons (i.e. houses that may or may not be covered by the signals). All the radio maps are made up of between 100.000 and 300.000 vertices (total), with wildly varying number of polygons. Some of the maps have less than 10 polygons. From there it jumps to between 10.000 and 30.000 polygons. The ratio of polygons to vertices does not seem to effect the time the queries take to complete very much. I use a projected coordinate system, and use the same system for both houses and radio sectors. Qgis shows that the radio sectors and maps are correctly placed in the terrain. My test queries are with only one house at a time within a single radio map. I have tested queries like "within"/"contains"/"overlaps", and the results are the same: Sub-second response if the house is "far from" the radio map (I guess this is because it is outside the bounding box that is automatically used in the query). 20-40 seconds response time if the house/point is close to or within the radio map. Do I have alternative ways to optimize queries, or must I change/simplify the source material in some way? Any advice is appreciated.
