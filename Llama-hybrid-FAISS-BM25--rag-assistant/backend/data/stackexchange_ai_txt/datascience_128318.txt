[site]: datascience
[post_id]: 128318
[parent_id]: 128314
[tags]: 
The efforts to add "guardrails" to LLMs is usually referred to as LLM alignment . While the internals of ChatGPT are not known, usually LLM alignment is done at the model level via training/fine-tuning/RLHF, not externally. LLM alignment is a whole field of research that is all the rage currently, due to the perceived need to control the output of LLMs. If you want to scratch the surface of the field, you can start with this survey .
