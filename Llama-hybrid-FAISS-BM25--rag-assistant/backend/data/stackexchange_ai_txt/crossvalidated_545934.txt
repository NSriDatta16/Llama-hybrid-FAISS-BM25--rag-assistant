[site]: crossvalidated
[post_id]: 545934
[parent_id]: 545917
[tags]: 
You have fallen into the common trap of tweaking an analysis until you get a satisfactory result. This process is guaranteed to overstate the value of the predictive instrument, or to make your predictions apply only conditionally. For example, removal of outliers results in a model that is conditional on outliers never appearing in future data to which you want to apply your model. I suggest choosing a flexible technique that is robust and that uses smart penalization (e.g., penalizes complex parts of the model more than simple parts such as top-layer additive signals) and sticking with the result. If you want to try a few methods (but not tweaking them) then model averaging may be worthwhile. If you had a huge test sample (e.g., n=50,000) you could play with the data more aggressively to optimize performance on that sample, then apply the result to yet another large test sample for unbiasedly estimating model performance.
