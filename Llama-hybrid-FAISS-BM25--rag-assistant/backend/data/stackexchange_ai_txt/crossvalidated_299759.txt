[site]: crossvalidated
[post_id]: 299759
[parent_id]: 299747
[tags]: 
Regression is quite well suited for learning what settings generate the best running index (or at least a good running index). All you need is in the regression coefficients. If the regression coefficient is positive, a greater value of the corresponding regressor will tend to yield a greater value of the response*. You want to maximize the response; hence, the recipe is to increase (maximize) the regressor value. Conversely, if the regression coefficient is negative, minimize the corresponding regressor's value. That is the answer the engineer needs. Consider a concrete example. Suppose the fitted regression equation is $$ y=0.5+2x_1-0.5x_2+\varepsilon. $$ Since $2>0$, an increase in $x_1$ should hopefully yield an increase in $y$. Thus the engineer should seek to increase $x_1$ as much as possible. On the other hand, since $-0.5 Edit: as Matthew Drury points out, a simple regression like this need not be a good model for your particular application. (Perhaps some feature engineering would make it better.) The important thing is that if the model has decent fit, then it can be used conveniently for finding settings in which the response is maximized. * This requires some assumptions such as exogeneity of the regressor.
