[site]: crossvalidated
[post_id]: 274043
[parent_id]: 273851
[tags]: 
If you were using Bayesian Model Averaging, you would average your predictions $p(y_{t+1}|m_k,y_{1:t})$ with weights that represented some posterior model probabilities $p(m_k|y_{1:t})$ like this $$ p(y_{t+1}|y_{1:t}) = \sum_k p(y_{t+1}|m_k,y_{1:t})p(m_k|y_{1:t}). $$ One way I could understand your question is to find under what circumstances can we understand your "accuracy" as a posterior model probability. If you were updating your model's posterior probabilities at every time step using this recursive formula $$ p(m_k|y_{1:t}) = \frac{p(y_{t}|m_k)p(m_k|y_{1:t-1})}{\sum_{k'} p(y_{t}|m_{k'})p(m_{k'}|y_{1:t-1}) }, $$ then the posterior would increase after correct predictions, and decrease with bad predictions. If you started off with uniform priors over all of your models, and if you only had two classes for the categorical observations, and if you predict $Y_t = 1$ when $P(Y_t =1|m_k) > .50$, and if your data was iid, then your "accuracy" could represent something close to the posterior model probabilities. It would probably get pretty close after a few steps.
