[site]: crossvalidated
[post_id]: 437267
[parent_id]: 437197
[tags]: 
Cross-entropy between two probability distributions $p$ and $q$ is defined as $$ H(p, q) = E_p [-\log q] = -\sum_x p(x) \log q(x) $$ In machine learning , $q$ 's are the predicted probabilities, while $p$ 's are the observed labels in $\{0, 1\}$ , the "true probabilities". Both $p$ and $q$ need to be in $(0, 1)$ , so your targets are wrong, leading to the results you have show. For different reasons (usually computational ones), people sometimes prefer their models to return log-odds (logits) , i.e. values in $(-\infty, \infty)$ , rather then transforming them to probabilities. This is why functions as the one above accepts logits as inputs. However this only applies to the predicted values, not the target values. If your target values were unconstrained real numbers, then this would be a regression problem and you would be using the loss functions appropriate for regression (squared error, absolute error, Huber loss, etc.). Cross-entropy would not have any mathematical sense if the values of $p$ were unconstrained real numbers, while it has information-theoretic meaning if the values are probabilities.
