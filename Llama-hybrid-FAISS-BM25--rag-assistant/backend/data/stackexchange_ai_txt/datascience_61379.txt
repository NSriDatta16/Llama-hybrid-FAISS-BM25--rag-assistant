[site]: datascience
[post_id]: 61379
[parent_id]: 47906
[tags]: 
There is a nice paper that discusses this problem of named as 'Modelling Bias' in VAE's. ELBO objective is: $$L_{ELBO}(x) = E_{q_φ(z|x)}[\log p_θ(x|z)] − D_{KL}(q_{φ}(z|x) || p(z))$$ The first term forces the VAE to put all the mass of $q_φ(z|x)$ the mode of $p_θ(x|z)$ while the second term forces it to be as diffuse as possible. But generally for images, the dimensionality of X is often orders of magnitude larger than the dimensionality of Z. Because the same per dimensional modeling error incurs a much larger loss in X space than Z space, when the two objectives are conflicting (e.g., because of limited modeling capacity), the model will tend to sacrifice divergences on Z and focus on minimizing divergences on X. Hence it may lead to over-fitting rather than generalization.
