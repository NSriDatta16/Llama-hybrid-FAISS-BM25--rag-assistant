[site]: datascience
[post_id]: 17740
[parent_id]: 17721
[tags]: 
The scenario you described with one horse is basically anecdotal evidence. To objectively evaluate what you're doing, you need to agree with the client to make this an experiment. I understand you don't trust my horse predictions and that's totally understandable. It is human nature to worry about the ones that got away. Let's handle this objectively and run an experiment. I'll give you buy/sell ratings on 50 horses. We then track their performance for six months. If on average my ratings outperform a coin flip, we'll know we're onto something at a macro level even if a few got away. If my models end up being worse than a coinflip, we'll know the model needs to be improved or you need to fire me.
