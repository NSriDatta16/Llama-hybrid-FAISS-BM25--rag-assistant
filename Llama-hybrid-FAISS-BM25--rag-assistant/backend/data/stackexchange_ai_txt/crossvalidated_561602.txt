[site]: crossvalidated
[post_id]: 561602
[parent_id]: 561164
[tags]: 
A different perspective. The chemistry that led to the first life forms and from there to life forms with a simple nervous system and onward to organisms with a brain, involved only processes analogous to random search. Any more sophisticated algorithms will have had to evolve from random search. This means that it should be possible to use only random search in machine learning and to get to excellent results. We couldn't exist if this were not true. The question is then how to use random search. Biology would strongly suggest that we should use a genetic algorithm. For example, with your 60 trials to get to the top 5% method, you can iterate this where you take the best few and create 60 mutants of these best few and search for the best of these. The problem is then that you can get stuck in a local maximum in the fitness landscape. There are many different solutions to this problem. One can use the analogue of sexual reproduction in biology, by mixing the weights from different networks. It is also good idea to also include a few results that are not in the top, as mutations of these may yield good results. And instead of starting with a very complex loss function, one can start with a simpler one. In many visual tasks such as handwriting recognition, coarse graining can work well. One then trains the neural networks using blurred images where instead of 26 letters there are only a few. You then reduce the amount of blurring so that more letters can be distinguished and then continue with the results of the previous learning session.
