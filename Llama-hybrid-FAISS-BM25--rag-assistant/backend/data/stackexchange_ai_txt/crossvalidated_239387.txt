[site]: crossvalidated
[post_id]: 239387
[parent_id]: 204617
[tags]: 
Since you do not have that many features I would remove features whose correlation is above 75 (i.e. only the seed_ty) Related to feature selection, I'm not really familiar with using neural networks but looping over all subsets of features is probably not a good idea due to the risk of overfitting. Particularly if you are using the classifier to assess the quality of the subset this is a really bad idea. There are several strategies you could use. I would recommend reading Saeys, Inza and Larra√±aga paper named: A review of feature selection techniques in bioinformatics, bioinformatics 23.19 (2007): 2507-2517, available here . Personally, I would obtain individual scores for each feature using metrics such as information gain and test the model with different subsets of the top features. Do not forget to use strategies like cross-validation or bootstrap to test the model.
