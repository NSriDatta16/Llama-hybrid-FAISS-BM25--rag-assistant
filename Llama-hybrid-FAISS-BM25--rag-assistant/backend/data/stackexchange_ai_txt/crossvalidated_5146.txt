[site]: crossvalidated
[post_id]: 5146
[parent_id]: 5144
[tags]: 
Well, following your update, it seems you are dealing with a factorial experiment ( factorial means that every factors are crossed, or, in other words, each unit is subjected to every possible combination of your factors), with five replicates. Let assume that these are not the same statistical units whose temperature is repeatedly measured across each of the 12 combinations (for the sake of clarity). An ANalysis Of VAriance (ANOVA) seems to be the most appropriate method to deal with this design. Basically, it will allow you to estimate the contribution of each source of variance (decay, particles, and velocity) wrt. the total variance in the observed temperature. What is not explained by these factors is called the residual variance (what you call the 'random effect'). A full additive model (i.e., without modeling interaction between your factors) will read something like $$ y_{ijkl}=\mu + \alpha_i + \beta_j + \gamma_k + \varepsilon_{ijkl}, $$ where $y_{ijkl}$ is the temperature for unit $l$ when considering levels $i=1\dots a$, $j=1\dots b$, and $k=1\dots c$, of factors $\alpha$ (decay), $\beta$ (particles), and $\gamma$ (velocity); the $\varepsilon_{ijk}$ are the residuals assumed to follow a gaussian distribution of unknown variance, $\sigma^2$. They can be viewed as random fluctuations around $\mu$, the overall mean, and reflect the between-unit variations that are not accounted for by the other factors. The $\alpha_i$, $\beta_j$, and $\gamma_k$ can be viewed as factor-specific deviations from the overall mean $\mu$. The so-called main effect of decay, particles, and velocity will be estimated by forming a ratio between the variance that they account for (known as mean squares ) and the residual variance (what is left after considering all variance explained by those factors), which is known to follow a Fisher-Snedecor (F) distribution, with $d-1$ and $N-abc$ degrees of freedom, where $d=a$, $b$, or $c$ stands for the number of levels of $\alpha$ (decay), $\beta$ (particles), and $\gamma$ (velocity). A significant effect (following an hypothesis test of a null effect, i.e. $H_0:\, \mu_i=\mu_j\,\, \forall i\neq j$ vs. $H_1:$ at least two of the $\mu_i$'s differ) would indicate that the factor under consideration has a significant effect on the outcome. This is readily obtained by any statistical software. For instance, in R you would use something like summary(aov(temperature ~ decay + particles + velocity, data=df)) provided temperature and factor levels are organized in four columns, in a data.frame named df , as suggested below: t1 0.1 10 30 t2 0.1 10 30 t3 0.1 10 30 t4 0.1 10 30 t5 0.1 10 30 t6 0.2 10 30 t7 0.2 10 30 ... t60 0.3 100 70 The effect of any of the three factors can also be summarized under an equation like the one you referred to sy simply calling (again under R): summary.lm(aov(temperature ~ decay + particles + velocity)) This follows from the fact that an ANOVA is nothing more than a Linear Model that you may have heard about (think of a regression model where the explanatory variables are all categorical). Should you want to account for possible interactions between all three factors, you need to add three second-order and one three-order interaction terms. If any of these effects prove to be significant, this would mean that the effect of the corresponding factors cannot be considered in isolation one from the other (e.g., the effect of decay on temperature is not the same depending on the number of particles). As for references, I would suggest starting with on-line tutorial or textbook like Three-Way ANOVA , by Barry Cohen, or Practical Regression and Anova using R , by John MainDonald (but see also other textbooks available on CRAN documentation ). The definitive reference is Montgomery, Design and Analysis of Experiments (Wiley, 2005).
