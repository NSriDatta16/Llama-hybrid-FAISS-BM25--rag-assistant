[site]: crossvalidated
[post_id]: 465691
[parent_id]: 
[tags]: 
Interpretation of Principal Component Analysis

The focus of this question is: What components should I keep? There is a dataset with the following structure, which will be the input values for a neural network. Each row is associated with an image in a directory. The Confidence variable is a dummy value that is always 1. The purpose of this dataset is to train it to a convolutional neural network to detect a particular object. That is why the network defines as input only 4 coordinates where the object is identified with the columns XMin, XMax, YMin, YMax. The names of the image features are: IsOccluded, IsTruncated, IsGroupOf, IsDepiction, IsInside. So I made a correlation table, you see that the 4 coordinates have high correlation with each other. I have a question here: How to interpret this correlation table to know if it is correct to continue with the analysis? Assuming that the result of that matrix is necessary to do the analysis, then a table is made with the main components and their relationship of variance explained as shown below. After that, use sklearn's PCA and it shows the number of components and their cumulative explanatory variance. From all this, I interpret that the 4 coordinates are totally necessary and I can discard the characteristics. Â¿Why are the 4 coordinates are necessary? Because those columns will be the input for a dataset to an CNN. What could be improved from the interpretation? Any help is welcome
