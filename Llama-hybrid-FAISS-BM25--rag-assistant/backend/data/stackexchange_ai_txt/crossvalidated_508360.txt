[site]: crossvalidated
[post_id]: 508360
[parent_id]: 
[tags]: 
When conducting a meta-analysis using Pearson's R as the effect size, should you include perfect values (i.e., r = 1.00)?

I'm in the process of conducting a meta-analysis of clinical research. Since most of the included studies report Pearson's R as the effect size, I've decided to use that as the meta-analysis statistic. Some of these values are perfect values (i.e., r = 1.00). I am planning to use Field and Gillett's SPSS syntax to do the meta-analysis. However, when I use their syntax it throws a bunch of errors when I include the perfect values and only produces the Hunter-Schmidt results. These don't seem to represent the data I've put into the calculation, as it produces a very small average effect size when it is more likely to be medium or large based on the raw data. I'm wondering if I should remove these perfect values from the meta-analysis calculation or if I should round them down to something that is basically 1.00 (i.e., 0.999). When I remove them or round them down, the syntax works and produces results that make sense. I am just not sure if this is good practice, statistically speaking.
