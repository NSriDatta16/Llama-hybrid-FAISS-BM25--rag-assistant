[site]: stackoverflow
[post_id]: 4555848
[parent_id]: 4555236
[tags]: 
I see a few things you are doing wrong. You want to set your python scripts chmod a+x and test like this cat input/svminput1.txt | ./mapper1.py | sort | ./reducer1.py because that is basically what Hadoop does in streaming is launch the script (the OS handles executing the script with the right interpreter) Now for the other files moving into the job for use with your mapper & reducer you just add them in through the command line -file whateveryouwant (like you have with misc.py) and when your map/reduce launches those files are local "." to your script so import and use them or whatever you want (open a text file, whatever you want)... you should do this with the chacheArchive stuff also just push them each as -file should be fine. Here is a very basic writeup to python streaming http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/ if you have not seen already and this a little more advanced python streaming with joins and keys http://allthingshadoop.com/2010/12/16/simple-hadoop-streaming-tutorial-using-joins-and-keys-with-python/ that might be helpful also. Hope this helps if not specific errors would be needed to-do anymore I think
