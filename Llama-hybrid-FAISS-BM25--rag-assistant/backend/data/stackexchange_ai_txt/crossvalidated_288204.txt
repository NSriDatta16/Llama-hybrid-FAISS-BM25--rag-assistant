[site]: crossvalidated
[post_id]: 288204
[parent_id]: 
[tags]: 
Why do I get such a large divergence between Gaussian and Gamma family GLMs?

From what I understand the Gamma distribution is a good choice for positive right skew data. My data is a magnitude quantity with heavy outliers as you can see here from a histogram of the pooled set: The data I am analyzing comes from a 2X2 factorial design (Region and Cond) with metric response variable (called here y). In R, the default (Gaussian) GLM fit for the multiplicative model comes in about as I'd expect given that the pooled mean of the data is around 990. Call: glm(formula = y ~ Region * Cond, data = myData) Coefficients: (Intercept) RegionPOST CondON RegionPOST:CondON 920.70 127.14 23.42 -19.90 And I get similar results using a Bayesian ANOVA with homogeneous variance. However I am uncomfortable with using these tests, because my data is so far from normal. I thought that I could change my models to handle Gamma distributions instead by calling the same command with the "family" argument set to Gamma but I get: Call: glm(formula = y ~ Region * Cond, family = Gamma, data = myData) Coefficients: (Intercept) RegionPOST CondON RegionPOST:CondON 1.076e-03 -1.445e-04 -1.251e-05 4.766e-05 These values bear no relation to my data that I can see, neither to means nor to the shape and rate of any likely Gamma distributions. Why does changing the family of the GLM to Gamma change the results so dramatically, and how can I interpret these results in the context of the original data?
