[site]: crossvalidated
[post_id]: 287672
[parent_id]: 238268
[tags]: 
In classification setting, there are two popular query strategies: uncertainty sampling and query by committee (see paper for an extensive review). In uncertainty sampling, an active learner queries the label about which it is least certain. For example, we can choose to query a point that has maximum entropy (computed from class probabilities). On the other hand committee strategies consists of a set of classifiers and the most informative query is considered to be a point about which the committee disagrees the most. Such a point can be computed by maximizing vote entropy or average KL divergence. I recommend to review the paper above for additional query strategies. If you are looking for implementations, consider the following library . It is compatible with scikit-learn and can be used with any classifier. It uses random subsampling as a baseline for measuring the benefit of active learning.
