[site]: datascience
[post_id]: 118516
[parent_id]: 
[tags]: 
Can __getitem__() in a PyTorch Dataset return a random sample?

Is __getitem()__ in a PyTorch Dataset restricted to always returning the same sample for the same index? I am thinking that the samples might be cached by some downstream tasks, for instance, so I am reluctant to do this, but is it actually not a problem? (Context: this is for a Masked Language Modeling task, where I was thinking of having an epoch cover each sentence once, with random masks for each sentence. The next epoch would have different masksâ€”so at the same index in the dataset.)
