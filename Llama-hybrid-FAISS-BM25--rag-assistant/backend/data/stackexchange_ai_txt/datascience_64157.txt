[site]: datascience
[post_id]: 64157
[parent_id]: 
[tags]: 
How to handle different categorical embedding sizes in hold out data set

I have a pytorch tabular dataset with zip code as a categorical embedding. I'm getting great results on the test set. When I go to run my hold out sample through, it errors out because I have more zip codes in the hold out then what the model was trained on. How do I handle this? In production, the likelihood of seeing a new zip code is high so I need to learn something I can transfer into production. Thank you.
