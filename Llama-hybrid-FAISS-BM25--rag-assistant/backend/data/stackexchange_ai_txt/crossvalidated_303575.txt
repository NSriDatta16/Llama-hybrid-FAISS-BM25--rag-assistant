[site]: crossvalidated
[post_id]: 303575
[parent_id]: 303560
[tags]: 
Is there a way to quantitatively compare semantic similarity between two words? Word embeddings are a method that has this aim. There are also extensions that are used to encode whole documents. How one may combine "semantic similarity" with the "change of position" metrics (e.g. Levenshtein distance) to calculate "aggregate" metric? Some people tried using word embeddings with dynamic time warping .
