[site]: crossvalidated
[post_id]: 377467
[parent_id]: 71822
[tags]: 
SVM uses Stochastic Gradeint Descent (SGD) or Gradient Descent (GD) algorithm for optimation. If we look SGD: $$ \triangledown (j, i) = w^{(j)} + C \frac{\partial L(x_{i}, y_{i})}{\partial w^{(j)}} $$ so, it depends on input values. It you multiply input values some big constant you increase convergence speed of the optimization problem. Therefore, you will get %90 accuracy. If you iterate enough, you will get same accuracy without multiplication of input.
