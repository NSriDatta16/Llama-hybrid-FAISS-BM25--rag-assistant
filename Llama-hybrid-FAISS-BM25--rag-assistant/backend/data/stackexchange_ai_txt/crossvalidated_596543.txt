[site]: crossvalidated
[post_id]: 596543
[parent_id]: 
[tags]: 
Why does width of confidence interval increases with trend

I am trying to understand bayesian statistics. I am familiar with machine Learning and the way that best fit is made through loss function. I am stuck with the concept of uncertainty in coefficients. Suppose I have a simple model, where y=trend*x, and the trend coefficient is normally distributed like, Now suppose I have, following data points and I multiply distribution by the data points, the results that i would get would be as follows: As I go further up the trend, my uncertainty increases, why is this the case, How would such analysis help in practical way? Am i making the right conclusions.
