[site]: crossvalidated
[post_id]: 361237
[parent_id]: 
[tags]: 
In exactly what sense do MCMC draws approximate the target?

Background We want to sample from some intractable density $\pi(\theta)$ . Using an MCMC algorithm, we generate a sample of draws $\{\theta_i\}_{i=1}^N$ from a Markov chain that has $\pi(\theta)$ as its invariant distribution. We typically use the draws $\{\theta_i\}_{i=1}^N$ to "approximate" $\pi(\theta)$ in the following ways: Use sample averages $(1/N)\sum_{i=1}^Nf(\theta_i)$ to approximate integrals like $$\mathbb{E}[f(\theta)] = \int f(\theta)\pi(\theta)d\theta;$$ Generate histograms and kernel density estimates to visualize $\pi(\theta)$ or its marginals; Compute the ECDF $\hat{F}(\theta)=(1/N)\sum_{i=1}^N\mathbf{1}_{\theta_i\leq\theta}$ to estimate quantiles of $\pi(\theta)$ . If $\{\theta_i\}_{i=1}^N$ were direct, iid draws from $\pi(\theta)$ , then there is theory that justifies all of these approximations. Question What exactly are the theoretical justifications for the different ways that we use MCMC draws to approximate the target distribution? As an example, the theorems in Sections 4.5 and 4.7 of Geweke (2005) establish that the sample averages $(1/N)\sum_{i=1}^Nf(\theta_i)$ satisfy a central limit theorem with respect to the true value $\mathbb{E}[f(\theta)]$ . Great. That takes care of (1). What about (2) or (3)? What justifies using a kernel density estimator with MCMC draws, or computing the ECDF of MCMC draws?
