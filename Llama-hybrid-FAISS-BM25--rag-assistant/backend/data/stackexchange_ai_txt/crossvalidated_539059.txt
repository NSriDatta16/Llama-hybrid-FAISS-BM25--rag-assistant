[site]: crossvalidated
[post_id]: 539059
[parent_id]: 539052
[tags]: 
Ah! Beautiful question. First, let's look at the mean value of the posterior distribution for one sample vs $n$ samples. \begin{align} B &= \frac{A}{A + 1} \\ B_n &= \frac{nA}{nA + 1} = \frac{A}{A + \frac{1}{n}} \end{align} where in the second equation I have divided the numerator and denominator by $n$ . Note that this does not change the expression of $B_n$ . Let's begin with one sample case and look at the mean value of the posterior distribution \begin{align} M + B(\bar{x} - M) = \frac{M}{A+1} + \frac{A \bar{x}}{A + 1}, \end{align} where $A$ is the variance of the prior distribution. The above expression is a weighted average of the prior mean $M$ and the true sample mean $\bar{x}$ , where the weights $1/(A + 1)$ and $A/(A+1)$ determine how much I should trust my sample mean vs prior mean. Now let us consider the case where we collect large number samples. As $n \rightarrow \infty$ , $1/n \rightarrow 0$ . Therefore, $B_n \rightarrow 1$ . Hence, the mean value of the posterior distribution converges to the sample mean $\bar{x}$ . This is given as follows: \begin{align} M + B_n(\bar{x} - M) &\approx M + (\bar{x} - M) \\ &= \bar{x} \end{align} So, as I get more samples, I can estimate the mean by taking an average of the samples $\bar{x}$ instead of relying on the prior distribution mean $M$ . In some sense, I become less dependent on the prior distribution sample mean as I get more samples. In the same way, you can also look at what happens to the variance of the posterior distribution as you get more samples. I will leave that as an exercise for you to solve.
