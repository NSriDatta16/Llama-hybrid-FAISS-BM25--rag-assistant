[site]: datascience
[post_id]: 62855
[parent_id]: 52719
[tags]: 
You are right when you say : the word vectors of task sentiment analysis are different that the word vectors (of the same word) of task question answering Each task have a specific domain, and words have different representation in different domain. Talking about "Apple" in a cookbook is different than talking about "Apple" in a company review. The pretraining of BERT is based on books and wikipedia. But some finetuning task are not based on such sources. Words may have a different meaning. This is the reason why BERT is finetuned : to "update" the meaning of words based on your specific domain.
