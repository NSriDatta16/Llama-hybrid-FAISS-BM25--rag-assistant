[site]: crossvalidated
[post_id]: 500163
[parent_id]: 500135
[tags]: 
You can write the variance so that it doesn't explicitly depend on the mean, which may be helpful. Any individual observation $X_i$ is an unbiased estimator of the mean, and the sample average $\frac{1}{n}\sum_i X_i$ is a good estimator For any pair of observatios $X_i$ , $X_j$ , an unbiased estimator of the variance is $\frac{1}{n(n-1)}\sum_{i\neq j} (X_i-X_j)^2$ Suppose you have two observations. The independence claim is that $X_i+X_j$ is independent of $(X_i-X_j)^2$ . That's not obviously untrue. In particular, $X_i+X_j$ is uncorrelated with $X_i-X_j$ , which is a weaker property related to independence. For bivariate Normal variables in particular, if $X_i+X_j$ is uncorrelated with $X_i-X_j$ then they are actually independent , and so the mean and variance are independent.
