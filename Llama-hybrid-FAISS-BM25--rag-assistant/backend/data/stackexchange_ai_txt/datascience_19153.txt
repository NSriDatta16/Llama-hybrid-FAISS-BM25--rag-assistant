[site]: datascience
[post_id]: 19153
[parent_id]: 
[tags]: 
Tensor Decomposition in TensorFlow for multinomial time series dimensionality reduction

I'm doing unsupervised learning (clustering and DR) on multinomial time series. I need to reduce dimensions for my data, which is sparse and has a lot of dimensions. I realized that some form of tensor decomposition may be the best way to go about this. What I have is a set of samples each with a set of features in time. Each time length can different, but there are the same features for each sample. Want to end up with is a set of samples with a single feature in time. With that, I can do clustering using distance determined by dynamic time warping. Does this entire scheme sound reasonable? TensorFlow has a feature tf.qr ( https://www.tensorflow.org/api_docs/python/tf/qr ) which can do tensor decomposition, but I don't understand the output or math behind it well enough to utilize it. I have tried running it with what seems like success, but I don't understand what is stored in the q and r output tensors. If someone could explain this to me and if this even applies to what I am trying to do, I would really appreciate that. In addition, I tried using scikit tensor's cp decomposition ( https://github.com/mnick/scikit-tensor/blob/master/sktensor/cp.py ) which returns a single tensor. I also do not understand what is stored in this output or if it does something similar to TensorFlow's tf.qr function or related to what I want to do. As you can probably tell by now, I am quite lost in the math. I've tried to find explanations of how these functions work, but I can't without jumping into multilinear algebra which I don't understand. If someone could point me in the right direction, I would greatly appreciate it. EDIT: if s1 and s2 are two multidimensional time series, then this should computer the distance between them. I tried it in python and it does in fact output a number, but I don't know if I am understanding this correctly. It behaves in the same way DTW would with one dimension but takes the sum of the MSE of all features instead of just one of them when computing the distance at a given point in time. Also, this DTW function has a time window which is set to 10 but of course can change... def MDTWDistance(s1, s2, window=10, num_columns=1): DTW={} w = max(window, abs(len(s1)-len(s2))) for i in range(-1,len(s1)): for j in range(-1,len(s2)): DTW[(i, j)] = float('inf') DTW[(-1, -1)] = 0 for i in range(len(s1)): for j in range(max(0, i-w), min(len(s2), i+w)): dist= mdist(s1.loc[i], s2.loc[j], num_columns) print i, j, dist DTW[(i, j)] = dist + min(DTW[(i-1, j)],DTW[(i, j-1)], DTW[(i-1, j-1)]) return np.sqrt(DTW[len(s1)-1, len(s2)-1]) With... def mdist(a, b, num_col): dist = 0 for col in range(num_col): dist = dist + (a[col]-b[col])**2 print a[col], b[col] return dist Is this doing what I think it does/what the papers say is appropriate?
