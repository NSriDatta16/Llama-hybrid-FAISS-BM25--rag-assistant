[site]: datascience
[post_id]: 45837
[parent_id]: 
[tags]: 
Using a combination of gradient boosting with LSTM for classification?

I am presently using an LSTM model to classify high dimensional tabular data which is not text/images (dimensions 21392x1970). I also tried XGBoost (Gradient boosting) in Python separately for the same classification task (classify into one of 14 categories of different categorical values). I have come across the provision of using feature_selection_ method in XGBoost, which can provide me the F1 scores of the most relevant features in prediction. I would like to create a hybrid model that combines the LSTM with the XGBoost but am confused as to how I can do something such as using the most important features for classification (probably getting these through XGBoost) and then feeding to an LSTM ?)by a combined approach. Any ideas, suggestions, and comments are appreciated!
