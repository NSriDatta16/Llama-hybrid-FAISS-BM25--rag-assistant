[site]: crossvalidated
[post_id]: 507385
[parent_id]: 
[tags]: 
Is there any mathematical results that quantifies the error that a deep-learning network does while approximating a function?

I am working with kernel methods (AKA Support Vector Machines), and found that they outperform systematically deep-learning methods, in all the numerical experiments I have done. Indeed, I noticed that deep-learning methods seems to provide non converging methods. So I was wondering if there exists any mathematical results stating that deep-learning approach can approximate a simple, one dimensional function ? Such results are straightforward with kernel methods, but I did not find any usable mathematical results for deep learning. Is there exists any ? Note : the Universal Approximation Theorem or Cybenko approach are not useful here.
