[site]: crossvalidated
[post_id]: 130634
[parent_id]: 121852
[tags]: 
Rand Wilcox in his publications and books makes some very important points, many of which were listed by Frank Harrell and Glen_b in earlier posts. The mean is not necessarily the quantity we want to make inferences about. There may be other quantities that better exemplify a typical observation. For t-tests, power can be low even for small departures from normality. For t-tests, observed probability coverage can be substantially different than nominal. Some key suggestions are: A robust alternative is to compare trimmed means or M-estimators using the t-test. Wilcox suggests 20% trimmed means. Empirical Likelihood methods are theoretically more advantageous ( Owen, 2001 ) but not necessarily so for medium to small n. Permutations tests are great if one needs to control Type I error, but one cannot get Confidence Intervals. For many situations, Wilcox proposes the bootstrap-t to compare trimmed means. In R, this is implemented in the functions yuenbt , yhbt in the WRS package. Percentile bootstrap may be better than percentile-t when the amount of trimming is >/=20%. In R this is implemented in the function pb2gen in the aforementioned WRS package. Two good references are Wilcox ( 2010 ) and Wilcox ( 2012 ).
