[site]: crossvalidated
[post_id]: 361643
[parent_id]: 
[tags]: 
Sampling z in VAE

How many times do we sample from $Q(z|x)$ in a Variational Autoencoder? Letâ€™s say that the autoencoder input $x$ is a single image 28x28 pixels - and $Z$ is is a one dimensional distribution. Then, to reconstruct the output $X'$ - I read (I could be wrong) that we can sample $10 000$ times. Why do we sample so many? And what do we do to reduce it to 28x28? EDIT I am still confused how we can sample $10000$ times from $Q(z|x)$. For example let us consider the example above and assume that $Q(z|x)$ ~ $N(0,1)$. We have a 28x28 pixel image as the VAE input denoted $X$ with $28$ nodes each corresponding to one pixel. Also, just for simplicity lets calculate the expectation of the likelihood part of ELBO instead of the whole thing. Since, the posterior is Gaussian and we sample only once $$ E_{z\sim Q}[\log p(x|z)] = \frac{1}{28} \sum_{1}^{28} (x_i-x'_i)^2 $$ Note that $Z_1$ in this case is a single value, and we are summing the error for each node If we were to sample twice instead - would the expectation be $$ E_{z\sim Q}[\log p(x|z)] = \frac{1}{2*28} \sum_{1}^{2*28} (x_i-\overline{x}_i)^2 $$ where $\overline{x}_i$ is the combined output of two samples for example: Node $1, 2,...28, 29$(Node $1$ of the second sample), $30$(Node $2$ of the second sample)...$56$(Node $28$ of the second sample)$. ...and so on for 10000 times. Is this correct? Now if this is correct then it deserves a follow up question. As mentioned in the answer below, we do not really need to sample so much. So, say we sample twice independently - but it just so happens that the second sample $Z_2$ is much closer to the mean of the distribution. Do we expect that the reconstruction $X'$ and $X"$ look very similar to each other?
