[site]: stackoverflow
[post_id]: 3047345
[parent_id]: 3046963
[tags]: 
Provided details are scarce. Answering to best of my understanding. .. one of the systems is IBM ppc997 and the other is AMD Opteron Former system generally (*) uses big-endian presentation, later - little-endian. Read this . (*) It depends on the OS. IBM's POWER CPU can do both little and big endian, but no OS actually running on them uses little-endian mode. Normally, for binary presentation one picks one endianness and goes with it for binary presentation. For network stuff big-endian number presentation is a norm. That means all places which do something like this: /* writing to binary */ int a = 1234; write(fd,&a,sizeof(a)); /* reading from binary */ int x; read(fd,&x,sizeof(x)); should be converted to something like this: /* writing to binary */ int a = htonl(1234); write(fd,&a,sizeof(a)); /* reading from binary */ int x; read(fd,&x,sizeof(x)); x = ntohl(x); Another approach is to save endianness indicator (e.g. write magic and check it on other side: MAGIC = 0x12345678 v. MAGIC = 0x78563412) along with the binary data, and apply conversion only when endianness differs. Though that approach is less elegant and has no real of advantages I'm aware of.
