[site]: stackoverflow
[post_id]: 4912772
[parent_id]: 4910887
[tags]: 
(Yes I'm purposely giving another answer.) The other answer is that all these algorithms have strengths and weaknesses and do well on some day but not others. But I had a similar observation about slope-one some time ago and even got some comments from Daniel Lemire who proposed the implementation originally. Consider what happens as the data becomes 100% dense -- each user rates every item. The rating diff between item A and item B is the average, over all co-rating users u, of the rating difference: average(r_uB - r_uA). But as all users rate, that approaches simply the average rating (over all users) for B, minus average rating for A: average(r_uB) - average(r_uA). Call those average(B) and average(A) for ease. Imagine the item P with highest average rating overall. The diff between A and P will be larger than the diff between A and any other B; it's (average(P) - average(A)), versus (average(B) - average(A)). P's diffs are always higher than any other B by (average(P) - average(B)). But since the algorithm estimates a preference by adding these diffs to a user's ratings, and averaging those, P becomes the top recommendation for all users, always. No matter what the user's ratings, and no matter what the diffs, the sum for P (and thus average) is largest. And so on. That's the tendency as data gets dense, and I think you see some echo of that effect already. It's not "wrong" (after all P is highly rated!) but feels intuitively suboptimal as the recommendations become unpersonalized. Daniel Lemire says that the better approach, described in some follow-on papers, is to segment the data model into "positive" and "negative" ratings and build independent models from both. It avoids some of this and gives better performance. Another variant, implemented in Apache Mahout, is to use better weighting in the estimated preference calculation. It has an option to weight against diffs who have a high standard deviation, and for those with low standard deviation. This favors diffs computed over many users. It's a crude step, but helps.
