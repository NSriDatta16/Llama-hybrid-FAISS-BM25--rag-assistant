[site]: datascience
[post_id]: 74063
[parent_id]: 
[tags]: 
Understanding neural network probability

I'm training a CNN model with two classes to predict. I know it gives me a probability for one class and for the other one, and I also know I can get the predicted label, but I don't the results given. Isn't the sum of the output for each evaluated input supposed to be equal 1.0? For instance: [[0.2858745 0.85059494] [0.2858745 0.85059494] [0.6040499 0.5927084 ] [0.8403308 0.291448 ] [0.04195209 0.95504093] [0.79433376 0.21279709] [0.79433376 0.21279709] [0.01326967 0.9891382 ] [0.0153821 0.9867737 ] [0.79433376 0.21279709] [0.01617167 0.98520505] [0.01351487 0.98596036] [0.01473185 0.9846144 ] [0.00896762 0.9899838 ] [0.00936404 0.9893628 ]] Is there something I didn't get? Code: model_05_01 = Sequential() model_05_01.add(Conv1D(filters=16, kernel_size=12, input_shape=(x_train.shape[1], 1))) model_05_01.add(MaxPooling1D(pool_size=4)) model_05_01.add(Conv1D(filters=32, kernel_size=12)) model_05_01.add(MaxPooling1D(pool_size=4)) model_05_01.add(Conv1D(filters=16, kernel_size=12)) model_05_01.add(MaxPooling1D(pool_size=4)) model_05_01.add(Flatten()) model_05_01.add(Dense(16, activation='relu')) model_05_01.add(Dense(2, activation='sigmoid')) model_05_01.compile(loss='logcosh', optimizer='adam', metrics=['accuracy'])
