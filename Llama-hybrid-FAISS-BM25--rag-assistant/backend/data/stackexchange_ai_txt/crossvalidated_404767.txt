[site]: crossvalidated
[post_id]: 404767
[parent_id]: 
[tags]: 
How to pass from {Probability density function, convolution} to {Probability density function, characteristic function}?

In Forsman, W.C. (1986) "Polymers in solution: theoretical considerations and newer methods of characterization", Springer, New York. https://www.springer.com/la/book/9780306421464 page 24, it states: it follows directly from $P(X=x_1+x_2) = P_1(x_1) * P_2(x_2)$ (*: convolution) that the characteristic function of $P(X=x_1+x_2)$ is just the product of the characteristic functions of the $P_i(X_i)$ . I understand the following: p(x+y)=(p_x * p_y)(τ) ≡ p_x(τ) * p_y(τ) ≡ ∫p_x (t) p_y (τ-t)dt. But I can't establish the connection in "it follows directly from" part. Namely, passage from {Probability density function, convolution} to {Probability density function, characteristic function}. Can someone detail the "follows directly" part? In Battin 1999, "An Introduction to the Mathematics and Methods of Astrodynamics, Revised Edition (AIAA Education)" page 726, it is written: $$ \phi_{X+Y}(t) = E(e^{it(X+Y)})= E(e^{itX}e^{itY}) =E(e^{itX})E(e^{itY}) (since X and Y are independent) =\phi_{X}(t)\phi_{Y}(t) $$ So, why convolution is ever mentioned? Why that messy stuff there? What I found: 1. http://elib.sfu-kras.ru/bitstream/handle/2311/20241/fateev.pdf It is known that the characteristic function of the sum of independent random variables is equal to the the (Erdogan: Two "the" here; smt is missing) characteristic functions of the terms, while the density of the probability distribution of the sum is the convolution operation using the probability density function of terms. 2. Whuber's idea: $$ P(X=x_1+x_2) = P_1(x_1) * P_2(x_2) $$ (Here, $x_1$ and $x_2$ are two random variables; $X$ is the sum of the random variables.) Now, take the Fourier transformation of each side, $$\mathcal{F} ( P(X=x_1+x_2) ) = \mathcal{F} (P_1(x_1) * P_2(x_2)) $$ Apply "Fourier transformation turns convoluiton into multiplication": $$\mathcal{F} ( P(X=x_1+x_2) ) = \mathcal{F} (P_1(x_1)) \mathcal{F} (P_2(x_2)) $$ Apply the inverse Fourier transformation: $$\mathcal{F}^{-1}\mathcal{F} ( P(X=x_1+x_2) ) = \mathcal{F}^{-1}(\mathcal{F} (P_1(x_1)) \mathcal{F} (P_2(x_2))) $$ The remaining issues in my mind: 1. Does the applying F^-1 and F consecutively may result in direct cancellation, or with 1/(2Pi) constant? 2. On the right hand side, there is $$ \mathcal{F}^{-1}(\mathcal{F} (P_1(...)) \mathcal{F} (P_2(...))) $$ , but not $$ \mathcal{F}^{-1}(\mathcal{F} (P_1(...)P_2(...)) $$ . What about the cancellation on the right hand side? 3. (neat explanation of the problem) I know "the characteristic function of the random variable $x$ is the inverse Fourier transformation of the pdf of the random variable $x$ (when $$ \sqrt{2\pi} $$ coefficient ignored)". $$ P(X=x_1+x_2) = P_1(x_1) * P_2(x_2) $$ Take the inverse Fourier transformation of each side: $$ \mathcal{F}^{-1} (P(X=x_1+x_2)) = \mathcal{F}^{-1}( P_1(x_1) * P_2(x_2) )$$ $$ \mathcal{F}^{-1} (P(X=x_1+x_2)) = \mathcal{F}^{-1}( P_1(x_1)) \mathcal{F}^{-1}( P_2(x_2) )$$ $$ \phi_{x_1+x_2}(t) = \phi_{x_1}(t)\phi_{x_2}(t) $$ So, "the characteristic function of $X=x_1+x_2$ is the product of the characteristic functions of the $X_i$ " is OK. But, what Forsman says is "the characteristic function of $P(X=x_1+x_2)$ is just the product of the characteristic functions of the $P_i(X_i)$ (i.e. the following expression)" is somewhat misleading? $$ \phi_{P(X = x_1 + x_2)}(t) = \phi_{P(x_1)}(t)\phi_{P(x_2)}(t) $$ By the above last paragraph, I hope I fully depicted the problem at last.
