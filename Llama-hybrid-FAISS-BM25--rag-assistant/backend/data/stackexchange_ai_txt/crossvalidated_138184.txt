[site]: crossvalidated
[post_id]: 138184
[parent_id]: 138154
[tags]: 
You can check the conditions for stationarity using his definition. A little above the definition it is mentioned that the $\epsilon_{t}$ are iid with mean zero and variance $\Omega$ (implicitly assumed finite). Hence, thanks to the convergence conditions mentioned in the defintion, it is OK to compute $$ E(Y_t)= \sum_{i=0}^\infty C_iE(\epsilon_{t-i})=0$$ and similarly for the (autoco-)variance(s). As the moments do not depend on $t$, we have stationarity. In fact, citing Brockwell/Davis, Introduction to Time Series and Forecasting, p51: The class of linear time series models, which includes the class of autoregressive moving-average (ARMA) models, provides a general framework for studying stationary processes. In fact, every second-order stationary process is either a linear process or can be transformed to a linear process by subtracting a deterministic component. This result is known as Woldâ€™s decomposition and is discussed in Section 2.6.
