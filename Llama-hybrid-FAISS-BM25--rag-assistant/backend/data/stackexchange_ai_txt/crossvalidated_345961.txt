[site]: crossvalidated
[post_id]: 345961
[parent_id]: 345737
[tags]: 
To clarify my thinking: Say we are using a large Deep NNet to try to model our data, but the data set is small and could actually be modeled by a linear model. Then why don't the network weights converge in such a way that one neuron simulates the linear regression and all the others converge to zeros? Why doesn't regularization help with this? Neural nets can be trained like this. If proper L1 regularization used then much of the weights can be zeroed and this will make neural nets behave like concatenation of 1 or so linear regression neurons and many other zero nerons. So yes - L1/L2 regularizations or like that can be used to restrict the size or representational power of the neural network. Actually the size of the model itself is a kind of regularization - if you make model large, it means that you injects a prior knowledge about the problem, that is, the problems is highly complex so it requires model that have high representational power. If you make model small, then it means you injects knowledge that the problem is simple so model don't need much capacity. And this means L2 regularization will not make networks "sparse" as you described, because L2 regularization injects prior knowledge that contribution of each neuron (weight) should be small but non-zero. So network would use each of the neurons rather than use only small set of neurons.
