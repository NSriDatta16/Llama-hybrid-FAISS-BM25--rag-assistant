[site]: datascience
[post_id]: 29885
[parent_id]: 
[tags]: 
XGBoost equations (for dummies)

I am having a hard time trying to understand the MSE loss function given in the Introduction to Boosted Trees (beware! My maths skills are the equivalent of a very sparse matrix): $ \begin{split}\text{obj}^{(t)} & = \sum_{i=1}^n (y_i - (\hat{y}_i^{(t-1)} + f_t(x_i)))^2 + \sum_{i=1}^t\Omega(f_i) \\ & = \sum_{i=1}^n [2(\hat{y}_i^{(t-1)} - y_i)f_t(x_i) + f_t(x_i)^2] + \Omega(f_t) + constant \end{split} $ The second equality sign implies that one could easily derive the second equation from the first one, but I cannot see how. My first na√Øve attempt was to: express $y_i$ as $a$ express $(\hat{y}_i^{(t-1)} + f_t(x_i))$ as $b$ and then expand $(a-b)^2$ But I wasn't successful. Any help is really appreciated.
