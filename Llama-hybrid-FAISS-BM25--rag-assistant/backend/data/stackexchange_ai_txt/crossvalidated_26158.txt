[site]: crossvalidated
[post_id]: 26158
[parent_id]: 26107
[tags]: 
I don't think you're going to get a lot of benefit here, at least in situations where the mean is not very informative about the variance. In these situations, whether the $X_i$ vary about a number close to $\bar X$ or close to $\hat X$ is not very helpful in determining how much they vary. To see this in the algebra, notice that $$ V_2 = \frac{1}{N-1}(\sum X_i - \hat X)^2 = \frac{1}{N-1}(\sum_i X_i - \bar X + \bar X - \hat X)^2 $$ meaning we can write it as $$ V_1 + \frac{N}{N-1}(\bar X - \hat X)^2. $$ Also, if you have $K$ different estimates of the same quantity, optimality is usually obtained by taking their weighted average, where the weights are proportional to the inverse of their (co)variance. The Gauss Markov Theorem is the main result, and its generalization by Aitken . NB for a situation where the mean is very informative about the variance, use binary $X_i$, where if you know the mean you know the variance.
