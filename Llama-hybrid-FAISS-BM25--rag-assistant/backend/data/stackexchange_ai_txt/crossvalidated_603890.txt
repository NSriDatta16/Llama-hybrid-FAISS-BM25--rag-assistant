[site]: crossvalidated
[post_id]: 603890
[parent_id]: 
[tags]: 
How to Redress an Invalid Logistic Regression

Recently I ran a logistic regression model using the census data here . The model attempts to assess the relationship between female labor force participation and other variables. Here is the code I used to create the model: library(tidyverse) library(stargazer) library(ggplot2) library(ggpubr) library(dplyr) library(haven) library(tidyr) individu % filter(sexe==2 & AGE5>=25) %>% select(AGE5, TY_ACT, NIV_ET_AGR, E_MAT, mil, reg, ENF_VIV) %>% rename_all(funs(c("Age","Act","Edu","Mar","Loc","Reg","Kid"))) %>% mutate(across(c("Edu","Mar","Loc"), as_factor)) %>% mutate(Kid = ifelse(is.na(Kid), 0, Kid)) %>% mutate(Act = ifelse(Act == 0, 1, 0)) %>% mutate(Edu = fct_drop(Edu)) %>% mutate(Mar = fct_drop(Mar)) %>% mutate(Loc = fct_drop(Loc)) %>% na.omit() newdata $Edu Edu, "Aucun niveau d'études" = "No Education", "Préscolaire" = "Preschool", "Primaire" = "Primary Sch.", "Secondaire collégial" = "Middle Sch.", "Secondaire qualifiant" = "High Sch.", "Supérieur" = "University") newdata $Mar Mar, "Célibataire" = "Single", "Marié" = "Married", "Divorcé" = "Divorced", "Veuf" = "Widow") newdata $Loc Loc, "Urbain" = "Urban") # Run the general model main_model Which gave me the following results: > summary(main_model) Call: glm(formula = Act ~ Age + I(Age^2) + Edu + Mar + Kid + Loc, family = binomial(link = "logit"), data = newdata) Deviance Residuals: Min 1Q Median 3Q Max -2.0413 -0.5466 -0.3897 -0.2084 3.6565 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -5.216e+00 4.054e-02 -128.665 However, when I followed the steps in this website to assess the statistical validity of my model, I found results suggesting that my model is not statistically very sound: # Hosmer-Lemeshow Test: The p.value should be high. > > ResourceSelection::hoslem.test(newdata$Act, fitted(main_model)) Hosmer and Lemeshow goodness of fit (GOF) test data: newdata$Act, fitted(main_model) X-squared = 2414.8, df = 8, p-value # Pseudo R^2: this should be close to 1, ideally. > > DescTools::PseudoR2(main_model, which = 'Nagelkerke') Nagelkerke 0.2642365 > # Residuals plot > > dev_res dev_res_std pearson_res pearson_res_std par(mfrow=c(1, 2)) > plot(density(pearson_res), main='Deviance (red) v. Pearson Residuals') > lines(density(dev_res), col='red') > plot(density(pearson_res_std), main='Deviance Standardized (red) v.\n Pearson Standardized Residuals') > lines(density(dev_res_std), col='red') Therefore I would like to know: is this because my response variable Act is not balanced (0: 84%, 1: 16%)? If so, how do I extract a sample that is balanced as per the variable Act , but also balanced by region. Any help would be very much appreciated. PS: I wanted to use the BalancedSampling library, it can create a balanced sample by region, but I don't think it will guarantee the proportions of Act will be balanced. EDIT 0: I created a balanced sample, i.e. one with 100,000 observations with Act==0 , and 100,000 observations with Act==1 . The problem persists, and the deviance graph looks like this: EDIT 1: Following the links in the first comment, which argue against the use of R^2 and Hosmer-Lemeshow test to measure the goodness-of-fit, and propose their own measures instead, I installed the rms package to check the goodness of fit as measured by their resid function. It gave me the following results: > lrm_one resid(lrm_one, "gof") Sum of squared errors Expected value|H0 SD Z P 1.004713e+05 1.003799e+05 2.218171e+01 4.121127e+00 3.770231e-05 The p.value is very small and the model is not good. Therefore it is clear that the problem is in my model, not in how I measure the goodness of fit. The residuals plots generated by rms are also similar to the ones above.
