[site]: crossvalidated
[post_id]: 156889
[parent_id]: 156888
[tags]: 
Why does the linear test static of GLM follow F-distribution? It doesn't . Then, the test statistic will follow an $F$ -distribution [...] does this hold for all generalized linear models? There's no result that establishes it in the general case, and indeed we can show (e.g. by simulation in particular instances) that it's not the case in general. It holds for the Gaussian case, of course, but the derivation relies on the normality of the data. You can see it's not the case for logistic regression, since the data (and hence "F"-statistics based on the data) are discrete. There is an asymptotic chi square result . This, combined with Slutsky's theorem should give us that the F-statistic will asymptotically be distributed as a scaled chi-square. However, in sufficiently large samples (where how large " large " is will depend on a number of things), we might anticipate that The F distribution would still be approximately correct, since both the $F$ distribution being used to figure out p-values, and the actual distribution of the test statistic are both going to the same scaled chi-square distribution asymptotically. We see the same issue with the common use of t-tests for parameter significance in GLMs (which many packages do) even though it's only t-distributed for the Gaussian case; for the others we only have an asymptotic normal result (but a similar argument for why the $t$ shouldn't do badly in sufficiently large samples can be made). I don't have a good book suggestion. Some books give a handwavy argument for using the $F$ (some akin to mine above), others seem to ignore the need to justify it at all.
