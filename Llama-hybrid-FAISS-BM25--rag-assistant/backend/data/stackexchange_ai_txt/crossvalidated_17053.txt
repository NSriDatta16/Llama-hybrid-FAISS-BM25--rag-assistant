[site]: crossvalidated
[post_id]: 17053
[parent_id]: 17052
[tags]: 
You can use predict() for that. You need the model fitted to the training data, and the data from your test group. With type="response" , you'll get the predicted probabilities, the default is the predicted logits. # generate some data for a logistic regression, all observations x all remaining obs # if idxTrn were a logical index vector, this would just be idxTst Now you may compare the predicted probabilities against actuall class values however you like. You may set a threshold for categorizing the predicted probabilities, and compare actual against predicted category memberships. > thresh predFac cTab addmargins(cTab) predicted actual lo hi Sum lo 12 4 16 hi 5 9 14 Sum 17 13 30 Note that the dataframe supplied to predict() needs to have the same variable names as the df used in the call to glm() , and the factors need to have the same levels in the same order. If you're interested in k-fold cross validation, have a look at the cv.glm() function from package boot .
