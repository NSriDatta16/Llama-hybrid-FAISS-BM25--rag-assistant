[site]: datascience
[post_id]: 92884
[parent_id]: 92882
[tags]: 
More data could potentially lead to more epochs required to find the best model. The number of epochs to reach the minimum loss will vary depending on your hyperparameters, dataset, and initial weights. I would get out of the mindset of trying to find the exact number of epochs required. Most popular deep learning libraries will allow you to stop training if the loss converges after a certain length of epochs. Additionally, if you overfit, you can create a callback function to save the best model only.
