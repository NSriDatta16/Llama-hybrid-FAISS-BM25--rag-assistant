[site]: crossvalidated
[post_id]: 155723
[parent_id]: 155720
[tags]: 
Going by your picture, it looks like what you are proposing is to stratify your data into layers depending on the value of $Y$, then compute the standard deviation of $X$ in each layer, then use that computed group standard deviation as a predictor. This leaks the true value of $Y$ into your predictors . Of course your model is more accurate, you've essentially allowed it to memorize the value of $Y$ by giving it a dictionary whose "words" are $\sigma(X)$ and whose "definitions" are $Y$. Consider what happens if you are given a new dataset with only the values of $X$, and you want to make a prediction of $Y$. How are you going to use your new $\sigma(X)$ predictor in this situation? You need to know $Y$ to stratify $X$ and compute $\sigma(X)$ for each group! Now, if you can define your groups without reference to $Y$, that's a different thing. ok, what i don't understand still is the "leaking the value of Y into your predictors" because in the end every model uses the Y values to calculate its coefficients, so what's the difference? You're completely correct, all regressions use the values of $Y$ to calculate their coefficients. Writing out the dependencies in detail, this looks like $$ Y = \beta_0(X, Y) + \beta_1(X, Y) X_1 + \cdots + \beta_n(X, Y) X_N $$ each coefficient is a function of $Y$ (more precisely, the values of $Y$ in the training data), but each predictor is not. In your case, you are creating a predictor that is a function of both $X$ and $Y$. This is what I mean by "leaks the true value of Y into your predictors". But let's assume that my method is not valid. However it gives me the smallest errors in a cross validation procedure for prediction. Yes, it is not surprising that your cross validation error is lower. Unfortunately, your application of cross validation is incorrect. The correct procedure would be this Split your data into in fold and out of fold pairs. For each pair, compute your features using only the in fold data . Make predictions on the out of fold data using only the values of $X$ , or features that are functions of $X$. Average the out of fold error rates of these predictions. Your procedure violates the second and third bullet points. I'd recommend taking a look at the section of Chapter 7 in The Elements of Statistical Learning titled The Wrong and Right Way to Do Cross-validation . my stat teacher used to tell us "if you can create a predictor which is better, you don't need to explain people how you created it" I don't mean to contradict your teacher without full context, but as stated, that is dubious advice.
