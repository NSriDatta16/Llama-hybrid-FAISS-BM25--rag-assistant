[site]: datascience
[post_id]: 12073
[parent_id]: 
[tags]: 
Redundancy - is it a big problem?

I am trying to create a sentiment analysis program which will classify some of the tweets which i have collected under a hashtag. There are 7750 tweets in the dataset and I am labeling them into the two classes now. Then I will use a neural network to classify them into positive and negative classes. The problem with the dataset is that it posses a lot of redundant data (Retweets basically). Manually deleting them is not possible and I have tried to find a programmable solution via the Tweepy API but couldn't find any. So my question is do I need to get rid of these redundant records or should i leave them as is?
