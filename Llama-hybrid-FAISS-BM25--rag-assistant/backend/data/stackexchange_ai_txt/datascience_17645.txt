[site]: datascience
[post_id]: 17645
[parent_id]: 
[tags]: 
Is Overfitting a problem in Unsupervised learning?

I come to this question as I read the use of PCA to reduce overfitting is a bad practice. That is because PCA does not consider labels/output classes and so Regularization is always preferred. That seems purely valid in Supervised Learning. What about the case for Unsupervised Learning ? We don't have any labels whatsoever. So 2 questions. Is overfitting a problem in Unsupervised learning? If yes, Can we use PCA to prevent overfitting?Is that a good practice?
