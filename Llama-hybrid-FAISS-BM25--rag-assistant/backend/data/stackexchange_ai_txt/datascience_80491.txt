[site]: datascience
[post_id]: 80491
[parent_id]: 
[tags]: 
Does LSTM without delayed inputs work as a deep net?

I want to predict a multivariate time series. My time series is $a_1(t),...,a_k(t)$ and I want to predict $a_k(t)$ . I use the following keras LSTM: model = Sequential() model.add(LSTM(90,return_sequences=True,input_shape=(train_X.shape[1], train_X.shape[2]))) model.add(LSTM(90)) model.add(Dense(1)) I use $a_1(t),...,a_{k-1}(t)$ as input and $a_k(t)$ as output to train it. So I don't use delayed inputs like $a_s(t-l)$ . My qestion is in this situation, Does LSTM work as a deep neural network? i.e. Is it same as the following keras net? model.add(Dense(90, input_dim=12)) model.add(Dense(90)) model.add(Dense(1))
