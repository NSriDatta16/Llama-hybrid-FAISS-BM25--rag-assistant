[site]: datascience
[post_id]: 121753
[parent_id]: 
[tags]: 
How to represent varying reliability of ratios calculations in a dataset?

I want to predict whether the client will renew his/her subscription based on groceries consumption patterns. Suppose an order contain only one type of grocery. I have a DataFrame containing ratios of values for different types of groceries for each client and the total number of orders. Each ratio represents the number of groceries of a specific type divided by the total number of groceries ordered. However, the reliability of these ratios varies based on the total number of orders. For example, if a client has only placed one order of a particular type, the ratio for that type will be 100%. However, if another client has placed 97 orders of the same type with 100 orders in total, the ratio would be 0.97%. Client ID Total Orders Type A Ratio Type B Ratio Type C Ratio 0 1 1.00 0.00 0.00 1 100 0.97 0.01 0.02 2 5 0.60 0.20 0.10 3 10 0.30 0.50 0.20 4 50 0.80 0.20 0.00 I am training a machine learning model using XGBoost, but I am struggling to capture the relationship between the ratios and the total number of groceries to weight reliability of ratios. It appears that the model is not effectively learning this relational information. Client 1 ratio on type A groceries is more reliable than client 0 but a model appears to only see that the ratio for Client 0 is larger than Client 1. I would appreciate any suggestions on how to address this issue. How can I incorporate the varying reliability of the ratios into my machine learning model? Are there any techniques or approaches that can help the model learn the importance of different ratios based on their reliability? Thank you in advance for your assistance!
