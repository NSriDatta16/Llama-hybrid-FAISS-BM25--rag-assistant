[site]: stackoverflow
[post_id]: 4276957
[parent_id]: 
[tags]: 
How to configure robots.txt to allow everything?

My robots.txt in Google Webmaster Tools shows the following values: User-agent: * Allow: / What does it mean? I don't have enough knowledge about it, so looking for your help. I want to allow all robots to crawl my website, is this the right configuration?
