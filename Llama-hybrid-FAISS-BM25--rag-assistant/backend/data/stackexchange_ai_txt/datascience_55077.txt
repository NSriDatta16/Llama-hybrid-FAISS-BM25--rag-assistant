[site]: datascience
[post_id]: 55077
[parent_id]: 55039
[tags]: 
Bayesian optimisation is sequential in the sense that you need to know the value of the function for n point to decide through an acquisition criteria the next point to evaluate. Maybe you could customize it to your problem so that the acquisition returns not one point but a batch of them, which you distribute at the next step. You can also use an hybrid method. First run a classic grid search, distributed, and evaluate the function at many many points. Feed all this knowledge (points and objective value at these points) to a classic bayesian optimiser which will pick points one by one and finer tune the optimisation here. Not as optimal as the former, but less implementation work here.
