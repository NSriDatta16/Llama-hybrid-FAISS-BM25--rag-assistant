[site]: crossvalidated
[post_id]: 60961
[parent_id]: 60939
[tags]: 
It is hard to make specific suggestions without knowing more information about the exact problem you are attempting to solve. However, I will make a few recommendations for general time series prediction. First, it is important to note that independence of observations is often a poor assumption for time series due to serial correlation of observations. Additionally, assuming that the time series is stationary may or may not be a good assumption. These issues complicate the partitioning of your data into training, cross-validation, and test sets. If there is a significant degree of autocorrelation this will reduce your effective sample size and increase your chances of over fitting, especially for complex machine learning algorithms like multilayer neural networks that have many tunable weights. Also, autocorrelation affects how you split your data set. If you randomly sample from your entire data set to create cross-validation and testing sets, then you will likely introduce a look-ahead bias into your out-of-sample error estimates. This happens because the out-of-sample data sets have points that are temporally adjacent to in-sample data points. This violates the independence assumption if there is significant autocorrelation and will artificially reduce your out-of-sample error estimates. This problem often leads to splitting the data set at a particular time point so that every observation before the split is training and every observation after the split is cross-validation/testing. This alleviates some of the issues with autocorrelation, but adds other complications if the in-sample time series differs significantly from the out-of-sample time series (non-stationary time series). Considering the issues above, I would start as simple as possible and work my way up in complexity as needed. I would start by temporally splitting my data set into an in-sample and out-of-sample set, making sure that the out-of-sample contained similar cycles and statistical properties as the in-sample set. Then I would approach the in-sample data set with a Random Forest. Not knowing the size of your data set, 20 input variables may be a conservative use of your degrees of freedom. However, due to the negative effects of autocorrelation on your effective sample size, I would apply a random forest to the data set to get an estimate of variable importance. Knowing the relative importance of your inputs might help you eliminate some of your weaker inputs and free up more degrees of freedom. This site is a good intro for using random forests for variable importance estimates , and this paper discusses key pitfalls of conducting variable ranking . Random forests also have the advantage that you can pull out individual decision trees and understand the classification process by following the branches of the tree. This process of examining several of the forestâ€™s decision trees can be very insightful and lead to better choices for the final classification algorithm. Neural networks and SVMs are less easy to interpret than random forests. Random forests also require less pre-processing of data than other machine learning algorithms, making them an approachable first step. Using a random forest does have the drawback that it randomly splits data into out-of-bag (OOB) and in-bag samples for each decision tree. This random splitting will lead to bias in the OOB error estimate of the forest if your time series has significant autocorrelation. However, you can confine this bias to the in-sample data set by only running the random forest on it and preserving the out-of-sample data set for actual error estimation. A random forest may provide you with enough power for your classification problem. However if you are looking for more improvement, I would proceed next by constructing a logistic regression using the variables deemed most important by the random forest. At this point, you have already used your in-sample data for variable selection and for insights by examining decision trees. However, you are probably safe splitting the in-sample data into training and cross-validation sets and then using learning curves to decide how complex you should make your classification algorithm. Start with a simple logistic regression, if you are still observing high bias via your learning curve, then you might consider moving to a multi-node, single layer neural network and repeating the process. Or you might consider using a SVM with a RBF kernel. This post touches on the differences between neural nets and SVMs . These choices will really be driven by the specifics of your problem and the availability of more data if you do encounter high variance in your final classification algorithm. Also, the complexity of your final classification algorithm will be governed by performance on cross-validation, but you should aim for the simplest solution that provides reasonable performance.
