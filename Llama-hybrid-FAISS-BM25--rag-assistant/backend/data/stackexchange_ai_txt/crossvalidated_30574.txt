[site]: crossvalidated
[post_id]: 30574
[parent_id]: 
[tags]: 
(Non-linear) Transformation of confidence interval for multinomial parameters

I have a certain computational biology problem I wish to model. Say I have a vector $\vec{f}$ that yields $\vec{p}$, of which the explicit form amounts to picking $\vec{p}$ as an eigenvector from an eigenvalue-problem with the largest associated eigenvalue. $\vec{p}$ is a probability vector, i.e. its components sum to 1. I now have a multinomial distribution with $\vec{p}$ as the parameter. The data I have consists of $N$ samples from this multinomial distribution. As is the case in statistics, I do not know $\vec{p}$ (or $\vec{f}$ for that matter). Say I can construct some confidence interval for $\vec{p}$ of the multinomial distribution (there are a number of methods in literature), how do I transform this confidence interval to $\vec{f}$? The function is defined as $\vec{f} = \vec{h}(\vec{p}) = \left( Q^T diag\left( \vec{p} \right) \right)^{-1} \vec{p}$, where $Q$ is a stochastic transition matrix, i.e. its rows sum to 1. I know that if the transformation is monotonic, the boundaries maybe simply be transformed to yield a confidence interval for $\vec{f}$. So far I have linearised $\vec{h}(\vec{p})$ around $\hat{p}$ and used this with okayish results, but there remain some substantial departures from 'optimal' confidence intervals as observed from non-parametric bootstrap samples. Ultimately, I would like to work in this framework, and if possible not go to Bayesian (or non-parametric bootstrapping), as the dimensionality of the problem will scale up (realistically $\vec{f}$ might be 1000-dimensional or so). Thanks for any suggestions.
