[site]: crossvalidated
[post_id]: 612429
[parent_id]: 
[tags]: 
Statistical test to compare models results for concordance index

I'm working on a model for survival prediction and using the concordance index to evaluate the results ( https://medium.com/analytics-vidhya/concordance-index-72298c11eac7 ) . I want to show that my model is better than a baseline model using my test set. My understanding is that for a typical test metric (ie prediction of housing prices for example ) one could use the Wilcoxson signed rank test to see if my model is statistically significantly better than a baseline model. However, in this case, the concordance metric doesn't have any meaning for a single sample-- it's a description of how well the model can discriminate ordering amongst a set of inputs. Therefore, is doing the following valid: divide test set into batches, get each model's prediction on each batch, and run the wilcoxon signed-rank test on the predictions on the batches? Perhaps also vary batch size and shuffle the samples and run the test again to verify the result still holds? Clarifications: I should have clarified that I'm not use the Harrel C-index but the adjusted Antolini index. I know the Harrel C-index is not often used anymore. The baseline model is a machine learning model that provides decent values. My model is also the same type of machine learning model but trained differently . The two models have the exact same architecture, and therefore the same set of predictors (just different weights on the predictors since the two models were trained differently).
