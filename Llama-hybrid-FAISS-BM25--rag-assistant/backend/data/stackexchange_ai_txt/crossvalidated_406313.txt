[site]: crossvalidated
[post_id]: 406313
[parent_id]: 405041
[tags]: 
Usually in biomedical research, we don't use a training set---we just apply logistic regression on the full dataset to see which predictors are significant risk factors for the outcome we're looking at; or to look at one predictor of interest while controlling for the effect of other possible predictors on the outcome. I'm not sure quite what you mean by threshold values, but there are various parameters that one may seek to optimize: AUC, cutoff values for a dichotomizing a continuous predictor variable, positive and negative predictive values, confidence intervals and p-values, false positive and false negative rates. Logistic regression looks at a population of subjects and assesses the strength and causal direction of risk factors that contribute to the outcome of interest in that population. It's also possible to "run it in reverse," so to speak, and determine an individual's risk of the outcome given the risk factors that the individual has. Logistic regression assigns each individual a risk of the outcome, based on their individual risk factors, and by default this is 0.5. If a subject's probability of having the outcome (based on all the data and subjects in your model) is 0.5 or above, it predicts he will have the outcome; if below 0.5 then it predicts he won't. But you can adjust this cutoff level, for example to flag more individuals who might be at risk of having the outcome, albeit at the price of having more false positives being predicted by the model. You can adjust this cutoff level to optimize screening decisions in order to predict which individuals would be advised to have further medical followup, for example; and to construct your positive predictive value, negative predictive value, and false negative and false positive rates for a screening test based on the logistic regression model. You can develop the model on half your dataset and test it on the other half, but you don't really have to (and doing so will cut your 'training' data in half and thus reduce the power to find significant predictors in the model). So yes, you can 'train the whole thing end to end'. Of course, in biomedical research, you would want to validate it on another population, another data set before saying your results can be generalized to a wider population. Another approach is to use a bootstrapping-type approach where you run your model on a subsample of your study population, then replace those subjects back into the pool and repeat with another sample, many times (typically 1000 times). If you get significant results a prescribed majority of the time (e.g. 95% of the time) then your model can be deemed validated---at least on your own data. But again, the smaller the study population you run your model on, the less likely it will be that some predictors will be statistically significant risk factors for the outcome. This is especially true for biomedical studies with limited numbers of participants. Using half of your data to 'train' your model and then 'validating' it on the other half is an unnecessary burden. You don't do that for t-tests or linear regression, so why do it in logistic regression? The most it will do is let you say 'yeah it works' but if you use your full dataset then you determine that anyway. Breaking your data into smaller datasets runs the risk of not detecting significant risk factors in the study population (OR the validation population) when they are in fact present, due to small sample size, having too many predictors for your study size, and the possibility that your 'validation sample' will show no associations just from chance. The logic behind the 'train then validate' approach seems to be that if the risk factors you identify as significant aren't strong enough, then they won't be statistically significant when modeled on some randomly-chosen half of your data. But that randomly-chosen sample might happen to show no association just by chance, or because it is too small for the risk factor(s) to be statistically significant. But it's the magnitude of the risk factor(s) AND their statistical significance which determine their importance and for that reason it's best to use your full dataset to build your model with. Statistical significance will become less significant with smaller sample sizes, as it does with most statistical tests. Doing logistic regression is an art almost as much as a statistical science. There are different approaches to use and different parameters to optimize depending on your study design.
