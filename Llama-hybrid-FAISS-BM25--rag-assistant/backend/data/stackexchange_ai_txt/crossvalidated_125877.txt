[site]: crossvalidated
[post_id]: 125877
[parent_id]: 
[tags]: 
For the given type of dataset, what would generally be the set of classifiers that should be tried to get the highest TPR for FPR = 0.01

I'm primarily looking to attain the maximum True Positive Rate for a small False positive Rate of say 0.01. The following is an instance: 1, 37.33, 228.39, 0, 77.060599, 0.073384, 0.052536, 1.389826, 0.526793, -0.806316, 20.302738, 6 There are 100k instances of each class available. I understand that a thorough experimentation can be required, but what would be your first set of classifiers to attack this classification problem? I have tried the default scikit-learn implementations of Random Forests, Gradient Boosted Classifier and Stochastic Gradient Descent with logistic loss function. As of now RF seems to be leading. But is it possible for SGD to beat RF at larger datasets? Or is there anything else that has any real chance of beating RF in this case?
