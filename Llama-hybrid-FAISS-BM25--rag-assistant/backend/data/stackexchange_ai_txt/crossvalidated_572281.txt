[site]: crossvalidated
[post_id]: 572281
[parent_id]: 
[tags]: 
Training on biased dataset, when the bias is quantitively known

I have a machine learning model (A neural network here) which minimizes MSE loss. The model should fallow an unbiased distribution. Nevertheless, the training set is biased, but fortunately by a known factor $w$ . Let's assume my dataset as $$X = {x_1, x_2, x_3 ... x_N}$$ where $N$ is a number of points in the dataset. Also I have a corresponding set of factors: $$W = {w_1, w_2, w_3 ... w_N}$$ where the index corresponds to the same point/example in the dataset. The weights are normalized between 0 .. 1 and they sum to 1. Basically every $w_i = P_{unbiased, i}/P_{biased, i} $ is a fraction of probability of drawing sample $i$ from unbiased distribution with respect to biased. So $w_i = 0.01$ means that it's 0.01 less populated in the unbiased dataset than the current one. How I should unbias my training, so that the model will fallow unbiased distribution of my data ? Is this the same kind of problem as training on the unbalanced dataset ? If second is true, two things come to my mind, but I don't know if they're right. Replicate data according to the weight - but this wilk take additional resources to train For every example, bias loss function according to $w_i$
