[site]: crossvalidated
[post_id]: 637700
[parent_id]: 637157
[tags]: 
I present a second analysis using a Bayesian hierarchical model to estimate the failure probabilities of the seven sets as well as the mean failure probability in the population of sets. The advantages of the Bayesian approach include: We estimate the joint posterior distribution of the failure probabilities, $p_1, \ldots, p_7$ , by generating samples $\{ p_i^{(j)} \}$ from the posterior. With that sample, we can estimate the posterior distribution of any function of the $p_i$ 's. For comparison with the other answer, I look at the the difference between the failure probability of the 5th set and the average failure probability of the other six sets: $p_5 - (p_1 + \cdots + p_7)/6$ . We explicitly incorporate domain knowledge and assumptions into the prior. For example, if we have used filters made by the filter manufacturer before, we would have an idea how often their filters fail. Or more generally, based on the literature / previous research, we can make an informed guess what's a reasonable range for the failure probability of a filter of type X or made with material Y and choose a prior that puts most of its probability mass on that range. Specifically I propose the following hierarchical model for the failure probabilities of $k$ sets: ( $X_k$ and $N_k$ are the number of failures and the number of tests, respectively.) $$ \begin{aligned} X_k &\sim \operatorname{binomial}(N_k, p_k) \\ p_k &\sim \operatorname{normal}(\mu_p, \sigma_p)\operatorname{T}[0,1] \\ \mu_p &\sim \operatorname{beta}(1, 24) \\ \sigma_p &\sim \operatorname{student-t}(3, 0, 1)\operatorname{T}[0,] \end{aligned} $$ where $\operatorname{T}[\text{lower}, \text{upper}]$ indicates the parameter is constrained to the range [lower, upper]. I don't put a constraint on the population mean failure probability, $\mu_p$ , as the support of the beta distribution is (0,1); no further restriction is necessary. I choose a weakly informative student-t prior for the standard deviation, $\sigma_p$ . More interesting is the prior for the population mean probability, $\mu_p$ . I choose a informative beta prior with mean and standard deviation both equal to 0.04. It's best to specify a prior consistent with domain knowledge but since I lack such knowledge, I go with something that seems reasonable to me: the beta(1,24) distribution gives $\operatorname{Pr}(\mu_p\leq0.05) = .71$ and $\operatorname{Pr}(\mu_p\leq0.1) = .92$ . I fit this model with Stan using its cmdstanr interface; the complete code to reproduce the analysis is attached at the end. Once we have a sample from the posterior of $\{p_i,\mu_p,\sigma_p\}$ we can explore various aspects of the result. (We should first check the model converges; it does.) Here are the posteriors of the failure probabilities $\{p_1, \ldots, p_7\}$ : the posterior of the population mean failure probability $\mu_p$ : and the posterior distribution of the difference $p_5 - \sum_{i\neq5}p_i/6$ : The posterior probability that the difference is positive (i.e. set 5 has higher failure probability than the other sets) is 0.927. References This analysis is inspired by the rat tumor rate example in BDA3. A. Gelman, J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. Rubin. Bayesian Data Analysis. CRC Press , 2013. It's freely available online. library("bayesplot") library("cmdstanr") code [K] p; real mu_p; real sigma_p; } model { // priors mu_p ~ beta(1, 24); sigma_p ~ student_t(3, 0, 1); // Pool the set-specific probabilities towards the population mean probability. p ~ normal(mu_p, sigma_p); // likelihood X ~ binomial(N, p); } " # The experimental results are: x 0) mu_p
