[site]: crossvalidated
[post_id]: 63823
[parent_id]: 63787
[tags]: 
Can we compare two totally different models' likelihood functions? Not exactly, but you can compare those models using their likelihood functions indirectly by using the Akaike information criterion (AIC), the Bayesian information criterion (BIC), or the Deviance information criterion (DIC). What's the minimum of the likelihood (obviously not zero)? The likelihood function associated to some models can be lower bounded for some data sets, but this is not true in general. The only general lower bound is zero. More generally, the likelihood surface often contains flat ridges when the associated Fisher information matrix is singular at the true value of the parameters (see this paper ). What's a good guess about the maximum without going through into iterative method of estimation? There is no general rule: this is more of an optimisation problem than something related to the likelihood function. Can we build up inequality equations and claim boundaries for the likelihood function The exact likelihood is defined as a probability (see Chapter 9 of this book or Wikipedia ), then this object is upper bounded by $1$. The problem is that people typically use the continuous approximation of this function (see the aforementioned reference) which is not upper bounded in general and it might have singularities. Other interesting scenarios where the likelihood function is important: Hypothesis testing: Likelihood ratio test. Some information criteria, for example AIC, BIC, and DIC. Bayesian inference: the posterior distribution is proportional to $Likelihood\times Prior$. The profile likelihood: used to obtain interval inferences, such as confidence intervals, for the parameters of interest.
