[site]: datascience
[post_id]: 14637
[parent_id]: 14636
[tags]: 
It looks like a classical email classification problem: Spam or Ham. In the following I will use some specific slang, do not worry, look it up in Google, if you will see specific terms you do not know. Prerequisite: ideally your dataset will be "balanced", having, say, 50% cars and 50% houses, could be 40/60 as well. Problems will arise, when one class will be say So called "bag of words" can be seen as a start. Steps: Your dataset consist of two columns, say, "description" and "label" Label has only two values car or house Tokenize your decription column (single words) Cleanse the desc column: remove stop words (like and, the , a - as they do not have any value), remove punctuation, possibly stem the words, remove numbers calculate document-term-matrix, possibly use TF-IDF By the end of this operation you will have a dataset with a label column (car or house) and long number of word (or even n-gram, e.g. "great_view" is a bi-gram) columns containing binary values: Label; vehicle, balcony, wheel, ..., ...., great_view Car, 1, 0, 1, ....., ...., ..., 0 House, 0, 1, 0, ..., ..., 1 Then use naive bayes or logistic regression as a start to train your model. Pre-process every new description as above and use your trained model to assign a probability to be a "car" or a "house", check the confusion matrix, maybe adjust the threshold . Everything I described can be done e.g. in R or Python. In R use the text mining package "tm".
