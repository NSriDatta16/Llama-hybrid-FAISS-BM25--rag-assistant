[site]: crossvalidated
[post_id]: 115475
[parent_id]: 115355
[tags]: 
Because the propensity score model is purely predictive - you're not interested in any coefficients - I've always understood it than you can hurl in all your variables that affect both cohort entry and outcome. You can twist these variables as you wish - square them, root them, all types of interactions, etc. etc. - as long as you're increasing the predictive quality of your model. In theory, you shouldn't even have to worry about hold-out data for your predictive model as you have no desire to generalise these results past your sample (basically, the risk of 'overfitting' isn't a problem). Finally, you don't have to limit yourself to logistic regression; as you're modelling a binary output, you might even use a GAM model - basically, anything to improve the prediction rates. ( I must add as a contrary note to @statsRus' point on use: in my experience it's the computer scientists who use all variables while the statisticians who carefully consider each one. I guess different work backgrounds produce different working habits. ) As for use of the score, it's generally discouraged to use it as a covariate - it has less impact - and certainly not alongside the variables used to make the scoring variable. An argument might be made if, in the propensity score, you categorised a continuous variable - age for instance - where you might then include the continuous version in the model but really, don't categorise the variable the first place... Using the score for matching (with calipers - especially variable 1:N matching) is popular but I believe the most impactful technique is as Inverse Proportional Treatment Weights (IPTW) - although I've not used this method and I can't remember how it works. Try looking at Peter C. Austin's work at the University of Toronto - he's written loads of papers on propensity scores. Here's one on matching for instance.
