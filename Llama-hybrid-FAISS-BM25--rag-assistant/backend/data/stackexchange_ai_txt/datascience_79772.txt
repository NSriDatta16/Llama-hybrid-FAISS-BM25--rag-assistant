[site]: datascience
[post_id]: 79772
[parent_id]: 
[tags]: 
Can we use BERT for only word embedding and then use SVM/RNN to do intent classification?

According to this article, " Systems used for intent classification contain the following two components: Word embedding, and a classifier . " This article also evaluated BERT+SVM and Word2Vec+SVM . I'm trying to do the opposite, comparing two different classifiers (RNN and SVM) using BERT's word embedding. Most Python codes that I found use BERT for the whole intent classification problem which made me confused. Example I only want to map the words into vectors with BERT and feed the result into a classifier (SVM/RNN). Does BERT support word embedding and text classification at the same time? Does someone has an explanation? Is what I'm trying to test feasible with Python? I have a dataframe that has two columns: intent and questions. It's a small dataset. Thank you!
