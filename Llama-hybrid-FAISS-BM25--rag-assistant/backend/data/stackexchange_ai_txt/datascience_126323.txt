[site]: datascience
[post_id]: 126323
[parent_id]: 
[tags]: 
Spatio"temporal" Processing to extract Peak Positions in Data

I am working on an experimental setup that produces 2D widefield image data for each frequency in a frequency sweep. The resulting data has the Form MxNxFxC with M and N being the image pixels, F being the frequency steps and finally C being a fluorescence value of the pixel (m, n) at the frequency f. The information of interest is encoded in the frequency values of a total of 8 fluorescence dips. This is an example of three arbitrary pixels: The exact position of the dips varies slightly, as the underlying metric changes from pixel to pixel. I usually exctract the position of these dips by fitting a model to the curve. But for a large amount of pixels (1024x1024 image size) this takes quite a toll on my measurement time. Now to my question: Is it feasible to train a CNN to return a data set made up of the frequency values for each dip for each pixel or is this a problem that poses no significant increase in processing over just fitting the data? I used to convolve a basic version of the model dip with single frequency sweeps before to exctract the rough position of the dips, I assume the CNN performs something similar - at least in the first layer. What architecture for the CNN would be a good starting point to accomplish this task? Does it pose a computational advantage over "rough estimation" by just manually convolving the data traces?
