[site]: crossvalidated
[post_id]: 60889
[parent_id]: 60888
[tags]: 
PCA creates new features that can be expressed as linear combinations of the old features. Furthermore all the new features are orthogonal to each other, which prevents collinearity issues in regression. You will always get a number of principal components less than or equal to the number of input features, which is where dimensionality reduction comes into play. You can also discard the principal components that account for the least amount of variation in the original dataset. A common threshold is to keep the PCs that account for 95% of the variation in the original dataset. See also whuber's comment. PCA can also destroy the predictive accuracy of your features.
