[site]: crossvalidated
[post_id]: 328261
[parent_id]: 
[tags]: 
How do Machine Learning methods employ regularization to reduce variance?

I was reading a paper and came across this sentence: "ML methods perform well by employing regularization to reduce variance and trading off regularization bias with overfitting in practice.: I am wondering if anyone would have any insight into this sentence. I understand that regularization involves shrinkage of parameters, but I fail to see how shrinkage reduces variance and what it means to trade off the bias? Does anyone have any further insights here? Thanks.
