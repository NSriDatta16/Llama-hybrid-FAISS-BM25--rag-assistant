[site]: crossvalidated
[post_id]: 544980
[parent_id]: 
[tags]: 
Is a regression problem more prone to overfitting than a classification problem?

Assume I have N data points and their number is very limited. The output range is very vast. I can do one of the fallowing things: Fit the problem to some regression algorithm (Tree regression, neural network etc ...) The problem can be divided also to 3 classes instead, like "bad, neutral, good". The question is: which problem is more prone to over-fitting, if the data are limited in number ?
