[site]: crossvalidated
[post_id]: 71574
[parent_id]: 71565
[tags]: 
If you increase the sample size enough, the most complex model in your candidate set will have the lowest AIC (if it contains the others as special cases). The AIC is intended to pick the model with best predictive accuracy from a candidate set of models that are all wrong—i.e. approximations to the infinite-dimensional "model" that is reality. So in this context "too big" a model is one that over-reaches & ends up adding noise, for a given sample size . For a selection rule that converges on the least-complex true model among your candidate set as sample size increases, use the Bayesian information criterion (BIC)—if you think that the truth is simple enough to be among the models you're considering.
