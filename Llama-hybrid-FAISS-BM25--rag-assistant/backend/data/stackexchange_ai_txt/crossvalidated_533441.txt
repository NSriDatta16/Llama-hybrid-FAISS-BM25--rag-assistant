[site]: crossvalidated
[post_id]: 533441
[parent_id]: 
[tags]: 
Effective way to visualize the differences between various sets of data and a reference set

I'm not a stat person, so I apologize if this question is trivial. I have data obtained from several simulation methods that need to be compared to experimental data (which presumably represent the "correct" values). Something like this: Sim method 1 Sim method 2 ... Experiment result result ... result result result ... result .... .... ... .... Note that the individual numerical values for each method don't really matter -- we only care about the difference with experimental values (i.e. we're trying to determine which simulation method is closer to experiment, on average). For something like this, people simply compare RMSDs (root mean square deviations) or some other similar average of the differences. However, because I'm comparing a lot of methods (and for a lot of categories) just including a table of RMSDs would kind large and unwieldy, so I was looking for a more visually appealing way of conveying the same information. I thought box-plots (or something similar) might work well in this case, with the box centered on some sort of "average" deviation from exp. values, and error bars depecting the variance of the data points from that avarge. However, I'm not sure what's the best way to compute the average and variance here, and whether the average should be something like a simple mean or an RMSD, whether the variance should be symmetrical or assymetrical etc. I'm looking for recommendations. What is the best way to visualize this sort of data?
