[site]: crossvalidated
[post_id]: 331469
[parent_id]: 112444
[tags]: 
Your mathematics are all correct, but it is useful to distinguish between parts of your analysis that are just standard model formation pertaining to the sampling mechanism (which would also occur in classical statistics) and parts that are specific to a Bayesian analysis. The statements you have made about the allowable values of the variables, and the sampling density $f(x|p)$ are model assumptions pertaining to the sampling mechanism. They are nothing to do with the Bayesian method. Regardless of whether you are doing your analysis with Bayesian methods or classical methods, you will need to form a belief about the allowable parameter space $p \in \mathcal{P}$ and the sampling density $f (x_1, x_2, x_3, x_4 | p)$ that represents the sampling mechanism. There is no necessity in either statistical methodology to assume that the $x$ values are IID, but if you think that appropriately represents the sampling mechanism, then that assumption is fine. The specification of the sampling mechanism gives you the likelihood function $L_\boldsymbol{x}(p)$. You can proceed from this point using Bayesian methods, or classical methods (MLEs, MOMs, classical hypothesis tests etc.). If you adopt the Bayesian approach then the only additional thing you need is a prior distribution on the parameter $p$ to represent your prior uncertainty about this parameter (or if you want to do robust Bayesian analysis, you might have a set of priors distributions instead). By specifying a prior distribution for the parameter, you can derive the posterior and predictive distributions of interest. You are correct that the predictive distribution for $x_4$ is: $$f(x_4| x_1, x_2, x_3) = \int \limits_\mathcal{P} f(x_4 | p) \pi (p| x_1, x_2, x_3) dp.$$ (Since you already have a parameter called $p$, I have used the common notation $\pi$ to denote the posterior density.) Remember, Bayesian inference works by representing uncertainty about the parameters as a probabilistic belief, and then proceeding naturally from this starting point to the posterior belief. Bayesian and classical methods both start with consideration of the sampling mechanism and the resulting sampling distributions, and neither necessitate any particular form.
