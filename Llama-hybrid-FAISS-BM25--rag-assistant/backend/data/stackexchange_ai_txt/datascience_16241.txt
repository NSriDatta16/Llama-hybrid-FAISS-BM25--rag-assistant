[site]: datascience
[post_id]: 16241
[parent_id]: 16128
[tags]: 
Here is what I built... Step 1: Store all the words in a Trie data structure. Wiki about trie. Step 2: Train an RNN or RNTN to get seq2seq mapping for words and store the model Step 3: Retrieve top n words with levenshtein distance with the. Wiki about LD with the word that you are trying to correct. Naive Approach : Calculating the edit distance between the query term and every dictionary term. Very expensive. Peter Norvig's Approach : Deriving all possible terms with an edit distance Check this. Faroo's Approach: Deriving deletes only with an edit distance http://blog.faroo.com/2012/06/07 ... Step 4: Based on the previous 2 or 3 or 4 words, predict the words that are retrieved from Step 3 above. Select the number of words depending on how much accuracy you want (Of course we want 100% accuracy), and the processing power of the machine running the code, you can select the number of words you wanna consider. Check out this approach too. It's an acl paper from 2009. They call it - language independent auto correction.
