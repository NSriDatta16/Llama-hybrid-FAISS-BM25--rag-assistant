[site]: crossvalidated
[post_id]: 44070
[parent_id]: 
[tags]: 
Nelder-Mead simplex (fminsearch) and crossvalidation (cvpartition) with a nested function approach - Valid?

I have a binary classification problem with a somewhat balanced training set ( 665 TP 568 TN). SVM is the classifier of choice, and I am trying to optimize the hyperplane parameters $c$ and $g$ using Nelder-Mead simplex (fminsearch) and cross validation following a certain scheme (see below). I have a feeling that this approach is biased, but I cannot really tell how to conduct it in a better way. Is the codeflow consistent in general? (as I am nesting anonymous functions) What would be a good $c$ and $g$ range that can set in the fminsearch options? Does it make sense to create the CV partitions once in the beginning, or should I reinit them on each new fminsearch run? %create cross fold partitions c = cvpartition(classes,'kfold',kFold); %minimization function (z = [c,g]) %where minperf is a function doing a crossvalidation with current parameterset summing %missclassificationrate over all folds (see at bottom) minfn = @(z)minperf(z,meas,classes,c,opt_mode); Loop for X optimization rounds and keep best setup %unconstraint optimization using nelder mead simplex %to avoid being stuck in local minimum this step is repeated X times and best %parameters are stored [searchmin fval] = fminsearch(minfn,randn(2,1)); %after finding C and r a final cross validation is performed for performance %estimation of final model finfun = @(xtr,ytr,xte,yte)confusionmat(yte,cross_svm(xtr,ytr,xte,z(1),z(2))); cm = crossval(finfun,meas,classes,'partition',c) cm = reshape(sum(cm),2,2) %the final model is constructed using all data and optimized parameters.. svmStruct = svmtrain(meas,classes,'Kernel_Function','rbf','Autoscale',true,... 'rbf_sigma',z(1),'boxconstraint',z(2)); Somehow I have a feeling there is a bias. Using blind data, performance is worse than what would be expected from the cross validation. Any suggestions for a good range I can set for $c$ and $r$ as parameters for fminsearch? %optmode just decides which measure is used for performance evaluation (e.g mcr) function out = minperf(z,meas,classes,c,opt_mode) fuun = @(xtrain,ytrain,xtest,ytest)perf_clsf(cross_svm(xtrain,ytrain,xtest,exp(z(1)),exp(z(2))),ytest,opt_mode); out = crossval(fuun,meas,classes,'partition',c); out = sum(out)/length(out); end UPDATE: Thanks for the answer, i recall out was a vector and not a single value.. my perf_cls simply returns this : out = sum(yte ~= ypredte); More remarks on this? UPDATE2: I found that mathworks is exactly proclaiming this method.. maybe they should add the bias remark.. http://www.mathworks.nl/help/bioinfo/ug/support-vector-machines-svm.html#bs3tbev-16 UPDATE3: Here a final remark, Varma and Simon compared a similar CV approach with another nested CV optimization revealing the bias of the above approach and showing the benefit of using the nested version: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1397873/
