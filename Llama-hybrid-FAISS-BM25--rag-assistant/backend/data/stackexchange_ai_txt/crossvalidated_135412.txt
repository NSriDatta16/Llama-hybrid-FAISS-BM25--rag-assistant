[site]: crossvalidated
[post_id]: 135412
[parent_id]: 
[tags]: 
Anomaly classification probability on Machine Learning

I am using features to predict a dataset classification. I have use the Gradient Boosting Classifier of scikit-learn for the prediction and tune it to reduce the error classification. The error classification has been done using MAE, i.e., reduce the sum of the difference between predicted and real value of all test set. In the following image ( link ) it can be seen a table to understand the differences, where a perfect classification should have only numbers on the diagonal. As it can be seen, the high classified values are wrongly predicted and giving a lower value. This is due to the low number of training examples with high classification that make them as a anomaly values and the distribution all test set. In the following plotting ( link ) of 2 variables it can be seen that there is a region that high values are more probable, but due to the number of lower values in the same region the prediction is not good. I cannot have more data of high classification values because they are anomalies, but I cannot reduce the training set too much because the Machine-Learning does not work. Is there any possibility to define a classifier probability distribution for each region? Or, is there any other better score method for this purpose?
