[site]: crossvalidated
[post_id]: 398373
[parent_id]: 
[tags]: 
Neural Networks cannot learn noisy 1D correlation

I have a noisy 1D problem that the neural network simply cannot discriminate. It is just as good as random chance. My dataset is at http://s000.tinyupload.com/?file_id=75528637079351980231 col0 is correlated with col1 but not correlated with col2. I am trying to train an NN with 2 inputs: Real = {col0, col1}, Fake = {col0, col2}. By eye I can see that the distributions are different but the NN cannot see anything. Even a sklearn polynomial fit doesn't work. Is there a mathematical reason that it is impossible for a neural network to see the difference between the two? The plot shows the binned means and standard deviations for col0 in bins of col1 (blue) and in bins of col2 (orange). The bars are NOT error bars, they are std.
