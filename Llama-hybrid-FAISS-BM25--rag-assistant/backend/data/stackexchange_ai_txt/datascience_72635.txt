[site]: datascience
[post_id]: 72635
[parent_id]: 72586
[tags]: 
I understand CART as a Classification and Regression Tree, as just a Decision tree. Decision Trees are greedy and deterministic. Random Forest is an ensemble of decision trees, so you will be using random trees ensembling to select features. I am guessing, your question is not really descriptive about the situation, that since the decision tree is not pruned and uses all data it gives a good solution there is no need to take care of overfitting or pruning They normally achieve better in the train than Random Forest because they overfit easily. Taking out features will just give the tree less information, so less power. Does it mean that CART needs a large number of features to produce a good model? Decision trees do good with a small number of features, it is not related. Just to check, are you evaluating in the test set right?
