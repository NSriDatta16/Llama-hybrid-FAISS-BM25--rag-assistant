[site]: crossvalidated
[post_id]: 122826
[parent_id]: 100047
[tags]: 
First a few words about Markov Processes. There are four distinct flavours of that beast, depending on the state space (discrete/continuous) and time variable (discrete/ continuous). The general idea of any Markov Process is that "given the present, future is independent of the past". The simplest Markov Process, is discrete and finite space, and discrete time Markov Chain. You can visualize it as a set of nodes, with directed edges between them. The graph may have cycles, and even loops. On each edge you can write a number between 0 and 1, in such a manner, that for each node numbers on edges outgoing from that node sum to 1. Now imagine a following process: you start in a given state A. Every second, you choose at random an outgoing edge from the state you're currently in, with probability of choosing that edge equal to the number on that edge. In such a way, you generate at random a sequence of states. A very cool visualization of such a process can be found here: http://setosa.io/blog/2014/07/26/markov-chains/ The takeaway message is, that a graphical representation of a discrete space discrete time Markov Process is a general graph, that represents a distribution on sequences of nodes of the graph (given a starting node, or a starting distribution on nodes). On the other hand, a Bayesian Network is a DAG ( Directed Acyclic Graph ) which represents a factorization of some joint probability distribution. Usually this representation tries to take into account conditional independence between some variables, to simplify the graph and decrease the number of parameters needed to estimate the joint probability distribution.
