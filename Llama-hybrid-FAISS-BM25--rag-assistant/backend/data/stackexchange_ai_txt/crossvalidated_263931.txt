[site]: crossvalidated
[post_id]: 263931
[parent_id]: 
[tags]: 
Calculation of transition probabilities of Markov Chain problem

In the step of learning Markov chains, I came across few questions from assignments on UTDallas website. Finding the transition probabilities seems a bit hard for me in this one particular question only. The question is (Sec 7.3, page 355, #1) Consider a system with two components. We observe the state of the system every hour. A given component operating at time $n$ has probability $p$ of failing before the next observation at time $n + 1$. A component that was in a failed condition at time $n$ has a probability $r$ of being repaired by time $n + 1$, independent of how long the component has been in a failed state. The component failures and repairs are mutually independent events. Let $X_n$ be the number of components in operation at time $n$. The process $\{X_n, n = 0, 1, . . .\}$ is a discrete time homogeneous Markov chain with state space $I = \{0, 1, 2\}$. a) Determine its transition probability matrix, and draw the state diagram. b) Obtain the steady state probability vector, if it exists Although the answers are given, but I cannot understand that on what basis the transition probabilities are calculated. Can someone help me in this... I had the following guesses my ownself (which mostly proved to be wrong) \begin{bmatrix} 1-r-r^2 & r & r^2\\ ??& ?? & r(1-p) \\ p^2 & ?? & ?? \end{bmatrix} The actual solution that the website pose is following... \begin{bmatrix} (1-r)^2 & 2r(1-r) & r^2\\ p(1-r)& pr + (1-p)(1-r) & r(1-p) \\ p^2 & 2p(1-p) & (1-p)^2 \end{bmatrix}
