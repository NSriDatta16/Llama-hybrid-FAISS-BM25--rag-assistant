[site]: crossvalidated
[post_id]: 562356
[parent_id]: 
[tags]: 
Convergence in distribution and convergence in Kolmogorov distance

Let $X, Y$ be two random variables with laws $F$ and $G$ respectively. The Kolmogorov distance between these two laws is defined as: $$ d_{Kol}(F, G) = \sup_{x \in \mathbb R} |\mathbb P(X \leq x) - \mathbb P(Y \leq x)| $$ Now consider a sequence of random variables $X_n \sim F_n$ and a random variable $X \sim F$ . It is easy to see that $d_{Kol}(F_n, F) \rightarrow 0$ implies $X_n \rightarrow_d X$ ( $\rightarrow_d$ is for convergence in distribution). My questions are: Under what assumptions, the other direction is also true? (that is, convergence in distribution implies convergence in Kolmogorov distance). This paper (the first couple of paragraphs) claims this to be true when $F$ is continuous, but I got lost when trying to prove it when using the second Dini's theorem. In general, can convergence in probability imply convergence in Kolmogorov distance (without assuming continuous target law)? Any ideas and insights would be really appreciated.
