[site]: crossvalidated
[post_id]: 133564
[parent_id]: 
[tags]: 
How can a Bayesian analysis say A < B, when both have only 0s?

I've used python to analyse data from AB tests using Bayesian analysis, and for all tests I assume no prior knowledge and so set alpha = beta = 1 . However I'm finding some odd results at low data volumes, which I thought was my code, but I'm also seeing using an online Bayesian calculator . This leads me to believe I don't understand the maths properly :). If we take an AB test with the following parameters: A trials: 100 A successes: 0 B trials: 10 B successes: 0 There is a 90% chance that B is better according to the analysis, however I don't understand how this can be the case with no successes recorded yet? Otherwise, the true success rate could be 0.00001% and this analysis should yield a low level of significance... So is this the case? Assuming it is, how can I adjust parameters to ensure that there is no assumption on the success rate (or at least that I can control this assumption).
