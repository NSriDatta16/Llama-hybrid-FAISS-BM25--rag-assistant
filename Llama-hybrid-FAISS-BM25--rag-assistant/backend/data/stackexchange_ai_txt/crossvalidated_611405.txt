[site]: crossvalidated
[post_id]: 611405
[parent_id]: 611381
[tags]: 
In general, the properties of the expected value for a discrete random variable arise directly from the properties of the (weighted) arithmetic mean , because the expected value of a random variable is defined precisely as the weighted arithmetic mean of the possible outcomes of that random variable, weighted by the probabilities of those outcomes. The definition of the expected value for a continuous random variable is a natural extension of this principle, if you understand integrals well enough. The extension is particularly interesting in the "frequentist" conception of probability as long-run proportions of events under the hypothetical ability to re-run some data generating process an infinite number of times. So the question here amounts to: why is linearity of the arithmetic mean intuitive? Consider some real-world quantity with plenty of random variation, such as the body lengths of snow crabs in the Bering Sea . Brushing aside all mathematical rigor, it is reasonable to "expect" that the body length of any random crab should be around the average body length of that type of crab in that region. So if you were to magically double all the body lengths of all the crabs, then naturally the average body length should double (linearity!), and therefore that the "expected" body length doubles accordingly. Similarly, you might be interested in the weights of luggage items being loaded onto an airplane, because you are interested in the total takeoff weight of the airplane. As with the crabs, if you double the weight of every item loaded on the plane, it is completely natural that you should double the average weight of those items, and therefore that you should double the "expected" weight of any one item. Furthermore, the total weight of all items is just the sum of the individual item weights. Here we can turn to the frequentist interpretation of probability for intuition about expected values. Imagine that there is some complicated and unobservable (and therefore random from our perspective) data-generating process by which the weight of each luggage item is chosen. Consider the average outcome of this data generating process. The total weight in this average outcome is naturally the sum of the individual weights. Because this is just a sum, we can use the basic properties of the arithmetic mean and state that this average total weight should also be the sums of the individual luggage weight averages. Finally, by equivalence between arithmetic means and expected values, we should conclude that the expected value of the sum is the sum of the expected values. To extrapolate this reasoning to categorical data, it might help to remember that we can think about categorical random variables as a collection of mutually-independent binary random variables. More abstractly, we can think of categorical data as vectors in barycentric space . In both cases, we have extended our scenario from univariate to multivariate, so the interpretation of the "expectation" must extend accordingly to mean the expected value of each element , and the intuition from above holds in that case.
