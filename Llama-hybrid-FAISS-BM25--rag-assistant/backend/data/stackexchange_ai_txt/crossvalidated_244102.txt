[site]: crossvalidated
[post_id]: 244102
[parent_id]: 237691
[tags]: 
To add to other comments I think there is no rule gainst seeing this percentage as a hyper(or maybe better to say hyper-hyper) parameter. The set up that I can think of is dividing your data by two at first. Let's say put 10% of your data aside (yeah ! it's percentage again) and then for the rest of your data slice it in different ways (30,30,30), (80,10,10). In each scenario, you'll get training, validation and test rates & you should be able to compare it to the rate that you get on that 10% test set and see if you can find any constant improvement because of a specific scenario. Like some other parts of machine learning, we may test it first and then try to find a reason for what we see (finding a relationship between the amount of data and these values, if there is any!
