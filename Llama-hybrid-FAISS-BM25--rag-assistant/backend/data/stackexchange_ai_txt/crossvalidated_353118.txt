[site]: crossvalidated
[post_id]: 353118
[parent_id]: 353116
[tags]: 
Precision refers to precision at a particular decision threshold. For example, if you count any model output less than 0.5 as negative, and greater than 0.5 as positive. But sometimes (especially if your classes are not balanced, or if you want to favor precision over recall or vice versa), you may want to vary this threshold. Average precision gives you average precision at all such possible thresholds, which is also similar to the area under the precision-recall curve. It is a useful metric to compare how well models are ordering the predictions, without considering any specific decision threshold. Reference: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html
