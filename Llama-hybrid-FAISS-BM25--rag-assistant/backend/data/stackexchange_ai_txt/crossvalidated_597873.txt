[site]: crossvalidated
[post_id]: 597873
[parent_id]: 
[tags]: 
Is this "stochastic gradient method" different from the stochastic gradient descent algorithm?

In a computational statistics book, I found an optimization method to find local minimum of a function. Let's assume that we have a differentiable function $f: \mathbb{R}^2 \longrightarrow \mathbb{R}$ . We want to find a local minimum $f(\theta)$ of the function. Starting with initialization $\theta^{*}_i$ , instead of using gradient descent, a slightly different method is used. Given a decreasing sequence of positive real numbers $\alpha_i$ (i = 1,2,3,...) Set i = 1 Sample $\omega_i$ from a uniform unit sphere Estimate the directional derivative of $f$ at $\theta = \theta^{*}_i$ along the direction $\omega_i$ , denoting the result as $f_{\omega_i}^{'}( \theta^{*}_i)$ Update $\theta^{*}_{i+1}$ := $\theta^{*}_{i} - \alpha_if_{\omega_i}^{'}( \theta^{*}_i)\omega_i$ Stop and return $\theta^{*}_{i+1}$ if(convergent). Otherwise increase i by 1 and go back to (1) This question is mainly because of confusing terminology in different books. I think this algorithm is not the traditional "stochastic gradient descent" algorithm that machine learning scientists often refer to. Is this true? And if it is, how do statisticians/machine learning scientists often call it?
