[site]: crossvalidated
[post_id]: 181588
[parent_id]: 
[tags]: 
Very low out-of-bag score after applying Random Forest

I am applying Random Forest to a matrix of 388 samples by 14 features. The features are: nominal (5 categories) (1 feature) nominal (2 categories) (13 features) The target variable is nominal (6 categories). Computing the out-of-bag score I get a score of 0.4974, which means, if I understood well, that my classifier misclassifies half of the samples. I am using 1000 trees, which are expanded until all leaves are composed by only 1 sample. I am using the Random Forest implementation in Scikit-learn . What am I doing wrong? I was thinking that maybe the number of samples is too large with respect to the number of features, but I am unsure on that.
