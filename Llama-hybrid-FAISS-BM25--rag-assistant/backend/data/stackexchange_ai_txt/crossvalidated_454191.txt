[site]: crossvalidated
[post_id]: 454191
[parent_id]: 
[tags]: 
Interpreting coefficients on priors in Bayesian models

First time posting on Stack Exchange, so please go easy on me. Suppose I estimated the following logistic regression: $Pr(Y_i=1) = \frac{\text{exp}(\alpha + \beta_1X_{1i})}{1+\text{exp}(\alpha + \beta_1X_{1i})}$ . Furthermore, suppose values of X are unobserved. We'll assume the following about $X$ : $X_i \sim N(\mu, \sigma)$ . Now suppose we have information about $\mu$ we want to use to model $X$ such that: $\mu = \alpha' + \beta'_1Z_{1i}$ . For simplicity, assume that $\sigma$ , $\beta_1$ , $\alpha$ , $\alpha'$ , and $\beta_1'$ all get uninformative priors. My question is this: How does one interpret the coefficient on $\beta_1'$ ? If it is positive, we could say that as $Z$ increases, our prior belief on $X$ is increasing in value, all else equal. But that prior may not track well with the mean of the posterior distribution of $X$ if our MCMC chains eventually converge elsewhere. What are we to make of $\beta_1'$ and its effect on $\mu_i$ if the posterior mean of $X$ is (perhaps wildly) divergent from its prior? Thanks in advance. David
