[site]: crossvalidated
[post_id]: 347623
[parent_id]: 
[tags]: 
Using non-normalized data for learning a RL agent using PPO

i want to use the baselines code from OpenAI to apply to a power trading setting where I trade energy on a market. My observation space includes several kinds of data, which is why I originally used their spaces.Dict type. That however doesn't seem to work, they only accept an array of min/max bounded numpy arrays. I could just flatten my whole data and pass it in as an array. But some values are very small (typical between 0 and 2) while others go up into the thousands. What would be a good way to preprocess the data? Do I normalize it just before I feed it to the NN? What impact does that have on the networks learning ability? The data includes: historical average prices for the last 168 steps known prices and volumes for the currently open for trading timeslots (24 at a time) predictions of demand already purchased amounts in previous trading slots code repo just in case It's really a bummer that OpenAI baselines work so sparsely, I worked a long time on making this "Gym API compatible" but now I am unsure if their code will actually live much longer..
