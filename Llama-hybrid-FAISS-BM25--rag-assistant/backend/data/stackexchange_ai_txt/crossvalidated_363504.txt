[site]: crossvalidated
[post_id]: 363504
[parent_id]: 
[tags]: 
IS optimization unnecessary in SVM?

According to here , Now knowing the $a_i$ we can find the weights $w$ for the maximal margin separating hyperplane: \begin{align*} w = \sum_{i=1}^{l} a_i y_i x_i \end{align*} I cannot understand what this says. I have trouble in how to choose $a_i$. I think we must conduct Newton-method, Pegasos, SMO, or stuff like that. In addition, I want to implement hard-margin (linear-separable) SVM in Python. So I am seeking for the most simplest(easiest) optimization method. I am very grateful to you if you make some answers taking this into account.
