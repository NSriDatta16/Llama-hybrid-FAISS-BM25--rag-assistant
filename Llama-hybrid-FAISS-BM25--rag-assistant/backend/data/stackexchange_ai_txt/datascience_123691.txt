[site]: datascience
[post_id]: 123691
[parent_id]: 
[tags]: 
Does the input data representation when training an autoencoder matter?

Suppose I want to train an autoencoder on English words. Does it matter what kind of input data representation I use? E.g., if I use word2vec as my input or bag of words, will the quality of my autoencoder differ? If so, what do people typically use for autoencoder input?
