[site]: crossvalidated
[post_id]: 457204
[parent_id]: 456203
[tags]: 
Your question is not completely clear and I can't comment because I don't have enough reputation but I'll do some assumptions here please correct if I'm wrong. So your data (time series) looks like this: Each timepoint is an hour with a timespan on one month. For each timepoint you have a number of sad tweets and a number of other tweets. So your data looks a bit like this: timepoint/date numberofsadtweets numberofothertweets 2020-01-01,00:00 200 800 2020-01-01,01:00 300 900 etc.... Now you ask: "I want to know for each hour if the number of sad tweets is significant". The thing about significance is, that it has to relate to a hypotheses + is used when you can't measure the full population. When you want to know if the number of sad tweets is significant my question is what hypothesis are you testing and number of sad tweets significant to what? What are you comparing this with? I assume you might want to know for each hour if there are significantly more sad tweets than other tweets? This question can easily be answered without significance. You can just look per hour which group has the most tweets. That would be your answer. However I can assume this was not what you mean. I guess you might want to know if on certain hours there are significantly more sad tweets compared to other hours? So now your hypotheses is "on certain hours the number of sad tweets is significantly more than other hours". Now significance and statistics come into play because you sampled one month and not the whole history and future of tweets to come. What you should do to see if there are more sad tweets on certain hours than others: Firstly, I don't think one month of tweets is enough for this analysis. Because you will have 24 groups (hours) with only 30 measurements per group(hour). In common practice this is not enough data for this kind of analysis. You might want to make bigger groups by for example taking two hour timepoints. You'll then have 12 groups with 30 measurements. Or take an extra month. Now lets continue with the testing: First you might want to correct for total number of tweets. This is done when on certain hours there are way more tweets than other hours so there will be automatically more sad tweets. If you don't mind about this effect its also fine but I think you'll want to correct for this. One way to do this is to calculate for each hour the percentage of sad tweets of the total number of tweets in that hour. Now we've corrected for total number of tweets we can compare groups. Here I highly advise you again to specify you hypotheses or make less groups. With 24 hours you're making 24^2 - 24 : 2 comparisons. With each comparison you're losing power. Just search bonferonni-holm correction and you'll know what I mean. I'd say make 4,3 or even 2 groups. So you can compare morning afternoon and night for example. This way you'll only have at most (4^2 - 4) : 2 = 6 comparisons. Okay now the testing: At the base of this comparison is the t-test. Here you have 1 categorical variable and one numeric variable. The simplest test is for example when you compare morning to evening. your grouping variable is then "part of the day"(morning/evening) and your numerical variable is "percentage of sad tweets". If the test is then significant that indicates that there is a difference in percentage of sad tweets between morning and evening. If you want more than 2 groups you need a slightly different approach but the idea is the same. You'll do a one way anova to see if there is any difference between groups. You use hours here as independent (categorical/grouping!) variable and percentage of sad tweets as dependent variable. If the anova is significant, you can do post-hoc t-tests to see which groups are significantly different. Another way to approach this is to see if you can model the percentage of sad tweets with time series analyses. But this is very different and I think you don't want it. so in short: make less groups correct for total number of tweets check assumptions for one way anova do one way anova do post hoc t-tests I hope my rambling made some sense!
