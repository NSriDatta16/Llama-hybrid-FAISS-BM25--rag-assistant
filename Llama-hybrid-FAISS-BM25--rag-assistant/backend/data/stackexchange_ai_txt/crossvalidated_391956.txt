[site]: crossvalidated
[post_id]: 391956
[parent_id]: 
[tags]: 
Time Series Forecasting RNN: Difference Between Masking & Excluding Rows

Suppose you have missing values in a time series E.g. : t1 x1 y1 t2 ? ? t3 x3 y3 t4 ? ? t5 x5 y5 You are trying to forecast this time series using a recurrent neural network (say LSTM) and you decide to handle the missing values using masking. Masking example (from Keras): set x[:, 3, :] = 0. and x[:, 5, :] = 0. - insert a Masking layer with mask_value=0. before the LSTM layer: model = Sequential() model.add(Masking(mask_value=0., input_shape=(timesteps, features))) model.add(LSTM(32)) I have heard people say that masking is somewhere inbetween completely removing missing values/rows and Imputing/learning missing values Can anyone explain why masking is any different to just removing the values from the time series? The way I understand it so far is that: if all values in input tensor equal the mask value then that time step will be skipped and the state transferred (if stateful is true). How is this different to excluding the row from the time series?
