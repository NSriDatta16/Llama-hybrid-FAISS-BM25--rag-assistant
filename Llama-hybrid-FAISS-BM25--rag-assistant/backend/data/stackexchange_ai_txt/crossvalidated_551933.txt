[site]: crossvalidated
[post_id]: 551933
[parent_id]: 551929
[tags]: 
I am not aware of any papers but here is a good risk function derived using causal inference theory. This is essentially the generalization of the so-called "DR learner" to the differences-in-differences setting. Your target function is $$\tau(x) := E[Y, A_2 = 1, A_1 = 1, X=x] - E[Y, A_2 = 0, A_1 = 1, X=x] - \left\{E[Y, A_2 = 1, A_1 = 0, X=x] - E[Y, A_2 = 0, A_1 = 0, X=x] \right\}.$$ A natural population risk function for $\tau$ is the least-squares risk $$ E_X \left\{ \left[ \theta(X) - \tau(X)\right]^2 \right\},$$ which can be written equivalently as (up to a constant not depending on $\theta$ ) $$R(\theta) = E_X \left\{ \theta(X)^2 - 2 \theta(X)\tau(X) \right\}.$$ The latter risk function is linear in $\tau$ and thus easier to work with. We aim to construct a root-n consistent and efficient estimator of the risk $R(\theta)$ , which is a path wise differentiable parameter when viewed as a function of the data-generating distribution $P$ . To do so, we need to derive the efficient influence function of $R(\theta)$ and compute the one-step efficient estimator for the risk (Bickel et al. 1993). A standard computation in causal inference gives the one-step efficient empirical risk function is the empirical mean of the loss function: $$L_{eff}(\theta, O) := \theta(X)^2 - 2 \theta(X) \tau(X) - 2 \theta(X) \left\{ Y - E[Y\mid A_1, A_2, X ] \right\} \bigg[\frac{1(A_2=1, A_1 = 1)}{P(A_2=1,A_1=1 \mid X)} $$ $$- \frac{1(A_2=0, A_1 = 1)}{P(A_2=0,A_1=1 \mid X)} - \left\{ \frac{1(A_2=1, A_1 = 0)}{P(A_2=1,A_1=0 \mid X)} - \frac{1(A_2=0, A_1 = 0)}{P(A_2=0,A_1=0 \mid X)} \right\} \bigg].$$ Define the pseudo-outcome, $$\psi_{\pi, \mu}(O) = \tau_{\mu}(X) + \left\{ Y - \mu(A_1, A_2, X) \right\} \bigg[\frac{1(A_2=1, A_1 = 1)}{\pi(1,1 \mid X)} $$ $$- \frac{1(A_2=0, A_1 = 1)}{\pi(0,1 \mid X)} - \left\{ \frac{1(A_2=1, A_1 = 0)}{\pi(1,0 \mid X)} - \frac{1(A_2=0, A_1 = 0)}{\pi(0,0 \mid X)} \right\} \bigg]$$ where $\tau_{\mu}(X)$ , $\mu(A_2, A_1, X) = E[Y\mid A_2, A_1, X ] $ and $\pi(a_2, a_1 \mid X) = P(A_2=a_2,A_1=a_1 \mid X)$ are nuisance functions that need to be learned from the data. The efficient empirical risk function is equivalent to the pseudo-outcome least-squares empirical risk function $$R_{n, \pi, \mu}(\theta) := \frac{1}{n} \sum_{i=1}^n \left\{ \psi_{\pi, \mu}(O) - \theta(X)\right\}^2.$$ $\tau$ can be estimated as $$\tau_n = \text{argmin}_{\theta \in \mathcal{F}} R_{n, \pi_n, \mu_n }(\theta)$$ for initial nuisance estimators $\pi_n$ and $\mu_n$ . The "causal forest" estimator is implemented by performing the random forest regression of the pseudo-outcome $\psi_{\pi_n, \mu_n}(O) $ on $X$ . References: See the references in this manuscript: https://arxiv.org/abs/2004.14497
