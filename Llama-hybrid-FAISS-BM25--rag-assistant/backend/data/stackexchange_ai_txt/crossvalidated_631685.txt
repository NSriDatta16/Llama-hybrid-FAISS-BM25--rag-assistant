[site]: crossvalidated
[post_id]: 631685
[parent_id]: 
[tags]: 
Ordinal vs multinominal classification in XGboost: differences in one-hot encoding

I have followed this post and tried to see if there will be any difference in predicted probabilities if I use different one-hot encoding in XGboost. This is my code with some dummy data, which is actually not ordinal in nature. from xgboost import XGBClassifier from sklearn.datasets import load_iris import pandas as pd df = load_iris(as_frame=True)['frame'] x = df[[_ for _ in df.columns if _ != 'target']] y = df['target'] model = XGBClassifier() y1 = pd.get_dummies(y) y2 = pd.get_dummies(y) y2.loc[np.where(y==1)[0], [1,2]] = 1 y2.loc[np.where(y==2)[0], :] = 1 m1 = model.fit(x,y1) m2 = model.fit(x,y2) print(m1.predict_proba(x) == m2.predict_proba(x)) The predicted scores are exactly the same, so I am unsure if the difference in encoding does anything in XGBoost. How can XGBoost handle ordinal classification then?
