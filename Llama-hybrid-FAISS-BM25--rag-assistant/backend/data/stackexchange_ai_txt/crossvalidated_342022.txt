[site]: crossvalidated
[post_id]: 342022
[parent_id]: 342006
[tags]: 
Typically plugging an estimate of a parameter in as if it were exactly known is a problem, if uncertainty about this parameter has a meaningful effect on the estimation/uncertainty about the other parameters. Of course, it may turn out that in a particular case the effect is not too large. Simulations with realistically simulated data would answer that. An alternative would be to sample values for the parameter and do the modeling for all these values and then aggregate all the obtained estimates and standard errors (e.g. using Rubin's rule). This would assume that you can estimate the first parameter on its own (also assume in your approach 1) and that you have some idea of the sampling distribution of the estimate (e.g. you often one might sample from N(estimate, SE of estimate), although in your case I assume that does not hold). Alternatively, if you obtained you estimate in a Bayesian MCMC approach, you could simply take the MCMC samples.
