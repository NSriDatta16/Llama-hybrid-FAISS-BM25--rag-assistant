[site]: crossvalidated
[post_id]: 399348
[parent_id]: 
[tags]: 
Coefficient of determination in time series models

Nagelkerke's (1991) generalized $R^{2}$ (below) is a modification of the Cox Snell (1989) generalized $R^{2}$ (the numerator in the below) which is a coefficient of determination based on the log-likelihood, and which gives a value of 0 when $L(\hat{\theta}) = L(0)$ , and gives a value of 1 when $L(\hat{\theta})$ fits the data perfectly. $$\overline{R}^{2} = \frac{1 - \left(\frac{L(0)}{L(\hat{\theta})}\right)^{\frac{2}{n}}}{1-L(0)^{\frac{2}{n}}},$$ where $L(\hat{\theta})= e^{\text{ll}(\hat{\theta})}$ and $L(0)= e^{\text{ll}(0)}$ . $L(0)$ is the likelihood of the model sans predictors. In a non-time series model that would be something like $\text{link}(y_{i}) = \beta_{0} + \varepsilon_{i}$ . However, time series models are predicated on modeling memory in autoregressive or non-stationary processes, and understanding how predictors affect the outcome or change in the outcome in the short and long run. Would it therefore make sense to interpret $L(0)$ as an unconditioned process in time series models (e.g., those below) when calculating Nagelkereke's (or the Cox-Snell, or some similar) generalized coefficient of determination, or should $L(0)$ be the likelihood from the simple expectation as above, and why? $$y_{ti} = \alpha_{0} + \alpha_{2}y_{t-1i} + \varepsilon_{ti}$$ or $$\Delta y_{ti} = \alpha_{0} + \alpha_{2}y_{t-1i} + \varepsilon_{ti}$$ Bonus question: If it would not make sense, is there a special term of art for something like this? A "coefficient of determination over baseline process" or whatever? References Cox, D. R.; Snell, E. J. (1989). The Analysis of Binary Data (2nd ed.). Chapman and Hall. Nagelkerke, N. J. D. (1991). A note on a general definition of the coefficient of determination . Biometrika , 78(3):691â€“692.
