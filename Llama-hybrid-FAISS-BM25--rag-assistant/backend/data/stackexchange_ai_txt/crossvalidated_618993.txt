[site]: crossvalidated
[post_id]: 618993
[parent_id]: 
[tags]: 
Why does the performance on the training set go down as the number of samples increases?

To my knowledge there are two types of learning curves, those that show the progression of the performance as the amount of epochs progresses, and those that show the performance progression as the amount of training data increases. I am referring to the second type. Here is the plot, as made with sklearn.model_selection.learning_curve : I observed that my training metric goes down as the number of training samples increases. I wanted to double check whether my reasoning is correct. I assume this happens because when there is only a small amount of training data, the model (simple neural network in this case) is able to accurately learn large parts of the training set (maybe even overfit). So the model has enough complexity to hold the information that describes the training data. As we add more data, it becomes a harder task for the model to 'learn by heart' the training data, and a more complex model would be necessary to maintain the same training set performance. Is this reasoning correct? Or are there other things at play?
