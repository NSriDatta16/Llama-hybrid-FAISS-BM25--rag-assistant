[site]: crossvalidated
[post_id]: 127307
[parent_id]: 127183
[tags]: 
If I understand you correctly, you have a number of explanatory variables but not much clue which of them could be relevant and which not. Here are a few ways to proceed: Try out all possible subsets of variables and pick the one that gives a regression with the smallest Bayesian information criterion (BIC) value. See e.g here for relevant R functions. In you want to allow for interactions, too, then either define new regressors by multiplying the existing ones in a pairwise fashion or look for an existing function to do that for you. Using BIC will help strike the right balance between possible overfitting and underfitting. If you intend to use your model for forecasting rather than explanation, use Akaike information criterion (AIC) instead of BIC. Forward or backward stepwise selection : start from a small model and add regressors one by one based on their relevance (broadly speaking) or start from a general model and remove regressors one by one, again based on their relevance. Shrinkage methods (LASSO, ridge regression, elastic net, principal components regression, partial least squares) : if you want to reduce the mean squared error of your model and do not care exclusively about the unbiasedness of your estimates, you might want to allow for some bias to gain a decrease in variance. This makes sense if you intend to forecast but not so much if your study is explanatory. See Hastie et. al "The Elements of Statistical Learning" chapter 3 subsections 3.3-3.7 for a more detailed overview. To address your concern about p-values : they are not sacred and many say they are given too much importance. Sometimes (when there is a lot of data) even irrelevant variables become statistically significant, but the magnitudes of their coefficients are small and substantively negligible. Sometimes two or more variables are jointly significant but not so individually. Thus you have to interpret them carefully and not just mechanically.
