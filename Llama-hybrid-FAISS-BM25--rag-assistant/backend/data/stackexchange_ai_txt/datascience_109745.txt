[site]: datascience
[post_id]: 109745
[parent_id]: 109744
[tags]: 
if you're new to deep learning frameworks, firstly I'd recommend pytorch. Although Tensorflow has more capabilities, most of them aren't required for beginners, and with growing experience and sophistication of your project, you still may switch to tf later, in case you need to really dive deep. Once you know pytorch, it will be a lot easier to get into tf. Now, about your model: If you're planning to implement a simple feedforward network, you can easily use the nn.Sequential module in pytorch to do so. Each layer in your sequential stack of layers has parameters (in most cases called weight and bias). These are of type torch.Parameter, which essentially means that the optimizer in training will recognize that they are model parameters that should be upgraded with gradient descent. Whether a parameter will be considered in the update step is determined by the attribute requires_grad = True / False . What you essentially want to do is to turn off upgrading of parameters (which is typically called "freezing") that belong to the hidden layers. This is plain easy. You simply loop through your layers with model.named_parameters() and set requires_grad=False for the ones that you want to keep fixed / random. Make sure you initialize your model parameters randomly (which is done by default, but there are different techniques to initialize them, which may alter your outcome). If you have absolutely no idea what I am talking about, simply do the 60minute intro tutorial in pytorch and you will be good to go. Knowing python is a prerequisite of course ;) For more sophisticated randomized models, you might be interested in looking into echo state networks, in case you need something like a recurrent network. Good luck!
