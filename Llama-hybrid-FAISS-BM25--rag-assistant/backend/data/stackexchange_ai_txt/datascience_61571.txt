[site]: datascience
[post_id]: 61571
[parent_id]: 61533
[tags]: 
Deep learning models are a subset of multi-layer perceptrons. What you consider to be "deep" is subjective - so long as you have multiple hidden layers, you can call it deep and get away with it. You can associate the terms "linear" and "non-linear" with either the mapping function or the model. A perceptron will always learn a linear boundary between classes ( this answer has a good explanation for that). Once you add a hidden layer, and turn the perceptron into a MLP, the model/resulting mapping function will be able to learn non-linear decision boundaries. This happens regardless of the activation functions of the layers.
