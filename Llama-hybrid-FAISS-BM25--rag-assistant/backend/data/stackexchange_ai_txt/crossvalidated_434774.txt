[site]: crossvalidated
[post_id]: 434774
[parent_id]: 434205
[tags]: 
This kind of problem is an optimisation problem that can either be solved directly from the profit function, or in two-steps using backward induction . To show you how to uses either of these methods, I will first write the optimisation problem out in a helpful mathematical form. I will show the solution by both methods. In this particular case, direct optimisation is much simpler, but if you have more difficult cases then the method of backward induction can be simpler. The optimisation problem: You have a continuous random variable $V \sim \text{U}(0, x)$ and you will choose two offers $y_1$ and $y_2$ . Your profit is the random variable: $$\pi_V(y_1,y_2) = y_1 \cdot \mathbb{I}(y_1 \leqslant V) + y_2 \cdot \mathbb{I}(y_2 \leqslant V Your goal is to choose a first and second offer to maximise your expected profit, which is the expected value of the above function. Direct optimisation: With direct optimisation we write out the expected profit as a bivariate function of your two decision variables, and we then conduct multivariate optimisation using standard calculus techniques. We can restrict attention to the cases $0 \leqslant y_2 , since both offers must be within the support of $V$ , and your second offer should be lower than your first. (The second offer only matters if the first is rejected, so it makes no sense to make a second offer that is equal or greater to the first.) Restricting attention to this case, the expected profit function can be written as the bivariate function: $$\begin{equation} \begin{aligned} \bar{\pi}(y_1,y_2) &\equiv \mathbb{E}(\pi_V(y_1,y_2)) \\[6pt] &= y_1 \cdot \mathbb{P}(y_1 \leqslant V) + y_2 \cdot \mathbb{P}(y_2 \leqslant V The gradient vector and Hessian matrix of this function are given respectively by: $$\nabla \bar{\pi}(y_1,y_2) = \frac{1}{x} \begin{bmatrix} x - 2y_1 + y_2 \\ y_1 - 2 y_2 \end{bmatrix} \quad \quad \quad \quad \quad \nabla^2 \bar{\pi}(y_1,y_2) = \frac{1}{x} \begin{bmatrix} - 2 & 1 \\ 1 & - 2 \ \end{bmatrix}.$$ It is simple to show that the Hessian is negative definite (eigenvalues are $\lambda_1 = -3$ and $\lambda_2 = -1$ ), so the function is strictly concave. This means that it has a unique critical point that is the global maximising value of the function. This point satisfies the first-order condition (FOC): $$\mathbf{0} = \nabla \bar{\pi}(\hat{y}_1,\hat{y}_2) = \frac{1}{x} \begin{bmatrix} x - 2\hat{y}_1 + \hat{y}_2 \\ \hat{y}_1 - 2 \hat{y}_2 \end{bmatrix}.$$ Solving these two equations in two unknowns yields the optimising prices: $$\hat{y}_1 = \frac{2}{3} \cdot x \quad \quad \quad \hat{y}_2 = \frac{1}{3} \cdot x.$$ Optimisation by backwards induction: With backward induction we begin by optimising the later decision, and then work backwards to optimise the earlier decision, assuming optimisation of the later decision. So, let's imagine that you have already made some first offer of $0 \leqslant y_1 \leqslant x$ and it has been rejected, so now you are going to make your second offer. Conditional on the rejection of the first offer, we have the posterior distribution $V | V , so the expected profit from a new offer of $0 \leqslant y_2 \leqslant x$ is: $$\begin{equation} \begin{aligned} \bar{\pi}(y_2) &= \mathbb{E}(\pi_V(y_1,y_2) | V \sim \text{U}(0, y_1)) \\[6pt] &= \mathbb{E}(y_2 \cdot \mathbb{I}(y_2 \leqslant V) | V \sim \text{U}(0, y_1)) \\[6pt] &= y_2 \cdot \frac{y_1-y_2}{y_1} \cdot \mathbb{I}(y_2 Univariate optimisation (omitting the calculus steps) yields the optimising value: $$\hat{y}_2 = \frac{1}{2} \cdot y_1.$$ Having obtained this optimising value, we proceed backward to the first offer. Assuming that the second offer is optimal, the expected profit as a function of the first offer $y_1$ is: $$\begin{equation} \begin{aligned} \bar{\pi}(y_1|\hat{y}_2) &= \mathbb{E}(\pi_V(y_1,\hat{y}_2) | V \sim \text{U}(0, x)) \\[6pt] &= \mathbb{E}(\pi_V(y_1,y_1/2) | V \sim \text{U}(0, x)) \\[6pt] &= \mathbb{E}(y_1 \cdot \mathbb{I}(y_1 \leqslant V) + \frac{y_1}{2} \cdot \mathbb{I}(y_1/2 \leqslant V Univariate optimisation (omitting the calculus steps) yields the optimising value: $$\hat{y}_1 = \frac{2}{3} \cdot x.$$ Substitution of this optimum offer to the second optimising offer then gives: $$\hat{y}_2 = \frac{1}{3} \cdot x.$$ This is the same answer that is obtained via direct optimisation. The above methods can easily be extended to the more general case where you have more than two opportunities for offers. As in the above case, the simplest method is the direct method ---i.e., you form a multivariate function for the expected profit conditional on a vector of offers, and then optimise this function using standard calculus techniques.
