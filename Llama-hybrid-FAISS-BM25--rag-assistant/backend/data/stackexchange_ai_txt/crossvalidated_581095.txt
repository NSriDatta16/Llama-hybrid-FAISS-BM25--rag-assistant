[site]: crossvalidated
[post_id]: 581095
[parent_id]: 579825
[tags]: 
In general, no supervised learning algorithm can safely make predictions outside the bounds of your training data. There are exceptions of course: a linear model does fine outside its domain if and only if the underlying natural system it is making predictions about is also a linear system. To put it another way: the model only knows about things it has seen before. This limitation is one of the reasons we generally assume and require that data are "independent and identically distributed" . Your data are not identically distributed with respect to the x3 feature (and potentially with respect to the target), so you're getting bad results. As for what you can do now, here are some ideas: Find some data examples in the data domain in which you'd like to make predictions. Select a learning algorithm that behaves according to your expectations or some other information. Find a purely analytic solution (e.g. using physics or economic theory or whatever). With option 2 you are essentially saying that you have some new information (a conceptual or physics-based model) that provides expectations for this new domain. You can use that to choose an appropriate model. For example, this figure (source) illustrates how different regressors behave outside the training domain (i.e. at the edges of these plots): With option 3 you're really just giving up on machine learning. It may or may not be an option for you.
