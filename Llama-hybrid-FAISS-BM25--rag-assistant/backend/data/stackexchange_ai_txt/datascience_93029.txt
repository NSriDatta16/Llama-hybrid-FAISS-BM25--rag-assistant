[site]: datascience
[post_id]: 93029
[parent_id]: 
[tags]: 
How to find out what portions of an image is helping CNN to classify it

I am working on an image classification problem using Transfer learning. Right now, I am getting an accuracy of 75% on train data and 67% in test data. Now I want to understand what portions/parts of the image are being utilized for classification graphically. Are there any packages that can return a copy of one of the input images with markings on the most useful pixels or parts of the image?
