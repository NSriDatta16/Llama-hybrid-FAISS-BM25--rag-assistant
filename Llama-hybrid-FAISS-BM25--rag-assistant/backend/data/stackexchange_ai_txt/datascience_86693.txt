[site]: datascience
[post_id]: 86693
[parent_id]: 86627
[tags]: 
I'm experienced primarily in recommender systems, but I've done enough work in NLP to have some ideas on how to approach this problem. I don't know of any formal name for the problem that you are proposing, but I do know that it's going to be really hard to train a model to learn from just that data, even if you had dense labels. There's just too much unstated human context embedded into the problem to train a model on that from scratch. Like for your example of Fruits traditionally grown in Germany. You have to find some Knowledge graph or embedding that has learned the relationship of fruits and where they grow geographically. There is a limited set of things out there that would be capable of this. So what you need to do is apply another model or language embedding to the data, and try to engineer a solution from that. The first thing I thought of is any large-scale pre-trained skip-gram or CBOW embeddings (these embeddings are often called "word-vectors" or "thought vectors"). A resource to the basics of that here . The idea here is to use some pre-trained language model and calculate embeddings for your inputs and outputs. Then you just do cosine similarity between the embeddings for each input and output, and see if you can get good matches. Because you're using sentences you're going either going to have to use a model that embeds sentences or documents (doc2vec is an example), or you're going to have to find some way to aggregate token embeddings. I would pick the former if you try this approach. But to build on that, once you have these pretrained embeddings, you could also train your own neural net on top of those embeddings to classify for matches. I would read up on the task of question-answer for neural networks for inspiration, as I imagine you might take some ideas from that for how to associate the queries and matches for a neural net (Google "QANet" for some leads on this). Another approach, which depending on the data you're working with, would be a knowledge graph. This solution would be more complicated, but basically you would break up the documents into different pieces (POS/NER tagging) and then search for semantic equivalents in a knowledge graph. Some example KGs can be found here . Another thing to google would be the field of "Ontology". Very much related to knowledge graphs but may get you some more niche results that could prove to be helpful. Some more context about the exact problem you're trying to solve or what kind of dataset you're working with may help illuminate other solutions. Hope that some of the terms I gave you pushes you into the right direction. Good luck!
