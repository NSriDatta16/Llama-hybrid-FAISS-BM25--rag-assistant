[site]: crossvalidated
[post_id]: 376619
[parent_id]: 
[tags]: 
Same maximum entropy and measures

As the author Christian Robert asks about reference measures that are absolutely continuous to one another, and from what I can gather this just means they have the same null set? But would that not be true for any continuous distribution? Since from what I can gather, Lebesgue is zero over points, non zero over intervals or such. Similar to continuous distributions which are zero at any given point. Some people pointed out that not all distributions have this , for example the cantor distribution, because it does not have a density. So the author pointed out, it is really about having a density not just a distribution. I am trying to work through some of the examples and problems. One talks about that if we have absolutely continuous measures, then we can construct example where corresponds maximum entropy distributions are the same. So this leads me to think, that the reference measure does not uniquely determine the maximum distribution? Ie, if they are absolutely continuous, then it may be ( or will be?), the same. And I am wondering why this would be true. I get the formula, but wouldn't they normalise differently? How would it end up being the same distribution? An example given is Lebesgue measure and standard normal. Since standard normal has a density, I think this is an example of absolute continuity. I am thinking they may give the same when the two measure have no distance between them? with known expected value and variance as constraints, we could find the Lagrange multipliers. But we will still have $\frac{1}{\sqrt{2\pi}}exp(\frac{-\theta^{2}}{2})$ But since its a density, wont it simply integrate to 1 as well with the normal, so even if both can be normalised I have trouble seeing how it gives the same max entropy. That is, I am wanting to see how different reference priors can lead to the same max entropy. More my thoughts: So, for a standard normal reference prior, since we know mean and variance I assume we could write it as $\pi^{*}(\theta)$ $\alpha$ $\exp(\lambda_{1}\theta+\lambda_{2}\theta^{2})\exp(\frac{-\theta^{2}}{2})$ Which I guess has the same form with a factor, would it still give the same normal though? $\exp(\lambda_{1}\theta+(\lambda_{2}-\frac{1}{2})\theta^{2})$ And as seen previously , for Lebesgue measure with known mean and variance, $\pi^{*}(\theta)$ $\alpha$ $\exp(\lambda_{1}\theta+\lambda_{2}\theta^{2})$ So both are normalise, but I have trouble seeing how they will correspond to same distribution. The second one is a normal with mean 0 and variance $\sigma^{2}$ unless the factor in the first just would change the Lagrange, and leave with same normal
