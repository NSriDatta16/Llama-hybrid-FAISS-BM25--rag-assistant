[site]: datascience
[post_id]: 84055
[parent_id]: 84038
[tags]: 
There are a couple of options: Optimize tensorflow for your specific CPU. Sometimes the official versions of tensorflow are not compiled with support for some instruction sets (e.g. SSE4.1, SSE4.2, AVX, AVX2, FMA). Usually, there is a tensorflow runtime warning message stating so. This prevents some computations to take place in parallel. You can either download a version that is optimized for your CPU (e.g. from intel ) or you can compile tensorflow yourself . Prune the model. BERT is a multi-head attention model, and it is possible to remove some of its attention heads while retaining most of the quality. Here 's a blog post that shows how to do it for tensorflow.
