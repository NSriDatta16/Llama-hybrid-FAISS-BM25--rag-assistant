[site]: crossvalidated
[post_id]: 444328
[parent_id]: 
[tags]: 
What does it mean to save optimizer states in deep learning libraries?

I was recently going through the Keras documentation on saving models . I am aware that saving a model involves saving the learned weights and biases after training. However, the doc also mentioned saving the optimizer state along with it. Apparently, it allows resuming training from where you left off. But can someone explain what exactly does it save behind the scenes? And what does the optimizer have to do with the training state?
