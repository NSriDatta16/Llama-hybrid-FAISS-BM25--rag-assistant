[site]: stackoverflow
[post_id]: 580742
[parent_id]: 579997
[tags]: 
What a fun question... as you've noted you won't be able to afford the overheads associated with traditional locking for a work queue for this. I'd encourage you to try to use one of the existing fine-grained task based programming environments if you can... I think about this in three buckets of work: The first chunk of the problem is to ensure safety, correctness and parallelizability, and it sounds like you have that covered because your function is pure. I think the next most challenging portion is describing the concurrency, specifically you mention this function is called many many times. Can you pipeline this and separate scheduling the function from its work? If you can't pipeline this, does it look like a parallel loop, a tree traversal or is it more unstructured than this. Specifically, obeying Amdahl if you can't overlap the work and ensure that there are several instances of it or something else running at the same time, you're effectively serial even though you are pure. Anything that you can do to refactor the work into a pipeline, a recursive tree traversal (or parallel loop) or if you must more unstructured work with explicity dependencies between tasks will help here regardless of the library used. The last area I think about is to ensure that there is efficient execution on your platform and this involves reducing overheads and contention in both your code and the scheduling code and ensuring that any serial code is absolutely as efficient as possible. If you can't use one of the existing libraries and must build your own, I'd encourage you to look at a work-stealing queue and self guided scheduling algorithms, as you've noted you won't be able to see gains from using a traditional locks because their costs outweigh your function costs and you'll most likely need to look at lock-free techniques to reduce the cost of scheduling and removing a task onto whatever queue you use. You'll also need to pay a lot of attention to sharing and contention both within your scheduling algorithm and within your function, because at this level of granularity in addition to the usual branch misprediction and instruction throughput issues, you'll also need to look at shared state and contention even on reads because they can be sources of contention too . I'm sorry if this wasn't super specific, but I hope it was useful.
