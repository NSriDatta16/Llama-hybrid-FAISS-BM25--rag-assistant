[site]: crossvalidated
[post_id]: 312158
[parent_id]: 312153
[tags]: 
A good method for forecasting short time series is double exponential smoothing, which I would prefer to applying single exponential smoothing to the differenced series. This will also allow for changes in trends, in contrast to a simple linear regression. Here is the relevant section in FPP , 2nd edition. The state space framework that, e.g., forecast::ets() uses will give you prediction intervals. If you can meaningfully group your time series (or at least some of them) so they exhibit common patterns, you might be able to improve forecasts by forecasting aggregates (on which the signal is hopefully more easily visible) and adapting lower-level forecasts. Here is the relevant chapter in FPP2 . I have repeatedly found this "optimal combination" approach to improve forecasts on all levels of the hierarchy. Making optimal combinations play nice with prediction intervals (or even better, predictive densities), is an ongoing research topic. There was a presentation on "Coherent probabilistic forecasts for hierarchical time series" by Souhaib Ben Taieb, James Taylor and Rob Hyndman at this year's International Symposium on Forecasting . I'd recommend you ping the authors and ask for the presentation. Of course, if you don't know a priori which time series will be positively correlated so you can hierarchically treat them, this is a problem - especially for short time series. You could simply cluster them, using one minus some correlation as a distance measure. But of course, if your series are short, then you might be clustering a lot of noise. As to change point detection, this is of course also a hard topic for short series. The strucchange package for R contains a number of useful functions. You might want to apply these to differenced series, or to the residuals in-sample, so your breakpoint detector is not thrown off by the trend. If you can cluster your series a priori (or an automatic clustering works well), then you might be able to detect the change points on the aggregates instead of the individual series, where once again, the signal will be stronger. The problem of course then is what to do with detected change points. A state space framework should of course be able to include an external step change predictor, but unfortunately I believe that neither forecast::ets() nor the functions in the smooth package allow for this (but it might be good if you checked, I'm not entirely sure). Alternatively, you could use auto.arima() and feed a change point indicator into the xreg parameter. Here is Rob Hyndman explaining the difference between regression with ARIMA errors and ARIMAX, recommended reading. EDIT - you write: Maybe I could use something like hierarchical forecasting described by Rob Hyndman (see e.g. those slides or the hts vignette) where the parameters to aggregate the individual series could be estimated using regression I agree that the hierarchical approach could definitely be helpful. However, if you estimate "optimal" coefficients for aggregating series, don't forget that this will be an additional source of variance, which could make your forecasts worse than just using flat weights of 1 (see Claeskens et al., IJF 2016, "The forecast combination puzzle: A simple theoretical explanation" ).
