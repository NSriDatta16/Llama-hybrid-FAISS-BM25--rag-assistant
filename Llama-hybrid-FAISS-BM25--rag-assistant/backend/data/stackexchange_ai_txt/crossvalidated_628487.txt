[site]: crossvalidated
[post_id]: 628487
[parent_id]: 230765
[tags]: 
You might want to try ZeroInflatedRegressor which is a pre-built implementation by Robert KÃ¼bler: from sklego.meta import ZeroInflatedRegressor import xgboost as xg xgboost_with_zeros = ZeroInflatedRegressor( classifier=xg.XGBClassifier(), regressor=xg.XGBRegressor() ) Do cross validate this - boosting models can overfit, and now you're using two. The dataset of the regressor is naturally much smaller than the dataset of the classifier, so the best hyperparameters may be very different.
