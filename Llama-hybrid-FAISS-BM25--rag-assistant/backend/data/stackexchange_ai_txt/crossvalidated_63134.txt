[site]: crossvalidated
[post_id]: 63134
[parent_id]: 
[tags]: 
Event Prediction through Machine Learning

I have a large data set consisting of ca. 40 categorical data items and a few interval data items (real numbers, less than 5 such items). Most categories should have a lot of values that repeat themselves over and over and very few that appear very rarely. Some categories are also overcategories of others (like country and city). The outcome of each data is either 1 if the event occured or 0 if it did not occur. The idea is to calibrate a machine learning model or a staistical model that can predict for every given data row the probability that the outcome is 1. The data set I will use will have at least 1 million rows. What machine learning approaches and statistical models will perform well on such a task? My initial thoughts are logarithmic regression and support vector machines (with extensions like random forest) How do I deal with the interval data items? The easiest approach is obiously to convert different ranges into categories, which I think will not be a problem. What libraries and tools can I use, when my data set has a size of 10 GB? I am interested in tools/libraries that include machine learning algorithms but also statistical tools to help me find attributes with significant influence on the outcome. I can code in Java and C++ at the moment. I looked into Root, a data analysis tool from CERN for lare data sets and its machine learning module TMVA but it can only handle real numbers and integers as input as far as I know.
