[site]: crossvalidated
[post_id]: 563109
[parent_id]: 563094
[tags]: 
As what you care about is predicting which email type is best suited to a particular demographic, don't worry about "statistical significance." That answers question 3. Statistical significance is often just a measure of your data set size. A predictor might be important in practice but just not pass the magical "p From that perspective, the answer to question 2 is also simple: use the entire model for predictions, if the model is well validated. With logistic regression, leaving out any predictor associated with outcome can lead to omitted-variable bias . With respect to question 1, you are essentially on the right path. Note that so far you only seem to be including 2-way interactions among the predictors, and you don't seem to be including a 2-way interaction of gender with age or income. In principle you could include higher levels of interaction, too. Make sure that any such omissions are conscious decisions rather than oversights. That's one advantage of letting software set up your data coding instead of trying to do it by hand. If you have values for age and income, it's preferable to treat them as continuous predictors instead of binning them . If you can't assume that they are linearly related to log-odds, methods like regression splines can handle nonlinearity in a flexible way that is informed by the data. The danger is that with too many interactions you might be overfitting your data. The usual rule of thumb to avoid overfitting with logistic regression is to have about 15 cases in the minority class (presumably the sign-up class in your case) for each coefficient in your model. I count 44 individual and 2-way interaction coefficients beyond the intercept, so you should have 600-700 sign-ups in your data set to handle even that level of model complexity; to evaluate higher-order interactions you would need more sign-ups. If you are still in the study-design stage, use that as an estimate of how large a study to conduct. Otherwise, if there aren't enough sign-ups to handle that number of coefficients, scale back your model complexity and use your knowledge of the subject matter to identify the most critical combinations of predictors to evaluate. Alternatively, try a learning method like boosted trees, although the resulting model might not be easy to interpret intuitively. Frank Harrell's course notes and book are useful resources for principles of regression modeling. An Introduction to Statistical Learning presents other modeling approaches.
