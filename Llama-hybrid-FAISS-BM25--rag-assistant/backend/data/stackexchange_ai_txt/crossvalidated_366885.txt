[site]: crossvalidated
[post_id]: 366885
[parent_id]: 
[tags]: 
xgboost performing poorly

I'm rather new when it comes to using XGBoost but I thought it would be good to learn how to use it. The dataset that I tried it on has 635 data points and 150 features. However the performance is rather poor around 50% when it comes to AUC. The same dataset when using logistic regression gives about 65%, after feature selection. The parameters used are the standard ones that comes with the sklearn wrapper, XGBClassifier. I also tried to tune the parameters with GridSearchCV but the outcome became either the same or worse. So my question: Is the performance lacking because the dataset is to small or that there are to many features? Or maybe it's both?
