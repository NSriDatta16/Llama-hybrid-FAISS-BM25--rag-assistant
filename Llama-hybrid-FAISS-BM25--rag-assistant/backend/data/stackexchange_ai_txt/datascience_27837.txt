[site]: datascience
[post_id]: 27837
[parent_id]: 22494
[tags]: 
One thing that hasn't been mentioned yet and that you can consider for the future: you can still increase your dropout at the fully connected layers. I read a paper once that used 90% dropout rate. Although it had many many nodes (2048 if i recall correctly), I have tried this myself on layers with fewer nodes and it was very helpful in some cases. I just looked up which paper it was. I can't recall which paper I just remembered but I found these that also had some success with 90% dropout rates. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., & Fei-Fei, L. (2014). Large-scale video classification with convolutional neural networks. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (pp. 1725-1732). Simonyan, K., & Zisserman, A. (2014). Two-stream convolutional networks for action recognition in videos. In Advances in neural information processing systems (pp. 568-576). Varol, G., Laptev, I., & Schmid, C. (2017). Long-term temporal convolutions for action recognition. IEEE transactions on pattern analysis and machine intelligence.
