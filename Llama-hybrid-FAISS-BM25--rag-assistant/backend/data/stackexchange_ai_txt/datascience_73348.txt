[site]: datascience
[post_id]: 73348
[parent_id]: 73324
[tags]: 
The main reason is that a linear combination of the input followed by a non-linearity stacked on top of eachother is a universal function approximator . Which means that no matter how complicated the true underlying function is, a neural network can approximate it to an arbitrarily small error. There's also the efficiency factor since a linear combination of $n$ inputs each having $m$ dimensions can be represented using a single matrix multiplication $h=X \times W$ where $X$ is an $n \times m$ matrix (where each row is an example and each column is a feature of that example) and $W$ is an $ m \times d $ weight matrix. And computers are VERY efficient at doing matrix multiplications . Thus, the more you build your model to use matrix multiplications the better.
