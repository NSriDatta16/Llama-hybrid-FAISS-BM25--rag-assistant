[site]: crossvalidated
[post_id]: 508821
[parent_id]: 
[tags]: 
Why iterations of Gibbs sampling for a bivariate Gaussian distribution can be seen as random walk?

In Section 4.4 of the excellent technical report Probabilistic Inference using Markov Chain Monte Carlo Methods , the author tries to analyze the performance of Gibbs and Metropolis algorithm with simulating samples from a bivariate Gaussian distribution. In this example, he claimed: Notice that in this example both Gibbs sampling and the Metropolis algorithm explore less confined direction by a random walk. This statement confuses me for a while (It also came to my attention that other books, e.g., Pattern Recognition and Machine Learning , Section 11.3, also adopted the similar perspective to estimate the number of iterations needed to obtain two nearly independent samples). What is the rationale of such statement? To me, suppose we want to sample from \begin{align*} \begin{bmatrix} X_1 \\ X_2 \end{bmatrix} \sim N\left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} \sigma_1^2 & \rho\sigma_1\sigma_2 \\ \rho\sigma_1\sigma_2 & \sigma_2^2\end{bmatrix}\right) \end{align*} using Gibbs sampling, the conditional distribution for $X_1$ given the current value of $X_2 = x_2$ is $N((\rho\sigma_1/\sigma_2)x_2, (1 - \rho^2)\sigma_1^2)$ . Therefore in a single Gibbs pass, a Gaussian random number is generated according to this distribution, which is (in my opinion) very different from a random walk. In particular, the state will not stay at the current value with positive probability. Does the author actually merely mean this example and the random walk share the "square root" phenomenon?
