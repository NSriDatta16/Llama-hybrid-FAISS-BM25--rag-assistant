[site]: crossvalidated
[post_id]: 160179
[parent_id]: 
[tags]: 
Do we need gradient descent to find the coefficients of a linear regression model?

I was trying to learn machine learning using the Coursera material . In this lecture, Andrew Ng uses gradient descent algorithm to find the coefficients of the linear regression model that will minimize the error function (cost function). For linear regression, do we need gradient descent? It seems I can analytically differentiate the error function and set it to zero to solve for the coefficients; is that right?
