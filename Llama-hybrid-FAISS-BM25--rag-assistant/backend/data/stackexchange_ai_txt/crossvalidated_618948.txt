[site]: crossvalidated
[post_id]: 618948
[parent_id]: 
[tags]: 
Minimum number of observations vs number of features

I'm a student, and I need to compare how different perform in a binary classification. I can freely choose any dataset for my work, but the specifications include to make A LOT of computing: many algorytms (logistic regression, networks, random forest, gbm, svm), stepwise for variable selection, repeated cross validation with each algorythm... . That's why I would like to choose a relatively small dataset... I know this is a very general question, but I would like to know if, supposing I have relatively well balanced dataset, there is a rule of the thumb, like 'I recomend a minimum of, say, 50 observations per feature'. More if variables are categorical, or if continuous? More if categorical has more categories, o less? It depends on the algorythm, too. If need to define one, let's say my question is about the simplest one, the logistic regression. Or, if modeling a network, how many observations per parameter? It's newbbie question, and may be a question too general to answer in just one post... A good article to read? Thanks!
