[site]: crossvalidated
[post_id]: 502603
[parent_id]: 
[tags]: 
Why does normalizing image twice work?

I made a 'mistake' while training a neural network, it is a typical image classification problem like this . However the data is much larger and came from Kaggle. In my Dataset class from PyTorch , I defined a flag if self.transform_norm is False: image = image.astype(np.float32) / 255.0 and this would signify that if my augmentations pipeline does not have a normalization technique, then we set this flag to False . One example that I would set the above flag to be True the below augmentation appear in my pipeline: albumentations.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0) I forgot to set the flag to True and thus, the images first went through a standardization from [0,255] to [0,1] and then normalized using mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] . I thought I did wrong but the training results were actually good. So I dug deeper and found PyTorch's documentation and realized that it may be me who has been doing it all wrong? However, I am not using PyTorch's pretrained model out of the box, usually, I go to Ross's timm/geffnet for the models. Do let me know if there is a "right" approach. To quote the link: All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. You can use the following transform to normalize:
