[site]: datascience
[post_id]: 64212
[parent_id]: 64197
[tags]: 
The key term for your problem is low resource languages . I'm not sure whether there is a standard approach but you could find papers about what people have done before in similar cases, potential software tools/data repositories which could help, etc. You might also be interested in the Universal Dependencies project: https://universaldependencies.org/ There are many things that can be done related to Universal Dependencies (UD): use the existing resources to analyze/parse some text data. As far as I know the standard tool would be UDPipe (python libraries here , here , maybe others...) train a new dependency parser. for instance I found this repository . start a treebank for a new language: https://universaldependencies.org/how_to_start.html . Warning: this is probably a lot of work if you start from scratch! and there's no or little ML involved in the creation of the data itself. The focus of UD resources is on dependencies but imho the main interest is that it provides resources which can be used for all the standard NLP tasks: sentence or word segmentation, POS tagging and lemmatization, etc.
