[site]: crossvalidated
[post_id]: 573603
[parent_id]: 208661
[tags]: 
If you already know game theory you may see many parallels with reinforcement learning with multiple agents. Decision theory which is essentially game theory with one player is a second area that similar and perhaps a closer match for single agent settings. Strict Domination and Backwards Induction solution concepts map to the main steps used in the rl policy iteration algorithm which does a value function BI estimation followed by greedification step SD The fields seem to diverge in some respects, game theory tends to makes strong assumptions on strategies being fully specified ahead of time and players being rational even when faced with an infinite decision tree. RL looks to solving these online and with minimal computational resources. In this sense rl offers a more realistic and algorithmic approach to solving essentially the same class of problems. The MDP Markov decision process used to formalise rl makes use of the markov property on the state which means rl decisions are made based on the current state and lack memory of earlier actions [unless explicitly included in the state].
