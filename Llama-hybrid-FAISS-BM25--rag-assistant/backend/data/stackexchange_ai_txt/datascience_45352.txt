[site]: datascience
[post_id]: 45352
[parent_id]: 45332
[tags]: 
Coming to your first question: Yes, you can but it's not advisable to use LS as a cost function for classification task since the optimization problem becomes non-convex! More on it, since your model in logistic regression would be sigmoid(a non-linear function) which means your cost function will have a lot of local optima!(think of a surface of the cost function as a Himalayan valley!), So, when you will use Gradient descent(an iterative approach) for minimizing your cost function, GD will be stuck somewhere in the local minima instead of global minimal, so you will not learn the best model parameters for your model on your data! Therefore, we change the cost function from LS to Log loss for classification task that ensures a nice bell-shaped curve surface of the cost function where the gradient descent can reach to global minima and give you the corresponding best model parameters which you can happily take it later to do predictions(on test-set)! More on it here Much more theoretical understanding of it you could find in ISLR at page 129 4.2 Why Not Linear Regression?
