[site]: crossvalidated
[post_id]: 335471
[parent_id]: 
[tags]: 
Overfitting during epochs

Especially in deep learning, the validation accuracy of a model usually not only plateaus but decreases when it starts overfitting. Because we only measure the validation accuracy after each epoch, wouldn't it be possible for a model to start overfitting during an epoch? From my understanding, this could be a significant problem if there is a lot of similar data available but I haven't found any material about it and have never seen such an approach in practice. Is there a reason besides computational cost that we only ever validate our models after an epoch? And would it make sense to check validation accuracy every n batches rather than epochs if you are trying to get the last bit of performance out of a model (e. g. for a Kaggle competition)?
