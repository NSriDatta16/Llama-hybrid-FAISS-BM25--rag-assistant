[site]: datascience
[post_id]: 24553
[parent_id]: 24549
[tags]: 
This package is very useful, this does the feature engg. for you, gives you the important variables. sample code would be something like this. set.seed(123) boruta.input By using this you can get all the important features but the downfall is it takes time if you have more data In my case my data consists 40 features and 200,000 records it took almost 2 hours but the results were good. For better understanding you can go through this link -- I think you can use this test too , in the description it tells that it can be applied on numerical data too. If you have data which is Nominal data, you can use G-test Attaching one more link along with this, which consists of tests for different kinds of features. Might be helpful in the future Link I have a question, why aren't you applying PCA(or any DR Techniques) on the data-set? (assuming that you din't try any DR Techniques) If you apply DR Techniques, I think you might get better Components which would aid you in getting better results/better understanding of data. As you mentioned that you were using NB Classifier, why did you choose that, is there any specific reason? As you know that there are many other Classifiers which might outrun NB Classifier. In my case I used NB Classifier for twitter sentiment mining, as those are short sentences and NB Classifier best suited for my analysis. Hope my answer is helpful! NB: Naive Bayes DR: Dimensionality Reduction
