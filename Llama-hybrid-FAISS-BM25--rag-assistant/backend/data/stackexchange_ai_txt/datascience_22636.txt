[site]: datascience
[post_id]: 22636
[parent_id]: 
[tags]: 
Can tuning individual precision and recall classification thresholds improve deep learning models?

I learned that Keras doesn't have a built-in way to set a threshold for precision and accuracy when building a classifier. Courtesy of a solution here , I wanted to see what would happen when I fit a simple 3 layer Multilayer Perceptron with different classification thresholds for these metrics. So I went ahead and fit a model with as such: model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics = [precision_threshold(0.5), recall_threshold(0.5)]) and got out these results: val_precision: 0.7048 - val_recall: 0.5795 Further, I plotted a normalized confusion matrix. And using this: def precision(cm = confusion_matrix): return round(cm[1,1] / (cm[0,1] + cm[1,1]), 4) def recall(cm = confusion_matrix): return round(cm[1,1] / (cm[1,0] + cm[1,1]), 4) I calculated the resulting precision and recall: Normalized confusion matrix [[ 0.6026 0.3974] [ 0.2204 0.7796]] Precision: 0.71 Recall: 0.78 This seems pretty reasonable so far. Then I switched up the thresholds and looked at what outcomes resulted. The table below shows what I got when I changed the precision threshold to 0.1 and the recall threshold to 0.9: |-----------------------------------------------------| | paramter settings for model fitting: | | [precision_threshold(0.1) recall_threshold(0.9)] | | | | validation results | |- val_precision 0.4089 - val_recall 0.0457 | | | | Normalized confusion matrix | | [[ 0.6148 0.3852] | | [ 0.2303 0.7697]] | | | | Precision 0.70 | | Recall 0.79 | |-----------------------------------------------------| Interestingly, if you look at the final Precision and Recall scores, I notice that they didn't change, even with the extreme parameters I set. Basically the same confusion matrix as well. I repeated this for a large set of different settings and got generally the same final Precision and Recall scores. I could past them in here but it would take up a lot of space. One more detail then I'll switch to my actual question. My model is based on the business case where a large precision value is very desirable and recall is not relevant. My question is this -- given that I desire large precision -- is tuning the specific precision and recall thresholds for the model valuable at all, if the final Precision and Recall scores are left fundamentally unchanged across all configurations of the thresholds? I hope this makes sense. Thanks for reading this.
