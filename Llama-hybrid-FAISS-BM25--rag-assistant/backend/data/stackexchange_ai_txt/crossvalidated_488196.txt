[site]: crossvalidated
[post_id]: 488196
[parent_id]: 293989
[tags]: 
You can approach this in two different ways: preprocess your data to look as similar as possible to the mnist data (at inference time) fine tune (transfer learning) the pre-trained MNIST model you intend to use to better fit your data In this case number 1 means adding some antialias, you could do this with upscale, blur, downscale or something like that. Number 2 means to train again the model, freezing a few layers or not, with your data only for a few epochs. In practice neural networks generalize well, in this case it probably does not make much difference if your images are antialiased or not. The only way to find out is to test your dataset with different preprocessing. Other aspects, like size and location, may matter more. A good model was probably trained with a lot of augmented data that can be extremely different from the base digits (shear, blur, noise, masking, etc.) If a little difference in antialias/compression artifacts would be enough to sway a model machine learning would be pretty useless.
