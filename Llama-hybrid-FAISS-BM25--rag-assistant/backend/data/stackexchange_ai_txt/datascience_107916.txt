[site]: datascience
[post_id]: 107916
[parent_id]: 
[tags]: 
Predict sequence using seqGAN

I am trying to create a GAN model in which I am using this seq2seq as Generator and the following architecture as Discriminator: def create_generator(): encoder_inputs = keras.Input(shape=(None, num_encoder_tokens)) encoder = keras.layers.LSTM(latent_dim, return_state=True) encoder_outputs, state_h, state_c = encoder(encoder_inputs) encoder_states = [state_h, state_c] decoder_inputs = keras.Input(shape=(None, num_decoder_tokens)) decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True) decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states) decoder_dense = keras.layers.Dense(num_decoder_tokens, activation="softmax") decoder_outputs = decoder_dense(decoder_outputs) Generator = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs) return Generator def create_discriminator(): model = tf.keras.Sequential() model.add(keras.layers.Flatten(input_shape=(9, 15))) model.add(keras.layers.Dense(256, activation=keras.layers.LeakyReLU(alpha=0.01))) model.add(keras.layers.Dense(128, activation=keras.layers.LeakyReLU(alpha=0.01))) model.add(keras.layers.Dense(1, activation = 'sigmoid')) return model I want to do the same as the normal seq2seq( translate from English to Spanish) like in the above link but was to use the GAN. The other necessary codes are below: cross_entropy = keras.losses.BinaryCrossentropy() def discriminator_loss(real_output, fake_output): real_loss = cross_entropy(tf.ones_like(real_output), real_output) fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output) total_loss = real_loss + fake_loss return total_loss def generator_loss(fake_output): return cross_entropy(tf.ones_like(fake_output), fake_output) generator_optimizer = tf.keras.optimizers.Adam(1e-4) discriminator_optimizer = tf.keras.optimizers.Adam(1e-4) import os checkpoint_dir = './training_checkpoints' checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt") checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer, discriminator_optimizer=discriminator_optimizer, generator=Generator, discriminator=Discriminator) @tf.function def train_step(gen_enc, gen_dec, dis): with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: generated_seq = Generator([gen_enc, gen_dec], training=True) real_output = Discriminator(dis, training=True) fake_output = Discriminator(generated_seq, training=True) gen_loss = generator_loss(fake_output) disc_loss = discriminator_loss(real_output, fake_output) gradients_of_generator = gen_tape.gradient(gen_loss, Generator.trainable_variables) gradients_of_discriminator = disc_tape.gradient(disc_loss, Discriminator.trainable_variables) generator_optimizer.apply_gradients(zip(gradients_of_generator, Generator.trainable_variables)) discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, Discriminator.trainable_variables)) return gen_loss, disc_loss import time def train(gen_enc_inp, gen_dec_inp, dis_inp, epochs): for epoch in range(epochs): start = time.time() gen_loss = 0 disc_loss = 0 for idx in range(len(gen_enc_inp)): # print(gen_enc_inp[idx:idx+1].shape, gen_dec_inp[idx:idx+1].shape) gen_loss, disc_loss = train_step(gen_enc_inp[idx:idx+1], gen_dec_inp[idx:idx+1], dis_inp[idx:idx+1]) if (epoch + 1) % 5 == 0: checkpoint.save(file_prefix = checkpoint_prefix) print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start)) print('Generative loss: {} and Discriminator loss: {}'.format(gen_loss, disc_loss)) train(train_encoder_input_data, train_decoder_input_data, train_decoder_target_data, 100) I was able to train the model with the dataset used in the above link. Now I want to use only the Generator part of the GAN model to translate unseen English words to Spanish and find out the accuracy. How can I do that? Please let me know if you need to know anything else.
