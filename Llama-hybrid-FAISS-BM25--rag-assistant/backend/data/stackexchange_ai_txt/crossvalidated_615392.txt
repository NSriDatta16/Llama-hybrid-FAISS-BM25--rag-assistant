[site]: crossvalidated
[post_id]: 615392
[parent_id]: 
[tags]: 
Accuracy of probability estimate from generative autoregressive language model

My understanding is that a discriminative classifier such as a CNN that takes an input $x$ and produces a discrete output label $y$ is typically trained to predict the best value of $y$ , and would not give accurate probabilities for the various possible values of $y$ . So it's an example of a deep neural net that cannot be used to reliably estimate the probability of a prediction. If we compare a CNN to a generative model such as an autoregressive language model that is trained to estimate $p(\mathbf{w})$ , where $\mathbf{w} = [w_1 ... w_n]$ is a sequence of words and $p(\mathbf{w}) = p(w_1) \prod_{i=2}^n p(x_i | x_{1..i-1})$ , the underlying components of the discriminative CNN classifier vs. the generative autoregressive language model are similar (i.e., convolutional networks and transformers are both constructed using matrix multiplications and activations) and both are trained in similar ways (via supervised vs. self-supervised learning). So would $p(\mathbf{w})$ yield an accurate estimate of the probability of an input sequence of words?
