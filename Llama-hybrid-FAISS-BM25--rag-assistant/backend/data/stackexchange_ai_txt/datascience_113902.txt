[site]: datascience
[post_id]: 113902
[parent_id]: 
[tags]: 
Val loss initially decreases, then increases

I've created an LSTM model to predict 1 output value from 8 features. My loss constantly decreases and my val loss also decreases from the start, however it begins to increase after so many epochs. Here's a picture of what's going on. Also here is my code: file = r'/content/drive/MyDrive/only force/only_force_pt1.csv' df = pd.read_csv(file) df.head() X = df.iloc[:,1:9] y = df.iloc[:,9] #X.head() print(type(X)) WIN_LEN = 5 def window_size(size, inputdata, targetdata): X = [] y = [] i = 0 while(i + size) I do get much better results when I use train_test_split and shuffle my training and testing data, however that leads to major overfitting problems. Also, I'm using time series data, so I don't want to shuffle anyways. Does anyone have any suggestions?
