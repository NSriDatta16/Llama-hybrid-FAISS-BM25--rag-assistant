[site]: crossvalidated
[post_id]: 643503
[parent_id]: 643459
[tags]: 
In a professional lab environment, you'll be better off with the stat math other folks have presented, b/c other folks in a clinical/lab environment think in terms of stats and know what stat terms mean. But, if you're working with non-math / non-stat professionals (eg: presenting findings to mgmt / execs), it might be better to NOT use average. My experience with non-math / non-stat folks is when they hear the words "on average", they take that to mean ALL items will be that.. not 1/2 the items will be that or less, and the other 1/2 will be that or higher. So, it might be better to get avg + 3 std deviations (six sigma style) to estimate that 97% or so of items will get done within that time span. EG: if you had an avg of 30 seconds per unit w/ std dev of 5 seconds... A bad way to tell someone would be "on avg, it takes 30 seconds to do each of these". And then later you're called into a meeting when folks are upset b/c "things took longer than you told us!" and you ask why.. and the go "well, I estimated 30 seconds per-unit, and multiplied by 1 million we were going to do.. and actual processing time was MUCH higher!" And then you smh while trying to explain what "average" means and that it can't be used to do estimates of ALL things. A better way would be... 30 seconds avg + 3 * 5 secs std dev = 30s + 15s = 97% of units are done within 45s. Tell management that, and they'll be much happier with the napkin math they do behind your back with it. It might also be worthwhile to make an initial pass at your batch runs to determine if there's any outliers. In six sigma, generally anything falling outside (avg + 3 * std devs) is considered "out of control", IE: something outside the system's control impacted it. It might be good to take a first pass, find all those 4 std dev+ outliers, remove them, and then calc off the remainder of stuff in 3 std devs and below. But, in six sigma and quality control we try to find the 4+ std dev outliers to determine what's impacting system outside system's control. So, it's a good idea to follow-up on why they're outliers. Maybe your system is reaching some kind of "max capacity" in some place, like a bottleneck. EG: in compute processing you get limited by processing, memory and input/output. Maybe you have lots of cpu & ram, but i/o is getting bottlenecked some place creating delays and outliers. In theory your process should run on avg 30 s, but you end up with some outliers taking 200 s. Maybe it's when system gets flooded with processing, and that's when bottlenecks start to impact. So, could look into load-leveling the system or find a way to add more resources.
