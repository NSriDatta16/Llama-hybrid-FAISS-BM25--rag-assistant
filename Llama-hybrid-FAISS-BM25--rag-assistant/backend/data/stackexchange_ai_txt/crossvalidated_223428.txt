[site]: crossvalidated
[post_id]: 223428
[parent_id]: 
[tags]: 
How to use a vector of ranks to predict actual values?

I am interested in this problem of learning a machine learning model to take a vector of ranks as input and predict their numerical values. Let's say I have a matrix $Y$ with shape $m$ (instances) by $n$ (features), I ranked every row of $Y$ using average to handle potential ties and get a matrix of ranks $R$ of the same shape. My questions are: How could I learn a model $f$ to achieve $y = f(r)$ ? Should I formulate this as a multiple-regression problem? What models fit well for this type of problem? Here is a python script to generate some toy data: import numpy as np from scipy.stats import rankdata Y = np.random.randn(1000, 20) R = np.apply_along_axis(rankdata, 1, Y) print R[0] print Y[0] Output: array([ 10., 8., 14., 18., 7., 3., 1., 9., 13., 4., 16., 20., 2., 12., 19., 5., 17., 11., 15., 6.]) array([ 0.06578002, -0.11636595, 0.56441059, 0.7740778 , -0.31002372, -0.69271934, -1.83806102, 0.02944196, 0.48905099, -0.68911226, 0.6119917 , 1.47756463, -1.65347498, 0.28952666, 1.09095143, -0.62324096, 0.7086212 , 0.21528326, 0.5837112 , -0.35102606])
