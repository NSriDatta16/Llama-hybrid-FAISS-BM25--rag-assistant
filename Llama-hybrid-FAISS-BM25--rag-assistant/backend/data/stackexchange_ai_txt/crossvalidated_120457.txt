[site]: crossvalidated
[post_id]: 120457
[parent_id]: 
[tags]: 
How to interpret the results of bootstrapping and Monte Carlo simulation utilised to test lasso logistic regression results?

My situation: sample size: 116 binary outcome (32 events) number predictors: 42 (both continuous and categorical) predictors did not come from the top of my head; their choice was based on the literature. I have run group lasso logistic regression as explained in suggested in a previous post, aiming to identify the most important variables in explaining my outcome. I am less interested in making predictions to much larger populations - my sample represents roughly 90% of the population I am most interest in. The lasso analyses resulted in 9 predictors with nonzero coefficients. As recommended in a previous post, I conducted bootstraping to assess reproducibility and Monte Carlo simulation to assess the methods' ability to find the true variables. I got the following results for the bootstrapping: on average, 78% (7 out of 9) of the variables in original model entered the models generated for the 100 bootstrap samples. On the other hand, only 41% (7 out of 17), for the other way around; 2 variables entered the new models more then 95% of times, 3 variables more than 90%, 5 variables more than 85% and 6 variables more than 75%. Those 6 variables are among the 9 included in the original model; and the following one for the Monte Carlo simulation: 44% (4 out of 9) of predictors composing the original set (assumed as "true") match the ones that entered the models generated in the Monte Carlo simulation, and 44% (4 out of 9) vice-versa. My overall question is: what would be an appropriate way to interpret those results? Can I say that my results are reproducible to other similar samples and that the method is able to select the true variables to an acceptable level? Also: Could I list all the variables and how frequently they enter the model generated for the bootstrap samples, and then argue that those that enter more frequently are more likely to be significant? Could I say that there is evidence that the original feature set is relevant in explaining the outcome (since ~7 out of the 9 variables entered the bootstrap samples' models on average and considering individual feature inclusion fractions) but prediction would be likely to be enhanced if additional variables are included (since bootstrap sample models tended to include 17 variables on average)? Can anyone suggest some references about the use of bootstrap and Monte Carlo in the context suggested in this post (analysis of zero versus non-zero predictor coefficients rather than estimation of coefficients' standard deviation or the like)?
