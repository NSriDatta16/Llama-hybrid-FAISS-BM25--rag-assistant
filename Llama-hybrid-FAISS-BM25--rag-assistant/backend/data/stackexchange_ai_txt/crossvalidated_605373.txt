[site]: crossvalidated
[post_id]: 605373
[parent_id]: 605370
[tags]: 
Detecting edges with several filters in a single layer seems like it could recognize a barcode, but you have to train 64x4x4 weights. Is that really neccesary. And why 64 filters? To capture multiple orientations? Possibly a more complex architecture with multiple layers (but less parameters) may help to improve the performance with less training. Here is a wild guess: Try to mimic the process of a real laser scanner, You scan for high contrast stripes (or edges). This can be done with a few 3x3 filters that detect high contrast lines . Or alternatively a few 1xn filters that operate on several preprocessed rotated versions of the image. The coefficients of this convolution layer might not need to be trained. It can be seen as a preprocessing step. Possibly you can also detect the stripes by detecting first edges and in the image with the edges you detect nearby maximum and minimum peaks. That might be more robust to barcode stripes that cover more than one pixel. Anyway, the point is that you might tackle the edge/line detection more as a preprocessing step that you do not include into the learning of the neural network. You have an additional layer that arranges the sensitivity. A scanner will only respond when the lines are wide (a second convolution layer) multiple in a row (a third convolution layer) With those convolutions you can detect whether a barcode is present in a similar way as a real barcode scanner does it. Finally you add those relu-layers to find the end, start and orientation of the barcode.
