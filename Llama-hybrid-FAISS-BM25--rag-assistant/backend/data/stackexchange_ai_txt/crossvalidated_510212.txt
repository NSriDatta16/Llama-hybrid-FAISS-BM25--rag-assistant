[site]: crossvalidated
[post_id]: 510212
[parent_id]: 509924
[tags]: 
Normality is actually quite important. Not in the sense that it must be true, because it never is true, but in the sense that with gross non-normality you should not use OLS, despite asymptotically correct inferences. For example, with grossly outlier-prone processes (substitute "rare, extreme value" for "outlier" to disentangle it from "incorrectly entered data value"), OLS is grossly inefficient compared to likelihood-based methods that model the conditional distributions more accurately. For another example, with highly discrete distributions, Poisson, multinomial logit, ordinal regression, logistic regression, etc., are more appropriate. When viewing regression as a model for the conditional distribution of $Y$ given $X=x$ , which is essential for predicting individual $Y$ values, for scientific integrity of the model, as well as for efficiency of estimates, it is clearly important to try to model that distribution reasonably well. Normality provides a reasonable approximation in many cases, but one should always consider alternatives.
