[site]: stackoverflow
[post_id]: 1235594
[parent_id]: 
[tags]: 
Comparing persistent storage solutions in python

I'm starting on a new scientific project which has a lot of data (millions of entries) I'd like to store in an easily and quickly accessible format. I've come across a number of different potential options, but I'm not sure how to pick amongst them. My data can probably just be stored as a dictionary, or potentially a dictionary of dictionaries. Some potential considerations: Speed. I can't load all the data off disk every time I start a new script, and I'd like as quick access to random entries as possible. Ease-of-use. This is python. The storage should feel like python. Stability/maturity. I'd like something that's currently supported, although something that works well but is still in development would be fine. Ease of installation. My sysadmin should be able to get this running on our cluster. I don't really care that much about the size of the storage, but it could be a consideration if an option is really terrible on this front. Also, if it matters, I'll most likely be creating the database once, and thereafter only reading from it. Some potential options that I've started looking at (see this post): pyTables ZopeDB shove shelve redis durus Any suggestions on which of these might be better for my purposes? Any better ideas? Some of these have a back-end; any suggestions on which file-system back-end would be best?
