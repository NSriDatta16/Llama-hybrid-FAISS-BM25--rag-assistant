[site]: crossvalidated
[post_id]: 138265
[parent_id]: 40856
[tags]: 
I like the example by @gui11aume (+1), but it can make an impression that the difference in two $p$-values arises only due to the different stopping rules used by the two experimenters. In fact, I believe it is a much more general phenomenon. Consider the second experimenter in @gui11aume's answer: the one who throws a coin six times and observes heads only in the last throw. The outcomes look like that: $$\mathrm{T \;\;\; T \;\;\;T \;\;\;T \;\;\;T \;\;\;H},$$ what is the $p$-value? The usual approach would be to compute the probability that a fair coin would result in one or less heads. There are $7$ possibilities out of total $64$ with one or less heads, hence the $p=7/64\approx 0.109$. But why not take another test statistic ? For example, in this experiment we observed five tails in a row. Let's take the length of the longest sequence of tails as the test statistic. There are $3$ possibilities with five or six tails in a row, hence $p=3/64\approx0.047$. So if in this case the error rate were fixed at $\alpha=0.05$, then the choice of the test statistic can easily render the results either significant or not, and this has nothing to do with the stopping rules per se . Speculative part Now, philosophically, I would say that the frequentist choice of the test statistic is in some vague sense similar to the Bayesian choice of prior. We choose one or another test statistic because we believe that the unfair coin would behave in this or that particular way (and we want to have power to detect this behaviour). Isn't it similar to putting prior on the coin types? If so, then the likelihood principle saying that all the evidence is in the likelihood does not clash with the $p$-values, because the $p$-value is then not only the "amount of evidence". It is "a measure of surprise", but something can only be a measure of surprise if it accounts for what we would be surprised about! The $p$-value attempts to combine in one scalar quantity both the evidence and some sort of prior expectations (as represented in the choice of the test statistic). If so, then it should not be compared to the likelihood itself, but perhaps rather to the posterior? I would be very interested to hear some opinions about this speculative part, here or in chat. Update following discussion with @MichaelLew I am afraid that my example above missed the point of this debate. Choosing a different test statistic leads to a change in likelihood function as well. So two different $p$-values computed above correspond to two different likelihood functions, and hence cannot be an example of a "clash" between the likelihood principle and $p$-values. The beauty of the @gui11aume's example is that the likelihood function stays exactly the same, even though the $p$-values differ. I still have to think what this means for my "speculative" part above.
