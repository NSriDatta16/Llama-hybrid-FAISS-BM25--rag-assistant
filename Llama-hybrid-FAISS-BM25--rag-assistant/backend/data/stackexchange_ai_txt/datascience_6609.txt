[site]: datascience
[post_id]: 6609
[parent_id]: 6595
[tags]: 
Ricky, Loose thoughts: Depending on the algorithm you intend to use, centering might not be a good idea (e.g. if you go for SVM, centering will destroy sparsity) I would suggest not to handle ordered / unordered separately, as you are likely to miss interactions that way . If the categorical ones don't have too many possible values, randomForest in R can handle factors. if that is an issue (as you seem to hint), I think you have two possibilities: binary indicators or response rates if it's feasible in terms of computational cost, i would convert all factors to binaries (use sparse matrices if necessary) and then try a greedy feature selection. caret, if memory serves, has rfe or somesuch. if that's too much trouble, try calculating response rates / average values per factor level (I don't see any info whether your problem is classification or regression): you split your set into folds, and then for each fold fit a mixed effects model (e.g. via lme4) on the remainder, using the factor of interest as the main variable. It's a bit of a pain to setup all the cv correctly, but it's the only way to avoid leaking information. Hope this helps, K
