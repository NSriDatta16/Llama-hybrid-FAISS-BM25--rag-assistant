[site]: crossvalidated
[post_id]: 185033
[parent_id]: 
[tags]: 
Linear regression, adding lagged dependent variables

I have a regression (time series) problem $$y_t = w_1x_t+w_2z_t$$ Now, when I include a time-1 lag in this problem, so that the equation becomes $$y_t = w_1x_t+w_2z_t+w_3x_{t-1}+w_4z_{t-1}$$ my $R^2$ values go up a little bit, but further including a time-2 lag: $$y_t = w_1x_t+w_2z_t+w_3x_{t-1}+w_4z_{t-1}+w_5x_{t-2}+w_6z_{t-2}$$ completely ruins the model: Multiple $R^2$ is equal to $1$, but Adjusted $R^2$ is NaN (in R), all Std. Errors, etc. are NA. Also, when I use the learned models for prediction, the first model is slightly better than the lag-1 model, which is immensely better than the lag-2 model (the lag-2 model predicts nonsense). What could be the reason for this (other than some implementation error on my side)? Too few data points to estimate the model (I have only 11 observations, but quite a few variables: The lag-0 model has about 20 variables, then there are 40 for the lag-1 model, and 60 for the lag-2 model)? Or is this an instance of multicollinearity? Does this indicate that the lag-0 model is most suitable?
