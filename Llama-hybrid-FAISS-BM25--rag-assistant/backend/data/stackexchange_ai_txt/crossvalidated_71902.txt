[site]: crossvalidated
[post_id]: 71902
[parent_id]: 71884
[tags]: 
A confidence interval and a test aren't quite the same thing, but they are very much related, and often involve some of the same steps of calculation, though used in a different way. It's possible to turn CIs into tests ("Is the hypothesized value inside the $1-\alpha$ confidence region?") and vice versa ("What set of values of the parameter(s) lead us to fail to reject at level $\alpha$?"), though the latter is sometimes called a consonance interval (or consonance region for more than a single parameter). A confidence interval for say a mean of a normal-distribution will be based on a pivotal quantity like $Q=\frac{\mu - \bar x}{s/\sqrt{n}}$. This quantity has a t-distribution with $n-1$ degrees of freedom. For example, consider a sample of size 5. The density of $Q$, a $t$ with 4 degrees of freedom, will look like so: I have marked on the positions ($\pm 2.776$) that enclose 95% of that probability. That is, if we knew $\mu$, 95% of the occasions for which we compute a $Q$ for a sample of size 5 with normal data, $Q$ would lie between $-2.776$ and $2.776$. $$-2.776 \leq \frac{\mu - \bar x}{s/\sqrt{n}} \leq 2.776$$ $$-2.776\,{s/\sqrt{n}} \leq \mu - \bar x \leq 2.776\,{s/\sqrt{n}}$$ $$ \bar x -2.776\,{s/\sqrt{n}} \leq \mu \leq \bar x + 2.776\,{s/\sqrt{n}}$$ That is, an interval of 2.776 estimated standard errors* about the mean is the interval size in this case. *(standard deviations of the distribution of the mean) As the coverage of the interval changes, or the size of the sample changes, those values change. They come from the inverse of the cumulative distribution function of the relevant $t$ distribution; for a $1-\alpha$ interval, you find the value that cuts off an upper tail area of $\alpha/2$; the lower tail follows by symmetry. In large samples, the $t$ distribution with $n-1$ degrees of freedom approaches a normal distribution, and those critical values come from the inverse of the normal distribution function. (1.96 is the corresponding value for a 95% confidence interval for a normal distribution). Indeed, as $n$ approaches infinity, the distribution of the sample mean approaches a normal distribution as a result of the central limit theorem, and from Slutsky's theorem the statistic $Q$ also approaches a normal distribution. In such samples, to compute the number of standard errors (such as the 1.96 mentioned above) for a normal distribution, you use the inverse normal cdf. Conversely to all the above, to find the coverage of an interval of half-width being a given number of standard errors, we use the distribution function
