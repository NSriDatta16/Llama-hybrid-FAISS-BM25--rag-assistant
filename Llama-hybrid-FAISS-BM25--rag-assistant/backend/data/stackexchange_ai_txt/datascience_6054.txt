[site]: datascience
[post_id]: 6054
[parent_id]: 
[tags]: 
In SVM Algorithm, why vector w is orthogonal to the separating hyperplane?

I am a beginner on Machine Learning. In SVM, the separating hyperplane is defined as $y = w^T x + b$. Why we say vector $w$ orthogonal to the separating hyperplane?
