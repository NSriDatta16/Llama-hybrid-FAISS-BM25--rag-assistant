[site]: datascience
[post_id]: 128149
[parent_id]: 
[tags]: 
Enhancing Soil Moisture Predictions Using Multimodal Data Integration in Agriculture

I am exploring an interdisciplinary research area involving multimodal data, focusing on agriculture. My study incorporates both visual and tabular data: crop and soil images from three distinct locations, alongside corresponding meteorological information (temperature, humidity, solar radiation, etc.), collected hourly from 9 am to 5 pm. The objective is to enhance soil moisture predictions by integrating these data modalities, aiming to estimate soil moisture accurately from crop images. Could you please suggest methodologies for effectively combining these data types? I've experimented with or considered the following: Feature Concatenation, utilizing MLPs/Random Forest for meteorological data and CNNs for image analysis. Conv-LSTMs. Vision Transformers. Additionally, I'm curious about strategies for incorporating sequential soil patch images into models like Conv-LSTMs to capture both temporal and visual features. Do you think this approach is viable?
