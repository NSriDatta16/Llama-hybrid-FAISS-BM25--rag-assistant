[site]: crossvalidated
[post_id]: 470287
[parent_id]: 
[tags]: 
Generalized Bayesian Linear Regression with stochastic inputs

I know that in bayesian linear regression, the weights are treated as random variables along with targets. However, input features are treated as deterministic values. But in my case, the input features are also random. However, I do know the probability density function of the input features(and let's say they are gaussian with some known mean and variance for simplicity). My goal is to compute the posterior distribution of weights and more importantly the predictive distribution of the targets for a new test input (which accounts for uncertainty not in just weights and intrinsic noise in training data targets but also the input features). Additional info: The stochastic input features are actually predictions(with a certain distribution) themselves of a certain quantity that'll help in predicting the target variable. We do observe the inputs in our case but they won't be available in real-time when making predictions of target variable, so we have to rely on the predictions of input features. And to make matters worse, those input feature predictions come from a 3rd party outside our organization. PGM view: Below is the probabilistic graphical view of bayesian linear regression where inputs are treated as deterministic values (diagram taken from prml bishop fig 8.7), \begin{equation} x \text{, the input feature in small circle indicating deterministic value treatment} \end{equation} only difference in my case is \begin{equation} x \text{, should also be in bigger empty circle indicating randomness and latent/unobserved like } w \end{equation}
