[site]: crossvalidated
[post_id]: 402542
[parent_id]: 402511
[tags]: 
In abstract terms, neural networks are models, or if you prefer, functions with unknown parameters, where we try to learn the parameter by minimizing loss function (not just cross entropy, there are many other possibilities). In general, minimizing loss is in most cases equivalent to maximizing some likelihood function, but as discussed in this thread , it's not that simple. You cannot say that they are equivalent, because minimizing loss, or maximizing likelihood is a method of finding the parameters , while neural network is the function defined in terms of those parameters.
