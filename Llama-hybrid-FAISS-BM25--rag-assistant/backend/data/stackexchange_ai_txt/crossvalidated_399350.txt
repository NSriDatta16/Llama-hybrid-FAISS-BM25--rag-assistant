[site]: crossvalidated
[post_id]: 399350
[parent_id]: 
[tags]: 
LSTM Bounded Forecast Time Series

Can anyone please provide a logical explanation as to why an LSTM produces a 'bounded' forecast when predicting over unseen time series data? This behaviour does not seem to occur when using a MLP. Example: LSTM's are frequently used in anomaly detection (e.g. https://arxiv.org/pdf/1802.04431.pdf - Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding ). This property is utilised in these cases where a model is trained on a healthy signal, and then predictions made in real time on an unprocessed signal. The predictions will then deviate from the model indicating an anomalous subsequence. Hypothesis: is this due to hyperbolic tangent activation function within the LSTM unit?
