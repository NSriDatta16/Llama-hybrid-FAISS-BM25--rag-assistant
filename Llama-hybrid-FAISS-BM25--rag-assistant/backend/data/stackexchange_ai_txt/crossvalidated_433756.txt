[site]: crossvalidated
[post_id]: 433756
[parent_id]: 431189
[tags]: 
The bias of a neural network is the response to zero input, which is very similar to the response of a randomly initialized network. So, intuitively, if you initialize your biases to suboptimal values, the optimization with respect to the loss can gain most by first adapting the bias and thus setting the proper range for the output. Hence, setting the biases correctly according to your prior knowledge of the output makes for the weight being learned earlier on in the process. Note that another way to achieve the same behavior would be to normalize (zero mean, unit variance) the targets of the network.
