[site]: crossvalidated
[post_id]: 320163
[parent_id]: 
[tags]: 
logistic regression - why we forget assumption on data?

I read logistic regression formula i.e. $ \log\frac{P(C_1|X)}{P(C_2|X)}=w^Tx+w_o$ but this equation is true if we have $P(X|C_1)$ and $P(X|C_2)$ sampled from two Gaussian with the same covariance matrices ( $\sum_1=\sum_2$ ); furthermore, we can derive the sigmoid transformation $P(C_1|X) = \frac{1}{1+ \exp{(-(w^Tx+w_o))}}$ but the linearity is given by our assumption on $P(X|C_1)$ and $P(X|C_2)$ ; the question is: I have a strong assumption on the data generation $P(X|C_i)$ (i.e. Gaussian with same covariance matrix and then same "shape") but in logistic regression we throw away all these assumption and use this model without taking care the original data generation (I understand this from Machine Learning: A Bayesian and Optimization Perspective , page 291); isn't this a very strange thing? We are using something build on an assumption and then we throw away this assumption and use this model however? It seems to me a very bias model, because seems to be true just for a class of data (generated with Gaussians with same covariace) but not for all others dataset; where is my mistake? EDIT Here it said the same Logistic Regression cite: We make little assumptions on P(x|y), e.g. it could be Gaussian or Multinomial. Ultimately it doesn't matter, because we estimate the vector w and b directly with MLE or MAP. so, it seems that an assumption on Gaussian is done, but, in my opinion, the question remains, because I still make an MLE on a model that is based on data made by two gaussian with same covariances ...
