[site]: crossvalidated
[post_id]: 435590
[parent_id]: 435579
[tags]: 
If you have a decent number of subjects, it's fine to show the mean of the individual proportions of correct responses (correct looks). In one sense, it's better than taking the proportion of correct responses while ignoring the clustering by patient. You essentially have individual estimates of the probability of a correct response, and you are averaging them for a group estimate of the probability of a correct response. The challenge is your individual proportions of correct responses are not independently and identically distributed from some distribution. Some are being drawn from a distribution with a span of {0, 1/2, 1} and some with {0, 1/3, 2/3, 3}. You could argue they are iid from some mixture distribution, but either way, they aren't iid Normal. So if you were worried your standard t confidence interval (CI) for the mean which uses a critical value from the t-distribution wouldn't perform well in your setting, you could write a small simulation study to check its coverage. I did this below. Alternatively, you could compare those t CIs to the CIs from a good bootstrap approach. The performance of the t interval will depend on your number of subjects, number of trials per subject, and true probability of a correct look. You'll want to tweak the code to match your situation better. The simulation below gets 93% coverage - which isn't terrible. HOWEVER, change theta to 0.9 and coverage drops to 89% - which ain't great if you're wanting a 95% CI. So the validity of the t CI will depend on your study's settings. I'm allowing some subjects to have only 1 trial (see NsDist below). When the number of trials is always 2 or 3, performance is a little better, but it still depends on nsubs and theta. ## R script to validate my gut sense loops
