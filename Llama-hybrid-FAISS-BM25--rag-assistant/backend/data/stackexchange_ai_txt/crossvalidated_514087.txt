[site]: crossvalidated
[post_id]: 514087
[parent_id]: 
[tags]: 
Estimating Population Mean from Samples of Different Sizes

This is a super-simple question, but I've run into this problem a number of times and I haven't known how to solve it or even what this issue is called. Suppose I have a dataset consisting of 29 observations: 10 each from person A and person B, and 3 from person C, person D, and person E. Now, I want to estimate the expected value of an observation from a new person, person F (suppose too that there's no structural reason why persons A and B appear more in the sample, and person F is no more similar to them than person F is to C-E). But the estimates for persons A and B are more precise, so I want to weight them more. How much more? I think that depends on how much of the variance is within-group versus between-group, but I don't know the right estimator here. I believe the data generating process for observation j from person i looks like $\text{val}_{ij} = \mu + \gamma_i + \epsilon$ , where $\gamma$ and $\epsilon$ are normally distributed with mean 0 and variances $\sigma_\gamma$ and $\sigma_\epsilon$ . If I thought $\sigma_\gamma$ was 0, which is very easy to test, I could just pool them all. If I didn't care about efficiency, I could just calculate all the group means, take the mean of that, and if I have enough groups, I get a good estimate. But the right answer has to be a weighted average of the group means, taking into account that 10 observations from person A are more informative than 3 observations from person C, but less informative than 9 observations from persons C, D, and E. I've run into issues with grouping to which the answer was clustered standard errors, which of course are appropriate in this setting, but I don't know how to get a point estimate here. Below is some R code where weighting by the square root of the group size is a better estimator than either the overall mean or the mean of the group means, but that's only the case for some parameter values. Thanks for your help! library(Hmisc) library(data.table) library(foreach) true_mean = 0 n_big_group = 200 n_small_group = 40 n_groups_big_group = 10 n_groups_small_group = 50 n_groups = n_groups_big_group + n_groups_small_group within_group_sd = 0.1 estimates = foreach(seed = 1:500, .combine = rbind) %do% { set.seed(seed) data = data.table(id = c(rep(1:n_groups_big_group, times = n_big_group), rep((n_groups_big_group + 1):n_groups, times = n_small_group)) )[data.table(id = 1:n_groups, within_group_noise = rnorm(n_groups, sd = within_group_sd)), on = .(id) ][, val := true_mean + within_group_noise + rnorm(n_big_group * n_groups_big_group + n_small_group * n_groups_small_group)] data.table(unbinned = mean(data $val), binned = mean(data[, .(val = mean(val)), id]$ val), my_estimate = data[, .(my_weight = sqrt(.N), val = mean(val)), id ][, Hmisc::wtd.mean(val, weights = my_weight)]) } # RMSE estimates[, lapply(.SD, function(x) sqrt(mean((x - true_mean)^2)))] # unbinned binned my_estimate # 0.02365728 0.02244304 0.02165596 ```
