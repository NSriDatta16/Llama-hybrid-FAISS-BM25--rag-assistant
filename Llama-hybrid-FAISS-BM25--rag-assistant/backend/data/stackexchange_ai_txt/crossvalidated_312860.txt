[site]: crossvalidated
[post_id]: 312860
[parent_id]: 312859
[tags]: 
Here's my understanding of it: an autoencoder detects features without explicit labels. It's a technique for unsupervised learning. From http://ufldl.stanford.edu/wiki/index.php/Stacked_Autoencoders Intuitively, it is trying to detect 4 ( h1-h4 ) features from X, and then try to reconstruct X with an estimate Xhat , from the 4 detected features. Now if you put the h detected features as an input to another auto-encoder, you're effectively "stacking" auto-encoders, like the following: So intuitively, this is trying to detect more features within the previously detected features. This is therefore "greedy" or "greedily stacking shallow (only 2 layers) auto-encoders". Historically this stacking and training the shallow auto-encoders is computationally faster than training auto-encoders with 4-5 layers directly. Sorry for imprecise language, just trying to provide an intuition. I'm learning also.
