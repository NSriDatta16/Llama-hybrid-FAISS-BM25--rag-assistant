[site]: crossvalidated
[post_id]: 481430
[parent_id]: 
[tags]: 
Intuition behind replacing backpropagation with random matrices

In a recent paper on the experimental results of when neural networks learn via directed feedback alignment, https://arxiv.org/pdf/2006.12878.pdf , it was shown that directed feedback alignment achieved results similar, albeit worse, to backpropagation in a variety of tasks. A clear implementation of directed feedback alignment could be found in the origin paper, https://arxiv.org/pdf/1609.01596.pdf . Essentially, it replaces the transpose of the weight matrices used in backpropagation with random constant matrices. Does anyone have any idea why such a method could possibly work?
