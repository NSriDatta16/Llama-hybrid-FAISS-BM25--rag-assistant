[site]: datascience
[post_id]: 62604
[parent_id]: 62583
[tags]: 
Not every model is able to learn sample-by-sample or incrementally. However, in scikit-learn, there're some models which have partial_fit method: Incremental fit on a batch of samples. This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning. This is especially useful when the whole dataset is too big to fit in memory at once. This method has some performance and numerical stability overhead, hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead. You can just search for methods name in sklearn's documentation. This method exists, for example, for GaussianNB and Stohastic Gradient Descent , both Classifier and Regressor. Also, you can use Random Forest and set number of samples (or sample ratio) per tree is small to fit the memory. Or use Dask and Dask ML to fit your data in memory.
