[site]: stackoverflow
[post_id]: 3113615
[parent_id]: 3109755
[tags]: 
Rather strange seeing that every time you want to get the stats, all solutions above churn through entire database to get counts. Would suggest to keep the data in flat, indexes and only get results for specific item, one at the time. If your item count is large, it will me more efficient. from collections import defaultdict from itertools import groupby class myDB: '''Example of "indexed" "database" of orders items on order''' def __init__(self): self.id_based_index = defaultdict(set) self.item_based_index = defaultdict(set) def add(self, order_data): for id, item in order_data: self.id_based_index[id].add(item) self.item_based_index[item].add(id) def get_compliments(self, item): all_items = [] for id in self.item_based_index[item]: all_items.extend(self.id_based_index[id]) gi = groupby(sorted(all_items), lambda x: x) return dict([(k, len(list(g))) for k, g in gi]) Example of using it: events = """1-hammer 1-screwdriver 1-nails 2-hammer 2-nails 3-screws 3-screwdriver 4-nails 4-screws""" db = myDB() db.add( [ map(str.strip,e.split('-')) for e in events.splitlines() ] ) # index is incrementally increased db.add([['5','plunger'],['5','beer']]) # this scans and counts only needed items assert db.get_compliments('NotToBeFound') == {} assert db.get_compliments('hammer') == {'nails': 2, 'hammer': 2, 'screwdriver': 1} # you get back the count for the requested product as well. Discard if not needed. This is all fun, but, seriously, just go for real database storage. Because indexing is already built into any DB engine, all of the above code in SQL would just be: select p_others.product_name, count(1) cnt from products p join order_product_map opm on p.product_id = opm.product_id join products p_others on opm.product_id = p_others.product_id where p.product_name in ('hammer') group by p_others.product_name
