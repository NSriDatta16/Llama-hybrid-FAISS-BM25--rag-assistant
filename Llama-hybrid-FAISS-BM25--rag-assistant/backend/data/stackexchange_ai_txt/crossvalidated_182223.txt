[site]: crossvalidated
[post_id]: 182223
[parent_id]: 178676
[tags]: 
Interesting question. Let's try: $P(x)$ only depends on $f(x)$, $P(x) = g(f(x))$ (in your case $g(f)=f/a)$). Thus, your samples will not be close to the maximum of $f(x)$: the probability to observe a sample with value $f$ is $$P(f) = \int dx \int df\delta(f-f(x)) g(f(x))dx = \rho(f)g(f)$$ where $\rho(f)=\int \delta(f-f(x)) dx$ is the density of $f$. Your samples will most likely be at the maximum of $\rho(f)g(f)$. I agree with you that, ideally, looking at $P(x)$ is the correct way of doing it. However, I also agree with you that it may be difficult to observe at least one x, given that x is high dimensional. In general, the quality of the sampler is quantified by the autocorrelation time of the average you want to compute, because the variance of the average depends on that time. Without a specific average, I don't know any general methodology. I would try to look at $P(f)$. I would measure $P(f)$ as a function of the number of samples N and see how the KL between $N$ and $2N$ goes to zero with N. The quality of the sampler can then be formulated how many samples are required to achieve a given KL on $\rho(f)$.
