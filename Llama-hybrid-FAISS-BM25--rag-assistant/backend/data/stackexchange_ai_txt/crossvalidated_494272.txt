[site]: crossvalidated
[post_id]: 494272
[parent_id]: 
[tags]: 
Can large # of epochs or smaller batchsize compensate for smaller data size in training lstms

I have about 40 time series (40 products) of weekly sales for 3 years ( = 156 data points for each series). So, in total I have about 6240 data points. To train a stateful or stateless lstm for predicting the sales (assuming I have yearly seasonality) and this smaller data might be insufficient. Can I compensate the smaller data size by training for large # of epochs or having smaller data size, if I want to go with lstm?
