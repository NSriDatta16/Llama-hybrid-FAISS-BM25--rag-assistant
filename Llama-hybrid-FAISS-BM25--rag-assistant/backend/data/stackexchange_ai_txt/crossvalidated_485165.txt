[site]: crossvalidated
[post_id]: 485165
[parent_id]: 
[tags]: 
Understanding RSE(Residual Standard Error)

I am reading the book " An Introduction to Statistical Learning " and I have trouble understanding their explanation of RSE(Residual Standard Error ) . This is what the book says : "The RSE is an estimate of the standard deviation of \epsilon . Roughly speaking, it is the average amount that the response will deviate from the true regression line. It is computed using the formula :" What I don't understand here is definition of RSE as " Standard deviation of \epsilon " . If Residual = y(i) - yHat(i) and going by my assumption that \epsilon is also = y(i) - yHat(i) Isn't the formula of RSE just computing the "root(squared mean)" of \epsilon ? If \epsilon = y(i) - yHat(i) , Then , standard deviation of \epsilon would be sum[y(i) - yHat(i) - mean(Y - Yhat)] / n-2 which is not what the above formula does . So , Technically , I think RSE is just squared mean of the Residuals or \epsilon and would be wrong to call it " Standard deviation of \epsilon " , if we go by the actual formula for standard deviation . Or , In my opinion this should mean the standard deviation of predicted yHat values rather than \epsilon . So , is this a misuse of the term " standard deviation " in the book or Am I missing something ? Please correct or help me understand .
