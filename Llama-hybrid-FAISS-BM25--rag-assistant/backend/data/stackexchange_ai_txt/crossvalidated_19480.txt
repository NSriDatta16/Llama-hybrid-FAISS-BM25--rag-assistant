[site]: crossvalidated
[post_id]: 19480
[parent_id]: 17711
[tags]: 
Ridge regression, as the name suggests, is a method for regression rather than classification. Presumably you are using a threshold to turn it into a classifier. In any case, you are simply learning a linear classifier that is defined by a hyperplane. The reason it is working is because the task at hand is essentially linearly separable - i.e. a simple hyperplane is all that is needed to separate the classes. The "ridge" parameter allows it to work in cases that are not completely linearly separable or problems which are rank deficient (in which case the optimisation would be degenerate). In this case, there is no reason why other classifiers shouldn't also perform well, assuming that they have been implemented correctly. For example, the SVM finds the "optimal separating hyperplane" (i.e. the hyperplane that maximises the margin, or gap, between the classes). The C parameter of the SVM is a capacity control parameter analogous to the ridge parameter, which allows for some misclassifications (outliers). Assuming the parameter selection process has been carried out diligently, I would expect the two methods to produce almost exactly the same results on such a dataset.
