[site]: crossvalidated
[post_id]: 513695
[parent_id]: 513305
[tags]: 
Your post is confusing. In some places, it seems you are asking about predictive analytics in general. In others you sound like your describing time series cross-validation/backtesting, and yet in others like you are talking about reinforcement learning. You did however touch on a point that is far too often overlooked by data scientists, so I will address that specific one. Formulating a plan of action and predicting future events is the exact same problem, the only difference is what part of the timeseries that is masked off during training. No. This is incorrect, but I have seen many data scientists, and even entire orgs make this mistake, or at least be unaware of the consequences. In fact you can tell pretty quickly the maturity of an ML tool or process by whether they take this into account or not. Let me explain: Except for a few extreme cases like object detection for generic images, or very basic NLP problems, for the overwhelming majority of predictive business problems, predictions will be less than perfect. You may get 85%, 90%, maybe even 95% accuracy, but never the perfect predictive accuracy of an image recognition model trained on 10 million images. Since your models will be inaccurate at least some of the time, your model needs to provide not only the predictions but also the uncertainty or confidence levels of those predictions. The decision you will make based on that prediction will then require that you consider the uncertainty of the predictions not the precautions themselves. The uncertainty is a modeling output, just like the central prediction. You can consider it a second order prediction of sorts. How you handle the uncertainty is not, however, a second order or 3rd order prediction. It is a decision that you have to make - you decide, you can't predict the decision. You make the decision (most often using software aides, but still). Your plan of action will take in the predictions as input, but also consider business objectives, budgets and costs, willingness to take risks, overall business strategy, etc...and then you make a decision based on all of that. Now if we had the magical ability to generate 100% accurate predictions all the time, then yes you are correct: There is only one possible decision, since we know the future with certainty. Since that is not the case, there are multiple possible plans of action, and the uncertainty will help decide what the risk associate with each possible plan is. After which, we decide, are we willing to take more risk or less risk, and from there make a decision. Here are a couple of concrete examples: I often get asked "Can we predict the best price for which to sell our products?" No you can't. You can predict how much you are likely to sell for different price points, along with the uncertainty associated with each prediction. You know that if you lower the price you will get higher demand but lower margins. If you increase the price, you will get higher margins, but you might decrease your demand by scaring away customers. Based on the confidence intervals, you know the risk associate with each decision (in this case price point). Then you decide on how much risk you are willing to take, and you either set a high price point, knowing that you might win big, but also loose big. Or you set a lower price, and you will definitely win, but never as much as if the price point were high. Fraud Detection: You run an E-comm web site, and you use ML to predict whether a transaction is fraudulent or not (e.g. using a stolen credit card, etc...). You will train a classification model that will give a probability that a transaction is fraud or not. Are you more willing to occasionally anger a legitimate customer by erring on the side of caution and flagging transaction that have only a 50% chance of being fraud? Or do you care more about customer satisfaction and are willing to occasionally loose money, as long you know that your legitimate customers will always be happy? In fact you probably won't use just the probability alone. You will likely also factor the sum of money involved in the transaction: For lower sums, you will be willing to let a fraudulent transaction pass, since you're better keeping your customers happy. For larger sums, you will more likely flag a 50% probability of fraud transaction as fraud, and have someone review it at least, before allow it to pass. Where do you draw the line between the two decision approaches is again a decision, not a prediction. If you want to see a pretty good illustration of how prediction uncertainty and risk are connected, look at the Markowitz Mean-Variance model for portfolio investments. Now there are situations where the clear boundary I described between the prediction problem and the decision problems can get blurred, like Reinforcement Learning (which you seem to be hinting at with your statement about knowing the end state but not how to get there) or Bayesian Optimization. But if you dig a little bit deeper into those approaches, you see that under the hood they still follow the predict/decide dichotomy in their own way. For example most RL models have a purely predictive inner loop involved, which is then used to drive the decisions the RL model makes at each iterations. On the other hand, Bayesian Optimization treats the whole thing as a pure prediction problem, but only because you have to specify upfront what are all the decision parameters you want to use and risks you are willing to take, so that they only thing model has to do is predict accordingly.
