[site]: crossvalidated
[post_id]: 137547
[parent_id]: 137424
[tags]: 
The order the predictors are entered into the model is of course irrelevant to the question of whether there's separation in the data. The safeBinaryRegression package † masks the usual glm function from the stats package, which fits generalized linear models, so that, for logistic regression, glm uses a linear programming algorithm to check for both complete & quasi-complete separation before trying to fit anything. If it finds separation it reports Separation exists among the sample points. or The following terms are causing separation among the sample points: depending on whether you've asked it just to test for separation or to find the predictors causing it. Otherwise it reports nothing. Unexpected result from lpSolveAPI for primal test ,however, is a software error message, not a statistical one. You could perhaps try on a machine with more memory, but it's probably safe to trust the results from when you didn't get an error. Using stats:::glm (i.e using the glm function from stats when safeBinaryRegression 's loaded) should reach the same results regardless of the order of predictors; it will often report non-convergence or predicted probabilities of nought or one in cases of separation. Multicollinearity among the predictors is another issue entirely. Generalized variance inflation factors (see the vif function ‡ from the car package) are useful for assessing its extent in models with more than one degree of freedom per predictor. † Konis (2007), "Linear programming algorithms for detecting separated data in binary logistic regression models", DPhil., U. Oxf. ‡ Fox & Monette (1992), "Generalized collinearity diagnostics", JASA, 87 , pp178–183.
