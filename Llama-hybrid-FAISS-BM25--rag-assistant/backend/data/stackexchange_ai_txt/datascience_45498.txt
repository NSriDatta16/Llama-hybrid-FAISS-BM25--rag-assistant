[site]: datascience
[post_id]: 45498
[parent_id]: 
[tags]: 
Computing number of batches in one epoch

I have been reading through Stanford's code examples for their Deep Learning course, and I see that they have computed num_steps = (params.train_size + params.batch_size - 1) // params.batch_size [github link] . Why isn't it num_steps = params.train_size // params.batch_size instead?
