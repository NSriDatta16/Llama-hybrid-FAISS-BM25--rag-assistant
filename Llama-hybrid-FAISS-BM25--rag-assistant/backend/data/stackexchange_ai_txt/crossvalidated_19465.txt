[site]: crossvalidated
[post_id]: 19465
[parent_id]: 
[tags]: 
Convergence requirement of Parzen window estimates

In our Machine Learning class we recently came across Parzen Window Estimates . The following statement was made: Let $\hat p_n$ be the estimator $\hat p$ using $n$ data points and let $p (x)$ be the real distribution of the data. For an acceptable estimate, we would like to require: $$\lim_{n \to \infty}{\mathbb{E}[\hat p_n (x)]} = p(x)$$ $$\lim_{n \to \infty}{\text{Var}[\hat p_n (x)]} = 0$$ The first requirement I would paraphrase as 'asymptotically unbiased'. But with the second requirement combined, I don't see the difference to requiring just $$\lim_{n \to \infty}{\hat p_n(x)} = p(x).$$ Is there an aspect I am missing, or are the two formulations equivalent?
