[site]: datascience
[post_id]: 76336
[parent_id]: 76304
[tags]: 
You can very well use the GridSearchCV to fine tune RandomForest. I do not understand what you mean by "If I'm using GridSearchCV(), the training set and testing set change with each fold." Generally we apply GridSearchCV on the test_data set after we do the train test split. The Crossvalidation splits the training data into multiple train and test split based on the Kfold value that you give. For example if k value is 10 then we will have the training data splitted into 10 folds where 1 will be used for testing and 9 together used for training. This happens until all the 10 folds are used for testing so you will get 10 accuracy score. In addition to this in gridsearchcv we pass a set of hyper parameters based on the model that we are using. This helps is finding the best hyperparameters for the model to get the best accuracy score and also to avoid overfitting. On the other hand oob is some unseen data by the random forest model. Let me know if you need more information in detail. Hope this is helpful
