[site]: crossvalidated
[post_id]: 579335
[parent_id]: 
[tags]: 
Combining Several Random Forests Together - Is this Statistically Valid?

I was reading this paper on the history of Bagging Estimators ( https://www.stat.berkeley.edu/~breiman/bagging.pdf ) and came across the following question ( Why is bagging stable classifiers not a good idea? ). Over here, the following point is mentioned: Apparently, there are theoretical reasons that suggest that bagging "stable models" (e.g. Random Forests) is not advisable as this may in fact result in a loss in accuracy. While this may be true, I noticed that the "randomForest" library in R (one of the most popular implementations of the Random Forest) has a function which allows you to directly combine several Random Forest models together (this looks like we are "combining" the three models together, not "bagging"): # https://cran.r-project.org/web/packages/randomForest/randomForest.pdf library(randomForest) data(iris) rf1 I was just trying to better understand this point : If it is not advisable to bag together several "stable models" such as Random Forest - is there any reason that one of the main implementations would allow for these models to be "combined" together? Or do these theoretical warnings only refer to "bagging" stable models together and not "combining" stable models together? Thanks!
