[site]: datascience
[post_id]: 33701
[parent_id]: 
[tags]: 
How to interpret PR and ROC Curve for an unbalanced test set

I have trained a neural network on a dataset, the test set is very unbalanced, ratio between positive examples and negatives is 1:25000. All positive examples are correctly predicted, instead negatives elements correctly predicted are 99% of total negatives. Plot of PR and ROC curves are those: What can be inferred from these curves? Those are my firsts works with classifiers and i'm confused. I think that precision is always low, because the negatives that are wrong predicted as positive have an high score assigned by the classifier (close to 1). ROC instead i think that is high because all positive examples are correctly predicted. These are my suppositions, correct me if I am wrong.
