[site]: crossvalidated
[post_id]: 585791
[parent_id]: 
[tags]: 
Reducing data set to preserve i.i.d. assumption in machine learning?

In statistics there is a lot of literature about sampling, but I have not found any machine learning literature that discusses the quality/usefulness of the data set itself. This comes as a surprise to me, as the i.i.d. assumption is important in e.g. Vapnikâ€“Chervonenkis theory for generalization. Specifically, I have 88.000 data points for housing prices from the period 2000-2022. Assume that housing prices in 2000 resembles a different housing market than today's housing market, i.e. housing prices in 2000 are drawn from a different distribution. If I want to be able to predict housing prices today, is it an acceptable procedure to reduce the data set to avoid this problem? As there is a trade-off between data length and the i.i.d. assumption, I also thought of running two ML experiments, one in which the whole period is used, 2000-2020, and one in which e.g. 2016-2020 is used, and then use newly sold houses as test data. Once again, however, I'm unsure if this is the way to go.
