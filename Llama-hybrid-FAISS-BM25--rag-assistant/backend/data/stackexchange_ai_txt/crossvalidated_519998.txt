[site]: crossvalidated
[post_id]: 519998
[parent_id]: 519993
[tags]: 
I am thinking about stability selection more like a statistical procedure to give you a set of significant variables in a high dimensional setting, where traditional linear regression would fail. That it uses LASSO in the paper, which is usually used for machine learning purposes is kind of a red herring. Now, as you correctly noticed, it cannot be easily used for model selection, but you can use it for feature selection, where the selected features by stability selection will be likely better than features selected by LASSO alone. In this case, you will first select variables using stabsel, and then fit a model that does not have to be LASSO, since you don't want to do another feature selection on these variables alone. You don't need to only take the selected variables, since the stabsel selection is quite conservative. Just be sure you do it inside your CV loop to avoid double-dipping. Another possibility is to run and validate your LASSO the same way as you do. But then as a supplementary analysis also run stability selection to tell you which variables are significant. Since prediction and identifying statistically significant variables are separate goals, you can have separate analyses for that. ps: stability selection works for any feature selection method, not just LASSO, lasso is just very convenient since it can produce the whole regularization path in one go
