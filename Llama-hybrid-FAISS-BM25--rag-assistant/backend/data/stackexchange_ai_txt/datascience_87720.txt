[site]: datascience
[post_id]: 87720
[parent_id]: 
[tags]: 
Reduce serving time complexity for real-time recommender systems

I am working on a real-time recommender system predicting a product to a user using deep learning techniques (like wide & deep learning, deep & cross-network etc). Product catalogue can be huge (1000s to 1 million) and for a given user, the model needs to be evaluated against each product in real-time. As scalability is an important concern, is there any way to reduce the serving time complexity by tuning model architecture?
