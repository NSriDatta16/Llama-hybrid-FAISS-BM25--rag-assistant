[site]: crossvalidated
[post_id]: 312294
[parent_id]: 309677
[tags]: 
I don't know a name for this model. I think what you want can be found as some kind of maximum likelihood estimate. Assuming the letters don't change location, you'd use 26 parameters, representing the location of each letter. Then you will have to think of the likelihood of seeing the "bundle" F - G - H for example. This likelihood can be a formula based on the three letters. Let's say the likelihood is h - g ~ Normal(.5, .5) and g - f ~ Normal(.5, .5) This way, parameters can switch, but the model would, based on only this particular likelihood, put H before G and G before F . There is something weird where it doesn't like them too far apart, but let's forget about that for simplicity right now. This likelihood should ideally be informed by how the bundle-choser works. Then you use some package that can find a Maximum Likelihood estimate. Maybe you can use stan to code the model, with the added benefit that Bayesian confidence intervals are around the corner. Or, if that works for your likelihood (it does in the simple case above) you can create a design matrix a bit like below, a b c d .. z -1 0 1 0 .. 0 1 -1 0 0 .. 0 and even fit it with r::lm . In this system, you'd use two lines per observation. The important point is that you will have to specify the balance between putting observations farther apart, or maybe switching labels, and all that can be done by specifying a likelihood. Then you optimize for the 26 parameters. EDIT Okay I didn't read your question too well, since you are already talking about a loss function, which is pretty much what's described here. If you have ~100K observations, specifying it as a linear model with 26 parameters, I think you can still fit such a thing. If you even need all those samples.
