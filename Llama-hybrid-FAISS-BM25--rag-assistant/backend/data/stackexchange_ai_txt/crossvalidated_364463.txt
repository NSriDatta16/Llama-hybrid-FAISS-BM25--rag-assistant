[site]: crossvalidated
[post_id]: 364463
[parent_id]: 
[tags]: 
Vae reconstruction loss

I have implemeted a Variational Autoencoder(VAE) with a prior different from unit gaussian. This gives me extremely sharp reconstructions compared to normal VAE(small values for reconstruction loss). But the generated samples are of extremely poor quality. Why is that? Also would the generated samples improve if trained longer. Right now I'm training for 50 epochs. Edit: The prior is similar to Laplace distribution. I'm working on Mnist dataset. Currently I'm comparing the reconstruction loss of vanilla vae with this custom vae for validation. Also the reconstructed images have no blurring. But it seems the latents learn nothing. I tried training for 200 epochs with no difference in generated samples but reconstructions got better.
