[site]: stackoverflow
[post_id]: 597286
[parent_id]: 597257
[tags]: 
I've learned quite a bit about low-level programming, and I think it's been tremendously helpful in every bit of code I write. Even high-level languages have some version of, say, the basic synchronization primitives (mutexes/locks, conditions, semaphores); they still have to read from the disk or from a network card; they still have to copy bytes from one place in memory to another, and so on... the point is, the fact that you're using a high-level language doesn't mean it's useless to know how those things work. If you have an understanding of how a computer functions at the lowest level, you can always apply that knowledge to write more efficient and/or less bug-prone code regardless of how abstracted your platform is. Knowledge of the low-level operations can even teach you things that you might never have learned otherwise - there's no better way to learn how to properly use something like a mutex than to have to implement one. (Okay, maybe that's slightly exaggerated, but you get my point I hope) Bottom line, I would say that yes, it is absolutely a good idea for programmers at all levels of abstraction to learn about the fundamentals. But I don't think it's necessarily such a good idea to start with the fundamentals. Programs at the level of assembly language are notoriously hard to understand and I think trying to foist that on a beginner to programming is just likely to discourage him/her. I mentioned that understanding basic operations will help you write more efficient and/or less error-prone code, but it's certainly not necessary to write code at all. So in my opinion, most people would probably do best starting somewhere in the middle, where they can still latch on to familiar concepts like objects while getting acquainted with the process of coding. After some experience in that area, CPU stuff is fair game ;-)
