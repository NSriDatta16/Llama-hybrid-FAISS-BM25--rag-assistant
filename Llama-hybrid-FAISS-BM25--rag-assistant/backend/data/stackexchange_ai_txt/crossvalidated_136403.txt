[site]: crossvalidated
[post_id]: 136403
[parent_id]: 
[tags]: 
determining how "important" a feature is in predicting a target in decision trees

Random forests allow us to compute a heuristic for determining how "important" a feature is in predicting a target. This heuristic measures the change in prediction accuracy if we take a given feature and permute (scramble) it across the datapoints in the training set. The more the accuracy drops when the feature is permuted, the more "important" we can conclude the feature is. Importance can be a useful way to select a small number of features for visualization. I have read about this method to select the important features in random forest. Can some one explain me what does scrambling a feature means in random forest??
