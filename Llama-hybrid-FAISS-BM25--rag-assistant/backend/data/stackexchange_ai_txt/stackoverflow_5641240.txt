[site]: stackoverflow
[post_id]: 5641240
[parent_id]: 
[tags]: 
Hadoop Distributed File System (HDFS) is the default file storage system used by Apache Hadoop. HDFS creates multiple replicas of data blocks and distributes them on data nodes throughout a cluster to enable reliable, and computation of huge amount of data on commodity hardware.
