[site]: datascience
[post_id]: 100018
[parent_id]: 
[tags]: 
Comparing RMSEs of multiple test sets having different sizes

The data I have is a time series data (stock returns), and I am training a Random Forest Regressor on it. Total observations = 2499 To better evaluate the performance, I have implemented rolling windows testing with training window sizes = 500, 700, 900,..., 2100. Though instinctively it would seem obvious to choose a window size which produced lowest RMSE, how can I be sure that the comparison is fair? I mean with increasing window size, the test set size decreases. With window size 500, test set size is 1999. With window size 700, test set size is 1799. I think the same question applies to Expanding Window So is it sensible to compare RMSEs when test samples are decreasing in size? If not, then how should one choose the best training window?
