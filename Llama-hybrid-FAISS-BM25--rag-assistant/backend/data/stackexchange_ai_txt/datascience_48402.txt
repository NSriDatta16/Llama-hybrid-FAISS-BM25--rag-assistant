[site]: datascience
[post_id]: 48402
[parent_id]: 38924
[tags]: 
So, this is a simple problem that could be solved using one-shot learning technique. To achieve this, we must build a model that understands our data and is capable of finding similarity or dissimilarity in your data. For this, we must carry out the following steps: Train (or finetune) the network on dataset of related images. After training the model, clip the last predicting layers to create embedding. Pass your testing data through the network and store individual embedding. Find the difference between the embedding and find the differences crossing a certain threshold. These images are potentially images having similar data and this could be easily used to find duplicacy in the dataset. I referred this paper on oneshot learning and later found this blog to be a little helpful.
