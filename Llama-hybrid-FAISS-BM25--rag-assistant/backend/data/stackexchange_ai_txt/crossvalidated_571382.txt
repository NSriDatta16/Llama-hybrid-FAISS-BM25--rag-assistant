[site]: crossvalidated
[post_id]: 571382
[parent_id]: 
[tags]: 
Parallel with Weighted Least Squared in Bayesian Regression

I have a dataset with a column of ratios $Y = z_1 / z_2$ , which will be my depending variable, and a set of columns that explain $Y$ . Here $z_1$ means "imports" and $z_2$ means "exports", which for different products comes from yearly data of the form Year: 2021 Product: Portable automatic data processing machines, weighing not > 10 kg, consisting of a least a central processing unit, a keyboard & a display Exporter | Importer | Value reported by the exporter | Value reported by the importer USA | Canada | 100 | 110 In this data both values may contain errors, and in a perfect world the value reported by the importer should be equal to the value reported by the exporter plus cost of transport. In addition to the columns required to fit a model involving $Y \mid (x_1,\ldots,x_n)$ , I have an additional column of weights $W$ , that I computed as $[\min(z_1,z_2) / \max(z_1,z_2)]^2$ , so that it reflects the discrepancy between the variables used for the ratio. In this problem I am interested in giving more weight to more concordant observations. Under a classic approach I would write glm(Y ~ x1 + x2 + ..., link = gaussian(), weights = w) # or Gamma() Is there an approach to do this in Stan? The documentation points at integer sampling/survey weights. For a bayesian model I've written the next Stan code which is not minimizing the sum of weighted squared residuals to produce residuals with a constant variance, but at least fits a hierarchical model. data{ int N; // number of observations vector[N] Y; // dependent variable CIF/FOB ratios vector[N] dist; // independent variable "distance" vector[N] year; // independent variable "year" vector[N] contig; // independent variable "contiguity" vector[N] colony; // independent variable "colony" vector[N] comlang_off; // independent variable "common language" vector[N] rta; // independent variable "regional trade agreement" vector[N] reporter_trade_sanction; // independent variable "sanctioned reporter" vector[N] partner_trade_sanction; // independent variable "sanctioned partner" int reporter_continent[N]; // independent variable "reporter continent" int partner_continent[N]; // independent variable "partner continent" } parameters { vector[8] beta; vector[6] alpha_reporter_continent; vector[6] alpha_partner_continent; real sigma_reporter_continent; real sigma_partner_continent; real sigma_mod; } model { target += normal_lpdf(Y | alpha_reporter_continent[reporter_continent] + alpha_partner_continent[partner_continent] + beta[1]*dist + beta[2]*year + beta[3]*contig + beta[4]*colony + beta[5]*comlang_off + beta[6]*rta + beta[7]*reporter_trade_sanction + beta[8]*partner_trade_sanction, sigma_mod); // priors target += normal_lpdf(alpha_reporter_continent | 0, sigma_reporter_continent); target += normal_lpdf(alpha_partner_continent | 0, sigma_partner_continent); target += normal_lpdf(beta | 0, 10); }
