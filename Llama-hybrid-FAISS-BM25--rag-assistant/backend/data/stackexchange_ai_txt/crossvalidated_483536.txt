[site]: crossvalidated
[post_id]: 483536
[parent_id]: 483535
[tags]: 
Entropy measures the amount of randomness or surprise of a random phenomenon/experiment , not necessarily a random variable (the latter need not even be defined). Regarding your question, measures of spread such as mean absolute deviation, variance and the like could be relevant. E.g. variance could indeed be considered an adjusted entropy measure that is a weighted average of the probabilities and [observed] values . For a continuous random variable with expectation $\mu_X$ and probability density $f(x)$ , $$ \text{Var}(X)=\int_{-\infty}^{\infty}(x-\mu_X)^2f(x)\ dx; $$ for a discrete one with possible values $x_1,\dots,x_n$ with the corresponding probabilities $p_1,\dots,p_n$ and with expectation $\mu_X$ , it is $$ \text{Var}(X)=\sum_{i=1}^{n}(x_i-\mu_X)^2 p_i. $$ You can see both the possible values and their probabilities/densities playing a role.
