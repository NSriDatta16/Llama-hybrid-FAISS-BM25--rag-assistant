[site]: crossvalidated
[post_id]: 236322
[parent_id]: 
[tags]: 
Does my classification model suffer from information leak?

I'm trying to solve a recommendation problem (recommending items to users). I have a dataset of triplets (user, item, reaction) , where reaction is either 0 or 1 (negative or positive) and two recommendation models: popularity-based: outputs relative popularity for a given item (the higher popularity is, the better). item-item k-nearest-neighbors: as described here . I now want to combine predictions from both models by logistic regression, and transition from (user, item, reaction) -dataset to (knn-score, popularity score, reaction) . Since reaction is binary, it seems perfectly reasonable to fit a logistic regression model on it, using knn-score and popularity score as features. The question is: can I do that on the same training set, or do I need additional cross-validation/folding, because my case seems to fit stacked generalization/blending approach? I.e., is there a possibility that my first-order recommenders (knn/popularity model) will leak information to the regressor? The argument against blending, I guess, is the fact that both of my first-order models are non-parametric, i.e. cannot overfit the data in the first place. They are just deterministic transformer functions (transforming item categorical variable to its frequency, for example, as popularity-based model does), which completely depend on data. Does this reasoning sound correct - or do I have to partition the data into folds and train first/second order models on different ones still?
