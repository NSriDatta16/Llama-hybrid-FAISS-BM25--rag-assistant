[site]: crossvalidated
[post_id]: 421736
[parent_id]: 421732
[tags]: 
Noisy labels for neural networks it is a challenging task. As they have a very flexible power of representation they adjust very well to data resulting in overfitting. Overfitting could lead us to misclassifying instances in test. Besides, if we have noisy labels, we will have even a worse model. I think there is not a closed topic and it is currently an interesting topic in data science research. Specially, in medical topics where the labels are usually noisy (because the difficult of labelling, doubtful cases,...) are many papers with several different approaches. I recommend you this paper: https://arxiv.org/pdf/1803.11364.pdf They use Expectation-Maximization (EM), learning both clean labels and the model iteratively together. They update weights with fixed labels and them they update labels with fixed weights. They also incorporate other things. Look at the error loss and the regularization terms. In the error loss regularizer $\mathcal{L}_p$ you can incorporate your information about expected label proportion. Besides, the regularizer $\mathcal{L}_e$ forces to predict one clean label and avoid so much uncertainty when predicting clean labels. In this way, you learn both neural networks weights and clean labels.
