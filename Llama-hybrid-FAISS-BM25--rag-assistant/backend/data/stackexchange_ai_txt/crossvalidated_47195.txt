[site]: crossvalidated
[post_id]: 47195
[parent_id]: 47132
[tags]: 
If your categorical data are ordered, and therefore could be transformed to continuous (but integer) variables, then the Random Forest algorithm is likely to be a competitive solution which requires very little tuning compared with other methods (such as neural networks). RF will effectively do feature selection (of sorts) internally so you shouldn't need to do any pre-selection before sending the data to the algorithm. In the case that you have unordered categorical variables then you can create a set of new binary variables representing each categorical one. For instance the variable Animal which could be one of Cat, Dog or Horse would become three variables, Cat, Dog and Horse with one set to 1 and the rest 0 depending on the value of the original variable. There is a succinct technical name for this kind of approach, but I can't remember what that is. It doesn't matter that this might produce lots of new variables as RF scales well with the number of inputs.
