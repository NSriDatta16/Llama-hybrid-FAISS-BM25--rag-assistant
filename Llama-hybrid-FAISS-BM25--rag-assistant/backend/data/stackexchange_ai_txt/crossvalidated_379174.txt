[site]: crossvalidated
[post_id]: 379174
[parent_id]: 378516
[tags]: 
Let me answer myself. First of all, my criterion of choosing any method for dimensionality reduction is visual inspection of a 2D mapping with a layer of clusters and their description. Judging by that, I like t-SNE more given it has mapped some of my texts into clear clusters (topics). MDS and PCA that I also tried did not give a clustering look to the mapping. Another option that I explored is a neural network designed specifically (by myself) for this task. Take a look and comment if you think it is worth it. First, I create input vector which is a concatenation of two objects in the k-dimensonal space. Then I build a multilayer dense network with bottleneck. The k-dimesnional input vector is being convolved to just 2 scalars. Notice that the layers that convolve k dimensions to 2 dimensions are shared between both input vectors. After that I include a stack of dence layers that should approximate euclidean distance (calculated between k-dimensional objects) using just 2-dimensional objects stemming from the bottleneck part. As a result the NN leans to approximate the euclidean distance from first calculating an input of 2 + 2 scalars denoting the preojection on a 2D plane. ## build keras model for dimension reduction ------------------------- input1 % shared_layer2 %>% shared_layer3 %>% shared_layer4 text_2_model % shared_layer2 %>% shared_layer3 %>% shared_layer4 main_output % layer_dense(units = 32, activation = "relu") %>% layer_dense(units = 16, activation = "relu") %>% layer_dense(units = 1) convolving_model % compile( loss = "mse", optimizer = optimizer_adam(), metrics = list("mean_squared_error") ) epochs % fit( x = list(train.x.1, train.x.2) , y = train.y , batch_size = batch_size , epochs = epochs , validation_split = 0.3 ) plot(history) After the NN has converged, I take the output of a hidden layer that is the 2D plane projections of the two input vectors. Use them as your dimensionality reduction matrix of coordinates. ## get hidden representations layer_name Surprisingly, the correlation of the euclidean distances between the calculated 2D coordinates and the original k-dimensional distances is a whopping 0.85 (if the NN converged well). colnames(calc_coords)
