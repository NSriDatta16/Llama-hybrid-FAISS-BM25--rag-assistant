[site]: crossvalidated
[post_id]: 622662
[parent_id]: 622655
[tags]: 
The only paper I've seen which includes an experiment on this issue for CNNs is Facenet: A unified embedding for face recognition and clustering 1 . Table 5— —demonstrates that differences are not significant for the $\text{VAL}$ metric, which is an accuracy metric for facial recognition tasks (see section 4). i have to have more epoch of learning before enough result Indeed, the authors hypothesize in section 5.4 that the drop in $\text{VAL}$ from $256$ to $512$ dimensions may be explained by the fact that the latter model required "more training". It's unclear whether the Table 5 experiments hold the number of epochs constant, so it's unclear whether "more training" refers to more training data (because larger models generally require more training data) or more epochs. In either case, without concrete experiments, I'm not convinced that increases in embedding dimensionality warrant significant increases in training compute. The increase in parameter count going from $256$ to $512$ is $1024(512 - 256) = 262,144$ for their NN2 Inception model (see Table 2). So the relative increase in (trainable) parameter count for the whole model is roughly $262,144 / 7.6\text{M} \approx 3\%$ . While parameter count is not a great proxy for model complexity 2 , this increase doesn't seem like something to worry about. An important consideration: if you're finetuning a pretrained CNN, the relative increase in trainable parameter count could be significant. In conclusion, I wouldn't worry too much about setting the embedding dimensionality too low. Most of the learning happens in the CNN backbone, which typically dwarfs the last linear/embedding layer. Go with a number which is in the ballpark of what worked for others who solved a task + data + architecture which is similar to yours, e.g., $[64, 512]$ if your images are faces. Half it if you're concerned that you don't have enough training data. If there isn't a relevant ballpark in the literature, then you'll have to do the hard work of validating one yourself. If there is one, the embedding dimensionality will be one of the last hyperparameters you need to tune, if at all. References Schroff, Florian, Dmitry Kalenichenko, and James Philbin. "Facenet: A unified embedding for face recognition and clustering." Proceedings of the IEEE conference on computer vision and pattern recognition. 2015. Nakkiran, Preetum, et al. "Deep double descent: Where bigger models and more data hurt." Journal of Statistical Mechanics: Theory and Experiment 2021.12 (2021): 124003.
