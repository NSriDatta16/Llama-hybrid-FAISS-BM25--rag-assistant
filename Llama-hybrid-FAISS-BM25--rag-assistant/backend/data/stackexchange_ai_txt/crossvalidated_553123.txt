[site]: crossvalidated
[post_id]: 553123
[parent_id]: 550311
[tags]: 
Why not follow up on both ideas, or at least on things closely related to both ideas? You seem to have enough sample data to model those data independently and then evaluate how well the model coefficients agree with those in the "population model." That might be the simplest way to both "parameterise a multi-state model for the 'sample model'" and use your sample data as a validation set for the "population model." Details depend on the type of model (parametric vs. semi-parametric) you're working with. The Cox-model semi-parametric analysis provided by the standard coxph() function in R nicely handles multi-state models with arbitrary transitions, based on left-truncated/right-censored data, as explained in a multi-state vignette and in Chapter 8 of Therneau and Grambsch . The flexsurv package allows for parametric multi-state modeling, as explained in a vignette . Using the "population model" to provide priors for a Bayesian model would tend to undercut any use of your "sample data" as a validation set for the "population model." If you do want to use a Bayesian approach, the likelihoods are just standard Cox partial likelihoods or parametric full likelihoods, evaluated for each transition with the corresponding covariates. The R Survival task view has many entries for Bayesian survival modeling, although I can't say whether any handle multi-state models. Evaluating the performance of the "population model" on your sample data would be a useful parallel evaluation. For a fair test, you should use the performance criteria applied in originally developing that model.
