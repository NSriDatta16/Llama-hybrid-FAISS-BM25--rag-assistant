[site]: crossvalidated
[post_id]: 508265
[parent_id]: 407811
[tags]: 
I think one of the differences is that missForest is, at least in its original form, a method for single imputation, i.e. imputing a single best imputation. It tries to find the "best" predictions for the missing values given some set of predictors that it identifies (e.g. using internal variable selection). It therefore does not account for inherent variability due to missingness, leading to overconfidence or bias in whatever analysis you do using the imputed dataset (see here and here for a discussion, and this paper for bias due to missForest ). mice on the other hand, even under a random forest-based implementation, tries to produce imputations that have a random component to them, instead of the "best" prediction (see here for a discussion). See this paper for how mice does random forest-based imputation. Essentially, it runs multiple random forest imputation models on bootstrapped samples of observed data and randomly selects the predicted value from one of the models.
