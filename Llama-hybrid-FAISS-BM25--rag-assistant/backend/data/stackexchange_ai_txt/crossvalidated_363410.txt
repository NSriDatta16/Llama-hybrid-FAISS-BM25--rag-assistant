[site]: crossvalidated
[post_id]: 363410
[parent_id]: 
[tags]: 
How To Choose Step Size (Learning Rate) in Batch Gradient Descent?

I'm practicing machine learning in python and trying to implement batch gradient descent algorithm by myself. Mathematically algorith is defined as follows: $\theta_j = \theta_j + \alpha \sum_{i=0}^{n}{(y^{(i)}-h_{\theta}^{(i)})x_j}$ for every j. where $x:$ input data $y:$ output data $n:$ number of data $\alpha: $ step size As a data, I have some house sizes in the US and respective house prices.Data can be found here . (Second row is irrelevant data, room number) My python code is like that: import numpy as np import matplotlib.pyplot as plt file = open("C:/Users/KubilayCan/Desktop/Python/Ben/ML/house_prices.txt", "r+") house_size, bedrooms, prices = list(), list(), list() for idx in file: temp = idx.split(",") house_size.append(int(temp[0])) bedrooms.append(int(temp[1])) prices.append(int(temp[2])) x = np.array(house_size) y = np.array(prices) # plot of given data plt.xlabel("House Size") plt.ylabel("Prices") plt.title("Graph 1:House Prices vs Prices") plt.scatter(x,y,c="r") plt.show() # batch gradient algorith #initialize x and theta ones = [1] * len(house_size) x_temp = list(zip(ones, house_size)) x = np.array(x_temp) x = np.transpose(x) theta = np.array([0 , 0]) alpha = np.array((0.007,0.00000002)) iteration = 1000 iter = 0 while iter True result (when closed form of gradient descent is used): [70610.61964034 134.35956941] Although I get somehow close, I couldn't get exactly this result. When I play with alpha values my results are dramatically change. How can I find the true values for the alpha variable? Is that only intuition? Or is there any mistake in my python code?
