[site]: datascience
[post_id]: 107766
[parent_id]: 107537
[tags]: 
It took me a while to understand what you meant, given that you also have a near-maximum at 50. But I think you mean you want to lower the risk, and stay away from that nasty looking minima at around 45? Averaging each point with its neighbour on either side gives you that. Averaging with N points either side makes it smoother, the higher N is. Even better is a weighted average, so points further away have less influence. (It looks like N is another hyperparameter we need to tune for! But I think we can guess say N should be 1 or 2 when dealing with a small number of points like this.) I didn't find a moving average function in scikit, but in pandas there is pandas.Series.rolling() . Or the answers at https://stackoverflow.com/q/14313510/841830 could be useful. Additional: My first thought had been to run this smoothing on each dimension (e.g. each hyperparameter), one at a time. But you can expand the idea to more dimensions: it would require using a nearest-neighbours algorithm to decide which are the N neighbours to average with. It might be more efficient to instead calculate the distance to every other neighbour, and weight based on inverse-distance or inverse-distance-squared. (So all other points influence the result, but the nearer ones have more influence.) It'll require playing around with the relative weight for the original point.
