[site]: stackoverflow
[post_id]: 5516812
[parent_id]: 5516641
[tags]: 
Well, it's a bit tough to tell what you need without specifics on your situation. For example, what is your sensor sampling rate, and how is the sensor fluctuation and noise that you're trying to remove characterized? However, if you already have moving average implemented, I might recommend trying a moving median instead. (Median of the last n samples, rather than average.) This will tend to reduce the impact of large short-term aberrations from normal from your output. If you can find parameters that work, it would be preferrable for CPU and memory requirements to use some form of a discrete-time low-pass filter. These are quite easy to implement, and only require knowledge of the previous output value and the current input to compute the current output. For example: Y = Y[n-1] + A * (X - Y[n-1]) (Where Y is the current output, Y[n-1] is the last computed output, and X is your latest sensor reading.) A is effectively the time constant of the low pass filter, but it's discrete time, so it depends on the sampling rate. Specifically, A = dt / tau , where dt is your sampling period in seconds, and tau is roughly analagous to the continuous-time time constant.
