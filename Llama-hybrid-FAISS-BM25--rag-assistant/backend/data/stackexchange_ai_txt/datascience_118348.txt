[site]: datascience
[post_id]: 118348
[parent_id]: 118343
[tags]: 
The problem here is that the SBERT embedding of a piece of text is a single vector, while the embeddings you get from Whisper are a sequence of vectors. Therefore, it's not a matter of just mapping two embedded spaces, but mapping a sequence of vectors in an embedded space to a single vector in a different space. Of course, you could train a small multi-head attention to mimic the equivalent SBERT but nothing guarantees that such an approach would give comparable results to computing the SBERT from Whisper's output text, or that it would be computationally worth it.
