[site]: crossvalidated
[post_id]: 319514
[parent_id]: 
[tags]: 
Why feature scaling only to training set?

I was following the book "Hands-On Machine Learning with Scikit-Learn & TensorFlow" by "Aurelien Geron". The following remark was made about feature scaling : - As with all the transformations, it is important to fit the scalers to the training data only, not to the full dataset (including the test set). Only then can you use them to transform the training set and the test set (and new data) My understanding of the above text is that feature scaling is done only on the training and not on the test set. Is this interpretation correct? In case yes, what is the rationale behind not using feature scaling for test dataset?
