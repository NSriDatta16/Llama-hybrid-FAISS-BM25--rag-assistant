[site]: crossvalidated
[post_id]: 613629
[parent_id]: 586202
[tags]: 
OK, here's my take on "how should we interpret them?" The p-value generally is the probability, assuming the null hypothesis (H0) were true, that we would observe something that is as far or further away from what can be expected under H0, than what we actually observed. If the p-value is very small, we have observed something that indicates so strongly against H0 that it would very rarely happen, were H0 in fact true. This makes the H0 look incompatible with the data, and can in this way count as evidence against it (depending on how small the p-value actually is, we can differentiate between weak, moderate, strong, (...) evidence against it). "As far or further away from what is expected" is defined in terms of the test statistic, i.e., the test statistic defines a direction of "critical deviation" from the H0. This has three implications. Firstly, even though a certain test may not provide evidence against the H0, it is still possible that the H0 is wrong in different ways than captured by the test statistic, which could in principle be found by other tests (i.e., violations of other aspects of the probability model chosen as H0, usually framed as "violation of the model assumptions"). Secondly, probability models are idealisations and one should not think that they can be literally "true" in reality. This means that non-rejection should never be interpreted as indication that the H0 is true. At best, it indicates that the data look more or less like data generated by the H0 can be expected to look like, considering the specific aspect measured by the test statistic . As p-values do not measure effect size, it is advisable to look at a confidence interval (CI) to see how "close" to the H0 the data are in terms of the parameter of which the CI is considered (many tests correspond to CIs, so this can be very closely connected to the test statistic). Thirdly, rejection of the H0 can be interpreted in terms of the direction encoded in the test statistic, i.e., a significant positive z-value in logistic regression (one-sided test) indicates (with the usual error probability; the stronger the smaller the p) that it is in fact more likely to observe a positive relation between explanatory variable and outcome than encoded in the H0 ("no relation"). Note that this statement avoids the implicit assumption that the model is true, which in reality won't be the case (see above). The value of testing an H0 if we don't believe that models are true anyway is that we need models to formally encode our thinking so that we can compare it systematically with the data. Even though the H0 is not literally true, one could think about the situation as "variable x not having any impact on the outcome" (given other variables in the model if this applies), which is encoded by the H0, and not rejecting the H0 certainly means that data are compatible with this idea (for which one possible formalisation is the exact H0 we are testing).
