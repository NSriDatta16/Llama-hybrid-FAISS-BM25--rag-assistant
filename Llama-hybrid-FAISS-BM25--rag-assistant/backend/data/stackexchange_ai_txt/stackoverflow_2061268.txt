[site]: stackoverflow
[post_id]: 2061268
[parent_id]: 2059251
[tags]: 
This isn't answering the actual question you asked, but it might be useful, and I like bit-twiddling hacks... It's possible to calculate the average (rounded down) of two unsigned integers, without overflowing or using an intermediate wider type, using some trickery: avg = (a & b) + ((a ^ b) >> 1) Why it works: for each column of the binary addition, a & b gives a "1" bit if the bits in that column sum to 2, and (a ^ b) >> 1 gives a "1" bit for the column to the right (which you can think of as 1/2 for the column you're adding) where the bits in that column sum to 1.
