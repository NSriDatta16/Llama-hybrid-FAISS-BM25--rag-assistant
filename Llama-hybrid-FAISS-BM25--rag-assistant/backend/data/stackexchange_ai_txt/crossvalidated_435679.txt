[site]: crossvalidated
[post_id]: 435679
[parent_id]: 435597
[tags]: 
Neural networks for semantic segmentation use a 1x1 convolution followed by a softmax in the end for classification, not for dimensionality reduction. It works just like a fully connected layer in a classification convnet, just replicated for each pixel. That is exactly what segmentation is: classification of every pixel. My question is related to why a linear transformation is used here whereas every other convolution operation in the network is followed by an activation function making them non-linear. My guess is you overlooked a softmax function following the last layer, it makes no sense to use linear outputs for segmentation. Why did the network result improve? The fact that stacking linear functions does not change the overall expressiveness does not mean that the learning behavior is the same. Multi-layered linear networks have different learning dynamics than directly optimizing a single linear transformation. It is only expected to observe different outcomes.
