[site]: crossvalidated
[post_id]: 369760
[parent_id]: 358944
[tags]: 
I went through this papers and others, and used Robust PCA for my own needs. Additionaly to Candes et al., you can take a look to the implementation suggested by Lin et al. (2013): https://arxiv.org/pdf/1009.5055.pdf . Besides detecting outliers, one of the problem formulation also allows you to complete missing entries. You can find a nice Python implementation of the Robust PCA problem formulation here . Question 1 : From what I understand, your 1d time series is a one-day pattern repeated over one complete week, plus noise. Therefore, as you would do using classic PCA, your samples are each day of your time series, and your features are each hours of the days, so you should reshape your data as a 7 x 24 matrix (n_samples x n_features). Indeed, like PCA, your samples (rows) are supposedly strongly correlated with each other, and so you can find a faithful low rank representation of your time series. Robust PCA comes in handy as it is not as strongly affected by outliers as PCA, where strong outliers might influence the main direction of variance. Before applying Robust PCA to your data, you should also look at preprocessing steps, such as making your time series stationary, center each day, and so on. Question 2 : The implementation from Lin et al. (2013) apply an adaptative threshold to filter $S$ entries, and keeping only the entries above the threshold. More details in the paper. This means that the work of detecting outliers is a priori done in the $S$ computation steps. Theoretically, filtering non zero values in $S$ matrix should give you the outliers in your data. However, with noisy or non smooth data, the sparse matrix $S$ may contain too many outliers. If you feel you detect too many outliers, one idea would be to apply a quantile based anomaly detection on the flattened sparse matrix. Let $\sigma = q_{75} - q_{25}$ your inter quartile range, then you could detect all values which distance to zero is more than $3 \times \sigma$ .
