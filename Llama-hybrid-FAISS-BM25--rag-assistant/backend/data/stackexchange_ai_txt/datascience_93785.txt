[site]: datascience
[post_id]: 93785
[parent_id]: 
[tags]: 
How do I get Kera's to use more than 1 core?

I've read that keras supports multiple cores automatically with 2.2.4+ but my job only runs as a single thread. I'm running inside a VM else I'd try to use the GPU I have which means the solution I'm working with is CPU based. Here's my snippet of code import numpy as np import tensorflow as tf from tensorflow import keras epochs_ = 1000 batch_size_ = 150 np.random.seed(42) tf.random.set_seed(42) from keras.layers import Dense, SimpleRNN, GRU, LSTM from keras.optimizers import SGD #simple RNN data_ = Lagged_Set model6 = keras.models.Sequential([ keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, len(data_.columns)]), keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, len(data_.columns)]), keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, len(data_.columns)]), keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, len(data_.columns)]), keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, len(data_.columns)]), keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[None, len(data_.columns)]), keras.layers.SimpleRNN(32, return_sequences=True), keras.layers.TimeDistributed(keras.layers.Dense(n_ahead)) ]) model6.compile(loss="MAPE", optimizer="rmsprop",metrics=['MAPE']) history = model6.fit(X_train, Y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, Y_valid)) I tried this which did nothing session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8) #tf.compat.v1.ConfigProto.set_random_seed(1) sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf) tf.compat.v1.keras.backend.set_session(sess)
