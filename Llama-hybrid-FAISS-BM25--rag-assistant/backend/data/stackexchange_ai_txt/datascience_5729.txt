[site]: datascience
[post_id]: 5729
[parent_id]: 5708
[tags]: 
In general, a decent starting point for problems like these is Naive Bayes (NB) classification using a simple bag of words model. Here are some slides describing NB as applied to natural language processing . There's nothing especially fancy about this approach, but it's pretty easy to implement and will give you a starting point to expand from. Once you've found some initial results assuming independence among your features and your output labels, you'll probably have a better sense of where the model is weak. From that point forward you can apply some feature engineering (maybe TF-IDF ) as well as some post processing to deal with samples that get assigned to related categories.
