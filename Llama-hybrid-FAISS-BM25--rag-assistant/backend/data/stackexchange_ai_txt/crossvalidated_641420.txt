[site]: crossvalidated
[post_id]: 641420
[parent_id]: 
[tags]: 
Calculating the True Error of a Distribution

I am currently studying "Understanding Machine Learning from Theory to Practice" written by Shai Shalev-Shwartz and Shai Ben-David. I am a bit confused about an example regarding the calculation of the True Error of a Distribution that the author presented in one of his lectures on YouTube. Let $X=\{a,b\}$ our Domain and $Y=\{1,0\}$ our Labels and $D$ our probability distribution over $X\times Y$ : \begin{equation} D(a) = D(b) = \frac{1}{2} \end{equation} \begin{equation} D(1 | a) = D(0 | b) = \frac{1}{2} + \epsilon \end{equation} \begin{equation} D(0 | a) = D(1 | b) = \frac{1}{2} - \epsilon \end{equation} Let H be our Hypotheis Class consisting of two function: \begin{equation} H=\{h_1,h_2\} \end{equation} \begin{equation} h_1(a)=1,h_1(b)=0 \end{equation} \begin{equation} h_2(a)=0,h_2(b)=1 \end{equation} Then the true error of $h_1,h_2$ is \begin{equation} L_D(h_1)=D(\{(x,y):h_1(x)\neq y\})=D((a,0))+D((b,1))=1/2-\epsilon \end{equation} \begin{equation} L_D(h_2)=D(\{(x,y):h_2(x)\neq y\})=D((a,1))+D((b,0))=1/2+\epsilon \end{equation} Is this correct?
