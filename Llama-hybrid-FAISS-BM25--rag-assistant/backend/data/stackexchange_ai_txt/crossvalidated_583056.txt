[site]: crossvalidated
[post_id]: 583056
[parent_id]: 292130
[tags]: 
This is a tricky exercise. Let's break it down in two parts. Specify a Poisson GLMM for the 1990 General Society Survey data. 1308 subjects responded to the question: Within the past 12 months, how many people have you known personally that were victims of homicide? The responses are broken down by race ("white" and "black"). Fit the Poisson GLMM. This is survey data; it seems natural to let the effects vary across participants. So let's make the GLMM a random-intercepts model. In mathematical notation we will compare: A Poisson GLM with fixed race effects. The intercept for "white" subjects is $\beta_0$ and the intercept for "black" subjects is $\beta_0 + \beta_1$ . $$ \begin{aligned} \operatorname{count}_{i} &\sim \operatorname{Poisson}(\lambda_i) \\ \log(\lambda_i) &= \beta_{0} + \beta_{1}(\operatorname{black}) \end{aligned} $$ A Poisson GLMM with random race effects. The intercepts for "white" subjects are $\operatorname{Normal}(\gamma_0, \sigma^2)$ and the intercepts for "black" subjects are $\operatorname{Normal}(\gamma_0 + \gamma_1, \sigma^2)$ . $$ \begin{aligned} \operatorname{count}_{i} &\sim \operatorname{Poisson}(\lambda_i) \\ \log(\lambda_i) &=\alpha_{j[i]} \\ \alpha_{j} &\sim N \left(\gamma_{0}+ \gamma_{1}(\operatorname{black}), \sigma^2\right) \end{aligned} $$ We have only observation from each participant, so we don't expect to get reliable estimates of the random intercepts. This is not a very sophisticated mixed-effects model. In fact, a Negative Binomial GLM fits the data better . Let's fit the two models: the GLM with stats::glm and the GLMM with lme4::glmer . fit.glm And now the tricky part. Let's calculate the deviance two ways: a) two times the negative log likelihood and b) the sum of the deviance residuals squared. # Compute deviance as -2 times the log likelihood. -2 * logLik(fit.glm) #> 1117.99 (df=2) -2 * logLik(fit.glmer) #> 728.0926 (df=3) # Compute deviance as the sum of the deviance residuals squared. sum(resid(fit.glm)^2) #> 844.7073 sum(resid(fit.glmer)^2) #> 214.0758 Notice that 844.7073 - 728.0926 = 116.6147 . This gives the "right answer" though the computation is not meaningful. The answer @RemkoDuursma points it out as well. To choose between the models we can use the deviance = -2 × log-likelihood or the AIC = -2 × log-likelihood + 2 × #parameters . See also Residual deviance, residuals, and log-likelihood in [weighted] logistic regression PS. I came across this error when I used a different R package to fit the Poisson GLMM, glmmML . fit.glmmML 844.7073 deviance(fit.glmer) #> 214.0758 deviance(fit.glmmML) #> 728.107 lme4::lmer and glmmML::glmmML report very different "deviance" for the same Poisson GLMM even though both use maximum likelihood and their parameter estimates are almost the same. It took me a while to realize they have a different definition of deviance.
