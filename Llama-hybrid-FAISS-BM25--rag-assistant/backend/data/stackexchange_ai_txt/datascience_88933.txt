[site]: datascience
[post_id]: 88933
[parent_id]: 88920
[tags]: 
It seems that you are collecting the lemmas in your docs. For that, you need a lemmatizer . If available for your language, you should use an external lemmatizer. Some packages supporting lemmatization for different languages are StanfordNLP (or its equivalent for Python, Stanza ), Spacy or NLTK . Depending on the language, the approach to get a good lemmatization varies, but many times it involves expressing the language morphological knowledge as rules. If no lemmatizer or stemmer is available in the language you are working with, another approach would be to use unsupervised approaches to segment words into morphemes, and use your linguistic knowledge of Georgian to devise some heuristic rules to identify the stem among them. This kind of approach consists of a model trained to identify morphemes without any labels (i.e. unsupervisedly). The most relevant Python package for this is Morfessor . Also, there is a Python package called Polyglot that offers pre-trained Morfessor models in different languages , so you should check if yours is included.
