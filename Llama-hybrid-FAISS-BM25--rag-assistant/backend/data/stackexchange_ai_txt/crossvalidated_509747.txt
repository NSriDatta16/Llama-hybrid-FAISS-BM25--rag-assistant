[site]: crossvalidated
[post_id]: 509747
[parent_id]: 
[tags]: 
Accuracy over different sample sizes from dataset

What I'm trying to do is predict how much more data would help in a classification task. So, what I'm doing is bootstrapping entries in my dataset to get a sample, with a specified size. Then, I fine-tune a KNN model on the sample, and compute it's accuracy. I do this multiple times for one specified size, storing the accuracies in a list, from which I can compute the mean accuracy as well as the standard deviation of accuracies. And then rinse-and-repeat, for a different specified number of samples. After doing this for enough different sample sizes, I practically get a new dataset, which I can fit a line to and predict how much more data would help. However, this new "Accuracy vs. Sample Size" dataset surprises me. What I expected was that at small sample sizes, more data would help out a lot, but with bigger sample sizes, more data would help out less, I would also never expect more data to harm the accuracy. But, for some reason, it follows some quadratic line, the accuracy of 20 instances is (around) the same as 160 instances, the accuracy increase gets bigger as the sample size increases, and the worst accuracy is 100 instances... It's also much bumpier than I expected (I know there will always be some randomness as I'm randomly sampling from the dataset, but I resampled up to 3500 times for each sample size, and when I looked at the distribution for the 3500 resamples, they basically formed a perfect normal distribution, which means it's converged to the real value, right?). Can anybody explain this behaviour? Here's a minimal working example (in python): # Imports import numpy as np import pandas as pd import matplotlib.pyplot as plt %matplotlib inline from sklearn.neighbors import KNeighborsClassifier from sklearn.model_selection import GridSearchCV import warnings warnings.filterwarnings("ignore") def auto_knn(X, y): """ Returns accuracy of KNN with fine-tuned 'n_neighbours', fitted on 'X' and 'y'. """ knn = KNeighborsClassifier() min_range, max_range = 6, 9 found_best = False while not found_best: knn_search = GridSearchCV(knn, [{ "n_neighbors": list(range(min_range, max_range)) }], cv=5, scoring="accuracy", return_train_score=True) knn_search.fit(X, y) if knn_search.best_params_["n_neighbors"] == min_range and min_range != 1: min_range, max_range = min_range-1, max_range-1 elif knn_search.best_params_["n_neighbors"] == max_range-1: min_range, max_range = min_range+1, max_range+1 else: found_best = True return knn_search.best_score_ def knn_scores_from_subsample(X, y, subsample_size, num_iters): """ Samples 'X' and 'y' with replacement to get new dataset of specific size, then fine-tunes KNN and retrieves accuracy. Resamples and retrieves accuracy 'num_iters' times. Returns list of accuracies. """ accuracys = [] for i in range(num_iters): print("\r["+"".join(["=" for _ in range(round(i/num_iters*100))])+"".join([" " for _ in range(round(100-i/num_iters*100))])+"] - "+str(round((i/num_iters)*100, 1))+"%", end="") selected_indexes = np.random.randint(0, len(X)-1, (subsample_size,)) accuracys.append(auto_knn(X.iloc[selected_indexes], y.iloc[selected_indexes])) return accuracys import requests from io import StringIO # Here, I'm using the Heart Failure Dataset (https://www.kaggle.com/andrewmvd/heart-failure-clinical-data), # I've already done feature engineering, selection and preparation, so I've uploaded the prepared dataset, # to easily retrieve here. orig_url = 'https://drive.google.com/file/d/1qvIkRx07Il-Mat86MSo_i8iu2YEn9rnO/view?usp=sharing' file_id = orig_url.split('/')[-2] dwn_url='https://drive.google.com/uc?export=download&id=' + file_id url = requests.get(dwn_url).text csv_raw = StringIO(url) data = pd.read_csv(csv_raw) data = data.drop("Unnamed: 0", axis=1) X = data.drop("DEATH_EVENT", axis=1) y = data[["DEATH_EVENT"]] # Generate 'accuracy' vs. 'specific sample size' # NOTE: This can take a very long time, to generate the image (above), it took many hours. scores_for_n = {} for num_points in range(20, 300, 10): scores_for_n[num_points] = knn_scores_from_subsample(X, y, num_points, 3500) # This will resample (with replacement) the dataset 3500 different times (and compute the accuracy). print("\nFinished "+str(num_points)+" points. Got a mean accuracy of "+str(round(np.array(scores_for_n[num_points]).mean()*100, 3))+"% With a standard deviation of: "+str(round( np.array(scores_for_n[num_points]).std()*100 ,3))+"%") # Plot 'accuracy' vs. 'specific sample size' plt.scatter(data_points, accuracies) plt.xlabel("Dataset Size") plt.ylabel("Mean Accuracy")
