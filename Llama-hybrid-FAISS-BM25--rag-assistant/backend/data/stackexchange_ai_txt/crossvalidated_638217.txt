[site]: crossvalidated
[post_id]: 638217
[parent_id]: 206144
[tags]: 
My understanding is that " vector embeddings" are more appropriately understood as " metric embeddings". The principle underlying metric embedding is: The more a,b are similar in meaning, the smaller the distance d(a,b). The reason why it occurs can be explained by the following figure: It is easier for a neural network (which is a continuous function) to map nearby points to the same target, than if there is an exception within the neighborhood (green dot). The latter would require more computing resources, ie, weights. Therefore the above principle holds. For the example below (left figure), the emergence of seeming "directionality" may be explained by the respective distances of the points being equal (right figure), thus forcing the shape to be a parallelogram. In other words, directionality of vectors may be just a side-effect of the distance metric:
