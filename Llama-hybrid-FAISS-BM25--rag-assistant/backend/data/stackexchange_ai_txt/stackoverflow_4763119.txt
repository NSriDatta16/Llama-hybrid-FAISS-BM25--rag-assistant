[site]: stackoverflow
[post_id]: 4763119
[parent_id]: 
[tags]: 
TSQL Merge Performance

Scenario : I have a table with roughly 24 million records. The table has pricing history related to individual customers and is computed daily. There are on average 6 million records for each day. Every morning a the price list is generated and a merge statement is ran to reflect the changes in their pricing. The merge statement begins with the previous day's previous data being inserted into a variable table, that table is then merged into the actual table. The main problem is that the merge statement takes pretty long. My real question centers around the performance of using a variable table vs physical table vs temp table. What is the best practice for large merges like this?
