[site]: crossvalidated
[post_id]: 144258
[parent_id]: 144085
[tags]: 
As amoeba wrote in the comments, this is a multiple regression problem and has nothing to do with PCA (see Linear regression on Wikipedia ). I here use the standard assumptions of a linear model with additive noise: $$ A = b ~ B + c ~ C + d ~ D + k + E. $$ Here $b$, $c$, and $d$ are the scalar regression coefficients for your three explanatory variables, $k$ is a constant offset, and $E$ captures everything that can't be fit into the other terms (the error). In Matlab, to compute $A$ if given all the values on the left-hand side, one would write in matrix notation: A = [B C D ones(n, 1)] * [b c d k]' + E assuming that all variables are represented as column vectors, and that $n$ is the number of data points. To solve this equation for the coefficients $b$, $c$, $d$, and $k$ for given $A$, you can use the backslash operator : coeff = [B C D ones(n, 1)] \ A This operator gives a least-squares solution , meaning $A$ is determined such that the sum of squared errors ($\sum_{i = 1}^n E_i^2$ or sum(E .^ 2) in Matlab) is as small as possible. You can then extract the single coefficients: b = coeff(1) c = coeff(2) d = coeff(3) These coefficients are estimates of how strongly the variables $B$, $C$, and $D$ contribute to $A$. Your title says that you are interested in a "percentage of contribution" of the independent variables, and I assume that you mean percentages of explained variance. The problem is that if the variables $B$, $C$, and $D$ are correlated (share variance among themselves), there is no simple answer to that question, because the variance of their contributions to $A$, which are $b ~ B$, $c ~ C$, and $d ~ D$, do not combine additively. Assuming that there are no correlations, you can compute those contributions like this: var([B C D] * diag([b c d])) / var(A) * 100 which gives you a three-element vector with estimates of the relative contribution in percent of the three independent variables.
