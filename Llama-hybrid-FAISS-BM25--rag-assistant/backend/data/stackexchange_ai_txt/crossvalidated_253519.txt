[site]: crossvalidated
[post_id]: 253519
[parent_id]: 
[tags]: 
Modelling an unusual distribution observed with return on investment outcome

This is a minor side-project I have been playing with and I wanted to see if anyone might have suggestions. Problem. I used a dataset of loans with payment and borrower credit history ( https://www.lendingclub.com/info/download-data.action ), where each loan is a 36,60 month term. I am not so concerned with defaults vs. paid off (i.e. probability), I want to build a predictive model using loan/borrower characteristics to select loans and achieve the best possible return on investment. I calculated the return on investment for each 36-month loan at term end (total payment recv'd / total loan amount at 36 months). https://i.stack.imgur.com/A4QsD.png The distribution makes sense, i.e. a portion of loans default before the term is up leading to ROI ranging from near zero to ~1. Then other loans (most of them) are paid back with interest and have ROI >1. I was wondering if there might be some suggestions about how to model such a thing? it seems to me like a mixture of two distributions and I was thinking Bayesian mixture modelling could account for this but there wouldn't be a clear parametric model to deal with this.
