[site]: crossvalidated
[post_id]: 501608
[parent_id]: 501602
[tags]: 
For your first question, the expression $$\frac{1}{m} \sum_{i=1}^m \log p_\text{model}(x_i;\theta)\tag{1}$$ is an average of iid random variables with expectation $$\mathbb E^X[\log p_\text{model}(X;\theta)]=\sum_{x} \log p_\text{model}\,(X;\theta) p_\text{data}(x)\tag{2}$$ whatever the distribution $p_\text{data}(\cdot)$ of $X$ . Hence correct asymptotically in $m$ . For the second question, maximising (1) is asymptotically like maximising (2), i.e., like minimising $$-\mathbb E^X[\log p_\text{model}(X;\theta)]\tag{3}$$ yet again like minimising $$\mathbb E^X[\log p_\text{data}(X)]-\mathbb E^X[\log p_\text{model}(X;\theta)]\tag{4}$$
