[site]: crossvalidated
[post_id]: 352468
[parent_id]: 
[tags]: 
Time Series forecasting with Gaussian Processes

I am trying to forecast various time-series with Gaussian Processes, using the functional approach like in the Mauna Loa example in section 5.4.3 of "Gaussian Processes for Machine Learning". (X = time, y = observed value at time-point). Except for that particular example, I almost always end up with the forecast being the mean of the training data. Despite using a Periodic Kernel and setting the periodicity to 7 for a clear weekly pattern, the forecast stays flat and the fitted values for the training set are also close to the mean with almost no variation. With some manual grid search, I get the training data fit to match the training data better but the forecast stays flat again most of the time. I have experimented with lots of different kernels (RBF, Periodic, etc.) and combinations, tried different starting points for the hyperparameters (especially variances and length-scales), used different time-scales and different scaling techniques for the observations (subtracting mean, dividing by std, both, no scaling at all). However, the forecasts are almost always flat. Now I know that the kernel and hyperparameter choices should be reasonable but I don't think that it should be that hard to get meaningful output and that I am rather doing something wrong here. The packages I tried are gpflow and sklearn on Python 3.6 and the parameters are being optimized via the marginal likelihood (no sparse GP or variational approximation) My question is: Has anyone an idea what I could be doing wrong here or how to make it easier to get reasonable forecasts?
