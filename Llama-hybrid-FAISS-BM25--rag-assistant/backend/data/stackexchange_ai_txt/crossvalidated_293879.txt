[site]: crossvalidated
[post_id]: 293879
[parent_id]: 
[tags]: 
Machine learning ensamble over ensamble results. Is this valid?

I have a dataset for which I run multiple algorithms over different subsets of its columns, but at the end, I want to classify each row (In my example, the data is the number, and the classification is "odd"/"even". I have the results from those many algorithms; as expected, some perform better than others in some cases, and vice versa. So.. I want to ensamble their results... for that, I can simply run a majority voting over the results; if 2 of 3 say it´s even and one says it´s odd, I´ll classify as even. BUT... I can also run a algorithms over those classifications (a KNN and a Naive Bayes in my example columns). (Is that ok?) And then, I can vote over the classification made over the "classification dataset" - columns G,H,I, and decide again. I have many doubts about this: Is this a good approach? Why? Why not? How should I divide my data and how should I validate the results? Model:
