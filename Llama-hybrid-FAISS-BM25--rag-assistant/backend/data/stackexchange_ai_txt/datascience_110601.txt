[site]: datascience
[post_id]: 110601
[parent_id]: 
[tags]: 
Deep Learning accuracy vs Confusion Matrix accuracy

I am working on deep learning with fer2013 dataset. After training the model I got val_precision: 0.9168 (precision: 0.8492) Epoch 67/100 238/238 [==============================] - 31s 130ms/step - loss: 1.5087 - tp: 2622.4142 - fp: 474.9121 - tn: 45584.3013 - fn: 5054.1213 - accuracy: 0.8972 - precision: 0.8492 - recall: 0.3410 - auc: 0.9042 - prc: 0.6758 - val_loss: 0.9754 - val_tp: 1389.0000 - val_fp: 126.0000 - val_tn: 22698.0000 - val_fn: 2415.0000 - val_accuracy: 0.9046 - **val_precision: 0.9168** - val_recall: 0.3651 - val_auc: 0.9235 - val_prc: 0.7276 Restoring model weights from the end of the best epoch. Epoch 00067: early stopping But when I output the "Confusion Matrix" I get precision of 0.13 - 0.18 ... I have some misunderstanding - why is my precision so different ? Is this confusion matrix part has errors ? Here is my notebook -> https://www.kaggle.com/code/prilia/emotion-recognition-with-resnet50-7emotions/notebook Please help
