[site]: crossvalidated
[post_id]: 571279
[parent_id]: 
[tags]: 
Bayesian estimation under transformation on the paramater

Consider the classical model Normal-Normal-Inserse-Gamma model: $$ x=(x_1,...,x_n)|\mu,\sigma^2\sim N(\mu,\sigma^2)\,\,(iid),\,\,\mu\sim N(m_0,\tau),\sigma^2\sim IG(a,b), $$ where $m_0,\tau,a,b$ are known. Suppose My interest is $\phi=\mu/\sigma$ . So the usual path would be: obtaining the posterior distribution of $(\mu,\sigma^2)$ , then take the variable transformation $\phi=\mu/\sigma$ and marginalize the posterior distribution in order to obtain $p(\phi|x)$ . As an alternative, I was wondering, can we adjust the likelihood in order to obtain an expression involving $\phi$ and assign a prior distribution directly to $\phi$ ? I mean: \begin{align} L(\mu,\sigma^2) & \propto (\sigma^2)^{-n/2}\exp(\frac{1}{2}\sum\left(\frac{x_i-\mu}{\sigma}\right)^2 \\ & \propto (\sigma^2)^{-n/2}\exp(\frac{1}{2}\sum\left(\frac{x_i}{\sigma}-\phi\right)^2 \\ & \propto (\sigma^2)^{-n/2}\exp(\frac{1}{2\sigma^2}\left[\sum\left(x_i-\bar{x}\right)^2+n\left(\phi\sigma^2-\bar{x}\right)^2\right], \end{align} so, as this point could I just assign some prior distribution to $\phi\sim p(\phi)$ and regard the $\sigma$ as constant? I know this is not the same model are the first one, but from the probabilistic point of view, is this ok?
