[site]: crossvalidated
[post_id]: 618257
[parent_id]: 618178
[tags]: 
As you said, the sole purpose of requiring $\theta_0 = 1$ is for "identifiability purpose". To see why it is so, first you should understand that a complete specification of an $MA(q)$ model (or more generally, an $ARMA(p, q)$ model) includes not only the equation \begin{align} X_t = \mu + \theta_0\varepsilon_{t} + \theta_1\varepsilon_{t - 1} + \cdots + \theta_q\varepsilon_{t - q}, \end{align} but also the distributional form of the process $\{\varepsilon_t\}$ , which is typically written as $\{\varepsilon_t\} \sim \text{WN}(0, \sigma^2)$ . The parameter space of the $MA(q)$ model is thus $\Theta = \{(\mu, \theta_0, \ldots, \theta_q, \sigma): \sigma > 0, \mu, \theta_0, \ldots, \theta_q \in \mathbb{R}\}$ . If we do not impose any constraint on $\theta_0$ , then the model is non-identifiable, meaning that different vectors of $(\mu, \theta_0, \ldots, \theta_q, \sigma)$ would give the same distribution of $\{X_t\}$ . For simplicity, assuming $q = 1$ . It is easy to see that $(0, 4, 4, 1)$ and $(0, 2, 2, 2)$ give the same distribution of $\{X_t\}$ . In particular, \begin{align} & X_t = 4\varepsilon_t + 4\varepsilon_{t - 1}, \; \{\varepsilon_t\} \sim \text{WN}(0, 1), \\ & X_t' = 2\varepsilon_t + 2\varepsilon_{t - 1}, \; \{\varepsilon_t\} \sim \text{WN}(0, 4) \end{align} would have exactly the same autocovariance function. This non-identifiability can be eliminated by requiring $\theta_0 = 1$ . Continuing the above example, if $X_t = \mu + \varepsilon_t + \theta_1\varepsilon_{t - 1}, \{\varepsilon_t\} \sim \text{WN}(0, \sigma^2)$ and $X_t' = \eta + \varepsilon_t + \phi_1\varepsilon_{t - 1}, \{\varepsilon_t\} \sim \text{WN}(0, \tau^2)$ have the same distribution, then it must hold $\mu = \eta, \theta_1 = \phi_1$ and $\sigma = \tau$ . I will leave that as an exercise to you. The same idea is frequently used in statistics to maintain model identifiability. Perhaps the most well-known example in this regard is the one-way ANOVA model $y_{ij} = \mu + \alpha_j + \epsilon_{ij}$ . Without imposing any constraint on $\{\alpha_j\}$ , the model is non-identifiable. To ensure the identifiability, people usually use the constraint $\alpha_1 = 0$ (just like in the $MA(q)$ model case) or the constraint $\alpha_1 + \cdots + \alpha_K = 0$ . For more details, I refer you to read Section 6.2 of Modern Applied Statistics with S by W. Venables, and B. Ripley. There are more similar notable examples in time series as well, for example, the first component of a cointegration vector is usually set as $1$ .
