[site]: crossvalidated
[post_id]: 257460
[parent_id]: 257439
[tags]: 
I am going to broaden the question by pointing out some things that worry me, some enormously, about your project. Trivially, smoothness_worst is listed twice as a predictor. Assuming that to be fixed, you are still throwing in 32 predictors into your model! That isn't anything except a recipe for poor statistical science. The predictors are a ragbag of size and shape measures of various kinds. Some have dimensions, but there is no dimensional thinking evident in your choice of predictors. For example, if some response, time in your case, is linear in area, it is most unlikely to be linear in perimeter too. Without knowing anything specific about your application, except a hint from some names that it might be in oncology, I am prepared to bet that you really need to thin down your predictors because they mean anything, many will be highly correlated with each other. Think in terms of groups of linear size measures, area size measures, shape measures, etc. and look carefully at their correlation. Most crucially of all, perhaps, I would guess that time is in practice always positive, in which case it's unlikely that linear regression really is the default model of choice. See e.g. this lucid post for an introduction to the argument that generalised linear models with logarithmic link are the starting point in modelling any response of this kind. Box-Cox, its wonderful name apart, is in my view oversold. Worrying about marginal distributions should take second place in regression to choosing a functional form that makes sense for the science and statistics of your problem. That doesn't rule out transforming some of the predictors, say on dimensional grounds. Linear regression isn't a washing machine that takes in dirty, messy data and removes the dirt and mess. You have to think your way towards a model that does justice to your data and the underlying science too.
