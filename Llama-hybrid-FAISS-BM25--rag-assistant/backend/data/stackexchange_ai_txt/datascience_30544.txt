[site]: datascience
[post_id]: 30544
[parent_id]: 30092
[tags]: 
Without knowing the geometry of your data, determining a kernel is generally achieved through trial and error. The radial basis function (RBF) kernel is a good starting choice because most data are not linearly separable. Fortunately training an SVM is fast, so brute-forcing the kernel search is not a terrible method. For selecting the C and gamma values, we generally use a grid search: Every cell in the graph represents a SVM model trained on your data given the respective C and gamma parameters. The color represents its accuracy depicted by the scale on the right. Note that our scales are logarithmic, so we are able to search a broad solution space while only training 169 models. From this example, we can predict that the optimal (C,gamma) value combination would be in the region around $( 10, 0.1 )$ or $( 10^{10}, 1e^{-7}) $ We can further refine our C and gamma parameters by "zooming" into the regions with greatest validation accuracy. In other words, we can repeat the grid search with finer granularity and with boundaries determined by the regions of interest until we find the optimal C/gamma combination.
