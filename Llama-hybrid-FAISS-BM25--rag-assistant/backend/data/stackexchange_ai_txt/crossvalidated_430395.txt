[site]: crossvalidated
[post_id]: 430395
[parent_id]: 
[tags]: 
Handling serial correlation in time series regression

Suppose that the time series data $(y_1, y_2,..., y_n)$ can be explained through a regression model with $k$ explanatory variables: (1) $y_t = b_0+b_1x_{1t}+b_2x_{2t}...+b_kx_{kt} + \epsilon_t,\ t=1,2,...,n$ where $(\epsilon_1, \epsilon_2, .., \epsilon_n) \sim N(0,\ \Sigma)$ . When serial correlation exists in the residual time series $\epsilon$ , we can solve the model (1) through generalized least squares. For simplification, let us assume the correlation structure of the residuals $\epsilon$ is AR(1). Occasionally I see in literature that, for the same data, some people model the serial correlation of AR(1) with a different model (2) $y_t = \phi y_{t-1}+b_1x_{1t}+b_2x_{2t}...+b_kx_{kt} + \epsilon_t,\ t=1,2,...,n$ with the assumption of white noise for the residuals: $(\epsilon_1, \epsilon_2, .., \epsilon_n) \sim N(0,\ \sigma^2I)$ . I suppose that the underlying assumption would be different for the model (2). Here are my questions: 1) What exactly is the difference in terms of assumptions between the two models? 2) How to justify the adoption of one model over the other? 3) What is the impact of different choices on statistical inferences about those explanatory variables $x_i$ ? 4) Any literature that discuss the choice between the two models?
