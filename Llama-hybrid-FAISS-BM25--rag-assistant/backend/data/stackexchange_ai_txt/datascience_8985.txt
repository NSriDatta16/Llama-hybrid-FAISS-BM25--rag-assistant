[site]: datascience
[post_id]: 8985
[parent_id]: 
[tags]: 
Overview A Markov process is any stochastic process $Y_{t}$ such that the future is conditionally independent of the past, given the present; the distribution of the process only depends on where the process is, not where it has been: $$ P(Y_{t+1}=y_{t+1} |Y_t = y_{t}, Y_{t-1} = y_{t-1}, ..., Y_{1} = y_{1}) = P(Y_{t+1}=y_{t+1} |Y_t = y_{t}) $$ This property is known as the Markov property. References The following threads on math.se provide references to resources on Markov processes: Good introductory book for Markov processes Nice references on Markov chains/processes?
