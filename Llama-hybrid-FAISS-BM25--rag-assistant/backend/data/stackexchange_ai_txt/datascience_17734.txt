[site]: datascience
[post_id]: 17734
[parent_id]: 17727
[tags]: 
If your data consists of observations in rows and each column is a variable for that observation, then you can call these columns dimensions. These can also be called features of the observation. Dropping columns/features from your dataset is essentially dimensionality reduction. You go from a higher dimensional space to a lower dimensional one (less columns). The fact that you're not combining features, rotating spaces doesn't mean it's not a valid form of dimensionality reduction. Why are you against using PCA for Neural Networks in particular? PCA doesn't care about what kind of classification you're running after it. In fact there is a convenience function in R's caret package implement PCA before Neural nets to ease computation of the NN.
