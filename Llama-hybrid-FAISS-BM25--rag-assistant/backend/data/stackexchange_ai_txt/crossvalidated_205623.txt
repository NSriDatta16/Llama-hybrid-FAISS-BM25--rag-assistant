[site]: crossvalidated
[post_id]: 205623
[parent_id]: 
[tags]: 
Large sample with many little groups of dependent observations

I work with traffic crash data and my sample consists of about 165,000 injured people distributed over roughly 107,000 crashes. The prevalent approach in traffic crash analysis is to look at every injured person as an independent observation from a common distribution, i.e. assume the observations are iid. My guess is, that this is mostly done to be able to apply logistic or log-linear regression in the next step. To me this seems simply wrong. There are roughly 38,000 crashes (involving roughly 96,000 injured people, thus more than half available to me) in my sample which involve more than one injured people. For the most part, 65%, there are two injured people involved in an accident but there are accidents with more than 10 people involved. My problem is that I want to find a model of a person's injury severity depending on a couple of variables which can vary by accident or by individual (i.e. the weather is per accident but if the person got transported by ambulance is by person). Now most of the modelling approaches I have read about so far assume that the samples are iid. But I cannot assure this here. If two injured people (or more) are in the same accident then their injury severity seems to most likely be correlated (maybe more severely in a car to car crash than in a car to bicycle crash). The only modelling technique I found so far that does not assume this kind of independence was the random effects model. I could take the accidents as groups and look at the individuals inside of these groups. But then I would have about 107,000 groups and a good part of these do only have one group member. Would it be an alternative to look at every accident as its own sample and then I basically look at a lot of independent samples which were collected over a large time frame (about 15 years). I am not sure if this does make sense at all though. I would have a lot of samples with only one observation. Thus fitting an individual model to each accident seems infeasible. Is there a kind of modelling technique that supports this viewpoint? Additionally I wanted to get away from regression models and use something more along the lines of algorithmic learning like random forests or support vector machines but these algorithms require iid observations again. Is there one or multiple good ways to approach these kinds of problems?
