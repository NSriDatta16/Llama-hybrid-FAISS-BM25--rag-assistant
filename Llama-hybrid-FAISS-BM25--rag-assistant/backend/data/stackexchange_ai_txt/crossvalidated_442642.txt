[site]: crossvalidated
[post_id]: 442642
[parent_id]: 
[tags]: 
How can I preprocess my data better? Help finding issues with the Dataset to improve accurracy

The 'DATA' and my Jupyter notebooks can be found here Now my issue is that for my data-set I get an mean accuracy from grid search of 0.64 (I get different for other models, like for svm 0.75) but for the same model if I use the breast cancer data-set provided in the Sci-kit Learn library I get an mean accuracy of 0.95. breast cancer data-set is similar to my data-set and both are binary classifications. Now I think that the problem must be with my data and therefore my models are under-fitting. I would like to know if that hypothesis is correct? and if it is what do I do with my data to improve my accuracy? or is there something wrong with the way I am doing this, if it is kindly point me to the right direction. you can find the above tried in an jupyter notebook called experiments here DATA I am building various ML models for classification task on this data-set using sklearn. For an example of the problem I am facing I am posting one the Models (decision trees) PRE PROCESSING df = data.copy() # create new data-frame from the original data for preprocessing df = df.drop(columns = ['F20']) # remove F20 from data,to avoid imputation x = df.drop(columns=['Class']) # select all attributes except class y = df.Class # select Class as output to the classifier smt = SMOTETomek(random_state = 42) # fixing random state for reproducibility of the model X_smt, y_smt = smt.fit_sample(x, y) from sklearn.preprocessing import MinMaxScaler scaler = MinMaxScaler(feature_range=(-3,3)) scaler.fit_transform(X_smt.values.reshape(-1, 1)) x = X_smt y = y_smt DECISION TREE def Build_tree(x,y): clf = DecisionTreeClassifier(random_state = 42) path = clf.cost_complexity_pruning_path(x, y) ccp_alphas = np.ndarray.tolist(path.ccp_alphas) max_depth = list(range(3,15,1)) parameter_grid = { 'ccp_alpha':ccp_alphas, 'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], 'max_depth': max_depth } cross_validation = StratifiedKFold(n_splits=10) grid_search = GridSearchCV ( clf, param_grid=parameter_grid, cv=cross_validation, n_jobs = -1) grid_search.fit(x,y) print('Average Accuracy of the model: {}'.format(grid_search.best_score_)) print('Best parameters: {}'.format(grid_search.best_params_)) clf = grid_search.best_estimator_ return clf
