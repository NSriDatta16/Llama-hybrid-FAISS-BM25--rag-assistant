[site]: crossvalidated
[post_id]: 7680
[parent_id]: 2213
[tags]: 
What George Dontas writes is correct, however the use of RNNs in practice today is restricted to a simpler class of problems: time series / sequential tasks. While feedforward networks are used to learn datasets like $(i, t)$ where $i$ and $t$ are vectors, e.g. $i \in \mathcal{R}^n$ , for recurrent networks $i$ will always be a sequence, e.g. $i \in (\mathcal{R}^n)^*$ . RNNs have been shown to be able to represent any measureable sequence to sequence mapping by Hammer. Thus, RNNs are being used nowadays for all kinds of sequential tasks: time series prediction, sequence labeling, sequence classification etc. A good overview can be found on Schmidhuber's page on RNNs .
