[site]: crossvalidated
[post_id]: 400087
[parent_id]: 
[tags]: 
how Deriving the formula for "The on-policy distribution in episodic tasks"?

in Sutton's book Reinforcement Learning: An Introduction Chapter 9, how to drive the formula for "The on-policy distribution in episodic tasks" as flow? that h(s) denotes the probability that an episode begins in each state s, and let η(s) denote the number of time steps spent, on average, in state s in a single episode. Time is spent in a state s if episodes start in s, or if transitions are made into s from a preceding state ¯s in which time is spent:
