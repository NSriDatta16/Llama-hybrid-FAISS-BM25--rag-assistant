[site]: crossvalidated
[post_id]: 153789
[parent_id]: 
[tags]: 
Is validation set always necessary?

Lets say I did the following steps: Used some separate development set to select some features. Decided a priori to use only one learning algorithm (SVM) with only default parameter values . Trained a single model on a training set. Tested this model on the test set. Is it OK that I didn't use a validation set, given that I had only one model a priori? Is this acceptable in a scientific work? Have in mind that the purpose of my work was only to show that the feature selection was good by showing that even some standard learning algorithm with its default parameter values can learn these features and get good accuracy. I don't claim that I've found the best learning method for my problem (my work is on IR and only uses ML, it's not about ML).
