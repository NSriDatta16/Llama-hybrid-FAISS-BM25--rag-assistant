[site]: crossvalidated
[post_id]: 483721
[parent_id]: 483716
[tags]: 
First, the term 'Naive Bayes' refers to the made assumption of conditional independence among feature variables, given the class outcome (that is, 'stroke' or 'no-stroke'). Taking the variables gender and ever_smoked, conditional independence is written as $Gender \; INDEP \; EverSmoked \; \mid \; Stroke$ . Conditional independence can hold also for numeric variables. Your two variables Gender and EverSmoked are categorical so a discrete classifier is appropriate for your purpose (you can try the off-the-shelf webservice Insight Classifiers , which copes also with numeric variables , all in one go). In general, (deep) neural networks, support vector machines and decision trees (C4.5) easily combine discrete and continuous feature variables.
