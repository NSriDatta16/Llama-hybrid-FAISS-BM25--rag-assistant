[site]: crossvalidated
[post_id]: 59886
[parent_id]: 59879
[tags]: 
In addition to @gung's answer, I'll try to provide an example of what the anova function actually tests. I hope this enables you to decide what tests are appropriate for the hypotheses you are interested in testing. Let's assume that you have an outcome $y$ and 3 predictor variables: $x_{1}$ , $x_{2}$ , and $x_{3}$ . Now, if your logistic regression model would be my.mod . When you run anova(my.mod, test="Chisq") , the function compares the following models in sequential order. This type is also called Type I ANOVA or Type I sum of squares (see this post for a comparison of the different types): glm(y~1, family="binomial") vs. glm(y~x1, family="binomial") glm(y~x1, family="binomial") vs. glm(y~x1+x2, family="binomial") glm(y~x1+x2, family="binomial") vs. glm(y~x1+x2+x3, family="binomial") So it sequentially compares the smaller model with the next more complex model by adding one variable in each step. Each of those comparisons is done via a likelihood ratio test (LR test; see example below). To my knowledge, these hypotheses are rarely of interest, but this has to be decided by you. Here is an example in R : mydata $rank rank) my.mod |z|) (Intercept) -3.989979 1.139951 -3.500 0.000465 *** gre 0.002264 0.001094 2.070 0.038465 * gpa 0.804038 0.331819 2.423 0.015388 * rank2 -0.675443 0.316490 -2.134 0.032829 * rank3 -1.340204 0.345306 -3.881 0.000104 *** rank4 -1.551464 0.417832 -3.713 0.000205 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 # The sequential analysis anova(my.mod, test="Chisq") Terms added sequentially (first to last) Df Deviance Resid. Df Resid. Dev Pr(>Chi) NULL 399 499.98 gre 1 13.9204 398 486.06 0.0001907 *** gpa 1 5.7122 397 480.34 0.0168478 * rank 3 21.8265 394 458.52 7.088e-05 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 # We can make the comparisons by hand (adding a variable in each step) # model only the intercept mod1 Chi) 1 399 499.98 2 398 486.06 1 13.92 0.0001907 *** anova(mod2, mod3, test="LRT") Model 1: admit ~ gre Model 2: admit ~ gre + gpa Resid. Df Resid. Dev Df Deviance Pr(>Chi) 1 398 486.06 2 397 480.34 1 5.7122 0.01685 * anova(mod3, mod4, test="LRT") Model 1: admit ~ gre + gpa Model 2: admit ~ gre + gpa + rank Resid. Df Resid. Dev Df Deviance Pr(>Chi) 1 397 480.34 2 394 458.52 3 21.826 7.088e-05 *** The $p$ -values in the output of summary(my.mod) are Wald tests which test the following hypotheses (note that they're interchangeable and the order of the tests does not matter ): For coefficient of x1 : glm(y~x2+x3, family="binomial") vs. glm(y~x1+x2+x3, family="binomial") For coefficient of x2 : glm(y~x1+x3, family="binomial") vs. glm(y~x1+x2+x3, family="binomial") For coefficient of x3 : glm(y~x1+x2, family="binomial") vs. glm(y~x1+x2+x3, family="binomial") So each coefficient against the full model containing all coefficients. Wald tests are an approximation of the likelihood ratio test. We could also do the likelihood ratio tests (LR test). Here is how: mod1.2 Chi) 1 397 480.34 2 394 458.52 3 21.826 7.088e-05 *** anova(mod2.2, my.mod, test="LRT") # LR test for gpa Model 1: admit ~ gre + rank Model 2: admit ~ gre + gpa + rank Resid. Df Resid. Dev Df Deviance Pr(>Chi) 1 395 464.53 2 394 458.52 1 6.0143 0.01419 * anova(mod3.2, my.mod, test="LRT") # LR test for gre Model 1: admit ~ gpa + rank Model 2: admit ~ gre + gpa + rank Resid. Df Resid. Dev Df Deviance Pr(>Chi) 1 395 462.88 2 394 458.52 1 4.3578 0.03684 * The $p$ -values from the likelihood ratio tests are very similar to those obtained by the Wald tests by summary(my.mod) above. Note: The third model comparison for rank of anova(my.mod, test="Chisq") is the same as the comparison for rank in the example below ( anova(mod1.2, my.mod, test="Chisq") ). Each time, the $p$ -value is the same, $7.088\cdot 10^{-5}$ . It is each time the comparison between the model without rank vs. the model containing it.
