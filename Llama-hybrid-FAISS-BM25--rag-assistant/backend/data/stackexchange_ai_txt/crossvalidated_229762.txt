[site]: crossvalidated
[post_id]: 229762
[parent_id]: 229734
[tags]: 
If the Gibbs sampler has not converged as yet, then $x_s$ is not a draw from the equilibrium distribution. Thus the expectation is not calculated with respect to the equilibrium distribution. Let $P^s$ be the distribution of the $x_s$ draw of the Gibbs sampler. If the sampler has not converged then $P^s \ne \pi$ where $\pi$ is the equilibrium distribution. So there will be some left over bias. If the sampler has converged, then $P^s$ is sufficiently close to $\pi$ so that, $$E_{\pi}\left[ \dfrac{1}{N} \sum_{s=1}^{N} g(x_s) \right] = \dfrac{1}{N} E[g(x_s)] = E[g(x)].$$ As a side, the more important question is that in practical settings it doesn't matter as much whether the sampler has converged perfectly, since as you get more samples, you do better estimation. Here is the reason. If instead of Gibbs sampling, the samples were obtained as iid samples, then the sample mean is a good estimate of the truth since $$\hat{g} = \dfrac{1}{N} \sum_{s= 1}^{N} g(x_s) \overset{a.s.}{\to} E[g(x)] \quad \text {as } N \to \infty, $$ where $\overset{a.s.}{\to}$ means convergence almost surely. This is often called the Strong Law of Large Numbers (SLNN). It is due to this convergence, if $N$ is large enough, we know that $E[g(x)] \approx \hat{g}$. This SLLN also holds for MCMC sampling (and hence for Gibbs sampling) if the Markov chain is Harris ergodic , i.e., the Markov chain is irreducible, aperiodic and positive Harris recurrent. This seems difficult to verify, but in fact holds for most MCMC algorithms. If your full conditionals in the Gibbs sampler are all valid distributions, then the Gibbs sampler is Harris ergodic, and thus the strong law of large numbers hold.
