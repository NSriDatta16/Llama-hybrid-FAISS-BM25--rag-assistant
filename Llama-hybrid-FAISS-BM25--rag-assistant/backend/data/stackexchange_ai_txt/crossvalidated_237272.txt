[site]: crossvalidated
[post_id]: 237272
[parent_id]: 237253
[tags]: 
You don't need to use a GLMM. There really isn't any need to assess any random effects or use them to control for non-independence. By default, people think of logistic regression as appropriate when the response is a Bernoulli trial, but it can be a binomial where there was more than one Bernoulli trial. You can use a regular old logistic regression with the response being the number of successes and number of failures for each child (cf., here ). In R , you would use: fit.glm = glm(cbind(successes, failures)~A*B + Age*(L1+L2), family=binomial, data) From there, the effects of Age and language ( L1 and L2 ) are simply nuisance variables. You can ignore them in the output. You can start by assessing the interaction that you care about (i.e., A*B ). If the interaction is sufficiently non-significant for your purposes, I would drop it and refit the model without it. The reason for this is that its existence complicates the interpretation of the 'main effects'. I would not drop it from the model just because the p-value is .06, however. You need to look at the magnitude of the coefficient and its standard error and decide if it makes sense to ignore it. I would certainly want the p-value to be above .2, for example. If you believe the interaction is real, you interpret it / the simple effects directly. Otherwise, interpret the main effects from the model without the interaction. Whichever way you go, I would try to visualize the data and the model.
