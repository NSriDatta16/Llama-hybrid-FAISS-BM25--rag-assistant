[site]: crossvalidated
[post_id]: 416962
[parent_id]: 416932
[tags]: 
If you are looking to just build a "good" (aka good enough) model and are not restricted to one type of model or another, I would recommend the following sequence of actions. Perform a single factor analysis first, where you calculate the Accuracy Ratio between your default indicator and each of your independent variables (since the outcome variable is binary -- default or no default -- the AR is equivalent in this case to Somers' D which can be easily calculated with any statistical software). Rank the results from best value of AR to worst, while also calculating the correlations between your predictors. This should address multicollinearity, as it will give you an idea of which factors are good candidates for the final model, while also telling you which ones to exclude due to correlation with other, well-performing factors, or because their correlation sign is counter-intuitive (this is particularly important in credit risk because it makes no sense to include a variable that has a negative correlation sign with default, like e.g. debt, where you would expect the opposite). Hopefully now you have decreased your predictors from 23 to e.g. 5 or 6, and you can then perform a simple logistic regression to estimate probability of default for future customers. To measure how well this method performs, you could split your data to development/validation samples, where you take for example 80% of the data and use it to train the model, then test the results on the remaining 20%. In general, a good model is one with discriminatory power $\geq 70\%$ . It should be noted here that the data characteristics themselves could also be at play if you still are not getting good results. As a rule of thumb, the method described above requires at least 50 defaults present in the portfolio, otherwise you are dealing with a so-called "low-default portfolio" , and those are generally more difficult to model in this way. Finally, it could also be that you simply have bad predictors as features, in which case not much can be done from a modelling point of view. You might be disappointed at my suggestion for a logistic regression instead of something fancier, but when it comes to this type of classification, it's a surprisingly well-performing method, especially if you look at the banking industry: fancier methods like neural networks etc. rely on both quantity and quality of data, two areas in which banks traditionally suffer when it comes to model building. Hope this helps.
