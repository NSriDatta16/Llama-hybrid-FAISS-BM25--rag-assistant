[site]: crossvalidated
[post_id]: 534738
[parent_id]: 
[tags]: 
loss function for probability maps

I am applying a deep learning architecture to predict the spatial distribution of nightly thunderstorms over location B based on the thunderstorms of the preceding afternoon over location A. Their relationship has been proven in prior research i.e., many thunderstorms over location A in the afternoon will result in many thunderstorms over location B during the following night. I am not interested in the temporal distribution of the nightly thunderstorms i.e., I only care whether or not there will be a thunderstorm over pixel X in location B during the night, not at which specific point during the night. I have at my disposal thunderstorm probability distribution maps of afternoons and nights over the region containing both locations A & B. The input to my NN is the afternoon time-series dataset containing the probability maps (floats between 0 and 1 of shape (24, 300, 300) with 24 being the afternoon time slices and (300, 300) representing the 2D map over the region containing both location A & B). The label is a 1D vector of size ~1300. I combined the night maps into one (300, 300) map and applied a mask over location B to reduce the label size from 300x300 to ~1300, containing again values between 0 and 1. Here comes the hard part (and the question): My data is not balanced i.e., there are many (>90%) pixels/values in the label which contain a value of 0. What would be a good way to resolve this 'unbalancedness'? and what loss function would be ideal for this problem? Currently I am using MSE as it seems most appropriate but I think a logarithmic loss function light be more suitable. Bonus points for those who can propose decent architectures, I do have limited training data. Thank you in advance for your answers!
