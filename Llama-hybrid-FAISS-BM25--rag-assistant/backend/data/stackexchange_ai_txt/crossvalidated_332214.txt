[site]: crossvalidated
[post_id]: 332214
[parent_id]: 180777
[tags]: 
Old question, I'm still searching for an answer though. Embrechts (1998) or Kruskal (1958) give this explanation, which may help, although to me it is not as clear as I would have hoped. Let $ \alpha + \beta X $ be the best linear estimate of $ Y $ given $ X $ in the least square sense, i.e., $E[Y-a-bX]^2$ is minimized by $a=\alpha$ and $b=\beta$. Then $\beta = \text{Cov}(X,Y)/\text{Var}(X)$ and $\alpha = E(Y)-\beta E(X)$. It follows that $$ \rho^2(X,Y)= \frac{\text{Var}(Y)-E(Y-\alpha -\beta X)^2}{\text{Var}(Y)}. $$ This means that $\rho^2(X,Y)$ is the average relative reduction in the squared deviation of $ Y $ from its "best" linear estimate, relative to the marginal variance of $Y$.
