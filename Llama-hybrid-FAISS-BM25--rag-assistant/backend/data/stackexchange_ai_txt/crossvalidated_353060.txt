[site]: crossvalidated
[post_id]: 353060
[parent_id]: 
[tags]: 
Explaining classification decision of a deep neural network in a non-vision task

I'm looking for a reliable way of explaining decisions of a deep neural network classification model. More specific, I want to know, which features contributed the most to a decision for a particular observation. For instance, imagine a credit scoring system - you would probably like to know why your model accepts or rejects an application. Unfortunately, I did some research and only found various methods (e.g. Grad-CAM) for Convolutional Neural Networks in the field of computer vision. I'm also aware of methods like LIME that are meant to explain any classifier's decisions. But, as far as I understand the paper , the problem is that LIME doesn't really work for relatively complicated models / data sets and there is a set of assumptions one have to satisfy. I'd like to find a method for other architectures (e.g. LSTM, Auto-Encoders, Dense NNs) and problems (e.g. sentiment analysis). Also, I implement my models in Python (Tensorflow, Keras, PyTorch). Is there any Python library that could help?
