[site]: datascience
[post_id]: 99499
[parent_id]: 28036
[tags]: 
The training one-example-at-time (what you can online learning) will yield worse performance on the evaluation metrics than training with many-examples-at-time. One-example-at-time will encourage the model to overfit to each and every data example. Increasing batch size will encourage the model to learn generalizable patterns. You'll have to balance training speed with evaluation metric performance. As far speeding-up your training, there are many possibilities: Reduce numerical precision from float32 Reduce the number of features Get a bigger or better computer Distribute the workload across a cluster.
