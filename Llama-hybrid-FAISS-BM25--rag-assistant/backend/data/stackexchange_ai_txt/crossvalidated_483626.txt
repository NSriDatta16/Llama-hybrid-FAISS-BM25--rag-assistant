[site]: crossvalidated
[post_id]: 483626
[parent_id]: 483345
[tags]: 
Your ability to get an AUC of 0.9 will depend on how well the predictors you have actually predict class membership. No amount of extra data can get around that fundamental constraint. A frequent rule of thumb is to make sure that you have at least 15 members of the minority class per predictor you are evaluating. A "predictor" here includes each level of a categorical variable beyond the first, and each interaction term that you include. So you should have no problem in building a model for these data, without overfitting, via a flexible logistic regression that incorporates splines for continuous predictors and several interaction terms, or a boosted tree that allows for interactions with deep trees. No promises about an AUC of 0.9, however.
