[site]: crossvalidated
[post_id]: 258289
[parent_id]: 
[tags]: 
Transformation bias with non-linear functions

This a more general question: I often deal with experimental data (subject to uncertainties in the measurements) that have to be transformed using a function, to calculate a parameter (which can, for example, be used by others to predict the behavior of a system/process). The propagation of the measurement uncertainties through such a function can be realized using different methods (e.g. Taylor series expansions listed here or Monte Carlo simulations). This works fine in most cases, but I'm not sure about transformation bias that is introduced by non-linear function: A non-linear function, applied to a random variable introduces a bias in the mean and other parameters of the resulting distribution. If the uncertainties are small and the functions are not highly non-linear, this bias it not very large, and at least in my field this issue is completely ignored by most scientists - but sometimes this is problematic. An example: $$ \alpha=\ln{(f\frac{1+R_0}{1+R}\frac{R}{R_0})}/\ln{(f\frac{1+R_0}{1+R})} $$ (giving the fractionation factor $\alpha$ for a Rayleigh fraction process for isotopes). Now I want to estimate $\alpha$ based on $f$, $R_0$ and $R$, that have been measured. Only one sample was taken/measured, but the measurement uncertainties of $f$, $R_0$ and $R$ were determined & follow normal distributions that are independent from each other. Of course, this doesn't allow to test whether the model function above is valid or not, but assuming that this is the case, the question is what the best estimate is for $\alpha$ and what the confidence interval is based on these measurements. If I use a Monte Carlo simulation to estimate the distribution of the output $\alpha$ using the known means & standard errors of the measurements, this distribution is clearly not normal, but rather something like log-normal: This article on experimental uncertainty analysis suggests that it is advantageous to first calculate the mean for the input parameters, and then apply the non-linear function. Calculating $\alpha$ in the example in this way gives $\alpha_1=1.000126$. The mean of the values resulting from the MCS is $\alpha_2=1.000112$ - apparently this value is biased due to the non-linearity of the function (and not very useful for my purposes?). Because of the long tail, the median is quite a bit lower again at $1.00008$, and I'm worried about the fact that $\alpha_1$ is quite a bit away from this median and the mode of the distribution. Now I want to give a confidence interval for $\alpha$. With normally distributed data this is straight forward, but what about this case? I could, for example calculate the CI for the mean using percentiles of data generated by the MCS (giving in this example $\{1.00006,1.00035\}$ as 95% interval). But wouldn't this be biased as well? The $\alpha_1$ even lies outside this range, so this can't be a good way to estimate CI for $\alpha_1$...?! Would it make sense to get the "relative" CI as in $\{1.00006,1.00035\}-\alpha_2=\{-0.00006,0.0003\}$ and and give them together with $\alpha_1$? I also tried transforming $\alpha$ to give a more normal distribution - for example, I could give $\ln{(\alpha)}$, a common form to express this parameter. Unfortunately, this doesn't give a normal distribution either, suggesting that the above distribution is not exactly log-normal (?): Is this really the best way (taking the means & applying the equation) to estimate a parameter such as $\alpha$ which then used by others (in the example above, one use could be to calculate $R$ if only $R_0$ and $f$ are known, or to compare it to another $\alpha$)? Is there a better way, for example related to maximum likelihood estimation (or even Bayesian statistics?), to estimate $\alpha$ for such an "empirical" distribution? But again, my main questions is - wouldn't all conclusions (mean, MLE, CIs, ...) drawn from the distribution after applying the function be biased? Or would this bias be removed "automatically" again when $\alpha$ is used when using it in an inverse function to calculate $f$, $R$ etc? But then I don't get why the wiki article linked above advises to use the "unbiased mean". An explanation or a reference to a good resource explaining these issues & the background that leads me in the right direction would be greatly appreciated! :)
