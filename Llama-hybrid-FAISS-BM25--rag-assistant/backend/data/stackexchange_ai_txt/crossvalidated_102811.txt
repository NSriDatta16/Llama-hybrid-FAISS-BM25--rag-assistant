[site]: crossvalidated
[post_id]: 102811
[parent_id]: 
[tags]: 
Question about the probability chain rule

I've understood from this: Is this a correct statement of the probability chain rule? that in the chain rule for probability, conditioning can be done on different variables. I was wondering what sort of implications this has for language modeling where we try and assign a probability to a sequence of m words P(w_1, w_2, ..., w_m) or any sequence for that matter. For example, say we want to assign a probability to P(the, cat, ran). As seen here: http://en.wikipedia.org/wiki/Language_model#N-gram_models one would compute P(the, cat, ran) by calculating P(the)*P(cat|the)*P(ran|the,cat). But given that conditioning can be done on different variables, would it be correct to say that P(the, cat, ran) = P(ran)*P(the|ran)*P(cat|ran,the)? If so, how is the sequence of the words actually taken into account? The probability of "the cat ran" is obviously more likely than "ran the cat".
