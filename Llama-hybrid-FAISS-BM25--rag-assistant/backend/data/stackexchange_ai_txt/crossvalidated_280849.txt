[site]: crossvalidated
[post_id]: 280849
[parent_id]: 279912
[tags]: 
You have a problem of missing data here, in which the missing-data mechanism hopelessly confounds the mechanism of the treatment effect. This likely represents a failed trial, which you should report honestly as such. In this study (ostensibly) of 'detoxification', you chose to measure not objective pre- and post-treatment serum or sweat concentrations of 'toxins', but rather subjective reports on a survey instrument. This tells me that you did not take at face value the 'detoxification' concept, or at least did not intend to examine scientifically the claim embedded in that word. Thus, at the very least, you demonstrate an agnosticism to your sauna 'detoxification' intervention that leaves open the possibility that it exerts its effects through psychosocial and similar 'placebo' mechanisms of the kind frequently described in connection with 'complementary and alternative medicine' treatments such as 'detox' . Can you argue persuasively that the mechanism driving the severe loss to follow up (LTFU) in your wait-listed group operated entirely separately from (placebo) mechanisms of 'detoxification'? I myself would tend to read psychological factors into this, like disappointment among those wait-listed and feeling lucky for those not wait-listed. How could you disentangle such phenomena from placebo mechanisms of the sauna treatment? I see that you list Bayesian methods as an area of interest in your bio; you would in fact be able to examine questions such as this using Bayesian methods that posit informative missingness mechanisms in your data set. See e.g. Greenland's work on quantitative bias analysis [1] and Chapter 8 in BDA3 [2]. I understand your original question as reflecting a hope that following one or more statistical 'best practices' might help you produce a credible analysis of this trial. As I have indicated with this answer, I consider that hope misplaced. Indeed, the only purely statistical advice that seems relevant at this point regards correct reporting of loss to follow up . From your earlier comment, I gather that you actually randomized on a 1:1 basis, so that the $N=12$ in your diagram counts only half of the veterans actually assigned to the wait-list. By correcting this under-counting, thus making clear the actual magnitude of LTFU in your study, you will begin the process of convincing the various people involved that the study has failed. Greenland S. Multiple-bias modelling for analysis of observational data (with discussion). J R Stat Soc A. 2005;168(2):267-306. doi:10.1111/j.1467-985X.2004.00349.x. Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB. Bayesian Data Analysis. Third edition. Boca Raton: CRC Press; 2014.
