[site]: crossvalidated
[post_id]: 201930
[parent_id]: 201927
[tags]: 
It appears that the policy network determines a probability distribution $p(a \mid s)$ over the possible moves $a$ when in game state $s$. When the program is searching the game tree it does so in a random fashion, and $p$ determines how it does this search. The hope is that this function will "guide" the program to good moves that a strong player is likely to make. This makes sense because when you search the game tree the branches that begin with mistakes are less relevant when evaluating the current board position against an intelligent opponent. When they say that the rollout policy (I believe they borrowed the term "rollout" from backgammon) is a linear softmax function they're referring to a generalization of the sigmoid function used in logistic regression. This function takes the form $$ \frac{e^{\beta^T_i x}}{\sum_{j=1}^{k} e^{\beta_j^T x}} $$ where $x$ is a vector that is a function of the current board position (according to the paper the linear softmax is only used at the last step of the policy network) and $\beta_i$ is a vector of weights which together determine the probability that the policy network will choose action $a_i$.
