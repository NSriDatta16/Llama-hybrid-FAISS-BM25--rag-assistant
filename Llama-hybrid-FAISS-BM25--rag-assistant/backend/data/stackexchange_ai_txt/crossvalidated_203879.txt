[site]: crossvalidated
[post_id]: 203879
[parent_id]: 203825
[tags]: 
If you are estimating a model you typically are looking for the minimum variance unbiased estimator (MVU) . Hence, you intend to find the one model whose predictions have the lowest variance possible while maintaining a bias $(y_{true} - y_{estimated})$ of zero. The thing is, there is a trade-off between the variance of a model and its bias . Ideally you want both values as close as possible to zero, which then would guarantee you correct predictions. However, by reducing the bias on the training-data you are raising the variance on the test-data and vice versa. Hence, there are certain cases where the MVU may not be what is wanted. You then need the bias term to be different from the differences between the averages. Which then would be a different use case for your bias term.
