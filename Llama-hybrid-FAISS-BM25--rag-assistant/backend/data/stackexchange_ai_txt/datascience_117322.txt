[site]: datascience
[post_id]: 117322
[parent_id]: 
[tags]: 
Explain notation in Bishop Eq 1.60

I'm starting to work through Bishop's "Pattern Recognition and Machine Learning" book, and have run into unfamiliar notation. Eq. 160 is prefaced by saying "For this purpose, we shall assume that, given the value of $x$ , the corresponding value of $t$ has a Gaussian distribution with a mean equal to the value [of the polynomial curve $y(x, \mathbf{w}) = \sum_{j=0}^M w_j x^j$ ]. Thus we have" $$p(t|x, \mathbf{w}, \beta) = {\cal N}(t|y(x, \mathbf{w}), \beta^{-1}) \tag{1.60}$$ I understand the LHS to read "the probability density as a function of $t$ , given $x$ , $\mathbf{w}$ and $\beta$ ". The RHS is indicating a normal distribution with variance $\beta^{-1}$ . The bit I don't understand is what is going on with the mean of this distribution - how should I interpret $\mu = t|y(x, \mathbf{w})$ ? Why isn't this just written as ${\cal N}(y(x, \mathbf{w}), \beta^{-1})$ ? What is the bar signifying? I only know its meaning within a probability. (This notation continues to be used, e.g. in Eqs. 1.61, 1.64, 1.69, so I'd like to make sure I understand it!) (I don't know if there are multiple editions of this book; the section I am reading here is 1.2.5 "Curve fitting re-visited", and Eq. 1.60 is the first equation in this section.)
