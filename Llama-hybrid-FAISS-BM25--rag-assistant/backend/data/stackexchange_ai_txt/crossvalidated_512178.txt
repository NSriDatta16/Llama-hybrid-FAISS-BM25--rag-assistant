[site]: crossvalidated
[post_id]: 512178
[parent_id]: 
[tags]: 
Prove the given transformation of a Markov Chain is a Markov Chain

Let $\{X_n:n=0,1,\dots\}$ be a discrete time Markov chain on state space $S$ . We define $Y_n$ as the following: $$Y_n=(X_n, X_{n+1})$$ Prove that $\{Y_n:n=0,1,\dots\}$ is a discrete time Markov chain My attempt: $$P(Y_n = (j_n,k_n) | Y_{n-1}=(j_{n-1},k_{n-1}),\dots,Y_0 = (j_0,k_0))$$ $$=P(X_n=j_n,X_{n+1}=k_n|X_{n-1}=j_{n-1},X_n=k_{n-1},\dots,X_0 = j_0,X_1=k_0)$$ Here is where I am slightly confused. Would it be valid to use implications of Markov's property and simply get: $$P(X_n=j_n,X_{n+1}=k_n|X_{n-1}=j_{n-1},X_n=k_{n-1})=P(Y_n=(j_n,k_n)|Y_{n-1}=(j_{n-1},k_{n-1}))$$ This seems like I am playing too fast and loose with the property however.
