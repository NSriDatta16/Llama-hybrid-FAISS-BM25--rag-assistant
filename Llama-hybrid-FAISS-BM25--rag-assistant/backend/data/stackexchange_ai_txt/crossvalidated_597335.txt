[site]: crossvalidated
[post_id]: 597335
[parent_id]: 
[tags]: 
What's the proper way to analyze data from an experiment where participants perform different tasks?

I've recently conducted an experiment on my university where participants had to perform various tasks using two different virtual reality interaction methods (each participant performed all tasks twice). Now that I have the results, I'm wondering about how to approach analyzing them. Initially I thought I could just compare the results of both interaction methods in each task and say something like this: "on average participants performed twice as good with method A compared to method B in task X". But the issue is that because the task difficulty level was quite varied, the score distribution varies as well. In some cases, achieving double the score in a task with a different interaction method is common, but for other tasks an increase of 30% is actually really significant. I thought about normalizing the data somehow, either based on mean or average score, but I don't think that's enough since it doesn't take into account the shape of the distribution. Is there a standard way of approaching data like this? Should I just refrain from using phrases like "performed twice as good" and rather talk about the percentage of top results achieved with each method? EDIT: The tasks: a game similar to whac a mole, repeating hand gestures, pointing at targets and building a tower. The experiment had 24 participants. Here is score distribution for two tasks: As you can see in both tasks the difference is clear, however for the second one the scores are much closer together. This might make it seem that the difference is less significant, but this mostly due to the nature of the tasks. Is there any way to account for this when analyzing this data?
