[site]: crossvalidated
[post_id]: 169148
[parent_id]: 
[tags]: 
How to represent and sample prior in the continuous case?

I'm trying to estimate an underlying distribution from a few data points. I'm using a bayesian updating technique and this works pretty well (see my other question ). However, I currently use a discreet set of hypotheses $P(a|i)$ with weight or prior $P(i)$. The data variable is $a$, my hypotheses are enumerated by $i$. Now I'd like to go to a smooth set of hypotheses, for example $P(a|\theta)$ or $P(a|\mu,\sigma)$ with some prior $P(\mu,\sigma)$. Then the expression for $P(a)$ becomes a marginalization integral: $$P(a) = \int_\theta P(a|\theta) P(\theta)\,d\theta$$ This is easy if $P(\theta)$ is simple (e.g. flat), but how do I represent it after a knowledge update (especially in a program)? The updated prior no longer has a nice functional form. I could discretize it again, but that limits my accurracy (and it may be feasible now in 2D, but it gets worse if I add more parameters). I could sample random $(\mu,\sigma)$ points, but I only see how that brings me through one iteration. It lets me calculate $P(a)$ for a given $a$. I want to use it to update my prior in light of new data $a^*$: $$P(\theta)\bigg|_\mathrm{new} = P(\theta|a^*) = \frac{P(a^*|\theta)}{P(a^*)} P(\theta)$$ Since the sum over random points would be in $P(a^*)$, and after the first iteration also in $P(\theta)$, this would explode quickly computationally. I'm sure there are well-known techniques to represent $P(\theta)$ and to perform the integration, and it would be great if someone could point me towards them.
