[site]: stackoverflow
[post_id]: 3988238
[parent_id]: 
[tags]: 
Help me with my backprop implementation in Python

EDIT2: New training set... Inputs: [ [0.0, 0.0], [0.0, 1.0], [0.0, 2.0], [0.0, 3.0], [0.0, 4.0], [1.0, 0.0], [1.0, 1.0], [1.0, 2.0], [1.0, 3.0], [1.0, 4.0], [2.0, 0.0], [2.0, 1.0], [2.0, 2.0], [2.0, 3.0], [2.0, 4.0], [3.0, 0.0], [3.0, 1.0], [3.0, 2.0], [3.0, 3.0], [3.0, 4.0], [4.0, 0.0], [4.0, 1.0], [4.0, 2.0], [4.0, 3.0], [4.0, 4.0] ] Outputs: [ [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [1.0], [0.0], [0.0], [0.0], [1.0], [1.0] ] EDIT1: I have updated the question with my latest code. I fixed few minor issues but I am still getting the same output for all input combinations after the network has learned. Here is the backprop algorithm explained: Backprop algorithm Yes, this is a homework, to make this clear right at the beginning. I am supposed to implement a simple backpropagation algorithm on a simple neural network. I have chosen Python as a language of choice for this task and I have chosen a neural network like this: 3 layers: 1 input, 1 hidden, 1 output layer: O O O O O There is an integer on both inptut neurons and 1 or 0 on an output neuron. Here is my entire implementation (a bit long). Bellow it I will choose just shorter relevant snippets where I think an error could be located at: import os import math import Image import random from random import sample #------------------------------ class definitions class Weight: def __init__(self, fromNeuron, toNeuron): self.value = random.uniform(-0.5, 0.5) self.fromNeuron = fromNeuron self.toNeuron = toNeuron fromNeuron.outputWeights.append(self) toNeuron.inputWeights.append(self) self.delta = 0.0 # delta value, this will accumulate and after each training cycle used to adjust the weight value def calculateDelta(self, network): self.delta += self.fromNeuron.value * self.toNeuron.error class Neuron: def __init__(self): self.value = 0.0 # the output self.idealValue = 0.0 # the ideal output self.error = 0.0 # error between output and ideal output self.inputWeights = [] self.outputWeights = [] def activate(self, network): x = 0.0; for weight in self.inputWeights: x += weight.value * weight.fromNeuron.value # sigmoid function if x 320: self.value = 1 else: self.value = 1 / (1 + math.exp(-x)) class Layer: def __init__(self, neurons): self.neurons = neurons def activate(self, network): for neuron in self.neurons: neuron.activate(network) class Network: def __init__(self, layers, learningRate): self.layers = layers self.learningRate = learningRate # the rate at which the network learns self.weights = [] for hiddenNeuron in self.layers[1].neurons: for inputNeuron in self.layers[0].neurons: self.weights.append(Weight(inputNeuron, hiddenNeuron)) for outputNeuron in self.layers[2].neurons: self.weights.append(Weight(hiddenNeuron, outputNeuron)) def setInputs(self, inputs): self.layers[0].neurons[0].value = float(inputs[0]) self.layers[0].neurons[1].value = float(inputs[1]) def setExpectedOutputs(self, expectedOutputs): self.layers[2].neurons[0].idealValue = expectedOutputs[0] def calculateOutputs(self, expectedOutputs): self.setExpectedOutputs(expectedOutputs) self.layers[1].activate(self) # activation function for hidden layer self.layers[2].activate(self) # activation function for output layer def calculateOutputErrors(self): for neuron in self.layers[2].neurons: neuron.error = (neuron.idealValue - neuron.value) * neuron.value * (1 - neuron.value) def calculateHiddenErrors(self): for neuron in self.layers[1].neurons: error = 0.0 for weight in neuron.outputWeights: error += weight.toNeuron.error * weight.value neuron.error = error * neuron.value * (1 - neuron.value) def calculateDeltas(self): for weight in self.weights: weight.calculateDelta(self) def train(self, inputs, expectedOutputs): self.setInputs(inputs) self.calculateOutputs(expectedOutputs) self.calculateOutputErrors() self.calculateHiddenErrors() self.calculateDeltas() def learn(self): for weight in self.weights: weight.value += self.learningRate * weight.delta def calculateSingleOutput(self, inputs): self.setInputs(inputs) self.layers[1].activate(self) self.layers[2].activate(self) #return round(self.layers[2].neurons[0].value, 0) return self.layers[2].neurons[0].value #------------------------------ initialize objects etc inputLayer = Layer([Neuron() for n in range(2)]) hiddenLayer = Layer([Neuron() for n in range(100)]) outputLayer = Layer([Neuron() for n in range(1)]) learningRate = 0.5 network = Network([inputLayer, hiddenLayer, outputLayer], learningRate) # just for debugging, the real training set is much larger trainingInputs = [ [0.0, 0.0], [1.0, 0.0], [2.0, 0.0], [0.0, 1.0], [1.0, 1.0], [2.0, 1.0], [0.0, 2.0], [1.0, 2.0], [2.0, 2.0] ] trainingOutputs = [ [0.0], [1.0], [1.0], [0.0], [1.0], [0.0], [0.0], [0.0], [1.0] ] #------------------------------ let's train for i in range(500): for j in range(len(trainingOutputs)): network.train(trainingInputs[j], trainingOutputs[j]) network.learn() #------------------------------ let's check for pattern in trainingInputs: print network.calculateSingleOutput(pattern) Now, the problem is that after learning the network seems to be returning a float number very close to 0.0 for all input combinations, even those that should be close to 1.0. I train the network in 100 cycles, in each cycle I do: For every set of inputs in the training set: Set network inputs Calculate outputs by using a sigmoid function Calculate errors in the output layer Calculate errors in the hidden layer Calculate weights' deltas Then I adjust the weights based on the learning rate and the accumulated deltas. Here is my activation function for neurons: def activationFunction(self, network): """ Calculate an activation function of a neuron which is a sum of all input weights * neurons where those weights start """ x = 0.0; for weight in self.inputWeights: x += weight.value * weight.getFromNeuron(network).value # sigmoid function self.value = 1 / (1 + math.exp(-x)) This how I calculate the deltas: def calculateDelta(self, network): self.delta += self.getFromNeuron(network).value * self.getToNeuron(network).error This is a general flow of my algorithm: for i in range(numberOfIterations): for k,expectedOutput in trainingSet.iteritems(): coordinates = k.split(",") network.setInputs((float(coordinates[0]), float(coordinates[1]))) network.calculateOutputs([float(expectedOutput)]) network.calculateOutputErrors() network.calculateHiddenErrors() network.calculateDeltas() oldWeights = network.weights network.adjustWeights() network.resetDeltas() print "Iteration ", i j = 0 for weight in network.weights: print "Weight W", weight.i, weight.j, ": ", oldWeights[j].value, " ............ Adjusted value : ", weight.value j += j The last two lines of the output are: 0.552785449458 # this should be close to 1 0.552785449458 # this should be close to 0 It actually returns the output number for all input combinations. Am I missing something?
