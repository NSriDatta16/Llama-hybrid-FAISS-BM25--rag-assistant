[site]: datascience
[post_id]: 75502
[parent_id]: 
[tags]: 
questions on multi-step air pollution prediction

I am trying to use RNN to predict the concentration of various air pollutants for the next 24 hours. The input data consists of 72 hours long and every hour owns 14 elements such as temperature, windspeed, and the history concentration of several pollutants. The output is the concentrate of a certain pollutant in the next hours. However, I found that if I used LSTM to predict just one-future-hour concentration, I could get a high accuracy on it. when I try to do prediction in a long term such as a 24-future-hour prediction, I choose to use an encoder-decoder framework to predict future 24 hours concentration. The problem is that no matter how I adjust the model, I cannot get as accurate as a single LSTM in the first hour, but a multi-step model is hard to do a rolling forecast by predicting all the input elements. (to be honest, I did it and it really was more accurate than an encoder-decoder framework in the first few hours, and then it is less accurate than the encoder-decoder one) I do some survey on some paper and they said it's better to cut the 24 hours into many segments. This method can promote accuracy in every hour. I want to know that why it is and I wonder that is there any model that can deal with this problem without cutting itself into several segments? Or am I wrong in understanding the model I used and didn't unleash its potential?
