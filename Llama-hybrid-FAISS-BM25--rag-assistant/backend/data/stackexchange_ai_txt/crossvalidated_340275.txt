[site]: crossvalidated
[post_id]: 340275
[parent_id]: 340175
[tags]: 
As a general statement: given a sufficiently powerful (/suitable) classifier, or cluster-er, one would never apply any dimensionality reduction. Dimensionality reduction loses information. Since such a cluster-er or classifier (esp classifiers, less so clusterers), internally incorperates some form of projection to a meaningful space already. And Dimensionality reduction is also projection to a (hopefuly) meaningful space. But dimensionality reduction has to do so in a uninformed way -- it does not know what task you are reducing for. This is especially true for classification, where you have outright supervised information. But it also applies to clustering, where the space one would want to project to for clustering is better defined (for this algorithm) than just "have less dimensions). @usÎµr11852's answer talks about this. As I said dimensionality reduction does not know what task you are reducing for -- you inform it in your choice of which dimensionality reduction algorithm you to use. So often rather than adding a dimensionality reduction step as preprocessing before clustering/classification, one is better to use a different classifier/cluster-er that incorperates a useful projection. One thing dimentionality reduction does have going for it in this though is its unsupervised nature in creating the projection to the (hopefully) meaningful space. Which is useful if you have little label data. But there are often other methods that are closely linked to your classifier (e.g. for neural networks, using autoencoder e.g. deep belief network pretraining) that are going to work better, because they are designed with that final task in mind. Not the more general task of dimensionality reduction.
