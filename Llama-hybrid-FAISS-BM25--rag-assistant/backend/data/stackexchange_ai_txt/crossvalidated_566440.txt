[site]: crossvalidated
[post_id]: 566440
[parent_id]: 566436
[tags]: 
This is a standard classification problem. The time-series property of your input is already taken care of by most algorithms, as long as you feed one complete time series at a time to your model, not e.g. single $(x, y)$ pairs. There are few models that deliberately disregard the order of the input features (i.e. they are permutation invariant), so those you definitely don't want to use. The first reflex would be to try some deep neural network, though 1000 function-label pairs might not be enough. But, provided you have the necessary hardware (GPUs), I would give it a try, though. I would expect that your best bet for a short path to victory here would be using out-of-the-box random forest or GBM models. And then, if the results of those methods don't satisfy you, of course, you have to get to know your data better: how many labels are there, is the labeling unbalanced, what is the type of dependence of your input features, do they have high mutual information, would it help to do some serious feature engineering... All this information about your data would help you in preprocessing your input data and the choice of the best model. Maybe you could even think about fitting a time series models to each of your "waves" (so you end up with as many time series models as you have time series) and then replace each wave with the parameters of its fitted model. You could e.g. use the excellent R packages written by Rob Hyndman (the one who wrote the first answer to your question :)
