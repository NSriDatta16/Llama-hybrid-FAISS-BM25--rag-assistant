[site]: crossvalidated
[post_id]: 308796
[parent_id]: 
[tags]: 
Confusion regarding the dimensions of matrices in the formula for SVD

I wanted to understand Singular Value Decomposition (SVD) hence consulted a few resources. In general I came across 2 different forms of SVD and hence got confused as to which one is correct or whether both are equivalent etc. The 2 forms I came across are : 1) Page 45 of deep learning book ( http://www.deeplearningbook.org/contents/linear_algebra.html ) The singular value decomposition is similar, except this time we will write A as a product of three matrices: $A = UDV^T$ ($^T$ implying transpose) Suppose that $A$ is an $m \times n$ matrix. Then $U$ is defined to be an $m \times m$ matrix, $D$ to be an $m \times n$ matrix, and $V$ to be an $n \times n$ matrix. and 2) Lec 47 of Mining Massive Datasets course ( https://www.youtube.com/watch?v=P5mlg91as1c&list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV&index=47 ) $A = UDV^T$ ($^T$ implying transpose) Suppose that $A$ is an $m \times n$ matrix. Then $U$ is defined to be an $m \times r$ matrix, $D$ to be an $r \times r$ matrix, and $V$ to be an $n \times r$ matrix. I consulted some more resources, it turns out that both the formulas are present in them as well. I need help to understand where is the gap in my understanding and what more do I need to cover (from a theoretical viewpoint) to bridge it.
