[site]: crossvalidated
[post_id]: 517858
[parent_id]: 515740
[tags]: 
Variational inference isn't a model in itself, it's just a technique for tractably working with otherwise intractable latent variable models. $q(z)$ can't approximate a posterior if you have none to begin with. So, you do need to define a latent variable model first. The only "assumption" is that you have a model at all. This might be less confusing with some examples: In a bayesian logistic regression model, you have a gaussian prior $p(z)$ and your observed variables are a tuple $(x,y)$ with $p((x,y)|z)$ being $\sigma(z^Txy)$ (let class $y$ be either -1 or +1). In a variational autoencoder, you have standard gaussian prior $p(z)$ , and $p(x|z) = \mathcal{N}(\mu = f(z),\sigma^2)$ where $f$ is some arbitrary neural network. So, in general, $p(x,z)$ is not gaussian, and it can usually be tractably computed.
