[site]: datascience
[post_id]: 49495
[parent_id]: 
[tags]: 
What are the key differences between a MLP with lagged features and a RNN

I've been working with multilayer perceptron (MLP) for a while. Whenever I assumed that the past values of a feature might be useful for predicting the future values of y, I would just create a new column in my data frame with Feature(t-1). This process would be repeated for further lags t-2,t-3...t-n. Besides the obvious problem of the curse of dimensionality, I am worried that the MLP doesn't know how to weight those time lagged features that are now in a new separate column. So in a nutshell: Is the above approach wrong? How does an RNN solve this?
