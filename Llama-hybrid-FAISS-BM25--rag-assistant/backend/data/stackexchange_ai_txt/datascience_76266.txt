[site]: datascience
[post_id]: 76266
[parent_id]: 76263
[tags]: 
At first, choosing the best model is probably not as important as getting the data-set setup properly. Most of data science and modelling is spent on building the best data-set to use. Random Forest Classification, SVM, XGBClassifier, even Logistic regression can perform adequately if given the properly prepared data-set to analyze. Also, the metric you are comparing you model to should be appropriate for imbalanced data. Just a FYI, accuracy is not one of them. Here are just a few suggestions to get you started: Data preparation/cleansing: you can try more methods to balance, such as down-sampling (think this is usually better than up-sampling as the data you are using was real data, not synthetic). SMOTE is okay also, but can be a bit more complicated to use properly you can try using a weighting function in your model to give more importance to the minority value, if you think a mistake in predicting that value is more important or more costly than a mistake in the majority, or just want to balance your predictions evenly between the classes You can use PCA, SVD or LDA to remove some of the correlations between your features Normalize the data as some algorithms still don't handle large differences in features very well (ex: feature one mean is .001 vs feature 2 mean is 1000). This is a good practice in any modelling. Look for fliers. Sometimes fliers can cause problems. Look for values that don't make sense, or are too far out of normal range. Metric to use: I usually use ROC_AUC to find which model is best at predicting both majority and minority classes. Sensitivity and Specificity are also 2 good metrics to use to see how good your model is at predicting each class
