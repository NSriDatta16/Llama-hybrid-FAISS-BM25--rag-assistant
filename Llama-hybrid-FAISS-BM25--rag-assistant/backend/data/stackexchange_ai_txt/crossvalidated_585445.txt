[site]: crossvalidated
[post_id]: 585445
[parent_id]: 
[tags]: 
How can Discriminator and Generator loss both move to 0?

I have been working with GANs for years and I still can't figure this out. A common thing I see is when the loss of both G and D are near zero. I usually use MSE or cross entropy loss. Shouldn't this be impossible regardless of whether your GAN setup is good/bad/stable/unstable? The loss for G is defined by how well it fools D. The loss for D is defined by how well it is not fooled by G. So a zero loss for G means it is fooling D every time, but a zero loss for D means it is never being fooled. So in other words when both losses are 0 it means D is both never and always being fooled. They are defined as inverses of each other. How could this happen? Here is a good link where they purposely create instability that causes G and D to both be near zero loss and it has code for reproducing. Relevant info is at the end. Link
