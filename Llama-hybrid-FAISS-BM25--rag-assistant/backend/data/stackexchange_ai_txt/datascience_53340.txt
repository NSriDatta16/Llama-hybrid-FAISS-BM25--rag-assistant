[site]: datascience
[post_id]: 53340
[parent_id]: 
[tags]: 
Does it make sense to use TF-IDF to extract most important tokens from a corpus?

I have a collection of documents and I'd like to extract the most important words and phrases from the entire corpus. My understanding of TF-IDF is that it is calculated per token per document , so the calculated weights are relative to a given document in the corpus. Is there a way to use TF-IDF to recover the most significant terms in the entire corpus, or is this the wrong approach? If the latter, what would be a more appropriate NLP approach?
