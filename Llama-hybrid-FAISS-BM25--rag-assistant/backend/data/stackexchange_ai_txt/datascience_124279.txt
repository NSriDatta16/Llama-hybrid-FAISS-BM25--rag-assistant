[site]: datascience
[post_id]: 124279
[parent_id]: 
[tags]: 
Validation loss hump in LSTM

I'm using PyTorch to fit an LSTM to a binary time series dataset which has about 300 time series of about 20 items. I am using 15% of the time series as a validation set. I then have an MLP on top of the time LSTM. In most cases, although the training loss decreases monotonically, apart from some noise, the validation loss rises before falling again, as shown below. What is going on?
