[site]: crossvalidated
[post_id]: 376053
[parent_id]: 376043
[tags]: 
Firstly, do you mean you trained on all data except for the last 2 days (and the tested on the last two)? This is quite a common problem with time series data. Imagine the following, you're trying to predict a continuous target variable based on some other continuous variable that fluctuates a lot, and you know is not in any way correlated to the target. If you train a model that massively overfits, for the sake of argument, a decision tree with no minimum leaf size, it will effectively "memorise" that, for example, "when 0.3587 Now, if both the feature and target vary sufficiently slowly in time, then, when doing k-fold cross-validation (randomly I assume rather than stratified), any one of your test examples probably has a few corresponding examples in the training set which were taken very close in time to this one. Thus both the feature and target value are likely to be close to an example in the training data, which the classifier has "memorised". If however, your test example is sufficiently far in time from any training examples, then your classifier will associate it with the training example whose feature value is closest to your current feature value, and return whatever the target was at that time...which we know is a random guess, if the feature carries no information about the target.
