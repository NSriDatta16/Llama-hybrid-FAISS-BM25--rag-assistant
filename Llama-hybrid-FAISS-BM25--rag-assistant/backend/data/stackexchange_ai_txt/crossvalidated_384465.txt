[site]: crossvalidated
[post_id]: 384465
[parent_id]: 
[tags]: 
Emotion detection: neural network overfitting on audio files

I am working on an analysis of audio data to understand emotions using the RAVDESS dataset . The input is the Mel-frequency cepstral coefficients (MFCCs) of each audio file, extracted using a Python module called Librosa . The output expected is a prediction of one out of 8 classes (happy, angry, neutral and so on). Actually, the accuracy of the model is 83% on the training set and 69 % on the test set. To review the project completely, in this Github repository you will find the previous version. Issue : looking at the plot of my cost function, it seems that the model starts to overfit after epoch 300 (training is decreasing way faster that test) I am searching for a strategy to improve the performances of the model: the goal is to reach 80% on the test set. General info about the problem and the data The shape of the training set and the test set are: ((1642, 40, 1), (810, 40, 1)) How the neural network is build: model = Sequential() model.add(Conv1D(256, 5,padding='same', input_shape=(40,1))) model.add(Activation('relu')) model.add(Conv1D(128, 5,padding='same')) model.add(Activation('relu')) model.add(Dropout(0.1)) model.add(MaxPooling1D(pool_size=(8))) model.add(Conv1D(128, 5,padding='same',)) model.add(Activation('relu')) model.add(Conv1D(128, 5,padding='same',)) model.add(Activation('relu')) model.add(Flatten()) model.add(Dense(10)) model.add(Activation('softmax')) opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6) model.compile(loss='sparse_categorical_crossentropy', optimizer=opt,metrics=['accuracy']) cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500, validation_data=(x_testcnn, y_test))
