[site]: crossvalidated
[post_id]: 610845
[parent_id]: 610551
[tags]: 
Let's look at the CLT. Its main issue is convergence in distribution. Rather than writing $Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\sim\mathcal{N}(0,1)$ , we can write $\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}\xrightarrow{d}\mathcal{N}(0,1)$ . The CLT has some variants, the Lindeberg–Lévy variant states it in a slightly different manner: $\sqrt{n}(\bar{X}-\mu)\xrightarrow{d}\mathcal{N}(0,\sigma^2)$ . This means that the difference between the average and the mean converges to the normal distribution $\mathcal{N}(0,\sigma^2)$ with rate $\sqrt{n}$ . For our needs, we can re-write the Lindeberg–Lévy variant as $\sqrt{n}\left(\frac{\bar{X}-\mu}{\sigma}\right)\xrightarrow{d}\mathcal{N}(0,1)$ . That is, the statistic $\frac{\bar{X}-\mu}{\sigma}$ converges to the standard normal distribution $\mathcal{N}(0,1)$ with rate $\sqrt{n}$ . Why is this important? One can think of the rate of convergence as the speed of approaching $\mu$ . Upon combining different variables (which depends on some theory like continuity conditions, Slutsky's theorem and the LLN ), we need to make sure they have the same rate of convergence or otherwise the convergence of the sum doesn't hold. Consider $Z_1=\frac{\bar{X}-\mu_X}{\sigma_X}$ and $Z_2=\frac{\bar{Y}-\mu_Y}{\sigma_Y}$ . If they have the same convergence rate (say $\sqrt{n}$ ) then we can write something like $\sqrt{n}(Z_1+Z_2)\xrightarrow{d}\mathcal{N}(0,2)$ . If they have different convergence rates, we cannot discuss the convergence of a combination. This issue of rate of convergence (which in CLT is $\sqrt{n}$ ) is the reason for writing the square root of the sample size in z-scores. The rate of convergence is an important and nontrivial topic, you can read some more here and here .
