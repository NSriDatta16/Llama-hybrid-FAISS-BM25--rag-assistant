[site]: datascience
[post_id]: 36909
[parent_id]: 
[tags]: 
Evaluating metrics F1, F2, Mean Average Precision for object detection

Up today in the company where I work we are using the F1 Score for evaluating the performance of our model, also our competitor's using the same metric. I would like to understand what's the difference between F1,F2 and mAP?(Please do not explain me how to calculate them, also I know that F measure gives the same weight to the precision and recall while mAP choose the best precision from all recalls) Why in competitions (e.g. PASCAL VOC) and articles for object detection I am reading it is always preferred to use mAP instead of F1 or F2 scores ? Thanks !
