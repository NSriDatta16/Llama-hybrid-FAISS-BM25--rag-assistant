[site]: crossvalidated
[post_id]: 458391
[parent_id]: 458389
[tags]: 
The priors for a Bayesian model induce a sort of regularization. This is best seen in linear regression, where the is a 1:1 correspondence between model prior standard deviations and the penalty parameter in something like lasso and ridge regression. Another interpretation would be to use Laplace priors for the coefficients of your Bayesian model, thereby making a sparsity assumption. This may or may not be easy. I'm not sure if libraries like brms implement such priors. Michael Betancourt has written on the topic of Bayes sparse regression, so if you are able to understand this , then I think this is your best bet.
