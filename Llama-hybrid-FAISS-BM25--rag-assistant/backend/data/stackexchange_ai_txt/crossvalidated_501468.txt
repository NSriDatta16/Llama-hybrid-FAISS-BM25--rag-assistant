[site]: crossvalidated
[post_id]: 501468
[parent_id]: 
[tags]: 
Resample Unbalanced sequence data in deep learning doesn't have good effect?

I'm working on text classification using a deep learning approach. Because the data I use has unbalanced conditions, I try to implement data balancing techniques using the imblearn library. However, instead of getting better results, I ended up getting really bad results after oversampling or undersampling. Say on the original data I get 85% accuracy with 5 epochs. After resampling, I got 3% accuracy with 5 epochs. Then, I tried to use a larger epoch for resampled data, and I got 78% accuracy with 15 epochs, then I got >80% accuracy with 25 epochs. Does this make sense? I mean, I even get better results without doing any data balancing techniques. But I've also tried it on shallow learning algorithms, and data balancing techniques had a good effect. Can anyone explain this? Thank you in advance
