[site]: crossvalidated
[post_id]: 79627
[parent_id]: 79622
[tags]: 
As you loop over the 10 folds, each fold returns an accuracy. That accuracy varies a little bit, depending on how you slice your data for each fold. The range of accuracies that you obtain represents the range of variability in the performance of your model that you might expect to see, if you brought that model to bear upon a brand new set of test data. From the 10 accuracies that you obtain, for each classifier, you can calculate a mean and a corrected sample standard deviation . You would like to know, for two classifiers with two different average accuracies, whether those differences are "significant", i.e., whether the differences are meaningfully different, or are simply due to the same random statistical fluctuations that account for the same fold-to-fold random variation that you have already observed in the first place. If you have an average accuracy $A_{1}$ and standard deviation $\sigma_{1}$ for classifier number 1, and the same for some other classifier number 2, you can estimate whether the difference in their relative performance is meaningfully different from zero by calculating $$\Delta_{12} = \frac{A_{1} - A_{2}}{\sqrt{\sigma_{1}^{2} + \sigma_{2}^{2}}}$$ This quantity can be interpreted effectively as a kind of Z score . If the score is large (a value greater than 3 standard deviations is a common choice of cutoff) you may declare the performance of the two classifiers to be significantly different, if not, they are essentially equivalent.
