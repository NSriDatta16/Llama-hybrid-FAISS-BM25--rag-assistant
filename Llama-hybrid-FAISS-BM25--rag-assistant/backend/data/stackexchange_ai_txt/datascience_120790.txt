[site]: datascience
[post_id]: 120790
[parent_id]: 
[tags]: 
How to normalize(or other) the audio data so that the same labels with the similar characteristics from different records?

I am trying to detect swallows from recordings taken from hospital. I manually labelled the recordings on the Praat. Now the valid labels are silence, swallows and nonswallows(noise, enviromenment noise etc.) After I construct my dataset and train with SVM(using libSVM library) I observed that the amplitudes variations of the swallow and silence events differ from one recording to other, this significantly has effects on the training. The reason is that in some recording swallows have very low amplitudes, and they can be learnt as silence events by algorithm. For that purpose, to see what happens in overall dataset, I got the histogram of silence/swallow events with their max amplitudes. How to normalize the data so that the same labels have the same pattern for overall dataset? Any recommendation? Here is how the amplitudes of the swallows events look like in the histogram of 32, where SAS means swallow for our preferred label for recordings.
