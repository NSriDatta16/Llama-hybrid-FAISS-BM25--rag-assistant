[site]: crossvalidated
[post_id]: 274752
[parent_id]: 274706
[tags]: 
I'm really not familiar with the equations you wrote down, but I know my backpropagation :) It's as simple as this (in my eyes): a neuron computes its input by taking all its incoming connections and multiplying the weight of the incoming connection with the activation from the source of the connection. Regardless of where the connection is coming from!! I most implementations of neural networks in programming languages, a neuron has an array of all outgoing and incoming connections. The neuron does not know where the connection is coming from , it only knows the source activation and the connection weight. Additionally, think of the following: an activation of a neuron is anywhere between the value of 0 and 1 for most programming languages. But when we perform this equation: $$ h_t = tanh( W_{hx} x_t +b_x) + tanh( W_{hh} h_{t-1} + b_h ) $$ We will get a value between 0 and 2 . Why would we want that?
