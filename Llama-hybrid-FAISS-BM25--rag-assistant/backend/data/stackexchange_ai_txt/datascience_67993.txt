[site]: datascience
[post_id]: 67993
[parent_id]: 
[tags]: 
Post-classification after inference in deep learning models

I designed a fire detection using Deep Learning binary classification in Keras ( fire vs none ). It's a simple model with a few layers. In my training dataset, I included both fire and smoke, and they are both detected (all under "fire"; mostly real fires are detected though. Smoke is less accurate). Now I need to differentiate these two in my detection results. So basically it would be 3 classes ( fire, smoke, none ). One solution that came into my mind was building a binary classification model and pipeline it after the main one. So it gets the main detections as input and prints which of the two classes it belongs to. Is there any other approaches? What are pros/cons of various approaches? Here is my simple architecture: def create_model(): model = Sequential() model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(300, 300, 3))) model.add(MaxPooling2D(pool_size=(2,2))) model.add(BatchNormalization()) model.add(Conv2D(64, kernel_size=(3,3), activation='relu')) model.add(MaxPooling2D(pool_size=(2,2))) model.add(BatchNormalization()) model.add(Conv2D(128, kernel_size=(3,3), activation='relu')) model.add(MaxPooling2D(pool_size=(2,2))) model.add(BatchNormalization()) model.add(Conv2D(128, kernel_size=(3,3), activation='relu')) model.add(MaxPooling2D(pool_size=(2,2))) model.add(BatchNormalization()) model.add(Conv2D(64, kernel_size=(3,3), activation='relu')) model.add(MaxPooling2D(pool_size=(2,2))) model.add(BatchNormalization()) model.add(Dropout(0.2)) model.add(Flatten()) model.add(Dense(256, activation='relu')) model.add(Dropout(0.2)) model.add(Dense(64, activation='relu')) model.add(Dense(2, activation = 'softmax')) return model #.... if retrain_from_prior_model == False: model = create_model() model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) else: model = load_model("checkpoints/model.h5")
