[site]: crossvalidated
[post_id]: 408456
[parent_id]: 408064
[tags]: 
When dealing with classification, the most intuitive metric to evaluate a model's perfomance is the accuracy, because it tells how many registers have been classified correctly: the higher, the better. However, as you have noticed, accuracy is not a good measure of the model's performance when dealing with an imbalanced dataset. Imagine that the minority class is the 1% of the total dataset... if your model predicted every register as the majority class, you would get a very high accuracy. It's preferable in cases such us yours to maximize other metrics rather than accuracy. ROC's AUC (Area Under de ROC Curve) can give you a better idea about how is the model predicting correctly both the positive and the negative class. Moreover, this metric is independent of the classification threshold, in contrast with sensitivity (also known as recall) or especificity. However, if you are specially interested in the performance of the possitive class rather than the negative one, it's recommnended to maximize the F1 Score, the harmonic averagte of precision and recall. You can read more about all this terms in this article . Good luck!
