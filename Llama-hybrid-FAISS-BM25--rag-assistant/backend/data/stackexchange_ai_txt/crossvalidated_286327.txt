[site]: crossvalidated
[post_id]: 286327
[parent_id]: 
[tags]: 
Machine learning/Deep learning to solve inverse tomographic problem

The typical simplifiled representation of a tomographic system is $y = Ax$, where $y$ is the collected data (sinogram in CT), $A$ is the projection matrix, and $x$ is the unknown image. The closed form solution, which is probably the most popular one, is to applying FBP algorithm to get the direct inverse of this model. In other words, $x$ can be solved directly from $y$ using FBP algorithm. The reason why we don't do $x = A^*y$ is that the the $A^*$ is too large to be computationally possible on a computer. Therefore, FBP is the way to go. Now I am wondering is there a way to do this reconstruction using machine learning/deep learning? I am not an expert on machine learning topic, but I will present the problem using a simple example. Basically, what I like is to have an image $x$ when a sinogram $y$ is given. Suppose I have an image (this is my $x$, or output in this case) of size $128 \times 128$. I can generate its sinogram (this is my $y$, or input data in this case) by simulating the physical process (Radon transform). The size of the sinogram should be $128 \times 360$. Which means the beam cast 128 rays across all 360 degrees. I can generate the sinogram for arbitrary images using my simulator. So I should have a lot of training data. I imaging between the input $x$ and its output $y$, there is black box in between inside which there are a lot of neurons, weights, bias structured within layers. Now I am wondering how to construct such a neural networks (ex. how many layers? how many weights for each layer?)? and how to train the weights and bias such that when I have a sinogram $y$, it can solve for the image $x$. If there is a paper talking about this, I'd like to read it. I hope the paper is simple, and an easy tutorial. I am really a beginner on this topic.
