[site]: crossvalidated
[post_id]: 420699
[parent_id]: 
[tags]: 
Transition for scikit learn to xgboost: Where can I find a comprehensive documentation for xgboost? (Python)

As the internet seems to be conviced that xgboost is well worth a shot when working with decision trees anyways, I set out to try it. I deal with a binary classification problem. Up to now, I was working with the scikit learn library and I always refered to the respective documentation; e.g. gradient boosting . It tells me which input parameters I can use and which methods I can apply. Is there something comprehensive like this available for xgboost as well? I found which input parameters I can use, but not which methods can be applied. What I've tired (and what worked surprisingly well) was simply using the methods I was using with the scikit learn gradient boosting classifier: import xgboost as xgb from sklearn.model_selection import train_test_split X = my_data y = my_data_target X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) xgbm = xgb.XGBClassifier().fit(X_train, y_train) xgbm_accTrain = xgbm.score(X_train, y_train) xgbm_acc = xgbm.score(X_test, y_test) xgbm_pred = xgbm.predict(X_test) xgbm_predProb = xgbm.predict_proba(X_test)[:,1] i = ["Gradient Boost", xgbm_accTrain, xgbm_acc, xgbm_pred, xgbm_predProb] av_pres = average_precision_score(y_test, i[4]) #calculated before as it will be needed more often print( "{: Can I do this? The results seem reasonable, but I want to be sure. One more thing: Several xgboost tutorials use a DMatrix (This iris classification , for instance). Why? I mean, it worked for me without it. Thanks a lot for your help!
