[site]: crossvalidated
[post_id]: 559150
[parent_id]: 559149
[tags]: 
What I think is a good solution so far, Improving the Prediction of Asset Returns With Machine Learning by Using a Custom Loss Function Dr. Dessain had the same question and answered in his paper. "Dessain (2021) offers arguably the most comprehensive overview to date, with 190 articles reviewed over the period 2010 â€“ June 2021, but with a narrow focus on the sole performance metrics used to compare algorithms predicting asset returns. He demonstrates that the mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE) or similar error-based performance metrics are not appropriate for assessing the results of algorithms predicting asset returns. The underlying reasoning is that error-based metrics treat all errors equally and do not differentiate an error that triggers a bad investment decision (an investment resulting in a negative return or a missed opportunity with no investment when the asset has led to a positive return) from a prediction error which does not have any adverse consequence, leading to a positive return or to a non-investment that avoided a negative return. The deductive reasoning is confirmed with an extensive empirical analysis." his custom loss functions aim to give more penalty on loss than profit. As you have expected, asymmetric design of the loss function is the key. Here is the code for custom loss functions please note that asymmetric designs has inherit limits. Models will learns to be 'safe.' In other words, yhat will be lower. This could make taking positions almost impossible since the real price(y) will be always higher. please note that in order to use AdjMSELoss2, you must adjust 10000 to be higher or lower. Most of the time it should be lowered since if (10000 * outputs * labels) is too big, mean(loss) becomes too low or nan. Then, model cannot be learned. def __init__(self): super(AdjMSELoss2, self).__init__() def forward(self, outputs, labels): outputs = torch.squeeze(outputs) beta = 2.5 loss = (outputs - labels)**2 adj_loss = beta - (beta - 0.5) / (1 + torch.exp(10000 * torch.mul(outputs, labels))) loss = beta * loss /(1+adj_loss) return torch.mean(loss)``` He also posted a performance metric, which has many advantages over other ratios like sharpe ratio. D-ratio "solely focuses on the added value of the algorithm." If you want to know more about D-ratio, please go check out his another paper, Machine learning models predicting returns: why most popular performance metrics are misleading and proposal for an efficient metric . I highly recommend it. He also posted code for D-ratio on his github What I think is the best solution in reality. only use deep learning to represent the environment use reinforcement learning to help a human trader. In other words, Machine Learning should not be used in actual trading, but only to help traders. Good use of machine learning could be calculating hedging, option price, and order executions. Any other paper or solution to the loss function? Please leave in the comments or answers.
