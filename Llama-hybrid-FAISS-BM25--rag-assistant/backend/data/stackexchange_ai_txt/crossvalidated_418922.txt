[site]: crossvalidated
[post_id]: 418922
[parent_id]: 417998
[tags]: 
The key distinction in my view between SEM as psychologists use the term and structural estimation/modeling as economists use the term is economists' focus on specifying a full economic model, solving for its equilibrium, and using restrictions implied by the equilibrium to estimate the parameters. (FWIW, my impression is that modern practice is somewhat different from Cowles Commission-style econometrics done in the 1940s-60s.) In economics, structural estimation often refers to estimating the "deep" (i.e. structural) parameters of an economic model — things like elasticities, risk aversion, the distribution of value that bidders in an auction place on the good, etc. In practice, this often takes the form of postulating some model in which agents optimize (e.g. a game theoretic or microeconomic model) and solving for the equilibrium. The assumption is that the observed data are equilibrium outcomes of the model. The equilibrium conditions often imply restrictions on the data that can yield estimators for the parameters of the model using (for example) generalized method of moments or maximum likelihood estimation. For an example, in urban and regional economics, many papers employ the Rosen-Roback spatial equilibrium framework. These models assume that each city/region has its own labor and housing markets, and that perfectly mobile workers decide where to live in order to maximize their utility. The model specifies labor supply and demand curves, which might depend on features of the city like amenities, and housing supply and demand curves. The equilibrium condition implies that utility across all cities must be equalized. If people could obtain a higher utility by moving, they'd move to the city in which they get higher utility. But by moving, they'd drive wages down (through increased labor supply) and housing prices up (through increased demand for housing). This process would continue until utility across regions is equalized. This equilibrium condition implies a set of restrictions on the data that can yield an estimator of the parameters of the model. E.g., if we specify utility that people can obtain in city $c$ as $U_{c} = f(Z_{c})+ \epsilon_{c}$ , in equilibrium we have a set of moment conditions $U_{c} = U_{c'} = \bar{v}$ for all $c, c'$ and some (arbitrary) constant $\bar{v}$ . These moment conditions can be used to estimate parameters of $f$ . In political science, structural models are much less common, but one place they do show up is in ideal point estimation. The idea is that we want to infer a political actor's ideology based on observable behavior such as roll-call votes or campaign donations. We then specify a model relating unobserved parameters of the decision problem (e.g. the utility the legislator with a given ideal point would get from passing a bill vs. the utility she gets from the status quo) to observable behavior (e.g. whether the member of Congress voted for or against the bill). Given some parametric assumptions about idiosyncratic error terms in the actor's utility function, we can derive a likelihood for the (unobservable) ideal points. This problem turns out to be nearly identical to the psychometrics problem of inferring "ability" through educational tests, and is often viewed as an Item Response Theory model. I am much less familiar with the psychology literature on SEM, but my impressions of it are similar to yours — a focus on measurement (as in the IRT models) and latent variable modeling. Caveat: I am a political scientist, not an economist.
