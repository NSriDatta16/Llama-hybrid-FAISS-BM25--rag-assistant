[site]: crossvalidated
[post_id]: 241545
[parent_id]: 241537
[tags]: 
Your first sentence seems to indicate that you conflate the model (in your case Random Forests ) with a means of validating its performance on a given dataset (e.g. k-fold cross-validation ). You should look at that, since for example choosing a different k in k-fold cross-validation might make sense depending on the data (see here ). To answer your question, not re-learning the model when new data arrives can lead to problems if the original dataset was too small to learn your model well in the first place (an indication for this is if your cross-validation error on the original dataset is high) the new data is qualitatively different from the original dataset. Was the data sampled in the same way or do you expect any bias in the new data? The only case where I can imagine that not re-learning would make sense if you can exclude the two points above and re-learning has a high cost in time or money. If the cost is low I would re-learn anyway, just to be sure.
