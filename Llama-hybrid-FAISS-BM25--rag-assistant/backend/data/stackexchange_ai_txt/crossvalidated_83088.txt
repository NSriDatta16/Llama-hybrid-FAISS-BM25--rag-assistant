[site]: crossvalidated
[post_id]: 83088
[parent_id]: 83066
[tags]: 
Power-Law distributions (e.g. Zipf's) are supposedly good for modeling certain frequencies of data that follow a descending frequency of occurrence, such as phonemes within a speech or text. The numerical value assigned to certain categories is the order statistic for the frequency in which a certain category occurs, for instance, participles in the English language "a", "the", "an" are usually the first class of words in such a model. A general graphical tool for measuring distributional assumptions is that of a QQ plot. If exactly one category has 0 frequencies, then your model can infer what the expected frequency might have been for that variable in resamples of the data based on the estimated power rule. If more than one such category has 0 frequencies, then it's impossible to estimate those values (so cluster them into an "unobserved" category). Otherwise, direct maximum likelihood will be impossible due to ties. There are advanced methods, however, of estimating statistics derived from order statistics using MCMC methods. In the case of maximum likelihood estimation, it boils down to the EM algorithm. With many ties in a frequency distribution, it is impossible to rank them. One can, however, permute rank assignment over all possible orders in those ties, and take the "expectation" to come up with an estimate of the power law. A similar method is used in Cox models to handle ties, called the Breslow method or the Efron method for ties.
