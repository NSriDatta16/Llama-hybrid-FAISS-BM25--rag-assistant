[site]: crossvalidated
[post_id]: 410275
[parent_id]: 
[tags]: 
Is it interesting to do several updates using the same batch in Stochastic Gradient Descent

I am working on a reinforcement learning problem. I was given a code where people used to train their neural-network as a Q-function estimator. During the training process, they sample $m$ (m small) examples from the memory which contains millions of experiences. The model is then trained on 10 epochs on this batch before getting other examples. I see this approach as a Stochastic Gradient Descent (SGD) with mini-batch and where a batch is used 10 times to train the network before using the next one. The idea is that by doing so the gradient descent will keep the same direction before moving to another batch of data. Is that a relevant approach ? I understand that the classical SGD aims at accelerating the learning process by making the network update more often than with just a gradient descent. I think that the classical approach of mini-batch with stochastic gradient descent is the most relevant for training a model, but those this second approach makes sens ? I didn't see anything about this topic during my research. Thank you.
