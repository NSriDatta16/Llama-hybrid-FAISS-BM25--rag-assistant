[site]: crossvalidated
[post_id]: 185367
[parent_id]: 
[tags]: 
How to optimize the choice of cointegration coefficient?

Testing for cointegration on the linear combination of time series vectors can be done by testing the error term for a unit root. $$Y_t - \gamma X_t = \varepsilon_t$$ In the bivariate case the choice of $\gamma$, the cointegration coefficient, is usually $\hat{\beta}$ as derived from OLS. However, I noticed that other values for $\gamma$ may produce a series that will test at a higher likelihood of cointegration; i.e., it is possible that choosing $\gamma \neq \hat{\beta} $ minimizes the cointegration test statistic. Question: Can anyone explain why a choice of $\gamma$ that is not derived from OLS in the usual sense may produce a series with a higher likelihood of cointegration? I find this peculiar, and am curious if it is common practice to seek such a value.
