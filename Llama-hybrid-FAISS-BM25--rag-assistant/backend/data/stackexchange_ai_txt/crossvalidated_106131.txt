[site]: crossvalidated
[post_id]: 106131
[parent_id]: 
[tags]: 
Estimate average percentage error based on another gaussian measurement

I have a model where the error is proportional to the throughput. This is, the observations I got come from a measurement instrument that has some error and it measures material going through in little buckets. I am approximating the model as follows $$ x_i = x~(1 + \epsilon_X) \\ \epsilon_X \sim N(\mu_X,\sigma_X) $$ I am also able to determine via another instrument, the total material before and after, so I am able to state (after simplifying) $$ \delta_i = \delta + \epsilon_D' \approx x_i \\ \epsilon_D' = \epsilon_D^1 - \epsilon_D^2 \\ \epsilon_D^{\{1,2\}} \sim N(\mu_D, \sigma_D) $$ The mean $\mu_D$ does not matter, as it cancels out in $\epsilon_D'$, but the mean $\epsilon_X$, if not zero, is what I am after . Things get complicated because the variance of $x_i$ depends on the actual throughput, so it seems I have heteroscedasticity in the model. Put other way, $\epsilon_X$ is given as a random percentage of the measured quantity. So, I have a number of $\delta_i$ readings, with random noise; and another set of $x_i$ readings with noise as above; they should match, but they don't due to noise. Actually, I am interested in the problem of finding out if the noise in $x_i$ is not zero-mean. Any pointers would be appreciated. Update For what is worth, in addition to Alecos' answer, I tried also what seanv507 suggested: by averaging $(1/n)\sum_{i=1}^n(Ln(x_i)-Ln(\delta_i))$, and then reverting with $Exp(.)$. It is very close to the ratio model (as said $1+x \approx e^x$ for small x ) with the additional advantage that $x_i$ is is never negative under this model (if this is what one wants).
