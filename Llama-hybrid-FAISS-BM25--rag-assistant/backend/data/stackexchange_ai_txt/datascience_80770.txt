[site]: datascience
[post_id]: 80770
[parent_id]: 
[tags]: 
I do feature engineering on the full dataset, is this wrong?

I am aiming to predict the number of days it takes to sell a given property, let's call this variable "DaysForSale" - in short DfS Using the DfS I created a variable called "median_dfs_grouped_street_name" which returns the median days it takes to sell a property for the different streets available in the dataset. (The street names are all categorized). After this, I do my train/test split and run my Random Forest method. Using the feature_imporatances function I see that the new feature is the second most important, which makes me wonder if this is the correct approach? I have two questions: Is it wrong to develop features using the target variable? Is it wrong to do feature engineering on the full dataset?
