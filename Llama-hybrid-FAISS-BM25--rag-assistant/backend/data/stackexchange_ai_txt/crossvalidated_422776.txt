[site]: crossvalidated
[post_id]: 422776
[parent_id]: 422769
[tags]: 
Linear Regression are already highly interpretable models. I recommend you to read the respective chapter in the Book: Interpretable Machine Learning (avaiable here ). In addition you could use a model-agnostic approach like the permutation feature importance (see chapter 5.5 in the IML Book). The idea was original introduced by Leo Breiman (2001) for random forest, but can be modified to work with any machine learning model. The steps for the importance would be: You estimate the original model error. For every predictor j (1 .. p) you do: Permute the values of the predictor j, leave the rest of the dataset as it is Estimate the error of the model with the permuted data Calculate the difference between the error of the original (baseline) model and the permuted model Sort the resulting difference score in descending number Permutation feature importancen is avaiable in several R packages like: IML DALEX VIP
