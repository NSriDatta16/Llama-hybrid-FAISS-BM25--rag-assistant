[site]: crossvalidated
[post_id]: 574457
[parent_id]: 
[tags]: 
Bayesian updates for Dirichlet-multinomial with Gamma prior

Let $$ \begin{aligned} X_i &\sim \text{Dir-multinom}(X\mid\lambda)\\ \lambda_{j} &\sim \text{Gamma}(\lambda_j\mid\alpha,\beta)\\ \end{aligned} $$ where $i$ iterates over observations, $j$ iterates over categories. I'm trying to perform inference on $\lambda$ . My thought was to calculate the latent $\pi$ , such that the model becomes: $$ \begin{aligned} X_i &\sim \text{Multinomial}(X_i\mid\pi_i)\\ \pi_i &\sim \text{Dirichlet}(\pi\mid\lambda)\\ \lambda_j &\sim \text{Gamma}(\lambda_j\mid\alpha,\beta) \end{aligned} $$ Then posterior updating for $\pi$ in the Gibbs sampler becomes: $$ \pi_i \mid X_i, \lambda \sim \text{Dirichlet}(\pi_i\mid \lambda + X_i) $$ Which is frequently sampled as $$ \rho_{ij}\mid X_{ij}, \lambda_j \sim \text{Gamma}(\rho_{ij}\mid \lambda_{j} + X_{ij}, 1) $$ then Gamma $\rho_i$ is reduced to Dirichlet $\pi_i$ by projecting onto the simplex (divide by the sum). With these $\rho_i$ 's, I should be able to produce estimates for $\lambda$ as owing to the second model formulation, the full conditional for $\lambda$ is proportional to $$ f(\lambda_j\mid\rho) \propto \prod_{i = 1}^{n}\text{Gamma}(\rho_{ij}\mid\lambda_j, 1)\times \text{Gamma}(\lambda_j\mid\alpha,\beta) $$ then sampling $\lambda$ using Metropolis Hastings. However, when I implement this sampler, my estimates for $\lambda$ and subsequently $\rho$ just grow larger the longer I run the sampler. I suppose I should mention that I can use the first model formulation; updating is slower as it can't be done marginally. Is there any valid reason the second model can not be implemented? I have reason for wanting the latent $\pi$ 's/ $\rho$ 's.
