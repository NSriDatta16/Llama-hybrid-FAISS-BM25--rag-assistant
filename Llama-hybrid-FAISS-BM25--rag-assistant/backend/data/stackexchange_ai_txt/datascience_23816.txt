[site]: datascience
[post_id]: 23816
[parent_id]: 12830
[tags]: 
The equivalent kernel simply has whatever shape the input has, and computes a tensor dot product. (I use the word "shape" as there seems to be some confusion over "size", which often ignores the channel/depth dimension). There's no "sliding the kernel across input" involved, since the kernel is as large as it can be. Quoting Stanford CS 231n course notes : any FC layer can be converted to a CONV layer. For example, an FC layer with K=4096 that is looking at some input volume of size 7×7×512 can be equivalently expressed as a CONV layer with F=7,P=0,S=1,K=4096,F=7,P=0,S=1,K=4096. In other words, we are setting the filter size to be exactly the size of the input volume, and hence the output will simply be 1×1×4096 since only a single depth column “fits” across the input volume, giving identical result as the initial FC layer. I believe "F=7,P=0,S=1,K=4096,F=7,P=0,S=1,K=4096" here means each conv kernel has shape 7x7x512, and there's 4096 such filters. The earlier answer mentioned that the last fc of AlexNet (which receives input with shape 1x1x4096 and computes 1000 class scores) is implemented as "1x1 convolution". To be complete, each such conv kernel has shape 1x1x4096, and there's 1000 of them. Le Cunn also explains this in the CNN paper , page 8, description of LeNet5: Layer C5 is a convolutional layer with 120 feature maps. Each unit is connected to a 5x5 neighborhood on all 16 of S4's feature maps. Here because the size of S4 is also 5x5, the size of C5's feature maps is 1x1; this amounts to a full connection between S4 and C5.
