[site]: datascience
[post_id]: 17391
[parent_id]: 
[tags]: 
Tensorflow speech-to-text training on single file with tf.nn.ctc_loss not converging

I want to train speech-to-text model on tensorflow. Code at: https://github.com/bikramjitroy/speech-to-text/blob/master/TrainingUnitTest-CTCTrain.py A sample "audio.wav" and "label.txt" file also present in repo. https://github.com/bikramjitroy/speech-to-text I am loading a wav file. Getting 20 mfcc feature per frame. Passing input to one layer RNN (256 hidden unit) and then added a fully connected layer and then using ctc_loss . The accuracy is not increasing even with 500 steps with one training example : Error = 70.932137 # Expecting it should go near zero Accuracy = 0.62068963 # expecting this will go to zero I have tried bi-directional rnn as well but that is diverging. What am I doing wrong in code?
