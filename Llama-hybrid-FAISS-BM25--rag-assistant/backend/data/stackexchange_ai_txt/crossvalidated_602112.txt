[site]: crossvalidated
[post_id]: 602112
[parent_id]: 601921
[tags]: 
Let me offer a (long) intuitive explanation without entering into measure-theoretic arguments. The main problem is thus how to make sense of the conditional probability $P(Y = y| V=x)$ when $V$ is an (absolutely) continuous random variable and for which $P(V=x)=0$ . First of all, rest assured that such a probability exists and makes sense. Here is a practical example. Example. Suppose that a real number $V$ is selected at random, with density $f$ . If $V$ takes value $x$ , a coin with probability $g(x)$ is tossed $(0 \leq g(x) \leq 1)$ . It is thus natural to assert that the conditional probability of obtaining a head, given $V=x$ , is $g(x)$ . But $V$ is absolutely continuous, so $\{ V=x \}$ has probability 0, thus the conditional probabilities do exist but they need to be defined. In the explanation below I'll use this example to make my argument more concrete. An intuitive but less rigorous way to define the overall probability of obtaining a head is by the following infinitesimal argument. The probability that $V$ will fall into the interval $(x,x+dx]$ is approximately $f(x)dx$ . Given that $V$ falls into this interval, the probability of a head is roughly $g(x)$ . So from the law of total probability, we expect that the probability of a head will be $\sum_x g(x) f(x) dx$ , which approximates $\int_{-\infty}^{\infty}g(x)f(x)dx$ . Thus the probability in question is nothing but a weighted average of conditional probabilities, the weights being assigned in accordance with the density $f$ . Now let's look a bit more closely at what's happening here. We have two random variables $Y$ and $V$ [ $Y=y$ , $V$ = (say) the number of heads obtained]. We are specifying the density of $V$ and for each $x$ and each Borel set $B$ , we are specifying a quantity $P_x(B)$ that is to be interpreted intuitively as the conditional probability that $V\in B$ given that $Y=x$ ; a longer notation is $P_x(B) = P\{V\in B | Y = x\}$ . We are trying to conclude that the probabilities of tall events involving $Y$ and $V$ are now determined. Suppose that $C$ is a two-dimensional Borel set. What is a reasonable figure for $P\{(Y, V)\in C\}$ ? Intuitively, the probability that $Y$ falls into $(x,x+dx]$ is $f_Y(x)dx$ . Given that this happens, that is, roughly given $Y=x$ , the only way $(Y,V)$ can lie in $C$ is if $Y$ belongs to the "section" $C_x = \{y: (x,y)\in C\}$ (as in the left figure). But this happens with probability $P_x(C_x)$ . Thus we expect that the total probability that $(Y,V)$ will belong to $C$ is $$ \int_{-\infty}^{\infty} P_x(C_x)f_Y(x)dx. $$ In particular, if $C = A\times B = \{(x,y): x\in A, y\in B\}$ as in the Figure on the right, $C_x = \emptyset$ if $x\not \in A$ , $C_x = B$ if $x\in A$ . Thus $$ P\{(Y,V)\in C\} = P(Y\in A, V \in B) = \int_A P_x(B)f_Y(x)dx. $$ Now this reasoning may be formalized by letting the sample space be $\Omega = \mathbb{R}^2$ , the Borel subsets be $\mathcal{F}$ $Y(x,v) = y$ , $V(x,v) = v$ and letting $f_Y$ be the density function on $\mathbb{R}$ . Suppose that for each real $x$ we are given a probability measure $P_x$ on Borel subsets of $\mathbb{R}$ and assume also that $P_x(B)$ is a piecewise continuous function of $x$ , for each fixed $B$ . Then it turns out that there is a unique probability measure $P$ on $\mathcal F$ such that for all Borel subsets $A, B$ of $\mathbb{R}$ $$ P(A\times B) = \int_A P_x(B) f_Y(x)dx.\tag{*} $$ The requirement (*), which can be regarded as a continuous version of the law of total probability, determines $P$ uniquely. In fact, if $C\in \mathcal{F}$ , $P(C)$ is given by $$ P(C) = \int_{-\infty}^{\infty} P_x(C_x)f_Y(x)dx.\tag{**} $$ Now if $Y(x,y) = x, V(x,y) = y$ , then $$ P(A\times B) = P(Y\in A, V\in B) $$ and $$P(C) = P\{(Y,V)\in C\}.$$ Furthermore, the distribution function of $Y$ is given by $$ F_Y(x_0) = P(Y\leq x_0) = P\{X \in A, V \in B\} = \int_{A}P_x(B)f_Y(x)dx = \int_{-\infty}^{x_0} f_Y(x)dx, $$ where $A = (-\infty, x_0]$ and $B = (-\infty, \infty)$ . Furthermore, $$ P(V \in B) = P\{Y\in A, V\in B\} $$ where $A = (-\infty, \infty)$ , hence $$ P(Y\in B) = \int_{\infty}^{\infty} P_x(B)f_Y(x)dx. $$ So to summarize: If we start out with a density for $Y$ and a set of probabilities $P_x(B)$ that we interpret as $P(Y\in B| V=x)$ , the probabilities of events of the form $\{(Y, V)\in C\}$ are determined in a natural way if you believe that there should be a continuous version of the law of total probability; $P\{(Y, V)\in C\}$ is given by (**), which reduces to (*), in the special case when $C = A\times B$ . Example (Cont'd). If $Y$ has density $f_Y$ , and a coin with probability of heads $g(x)$ is tossed whenever $Y = x$ (suppose a head corresponds to $V=1$ ), then the probability of obtaining a head is $$ P(V = 1) = \int_{-\infty}^{\infty} P(V=1 | Y=x) f_Y(x)dx = \int_{-\infty}^{\infty} g(x) f_Y(x)dx, $$ in agreement with the previous intuitive argument.
