[site]: crossvalidated
[post_id]: 547828
[parent_id]: 
[tags]: 
PCA whitening and centering in inference/test samples

[cross-posted from SO] I'm working on speaker identification. I need to take the speaker embeddings from a neural network and apply a few transformations to finally generate the score for verification. I get the following data from the neural net, X_embeddings with shape (14290, 512) y_embeddings with shape (14290,) Here, there are 14290 samples, 512 unit embedding vectors. Now, I want to apply zero-centering, and PCA whitening on the data, then finally train an LDA model on the data. from sklearn.preprocessing import StandardScaler from sklearn.decomposition import PCA # centering, unit variance scaler = StandardScaler() # zero mean (feature-wise), unit-var scaler.fit(X_enrollment) X_enrollment = scaler.transform(X_enrollment) # whitening pca = PCA(whiten = True) # X_enrollment already unit variance pca.fit(X_enrollment) X_enrollment = pca.transform(X_enrollment) Now, the test samples come from a much larger size and randomly. So, I have to process the test samples online. Should I directly apply the transform from the scaler and pca to the test samples (each with shape (1, 512) )? Or, is there a better approach to handle the test pre-processing?
