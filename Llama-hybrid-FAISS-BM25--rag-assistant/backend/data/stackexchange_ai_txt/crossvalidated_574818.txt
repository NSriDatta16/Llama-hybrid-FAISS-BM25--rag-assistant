[site]: crossvalidated
[post_id]: 574818
[parent_id]: 
[tags]: 
Fitting of moving average process

I have been trying to wrap my head about the parameters estimation and forecasting of moving average model. It appears that the fitting use the innovations algorithm. If I understood correctly you assume your optimal linear predictor has the form $\hat{X}_{n+1} = \sum_{j=1}^{n} \theta_{n,j} (X_{n+1-j} - \hat{X}_{n+1-j}) $ with $\hat{X}_1 = 0$ One then estimate these parameters iteratively using the innovations algorithm: $$\theta_{n,j} = [\gamma(j)-\sum_{k=1}^{n-j} \theta_{n-j,k} \theta_{n,j+k} v_{n-j-k}] / v_{n-j}$$ $$v_n = \gamma(0)-\sum_{j=1}^n \theta_{n,j}^2 v_{n-j}$$ with $$v_0 = \gamma(0)$$ . Okay, now let's consider a MA(1) process : $$X_n = Z_n + \theta Z_{n-1}$$ with $Z_n \sim \mathcal{N}(0,\sigma^2)$ . We can compute the autocorrelation function of this process : $$\gamma(0) = (1+\theta^2) \cdot \sigma^2$$ $$\gamma(1) = \theta \cdot \sigma^2$$ Now, if we apply the first iteration of the innovations algorithm, we'll find: $$\theta_{1,1} = \gamma(1) / \gamma(0)$$ $$v_1 = \gamma(0) - \frac{\gamma(1)^2}{\gamma(0)}$$ What's making me crazy is that obviously $\theta_{1,1} \neq \theta$ and $v_1 \neq \sigma^2$ . Yet, it seems that we could very well infer the parameter $\theta$ and $\sigma$ by solving for them in the autocorrelation functions. My question is then the following : why don't we solve the autocorrelation equations to estimate the parameters of the model and then use this to compute the innovations ? It seems we are using $\gamma$ 's already, so why not directly infering our best estimate of $\theta$ ? Thank you so much for your help !
