[site]: crossvalidated
[post_id]: 401739
[parent_id]: 401703
[tags]: 
This boils down to using links besides the canonical link for a non-Gaussian family. As the course notes say: The choice of link is separate from the choice of random component thus we have more flexibility in modeling You are not wrong to be confused by this, because nowhere in the introduction is one of these non-canonical links used. In the case of logistic regression, this means that we would not model the log odds , but rather have something called a linear probability model . This all would be a lot less confusing if we were to call it bernoulli regression , to emphasize the distribution of the response, conditional on $x$ , rather than the connection between the linear predictor: $\eta = \beta_0 + \beta_1 x_i$ and the expected value of the response, $E(Y | \eta)$ . If we used a linear probability model we would have these three conditions hold: $$ \begin{align*} \eta & = \beta_0 + \beta_1 x, \\ E(Y|\eta) &= \eta, \\ \text{Var}(Y|\eta) & = E(Y|\eta)(1 - E(Y|\eta)). \end{align*} $$ The first equation holds for all generalized linear models. If we had the logit link, the second equation would read $\text{logit} \; E(Y|\eta) = \eta$ but the identity link means we don't put anything special here. (Some other non-canonical links include the log link and the complimentary log-log.) The third equation holds because we have the Bernoulli (aka binomial with 1 trial) family, and in this distribution the variance is always an inverted quadratic function of the mean. The notes are pointing out that line 2 can occur with just about any family, which would also be true with ordinary least squares, but we can still have something special happening with the conditional variance of $Y$ .
