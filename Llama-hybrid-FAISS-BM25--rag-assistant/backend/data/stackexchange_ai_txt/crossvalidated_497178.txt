[site]: crossvalidated
[post_id]: 497178
[parent_id]: 
[tags]: 
What does it tell you when PCA cannot reduce the dimensionality of your dataset

I'm new to PCA and I'm trying to apply it to a dataset I have with 15 different features. I normalized my dataset before applying PCA and used the PCA method in the decomposition function from sklearn. I was hoping that a few PCAs (probably less than 10) would be able to explain 90% of the variance of the data matrix. But the cumulative variance I got is [0.21 0.323 0.413 0.486 0.555 0.619 0.681 0.74 0.794 0.844 0.89 0.922 0.953 0.981 0.9998] which means that I need at least 12 PCs to explain 90% of the variance and 15 PCs to explain 100%. So it seems like PCA does not reduce the dimensionality of my dataset. Does it mean that the 15 features I have are not redundant? like there is no redundancy in my dataset and it's better not to eliminate any of the 15 features I currently have? Below is my features correlation heatmap.
