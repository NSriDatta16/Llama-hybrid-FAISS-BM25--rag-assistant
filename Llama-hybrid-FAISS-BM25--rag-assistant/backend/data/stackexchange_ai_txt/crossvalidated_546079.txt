[site]: crossvalidated
[post_id]: 546079
[parent_id]: 546060
[tags]: 
No, this procedure isn't fair because you're essentially fitting your $k$ (number of principal components) to the test set. This results in information leakage from the test set and therefore means you'll get a biased estimate of how well your model will generalise to unseen data. You should think of $k$ as another hyperparameter that you're tuning, so you should use the validation set for this purpose. I guess the key is to realise that you're basically tuning a pipeline ( $k$ + logistic regression hyperparameters), so use the validation set to tune it and then use the test set to get an idea of how well your best model will generalise.
