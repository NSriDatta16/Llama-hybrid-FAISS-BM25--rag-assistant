[site]: crossvalidated
[post_id]: 403854
[parent_id]: 403829
[tags]: 
The usual goal in regression is to include all relevant predictors in the model. Omitting important predictors correlated with included predictors can lead to reversed signs of regression coefficients in standard linear regression (see Simpson's paradox ). In logistic or Cox survival regressions, omitting a predictor related to outcome will even bias the coefficients of predictors with which it is not correlated. So starting with separate models for each of x and z is not a good way to proceed. Multicollinearity (perhaps an over-statement in this case with only 2 predictors) gets a lot of attention but doesn't by itself necessarily lead to problems unless it's so extreme that you can't get reliable estimates of the coefficients. As this answer notes: ... the effects of collinearity are seen in the variances of the parameter estimates, not in the parameter estimates themselves. The VIF, after all, is the Variance Inflation Factor for a coefficient. What you are seeing is what you would expect if x and z are correlated with each other and if one or both are directly related to y . Then each of x and z could be significantly related to y individually (based on some p -value cutoff), but including both in a 2-predictor regression could lead to 1 of them appearing to be "not significant." It's quite possible in your 2-predictor model that x is still related to y in the same direction as it was individually, but that a high standard error for its regression coefficient (due to its correlation with z ) made it fail to meet some p -value cutoff. If your intent is prediction of y in new cases based on values of x and z , then there is no reason to omit either of x or z . In such a situation it's best to try to retain all variables related to outcome, even those that don't pass some particular test of statistical significance. Variable selection based on p -values or other relations to outcome " only makes things worse ." You do have to take precautions against overfitting or use other modeling approaches when the ratio of cases to predictors gets low, but with only 2 predictors that shouldn't be a problem provided you have more than a couple of dozen cases.
