[site]: crossvalidated
[post_id]: 574507
[parent_id]: 
[tags]: 
Difference between geometric distribution expectation and 1 - failure with Binomial

I'm trying to understand a simple problem: How many times you'd need to roll two dice to get two ones in a single roll. One way I see this is as a problem the geometric distribution describes. You want to know the expected value of the distribution: the mean number of trials until success. This is $1\over p$ , or $36$ . However, it occurred to me we can think of it another way: As the number of Bernoulli trials until there's at least a 50% chance none of the trials is double-heads. We can describe this as: $1 - (35/36)^n = 0.5$ , or $0.5 = (35/36)^n$ or $log_{0.972}^{0.5} ~= 24.4$ trials. I'm trying to understand whether it's correct to calculate one way or the other. If I run the second way as a simulation, I see a very long tail, which I assume is why the mean is right-shifted. bins Is the correct intuition that the second method finds the $median$ because it's finding the point where the cumulative probability, $\Phi = 0.5$ . The probability associated with any particular roll would be $(1 - (35/36)^{n+1}) - (1 - (35/36)^n)$ The expected value found by the geometric distribution simply integrates over the outcome space to average the associated probabilities with the number of trials. Is the correct answer then that it depends what you want? If you want the most likely number of trials, then the answer is 24. If you want the average over all possible outcomes, then the expected value is 36.
