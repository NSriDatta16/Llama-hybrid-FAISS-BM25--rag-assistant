[site]: datascience
[post_id]: 71677
[parent_id]: 71659
[tags]: 
Yes thats possible, but you need some kind of adaption. Normally you would use transfer learning to teach your model, that there are more things to detect with the features it already can extract. For that you normally take your model, and just delete the last dense layer, which is for classification. Then you freeze all earlier layers of the CNN and setup a new Dense-layer on the end with the number of classes you want to detect. Giving the network now new examples with ground truth (not that many normally) to adapt onto the new domain. This can work, but also defenitely fail. For example i tried using ResNet-backbones (51,101) trained on ImageNet (a big dataset to find humans, cars and stuff) and tried to use it on microscopy cell segmentation and classification. Yeah it found some boundarys, but couldnt get a precise classification at all. To sum it up: yes you can transfer learn, or use tasks of the field of "UDA" -> Unsupervised domain adaption, or normal Supervised / semi-supervised domain adaption to teach models new things. Or just to strengthen their knowledge. Detecting things without having seem them ever before is also an updcoming task and is called " zero-shot-learning ", often in combination with Graph-Neural-Networks but its quite in the beginning. Bridging the gap between multiple domains is one of the sota questions in ML overall, trying to find object specific features. One step in this direction are cGAN , trying to transform one image into another, by extracting the most important information of both domains, to perfom a precise transformation. But also that, is quite in the beginning , but can work surprisingly well with some effort and loss-function tuning. Some examples: Transform green to red to make it possible for another CNN to segment the image: Additional interesting papers on that topic are: Noisy Student Unsupervised Pixelâ€“Level Domain Adaptation with GenerativeAdversarial Networks Transfer learning
