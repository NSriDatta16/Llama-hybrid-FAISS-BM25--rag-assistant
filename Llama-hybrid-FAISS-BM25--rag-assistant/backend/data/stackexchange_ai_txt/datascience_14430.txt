[site]: datascience
[post_id]: 14430
[parent_id]: 14402
[tags]: 
The answer depends a lot on what you want to achieve: Please future reader's of your machine learning paper OR Solve a use-case that matters to some business In first case, you have to scan this audience's publications, see what they use, and use the same. There isn't a perfect metric, since actually it depends on the business' cost-ratio. In the second case, all you need is the cost-matrix and the result follows naturally. Optimizing anything which isn't the cost-matrix is a rather academical exercise. The cost-matrix has one parameter and depends really on the business. No reference is going to solve this decision for you. The discussion between performance metrics is missing the point. There is only one answer once you manage to squeeze out a cost-matrix from your business stakeholders. In a business anything can be estimated in terms of money. It only gets tricky, if it more complex than a single class weight. So the answers are: Parameter performance: calculate cost; Overall performance: take max(), or to be more precise correct for testing multiple hypotheses, too There isn't any, unless you find one which proves that optimizing a metric optimizes for all possible cost matrices simultaneously. In that sense, ROCAUC is actually a pretty meaningless artifical metric, despite being popular. There is an interpretation which relies on the fitted model's probabilities being correctly estimated, but if you want to get real, only cost matrices matter. Model the real world impact of you model and you'll get answers! PS: I personally consider TPR-FPR the best bet in absence of a defined cost matrix.
