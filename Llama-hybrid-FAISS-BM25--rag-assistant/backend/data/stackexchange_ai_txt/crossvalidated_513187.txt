[site]: crossvalidated
[post_id]: 513187
[parent_id]: 
[tags]: 
Determining ML Approach for calculating SVD using neural networks

I am currently working on a project where I need to perform SVD (Singular Value Decomposition) computation on a noisy data using neural networks. It doesn't have to be exact SVD, certain degree of approximation is acceptable. What would be the best and efficient approach to perform this task? First, I would like to check if using neural network would demonstrate a faster calculation time for large matrices than SVD with its cost time = for m x n matrix. As a possible consequence, I would like to obtain a control over the calculation speed by setting a precision threshold for the neural network in order to overperform classic SVD. Second, while computing an SVD is relatively simple, brute-force, matrix algebra an interesting problem is identifying the SVD in an over-determined system with noisy data where I think ML could be applicable. I plan to train my neural network on a set of generated (or sample) matrices (input) and their corresponding SVD values which are to be used as output . Then, feed the neural network with another set of matrices for which I know SVD values. Next, compare the neural network result with the SVD values and calculate the error between the two; compare the execution time between neural network and numpy.linalg.svd . What are the ways to approach this and what learning approach should be used for this task? What difficulties should I be prepared for?
