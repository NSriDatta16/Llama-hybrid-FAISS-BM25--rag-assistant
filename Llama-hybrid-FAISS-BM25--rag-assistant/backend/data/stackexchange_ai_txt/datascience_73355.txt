[site]: datascience
[post_id]: 73355
[parent_id]: 
[tags]: 
'loss: nan' during training of Neural Network in python

I am training a neural network in python. But the accuracy is very low. precision recall f1-score support 0 0.10 1.00 0.19 1536 1 0.00 0.00 0.00 1517 2 0.00 0.00 0.00 1464 3 0.00 0.00 0.00 1504 4 0.00 0.00 0.00 1535 5 0.00 0.00 0.00 1468 6 0.00 0.00 0.00 1503 7 0.00 0.00 0.00 1499 8 0.00 0.00 0.00 1503 9 0.00 0.00 0.00 1471 accuracy 0.10 15000 macro avg 0.01 0.10 0.02 15000 weighted avg 0.01 0.10 0.02 15000 It seems that during training of the first epoch the loss value returns nan. epoch 1: 64/2483 loss: 3.520028: 0%| | 0/39 [00:00 Im trying to normalize the input dan fill the nan input using: #fill the nan col_mean = np.nanmean(features, axis = 0) inds = np.where(np.isnan(features)) features[inds] = np.take(col_mean, inds[1]) #normalize features = np.interp(features, (features.min(), features.max()), (0, +1)) but the accuracy still doesn't change.
