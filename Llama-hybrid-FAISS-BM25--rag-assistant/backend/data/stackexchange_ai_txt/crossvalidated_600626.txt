[site]: crossvalidated
[post_id]: 600626
[parent_id]: 600576
[tags]: 
Let me first make sure that we are on the same page that BO is a terrible approach to solve this particular problem . For many reasons some of which I will now enumerate. Given that your observations are generated from $y \sim N(p,2)$ , "the best" way to get $p$ (the best in multiple ways, for example it's the MLE) is a sample mean, $p := \frac{1}{N} \sum_{i=1}^N y_i$ . But my understanding is that you are trying to learn BO so let's pretend we want to estimate $p$ by maximizing the Gaussian curve. So, your model can be written as follows. I want to maximize some function $f \colon R \mapsto R$ , given by $$ {\displaystyle f(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({x-p}\right)^{2}}}.$$ This is not a black-box problem. You have an expression for $f$ so you can compute gradient and use Newton's method. Even if the formula is more complicated than this, BO will be very inefficient. You will be much better off computing gradient by autodiff and use a gradient-based optimizer. This is a single-peaked problem. BO is a global algorithm, meaning that it is designed to explore the state space rather than excel in exploiting local curvature as local algorithms do (Newton, quasi-Newton or trust-region ones). With an appropriate acquisition function and the kernel appropriately smooth, BO is guaranteed to converge globally even on non-convex and noisy functions. But the price you pay for this is much lower rates of convergence on convex problems than the alternatives I mentioned above. $f$ is computationally cheap. The selling point of BO is that in can locate the basin of attraction of the global minimum of a very wild function with as few calls to $f$ as possible. It will not be good at polishing the minimum up to the numerical precision (it will always over-explore). But it's useful if each call to $f$ is very costly and you need only an ok-ish solution. This is not the case here. Ok, but let's pretend it's a black-box function and you don't know it's single-peaked. You can only obtain noise-corrupted measurements, $$ y_i = f(x_i) + \varepsilon_i, \quad \varepsilon \sim N(0,2)$$ In a small sample, GP regression will not be able to tell apart the non-linearity in $f$ from the noise $\varepsilon_i$ . Figure 5.5 in Rasmussen & Williams "Gaussian Processes for Machine Learning" says it all. So, it's usually the best to fix $\nu$ , especially at the beginning. Update To your point about the standard deviation: We use predictive standard deviation in the formula for EI because this follows from the expression for $E [ \max\{0,f - f^*\}]$ given that $f \sim GP(m,k)$ . SD is also nice because it turns that it's equal to so called "power function" which can be used to bound the approximation error in $L_{\infty}$ norm, $\sup_u |f(u) - \hat{\mu}(u)|$ , where $\hat \mu$ is the GP predictive mean. (See e.g. [4] Proposition 3.5). So, the SD is not as useless as it looks in this particular example. Three final remarks EI (or PI) with noisy observations are always problematic becasue you don't know what the best so far actually is. In the matlab code, you have ybest_so_far = max(predict(model, xo)); which may be far off the truth given the magnitude of the noise. The max of actual realization isn't perfect either, again due to the noise. See [3] for more. It is common practice to initialize BO over some quasi-uniform set, e.g uniform random points (see e.g. [2] on p. 473). It is because initial recommendations of any acquisition are rubbish. Take a look at fitrgp function a try to limit the admissible bounds on hyperparameters. Too much change in hypers is not good. In the same paper Jones et al. suggest to estimate then every 10th or so iteration, not continuously. But ultimately, this is a very difficult problem given that noise and signal are essentially isomorphic. Good luck! [2]: Jones, Donald R., Matthias Schonlau, and William J. Welch. “Efficient Global Optimization of Expensive Black-Box Functions.” Journal of Global Optimization 13, no. 4 (1998): 455–92. https://doi.org/10.1023/A:1008306431147 . [3]: Picheny, V., Wagner, T., and Ginsbourger, D. (2013b). “A Benchmark of Kriging-Based Infill Criteria for Noisy Optimization.” Structural and Multidisciplinary Optimization,48: 607–626. [4]: Stuart, Andrew, and Aretha Teckentrup. "Posterior consistency for Gaussian process approximations of Bayesian posterior distributions." Mathematics of Computation 87.310 (2018): 721-753.
