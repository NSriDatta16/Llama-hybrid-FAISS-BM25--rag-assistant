[site]: stackoverflow
[post_id]: 4924235
[parent_id]: 4916170
[tags]: 
Searching for bit patterns within byte data is a little more challenging than typical searches. The usual algorithms don't always work well as there is a cost for extracting each bit from the byte data and there is only an 'alphabet' of two characters, so just by chance 50% of comparisons will match (this makes many algorithms much less efficient). You mentioned trying the bitstring module (which I wrote) but that it was too slow. That's not too surprising to me so if anyone has any great ideas on how to do this I'm paying attention! But the way bitstring does it suggests a possible speed up for you: To do the match bitstring converts chunks of the byte data into ordinary strings of '0's and '1', and then uses Python's find method to do a quick search. Lots of the time is spent converting the data to a string, but as you are searching in the same data multiple times there's a big saving to be had. masks = ['0000101010100101', '010100011110110101101', '01010101101'] byte_data_chunk = bytearray('blahblahblah') # convert to a string with one character per bit # uses lookup table not given here! s = ''.join(BYTE_TO_BITS[x] for x in byte_data_chunk) for mask in masks: p = s.find(mask) # etc. The point is that once you convert to an ordinary string you can use the built-in find , which is very well optimised, to search for each of your masks. When you used bitstring it had to do the conversion for every mask which would have killed performance.
