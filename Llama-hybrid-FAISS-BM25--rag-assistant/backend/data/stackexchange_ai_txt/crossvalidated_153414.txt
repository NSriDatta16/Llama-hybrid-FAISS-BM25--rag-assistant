[site]: crossvalidated
[post_id]: 153414
[parent_id]: 
[tags]: 
Cross Validation and Logistic Regression

Cross Validation-validation, Over Fitting over-fitting, Logistic Regression and logistic regression (restrictedI am restricted to using SAS only) I have a data set of 60 000 records (binary response, roughly 90 continuous predictors ...the the data set is full of legitimate zeros, so I am analyzing the Principal Component Analysis scores ...95% 95% variance summarized in 15 components),. I randomly broke it into a 60%-40% training set (proc surveyselectproc surveyselect), and 40% test set. I used logistic regression on the training set and it seems to be working on the test set. I keep trying different logistic parameters by randomizing the two sets. I am worried about over fitting. The AIC (Akaike's Information Criterion) and SC (Schwartz Criteria Criterion ...also also called Bayesian Criteria Criterion) are quite high, greater than 1000. The c-value (convergence criteria...area under the ROC) of the logistic model is 0.52 ( I have split the dataset many times and keep getting similar AIC's, SC's and C-values)values; I'm told that this is not good). What should I do to see if I am over fitting? I have been thinking of splitting the original set again and again to collect different parameters....use use Cross Validation techniques to check for overfitting....would would anyone have any recommendations? Thanks.
