[site]: crossvalidated
[post_id]: 587619
[parent_id]: 
[tags]: 
Sample size calculation for a difference between two groups with clustered data

I want to compare proportions or means in two groups in a clustered sample. Suppose the sampled clusters are schools or hospitals or Census areas, and we sample from each of these an equal number in each of the two comparison groups. In other words, it is not the case that entire clusters are in one comparison group or another (i.e., not a cluster randomized trial). In survey analysis, standard errors for estimating means and proportions are typically inflated in cluster samples because of the intraclass correlation (ICC) among subjects in clusters -- we sample $n$ subjects but we really have a smaller effective sample size due to the ICC/design effect. However, when we want to compare two groups in a clustered sample, and both groups are present in all clusters, my simulations for various ICC values are basically finding that the various approaches for estimating a difference between the two groups (in particular, survey regression and GEE with an exchangeable working correlation matrix) have roughly similar standard errors to the standard error associated with a t-test that ignores the clustering, on average . In fact, on average, the standard error is marginally smaller as compared to the approach that ignores the clustering in the data. My first question is: Is this correct? Does it make sense? Have I made some mistake? Intuitively, I think it makes some sense to me -- we can think of observations in the two groups as almost forming pairs in each cluster, and paired t-tests typically have greater power than two-sample independent t-tests. It seems this extra statistical power from having both groups present in each cluster can compensate for the increased uncertainty present in each group's respective estimates. I found some literature that seems to agree with me on this, but it's not much: https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-9-39 "Thus, in an observational study, with all centers having identical group distributions [. . .] taking into account the center effect leads to increased power" For SRS, the variance for a difference in means is: $Var(\hat{y}_{1, srs} - \hat{y}_{2, srs}) = Var(\hat{y}_{1, srs}) + Var(\hat{y}_{2, srs})$ For a clustered sample, the variance for a difference in means is: $Var(\hat{y}_{1, cluster} - \hat{y}_{2, cluster}) = Var(\hat{y}_{1, cluster}) + Var(\hat{y}_{2, cluster}) - 2Cov(\hat{y}_{1, cluster}, \hat{y}_{2, cluster})$ In other words, it can be the case that despite $Var(\hat{y}_{i, srs}) for $i = 1, 2$ , positive covariance between the two cluster estimates can potentially actually more than compensate. Is this correct? Or is there some quirk in my simulations causing this to happen? My second question is : are there any suggestions on sample size calculations for such a study to ensure it is sufficiently powered? Simulations like I have been doing appear to be the best solution, but I'm wondering if I'm missing something obvious, and I do not want to under-power the study. I see there is a package in R called samplesize4surveys with functions for differences in means and proportions, but I have trouble parsing some of the documentation and replicating simple SRS results. I would appreciate any references as well. In practice my outcome of interest is binary, not continuous, but I think the same lessons should hold.
