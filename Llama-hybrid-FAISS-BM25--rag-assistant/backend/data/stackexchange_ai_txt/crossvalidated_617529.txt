[site]: crossvalidated
[post_id]: 617529
[parent_id]: 616904
[tags]: 
If you had a large number of data points, I'd strongly recommend simply fitting a random forest while keep your response continuous. Random forests can deal with possible nonlinearities and are structurally quite robust to overfitting. There's no need to dichotomise your continuous variable - it throws away information that is likely useful - so just keep it continuous. Importance can be defined in different ways (more on this in a bit), but the 'permutation importance' commonly used for random forests is conceptually appealing. But with 300-800 data points and >3000 predictors, fitting any flexible model is optimistic. You may be better off fitting a less-flexible model such as a linear regression, though I suppose you could include quadratic terms if linearity is too strong an assumption. An important part of this fitting would be to use regularisation, such as LASSO. Note however that the retained parameters aren't necessarily more important , in part because importance isn't a single well-defined concept . The relaimpo R package implements a variety of different importance metrics and they can provide fairly different rankings . You could try both modelling options and see how well they work in your case. For importance rankings, I recommend looking into the different metrics and thinking carefully about what way of quantifying importance would be most useful for your specific application.
