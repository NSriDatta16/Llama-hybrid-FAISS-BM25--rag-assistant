[site]: crossvalidated
[post_id]: 439995
[parent_id]: 
[tags]: 
How to tune MCMC with unwieldy posterior

Let's say I have $n$ observations of a random variable, $X_1, \dotsm, X_n \sim \mathcal{N}(0, \sigma^2)$ . I also assume $\sigma^2$ has a Gamma(1,1) prior distribution, $\pi(x) = \exp(-x)$ . I'm now attempting to use Metropolis-Hastings to sample from the posterior distribution (which I believe is): $$f(\sigma | X) \propto \frac{1}{(2\pi\sigma^2)^{n/2}}\exp{-\left( \sigma^2 + \sum\limits_{i=1}^n\frac{X_i^2}{2\sigma^2}\right)}$$ However, for larger $n$ , this unnormalized density produces usually either quite small or quite large values, making it difficult to get the Markov chain to mix well. My question is: in general (and for the MH algorithm), what are my options for attempting to sample with such an unwieldy distribution?
