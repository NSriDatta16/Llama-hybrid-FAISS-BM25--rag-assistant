[site]: crossvalidated
[post_id]: 157701
[parent_id]: 157698
[tags]: 
So, I welcome any comments or corrections, it's been a while since I've sat in front of a textbook. Insofar as I've always thought of it, the frequentist isn't as interested in the distribution of $\hat{\mu}$ as the Bayesian is of $\mu \mid y$ (I'm totally going to get flamed for that statement). Why do I say this? In the frequentist view of things, $\mu$ is a degenerate random variable, and $\hat{\mu}$ is our best guess at $\mu$. Hence, we may use the (implicit) distribution of the estimator as a means of handling the error of our guess, but we can't really interpret $$P( \hat{\mu} \in [a,b]) = p(a,b)$$ as something like The probability that $\mu$ lies in $[a,b]$ is $p(a,b)$. Instead, $p(a,b)$ encodes our uncertainty in $\hat{\mu}$ and -- this is my opinion -- this doesn't really help us get a handle on $\mu$... In the bayesian view, however (as you've identified), $\mu$ is a (nondegenerate) random variable, and our collection of data, $y$, affords us the ability to say things like $$P(\mu \in [a,b] \mid y) = p(a,b)$$ The probability that $\mu$ lies in $[a,b]$ is $p(a,b)$. ... I'm not sure if this helps, but leave a comment and I'll cleanup/elaborate as necessary!
