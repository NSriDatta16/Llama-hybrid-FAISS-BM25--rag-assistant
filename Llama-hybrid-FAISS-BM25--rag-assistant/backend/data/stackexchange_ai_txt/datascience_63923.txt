[site]: datascience
[post_id]: 63923
[parent_id]: 63920
[tags]: 
Logistic Regression expects labelled y_train, you do not need to do OneHotEncoding. y : array-like, shape (n_samples,) Above is from sklearn LogisticRegression.fit. I think as long as it is label encoded(using LabelEncoder ), basically this tool will automatically generate label mapping from your categorical values to unique integers between 0 to n-1, where n represent count of distinct value of the category. LogisticRegresion will work fine with label encoded target value. Protip : Please use labelencoder or OneHotEncoder to make mapping of categorical values. The problem with get_dummies is that it relies on , suppose you are doing transformation on different separated dataset(e.g. test set contained in another dataframe), suppose that on trainset you have 3 unique categorical values but on test set there are only 2 unique values. Then pd.get_dummies will only give you 2 columns (other than 3) when you are perform it on the test set.
