[site]: datascience
[post_id]: 115472
[parent_id]: 
[tags]: 
Is there meta-cognition in machine learning algorithms?

I have very little knowledge about machine learning, but I'm wondering if some neural networks have in-built abilities to gauge their own ability to learn and their improvement, taking this as a training set as well, and thus learning to learn as they're learning the assigned task? Perhaps there are other networks given this training task, supervising and training the networks that are learning the assigned task? I guess the "meta-cognitive" abilities could be improved if the neural network would train until mastery, and then have their data wiped clean, except for the meta-cognitive data, thus allowing it to continue training it, without the bottleneck of mastery over the assigned task. So, my questions are this: Are such meta-cognitive processes built into some neural networks? If so, does it work well? If so, is it more translatable than the abilities learned from the training for the assigned task (the implication being that this might be the road to AGIs)?
