[site]: crossvalidated
[post_id]: 283901
[parent_id]: 283891
[tags]: 
Many issues with your analysis and question: 1: the premise "the Bayesian approach is the most correct in Machine Learning" is flawed. 2: It's not actually Bayesian. Base a decision on Pr(C|x) and not Pr(x|C) 3: The LR statistic is UMP for Gaussian mixtures. We expect frequentist and approximate Bayesian inference to be superior. 4: Your Bayes inference looks wrong. It looks like you set C to a single variable representing the Bernoulli proportion of class membership, presumably a beta distribution, which has simply multiplied the same likelihood ratio threshold by an arbitrary factor and led to a mis-calibrated decision rule. Each observation has a class membership, so that is N bernoulli variables, either conditional (hypergeometric) on the proportion or not (binomial) and a prior on the probabilities of class membership taken from a dirichlet distribution. The dirichlet posterior can be updated using the EM estimated centroids for the Gaussian mixture.
