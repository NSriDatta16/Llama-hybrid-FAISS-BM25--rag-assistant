[site]: datascience
[post_id]: 121014
[parent_id]: 
[tags]: 
What does it exactly mean by "different representation subspaces" in transformer?

I was trying to understand transformer architecture from "Attention is all you need" paper. The paper says: Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this. What does it exactly mean by "different representation subspaces". Can you give intuitive example in terms of natural language conversation example. For example, in sentence "Jane went to Africa during summer", query matrix $Q$ correspoding to word "Africa" can comprise of different queries "Who went to Africa?", "When went to Africa?". What are "different representation subspaces" here? Or with any other example of your choice?
