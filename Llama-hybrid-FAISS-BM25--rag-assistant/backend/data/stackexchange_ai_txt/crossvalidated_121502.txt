[site]: crossvalidated
[post_id]: 121502
[parent_id]: 
[tags]: 
How important is the quality of solutions to NP-hard problems arising in machine learning problems?

Machine learning and inference problems give rise to intractable problems. For instance the exact inference in Bayes nets is an NP-hard problem . At the same time there are polynomially tractable classes of Bayesian inference problems see here . In case the problem at hand is intractable, it is very hard to get a good solution as the size of the input increases. However, it should be possible to get a good approximation at the cost of computational time. For large problems though, does it worth the computational effort ? What is the value of a huge training set if it leads to an intractable inference problem ? Is it better to go for an optimal solution using smaller training to the expense of potentially skipping crucial parts of your input or to go for worse solutions using a big training set which includes most of the crucial parts.
