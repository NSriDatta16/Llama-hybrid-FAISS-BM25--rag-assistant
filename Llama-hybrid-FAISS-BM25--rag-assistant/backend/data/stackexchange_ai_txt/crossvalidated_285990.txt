[site]: crossvalidated
[post_id]: 285990
[parent_id]: 
[tags]: 
Are there any statistical model that could learn an arbitrary probability distribution?

I have the follow problem: I need a statistical model or machine learning method that allow me to parameterize a probability distribution into a finite number of parameters $\theta$. That's mean, given $\theta$, I would get the distribution function $F_\theta(x)$ over $\mathbb{R}$. But I still need the following feature: I can compute the probability density function $f_\theta(x)$ easily I can compute the inverse $F^{-1}_\theta$(y) Hopefully it is easy to compute the gradient of $\log f_\theta$ for me to find the MLE of $\theta$. (It is okay if there is another statistical inference technique) I have thought the following way: Parameterize $F_\theta$ by a neural network and then use a sigmoid function at the end of the network to enforce the output to $[0,1]$ But then I don't have any idea how to guarantee the function that I learnt is monotonic increasing in $x$. Parameterize $f_\theta$ by a neural network and then use an exponential function $\exp(\cdot)$ at the end of the network to enforce the output to be positive. But then I suffer from the problem that computing $F_\theta(x)$ and $F^{-1}_\theta(x)$ are difficult. Use a mixture model with many components to model the distribution function. Are there any existing statistical model or machine learning deal with such problem?
