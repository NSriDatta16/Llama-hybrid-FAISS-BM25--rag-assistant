[site]: crossvalidated
[post_id]: 147326
[parent_id]: 
[tags]: 
Help for interpreting SVM cross-validation results

I am using support vector machines for an unbalanced binary problem (0: 25%, 1: 75%). I do K-fold cross-validation with $K=10$. The metrics I get are: 80% classification accuracy on average for the training set 70% classification accuracy on average for the test set 50% f1-score on average for the test set. What kind of interpretation I can do here? In particular, is the f1-score a good one or a not so good one ("publishable")? I am mainly interested in correctly classifying the instances of class '0'. What metrics should I be looking at?
