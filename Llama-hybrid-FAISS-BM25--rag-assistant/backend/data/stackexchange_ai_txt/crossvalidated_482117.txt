[site]: crossvalidated
[post_id]: 482117
[parent_id]: 
[tags]: 
Neural Networks: cross validation necessary?

I am training some networks to detect certain characteristics in x-ray images. The images are divided into three classes: A, B and C. I have currently used the neural network committee building approach. My committee consists of 10 networks, which in turn are trained using the bagging resampling technique: each training set consists of a sampling with repetition of the original training set. According to what I read in the literature, this gives diversity to the committee and allows each network to "specialize" in some characteristic present in the images. So what I do is this: I divide the dataset into training, validation and testing (70/15/15). I train each network that makes up the committee by varying the training set (using the bagging technique) and varying the number of neurons in the hidden layer. I use the validation set for early stop. I use the committee to deliberate on the set of tests by means of votes, giving greater weight to the networks that were most correct. The results were very satisfactory, being superior to the methods used by other people with the same data set. The problem is that the data set is relatively small: only 525 samples. It is also a noisy dataset, with some possibly incorrect classifications. As they are images, I am using pixels as input values ​​for networks. I resized the images to be 324 pixels, but there are still a large number of variables for my number of samples. I read about using cross-validation when you have few samples. 1) Should I use this? 2) How could I use it in this case?
