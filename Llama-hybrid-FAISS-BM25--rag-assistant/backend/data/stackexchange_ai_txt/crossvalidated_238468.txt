[site]: crossvalidated
[post_id]: 238468
[parent_id]: 238435
[tags]: 
Is this just the same as setting weight to zero? Yes, setting weight to zero is equivalent to no connection. Research on neural nets that learn paths/connections? You may also want to look at the literature on neuro-evolution . Examples: Zaremba, Wojciech. Ilya Sutskever. Rafal Jozefowicz " An empirical exploration of recurrent network architectures. " (2015): used evolutionary computation to find optimal RNN structures. Franck Dernoncourt. " The medial Reticular Formation: a neural substrate for action selection? An evaluation via evolutionary computation. ". Master's Thesis. École Normale Supérieure Ulm. 2011. used evolutionary computation to find optimal connections and number of neurons. Bayer, Justin, Daan Wierstra, Julian Togelius, and Jürgen Schmidhuber. " Evolving memory cell structures for sequence learning. " In International Conference on Artificial Neural Networks, pp. 755-764. Springer Berlin Heidelberg, 2009.: used evolutionary computation to find optimal RNN structures. Equivalently, this question might be posed as allowing the addition/subtraction of neurons in various layers (along with their connections) You can use Gaussian processes to determine this kind of hyperparameters. Example: Franck Dernoncourt, Ji Young Lee Optimizing Neural Network Hyperparameters with Gaussian Processes for Dialog Act Classification , IEEE SLT 2016.
