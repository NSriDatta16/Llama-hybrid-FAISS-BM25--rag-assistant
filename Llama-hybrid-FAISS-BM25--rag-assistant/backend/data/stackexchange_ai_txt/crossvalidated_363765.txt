[site]: crossvalidated
[post_id]: 363765
[parent_id]: 363666
[tags]: 
I like @Ben (though I don't think we need to rely on Bayes factors necessarily) and @FabianWerner's answers. I'd like to add that Bayesian statistics allow us to not be so strict: An association of exactly zero is highly improbable in most settings. So instead of having a rigid straw-man null hypothesis of " r = 0," (the null hypothesis that frequentist statistics assume and test against), we can get a posterior distribution and see regions where we are most confident that the parameter lies. If the posterior distribution of the parameter is centered tightly around zero, we can believe that there's probably a practically null relationship (e.g., close enough to zero that we don't care). Frequentists can't do this—they assume the null is true. A p -value is the probability we observe our data (or more extreme data), given that the null hypothesis is true. It can't tell us anything about the null, because it is (a) a rather meaningless null in most situations, and (b) it assumes this null is true. This comes up a lot when we have such big samples that almost anything is significant in frequentist statistics. Since the null hypothesis is a parameter being precisely 0.0000000..., then even a small deviation can be "significant." I like that Bayesian statistics allow us to look at probabilities of where the parameter is likely to be, so we can see how likely it is that the parameter falls in a range of values we don't care about. If my client wants at least a one percentage point increase, I can specify how likely it is that we get a one percentage point increase, how likely it is that we get -1 to +1 change (where we don't really care—a null association for all intents and purposes), and how likely it is to get an increase of -1 or less (a backlash effect).
