[site]: crossvalidated
[post_id]: 422759
[parent_id]: 422755
[tags]: 
To give a general answer on the background and the concept behind series, time series can be used to predict both long term and short term, the problem is what you are trying to predict and how: sometimes time series theory itself will tell you that some series are indeed not predictable, especially in the long term (because their long term moments are not defined). For example you have cited the case of ARIMA processes. Suppose of order 1 for simplicity, so suppose you have a typical random walk without drift. This is by definition a process that is not stationary, and therefore not predictable on a standalone basis (i.e. provided that is NOT cointegrated). Indeed the best forecast for tomorrow is today realization and the variance tends to accumulate over time linearly. This is due to the fact that its first difference is a white noise, so the next observation will be equal to the past observation plus a completely random term. Which means that the process will have perfect memory of all the past shocks happened over time (I.e. of all the innovations, which will be compounded over time, making the ACF nearly one for all past lags). The things remains true also if the process is cointegrated. However, if the process is cointegrated with another integrated process, then there exists a combination of the two which can be stationary (remember that we are using the example of processes integrated of order 1, so cointegration implies the existence of a combination integrated of order 0, I.e. stationary). This means that there exists a long-term relationship with another process and the deviations from the long term relationships tend to be corrected over time (Error correction models). In this case, even if you cannot predict each process on a standalone basis, you can find the long term relationship and believe that temporary deviations from that relationship will be canceled over time (how frequently they will be corrected and how long the deviation may persist depends on the Error correction model). Generally speaking, in time series you search for stationarity, which allows you to predict both short term and long term (think for example of an AR process that has a long term expected mean and variance because it is less persistent than an ARIMA and tends to forget past shocks with an exponential decay in the ACF). Especially stationarity in mean and variance provided that your process is a linear process and you can consider the first two moments alone. So stationary processes are predictable, both short-term and long-term. However, remember that, intuitively, short term predictions are usually associated to reduced MSE (prediction error): for example one-step-ahead predictions are less noisy than 2-step-ahead predictions: the reason is that conditional variance will be compounded over time, for each step ahead, making your forecast more noisy if you try to predict the distant future. Notice also that time series can be defined at multiple frequencies. What matters is that the frequency will be left constant in the time series. For example you may model a time series for the daily sales of a shop. And you may model a different time series on the annual sales of the same shop. So in one case you are modeling a short-term frequency and in the other case you are modeling a long-term one. For all frequencies however what matters is that your prediction will be feasible, i.e. the data will tell you that the series follows a predictable process. If not, you have to find other ways to predict the series, for example you have to strive to find some relationships relating to the series that are stationary. An example can be finding cointegrating relationships, as I mentioned before. Thus, to summarize, considering for simplicity the only case of a univariate prediction of a stationary process, we could say that stationarity is a necessary condition for long term forecasts of tomorrow realizations based on the past realizations of the same process alone (as I anticipated we are considering univariate time series models). Once you can predict a series in the long run, then how much noise there will be in the long term forecast depends on how much the process is persistent, how much variance there will be, and clearly how far in the future your prediction will be: in a univariate prediction of a stationary process, predicting n-step ahead is more noisy than predicting 1 step ahead keeping all other conditions unchanged.
