[site]: crossvalidated
[post_id]: 115819
[parent_id]: 
[tags]: 
Covariance for a multivariate Bayesian Additive Regression Tree

Chipman, George, and McCullogh (2010) state that: One can also extend the sum-of-trees model to a multivariate framework such as: $$ (29) \qquad\qquad Y_i = h_i\left( x_i \right) + \varepsilon_i, \quad \left(\varepsilon_1, \varepsilon_2, \dots, \varepsilon_p\right) \sim N\left( 0, \Sigma \right) $$ where each $h_i$ is a sum of trees and $\Sigma$ is a $p$ dimensional covariance matrix. ... The multivariate version of BART (29) is easily fit by drawing each $h^*_i$ given i given $\{h^*_j\}_{j \neq i}$ and $\Sigma$, and then drawing $\Sigma$ given all the $h^*_i$ (p. 295). but do not explain how. Am I supposed to assume an inverse-Wishart prior on $\Sigma$? If so, would I then just draw from $Wishart^{-1}\left(YY^T + \Psi, N+\nu \right)$? (where $N$ is the sample size, $Y$ is the response vector, and $\Psi$ and $\nu$ are the prior parameters; as per Wikipedia ). The univariate version of the model has an inverse-chi-square distribution (p. 272). Citation: Chipman, Hugh A.; George, Edward I.; McCulloch, Robert E. BART: Bayesian additive regression trees. The Annals of Applied Statistics 4 (2010), no. 1, 266--298. doi:10.1214/09-AOAS285. http://projecteuclid.org/euclid.aoas/1273584455 .
