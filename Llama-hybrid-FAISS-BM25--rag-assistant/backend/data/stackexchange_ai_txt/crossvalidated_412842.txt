[site]: crossvalidated
[post_id]: 412842
[parent_id]: 
[tags]: 
How to reconstruct an image from a training set?

Description : I have taken a series of images/photos of a panorama from different positions ( x,y ) in space pretty close to each other (max 100m difference). Here there is a top view representation to describe what I did: Where the black stars are the positions where I took the photos of the panorama in front of me. My goal : Now imagine standing in the green star. What I would like to do is to have a "black box" that can output an image that tries to predict what the panorama would be, keeping in mind that I have a "training set" from which I could infer such information. Since I am not very skilled with machine learning, I thought of a neural network that takes as inputs the positions and the images as labels. However, what I've learned from the past is that it usually works the other way around. Anyways I guess it is some sort of supervised learning. My question : Is there a way to achieve such a result through some ML tool or other techniques? If so, could you provide me some links or examples that I could take inspiration from? Note: I read that DCGAN may be the way but I cannot find a similar example that could work for my case.
