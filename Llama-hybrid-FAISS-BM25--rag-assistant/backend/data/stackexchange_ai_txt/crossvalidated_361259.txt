[site]: crossvalidated
[post_id]: 361259
[parent_id]: 361237
[tags]: 
The main theoretical justification of (1), (2), and (3) is ergodicity of a Markov chain. Let $\mathcal{X}$ be the state space of the Markov chain and let $\mathcal{B}(\mathcal{X})$ be the Borel $\sigma$-algebra for $\mathcal{X}$. A Markov chain is characterized by its Markov transition kernel $P: \mathcal{X} \times \mathcal{B}(\mathcal{X}) \to [0,1]$. That is for element $x \in \mathcal{X}$ and set $A \in \mathcal{B}(\mathcal{X})$, $$P(x, A) = \Pr(X_{1} \in A \mid X_0 = x)\,.$$ After taking $t$ steps, the $t$-step transition for the Markov chain is $$P^{t}(x, A) = \Pr(X_{t} \in A \mid X_0 = x)$$ Under certain regularity conditions (aperiodicity, irreducibility and Harris recurrence), the $t$-step transition kernel converges to the stationary distribution $\pi$ in total-variation norm. That is, $$ \|P^t(x, \cdot) - \pi(\cdot)\|_{TV} \to 0 \text{ as } t \to \infty\,.$$ Convergence in total variation is strong than convergence in distribution. Thus, for large $t$, drawing from $P^{t}(x, \cdot)$ is approximately drawing from $\pi$. As a consequence of this you get (1) by the Birkhoff Ergodic Theorem for Markov chains, (2) by the definition of convergence in distribution, and (3) because it is essentially an expectation so it is a special case of (1).
