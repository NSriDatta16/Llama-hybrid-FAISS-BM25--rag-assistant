[site]: crossvalidated
[post_id]: 552852
[parent_id]: 552847
[tags]: 
You're right, you would not normally use early stopping for standard forms of regression or SVMs. In part, you are - to some extent - avoiding overfitting for those models by the natural limitations of these models (they only ever get a complex as you specify them to be). It's much more typically used for things like neural networks and gradient boosting (XGBoost, LightGBM etc.). These models will keep on making the solution more complex the more iterations you do, can approximate arbitrarily complex functions and - given enough features and time - overfit as much as you like (up to and including memorising the training data). I.e. you need to somehow stop training before you overfit and early stopping is an obvious way.
