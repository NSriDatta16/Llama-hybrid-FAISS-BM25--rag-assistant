[site]: datascience
[post_id]: 19483
[parent_id]: 19478
[tags]: 
Generally, the fact that your training and validation performance are improving at the same rate is a good thing- this (usually) means that the algorithm is learning generalizable features of your problem space rather than overfitting to the noise of your training set. Reaching a plateau in performance is also to be expected- it's very rare that a real-world machine learning problem can be perfectly solved, and a perfectly solved problem would be the only type that didn't reach a plateau in testing and validation performance (before it eventually did reach a plateau at 100% accuracy). Think of the plateau as the maximum performance that can be achieved given the particular parameter values, features, and architecture of the solution. In order to achieve performance beyond your plateau values, one of these considerations will need to be adjusted.
