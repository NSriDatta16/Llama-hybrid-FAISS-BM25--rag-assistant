[site]: crossvalidated
[post_id]: 279064
[parent_id]: 278440
[tags]: 
The first scenario may be due to over fitting of the training data. In-sample and out of sample performance also depends on what evaluation metric you are using (or is applicable to the problem). Besides comparing the metrics, try checking the confusion matrices as well to check the misclassifications. Using metrics like logloss and introducing regularization parameters might be another option.(Check out XGBoost - It allows adding alpha, beta regularization parameters.)
