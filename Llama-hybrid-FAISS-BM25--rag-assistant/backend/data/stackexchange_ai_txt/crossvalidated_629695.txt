[site]: crossvalidated
[post_id]: 629695
[parent_id]: 
[tags]: 
Imbalanced classes and possible ways to increase precision, recall and f1-score of the prediction model

I've just started my data science internship, and this is my first time in the field. I'm sure I'll face challenges in the future where I might need your help. It's also my first time asking a question on Stack Exchange, so I hope the community will be friendly and understanding. I have a binary classification problem of performing and non performing loans of customers. My ultimate goal is to predict whether a customers is performing or non performing when they come to take a loan. My dataset is imbalanced as there are lot of performing customers(74%) than non performing(26%). I have applied logistic regression and as a remedy for the imbalanced data set I have used SMOTE which is a oversampling method but it generates data synthetically and surprisingly give very good prediction accuracy, precision and recall. But as it is not appropriate to oversample in this context my supervisor asked me to apply cost sensitive learning. I have applied cost sensitive learning to both logistic and random forest but logistic regression perform better. Here is the confusion matrix and prediction report of the logistic regression when applied cost sensitive learning. As you can see here precision and f1-score of non performing customers(1) not satisfying. Also most critical in the context is to identify non performing customers(1). From most methods I used these metrics increased for the majority class(0) but further decrease for the minority class(1). I have seen similar questions but most of them are not clear enough. So I need some advice on what are the possible methods that I can use to overcome the imbalance problem and increase the precision, recall and f1-score of both classes. Thank you in advance!
