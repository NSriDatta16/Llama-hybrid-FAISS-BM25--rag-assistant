[site]: crossvalidated
[post_id]: 255580
[parent_id]: 
[tags]: 
ML Text Classification Hybrid Models â€” How to incorporate expert dictionaries with Naive Bayes / SVM / Maximum Entropy

I'm currently building a business intelligence product that requires the classification of employee review text into 15 different categories with bearing on the company's strategy execution (e.g. innovation mindset, resource allocation, collaboration.) As I hand-coded a training set for a prospective machine learning classifier, I also built a dictionary of 10-20 terms for each category that reliably mapped into the given category. For instance, the terms "R&D" "cutting edge" and "introduce new products" appear in the dictionary of terms for innovation . With a training set of about 2200 hand coded text entries, I've found the performance of the ML text classifier models (I've employed MAXENT, Naive Bayes, SVM, and GLMNET), is still quite poor,especially for certain categories. I realize the training set is fairly small for a text classifier, but the hand-coding is very time intensive, and before going back to manually building a bigger train set, I wanted to seek advice on leveraging the "expert dictionaries" I've built to improve performance. The dictionaries reliably cover about 75% of classification cases, but I'm unsure on how to merge them with the machine learning models. I suppose on the one hand I could code up a rules-based approach by which the appearance of a phrase like "cutting edge" would mandatorily classify a text block into a given category like innovation . This seems a little bit too rigid and doesn't really interact with the ML models. Does a more elegant solution that perhaps can use the dictionary phrases to inform the priors of the ML classifiers? Alternatively, is there some way to manually juice up the sensitivity of those phrases in the classifiers? Any advice, resources, or links to academic papers on this sort of hybrid dictionary/rules-based + machine learning approach are greatly appreciated. I've been doing most of the work so far in R using the "tm", "RTextTools", and "e1071" packages, so R resources are most helpful, but python classification tools could be useful as well.
