[site]: crossvalidated
[post_id]: 487055
[parent_id]: 
[tags]: 
Are maximizing the log probability and assigning the ground-truth token the highest rank the same?

I have been reading this paper titled Neural Text Generation with Unlikelihood Training . It is about the maximum likelihood function used to train generative models. Anyway, it says that a major flaw of the likelihood objective is that it pays relatively little attention to the argmax or the top of the ranked list of next token probabilities, instead optimizing the likelihood of the entire distribution. In other words, there is a discrepancy between maximizing the log-probability of a ground-truth token and ensuring the rank of the ground-truth token to be one. Now, why would that be? My understanding is that if your model assigns the highest probability to the ground-truth token, the loss will automatically be minimized (I am considering the loss function to be cross-entropy loss) so where is the discrepancy?
