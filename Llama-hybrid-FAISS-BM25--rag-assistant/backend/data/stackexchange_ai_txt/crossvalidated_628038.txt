[site]: crossvalidated
[post_id]: 628038
[parent_id]: 627982
[tags]: 
My question is: for the general GLM, what should be the corresponding activation function if the GLM were represented as a neural network? If you have a model for the expectation of the form: $$\mu = g^{-1}(X\beta)$$ In GLM jargon, $X\beta=\eta$ is the linear prediction, and $g$ is the link function. Then it can be equally stated as a neural network with a single layer and $g^{-1}$ as the activation function. Note, however, as @Sycorax and @Dave mentioned, a linear predictor and a link function do not a GLM make. A GLM also has another component: an assumption on the conditional expectation of the response variable. In GLMs, we assume the response is distributed, conditional on the predictors, according to a particular distribution from the exponential family. Different choices entail different likelihoods.
