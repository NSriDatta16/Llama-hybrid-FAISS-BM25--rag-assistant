[site]: crossvalidated
[post_id]: 214384
[parent_id]: 214162
[tags]: 
Frank Harrell does not rule out intelligent use of backward elimination. He includes as a possibility (page 97, RMS, 2nd edition ): Do limited backwards step-down variable selection if parsimony is more important than accuracy. This, however, is only to be done in the context of an already well-specified model. It is the last step before the "'final' model." As this paper linked from the related question emphasizes, the variable selection in GETS must begin with an already well-specified model: The search should start from a congruent statistical model to ensure that selection inferences are reliable. Problems such as residual autocorrelation and heteroscedasticity not only reveal mis-specification. They can deliver incorrect coefficient standard errors for test calculations. Consequently, the algorithm must test for model mis-specification in the initial general model. This is a good deal different from many questions on this site, where those without much evident statistical background often seem to want a plug-and-play approach to the entire problem. They start with some type of multiple regression, give little thought to underlying subject matter, data transformations, the peculiar problems in time series, or the like, and want to determine automatically "what are the most important variables"? Also, GETS seems inherently inapplicable to the $p>n$ setting, where so much of the difficulty (and interest, and poor statistical technique) in variable selection arises. Although time series are outside my expertise, I suspect that large time series from which autocorrelations have been removed effectively provide $n\gg p$, with many degrees of freedom left. I also wonder (without any solid knowledge of time series) whether removing time-based autocorrelations may in practice help minimize other sources of non-orthogonality among predictors. The various flavors of GETS pay a good deal of attention to tradeoffs between Type I and Type II errors in the steps of the reduction of the initial well-specified model to a reduced form, which may obviate shrinkage corrections (or include them implicitly in the estimates of the reduced model).
