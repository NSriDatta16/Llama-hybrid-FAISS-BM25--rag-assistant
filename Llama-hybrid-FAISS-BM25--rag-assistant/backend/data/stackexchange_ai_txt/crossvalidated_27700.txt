[site]: crossvalidated
[post_id]: 27700
[parent_id]: 
[tags]: 
Linear regression forecast underestimation

I have the following multiple linear regression model: Call: lm(formula = Y ~ X1 + X2 + X2 + X3 + X4 + X5 + X6 + X7, data = my.model, na.action = na.omit) Residuals: Min 1Q Median 3Q Max -43.836 -1.507 0.010 1.485 46.231 Coefficients: Estimate Std. Error t value Pr(>|t|) (Intercept) -0.0244927 0.0245157 -0.999 0.318 X1 -0.3484619 0.0134383 -25.931 The model is affected by multicollinearity but my question is about the forecast, so this shouldn't be an issue. I checked the absolute values of my model forecast and compared against the actual Y absolute values. The average of the absolute predicted values is significantly lower than the absolute observed values mean: > lm1.predict = predict(lm1, mydata) > mean(abs(lm1.predict)) [1] 0.3294776 > mean(abs(mydata$Y)) [1] 1.206954 Does this mean that the linear regression variables I am using tend to underestimate the outcomes? Can any other conclusion be derived from this simple comparison? EDIT Another way to look at this is to calculate the absolute difference between each observation and the relative outcome: > mean(abs(mydata$Y - lm1.predict)) [1] 1.208378 These are the diagnostic from the regression:
