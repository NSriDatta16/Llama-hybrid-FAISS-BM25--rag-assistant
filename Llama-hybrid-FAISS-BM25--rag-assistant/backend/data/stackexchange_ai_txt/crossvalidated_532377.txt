[site]: crossvalidated
[post_id]: 532377
[parent_id]: 
[tags]: 
Noob question about bayes rule denominator estimation

A known problem of Bayes rule is the intractability of the estimation of $p(D)$ given a multiparametric problem, since $p(D)$ is found by marginalizing the joint probability $p(D, \theta_{1..n})$ over the whole n-dimensions $\theta$ space. But I was wondering, since $p(D)$ , in theory, does not depend on the actual parameterization of the model (otherwise it would be conditional on $\theta$ and not marginal), wouldn't be sufficient to estimate in a way that doesn't use $\theta$ at all? I wouldn't know how to do it with no parameters at all, but the first thing that comes to my mind would be to use a simplified model with just one parameter to integrate over and then use the $p(D)$ estimated this way as a denominator of the joint density of the complex model. What am I missing? If one can compute $p(D)$ analytically (or numerically but fast) from a simpler model, couldn't she plug it into a complex model to avoid using MCMC to estimate the normalized posterior?
