[site]: crossvalidated
[post_id]: 611099
[parent_id]: 
[tags]: 
Performances of train/test split vs train/validation/test split

Despite there are multiple questions about it, I cannot figure a solution about my problem. I have built a simple neural network classifier on the MNIST database. I have divided it in training, validation, and test sets. Then on the first two sets I have obtained the hyperparameters, in particular the number of epochs following an Early Stopping procedure. Then I train a new model with the same architecture of the previous one on traininig+validation for the same amounts of epochs. I do not understand why this new model performs poorer on the test test in comparison to the old one. I can also share the code, but I know that CrossValidated is for more conceptual questions.
