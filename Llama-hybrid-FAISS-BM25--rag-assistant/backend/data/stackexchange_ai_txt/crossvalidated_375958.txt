[site]: crossvalidated
[post_id]: 375958
[parent_id]: 375351
[tags]: 
First a little disclaimer: I don't have the academic credentials to back anything up that I'm saying now. This is just what I use in practice. There's the metric called Youden's index which is: $$Y = -1 + sensitivity + specificity$$ If $Y = 0$ then your classification system is random, if $Y = 1$ then it is a perfect classification system. It is possible to favor sensitivity over specificity or vice-versa by adding weights: $$Y = -1 + sensitivity \cdot 2 \cdot w + specificity \cdot 2 \cdot (1 - w)$$ If your classifier is detecting spam and the cost of a false positive is high you want as much true negatives as possible and thus favor specificity over sensitivity. By adding weights you get an index of how good your classification system is given the associated costs of wrong classifications. You can also plot a $Y$ curve(s) (even multi-dimensional) in case you have parameters in your classification system and then calculate the area under the curve or volume (in case you have two parameters) or you can just sum up the $Y$ s for each combination of parameters. This of course can easily be extended to multiple classes: $$Y = \frac{-N + \sum_{i}{sensitivity_{i}\cdot 2\cdot w_{i} + specificity_{i}\cdot 2 \cdot (1-w_{i})}}{N}$$ I use this to compare neural networks that distinguish between multiple classes but it's more important to be able to correctly classify a few classes and the remaining classes are not that important (e.g. being able to recognize a stop sign is much more important than being able to recognize a sign that tells you at which time of the day you're allowed to park there). Weights allows me to do this be configuring how important it is to recognize something (sensitivity) and how important it is to be able to recognize that something isn't something (specificity) (e.g. I want a high specificity on the park sign but the sensitivity isn't that important and I want high sensitivity on the stop sign)
