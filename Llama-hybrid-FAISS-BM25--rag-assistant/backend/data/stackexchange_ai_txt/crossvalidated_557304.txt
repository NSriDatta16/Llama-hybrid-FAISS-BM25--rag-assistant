[site]: crossvalidated
[post_id]: 557304
[parent_id]: 
[tags]: 
Are convolutional autoencoders required to have symmetric encoders and decoders?

I am a newer to deep learning. Recently I am studying the convolutional autoencoder (CAE). I found the architectures built with keras and matlab are a little different. In particular, the architecture in keras is ( https://blog.keras.io/building-autoencoders-in-keras.html ): import keras from keras import layers input_img = keras.Input(shape=(28, 28, 1)) x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img) x = layers.MaxPooling2D((2, 2), padding='same')(x) x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x) x = layers.MaxPooling2D((2, 2), padding='same')(x) x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x) encoded = layers.MaxPooling2D((2, 2), padding='same')(x) # at this point the representation is (4, 4, 8) i.e. 128-dimensional x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded) x = layers.UpSampling2D((2, 2))(x) x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x) x = layers.UpSampling2D((2, 2))(x) x = layers.Conv2D(16, (3, 3), activation='relu')(x) x = layers.UpSampling2D((2, 2))(x) decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x) autoencoder = keras.Model(input_img, decoded) autoencoder.compile(optimizer='adam', loss='binary_crossentropy') While in Matlab, the architecture is ( https://www.mathworks.com/help/deeplearning/ug/image-to-image-regression-using-deep-learning.html ): encodingLayers = [ ... convolution2dLayer(3,8,Padding="same"), ... reluLayer, ... maxPooling2dLayer(2,Padding="same",Stride=2), ... convolution2dLayer(3,16,Padding="same"), ... reluLayer, ... maxPooling2dLayer(2,Padding="same",Stride=2), ... convolution2dLayer(3,32,Padding="same"), ... reluLayer, ... maxPooling2dLayer(2,Padding="same",Stride=2)]; decodingLayers = [ ... transposedConv2dLayer(2,32,Stride=2), ... reluLayer, ... transposedConv2dLayer(2,16,Stride=2), ... reluLayer, ... transposedConv2dLayer(2,8,Stride=2), ... reluLayer, ... convolution2dLayer(1,1,Padding="same"), ... clippedReluLayer(1.0), ... regressionLayer]; layers = [imageLayer,encodingLayers,decodingLayers]; It can be found that, in keras, a convolution layer is added to the encoded layer (i.e., after maxpooling); while in matlab, transposed convolution is directly after the maxpooling layer. The architecture of CAE should be symmetric, from my understanding. Therefore, the first layer in the decoded part in keras should be upsampling, since the last layer in encoded part in keras is maxpooling. But now the first layer in decoded part in keras is convolution, it seems that the architecture is not symmetric. But the architecture in matlab is symmetric. Additionally, from my understanding, a combination of an upsampling2D layer and a convolution layer in keras is equivalent to transposedConv2dLayer in matlab. Therefore, I want to know whether the convolutional layer mentioned above in keras is simply for keeping the image size to be same as the input, but should be neglected if the symmetrical architecture of CAE is considered? Or the symmetry of network architecture is not enforced?
