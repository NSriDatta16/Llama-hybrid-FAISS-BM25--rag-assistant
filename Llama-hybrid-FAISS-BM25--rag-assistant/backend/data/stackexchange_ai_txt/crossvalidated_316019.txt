[site]: crossvalidated
[post_id]: 316019
[parent_id]: 315428
[tags]: 
There are many times in basic science (and other) research designs, where experiments are replicated and, at first glance, repeated measures seem appropriate. However, most procedures designed to handle data derived from non-independent units, such as the paired t-test, require more than one observation taken on the same experimental unit. A replicated experiment or one in which numerous observations are derived from the same organism or set of conditions are not usually measurements on identical experimental units, while shared conditions do create an appropriate environment for evaluation of clustered effects. While the presence of group or cluster effects could be considered, often these designs assume that observations (e.g. cells) taken from between replications (e.g. dishes or mice) are sufficiently homogeneous to ignore potential clustering effects. Ignoring the potential for replicate-level effects by lumping the numerous between-cluster observations into one group or treating the data as repeated measures set the stage for errors in estimation of true effects of exposure/treatment. In the OP's case, the notion of using a logistic procedure to model a binary outcome is appropriate (a cell is either irregular or non-irregular). The idea of comparing proportions is also correct and the Chi-square test or Fisher's exact test are readily available for this purpose. This is not count data, as suggested later in the question. If the petri dishes are considered flawlessly homogenous, then no further testing is necessary and the effect of treatment on cell morphology is complete. This approach would further be supported if each time a replicate of the treated and untreated dishes were run the replication was carried out in the same incubator with exchange of position in the incubator with the same set of reagents, etc. This situation would not create repeated measures, but would create the best experimental design for isolation of treatment effects provided the control was truly a control. A less optimal design would replicate on separate days, in multiple incubators with different lots of reagents, etc. Here, we cannot be sure that experimental conditions were homogenous between dishes and treatments effects may be lost as the control of the experimental conditions are lost. If the OP wanted to evaluate the effect of replication on experimental results, then careful consideration of the experimental approach should be undertaken (details not provided by the OP for comment) and some hypothesis as to whether replication affected the treatment effect should be generated and tested based on the experiment as executed. As other answers suggest, the best approach is probably to proceed with a series of generalized linear models with a binomial link function. To test the hypothesis that replication determines cell irregularity, one could test for the effect of replication as a dummy-coded variable using a model similar to: (pseudo-code): irregular_cell = factor(replication) If the number of groups is few and measurements within groups are many, this should suffice to test the hypothesis of replication effects on cell irregularity. If the groups are many and within-group measurements are few, then an assessment of replication effects is best estimated using a Generalized Estimating Equation or Random effects model. These models could further test the association of interactions between clusters and treatment and there are many CV references for this type of work. Ultimately, the OP could find that replication explained a significant amount of variation and would then need to reconsider the experimental design or report treatment effects with main effects and/or standard errors adjusted for replication. S. H. Hurlbert (1984) Pseudoreplication and the design of ecological field experiments, Ecological monographs 54(2) pp. 187 - 211
