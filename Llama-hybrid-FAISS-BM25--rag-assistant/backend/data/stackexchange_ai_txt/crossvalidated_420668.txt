[site]: crossvalidated
[post_id]: 420668
[parent_id]: 
[tags]: 
How many Markov chains are there for 2 states in 1, 2 and 3 steps?

wiki uses this example to illustrate Markov chains. The probabilities of weather conditions (modeled as either rainy or sunny), given the weather on the preceding day, can be represented by a transition matrix: ${\displaystyle P={\begin{bmatrix}0.9&0.1\\0.5&0.5\end{bmatrix}}}$ The matrix P represents the weather model in which a sunny day is 90% likely to be followed by another sunny day, and a rainy day is 50% likely to be followed by another rainy day. The columns can be labelled "sunny" and "rainy", and the rows can be labelled in the same order. The weather on day 1 is known to be sunny. This is represented by a vector in which the "sunny" entry is 100%, and the "rainy" entry is 0%: ${\displaystyle \mathbf {x} ^{(0)}={\begin{bmatrix}1&0\end{bmatrix}}}$ for day n + 1( Note : the original value on wiki is n, which seems to be incorrect) ${\mathbf {x}}^{{(n)}}={\mathbf {x}}^{{(0)}}P^{n}$ The superscript (n) is an index, and not an exponent. In the particular case, the state space of the chain is {rainy , sunny} how many Markov chains are there respectively on day1, day2 and day3? for example, on day1 ${\displaystyle \Pr(X_0=sunny) = 1,}$ ${\displaystyle \Pr(X_0=rainy) = 0,}$ how many Markov chains are there on day1, 1 or 2? how many Markov chains are there on day2 and day3 respectively?
