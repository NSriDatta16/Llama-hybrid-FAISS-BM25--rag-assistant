[site]: datascience
[post_id]: 27180
[parent_id]: 
[tags]: 
How do I separate Interleaved sentences using LSTM networks?

I have a problem statement wherein the following input The James world Bond shall can't end save us tomorrow. must be converted into this - The world shall end tomorrow & James Bond can't save us Essentially my inputs are a set of sentences interleaved with each other, and I need to separate them. My training data contains slight variations of these interleaving sentences, I have been trying to work with a 1024 cell 2 Layered LSTM network, currently achieving about 65% accuracy when trying to predict the next word given the current set of words. I use the prediction from this model to chain words together into distinct sentences. The questions that I have are Is LSTM RNN the best way to achieve something like this? What should be a good LSTM Cell size? (I have a vocab of about 22K words.) Are 2 layers sufficient for modeling this problem statement?
