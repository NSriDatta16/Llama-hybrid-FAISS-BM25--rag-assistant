[site]: crossvalidated
[post_id]: 470638
[parent_id]: 
[tags]: 
Are time series models limited in real life application and are primarily used to model the residuals of another model?

I"m trying to see the big picture and where time series fits in to statistical inference. I'm trying to understand when we would use a time-series model like ARIMA, GARCH, and others. From the studying I have done so far, it seems like time series models are best used to model the residuals created by other models. Not only that, it is only applicable to model residuals for very specific other models, like linear regression. In other words, broadly speaking, the models described in Tsay and Shumway's book seem to have very limited scope in real life application. For example, if I were to build a boosting tree or neural network, I would imagine there is no need for any of the traditional time series models even if I was building the model on time series data? As neither a tree nor a neural network make any assumptions about the distribution of the data nor derive any analytical results, I can just include lagged values as another feature within the data. I could probably use the ACF plot or Ljung-Box test and look for serial correlation, then include the significant lags as additional features. The models described in Tsay and Shumway, from my understanding, seem to only be applicable if your original model makes strict assumptions like normality and iid. Basically, it only applies to residuals of regression models. Otherwise I don't see how they could be of any use in real life - unless you just have some process that is 100% explained by lagged values of the same process. Would you say my understanding is correct in that the models in Shumway and Tsay have limited scope in real life applications? This would make some sense as I rarely see job descriptions ask for one to understand time series models. There was a small burst maybe like 5 years ago asking for people to understand GARCH but now it's all about ML. Thanks. I'm really having a hard time seeing how time series fits in with statistical inference and am hoping to finally clarify my understanding. Right now every time I think of a "problem", I automatically think first to use a boosting tree (ease of use and it provides variable importance and has good performance), second to use neural networks (if I want to batch process, sequentially add data, or huge data sets), and third to use linear regression (if I want to know how much my feature affects the predictor, analytical results, and speed). I can't think of where TS comes in other than modeling my residuals of regression models.
