[site]: crossvalidated
[post_id]: 509007
[parent_id]: 508937
[tags]: 
The reason lies in the relationship between $\mathbf{w}$ , the vector determining the boundary hyperplane, and the slack variables, $\mathbf{\xi}$ . The slack variables are unit-less, but the boundary vector $\mathbf{w}$ isn't (but this fact gets somewhat obscured through standardisation). As we scale up the inputs $\mathbf{x}_i$ , $\mathbf{w}$ must scale down in order to keep the functional margin constant ( $\pm 1$ ). So the balance between the slack variables $\xi_i$ and the boundary vector $\mathbf{w}$ shifts as we scale the data. In more detail: The SVM classifier solves the optimisation problem: \begin{align} \min_{\mathbf{w}, b, \mathbf{\xi}} \quad & \frac{1}{2}\| \mathbf{w}\|^2 + C\sum_i \mathbf{\xi}_i \\ \text{s.t.} \quad & y_i(\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1-\xi_i \\ \quad & \xi_i \geq 0 \end{align} So, if $\mathbf{x}_i$ 's are small, $\mathbf{w}$ will need to be large in order to satisfy the first condition and it will dominate the objective function. On the other hand, if $\mathbf{x}_i$ 's are large, $\mathbf{w}$ will be small and, for a sufficiently large $C$ , the objective function will be dominated by the $\mathbf{\xi}_i$ 's. In order to keep the class boundary invariant to scaling, we need to divide $C$ by the square of the scaling factor: for scaling in [.5, 1, 2]: X_sc = scaling * X_std clf = svm.SVC(kernel='linear', C=.1/scaling**2, random_state=1) clf.fit(X_sc, y) plotSVM(X_sc, y, clf) produces:
