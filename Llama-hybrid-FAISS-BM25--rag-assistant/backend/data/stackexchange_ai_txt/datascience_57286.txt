[site]: datascience
[post_id]: 57286
[parent_id]: 
[tags]: 
LSTM number of units for time series

My question is on the number of units in an LSTM cell. I've come across the following example which is a model for predicting a value in a series based on its 2 lag observations. I'm wondering why the number of units in the LSTM cell is 100 which is much higher than the number of features. In general, wouldn't be more logical to set the number of units to the number of input features? What is the advantage of having a number of units higher than the number of features? And what does it intuitively mean? My code: series = array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) n_features = 1 series = series.reshape((len(series), n_features)) n_input = 2 generator = TimeseriesGenerator(series, series, length=n_input, batch_size=8) model = Sequential() model.add(LSTM(100, activation='relu', input_shape=(n_input, n_features))) model.add(Dense(1)) model.compile(optimizer='adam', loss='mse')
