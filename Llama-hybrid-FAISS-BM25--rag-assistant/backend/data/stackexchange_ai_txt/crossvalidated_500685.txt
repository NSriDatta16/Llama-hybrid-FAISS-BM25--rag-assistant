[site]: crossvalidated
[post_id]: 500685
[parent_id]: 
[tags]: 
Can missing values linked with outcome variable be a source of bias in machine learning

Background: In a binary classification problem (healthy vs. patients), I have a relatively small sample size (40 patients and 40 healthy subjects). I can include some additional subjects in both the groups but some of the features might be missing in these additional subjects. The missing values are not randomly distributed; the patient group, in general, tends to have more missing values than healthy subjects on an average. One of my professors suggested using boosted trees (xgboost) or other decision trees methods (random forest) as they can handle missing data and therefore my overall sample size would increase. My concern with this is that the classifier might end up learning this bias of more missing values in the patient group. I have not seen any discussions on whether these tree methods can learn missing values as a "feature" itself. Perhaps I am missing some keywords? My intuition would be to avoid any systematic difference between the groups (which is not related to healthy/patient labels) out of the picture. Additional information: My features come from multiple kinds of tests/assessments that individuals go through. Each test would give me ~50-80 features and there are 5 tests. The missing information arises from the fact that patients may not cooperate for one or two of these 5 tests. The probability of the label being a patient if the data of one or two tests are missing is quite high. Question: Can tree-based methods (or other ML methods in general) learn these kinds of systematic differences or are my concerns trivial? Are there ways to deal with these (except for not considering those subjects who have missing data)?
