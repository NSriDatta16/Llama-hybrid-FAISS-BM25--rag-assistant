[site]: stackoverflow
[post_id]: 5647265
[parent_id]: 
[tags]: 
Help me solve this bug with my ray tracer

I'm not going to post any code for this question because it would require way too much context, but I shall explain conceptually what I'm doing. I'm building a simple ray tracer that uses affine transformations. What I mean is that I'm intersecting all rays from camera coordinates with generic shapes. The shapes all have associated affine transformations, and the rays are first multiplied by the inverses of these transformations before intersecting with scene objects. So for example, say I wanted a sphere of radius 3 positioned at (10,10,10). I create the sphere and give it a transformation matrix representing this transformation. I create a ray in camera coordinates. I multiply the ray by the inverse of the sphere's transformation matrix and intersect it with the generic sphere (r=1 at (0,0,0)). I take the distance along this generic ray at the intersection point and using it I find the generic normal and the point along the original ray and save these into a Transformation object (along with the distance (t) and the actual transformation). When it comes time to figure out the colour of this intersection point I take the transformation's inverse transpose and multiply it by the generic normal to find the normal. The point of intersection is just the point along the original non-transformed ray if I use the t value from the intersection of the inverse transformed ray. The problem is, when I do things this way the transformations have weird effects. The main effect is that transformations seem to drag lights from the scene along with them. If I build a bunch of images and apply a slightly larger rotation to the sphere with each frame, it seems to drag the lights in the scene around with it. Here's an example I honestly cannot figure out what I'm doing wrong here, but I'm tearing my hair out. I can't think of any good reason whatsoever for this to be happening. Any help would be hugely appreciated.
