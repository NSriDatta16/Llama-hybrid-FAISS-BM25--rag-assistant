[site]: crossvalidated
[post_id]: 390980
[parent_id]: 
[tags]: 
Does this mean my model is useless?

Long story short, I have a random forest I've created. It's mean absolute error is .209 for the test set. The (scaled) standard deviation of the y column is .201 (for all the y column data, not just test set). I have a decent grasp of statistics, but I'm not sure if this means that my model is basically worse than just taking a random value +/- .2 from the mean of the y column? Or has my scaling made these values incomparable? The actual SD of the y column is 4.388494. Shouldn't MAE be lower than SD? Some explanation, hopefully intuitive, as to why that's not necessarily true (if I'm wrong) would be appreciated, or an answer for the general case if I shouldn't be comparing the scaled sd to my MAE.
