[site]: crossvalidated
[post_id]: 142365
[parent_id]: 
[tags]: 
A continuous generalization of the binary bandit

There is plenty of reading out there about Bayesian (beta-binomial) multiarm bandits for 0/1 data, but I would like to extend this slightly. To give some context, suppose I have two webpages, A and B. Now I want to test which webpage gets more people to call in, so I begin by randomly serving A, B to incoming visitors. This is equivalent to starting with the same beta priors on A, B - either $\text{prior}_A = \text{prior}_B = \mathrm{Beta}(0,0)$ aka uninformed or some $\mathrm{Beta}(k_1, k_2)$ for both. As the binary data comes in (either people call or they don't), I update according to Bayes' Rule and so I end up with $\text{posterior}_A = \mathrm{Beta}(k_1 + \text{wins}_A, k_2 + \text{trials}_A - \text{wins}_A)$ and similarly for B. Here a trial is me serving the visitor a webpage and a success is a call, to be clear. My Question What is the continuous analogue of this binary data model? That is, if my data coming in is now of the form $0.5, 1.6, 8.95$ etc., what can I use to optimize which is better A or B? I have looked into Gaussian processes a little bit but I'm not sure this is what I want. Thanks for any help. An extension to this question may be found here .
