[site]: crossvalidated
[post_id]: 303014
[parent_id]: 302917
[tags]: 
I have been trying to create a simple example case to clarify the situation of your problem. For this example case I have used a logistic model $\pi(x) = \frac{1}{1+e^{-a(x+b)}}$ with $a=1$, $b=0$ and $x = N(0,2)$ # model_pars a = 1 b = 0 # x-dist_pars xmu = 0 xv = 2 # discretezation_pars np = 200 # random measured data set.seed(1) x bins))+1))# find out bin number by counting number of smaller bins nk0 resulting in the following frequency distribution > nk0 [1] 25 7 19 15 10 7 6 2 3 4 > nk1 [1] 2 1 4 6 17 7 15 14 9 27 > then using 100 times a Monte Carlo simulation (pretending that $-a(x+b)$ depends, as you mention, on complex machinery such as neural networks or whatever, and requires MC rather then direct calculation) changing the parameter $a$ and keeping fixed $b$, $\mu_x$, $\sigma_x$, results in the following graphs. The graphs in the array display the change of the single terms for the $\chi(mc=i,bin=j) = \sqrt{\frac{(N_{Data,j}-N_{MC,i,j})^2}{N_{Data,j}}}$ (I used $N_{data}$ for the deviations in the denominator.) with $i$ and $j$ varying in the columns and rows of the graph. The larger graph in the lower left corner shows an average of the terms over different number of MC simulations. I believe it is interesting to have a graphical display of the origin of the jitter. At first I assumed that you were change the random parameters for each repetition of your Monte Carlo simulation and this would cause large variations that look like jitter. Now, the image shows that you can get this jitter from other sources as well. As you mentioned while changing the nuisance parameter causes observations to move from one bin to another. You see this in the single terms changing in steps. What is important for jitter is that you can have alternating steps up and down. While one parameter goes down another goes up. This creates jitter without a need for the single terms having jitter (if the single terms have jitter the problem becomes larger). I wonder if jitter is really the key problem. It is more a symptom of the deviation between the MC simulations and the theoretic frequencies. It is this deviation that seems most troubling to me. See for instance the change of the curves in the figure when the number of MC simulations is increased. It is not the jitter that is so much a problem here, and it is much more the variation among different simulations. Note 1: You mention that you currently have no information about the error of the simulations ("I do not know the error on the Chi-square itself"). Does this mean that you perform only a single simulation (with varying nuisance parameter)? You don't have multiple $N_{MC}$ for fixed nuisance that allows you to estimate variation of your $\chi$ parameter and terms for each bin and $\chi^2$? How much trouble would it be to perform the scan with lower accuracy and use the gain in computation time to perform multiple simulations in order to estimate the variation between different simulations at the same point in the parameter space? Maybe I am getting something incorrect. Could you better describe your Monte Carlo simulation? Number of simulations, change of parameters and random numbers, etc. Add some graphs. Note 2: Another note. You may get more jitter when changing particular parameters. But, eventually the error of the MC simulation is, around the same point, the same for all parameters (and it is just that the simulation error manifests in more or less jitter depending on the parameter that is being scanned).
