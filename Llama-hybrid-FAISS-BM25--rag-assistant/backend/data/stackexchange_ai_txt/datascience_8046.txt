[site]: datascience
[post_id]: 8046
[parent_id]: 
[tags]: 
Random Forest Class Weighting for Logistic Probabilities

I have a model at work that I am building and am running into some odd outputs from the random forest as it pertains to the probability of response. In my case, the class distributions are very unbalanced, around 45000 records in my training data, and only 300 are responders. So I took a smaller sample of the non-responders, 1000, so that my training data was 1300 total. This worked well, but it appears like the outputted predicted probability needs to be adjusted in some way given that I altered the distribution of the classes. When I create a gains table, the predicted response rate of the first decile comes out at 50%, but it should be around 2%. I dont have this problem with running an xgboost model with all training variables. I know that in traditional logistic regression, you can weight the classes if you take a smaller sample so that it can accordingly adjust the predicted probability. Is there a way using random forest to solve this problem?
