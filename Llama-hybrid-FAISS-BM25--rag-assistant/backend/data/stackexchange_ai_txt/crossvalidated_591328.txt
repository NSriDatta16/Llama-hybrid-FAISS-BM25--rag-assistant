[site]: crossvalidated
[post_id]: 591328
[parent_id]: 
[tags]: 
Hierarchical Bayesian modeling with count data (PYMC): how to specify this model?

I'm completely new to Bayesian statistics and tried to get a grasp of the fundamentals for a specific case I'm working on. However, I feel like I've led myself down a blind alley and I'm still struggling with defining the model. So, here's the use case in a nutshell: I'd like to build a model that predicts delivery time of particular products (coming from specific suppliers). I have: A prediction the supplier gives us whenever we place a specific order. Some suppliers' predictions are worthless, others are quite predictive. An exponentially weighted mean of past deliveries for the specific product we're ordering. Again, sometimes past deliveries are highly predictive for the delivery time; while sometimes the suppliers' prediction for the specific order is a better estimate. It is worth noting that I already adjusted the delivery time distribution: there are almost no deliveries with a delivery time less than 2 workdays, so I subtracted 2 workdays from the delivery time variable with a floor of 0. In other words, I'd like to weigh past performance vs current predictions differently for each supplier in a partially pooled (i.e. hierarchical) model . All of the variables are count data (poisson distributed), with variance > mean, so my first guess is to estimate this using a negative binomial distribution. Some suppliers have a delivery time distribution that is somewhat zero-inflated (as in: they tend to deliver in 2 workdays), while others experience a peak only after 5 workdays, with very little deliveries with I want to start with a straightforward model containing: A group-specific intercept (i.e. a different 'starting point' for each and every supplier; since some suppliers tend to deliver the goods in e.g. 3 workdays, while others tend to deliver goods in 7 workdays,etc.) (supplier membership is indicated by the 'levnr_idx' dimension in the model below) A group-specific slope for the suppliers' prediction ( 'first_eda' in the model below) To predict the delivery time ( 'delivery_time_adj' in the model below) However, I have a feeling the model is not correctly specified. It takes a really long time to fit for the NUTS sampler; and I tend to get divergences. Am I doing something wrong here? with pm.Model(coords=coords) as model: levnr_idx = pm.Data("levnr_idx", levnr_idxs, dims="obs_id", mutable=True) first_eda = pm.Data("first_eda", model_sel_train.first_eda_delivery_time, dims="obs_id", mutable=True) # Hyperpriors: a = pm.Normal("a", mu=np.log(6), sigma=np.log(3)) sigma_a = pm.Normal("sigma_a",mu=np.log(3),sigma=np.log(2)) b = pm.Normal("b", mu=0, sigma=5) sigma_b = pm.Normal("sigma_b",mu=0, sigma=5) # Supplier-specific intercept a_levnr = pm.Normal("a_levnr",mu=a,sigma=sigma_a,dims='levnr') # Effect 1: Supplier specific slope for EDA b_levnr = pm.Normal("b_levnr",mu=b,sigma=sigma_b,dims='levnr') alpha = pm.Exponential("alpha",2.0) deltime_est = pm.math.exp(a+a_levnr[levnr_idx]*sigma_a) + ((b+b_levnr[levnr_idx]*sigma_b) * first_eda) #exp because negative binomial distribution >= 0 # Data likelihood deltime_like = pm.NegativeBinomial("deltime_like", mu=deltime_est, alpha=alpha, observed=model_sel_train.delivery_time_adj.values,dims="obs_id") Moreover, when doing a posterior check; it's obvious that: The model does seem to do something right: the correlation between predicted and observed is 0.6 But the model's prediction is never zero; the posterior distribution starts at 1 (see image below). It doesn't look like I need to transform the prediction in one way or another (I take an exp of the parameters in the model to arrive at an estimation; but this shouldn't be an issue here). It really looks as if the zero-predictions are 'missing' somehow. The question is: why? And how do I fix this? Thanks in advance!
