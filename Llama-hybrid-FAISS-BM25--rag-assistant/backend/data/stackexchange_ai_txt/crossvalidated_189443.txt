[site]: crossvalidated
[post_id]: 189443
[parent_id]: 
[tags]: 
Shifting input over image for CNN object detection?

I've got a CNN which is trained supervised and calculates if a specific object is present in an image. Since I am interested in the object's position in the image I tried to alter my architecture so that it not only calculates the presence of an object but also its location. However, as I am very new to this field, I am not sure if my attempt is a "good" idea or even sufficient for my interests. My architecture simply "grids" the image into $n * n$ grids, so rather than always classifying the whole image, the CNN only gets one grid at a time as input. Hence, I can take the grid with the highest probability and it's location for locating an object. The CNN is a "standard" CNN: 5 layers with convolution and max pooling layers. I am using ReLUs for each layer as well as dropout. This is followed by a fully-connected layer at the end for classification. Since training my network takes quite a lot of time I have no "complete" results so far. First experiments showed a moderate object detection performance. Especially when the object is relatively small or too big (and therefore overlapping on several grids) the performance is bad. Are there any tricks to boost the performance? Since I am a beginner I guess there are multiple ways to improve my architecture? Or would another architecture be a better way? Is shifting the input grid even a good idea for locating an object?
