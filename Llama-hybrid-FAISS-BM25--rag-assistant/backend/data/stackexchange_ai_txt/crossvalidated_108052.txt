[site]: crossvalidated
[post_id]: 108052
[parent_id]: 
[tags]: 
Olive Dunn (1964) created a post hoc pairwise multiple comparisons procedure appropriate to follow the rejection of a Kruskal–Wallis test . The Kruskal–Wallis test, being a non-parametric analog of the one-way ANOVA , is an omnibus test of the null hypothesis that none of $k$ groups stochastically dominate one another: $\text{H}_{0}\mathbb{: P}\left(X_A > X_B\right) = 0.5$ for all $A,B \in 1,\dots,k$ , $\text{H}_\text{A}\mathbb{: P}\left(X_A > X_B\right) \ne 0.5$ for at least one $A\ne B$ The test is constructed in part by summing jointly ranked data. The rank sum test , itself a non-parametric analog of the unpaired t -test, is possibly intuitive, but inappropriate as a post hoc pairwise test, because (1) it fails to retain the dependent ranking that produced the Kruskal–Wallis test statistic, and (2) it does not incorporate the pooled variance estimate implied by the null hypothesis of the Kruskal–Wallis test. Dunn's test statistic is a normal approximation to the exact rank sum test statistics. From the prior Kruskal–Wallis test, it uses the average rankings test for each group's score to infer difference of mean rankings in each group. Let $W_{i}$ and $n_{i}$ be the $i^{\text{th}}$ group's summed ranks and sample size, respectively. Assign any tied values the average of the ranks they would have received had they not been tied (e.g., the value 2 in the list (1, 2, 2, 3) has rank 2.5). The input to the test is the per-group average rank, $\overline{W}_{i}=W_{i}/n_{i}$ The test statistic for the groups $A$ and $B$ is calculated as follows: $$z_{A,B} = \frac{\overline{W}_{A}-\overline{W}_{B}}{\sigma_{A,B}}$$ where: $\sigma_{A,B}=\sqrt{\left[\frac{N\left(N+1\right)}{12}-\frac{\sum_{s=1}^{r}{\tau^{3}_{s}-\tau_{s}}}{12\left(N-1\right)}\right]\left(\frac{1}{n_{A}}+\frac{1}{n_{B}}\right)}$ ; $N=\sum_{i=1}^{k}{n_{i}}$ is the total sample size of the $k$ groups, $r$ is the number of tied ranks across all $k$ groups, and $\tau_{s}$ is the number of observations across all $k$ groups with the $s^{\text{th}}$ tied rank. The issue of multiple comparisons changes the meaning of $\alpha$ (desired Type I error rate). Dunn was an early thinker about making adjustments/corrections for family-wise error rates (1961), and these or false discovery rate corrections are appropriate for Dunn's test. Dunn's test with corrections for ties is implemented in the R dunn.test package. References Dunn, O. J. (1961). Multiple comparisons among means. Journal of the American Statistical Association , 56(293):52–64. Dunn, O. J. (1964). Multiple comparisons using rank sums. Technometrics , 6(3):241–252.
