[site]: crossvalidated
[post_id]: 413859
[parent_id]: 413640
[tags]: 
What is nice is that regardless of how you allocate the students to the classes, as long as you randomly assign the classes to treatment, your effect estimate will be free of confounding. Ideally, though, you want the class composition to be the same on average between the treatment groups (i.e., for the distribution of baseline skill to be the same across treated classrooms as across control classrooms). Here's one way you could do this: Perform a match on students with respect to baseline skill. That means for each student, find a student with similar baseline skill and make them a pair. You could try to minimize some global measure of pairwise imbalance to ensure no one is paired with someone too different from them. For example, if you were to use a greedy algorithm, the first students to be paired would be paired with students close to them, while the last students to be paired will have to be paired with whoever is left, who might not be so close. An optimal matching algorithm might instead yield a set of pairs for which the distance between each member is small on average, and large distance are penalized. One member of each pair will eventually go to treatment and the other to control. This type of matching (i.e., before treatment has been assigned) is called non-bipartite matching. There are a few software packages that can do this. One I found is the nbpMatching R package. I believe the designmatch R package can do this as well. Once you have your matched pairs, we want to assign the pairs into classroom blocks. It doesn't really matter how this is done because the treatment effect will be unbiased regardless, but to reduce the within-classroom treatment effect variability you could create strata of the pairs based on average pairwise baseline skill and then make each stratum (or randomly slices block of a stratum) into a classroom-block. This way, each classroom-block will contain pairs roughly homogeneous in baseline skill level. Within each classroom block, randomly assign one member of each pair to treatment and the other to control. The treated students become their own classroom and the control students become their own classroom (i.e., each classroom-block splits into two classrooms, one treated and the other control). The value of this design is that it makes extensive use of pairing and stratification. Students are cross-classified both into student-pairs and classrooms. Because the students within pairs are similar to each other, conditioning on pair membership in the analysis will greatly improve the precision of your effect estimate. Likewise, because classrooms within classroom-blocks are similar to each other, conditioning on classroom-block membership will improve the precision of the estimate. Allowing the treatment effect to vary across classroom-blocks also allows you to assess the extent to which the average classroom-level baseline skill might change the treatment effect. Your final analysis could be a multilevel model with student performance as the outcome, a random effect for student-pairs, fixed or random effects for classrooms, fixed effects for classroom-blocks, and a treatment by classroom-block interaction. The effect of treatment overall could be computed as the average of the classroom-block-specific treatment effects, and you can use the classroom-block-specific treatment effect to assess the degree to which the treatment effect varies across classrooms with different levels of average baseline skill. If that seems like too much, you can run a GEE or regression model of the outcome on treatment alone (or with some fixed effects) that accounts for the pairing and nesting within classrooms and classroom-blocks using cluster-robust standard errors. No matter what analysis you perform, as long as you are comparing the treatment group means, you effect estimate will be unbiased. All this design stuff is just a matter of improving precision and adding interpretational benefits.
