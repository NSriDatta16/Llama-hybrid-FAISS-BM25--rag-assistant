[site]: crossvalidated
[post_id]: 51941
[parent_id]: 51736
[tags]: 
What about an estimator which is an average over its closest k neighbors with the weights given to the neighbors decreasing with distance from the target point. The right taper for the weights could be fit beforehand using some sort of error minimization training scheme? Alternatively, I was thinking of a Voronoi tessalation. For a point of interest find its Voronoi cell and add in the effect of next-neighbor cells with a reduced weight and so on? Too simplistic? PS. Would there be a chance that the Income (say) at a location is better predicted by $fn(income, age, sex)$ of its neighbors than by merely $fn(income)$ of its neighbors? In essence, can mixing predictors get a better predictive model than keeping them separate? In the extreme could one ever have a situation where neighbor age alone was a better predictor of a points income than neighbor income? Just wondering.
