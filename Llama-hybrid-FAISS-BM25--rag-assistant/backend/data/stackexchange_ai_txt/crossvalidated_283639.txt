[site]: crossvalidated
[post_id]: 283639
[parent_id]: 258614
[tags]: 
Your question touches on two topics: Preprocessing of the data. Initialization of weights. For this question there are already good answers: What are good initial weights in a neural network? . As for the first question, I shall refer to the paper: LeCun et al., Efficient Backprop , section 4.3. It is explained in great detail, among other issues about training. Nevertheless, some practices have changed since then. For example, ReLus have replaced tanh and sigmoids.
