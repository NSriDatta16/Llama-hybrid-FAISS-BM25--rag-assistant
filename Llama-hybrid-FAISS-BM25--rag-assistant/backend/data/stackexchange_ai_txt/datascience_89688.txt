[site]: datascience
[post_id]: 89688
[parent_id]: 
[tags]: 
Reinforcement Learning model always gives different output

I am trying to build a reinforcement learning model for hardware capacity optimisation. The state of the model would input like CPU capacity utilisation, memory utilisation. The model is supposed to predict what should be the CPU, memory etc I need to provision for my environment. The model uses DQN at its core and reward mechanism is based on the current capacity used. The challenge I have is that every time I run with same input state and reward mechanism, I am getting different combination of hardware to be provisioned. Is it possible that RL might give different output for same set of inputs and reward?
