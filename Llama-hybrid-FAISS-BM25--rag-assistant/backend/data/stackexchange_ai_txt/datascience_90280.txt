[site]: datascience
[post_id]: 90280
[parent_id]: 82808
[tags]: 
RNN is not able to retain memory that are from far back in the past because of the vanishing gradient problem (i.e. the gradient from backpropagation is unable to reach the earlier states). This is a limitation of the model itself. Thus, we need to introduce a more powerful model, i.e. lowering the bias (in the expense of increasing the variance). Introducing the cell state into the LSTM cells actually increased the complexity of the model. As you know, increasing complexity will usually increase variance and decrease bias. The cell state acts as a highway in order for the gradient to flow better to the earlier states, which in turn allows the model to capture memory that are further back in the past.
