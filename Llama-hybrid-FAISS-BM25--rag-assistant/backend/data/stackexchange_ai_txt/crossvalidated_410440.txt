[site]: crossvalidated
[post_id]: 410440
[parent_id]: 
[tags]: 
What does it mean when the global gradient norm keeps decreasing while loss has converged?

I am training an autoencoder with a $L^2$ loss. Training gives reasonable results and the loss quickly converge to a non-zero but acceptable value after about 5 epochs: However, looking at the "global gradient norm" (the norm of the gradient with respect to all model parameters), I see that it keeps decreasing after the loss seemingly converged. I am surprised because I expected that a flatlining loss would imply that the model converged, or at least that the model hops and buzzes between equivalent places of the parameters. But it seems it is still evolving to non-equivalent models, meaning that the optimization is still proceeding even though the loss has flatlined. How to interpret those findings?
