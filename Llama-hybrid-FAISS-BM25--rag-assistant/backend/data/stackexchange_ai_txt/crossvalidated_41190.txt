[site]: crossvalidated
[post_id]: 41190
[parent_id]: 
[tags]: 
libSVM for unbalanced data

I'm using libSVM for binary classification and my training data is very unbalanced (-1:90%, +1:10%). According to libSVM's documentation, it's better to set different penalties for positive and negative classes. For example, the SVM problem is: $\min\limits_{w,b,\xi} \frac{1}{2}{\bf w^Tw} + C^+\sum\limits_{y_i=1} \xi_i + C^-\sum\limits_{y_i=-1} \xi_i$ My question is which penalty should be larger and why. Thanks
