[site]: datascience
[post_id]: 64321
[parent_id]: 64312
[tags]: 
Welcome to the community! In text-related tasks, DL have shown amazing breakthrough e.g. in NLU for reading comprehension or question answering . If you have heard about Google's BERT , that was one of big steps which, to some extent, pushed the boundaries of SOTA in NLP/NLU last year and currently, a heavy wave is going on doing research on different NLP/NLU tasks mostly based on either the idea coming from BERT or directly from its pretrained models. The quora QA dataset , SQuAD dataset , etc. are great starting points to play with bert and its successors and see how great the idea was. Hope it helps!
