[site]: crossvalidated
[post_id]: 517234
[parent_id]: 517159
[tags]: 
I got my answer in the data science community so I figured I'd share it here for visibility as well. Thanks to user @Erwan Answer link To summarize it I'll say the following: You can try pooling: "pool" together all the predictions from each round of testing, and compute the metrics once over these pooled predictions Basically you could just keep a list of the predictions and true values for each test set. Then after testing for each patient, combine all sets of predictions and true values together and produce one confusion matrix at the end containing the combined predictions and true values from all patients. Then you'll be able to calculate accuracy, recall, and precision
