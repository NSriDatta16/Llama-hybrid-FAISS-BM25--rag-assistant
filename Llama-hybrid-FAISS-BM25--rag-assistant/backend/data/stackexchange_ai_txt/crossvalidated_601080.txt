[site]: crossvalidated
[post_id]: 601080
[parent_id]: 600616
[tags]: 
In some literature the term "plausible" for parameters is used synonymously with "high likelihood". The idea is in principle the same as the idea behind statistical tests: Parameters are implausible for the observed data if under the parameter these data are very unlikely, measured by the likelihood. This is the starting point for basing inference about parameters as exclusively as possible on the likelihood, as advocated by some authors, e.g., famously, A. W. F. Edwards in his book "Likelihood". There is also Birnbaum's proof of the Likelihood Principle, often interpreted as "all evidential information about the parameter from the data is in the likelihood function" (which has been challenged, I think convincingly, by Evans, Fraser, Mayo and others). In this spirit, if the "relative likelihood" of a parameter value is very low compared to the maximum likelihood, it means that the parameter value is far less plausible than the maximum likelihood estimator. Obviously even if we subscribe to this view, there needs to be a somewhat arbitrary definition of a cutoff value between "plausible" and "implausible" if we want to use these terms in a binary manner. The idea behind the likelihood-based CI is apparently to say that a parameter value is "too implausible" if its likelihood is so low, compared to the ML estimator, that it doesn't belong to a CI defined based on large likelihood only (which then is relative to the chosen confidence level). Bringing this together with the meaning of CIs with level $\beta=1-\alpha$ , it means that for repeated experiments, only with probability $\alpha$ (say 0.01) a true parameter value will be declared "implausible". Note however that the very definition of CIs runs to some extent counter to the likelihood "philosophy", as it relies on the sampling characteristics of the CI computation method, which are not comprehensively covered by the likelihood function (opponents of frequentist inference, particularly Bayesians, have occasionally used this argument against CIs, whereas frequentists have used it against the Likelihood Principle). Regarding the originally cited paper, claiming as an advantage of the likelihood method for computing a CI that it coincides with "plausibility" is somewhat circular as the likelihood method does this by definition as far as plausibility doesn't mean anything else than "high likelihood". It is, if you want, not an additional feature of the likelihood method beyond its definition. However, this feature still gives the likelihood method some intuitive appeal.
