[site]: crossvalidated
[post_id]: 638871
[parent_id]: 
[tags]: 
Sample size in simulation and stopping criteria

I want to estimate the average of a random variable by simulation. Also, I want to estimate a proportion by simulation. I know that there are formulas to calculate the minimum sample size so that the estimated value is closer than $e$ units to the real value, with (at least) $1-\alpha$ probability. They are the typical formulas used to calculate sample sizes in parametric inference. And I think they are OK. However, I also remember, from my university days, using different stopping criteria when applying an iterative algorithm aimed at giving a final value as a result (e.g., root finding algorithms). For instance, I remember setting a stopping condition based on the absolute or relative difference between the values returned by two consecutive iterations. Example: Let $\bar{x}_{n}$ be the average of the $n$ first simulated values. Assuming that I want to estimate $\mu$ , the population average, I would stop the simulation when $\left| \bar{x}_{n} - \bar{x}_{n-1}\right| , for a given $e$ as small as needed. Also, a stopping condition based on the relative difference could be used (i.e., stop when $\left| ( \bar{x}_{n} - \bar{x}_{n-1}) / \bar{x}_{n-1} \right| ). I vaguely remember that this approach presents some issues. For instance, despite the fact that the (absolute) difference between $\bar{x}_{n}$ and $\bar{x}_{n-1}$ can be small, if it is always positive or always negative for $n$ , $n+1$ , $n+2$ , etc., this could mean that we are not yet close enough to the value we want to estimate, but that the estimation is 'moving' very slowly towards it. In other words, the fact that $\left| \bar{x}_{n} - \bar{x}_{n-1}\right| does not necessarily imply that $\left| \bar{x}_{n} - \mu \right| (obviously). So, I am asking for some expert advice here. Are these stopping criteria I just mentioned too na√Øve? When can I use them? Is there any stopping criteria commonly used to decide when an algorithm has 'converged enough', based, for instance, on the deceleration of the successive approximations or estimations...? EDIT Just to make it clearer (I hope), I am interested in (Monte-Carlo) simulation (but not Markov-Chain simulation). I am also interested in knowing when to stop the simulation, so that a given accuracy (closeness to the true value) can be guaranteed. I thought that an approach similar to the stopping criteria for iterative algorithms could be applied here.
