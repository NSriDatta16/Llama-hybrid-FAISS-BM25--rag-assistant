[site]: crossvalidated
[post_id]: 6271
[parent_id]: 2691
[tags]: 
Why so eigenvalues/eigenvectors ? When doing PCA, you want to compute some orthogonal basis by maximizing the projected variance on each basis vector. Having computed previous basis vectors, you want the next one to be: orthogonal to the previous norm 1 maximizing projected variance, i.e with maximal covariance norm This is a constrained optimization problem, and the Lagrange multipliers (here's for the geometric intuition, see wikipedia page) tell you that the gradients of the objective (projected variance) and the constraint (unit norm) should be "parallel" at the optimium. This is the same as saying that the next basis vector should be an eigenvector of the covariance matrix. The best choice at each step is to pick the one with the largest eigenvalue among the remaining ones.
