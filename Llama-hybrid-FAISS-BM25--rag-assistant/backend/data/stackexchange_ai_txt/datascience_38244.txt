[site]: datascience
[post_id]: 38244
[parent_id]: 
[tags]: 
How to interpret my neural network with high accuracy but low probability in test results

I have built a classical ANN using keras which provides probability (using sigmoid function) of the outcomes (0 or 1). While the accuracy of the model is high when the model is fit ~90%, the outcome probability of the test set results is very poor. How can I interpret this? Build ANN classifier = Sequential() classifier.add(Dense(activation="relu",input_dim=7,kernel_initializer="uniform", units = 4)) classifier.add(Dense(activation="relu",kernel_initializer="uniform", units = 4)) classifier.add(Dense(activation="sigmoid", kernel_initializer="uniform", units = 1)) classifier.compile(optimizer="adam", loss="binary_crossentropy",metrics=['accuracy']) classifier.fit(X_train,y_train, batch_size=10,epochs=100) Predict results: y_pred = classifier.predict(X_test) I have attached the test set results where result probabilities can be seen with respect to frequency. blue shows probabilities for 1 and orange for 0 Is this a case of overfitting? How can I tweak an ann to avoid overfitting?
