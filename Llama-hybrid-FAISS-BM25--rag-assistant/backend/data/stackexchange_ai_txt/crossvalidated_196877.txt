[site]: crossvalidated
[post_id]: 196877
[parent_id]: 
[tags]: 
Can the Bayes Optimal Predictor be generalized?

I'm reading Understanding Machine Learning by Shai and Shai. In it, the Bayes Optimal Predictor is defined as $$f_{\mathcal{D}}(x) = \mathbb{1}[\mathbb{P}[y = 1 | x] \geq 1/2]$$ Where $\mathcal{D}$ is any probability distribution over $\mathcal{X} \times \{0,1\}$ . This seems to be true of all binary classifiers. Can this be applied to other classes of tasks (e.g., regression)? Intuitively it would make sense for the regression case to be $$f_{\mathcal{D}}(x) = c\cdot\mathbb{1}[\mathbb{P}[y = c | x] \geq 1/2],$$ but I'm not sure this is true.
