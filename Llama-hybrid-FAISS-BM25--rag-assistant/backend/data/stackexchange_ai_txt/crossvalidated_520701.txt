[site]: crossvalidated
[post_id]: 520701
[parent_id]: 520577
[tags]: 
My view may be a bit unorthodox, but for me, a confidence interval (and similar uncertainty measurements) is for telling me what I cannot do with a number. We people like thinking in numbers (at least in positive integers and decimals). We use them everyday, to the point where we don't even notice the operations we are doing with them, as long as we don't have to pull out a calculator. And in this intuitive, super-easy use, we forgot that numbers are only a representation of the real thing, and sometimes the answer we get by number manipulation is not the answer we are looking for. Confidence intervals can help us avoid some specific misapplications of numbers. First example: Measurement. I have a kitchen scale whose product description proclaims an accuracy of 2 grams. Let's assume that this statement means that, if I measure out 1 kg of sugar every day to make jam, on 99% of days the actual amount of sugar will be between 998 and 1002 grams, so this is a roundabout way to state a confidence interval about the results of repeated uses of the scale. This is quite sufficient for making great jam, but not at all sufficient if I want to measure 4 grams of gelatin, because using 2 or 6 grams instead of 4 will likely make a recipe fail. So, by knowing the width of the confidence interval, I know that my scale is useless for a certain kind of ingredient. Second example: Comparison. Let's say that somebody publishes an article on the caffeine content of types of tea, and describes that the average cup of black tea has 39.4 mg of caffeine, while the average cup of green tea has 31.8 mg. Newspapers articles and nutrition guides shorten the information "green tea has less caffeine than black tea" and people who want to reduce their caffeine intake may decide to switch their tea. But if you look into the original research, you are likely to see a confidence interval of 30 to 50 mg for green tea and 25 to 60 mg for black tea*. These are very wide intervals, and they overlap a lot. If you were to switch from black tea to green tea, there is quite a good chance that your caffeine intake may go up instead of down. This makes the conclusion "black tea has more caffeine than green tea" incorrect, at least the way it is understood in everyday communication - but you cannot know that until you have looked at the confidence intervals. Third example. Let's leave the kitchen and look at something a real statistician might do - calculate an odds ratio from a medical study. These calculations are quite important, with huge consequences for approval, or at least warnings that affect prescription patterns. Let's say that on a new medicine, the odds ratio for myocardial infarction is 1.7 for women under 30, 1.2 for men aged 50-65, and quite close to one for all other groups. Now what should the regulator do? If you don't look at the confidence intervals, you might think that a warning against prescription should be issued for both groups, or at least for the women. But it may turn out that the correct thing is to issue a warning for the men, but not for the young women - if it so happens that the confidence interval for the young women crosses the 1, but that for men is tighter and is completely above one, meaning that we can be quite certain their risk is indeed higher when on the medicine. In this case, we are not allowed to make a policy decision based on the huge-looking 1.7 odds ratio - but we can only know this when using the confidence interval. These examples are somewhat randomly picked, I am sure that there are more, or better ones. But in a nutshell, when you start looking at confidence intervals (without even doing fancy calculations with them), you can save yourself from some serious mistakes in interpretation. * In reality, this type of study is most likely to simply report the range observed in the tested samples, but for the sake of argument, let's assume the authors actually calculated confidence intervals
