[site]: crossvalidated
[post_id]: 307483
[parent_id]: 54525
[tags]: 
(The answers by @Sjoerd C. de Vries and @Hrishekesh Ganu are correct. I thought I could nonetheless present the ideas another way, which may help some people.) You can get a ROC like that if your model is misspecified. Consider the example below (coded in R ), which is adapted from my answer here: How to use boxplots to find the point where values are more likely to come from different conditions? ## data Cond.1 = c(2.9, 3.0, 3.1, 3.1, 3.1, 3.3, 3.3, 3.4, 3.4, 3.4, 3.5, 3.5, 3.6, 3.7, 3.7, 3.8, 3.8, 3.8, 3.8, 3.9, 4.0, 4.0, 4.1, 4.1, 4.2, 4.4, 4.5, 4.5, 4.5, 4.6, 4.6, 4.6, 4.7, 4.8, 4.9, 4.9, 5.5, 5.5, 5.7) Cond.2 = c(2.3, 2.4, 2.6, 3.1, 3.7, 3.7, 3.8, 4.0, 4.2, 4.8, 4.9, 5.5, 5.5, 5.5, 5.7, 5.8, 5.9, 5.9, 6.0, 6.0, 6.1, 6.1, 6.3, 6.5, 6.7, 6.8, 6.9, 7.1, 7.1, 7.1, 7.2, 7.2, 7.4, 7.5, 7.6, 7.6, 10, 10.1, 12.5) dat = stack(list(cond1=Cond.1, cond2=Cond.2)) ord = order(dat$values) dat = dat[ord,] # now the data are sorted ## logistic regression models lr.model1 = glm(ind~values, dat, family="binomial") # w/o a squared term lr.model2 = glm(ind~values+I(values^2), dat, family="binomial") # w/ a squared term lr.preds1 = predict(lr.model1, data.frame(values=seq(2.3,12.5,by=.1)), type="response") lr.preds2 = predict(lr.model2, data.frame(values=seq(2.3,12.5,by=.1)), type="response") ## here I plot the data & the 2 models windows() with(dat, plot(values, ifelse(ind=="cond2",1,0), ylab="predicted probability of condition2")) lines(seq(2.3,12.5,by=.1), lr.preds1, lwd=2, col="red") lines(seq(2.3,12.5,by=.1), lr.preds2, lwd=2, col="blue") legend("bottomright", legend=c("model 1", "model 2"), lwd=2, col=c("red", "blue")) It's easy to see that the red model is missing the structure of the data. We can see what the ROC curves look like when plotted below: library(ROCR) # we'll use this package to make the ROC curve ## these are necessary to make the ROC curves pred1 = with(dat, prediction(fitted(lr.model1), ind)) pred2 = with(dat, prediction(fitted(lr.model2), ind)) perf1 = performance(pred1, "tpr", "fpr") perf2 = performance(pred2, "tpr", "fpr") ## here I plot the ROC curves windows() plot(perf1, col="red", lwd=2) plot(perf2, col="blue", lwd=2, add=T) abline(0,1, col="gray") legend("bottomright", legend=c("model 1", "model 2"), lwd=2, col=c("red", "blue")) We can now see that, for the misspecified (red) model, when the false positive rate becomes greater than $80\%$, the false positive rate increases more quickly than the true positive rate. Looking at the models above, we see that that point is where the red and blue lines cross at the lower left.
