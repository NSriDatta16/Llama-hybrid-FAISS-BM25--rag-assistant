[site]: crossvalidated
[post_id]: 411172
[parent_id]: 411128
[tags]: 
Autocorrelation (also called serial correlation) occurs when the errors are correlated across time; it is a violation of the classical assumption that the errors are independent of each other, i.e., it means that our sample is not random. Stated more formally, we say that correlation exists in a regression model if the following equation is violated: $$ Corr(u_t,u_s|\boldsymbol{X}) = 0, \forall t \ne s. $$ This equation reads as, conditional on the values of explanatory variables, the errors in two different time periods are uncorrelated ( $\forall$ means "for all"). Autocorrelation is a common problem in regressions that have a time-series component (either time series models or longitudinal models). There are two problems associated with autocorrelation of errors: It may indicate that a relevant independent variable is missing from the model, which can result in biased estimates of coefficients for other explanatory variables in the model. If you have information that allows you to predict the error term for an observation, you need to incorporate that information into the model itself. It reduces the precision of coefficient estimates. It makes the estimated standard errors returned by the OLS method too small, and therefore makes the t-statistics larger than they should be. The misleadingly large t-statistics can make you think that a slope estimate is statistically significant when it is not. There is plenty of Q&A's on this site dealing with this issue, if you need more information, like how to test for and correct for autocorrelation in regression. You can search for different terms, like this: https://stats.stackexchange.com/search?q=regression+autocorrelation+assumption .
