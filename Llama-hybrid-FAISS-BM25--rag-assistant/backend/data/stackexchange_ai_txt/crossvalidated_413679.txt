[site]: crossvalidated
[post_id]: 413679
[parent_id]: 
[tags]: 
Models for ranking possible classifications by confidence

What are good means of finding the various highest confidences or likelihoods for a (say) hundred possible outcomes of a classification problem? Inputs belong to only one class, unlike document ranking , but the best guess can of course be wrong. We will need to review the #2 and #3 ranked results if #1 turns out to be incorrect (facial recognition systems must do this too). We have labelled training sets for all the cases. Given the feature vector for some input, calculating cosine similarities is simple but na√Øvely weights all dimensions equally. Keyword-based approaches from information retrieval don't seem suited to comparing feature vectors. A Bayesian model is probably suited, but must we run all hundred measures for every input? Are there any techniques that help to acquire the top possible classifications for each input without running all hundred calculations? I can easily enough guess which cases are more common and start with those, but it doesn't rule out there being a high-scoring possible classification among one of the least predictable options.
