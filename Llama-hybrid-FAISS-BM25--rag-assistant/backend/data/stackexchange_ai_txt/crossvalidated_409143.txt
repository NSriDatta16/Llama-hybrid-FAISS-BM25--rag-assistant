[site]: crossvalidated
[post_id]: 409143
[parent_id]: 
[tags]: 
Feature extraction vs Fine tuning with Restricted Boltmann Machines

I am reading a paper which uses a Restricted Boltzmann Machine to extract features from a dataset in an unsupervised way and then use those features to train a classifier (they use SVM but it could be every other). I am a little bit confused about what they call feature extraction and fine-tuning. I don't understand whether there is a difference in the two approaches or if they could be mixed together to reproduce their experiment. To me, doing feature extraction is training the RBM on a dataset, find relevant hidden features and then use them as input of a classifier, which has no weights (parameters) in common with the RBM. On the other hand, fine tuning is to train the RBM on a dataset and then initialize the weights of a classifier with the same structure (imagine a feedforward NN) with those coming from the trained RBM. Is there a cross line between those two definition? What I think they do in the paper is feature extraction in the sense I explained above, but they mention also fine-tuning with backpropagation and I would those concepts to be clarified.
