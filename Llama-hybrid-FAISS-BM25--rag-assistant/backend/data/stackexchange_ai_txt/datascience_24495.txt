[site]: datascience
[post_id]: 24495
[parent_id]: 24379
[tags]: 
Since you only have 5 groups, you should probably look at distances instead of clustering. Now the question is: which distance should you use. Of course you could use Euclidean, Manhattan, or cosine distances and be done with it. In this case, I'd pick cosine distance because it reduces the impact of a single dimension on the overall distance and since you have 2000 features/interests, it might help. Now, I'm guessing that the interest groups are somewhat correlated. In an extreme case, 1999 interests are very correlated, and 1 isn't. If this happens and you use regular distances, it means that two groups who only agree on the 1999 interests will be considered much closer than the ones who only agree on the 1 interest. Even though, you know that you're only dealing with two interests here. So you might want to use some form of weighting to compute your distances using the correlation between the interest groups. Perhaps the more unique groups should matter more than the groups who are very similar to other interests. To do that, you could use dimensionality reduction techniques like PCA. PCA will "remove" redundant interests and "group" them into one. Once you have reduced the dimensionality of your data (let's say that now you are looking at 20 interests instead of 2000), you can compute your distances. Of course, distances are subjective and you have to define how much agreeing on specific interests matters. Perhaps agreeing on sports matters more than agreeing on books. If you have this prior knowledge, you'd have to manually input it into your weights. Once you've decided on how to compute your distances, you could compute multiple distance matrices by sampling subsets of the features (interests). That way, groups that are far away from each other will remain far away most of the time, same thing with groups that are close to each other. You could then look at the average distance to decide how far away the groups are from each other.
