[site]: crossvalidated
[post_id]: 17023
[parent_id]: 16998
[tags]: 
I am not sure I understand the last part of your question But, how can I compare the accuracy of my classifier without citing a test set? but I think I understand your concern. A given binary classifier's accuracy of 90% may be misleading if the natural frequency of one case vs the other is 90/100. If the classifier simply always chooses the most common case then it will, on average, be correct 90% of the time. A useful score to account for this issue is the Information score . A paper describing the score and its rationale can be found here . I learned about this score because it is part of the cross-validation suite in the excellent Orange data mining tools (you can use no-coding-needed visual programming or call libraries from Python).
