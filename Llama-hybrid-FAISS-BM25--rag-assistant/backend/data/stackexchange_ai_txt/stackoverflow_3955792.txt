[site]: stackoverflow
[post_id]: 3955792
[parent_id]: 3955419
[tags]: 
+1 What rob said. What you're doing is a hack that is not supposed to work, so you can't really complain when it fails. Serving a gzip resource is completely different to serving a resource with a different type using a Content-Encoding header to compress it on the wire. Serving pre-gzipped files will obviously also fail for user agents that don't understand gzip. The HTTP standard provides a mechanism for negotiating this: Accept-Encoding and Content-Encoding . Unless you re-implement that mechanism in a complete, standard-compliant way (and the article in Michael's link doesn't begin to get that right), you're blocking clients. This is all unnecessary. Gzip is fast and servers typically cache the compressed version of static content so you gain nothing by trying to second-guess it. HTTP compression is part of the web server's core competency, let the web server do its job and leave gzip alone.
