[site]: datascience
[post_id]: 107249
[parent_id]: 
[tags]: 
What happens if you don't include any activation function on hidden classification layers?

What happens if we don't apply an activation function to the classification hidden layers and apply it only for the final output layer (Sigmoid, Softmax)? I'm asking this because I have trained a CNN with transfer learning and fine tuning, and in the final classification layers that are after the convolution layers of the base model I didn't include any activation layer except for the final one ('Sigmoid', it is a binary classification) and I got good results in the test set. Is this something strange? It could happen?
