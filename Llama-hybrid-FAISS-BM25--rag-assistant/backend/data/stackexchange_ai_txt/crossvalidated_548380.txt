[site]: crossvalidated
[post_id]: 548380
[parent_id]: 548254
[tags]: 
There is nothing per se wrong or flawed about representing wind direction, a circular variable, via a cyclic cubic regression spline. That this approach is not as common (or used at all) in your field could simply be due to people in your field not being as familiar with modern GAMs, splines, or cyclic splines in particular. They may be familiar with the decomposition using cosine and sine functions and hence just following the crowd or familiar. More generally, GAMs are just GLMs. GAMs are certainly fancy GLMs but they are still GLMs. If I were to generate the model matrix that the GAM is creating and plug it into glm() (via say glm.fit() ), I'd be fitting a GAM. I wouldn't be doing any smoothness selection if I use glm.fit() , but I would be fitting a GAM as a GLM. What sets modern GAMs apart, is the way we choose the wiggliness of the fitted functions; in modern GAMs we set some upper limit on the expected wiggliness (via the k argument in {mgcv}) — there are other ways if we're fitting modern GAMs in a fully Bayesian setting — and then we apply a wiggliness penalty to the fit (the log likelihood), which penalises overly complex ≡ wiggly estimated functions. This is a form of penalization or regularization, similar to the ridge or lasso penalties that you might have encountered in the GLM world. If we take a step back and think about what both approaches (cosine-sine decomposition and cyclic splines) are doing, they are both representing the information in the data in some way that respects the circular nature of the original data. These representations don't suffer from the circularity feature of the original data and hence are more amenable to be used as covariates in a model. Both the cosine and sine decomposition and the cyclic CRS approach can be viewed as basis expansions of the original data, in the same way that adding polynomials of a covariate $x$ ( $x^0 = 1$ , $x^1 = x$ , $x^2$ , $x^3$ , etc) to a model can represent non-linear relationships. The Cyclic CRS does the same thing as the cosine, sine decompsition qualitatively; it provides continuous variables that encode in some way features of the original data, via a basis expansion. The Cyclic CRS is a richer decomposition but it isn't as immediately intuitive as the northlyness and easterlyness interpretation say of the cosine sine decomposition. We can get around that by plotting the estimated smooth function (perhaps using polar coordinates so you really see the circular nature of the effect of the covariate on the response). The main issues I have encountered with using cyclic CRS are that you really have to have data that cover the full range of (in this case) wind direction, and that you must specify the end points where values of the covariate map onto one another (0 and 360 in the case of wind direction). If you don't have data that cover the full range and don't specify the join point, the spline is going to try to make the data join at incorrect places. If you have data covering the interval 20-270 degrees, the spline will be constrained to make 20 == 270, thus introducing a bias. If you do specify the end points where values of the covariate wrap around to map onto one another again, but you don't have data that cover the full range of the variable, then you may introduce uncertainty and noise into the model estimates. In the case of these cyclic splines, if you observed data values in the range 90-270 and represented this directional variable as cyclical, you are going to have the effect on the response for a lot of the range of this variable totally unsupported by data; this would involve extrapolation beyond the observed data and this could affect the fit to the data where you have observations. It may well be better to ignore the circularity in wind direction if you only observe values over a restricted part of the range of values that could be observed. You also have to be careful about choosing the end points as it can make a difference to fitted and predicted values. For wind direction we have a clear point at which the data values wrap around: 0 ≡ 360! However, for a variable related to seasonality, this equivalence point is not always as immediately obvious. If you had monthly data for example with months measured as 1, 2, ..., 12, you shouldn't set the end points to be c(1, 12) because December isn't exactly the same as January, unlike 0 ≡ 360. So what do you do? In some limited testing, IIRC, setting the knots to be c(0.5, 12.5) seemed to produce fits with lowest error against simulated data (compared with say c(1, 13) ), perhaps because you are only pushing the end points only a little bit beyond each end of the observed data rather than a bit more at one end only. I don't know if this holds more broadly, and we stopped looking into it as the differences in RMSEP were small, so caveat emptor.
