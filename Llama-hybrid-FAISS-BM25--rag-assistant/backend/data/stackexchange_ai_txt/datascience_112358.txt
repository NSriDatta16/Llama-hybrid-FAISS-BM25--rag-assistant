[site]: datascience
[post_id]: 112358
[parent_id]: 112138
[tags]: 
Permutation feature importance is a way to access global feature importance. Permutation feature importance is defined as the decrease in an evaluation metric when a feature value is randomly shuffled, breaking the relationship between the feature and the target. Any reduction in an evaluation metric is indicative of how much the model depends on the feature. Permutation feature importance can be used with any machine learning algorithm (assuming tabular data). One option would be to feed all the information into the permutation feature importance algorithm, letting the algorithm figure out the empirical importance of each feature for this task. Even though a feature is labeled as "Irrelevant", it might still have some importance for prediction.
