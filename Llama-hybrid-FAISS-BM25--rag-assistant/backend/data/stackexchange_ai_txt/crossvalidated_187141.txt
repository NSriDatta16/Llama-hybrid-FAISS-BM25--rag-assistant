[site]: crossvalidated
[post_id]: 187141
[parent_id]: 187118
[tags]: 
In addition to Marc Claesen's good advice (+1). The logistic regression mentioned is the "most basic" binary classification algorithm. I would definitely recommend looking it up before anything else so you get an idea of what you are dealing with. You need to fit an generalized linear model - look at the glm function in R. You will be able to interpreter your results easily. To that extent, using a linear kernel will get you very similar results with logistic regression. In fairness, generally , non-linear kernels seem to be better than linear kernels for classification tasks but this is not absolute and SVMs are more complex to interpreter than logistic regressions. Having said all this I think that both approaches mentioned (SVM and LR) throw a tonne of information out of the window for your particular task. You have time-series. Not only that, you have a binary time-series. Not only that you have strong a auto-regressive component (I can't think of the times I identify a bad habit, broke it for a bit and then started it over again). And your data are extremely likely to have subject specific effects. In other words you have a GLMM with autoregressive random effects. You can fit these guys using R's MCMCglmm . Honourable mentions: " binary timeseries prediction "; ARMA models come into play there (that's why I asked). In your case, a GLMM with autoregressive error structure should give similar results with a ARMA but I do not know enough about binary ARMAs to send you to a particular implementation. " Hidden Markov Models "; HMMs essentially model transition probabilities by identifying patterns. And really this is what you want to do. They are a lot reference on the matter; usually the relate to NLP (predict the next utterance) but you solve the same problem with them in the end of the day. So to recap, try a simple GLM first to do a logistic regression. Afterwards, you might want to amp your game by using kernel generated features (so go with Marc's suggestion with the SVM) or by directly exploit the longitudinal and subject-specific nature of your data (so check the GLMM). These two should probably give you almost everything you can get out of your data with a first pass.
