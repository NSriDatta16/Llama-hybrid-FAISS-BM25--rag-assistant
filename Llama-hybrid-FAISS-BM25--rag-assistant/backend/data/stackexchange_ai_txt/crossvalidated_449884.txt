[site]: crossvalidated
[post_id]: 449884
[parent_id]: 
[tags]: 
How does the batch size affect the Stochastic Gradient Descent optimizer? (Example using Keras)

First of all, I know that there are lots of questions and answers about the topic throughout the site $-$ such as here , here or here (and I've probably read them all). However, I am still confused. Here is what happens. According to what I have understood from Chapters 3 and 7 of this book, Stochastic Gradient Descent works at the following way: For instance, set epoch = 5 For each epoch, randomly select one data point from the available data set and do the forward propagation. Compute the estimated value of $y$ and the associated error $-$ which depends on the chosen loss function; Do the back propagation and update the weights vector; If you did not complete 5 iterations yet, go back to step 1. . In summary, if I set up epoch = 5 , I will update the weights vector only 5 times $-$ considering a single data point at each one of them. Obviously, it only makes sense if I define the epoch arbitrarily large. Now, according to what I have understood about the ( Mini- ) Batch Gradient Descent , we have the following situation. For instance, imagine that we have a data set of size n = 950 and set epoch = 5 and batch_size = 100 ; For each epoch, select the first 100 data points and perform the forward propagation. Computed the estimated value of $y$ and the associated error. Do the back propagation and update the weights vector; Select the next 100 data points (let's say, from 101 to 200) and do it again: perform the forward propagation, compute the error, perform the back propagation, updated the weights vector [ $\cdots$ ]. Until you finally select the last 50 data points (let's say, from 901 to 950) and do all the required stuff; If you did not complete 5 iterations yet, go back to step 1. . In summary, if I have n = 950 and set up epoch = 5 and batch_size = 100 , I will update the weights vector $\lceil\frac{950}{100}\rceil \times 5 = $ 50 times. Here, if I choose batch_size = n I will have the "Traditional" Gradient Descent. Thus, the first question is: am I right? Considering what I have written so far. If so, how to explain the following scenario? By using Keras , I will try to construct an ANN (Artificial Neural Network) to classify the MNIST data set . Here is the code: from tensorflow import keras mnist = keras.datasets.mnist (X_train, y_train), (X_test, y_test) = mnist.load_data() X_train = X_train / 255 X_test = X_test / 255 model = keras.models.Sequential([ keras.layers.Flatten(input_shape = (28, 28)), keras.layers.Dense(units = 128, activation = 'tanh'), keras.layers.Dense(units = 64, activation = 'tanh'), keras.layers.Dense(units = 32, activation = 'tanh'), keras.layers.Dense(units = 10, activation = 'sigmoid') ]) model.compile(optimizer = 'sgd', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']) model.fit(X_train, y_train, epochs = 5) I know that the chosen activation function are not the most common ones (instead, I could have used ReLU for the hidden layers and SOFTMAX for the output), but that is not the point of my question. So let's move on. Here is the thing: Since I am using the Stochastic Gradient Descent optimizer ( optimizer = 'sgd' ), I should not be able to set a batch_size (actually, the only option would be batch_size = 1 , if I am not wrong). However, it is perfectly fine if I try to set batch_size = 32 as a parameter for the fit() method: model.fit(X_train, y_train, epochs = 5, batch_size = 32) Things get worst when I realized that, if I manually set batch_size = 1 the fitting process takes much longer , which does not make any sense according to what I described as being the algorithm. So, the second question is: what am I missing? Thanks in advance.
