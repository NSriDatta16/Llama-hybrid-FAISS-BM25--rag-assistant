[site]: crossvalidated
[post_id]: 443234
[parent_id]: 
[tags]: 
Random Forest in R - How to perform feature extraction and reach the best Accuracy result?

I'm working on a university project where I need to build a Random Forest model in R to predict if patients have depressive tendencies according to their EEG-data. I already preprocessed the data and built a general model for the forest. Currently, I'm fine-tuning it to receive the best possible prediction Accuracy. If I understand that correctly, I need to do some Feature Extraction (At this moment, I have 1584 Features) and tuning of the hyperparameters. But I'm not sure how to perform the Feature Extraction in R? Right now, I'm doing this: library(dplyr) library(caret) library(randomForest) library(eegkit) library(rlist) library(edfReader) library(eegUtils) library(e1071) library(ggplot2) yourdata_neu $Depressiv Depressiv) inTraining Run the randomForest 10 times and save each time the importance of every feature in the data frame "Importance_Table" Calculating the mean of the 10 trials for each feature in "Importance_Table_Mean" Use the data frame "Importance_Table_Filter" to save all features with an importance value of under 50 (50 was chosen by me) Get the colnames(feature names) of the data frame "Importance_Table_Filter" and save them in the variable "Excluding_Channels" Dropping all channels with an importance value of under 50 from my data set (yourdata_neu) and keeping the ones with more than 50. But I get the feeling that this isn't a good approach and very subjective. Does anybody have an idea to improve my model? My idea was to perform the Feature Extraction first and then optimizing the hyperparameters. It that common or advised to do it like this? I'm grateful for every input :) EDIT: Providing the values inside of the variable "yourdata_neu" (It contains the df_test values): https://drive.google.com/file/d/1k02hyqU51cAy5ka1gs5Ydr5_gOM5vTew/view?usp=sharing
