[site]: crossvalidated
[post_id]: 472822
[parent_id]: 
[tags]: 
Is LSTM (Long Short-Term Memory) dead?

From my own experience, LSTM has a long training time, and does not improve performance significantly in many real world tasks. To make the question more specific, I want to ask when LSTM will work better than other deep NN (may be with real world examples)? I know LSTM captures the sequential relationship in data, but is it really necessary? Most demos on related topic are meaningless. They just focus on toy data e.g., IMDB review, where simple logistic regression will get very good results. I do not see any value of using LSTM which has huge computational cost but marginal improvements (if there are any). Even with these toy examples, I did not find any good use cases that LSTM can solve very well but other models cannot.
