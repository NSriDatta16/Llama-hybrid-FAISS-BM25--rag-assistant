[site]: crossvalidated
[post_id]: 623746
[parent_id]: 
[tags]: 
Cross validation and hyperparameters tuning

I have few questions concerning the selection of hyperparameters for predictions in cross validation. If I understand well, during the CV, you just create folds (inner and outer for a nested CV), and then, for each fold, you train your algorithm, and make predictions on the test set, right ? Then, to estimate unbiased performances of your model, you calculate the average and the SD of all folds. And, with this "average" performance, what do you do with this ? I mean, I can't extract global "hyperparameters" optimized I guess... And can't i predict on a whole new dataset then ? If someone could explain me the mechanism behind this^^ For example, I computed manually a nested cross validation (5 folds inner and 5 outer) on my datas, and I obtain these results on my validation set to select the best model. These are average with sd performances. What can I do with this ?
