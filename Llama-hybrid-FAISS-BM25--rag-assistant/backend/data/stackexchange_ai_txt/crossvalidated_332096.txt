[site]: crossvalidated
[post_id]: 332096
[parent_id]: 
[tags]: 
Neural network with a custom loss function

I'm trying to implement a simple neural network (in Python) with 1 hidden layer and a loss function based on the GINI coefficient. But I just cannot find a way to minimize it with gradient descent. I'm not sure if this is even possible with this method. A simplified form can be written this way with e, current vector of errors : $$ e = y - \hat y $$ $$min\ G(e)=min\sum\limits_i\sum\limits_j \mid e_i-e_j\mid$$ Any idea or a trick to do this ? Thanks
