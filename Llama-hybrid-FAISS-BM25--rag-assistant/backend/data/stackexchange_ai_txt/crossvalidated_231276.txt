[site]: crossvalidated
[post_id]: 231276
[parent_id]: 231140
[tags]: 
To correct your understanding a bit, your interpretation of the model coefficients as the marginal contribution of a predictor is not one I've ever heard before. And I don't think it's right. Marginal suggests that it is not conditional. In an OLS model with two factors, $X$ and $Z$, the two respective coefficients $b$ and $c$ certainly differ from the results obtained by regressing $X$ and $Z$ separately and obtaining coefficients $b_m$ and $c_m$. In the two factor model, the interpretation of $b$ is "an expected mean difference in $Y$ comparing groups differing by one unit in $X$ having the same value of $Z$", whereas the marginal model would not have the "having the...". The idea of "forcing" people one unit higher is a causal interpretation, and with observational data and causal analysis, is a type of counterfactual reasoning, sort of rewinding time. The model you've written is a heteroscedastic one, and the rearrangement would require terms of $(1-X)$ and $(1-Z)$ to obtain $\mu_{ij}$ for specific covariate values of $X_i Z_j$. So I'd recommend writing it like: $$E[Y|X,Z] = \mu_{00}(1-X)(1-Z) + \mu_{01}(1-X)Z + \mu_{10}X(1-Z) + \mu_{11}XZ$$ Omitting the interaction term from this model produces fitted values which are a complex combination of the $\mu$s depending on the correlation of $X$ and $Z$, but they can be calculated by hand, and estimated consistently. Yes it's true that omitting certain predictors from a model (what we call "model misspsecification") will result in errors which are correlated with the omitted predictors and the observed predictors if those two are correlated. This is something we really never observed because the error is a thing different from the residuals. If I fit the OLS model, the residuals will be orthogonal to any predictor in the model. My first paragraph should address the difference in interpretation from the unadjusted model, and the adjusted one. The interpretation will not be the same. The actual value of the coefficient will not be the same unless $X$ and $Z$ are uncorrelated, but even when they are I would not interpret the regression models results as the same. In your description of results you omitted an interaction term. In regression analysis we often consider exploring interaction terms as a type of post hoc analysis. What you might imagine is that when the interaction is present --suppose the object of inference is the relationship between $X$ and $Y$ controlling for $Z$ (binary)-- there is one slope comparing $X$ to $Y$ when $Z=0$ and another when $Z=1$, by omitting the interaction term, the estimated slope comparing $X$ to $Y$ is just a weighted average between the two $Z$ levels. In observational studies, what you are probably calling "empirical" studies", you mustn't use causal language in interpreting any of the findings, including words like "impact" "change" and "increase".
