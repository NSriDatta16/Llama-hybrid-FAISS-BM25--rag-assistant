[site]: crossvalidated
[post_id]: 599681
[parent_id]: 
[tags]: 
Do the neural networks belonging to a deep ensemble need to be trained on the same training set?

As the title says, I was wondering, if I have to train every neural network of a deep ensemble on a different training set or on the same one. I ask this question because I am getting weird results. If I use the same training set I get overconfident predictions and the deep ensemble fails to estimate the epistemic uncertainty. I think this happens because each network end up finding the same solution instead different solutions spread over the parameter space (? or it's the feature space? not sure). If instead I change the training set for every element I get worthless predictions Update: after further inspection, it seems that some of the networks of the ensemble do not learn and the average predicted value remain close to 0 for all input. This shift the mean of the ensemble toward 0. How can I improve the quality of the estimate of the uncertainty?
