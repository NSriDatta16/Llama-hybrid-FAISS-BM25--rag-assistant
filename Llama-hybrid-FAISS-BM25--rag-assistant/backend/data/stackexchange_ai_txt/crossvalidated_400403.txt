[site]: crossvalidated
[post_id]: 400403
[parent_id]: 400391
[tags]: 
As Frank said, if you use PCA to create a few variables, you should not have inversion problems (especially if you use an orthogonal rotation), nor will you have collinearity (which ridge regression helps with). But I would not say PCA is a good method of variable selection. PCA creates linear combinations of variables that capture as much as possible of the variance in the full list of variables. Those combinations won't (usually) be very helpful in variable selection, if your goal is to have a model with the original variables. Model building and variable selection is a huge topic, discussed here many times. When advising people, I always try to get them to avoid any automatic method because automatic methods don't let you use your brain. If you must use an automatic method, LASSO is a good choice, but you would do that on the original variables, not the principal components. Finally, if you do decide to go with some kind of dimension reduction, I'd consider partial least squares, which is sort of like PCA regression, but also accounts for relations with the DV.
