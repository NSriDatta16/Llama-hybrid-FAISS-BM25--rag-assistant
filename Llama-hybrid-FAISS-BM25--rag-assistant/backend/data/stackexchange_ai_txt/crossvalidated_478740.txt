[site]: crossvalidated
[post_id]: 478740
[parent_id]: 
[tags]: 
How to compute standard deviation from mean absolute error?

I would like to compute the standard deviation from mean absolute error for predictions of a CNN I trained. consider model_predict as the predicted value for the network, and y_test as the ground truth. I tried: std = np.sqrt(np.mean(np.abs(y_test_n - np.mean(model_predict))**2)) and std = np.sqrt(np.mean(np.abs(y_test_n - (model_predict))**2)) I think the first one is the correct computation, but the values are suspicious (doesn't much difference between different weights). Which one of the above formula (if any) is correct for standard deviation from mean absolute error? If none, how can one compute that?
