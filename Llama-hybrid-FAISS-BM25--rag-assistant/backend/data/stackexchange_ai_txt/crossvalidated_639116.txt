[site]: crossvalidated
[post_id]: 639116
[parent_id]: 638667
[tags]: 
Logistic regression (using logit link) is a binary response model, with $P(y_i=1|x_i)=\hat\pi_i$ and $\hat\theta_i=x^T_i\hat\beta=logit(\hat\pi_i)$ . Whether we want to predict $P(y_i=1|x_i)$ or $P(y_i=0|x_i)$ , we use the same covariates for prediction. If the response has more than 2 levels, then the usual GLM model would be multinomial regression. In a way, DCM is the far more complex version of logistic regression. For each choice $1,...,k$ we have a set of corresponding covariates, and naturally enough all other covariates are not used by this choice. That is, there is some kind of hierarchical structure of the covariates. The set of variables belonging to person $i$ corresponding to alternative $j$ is denoted $z_{ij}$ and then we can write the utility $U_{ij}=z_{ij}^T\beta+\epsilon_{ij}$ , and in general we expect person $i$ to choose alternative $j$ if $U_{ij}>U_{ik},\forall k\ne j$ . If we look at DCM for two alternatives, then it can be easily be written as logistic regression (see here ). If we have $K\ge3$ alternatives, then the probability of person $i$ choosing alternative $j$ is $P_{ij}=\frac{\exp(\beta z_{ij})}{\sum_{k=1}^K\exp(\beta z_{ik})}$ . This is also sometimes called multinomial logit . Therefore, logistic regression is the binary special case of the multinomial logit model.
