[site]: crossvalidated
[post_id]: 509902
[parent_id]: 
[tags]: 
what should I do after hyperparameter tuning (retrain, rescaling)?

I built a binary classification model. I split data into train and test and I scaled them (StandardScaler, fit_transform on train - transform on test). Everything was aimed at achieving a good scoring (recall in my case). After a GridSeachCV, I ended up the best model was XGBoost with the optimal hyperparameters identified by GridSearchCV. So my questions are more on the process: Should I retrain that XGBoost model on the entire dataset (model.fit(X_data, y_data))? I guess yes. Should I use cross-validation at this stage again? if yes, why? and how? I have to scale my data as I did it during the model construction, but should I recalculate the scaling based on the full dataset or should I use the scaling I computed during the model construction? Thanks
