[site]: crossvalidated
[post_id]: 77170
[parent_id]: 69960
[tags]: 
It may be helpful to randomly fetch fewer records (try 2000 or 5000). From here what I would do is try making multiple classification trees and average your results across trees. Here's a great video by Wallace Campbell showing how to average multiple trees to decide on one tree ( http://vimeo.com/71992876 ). I'd also recommend taking a look over your 200 columns. To save on computing power you may come across columns little to no variability. These predictors may not be useful to you or others. You may save some computer power by seeing if this exclusion improves your ability to run your analyses. Allowing surrogates in your decision tree would greatly influence your prediction and allow you to avoid imputation. You may want to experiment the number of surrogates you allow in your model.
