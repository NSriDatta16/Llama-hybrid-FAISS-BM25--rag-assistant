[site]: crossvalidated
[post_id]: 534044
[parent_id]: 
[tags]: 
How to use BinaryCrossEntropy (intutively) for Generator Network in DCGAN model?

TL;DR: Can someone tell me intuition working on BCE loss in the generator, specially for RGB as each pixel is having 3 values i.e. a list of values rather than just a single one. I have same problem as this stack question but the thing is I am trying to find an intuition of BinaryCrossEntropy for RGB i.e 3 channels. First, let me tell you that what I think of this function on Images (please correct if wrong), for example, we have a Grayscale image, for U-Net / Autoencoder architecture, you can Flatten the image and can say whether this Pixel is 0/1. That makes sense. Also, when we are using U-Net Segmentation, we classify that this pixel belongs to one of which classes. So even if the last layer return WxHxC (say C = 6) channels, we can think it as that the pixel is One Hot Encoded. And then just try to superimpose the class Number on the original image as: The main thing here is that when we use the DCGAN Architecture , we use the BinaryCrossEntropy for Discirminator as well as the Generator network. Discriminator work is fine as it is very common but how does that work for Generator? This Keras Implementation at the official site uses the same BCE loss function Can someone tell me intuition working on BCE loss in the generator, specially for RGB as each pixel is having 3 values i.e. a list of values rather than just a single one.
