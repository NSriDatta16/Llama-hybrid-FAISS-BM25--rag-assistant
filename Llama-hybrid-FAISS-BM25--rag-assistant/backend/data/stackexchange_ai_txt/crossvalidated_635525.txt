[site]: crossvalidated
[post_id]: 635525
[parent_id]: 635194
[tags]: 
if you allow me to write a few thoughts on your problem: first and foremost, what is usually done in this kind of analysis (i.e., multiple parameters jointly influencing some outcome), is that you estimate intercorrelation between particular parameters. You can use just Pearson, ICC, or VIF for that. This way you can exclude highly intercorrelated variables even before designing you model. With simulation things can be a bit more complicated, although you can always split simulation into: generating the data, checking intercorrelations, and running the model. That is of course, if I got your problem right. What I understand well is that, for variables that I assume to be confounders, I need to simulate effect sizes for each confounder on the treatment and outcome. For example, if Z1 has an effect of 0.23 on Y, I would also need to simulate an effect of say, 0.04 on X, otherwise, it would not be a confounder. However, in more complex data generating processes, the confounders may impact the value of other confounders themselves. That is, it may be inappropriate to define each confounder as a distribution completely exogenous to the other confounders of interest. Why do you consider X as being mathematically different from Zx? From the strictly technical perspective these are all linear regression parameters and they all can influence each other. It does not matter whether some of them are clinically relevant, or are confounding variables. Please also note that a lot of your rationale depends on how you define a "confounder" exactly. What definition are you using, from which interpretation/handbook? In my opinion there are two options: A counfounder Z is a variable/phenomenon that explains the variance of the Y, while the variance of Y is expected, and should be, influenced only by X. A counfounder Z is a variable/phenomenon that explains the variance of the Y, while the variance of Y is expected, and should be, influenced only by X; and Z explains the variance (is correlated with) X. See the difference? I can imagine scenario in which two events totally unrelated to each other are jointly influencing some other variable. Let me use the following example: a patient is being stressed out by his boss at work, and by his spouse at home. The boss and the spouse are unrelated, but they both, jointly or individually, can contribute to the patient developing a depression. Now, which one of the two is a confound? It depends on what are you studying. If you are interested in the influence of work-related stress to developing depression, then home situation is your confound. If you are studying marriage relationships, then what is happening at work is the source of your confounding variables. Now, the example of partly related/correlated X and Z influencing Y would be if the boss (X) and a co-worker (Z) would be stressing out the patient enough to get him depressed (Y). Why? Because the co-worker (Z) is also stressing out the boss (X) (not only our patient), and this is in part the reason why X is contaminated by Z. If you remove a confound Z, then X would explain Y better, but bear in mind that Y can still be the same, or can change, only an experiment would tell (or a specific simulated dataset). Please also note, that in this situation it is very hard to tell, whether it is not also the other way around, i.e., boss (X) is stressing out the co-worker (Z), and they both influence patient (Y). At some point, the theoretical deliberations are not enough, and you have to head out to practice to disentangle different phenomena. as long as I specify the effect that each confounder has on the outcome and treatment, is the simulation analysis good to go I would say yes. However, on the other hand, I see problems with me embedding further assumptions into the analysis for effect sizes that are not of interest (i.e. I would have no actual interest in knowing/pondering how Z3 might impact Z1, Z2, Z4, etc.). It depends on the problem. If you want to provide more cognitive explanation to the simulation process, you can model these influences, but I can imaging a different goal for you simulation to just estimate the influence of X and Zx treated as separate variables (bear in mind the first paragraph of my answer). Interestingly, in one of your recent analyses, when we removed inter-correlated variables, then our model performed worse. Does that mean that the intercorellations were artificially improving the accuracy, or that despite intercorrelations model was getting some important information from more number of parameters? Only an attempt to apply the model in practice (e.g., prospective clinical trial) would provide an answer to this question. I would not trust only simulation, unless there was a clear mathematical/logical proof that I would be able to understand. Otherwise I would go with empirical experiment, because its outcomes are more cognitively available. To further comment on you immediate methodological/statistical issue, concerning taking into account how particular parameters influence not only the outcome, but also each other, I would advise you to look at your problem, even a simulated one, from the practical perspective of some example research question, it helps a lot to get the right answers, even on the theoretical level.
