[site]: crossvalidated
[post_id]: 611588
[parent_id]: 474651
[tags]: 
If we consider a neural network to just be some mapping $f(x): X \mapsto Y,$ where $X$ and $Y$ are features and outcomes (basically, the term "AI" is just rebranding point estimation, which has been studied a lot in statistics), we can maybe make some progress on this question. In particular, we can note that a neural network, when trained on a dataset $(X_n,Y_n)$ is actually $f_n(x).$ The question of whether a neural network si "biased" is then whether $Ef_n(x)=f_0(x),$ where $f_0$ is the true mapping from $X$ to $Y$ , chosen by nature. In general, if a neural network can approximate any function, which I think it basically can, then definitely $f_n(x)\rightarrow^p f_0(x),$ for any $x$ , or, in other words, as the sample size $n\rightarrow\infty$ then $f_n\rightarrow f_0$ in probability (ie, the probability $f_n$ and $f_0$ are different shrinks to zero), or $f_n$ is consistent. This is not the same as unbiased, and some biased estimators can be consistent. To show that a neural network is unbiased would requie that one evaluate the expectation $Ef_n(X)$ for a neural network by hand, which is, as far as I know, not really possible. By regularizing in such a way that the regularization does not disappear in the limit, we are definitely causing bias that also will not disappear in the limit, and therefore also losing consistency. However, this can make sense to still do in the finite sample if the error from variance dominates the error from bias. Looking at the "bias" of the individual weights $w_n$ in the network rather than of the function $f_n$ itself is problematic imo because the individual weights can be different and give the same function. There are not really "true" weights $w_0$ that we can assess in terms of their distance from $Ew_n$ to make statements about bias. Now that we maybe have considered a fully flexible neural network, we can consider a CNN, which has tied parameters. This will definitely lead to bias. That said this is maybe a feature of the model, so maybe the function is consistent even under this constraint. Actually not sure about this.
