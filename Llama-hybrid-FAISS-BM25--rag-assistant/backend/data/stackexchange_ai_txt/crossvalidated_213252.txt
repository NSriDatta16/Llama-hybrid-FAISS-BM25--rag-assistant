[site]: crossvalidated
[post_id]: 213252
[parent_id]: 213119
[tags]: 
A simple approach is to identify and discard features with high inter-feature-correlation (see e.g. this question for more details and an example in R caret). You could also utilize classic feature selection approaches, such as feature filters , which select features from considering the features itself (e.g. inter-feature-correlation) and the target variable (e.g. feature-target-correlation), without including the model - or feature wrappers , which additionally take models into account, hence optimize the resulting model performance instead (see e.g. the built in feature selection approaches in R caret ). In contrast to those purely selective mechanisms you can also utilize dimensional reduction mechanisms using PCA to compute PC dimensions, then discarding less important PC dimensions, like you already mentioned. BTW: the linear independence of PC features is caused by how PCA works.
