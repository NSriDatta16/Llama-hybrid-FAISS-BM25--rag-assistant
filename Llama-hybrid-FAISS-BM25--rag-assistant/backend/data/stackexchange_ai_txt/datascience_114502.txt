[site]: datascience
[post_id]: 114502
[parent_id]: 
[tags]: 
How is model scheduling set up in practice?

I have been working on various machine learning models so far, but never yet on the deployment phase of an ML project. I have vaguely used Apache Airflow and I'm aware that it is a tool for scheduling DAGs, but I never set up such a scheduling on prod environment myself. Now I would like to gain a bit more knowledge on model deployment and orchestration, but currently I have no access to a company's dev/prod environment to experiment on. My questions are: Once a ML solution is ready to go into production and has to be ran, say, every hour, where would it run exactly? Do companies that develop ML solutions typically rent out a cloud server, for instance on AWS, and connect their Airflow environment to that? In such case, do companies generally package the product in a Docker image? If I were to try out using Airflow scheduling on my home laptop, would it make any sense? Could I set up scheduled jobs? I imagine these jobs would only run if my laptop is switched on, else they would fail. Is my interpretation correct?
