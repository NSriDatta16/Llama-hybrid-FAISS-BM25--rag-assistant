[site]: datascience
[post_id]: 60870
[parent_id]: 60868
[tags]: 
Regarding your first problem: I would suggest that you do not discard the the amount of values even if it goes more than or less than 250. Instead what you can do is ; aggregate the values of accelerometer over a time intervals and then tie it up to a single action. Regarding your second problem: You have around 750 columns of the data. It would be very difficult to use random forest algorithm on it and get higher accuracy on it. You have to apply dimension reduction and then feature extraction techniques. You can go ahead with PCA (principal component analysis) f 750 independent variables. Reduce it down to 2 or 3 variable and check how much variance these reduced variables can explain. if it less than 60%. You can apply T-SNE algorithm to extract features more on it. P.S. to check if your reduced variable can explain your dependent variables (like squat, sitting, pushup), you can plot the scatter plot of reduce variable values and then color the values based on your dependent variable. you can click below link to understand what I am saying https://blog.bioturing.com/2018/06/18/how-to-read-pca-biplots-and-scree-plots/
