[site]: crossvalidated
[post_id]: 329906
[parent_id]: 328897
[tags]: 
First, it would be a good idea to combine 1 and 2. Second, rather than including the propensity score in an adjusted t-test/regression, estimate balancing weights, and use those in a weighted t-test/regression that also adjusts for the features. Balancing weights are weights that when applied to your data set will make the weighted groups appear similar to each other on the features. A good method of weighting is generalized boosted modeling, but there are others. In R, your command would look like: lm(Days_being_healthy ~ Med_group, data = data, weights = balancing.weights) presuming your data is stored in data and your balancing weights are stored as a vector called balancing.weights . You can do a bootstrap of the entire process to estimate standard errors or a confidence interval. When choosing tuning parameters for boosting, I recommend "ks.max". Your #3 would work but only on the condition that within each cluster, the groups look similar on the features. A common way to do this without machine learning is to estimate propensity scores and stratify in quantiles of the propensity score, then estimate treatment effects within each quantile and pool them. This approach has been shown to be more biased than weighting as I described above.
