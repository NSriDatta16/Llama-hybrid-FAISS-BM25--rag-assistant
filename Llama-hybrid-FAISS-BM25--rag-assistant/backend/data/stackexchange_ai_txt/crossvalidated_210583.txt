[site]: crossvalidated
[post_id]: 210583
[parent_id]: 210580
[tags]: 
You can expect an improvement if all of your models perform better than random chance and if the models are sufficiently un-correlated. Winning entries in data mining competitions such as Kaggle are very often ensembles of models similar to your description. See for example this interview http://blog.kaggle.com/2016/03/23/telstra-network-disruption-winners-interview-1st-place-mario-filho/ with the winner of a recent Kaggle competition where the winning solution was an ensemble of 15 models. It's not a completely one way street though - if you were models were easily interpretable beforehand, your averaged model will be less interpretable, and if you intend to implement your model, using the average of ten models instead of just one model adds to the computational requirements (whether or not this an issue will obviously depend heavily on your application).
