[site]: crossvalidated
[post_id]: 409177
[parent_id]: 409143
[tags]: 
Here is a summary of what I get from the article to help clarify your ideas. The authors propose 2 steps : 1) Learning the relevant features from the data with a Deep Belief Network (DBN) which is a network made of stacked RBMs. This network is trained first unsupervisedly (pretraining to get good initial weights and biases). Then when the authors talk about backpropagation they are fine-tuning their network by turning the DBN into a feedforward NN. In fact, I think they follow strictly the method they reference : Hinton & Salakhutdinov's Science paper . You may read it, it describes the unsupervised pretraining / supervised fine-tuning procedure, which has since become quite commonly used in machine learning. 2) Learning a mapping from the extracted features to the stock price. They set up another supervised classifier, a SVM, but this could again be a feedforward NN as you mention. In a few lines of the article a few different concepts are used and mixed (discriminative/generative models, directed/undirected graphical models, unsupervised/supervised learning...) so things can indeed get messy!
