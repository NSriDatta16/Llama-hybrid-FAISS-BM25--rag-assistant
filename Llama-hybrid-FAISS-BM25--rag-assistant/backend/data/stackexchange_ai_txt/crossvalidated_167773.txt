[site]: crossvalidated
[post_id]: 167773
[parent_id]: 
[tags]: 
Explaining the steps of a visualization tool

this is my first post on CrossValidated. I've done, for academic purpose, a web tool doing this process: web scraping from various sites pre-process the responses (cleaning, error and redundance detection) and make a structured data out of these scraped informations (then I save these structures in db) quantitative analysis and a sort of semantic analysis of the data show interactive data visualization in different forms and purposes (node graph, line graph, treemap, so a sort of visual analysis) Now I'm writing an article about the tool, but I'm in doubt about the terms explaining this process and its steps correctly (also some of those steps, the cleaning and error detection for example, some academic papers sustain it's part of data-mining, some other sustain it's a previous step). From these few infos, my tool is more about information retrieval or data-mining? Any advice about that (maybe some references too) would be appreciated.
