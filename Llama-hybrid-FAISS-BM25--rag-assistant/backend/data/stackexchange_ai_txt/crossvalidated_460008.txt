[site]: crossvalidated
[post_id]: 460008
[parent_id]: 
[tags]: 
Creating a metric learning training dataset from probabilistic data

I have the following Bayesian probability data that I'd like to use to build a metric learning training set. Here's the problem setup: Each user is encoded in an n-dimensional feature vector with an attached binary label. Each feature has one of the following values [-1 (absent), 0 (unknown), 1 (present)] , and each label has one of the following values [0, 1] . For example: user1: [Feature_1: 0, Feature_2: -1, Feature_3: 1,..., Feature_n: 0] user1 label: [0] Unfortunately, I do not have a data set of user vectors, but I do have the following probabilities: P(label) = 10% P(~label) = 90% P(Feature_1 | label) = 10% P(Feature_2 | label) = 20% ... P(Feature_n | label) = 15% P(Feature_1 | ~label) = 1% P(Feature_2 | ~label) = 2% ... P(Feature_n | ~label) = 5% My thought is that I can create a training data set out of the above probabilities like so: Create 100 user vectors with label = 1 1.a. Of these 100 user vectors: randomly choose 10% of them to have Feature_1 = 1, randomly choose 20% to have Feature_2 = 1...and randomly choose 15% to have Feature_n = 1 Create 900 user vectors with label = 0 2.a. Of these 900 user vectors: randomly choose 1% of them to have Feature_1 = 1, randomly choose 2% to have Feature_2 = 1...and randomly choose 5% to have Feature_n = 1. Then fill in the rest of the matrix with 0s Is this a valid approach? Any suggestions?
