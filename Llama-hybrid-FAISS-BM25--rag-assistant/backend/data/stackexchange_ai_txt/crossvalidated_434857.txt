[site]: crossvalidated
[post_id]: 434857
[parent_id]: 
[tags]: 
Why is pseudo-random sampling applicable for Monte Carlo integration, even though it does not satisfy the CLT requirements?

Assume we have a function $f\left(x\right)$ defined on $\left[0, 1\right]$ that we want to integrate and estimate the error using Monte Carlo method. We generate realizations of uniformly distributed independent random variables $x_n$ on $\left[0, 1\right]$ and find $f_n = f\left(x_n\right)$ where $f_n$ happen to be independent and identically distributed random variables. Hence we may be able to apply the CLT to their sum or average. We can take $\overline f = \sum\limits_{n=1}^{N}f_n$ that may have an approximate normal distribution with expected value $\int\limits_0^1 f\left(x\right)dx$ and sample variance $\sigma^2 = \frac{1}{N-1} \sum\limits_{n=1}^{N} \left(f_n - \overline f\right)^2$ . We can use the sample variance as an estimate of the integration error. Now assume we do the same thing, but instead of random points $x_n$ we generate pseudo-random points $x_n$ (using Mersenne Twister for example). The sequence is determined now, and $f_n$ no longer satisfy the CLT requirements, but it seems like $\overline f$ and $\sigma$ still give good integral value and error estimations respectively. So my question is how can one formally explain why this is happening. It is clear that pseudo-random points are "random enough" to be close to satisfying the CLT, but it is a heuristic explanation, and I am interested in an actual mathematical proof.
