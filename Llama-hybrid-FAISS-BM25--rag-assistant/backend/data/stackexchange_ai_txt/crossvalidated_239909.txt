[site]: crossvalidated
[post_id]: 239909
[parent_id]: 
[tags]: 
when is measurement aggregation justified?

I am struggling with what appears to be a general practice within applied/organizational psychology (and related literature) of including aggregated variables as fixed effects in statistical models. This appears to be referred to as "composition modeling". The following article is good example of this tendency: http://dx.doi.org/10.1080/02678373.2016.1173124 . In this case, two survey measures ("incivility climate" and "competitive team norms") are aggregated to the "work team" level and entered into a statistical model predicting "job-related affective well-being" along with other variables and a random intercept for "work team". There are other issues with this model, but my reason for posting concerns the issue of aggregation. I am having a difficult time understanding the utility in aggregating a measure when individual-level data is available - either from a methodological or a theoretical perspective. There appears to be an effort within recent org-psych methods literature to establish guidelines under which a construct may be aggregated (see the following link (also attached for your reference) http://orm.sagepub.com/content/18/4/704.full.pdf+html%27 ). In brief, the justification involves establishing that a construct possesses within-group agreement and between-group differences. However, I still don't see how establishing the presence of within-group agreement and between-group differences justifies "throwing away" within-group information. QUESTION: Assuming that within-group agreement will never be perfect, even if a researcher has established a measurement as a group-level construct, doesn't it make sense to still model the within-group variability in order to properly capture all uncertainty in model predictions?
