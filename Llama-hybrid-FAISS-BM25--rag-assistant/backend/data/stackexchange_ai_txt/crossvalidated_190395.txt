[site]: crossvalidated
[post_id]: 190395
[parent_id]: 
[tags]: 
'Z-standardizing' data based on Poisson process

Hello all this is my first post on Cross Validated, so please let me know if it is not in an acceptable form. I have been attempting to analyze a data set where I have a Bernoulli process that is generating a sequence of two outcomes with given probabilities. I am calculating the average length of runs of a given outcome which I believe could be considered a Poisson process for example: sample sequence= 0,0,0,1,1,0,0,0,0,1,1,1 mean run length= 3 This is a plot of some fake data that I generated to illustrate the distribution. I am then attempting to quantify how the 'streakiness' of this sequence compares to a distribution of other sequences, and I would like the output to be in the form of a standard normal variable. More succinctly: given my sample sequence and the distribution above, how many 'standard deviations' more streaky is the sample sequence than the distribution? So far I have tried using a Freeman-Tukey transformation e.g.: $r=sample \ run \ length$ $\mu=mean \ of \ distribution$ $X=\sqrt{r}+\sqrt{r + 1} - \sqrt{4*\mu+1}$ But this is providing some odd output. For example if the run length in the sample is equal to the mean run length of the distribution I would assume X above should be 0 but it is not. My question is twofold. Am I correct in assuming that the run lengths above are actually the result of a Poisson process? If so, Is this the correct "standardizing transformation" for these type of data?
