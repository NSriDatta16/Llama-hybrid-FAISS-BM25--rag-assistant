[site]: crossvalidated
[post_id]: 621480
[parent_id]: 621462
[tags]: 
Not sure what the confusion is about $p_g$ — it's the probability distribution of images produced by generator $G$ . We generally assume that $\mathbf{x}$ is an image tensor, so you can think of $p_g$ as some probability density function with pixel-space support (e.g., over $\mathbb{R}^{\text{height} \times \text{width} \times \text{channels}}$ ). It has nothing to do with $P(\mathbf{x}\text{ came from G})$ ; it is simply the distribution of images encoded by $G$ . The original GAN paper might also give you more insight on what $p_g$ actually is -- in practice, to sample from $p_g$ , we might do $\mathbf{x} \sim G(\mathbf{z})$ where $\mathbf{z} \sim \mathcal{N}(0, 1)$ (or some other distribution). I don't usually think of $p(y | \mathbf{x})$ as a "thing to plot," but rather from a classification perspective. In the context of this paper, $p(y \mid \mathbf{x})$ is InceptionNet's estimate of the probability that image $\mathbf{x}$ belongs to class $y$ (i.e., that $\mathbf{x}$ is an image of $y$ ). I'm not familiar with ways to plot the entire conditional distribution, but you could visualize the multinomial distribution of $y$ given a single image $\mathbf{x}$ pretty easily (i.e., P(y = class | x) for the most "likely" classes). We do not need the explict form of $p_g$ to estimate $p(y)$ , as demonstrated in Eq. 5. I am not sure what the confusion is about $\int_x$ — it's the integral taken over the support of $p_g$ (i.e., pixel-space). An equivalent way to write that integral (that leads directly to Eq. 5) is $\int_x p(y \mid \mathbf{x}) p_g(\mathbf{x}) dx = \mathbb{E}_{\mathbf{x} \sim p_g}[p(y \mid \mathbf{x})]$ , which follows from the law of the unconscious statistician.
