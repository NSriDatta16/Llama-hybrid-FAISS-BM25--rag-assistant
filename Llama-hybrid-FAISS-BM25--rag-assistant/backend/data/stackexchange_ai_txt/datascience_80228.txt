[site]: datascience
[post_id]: 80228
[parent_id]: 80225
[tags]: 
You could start using a dynamic regression model, they are used when besides the times series to be forecasted, you have another series where you could use it. Essentially, this is a usual regression model, also called Autoregressive Distributed Lags (ADL), where you include not only the dependent variable $ y_{t} $ but also explanatory variable $ x_{t} $ . Following equation exemplifies that: $$ y_{t} = c + a_{1} y_{t-1} + b_{0} x_{t} + b_{1} x_{t-1} + \epsilon_{t} $$ Now notice that equation above uses $ x_{t} $ , meaning that at time you have variable $ x $ so you could use it to forecast $ y_{t} $ . This is not always possible, so take care of data leakage. You can read more about it in Forecasting: Principles and Practice - Chapter 10 Dynamic regression models Having said all that, you can also improve your ML approach by computing temporal features. Rolling Averages up to lag t, Rolling sum, max, min, and all lags variables could be example of feature engineering you could apply and still use a machine learning approach. Also, if you use python, there is a fresh package called sktime where you can use Reduced Regression . Example from their notebook (link above): from sktime.forecasting.compose import ReducedRegressionForecaster forecaster = ReducedRegressionForecaster(regressor=regressor, window_length=12, strategy="recursive") forecaster.fit(y_train) y_pred = forecaster.predict(fh) plot_ys(y_train, y_test, y_pred, labels=["y_train", "y_test", "y_pred"]); smape_loss(y_test, y_pred)
