[site]: crossvalidated
[post_id]: 374951
[parent_id]: 374949
[tags]: 
If I decide to have k=5 (from this text), I will have 2 sets of data per k. So I can fit a model on these 2 sets, and test the data with the other sets and record their errors. You would be training the model on $4$ sets and estimating the prediction error on remaining $1$ set. For standard linear regression i.e OLS, there is no Hyperparameter . If you are doing OLS, then I am afraid you can only use cross-validation to estimate the prediction error for the given dataset. You really don't have a choice of models to select from. This is because you don't have models indexed by tuning parameters. But, let's say you wanted to perform ridge regression or LASSO then you have lambda i.e. shrinkage factor as a Hyperparameter. In this case if you use different shrinkage factors, you want to find the best shrinkage factor among them . So, you would perform cross validation for each shrinkage factor and get the prediction error estimate(average across the validation sets) for each. Then select the model(shrinkage factor) with the least prediction error estimate.
