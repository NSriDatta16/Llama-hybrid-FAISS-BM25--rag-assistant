[site]: crossvalidated
[post_id]: 125900
[parent_id]: 
[tags]: 
cost function in logistic regression vs optimization algorithms

I have a table like: tabla Let's suppose I need to predict e with c using a logistic regression: log_pru Let's suppose also that my gain is 90 when my choice is TP, and -10 when is FP function is: mycost If I'm able to identify each TP without FP, my gain would be: maxgain In the log model, my gain would be: tabla $ganLog pred_res>.1, tabla$e*90-10, 0) which is 420. I thought that introducing the cost function in the optimizing algorithm might be useful to reflect my actual problem. So, to use "optim", I wrote the following function (which is a sigmoidal): fn $c * beta) prediction 0.5, 1, 0) mycost(tabla$ e, prediction) } guess And my result is: alpha $par[1] beta par[2] J $c * beta) tabla$ pred_guess = J/(1+ J) plot(tabla $c, tabla$ e) lines(tabla $c, tabla$ pred_guess) mycost(tabla $e, ifelse(tabla$ pred_res > 0.1, 1, 0)) tabla $ganOpt pred_guess>.5, tabla $e*90-10,0) sum(tabla$ ganOpt) Which is 460. (almost 10% greater than the obtained by the logistic with glm). If I plot both graphs: plot(e ~ c, data=tabla) lines(tabla$c, log_pru$fitted, type="l", col="red") abline(0.1, 0) abline(v=min(tabla$c[tabla$pred_res>0.1]), col="blue") .1" /> An the other model would be: plot(tabla$c, tabla$e, main="optim") lines(tabla$c, tabla$pred_guess, col="red") abline(0.5, 0) abline(v=min(tabla$c[tabla$pred_guess>0.5]), col="blue") I know that you can introduce a cost function in cv.glm but this is only o select among models already chosen, so, my questions are: Would it be a good idea to introduce a cost function in the algorithm that selects the parameters? What does SAS do with the cost function in Miner? Does it use it to select the parameters values? Why glm package in R doesn't have the possibility to introduce another cost function? Would it be a bad idea to use "optim" in real examples? What about over-fitting? And also, do I have to program all the variables like I did in this mini example? Is there a better way? What about doing oversampling or downsampling to avoid this? I would really appreciate a theoretical answer.
