[site]: crossvalidated
[post_id]: 285021
[parent_id]: 
[tags]: 
Repeated measures analysis: why nest experimental factors within subject factor?

Consider a pure repeated measures design, with (let's say) 3 experimental within-subject factors A, B, and C, and (for simplicity) 2 levels per factor. So we have 2*2*2 = 8 measurements per subject. Now I would like to test the fixed effects with a linear mixed effects model. I have read in several sources (for example Andy Field's Book "Discovering Statistics using R", and this site: http://www.jason-french.com/tutorials/repeatedmeasures.html ) that with lme, one should use the following syntax: model However, I do not understand why you would "nest" the factors within the subject in the random part of the model, and not just use (1|id). What is the point of this, and what does it do? Conceptually, I don't understand why one would nest the experimental fixed factors within the random subject factor. The way I understood nesting until now, you would only use it to account for the fact that certain lower factor levels only exist within certain higher factor levels - like pupils within classes within schools within cities, etc. How does this apply to a repeated measures design with fully crossed within-subject factors? Mathematically, the way I understood this is that such a model would first estimate a random intercept for each subject, capturing random differences in the average values of the dependent variable between subjects. So in the case of, (let's say) 20 subjects, we get 20 different random intercepts. Then, apparently, the model estimates random intercepts for each combination of subject and level of factor A (resulting in 40 random intercepts), then for each combination of subject, factor A and factor B (80 random intercepts), all the way down to the most specific level, where we get as many estimated random intercepts as we have measurements (160). What is the point of this, and why would we not only estimate a random intercept per subject (1|subject)? Also, wouldn't all of these random intercepts together explain the dependent variable nearly perfectly, and leave little to nothing to be explained by the fixed effects? Lastly, my intuition tells me that these random intercepts should at least partially explain the same information as would be captured by entering random slopes of the experimental factors into the model. Is that correct?
