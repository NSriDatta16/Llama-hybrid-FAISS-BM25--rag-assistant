[site]: datascience
[post_id]: 23020
[parent_id]: 
[tags]: 
What to do after selecting a model with cross-validation?

I have been building a neural network for classification. To select my best model. I have been using 10-Fold cross validation. and selected the network that gives the highest mean accuracy. Now that I have selected the best model, I want to use all the data I have to train this model because the amount of data I have is limited (I will merge training, dev and test data). My issue is that, when training with all the data, I don't know when to stop training. Training loss is not an indicator for sure. Usually, I have a development set that I use to monitor training. When the training loss does not improve anymore, I stop training. Any suggestions on how to supervise a model with only training data? In other words, how to tell when the network needs to stop?
