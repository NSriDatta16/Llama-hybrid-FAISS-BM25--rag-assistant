[site]: crossvalidated
[post_id]: 400083
[parent_id]: 
[tags]: 
Sampling my samples: What happens to the confidence interval and the average?

I have 25 small images where some pixels contain defects (normal distr). Now I can count for every image the amount of defects and calculate the average defect per image with its CI. Due to time constraints we cannot check every pixel for defects. Therefore we sample the pixels for each, but I'm still interested in the average defect per image . My question is how can I obtain this statistic with a 95% CI for the original problem then? My idea: (5/200)*1000, with 5 defects found in the sampled 200 pixels and 1000 the total amount of pixels in the image. Is this statistically sound? Because the (5/200) is a statistic in itself..?
