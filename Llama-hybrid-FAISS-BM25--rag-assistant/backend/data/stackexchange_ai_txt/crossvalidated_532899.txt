[site]: crossvalidated
[post_id]: 532899
[parent_id]: 532890
[tags]: 
No, that's not how feature importance works. The feature importance does not understand the classes as treatments. Feature importance essentially measures how well each feature can be used to construct a split that divides the data into the classes. The feature importance does not describe one class individually . You can verify this by fitting a random forest, and saving the feature importance, and then comparing them to the feature importance of a model with the reversed class labels. Neglecting random variation, the importance measures will be similar. I'd recommend reading a high-quality reference on random forest, such as Leo Breiman's papers or the treatment in Hastie et al.'s Elements of Statistical Learning.
