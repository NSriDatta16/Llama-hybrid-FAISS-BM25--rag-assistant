[site]: crossvalidated
[post_id]: 256003
[parent_id]: 
[tags]: 
Planning VS Reinforcement Learning for Large State Spaces

Does knowing everything about your environment yield any major shortcuts to finding the optimal policy, in a Markov Decision Process with a very large (finite) number of states? Mere planning clearly requires less effort than reinforcement learning for smaller state spaces; in many cases we can just calculate the policy or value function from the transition diagram using backward induction (dynamic programming). However, when the state space becomes too large to solve, or perhaps even to represent, are we stuck with the trial-and-error methods of reinforcement learning anyhow, or are there easier algorithms to implement for large scale planning?
