[site]: crossvalidated
[post_id]: 451865
[parent_id]: 
[tags]: 
Detect abrupt change in time series

I am trying to detect abrupt change (the "bump") in my data. My end goal is to fit a decline curve that describes the overall trend of a gas well's production rate over time. When fitting my curve, I should not fit my curve from those "bumps", as they are caused by operational issues on the well site. They must be ignored. An ideal curve I want to fit would like like the below green lines: To achieve this, I'm resorting to outlier detection methods. I want to identify those "bumps" marked by the red boxes, and exclude them. FYI, the curve is described by the following model: $$q = \frac{q_i}{(1+bD_it)^\frac{1}{b}}$$ where $D_i$ and $b$ are the parameters I need to fit. Question: How can I detect those bumps in my time series?
