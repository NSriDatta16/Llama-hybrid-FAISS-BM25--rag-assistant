[site]: crossvalidated
[post_id]: 426929
[parent_id]: 426898
[tags]: 
To get you into the concept of overfitting and underfitting, here is a small approach for you: In Machine Learning you need to split your data in Train and test data: 1. Train Part X_Train, y_train where X_train are your futures and y_train is your target variable (in your case a binary target: 1: it is a face, 0 it is not a face) Then with this training data you are training your data. classifier_train(X_train, y_train )` Your classifier is trained. You can also measure your classifier now with the training data, where you do: y_train_predict = classifier_prediction(X_train) , so you will get an score between: (y_train, y_train_predict) , this is your training score/accuracy 2. Test Part Now the other part of your data comes in, your test data: Now you do not train your algorithm again, you only use the trained classifier, and run a prediction for your test data: y_test_predict = classifier_prediciton(X_test) with this you can also get an score (y_test, y_test_predict) this will be your test score. 3. Comparing train and test results If you have an train accuracy now from 0,99% and a test accurarcy from 0,2% your training is overfitting, which means that it is only good for known data and not for unknown data, this two scores should be balanced.
