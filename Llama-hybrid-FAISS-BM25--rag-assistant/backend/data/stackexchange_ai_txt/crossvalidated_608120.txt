[site]: crossvalidated
[post_id]: 608120
[parent_id]: 
[tags]: 
Proper imputation of missing values for machine learning

I always struggled to get imputation for missing values right, and it doesn't help that you can find contradictory opinions online about it. Say I have data X that I split into X_train and X_test, and I want to use a machine learning algorithm that does not handle missing values (say logistic regression or a neural network). My approach right now is to fit the standard_scaler of sklearn to my train data X_train, then use that fitted scaler to transform my test_data X_test, then fill missing values of both with 0s. The standard scaler subtracts the mean of the training samples and divides by the samples standard deviation. I combine the resulting X_train, X_tet via concatenation to get a new X (to use when evaluating etc.). In the past, I simply used the standard scaler on X before doing a train_test split, filled nas with zeros and went along with my machine learning. It seemed to me that was wrong, as I used information of my test data to fit the standard scaler. Is the approach described above reasonable and does it avoid potential pitfalls?
