[site]: crossvalidated
[post_id]: 17016
[parent_id]: 
[tags]: 
One Bayes classifier to rule them all?

I listen for tweets matching keywords. When I receive a tweet, it may or may not be part of the set of things I'm interested about. Think about the Gemini Awards, a show similar to the Oscars, in Canada. #Gemini also happens to be an astrological sign, and many, many, many people talk astrology on Twitter. Now, imagine I have thousands of those TV show keywords I'm watching for on Twitter / Facebook / et al. I thought of using Naive Bayes Classifier(s) to determine if the interaction's part of my result set or not. I want to know if I should create / maintain one classifier per TV show, or one global classifier. On the one hand, having one classifier per TV show would mean: I can parallelize training per TV show (membership tests can be parallelized for both approaches); Training is very fine grained; The classifiers answer one of two categories: in or out; A message that mentions two or more TV shows would be classified "in" by multiple classifiers; When something is really outside of what we want, we have to train all N classifiers on this; New TV shows can be trained very quickly into their resulting domain. On the other hand, one classifiers means: Only one show at a time can be trained; Only one kind of answer can be returned per message: show X or no shows; Adding a new TV show would imply a longer training period, to rebalance the common words into the different categories; Training for irrelevancy is very easy, since there is only one classifier to talk about. I'm wondering about general performance and storage characteristics for one or more Bayes Classifier. Maybe I'm also taking a completely wrong approach and should be using a different algorithm to determine membership?
