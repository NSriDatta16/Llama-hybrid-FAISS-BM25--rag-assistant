[site]: stackoverflow
[post_id]: 4366390
[parent_id]: 
[tags]: 
Linux, big text file, strip out content from line A to line B

I want to strip a chunk of lines from a big text file. I know the start and end line number. What is the most elegant way to get the content (lines between the A and B) out to some file? I know the head and tail commands - is there even a quicker (one step) way? The file is over 5GB and it contains over 81 mio lines. UPDATED : The results time sed -n 79224100,79898190p BIGFILE.log > out4.log real 1m9.988s time tail -n +79224100 BIGFILE.log | head -n +`expr 79898190 - 79224100` > out1.log real 1m11.623s time perl fileslice.pl BIGFILE.log 79224100 79898190 > out2.log real 1m13.302s time python fileslice.py 79224100 79898190 out3.log real 1m13.277s The winner is sed . The fastest, the shortest. I think Chuck Norris would use it.
