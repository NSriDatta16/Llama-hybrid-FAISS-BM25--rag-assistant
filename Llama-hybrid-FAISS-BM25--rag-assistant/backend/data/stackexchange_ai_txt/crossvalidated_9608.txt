[site]: crossvalidated
[post_id]: 9608
[parent_id]: 9599
[tags]: 
This is a problem which can be relatively easily solved using a Bayesian approach. This is one of the "re-using" the original data answers, rather than one which uses the CIs. Each coin has some long run frequency of heads $\theta_i$ $(i=1,\dots,50)$. Now you have some partial information about these frequencies, that you suspect them to be below 5%. Not exactly clear what is meant by this: do you want to test this? or do you have information which says that it should be less than 5%? And do you think its 5% because of the data, or did you think this before seeing the data? Given that you have a reasonably large amount of data, this kind of information probably won't make much difference - so I will simply ignore it. Now there has been no logical connection stated between each coin - so I will not pre-suppose that one exists. This means in words that knowing the results of one coin doesn't tell you anything about any other coin. So we start by supposing that the only thing that was known about each coin is that it is possible for each to give heads, and possible for it to give tails (i.e. we assume that if we flipped the coin until we saw both a head and a tail we would not sample forever). This results in a uniform prior for each: $$p(\theta_{i}|I)=1$$ (where $I$ simply denotes the "prior information" or assumptions contained in the problem). Now you will throw each coin $n_{i}=30$ times, and conditional on $\theta_{i}$ the number of heads observed $x_{i}$ will have a binomial sampling distribution $$(x_{i}|n_{i},\theta_{i},I)\sim Binomial(n_{i},\theta_{i})$$ The posterior distribution for each $\theta_{i}$ will have a beta distribution: $$(\theta_{i}|x_{i},n_{i},I)\sim Beta(x_{i}+1,n_{i}-x_{i}+1)\implies p(\theta_{i}|x_{i},n_{i},I)= \frac{\theta_{i}^{x_{i}}(1-\theta_{i})^{n_{i}-x_{i}}}{B(x_{i}+1,n_{i}-x_{i}+1)}$$ Where $B(a,b)$ is the beta function . Note that each posterior has mode (most likely value) equal to the observed proportion $\frac{x_{i}}{n_{i}}$. Now this is the posterior for each of the $50$ coins is always proper, well behaved, and exact even when the observed fraction is zero (no approximations have been made). Denote the number of future trials as $m_{i}$ and the unknown number of heads in these trials by $y_{i}$ So if you knew which coin you picked, then you have a posterior predictive for the next result: $$p(y_{i}|m_{i},x_{i},n_{i},\text{ith coin},I)=\int_{0}^{1}p(y_{i}|m_{i},\theta_{i},I)p(\theta_{i}|x_{i},n_{i},I)d\theta_{i}$$ $$={m_{i} \choose y_{i}}\int_{0}^{1}\theta_{i}^{y_{i}}(1-\theta_{i})^{m_{i}-y_{i}}\frac{\theta_{i}^{x_{i}}(1-\theta_{i})^{n_{i}-x_{i}}}{B(x_{i}+1,n_{i}-x_{i}+1)}d\theta_{i}$$ $$={m_{i} \choose y_{i}}\frac{B(x_{i}+y_{i}+1,m_{i}+n_{i}-x_{i}-y_{i}+1)}{B(x_{i}+1,n_{i}-x_{i}+1)}=\frac{{x_{i}+y_{i} \choose y_{i}}{m_{i}+n_{i}-x_{i}-y_{i} \choose m_{i}-y_{i}}}{{m_{i}+n_{i}+1 \choose m_{i}}}$$ Which looks like a hypergeometric like distribution, but not quite, as the "random variable" $y_{i}$ appears in different places to what you would see in a hypergeometric. This is called a beta-binomial compound distribution . Note that it is "parameter free" - it only depends on what is unknown but of interest $y_{i}$ and what is known $m_{i},x_{i},n_{i}$ - no "pluggin in" of any estimate is required - hence this is an exact inference. What if we chose one coin randomly and flipped it $m$ times? But if you now don't know which coin is going to be picked, then the answer cannot depend on $i$. To do this we simply average out, or marginalise out the $i$. Assuming that you have no reason to suspect any one coin will be preferred in the choice (what is really meant by "randomly" I think), then each is equally likely, and we get: $$p(y|m,D,I)=\frac{1}{50}\sum_{i=1}^{50}\frac{{x_{i}+y \choose y}{m+n_{i}-x_{i}-y \choose m-y}}{{m+n_{i}+1 \choose m}}$$ Where $D\equiv x_{1},\dots,x_{50},n_{1},\dots,n_{50}$ ("the data") and the $i$ subscript has been dropped from $m,y$ to indicate that the result doesn't depend on $i$ (i.e. doesn't depend on which coin is flipped). Now this is an exact answer to your problem. You can calculate a 95% interval for $y$ using this probability distribution, setting $m=30$ (since this is the sample size you used). This should give you what you are after - in that the frequentist CI is usually phrased in a predictive fashion "if we sampled again what would we likely the true value be covered by the CI 95% of the time" - a CI talks about the future.
