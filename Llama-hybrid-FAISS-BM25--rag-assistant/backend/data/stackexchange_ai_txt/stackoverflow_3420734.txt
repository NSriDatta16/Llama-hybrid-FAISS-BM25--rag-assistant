[site]: stackoverflow
[post_id]: 3420734
[parent_id]: 3420711
[tags]: 
It's not enough to know n . Allocation of an item to a bucket is a function of the item itself so, if you want a perfect hash function (one item per bucket), you need to know the data. In any case, if you're limiting the number of elements to a known n , you're already technically O(1) lookup. The upper bound will be based on the constant n . This would be true even for a non-hash solution. Your best bet is to probably just use the hash function you have and have each bucket be a linked list of the colliding items. Even if the hash is less than perfect, you're still greatly minimising the time taken. Only if the hash is totally imperfect (all n elements placed in one bucket) will it be as bad as a normal linked list. If you don't know the data in advance, a perfect hash is not possible. Unless, of course, you use h itself as the hash key rather than h%n but that's going to take an awful lot of storage :-) My advice is to go the good-enough hash with linked list route. I don't doubt that you could make a better hash function based on the relative frequencies of letters in people's names across the population but even the hash you have (which is ideal for all letters having the same frequency) should be adequate. And, anyway, if you start relying on frequencies and you get an influx of people from those countries that don't seem to use vowels (a la Bosnia a ), you'll end up with more collisions. But keep in mind that it really depends on the n that you're using. If n is small enough, you could even get away with a sequential search of an unsorted array. I'm assuming your n is large enough here that you've already established that (or a balanced binary tree) won't give you enough performance. A case in point: we have some code which searches through problem dockets looking for names of people that left comments (so we can establish the last member on our team who responded). There's only ever about ten or so members in our team so we just use a sequential search for them - the performance improvement from using a faster data structure was deemed too much trouble. a No offence intended. I just remember the humorous article a long time ago about Clinton authorising the airlifting of vowels to Bosnia. I'm sure there are other countries with a similar "problem".
