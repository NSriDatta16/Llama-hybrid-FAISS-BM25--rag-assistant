[site]: crossvalidated
[post_id]: 589418
[parent_id]: 586338
[tags]: 
With "A," "B," and "C" as mutually exclusive and unordered outcome classes in the trials of each combination of experiment ( Exp ) and treatment Group , this is a standard application of multinomial logistic regression. One Class is taken as the reference and regression coefficients then express predictor-associated differences in log-odds of each of the other classes with respect to that reference class. This differs from a set of binomial regressions against the reference class, as the probabilities among classes are constrained to sum to 1. The principles are nicely outlined in this UCLA web page , which recommends the multinom() function in the R nnet package As your data are already aggregated, you use the Counts as weights for each of the outcomes. Treat Exp as a fixed effect after making sure it's interpreted as a factor rather than numeric. The following allows for the effect of the treatment Group to differ among experiments. library(net) prop_data $Exp Exp) mnMod The overall reference is for Class "A" under Group "Control" in Exp 1. Intercepts for "B" and "C" are log-odds differences from "A" at those reference predictor values. Regression coefficients are further log-odds differences associated with Group , Exp , and the interactions between them. For these sample data you would need to pay attention to systematic differences among the experiments, as some Exp and Group:Exp (interaction) coefficients are quite significant: summary(mnMod) $coefficients/summary(mnMod)$ standard.errors ## (Intercept) GroupTreated Exp2 Exp3 ## B -34.24556 4.641310 -0.2237779 3.862921 ## C -34.56243 1.614329 -1.7310543 1.343344 ## GroupTreated:Exp2 GroupTreated:Exp3 ## B -0.04000224 -0.8928776 ## C 0.03672621 3.7516681 The coefficient estimates are assumed to have a limiting normal distribution, so these ratios to their standard errors are z-scores. A ratio with absolute value > 1.96 would be considered significant at p You might wonder what happened to all of the information about Class "A." That's implicit in the constraint that the probabilities among all classes sum to 1. Post-modeling software like the emmeans package allows you to extract that information and perform appropriate post-hoc tests. For example, if one could ignore the experiment-specific outcomes and average over the experiments, you would get the following report of Class probabilities and standard errors as a function of Group : library(emmeans) emmeans(mnMod,~Class|Group) ## Group = Control: ## Class prob SE df lower.CL upper.CL ## A 0.7898 0.00368 12 0.7818 0.7979 ## B 0.1221 0.00295 12 0.1156 0.1285 ## C 0.0881 0.00257 12 0.0825 0.0937 ## ## Group = Treated: ## Class prob SE df lower.CL upper.CL ## A 0.7336 0.00446 12 0.7239 0.7433 ## B 0.1556 0.00367 12 0.1476 0.1636 ## C 0.1109 0.00317 12 0.1039 0.1178 ## ## Results are averaged over the levels of: Exp ## Confidence level used: 0.95 That suggests that "Treated" leads to an increase in probabilities of "B" and "C" with a corresponding decrease in probability of "A."
