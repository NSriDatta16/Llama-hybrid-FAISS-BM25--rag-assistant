[site]: crossvalidated
[post_id]: 446934
[parent_id]: 
[tags]: 
Need precision about an example in a book about bayesian filters

My question is about the example here : https://github.com/w407022008/Kalman-and-Bayesian-Filters-in-Python/blob/master/02-Discrete-Bayes.ipynb#Adding-Uncertainty-to-the-Prediction paragraph : Integrating Measurements and Movement Updates . and https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/03-Gaussians.ipynb paragraph Bayes Theorem The Author says that if the sensor measure a position $z$ , his belief is that $p(x and $p(z-10 \le x Later, when he illustrates it with the Bayes' Theorem, then he says that $p(z|x)$ is the likelihood of the measurement, and use the same distribution as previously defined to model it. However something bothers me : from how he describe his belief in the sensor, I understand that, "given" (could be rephrased by "wknowing ?) a measurement z of x, he gives the probability of x lying in intervals. I feel more like it's the description of a general of $p(x|z)$ without any prior knowledge ? What is actually $p(z|x)$ (and the other terms) in the formulation of the Bayes' Theorem the author give ? I think I'm wrong but I would like to know where, and why ?
