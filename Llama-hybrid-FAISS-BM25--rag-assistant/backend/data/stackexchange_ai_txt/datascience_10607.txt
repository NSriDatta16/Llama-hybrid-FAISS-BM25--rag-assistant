[site]: datascience
[post_id]: 10607
[parent_id]: 10585
[tags]: 
I don't feel secure enough to give a definitive answer but this described situation arises in phoneme classification when the data is split up in arbitray small parts. Here even though it is the same problem it does not cause any problems I know of. So I would just give it a try violating this assumption and just see if it works. This approach is often used in machine learning. For example Naive Bayes is sometimes used when the training data does not behave like a diagonal covariance gaussian etc.
