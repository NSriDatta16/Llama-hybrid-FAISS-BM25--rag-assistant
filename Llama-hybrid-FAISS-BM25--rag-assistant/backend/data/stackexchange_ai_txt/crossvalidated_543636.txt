[site]: crossvalidated
[post_id]: 543636
[parent_id]: 543627
[tags]: 
The Bayes risk is used to attach a single number to a decision procedure $\delta(\cdot)$ , hence to rank all procedures under a given prior, and therefore to find an optimal Bayesian procedure . In the non-Bayesian or frequentist setting, the risk $$\mathbb E_\theta[L(\theta,\delta(X))]$$ is a function of $\theta$ , which makes procedures non-ordered in most settings and then prevents the derivation of an optimal frequentist procedure, unless further restrictions are imposed on the procedures. Conditioning upon the observed data $x$ leads to the posterior expected loss $$\mathbb E[L(\theta,\delta(X))|X=x]=\mathbb E[L(\theta,\delta(x))|X=x]$$ where the error is integrated out in $\theta$ wrt the posterior distribution of $\theta$ given $X=x$ . Once again, this quantity is a real number for a given realisation $X=x$ which allows for the comparison of all possible values of $\delta(x)$ [in $\delta$ not in $x$ ] and thus for the derivation of the optimal Bayesian decision value $\delta^\pi(x)$ . The optimal Bayesian decision procedure thus associates with each possible realisation $x$ of $X$ the decision value $\delta^\pi(x)$ , meaning it is feasible to always reach the optimal decision. That the marginal distribution $m(\cdot)$ is involved in the Bayes risk is of no particular concern and a consequence of the identity $$\pi(\theta) f(x|\theta) = m(x) \pi(\theta|x)$$ The Bayesian decision $\delta^\pi(x)$ depends on the actual observation $x$ and minimises the posterior loss $\rho(d,x)$ . The Bayes risk is the maginal average of the errors (posterior losses) across all possible realisations of $X$ , with theoretical uses in admissibility and minimaxity theorems, but it is not used as such to reach the optimal decision.
