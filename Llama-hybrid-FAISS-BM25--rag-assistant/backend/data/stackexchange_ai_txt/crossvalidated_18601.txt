[site]: crossvalidated
[post_id]: 18601
[parent_id]: 
[tags]: 
The variance of a random variable $X$ , sometimes called a population variance and often denoted by $\sigma^2$ , is the expected squared deviation from its mean: $$\mbox{Var}\left[X\right] = \mbox{E}\left[\left(X - \mbox{E}\left[X\right]\right)^2\right] = \mbox{E}\left[X^2\right] - \left(\mbox{E}\left[X\right]\right)^2.$$ As such, the variance measures the spread of a random variable around its expected value. The square root of the variance, is called the standard deviation . Variance is a parameter, i.e. a property of a random variable or of the population. One way to estimate that property from data, is by means of the sample variance. Concretely, assuming the population is infinite and given an independently and identically distributed random sample $X_1,\ldots,X_n$ , the sample variance is $$S^2 = (n-1)^{-1}\sum_{i=1}^n (X_i-\bar X)^2,$$ where $\bar X = n^{-1}\sum_i X_i$ is the sample average. Not all random variables have finite variance. This occurs when $\mbox{E}\left[X^2\right] $ diverges. For example, the Cauchy distribution (Student's $t$ distribution with 1 degree of freedom) does not have a finite variance.
