[site]: datascience
[post_id]: 62935
[parent_id]: 62922
[tags]: 
Neural networks are convenient for automatically building features from the data, but as far as I know this is not compatible with interpretability since we don't know what the features represent. So the only way I'm aware of to obtain predictions that can be explained and analyzed is to use traditional models, and this would certainly require a bit of feature engineering in this case. I would recommend decision trees which are completely transparent in their decision process and can be understood even by non-experts. With this kind of model the idea would be to provide the features which represent the evolution across time, e.g. min/max/average over the last N years, difference current-N, etc., possibly for several values of N.
