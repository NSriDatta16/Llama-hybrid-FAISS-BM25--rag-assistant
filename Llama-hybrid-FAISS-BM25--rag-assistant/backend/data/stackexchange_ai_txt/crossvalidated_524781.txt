[site]: crossvalidated
[post_id]: 524781
[parent_id]: 
[tags]: 
Score-probability obtained from Random Forest

Assume we have a classification problem with two classes $\{-1,1\}$ . In my research I rather need probability, than just predicted classes. I use isotonic regression to calibrate classifier. In sklearn in the description it says: Methods such as bagging and random forests that average predictions from a base set of models can have difficulty making predictions near 0 and 1 because variance in the underlying base models will bias predictions that should be near zero or one away from these values. Is my following conclusion correct? Conclusion: If one uses random forest then one should not count to much on the estimators of probability which is close to either $0$ or $1$ . Though, if the estimator is somewhere close to $0.5$ , then the estimator is more informative. Also, assume that in my case this classifier is the first step, for example, in stacked model. Then, there is no much sense in choosing very high threshold, cause the estimator is not very accurate.
