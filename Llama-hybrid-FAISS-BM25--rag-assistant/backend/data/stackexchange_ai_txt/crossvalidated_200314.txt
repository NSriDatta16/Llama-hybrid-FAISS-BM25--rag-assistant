[site]: crossvalidated
[post_id]: 200314
[parent_id]: 
[tags]: 
relationship between the policy and the reward in reinforcement learning

The aim of reinforcement learning (RL) is to make an agent learn the policy: when it is in a particular state, it must know what action to choose. At the same time, an alternative statement would be to say that in RL, the aim of the agent is to maximize cumulative rewards. I know that policy and cumulative reward are two distinct things. But how are they related in this context? Also, in a discrete RL, we usually construct a Q table of actions and states for an agent. As the number of iterations increase, the values of the table update themselves. For example, if the in a certain state $s_1$, there are three possible actions $a_1, a_2, a_3$. Let's say that somehow the Q value under $(s_1,a_2)$ is the largest among the three values, then it means that the agent will likely take action $a_2$. How are policy, Q values, cumulative rewards related to each other?
