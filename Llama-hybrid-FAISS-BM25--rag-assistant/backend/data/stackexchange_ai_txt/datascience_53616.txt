[site]: datascience
[post_id]: 53616
[parent_id]: 39095
[tags]: 
The paper explicitly states the following lines: Our work is one more point on a significant trendline started with Xception and MobileNets, that indicates that in any convolutional model, whether for 1D or 2D data, it is possible to replace convolutions with depthwise separable convolutions and obtain a model that is simultaneously cheaper to run, smaller, and performs a few percentage points better. A Convolutional neural network forms a chain of differentiable feature learning modules, structured as a discrete set of units, each trained to learn a particular feature. If trained and reused, these could be extended to be used for cosine similarity findings. Depthwise separable convolutions define individual feature paths and so it would be easy for this case where you have concatenated the outputs.
