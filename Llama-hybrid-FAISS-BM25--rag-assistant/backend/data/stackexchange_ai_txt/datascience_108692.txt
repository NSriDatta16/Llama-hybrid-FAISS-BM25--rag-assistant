[site]: datascience
[post_id]: 108692
[parent_id]: 108685
[tags]: 
Your initial thought to use embeddings is the right way to go. Token level similarity metrics such as distance and TF-IDF etc. are going to only take you so far. You will end up chasing variations in spelling, whether they are the acceptable kind (Road vs RD.) or just misspelling (Mississippi vs Missippi). You can try to build dictionaries, use lemmatizers etc., but it'll be quite the battle just to get them all correct enough. Try using SentenceBert ( https://www.sbert.net/ ). It can use different models, all trained on different datasets and with differing vector sizes. So some experimentation will be needed. Example For example, I ran a small sample that compared embeddings for the following "sentences" Address Landmark 1 First Street, NE Washington, DC 20543 US Supreme Court 1600 Pennsylvania Avenue NW, Washington, DC 20500 The White House (address) The White House The White House (name) 20 W 34th St, New York, NY 10001 Empire State Building and saw the following Cosine Similarities SCOTUS WH (addr) WH ESB SCOTUS 100.00% 83.06% 42.30% 68.60% WH (addr) 83.06% 100.00% 43.95% 69.73% WH 42.30% 43.95% 100.00% 36.20% ESB 68.60% 69.73% 36.20% 100.00% Results As you can see the name "The White House" and it's address are a 100% match. No token based approach will give us this level of match. We also have a good match between the address for the Supreme Court and the WH address, but lower on the name. Elasticsearch, KNN, etc.## YMMV with Elasticsearch depending on what you are doing with the results. Also, the same with KNN, clustering etc. Clustering will bring in a completely different dimension where you will have to understand the meaning of each cluster before you can use the outcome.
