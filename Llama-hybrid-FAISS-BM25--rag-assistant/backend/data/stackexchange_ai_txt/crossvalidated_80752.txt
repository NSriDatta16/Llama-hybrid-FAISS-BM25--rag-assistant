[site]: crossvalidated
[post_id]: 80752
[parent_id]: 80751
[tags]: 
Just as fitting each tree in the forest with a random subset sample (a bootstrap sample) of the available data adds stochasticity to improve the out-of-sample fit (by reducing the variance component of the error), so does selecting $m$ variables within which to search for each fit add stochasticity. The extra stochasticity makes each tree a poorer model than it would be without the random selection of variables and this is how the Random Forest achieves lower error over a single tree or bagging, which is Random Forests without the random selection of $m$ variables.
