[site]: crossvalidated
[post_id]: 345535
[parent_id]: 
[tags]: 
Evaluating neural network for certain task

Let us assume I have trained an object detection neural network to detect traffic lights such as here: https://youtu.be/P7j6XFmImAg Now I would like to verify the model will work well enough "in the wild". I have made a validation set and calculated mAP and IOU values, both for example ~80% and Precision and Recall ~90%. How can I confirm that these metric values are sufficient to say the model will work well enough? From my reading, a common benchmark taken is human accuracy. Then they usually compare the neural network's performance to the human's performance and say "ok, it's better than a human, therefore it should be good enough in the wild." Unfortunately, I don't have such a benchmark. Are there any other ways to verify neural network accuracy? An idea I had is to run a whole bunch of tests on the road and count the "misses" (False Negatives) and then calculate some kind of "FN occurrences per mile" metric for the network. Then maybe you could extrapolate how many miles you would have to drive to miss a light and if this is high enough for you (because you won't drive that much) then I guess you are ok going with the evaluated model.
