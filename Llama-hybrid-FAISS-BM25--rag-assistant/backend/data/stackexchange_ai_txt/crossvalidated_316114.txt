[site]: crossvalidated
[post_id]: 316114
[parent_id]: 316110
[tags]: 
The issues with accuracy are well documented. Practically : It almost certainly does not measure what you really care about. Accuracy assigns equal severity to all errors in classification. This is almost always unrealistic. Statistically : It fails to be sensitive to the probabilistic nature of classification. It is a ridiculous delusion of grandeur to believe that a predictive model should be able to preform hard class assignments, that's not how the universe works. All of our learnings from data are uncertain, and it is a careful scientist's job to quantify their uncertainty. Mixing of Concerns : Assigning classes and taking actions is a business, not a statistical, problem. A statistical model's job is to estimate predicted probabilities, which you may then use as an input to a decision rule to solve a business or scientific problem. This has many benefits, including a clean separation of concerns, an adaptability of the model to different problem domains, and an ability to estimate the expected benefits and costs of various successes or errors in decision making. Mathematically : The accuracy loss function is not even continuous, so in particular it is not differentiable, and very not-smooth. Optimization techniques work best on smooth functions, so it's unclear how one would fit such a model. Culturally: A focus on accuracy in introductory ML and statistical learning courses creates cultural problems. Observe the backlog of questions on this site evaluating their logistic regressions by naively thresholding at a 0.5 predicted probability, getting poor results in terms of accuracy, and wondering what's wrong with their model. Nothing is wrong with their model, logistic regression's job is to estimate conditional probabilities, which has been implicitly rejected. None of this has anything to do with class balance. The issue with accuracy arising from class balance is real, but secondary to deeper problems.
