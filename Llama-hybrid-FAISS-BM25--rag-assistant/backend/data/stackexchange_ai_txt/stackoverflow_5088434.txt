[site]: stackoverflow
[post_id]: 5088434
[parent_id]: 5088128
[tags]: 
I think the both @Jon Skeet and @Jeremiah Willcock's answers are describing using MRU as a way to avoid polluting the cache with useless entries. This only works if your cache APIs allow you to change the policy on the fly; e.g. on a per-request basis. Setting your cache policy to MRU in "normal" situations is probably a bad idea ... because your cache becomes ineffective once it fills up. MRU has the problem that if you get a hit on an entry that is often used in "normal" mode while doing MRU lookups, you end up throwing out the entry ... Better alternatives to MRU for doing a scan without poluting the cache are: bypass the cache entirely, probe the cache without doing a read through / update, and without altering the LRU chains. For what it is worth, I cannot think of any use-cases for MRU that don't fit this general pattern. Incidentally, @Jon Skeet's example of buses arrivals is not always borne out in reality due the bunching effect. If a bus is running late, there are likely to be more than average people waiting at each bus stop. The bus has to stop more frequently, and stays longer at each stop. This slows down the late bus. A bus that is on time that is following the late bus will typically have fewer people than the average waiting at each bus stop. (Because they just go onto the late bus.) This speeds up the following bus. The net result is that the buses tend to bunch up. See: https://en.wikipedia.org/wiki/Bus_bunching
