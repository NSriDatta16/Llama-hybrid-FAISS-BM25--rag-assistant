[site]: crossvalidated
[post_id]: 402035
[parent_id]: 402021
[tags]: 
Yes. We often conceptualize uncertainty as making inferences about the population from a sample but it is far from the only appropriate use of hypothesis testing. Think of each clinic's outcome as the realization of a random variable - your question is not whether the averages for the two groups of clinics diverged after the policy change, which you can calculate exactly, but whether the divergence is more than would be expected due to the underlying randomness. The easiest way to implement DiD is to formulate it as a regression and just run OLS: $Performance_{c,t} = \alpha + \beta_{1}*D_{after,c,t} + \beta_{2}*D_{intervention,c,t} + \beta_{3}*D_{after,c,t}*D_{intervention,c,t} +\epsilon_{c,t}$ where $D_{after,c,t}$ is a dummy variable that is set to 1 for observations after the change and 0 before it and $D_{intervention,c,t}$ is a dummy variable that is set to 1 for observations in the intervention group. $\beta_{3}$ is your DiD estimator and the regression will give you it's standard error, confidence interval, and t-statistic. This also makes it easy to include additional explanatory variables or adjust the standard errors for clustering if you think it makes sense in your setting. You can use that information, but it is no longer a "difference-in-differences" analysis. It is often called a "dose-response" analysis. For an example, see this paper: Health insurance and opioid deaths: Evidence from the Affordable Care Act young adult provision .
