[site]: crossvalidated
[post_id]: 116088
[parent_id]: 116064
[tags]: 
Assume you have time series on a variable $Y$ and on a variable $X$, say both non-negative, and based on some idea of yours you believe that there is a reasonable argument that they can be linked by a linear relationship $$y_t = \beta x_t + u_t \tag{1}$$ Now say that your theoretical argument is basically sound, but it captures how $Y$ relates to $X$ around a positive deterministic time trend , denote it $d_t =1,2,...$. In reality therefore, the true relationship is $$y_t = \beta x_t + \gamma d_t + v_t \tag{2}$$ where $v_t$ has all the nice properties. But you are impatient, you don't even graph the series to see how they evolve over time, and you go on and estimate model $(1)$ by OLS. You will obtain $$\hat \beta = \frac {\sum_{t=1}^Tx_ty_t}{\sum_{t=1}^Tx_t^2}$$ and inserting the true equation $(2)$ for $y_t$ into this, you will get $$\hat \beta = \beta + \frac {\gamma\sum_{t=1}^Tx_id_t +\sum_{t=1}^Tx_tu_t}{\sum_{t=1}^Tx_i^2}$$ Consider the expected value of the estimator conditional on the regressor series $$E(\hat \beta \mid X) = \beta + \frac {\gamma\sum_{t=1}^Tx_id_t }{\sum_{t=1}^Tx_i^2}$$ which explodes as $t$ increases since $d_t$ increases, going away from the true value of the parameter. This happens because the estimator is forced to incorporate the existence of the time trend into the estimate of $\beta$. In practice if you start with a sample of length $T$ and then gradually increase the sample length, you will see the OLS estimate of $\beta$ to increase also, making the whole estimation useless. This is the most basic example to show that stationary and non-stationary data "don't mix". It would be instructive to work the reverse case. Assume that $y_t$ is stationary, and you try to regress it on a time trend. Say, the true model is $$y_t = \alpha + v_t$$ but you specify and estimate $$y_t = \alpha + \gamma d_t + u_t$$ What will happen here? ADDENDUM Responding to conversation in the comments, the essence of the answer above is that if some of our data series are stationary, and some non-stationary, putting them together through an estimation algorithm will not provide meaningful results. But , there exist techniques to transform the data series so that they become stationary, and then we can execute estimation (since now all data series involved in the estimation have become stationary), and obtain meaningful results. Detrending or Differencing a non-stationary series is the most usual such technique. Moreover, there exists the phenomenon of co-integration, where, say, two stochastic processes are both non-stationary, but there exists a vector of constants that makes their linear combination weighted by this vector a stationary process. In such cases, regressing the one non-stationary series on the other non-stationary series provides meaningful results, and in some cases it is even to be preferred from the alternative approach, i.e. to, say, differencing both series to make them both stationary.
