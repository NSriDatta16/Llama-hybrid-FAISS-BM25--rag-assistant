[site]: crossvalidated
[post_id]: 421269
[parent_id]: 
[tags]: 
Bayesian Hypothesis Tests with continuous priors

I am new to the Bayesian world, and I'm trying to understand how hypotheses tests are performed here (as opposed to the frequentist framework). I am aware that likelihoods, priors and posteriors can be discrete or continuous. And once we have calculated posteriors, we can build a lot of things like credible intervals and so on. Now, the problem arises when I'm applying this to hypotheses tests. So far I encountered situations where there were a finite number of hypotheses to compare ( $H_0$ , $H_1$ , $H_2$ ..), as well as a discrete number of parameters associated to them. For example , I'm tossing a coin n times with associated observations $X_1, ..., X_n$ where: $$X_i \sim Bernoulli(\theta)$$ where $\theta$ is the probability of getting heads. I want to test whether this coin is loaded or not and I may have prior beliefs such that: \begin{cases} p(\theta=0.5) = 0.5\\ p(\theta=0.7) = 0.5\end{cases} I would then have my hypotheses $H_0$ (coin is fair) and $H_1$ (coin is loaded). I would then calculate a posterior for each hypothesis and conclude. But what if $\theta$ was continuous ( e.g. follows a Uniform distribution) ? What would my hypotheses be ? And how to calculate them ?
