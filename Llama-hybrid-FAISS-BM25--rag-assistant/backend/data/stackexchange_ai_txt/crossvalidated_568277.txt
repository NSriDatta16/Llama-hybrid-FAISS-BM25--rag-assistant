[site]: crossvalidated
[post_id]: 568277
[parent_id]: 567696
[tags]: 
a) Neither bias nor imprecision are desirable, and I don't recall anyone arguing that one is (in principle) worse than the other. The issue is that they are both reasons why your sample statistic differs from the population parameter it estimates. Bias and imprecision could be relatively worse in a particular condition or using a particular estimator, which is what the trade-off is all about (see next point). b) No, you would never prefer an estimator with higher (R)MSE. (Root-)mean-squared error sums the (squared) bias and sampling variance, so it is a composite summary of "how incorrect you can expect your estimate to be, on average," taking both bias and imprecision into account. Thus, (R)MSE provides a reasonable way to compare one estimator that is biased but precise vs. another that is imprecise but unbiased. c) Yes, if the meta-analysis aggregates a sufficient amount of data, then it could overcome the lack of precision of unbiased estimation. But finding unbiased results is a huge practical problem for meta-analysis (e.g., publication bias).
