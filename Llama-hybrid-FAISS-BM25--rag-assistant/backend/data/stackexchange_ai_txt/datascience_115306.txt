[site]: datascience
[post_id]: 115306
[parent_id]: 115302
[tags]: 
In general, test data insights should not affect our decisions, and test data should not leak into model training process. What happens when we perform certain actions before splitting? Exploration : if we split the sets ourselves, we assume the distributions having no significant differences, so performing exploratory analysis on the full data is acceptable. Feature selection : once again, if we assume the distributions to be roughly the same, stats like mutual information or variance inflation factor should also remain roughly the same. I'd stick to selection using the train set only just to be sure. Imputing missing values : filling with a constant should create no leakage. Strategies like filling with mean values result in a leakage (albeit a minor one, if it's a school project, reviewers are known to often turn a blind eye on that). Dropping outliers : if we expect the real input data to be filtered the same way, it can be done before splitting. Otherwise it's just cheating (we exclude observations that are hard to predict from all sets). Feature encoding : depends on the encoding strategy. OHE shouldn't result in a leakage, target encoding would make a huge leak. Feature engineering : if we operate within a single observation (like, adding two features' ratio), there's no leak. If it's based on other observations somehow, it's a leak (this applies to most scaling methods just as well). If it considers target too (e.g. SymbolicTransformer()), the leak becomes really huge.
