[site]: crossvalidated
[post_id]: 135324
[parent_id]: 135135
[tags]: 
Let's plot your data: opar We can already see a couple of things: Your series have very unequal lengths. You typically have a peak near the beginning - but the peak can also occur one third into the series (see series 2), with very low sales before that. You may have a secondary peak around mid-way through your series (series 1 & 3), but not necessarily (series 2). Your series differ very much in scale (which is not evident from the plots), with totals between 2786 (series 1) and 41908 (series 3). This will be very, very hard to forecast if you have high hopes for accuracy. "Typical" time series forecasting algorithms like ARIMA or Exponential Smoothing will not work here. They forecast univariate series out into the future. I would start with a simple approach. For instance, we could first rescale your series to a target length. I'll use the median length of your series, but if you know that your actual data will have a length of 50, you can use that. dest.length I'll rescale linearly, using an appropriate matrix. Check this for small values of nsource and ndest to understand what is happening here. make.scale.matrix We rescale each entry of a list using lapply() : tt.rescaled Let's plot the rescaled series: opar As you can see, these still look similar to your original series, but now they are comparable, because they have the same length. In addition, the rescaling keeps the original totals over time: > sapply(tt,sum) [1] 2786 9476 41908 > sapply(tt.rescaled,sum) [1] 2786 9476 41908 So, now we can do some extremely simple modeling and forecasting. For instance, we can simply take pointwise averages: forecast As you see, this average is dominated by series 3, which has the highest sales. An alternative would be to forecast total sales (e.g., as the average or the median of total sales) and the "lifecycle" (as the average of each rescaled series' lifecycle) separately: lifecycle We now see three peaks: the first and the third peak come from series 1 & 3, the second peak from series 2. Is the first or the second forecast better? It's hard to tell. Of course, you could also start going over this with a kernel smoother or some such. I would recommend using some very simple approach like this one. Don't overthink the statistical part. Instead, spend your time on getting more information. Can you find out: why a series has a certain length why a series has its initial peak right at the beginning or later why a series has a second peak or not why the total amount for a series is what it is All data along these lines will help you understand your time series better, and you will be able to use this in forecasting. Until then, you should also work on the entire process. Is it a problem if you mistime a peak? Or not? Or is getting the total wrong worse?
