[site]: datascience
[post_id]: 41337
[parent_id]: 
[tags]: 
prediction for a linear sum

I am learning about SVMs in particular linear SVMs through many questions here. However, one problem i faced is that there seems to be no indepth explanation on how does linear SVM works in terms of predicting new data. I understand that the main purpose of SVM is to find linear separating hyperplane $w^Tx+b$ and a linear SVM is actually a set of super long equation. Let's consider a 2 class problem : A and B. Suppose $(w^*,b^*)$ are the minimizing hyperplane parameters for a fixed choice of $\lambda$ . Then how we classify a new, unlabeled test point $x_{test}$ ? Simple way that I thought would be reasonable is to have $(w^*)^Tx+b^*>0$ to class A and $(w^*)^Tx+b^* to class B. But how do we assign if it's 0 and what if there is an outlier in other class for example? IS this a good way of labeling test data?
