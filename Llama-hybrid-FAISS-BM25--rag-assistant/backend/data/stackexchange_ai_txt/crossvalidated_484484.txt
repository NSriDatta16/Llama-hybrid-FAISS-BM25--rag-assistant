[site]: crossvalidated
[post_id]: 484484
[parent_id]: 484307
[tags]: 
It is not unusual at all to get negative confidence limits with small datasets. They are due to using naive normal-theory intervals: $\hat p \pm z_{\alpha/2}SE(\hat p)$ . When $\hat p$ is small and the sample size is small, the $\pm$ part can easily exceed $\hat p$ , leading to a negative bound. There is kind of a workaround for this. The "prob" mode involves considerable post-processing, so by the time we get to the estimates themselves, it is way too late. However, the transform argument is passed to the reference grid right after it is constructed, along with auxiliary arguments such as N.sim . So we can get the software to simulate values from the sampling distribution on the linear-predictor scale; then those simulations are used henceforth as if they were samples from a posterior distribution. This does a much better job of keeping us in bounds: > (emm2 = emmeans(MULTI,~G*IND, mode = "prob", transform = "pass", N.sim = 1000)) Generating a posterior sample of size 1000 G IND prob lower.HPD upper.HPD G1 A 0.251 0.0724 0.455 G2 A 0.303 0.0298 0.578 G1 B 0.549 0.3216 0.763 G2 B 0.487 0.1979 0.812 G1 C 0.203 0.0181 0.378 G2 C 0.197 -0.0156 0.465 Point estimate displayed: median HPD interval probability: 0.95 > pairs(emm2) contrast estimate lower.HPD upper.HPD G1 A - G2 A -0.05611 -0.36235 0.2973 G1 A - G1 B -0.29662 -0.66566 0.0561 G1 A - G2 B -0.24502 -0.60983 0.1033 G1 A - G1 C 0.04915 -0.23211 0.3643 G1 A - G2 C 0.04872 -0.25559 0.3496 G2 A - G1 B -0.24292 -0.59601 0.1025 G2 A - G2 B -0.18666 -0.69630 0.3710 G2 A - G1 C 0.10710 -0.19314 0.4655 G2 A - G2 C 0.10372 -0.32463 0.4908 G1 B - G2 B 0.06313 -0.32163 0.4363 G1 B - G1 C 0.35135 0.00661 0.7039 G1 B - G2 C 0.35400 0.03511 0.6642 G2 B - G1 C 0.29695 -0.03502 0.6413 G2 B - G2 C 0.29292 -0.21142 0.7314 G1 C - G2 C 0.00192 -0.28734 0.2834 Point estimate displayed: median HPD interval probability: 0.95 Note that this produces a Bayesian-like summary based on highest posterior density regions. It didn't keep all the limits from going negative, but they are a lot better behaved. (You can do summary(emm2, point.est = mean) if you would rather see means instead of medians; it will not change the intervals.) You can't use cld() on these results, but that's a method I recommend against anyway. Postscript I was surprised to see any negative values at all, so I traced this and found out that the simulations not done early as I had thought, but are done on the final results on the "prob" scale. They still behave a lot better, probably because the covariances among the estimated $\hat p$ values are taken into account. I will investigate why it didn't work at the linear-predictor level as I had described. Postscript 2 Adding transform = "response", N.sim = ... does already work correctly for ordinal models, just not for multinom because it turns out this doesn't use regrid() until later. I souped-up the multinom support so this does also work for multinom (the transform option is not necessary.) > emmeans(MULTI,~G*IND, mode = "prob", N.sim = 1000) Simulating a sample of size 1000 G IND prob lower.HPD upper.HPD G1 A 0.247 0.0888 0.437 G2 A 0.296 0.0845 0.572 G1 B 0.535 0.3251 0.742 G2 B 0.477 0.2196 0.779 G1 C 0.197 0.0684 0.415 G2 C 0.183 0.0227 0.456 Point estimate displayed: median HPD interval probability: 0.95 You need to install this from GitHub or wait until this is updated on CRAN (probably version 1.5.1)
