[site]: crossvalidated
[post_id]: 617894
[parent_id]: 
[tags]: 
Distribution of a conditional expectation

I am interested in calculating the distribution of a conditional expectation, I would like some help figuring out if I am on the right track. Consider a variable $x\sim f(x)$ and a noisy signal $s$ of $x$ drawn from $g(s;x)$ . Consider $E(x|s)$ computed using Bayes' rule. I am interested in the distribution of all possible values of $E(x|s)$ which I will call $q(z)$ , which I think I can define as $$ q(z) = \int 1(E(x|s)=z) g(s;x)ds $$ where 1 is the indicator function. My question is whether my definition of $q(z)$ makes sense or if there is a better/conventional way to define it. I am somewhat confused because the law of iterated expectations states that $E_sE(x|s)=E(x)$ but this should only imply $E(q(z))=E(f(x))$ , correct? To help understanding what I am after, for example, consider $x\sim U[0,1]$ and $s$ one Bernoulli draw with parameter $p=x$ . Then using Bayes' rule $E(x|s=1)=2/3$ and $E(x|s=0)=1/3$ (the prior is a Beta(1,1), the two posteriors are Beta(2,1) and Beta(1,2) with averages 1/3 and 2/3). The two values of the conditional expectations which are equally likely because of the symmetry of f(x), therefore $$q(x) = \begin{cases} 1/2 & \text{if } x=1/3 \\ 1/2 & \text{if } x=2/3 \\ 0 & \text{otherwise} \end{cases}$$
