[site]: crossvalidated
[post_id]: 139236
[parent_id]: 93010
[tags]: 
I have myself come to a very similar question, and I think i do now understand whats going on. I'll try to explain... :) I found [1] quite helpfull to come to my conclusions. I also want to stress, that I'm not entirely sure about the stuff that follows, so please correct me if I'm wrong. Assume you do the followin sampling: $$\mathbf{v^0} \rightarrow \mathbf{h^0} \rightarrow \mathbf{v^1}$$ where $\mathbf{v_0}$ is a visible binary data vector from your training set $\mathcal{T}$, $\mathbf{h^0}$ is the first sampled hidden binary vector and $\mathbf{v^1}$ is the first sampled visible vector (sampled from binary $\mathbf{h^0}$ and NOT its activations). For a parameter update $\Delta w$ (taking CD1) of the weight matrix you usually write: $$ \Delta w \propto \left _\mathcal{T} - \left _\mathcal{T}$$ In [1] they rewrite the first bracket $\left _\mathcal{T}$ as $\left _{p(\mathbf{h^0}|\mathbf{v^0},w)}\right>_\mathcal{T}$. The inner brackets average over the distribution of sampled hidden vectors for a specific data vector $p(\mathbf{h^0}|\mathbf{v^0},w)$ from the training set. This distribution is given by the activation probabilities for sampling $\mathbf{h_0}$ (lets call them $\mathbf{a_h^0}$) , hence you can directly perform the inner average by taking $\mathbf{a_h^0} \mathbf{v^0}$. I think for the second bracket, one can write: $$ \left _\mathcal{T} = \left _{p(\mathbf{v^1}|\mathbf{h^0},w)}\right>_{p(\mathbf{h^0}|\mathbf{v^0},w)}\right>_\mathcal{T} $$. Here we can only perform the most inner average by taking the activations of the visible layer $\mathbf{a_v^1}$. One can easyly see this from the following (onedimensional) example. Lets assume the probability to be active (h or v equals 1) is given by a sigmoid function: $$ P(h = 1 | v) = \mathcal{S}(v) \\ P(v = 1 | h) = \mathcal{S}(h)$$ the expectation values then read: $$\left _{p(h|v)} = 1\times v\times \mathcal{S}(v) + 0 \times v \times (1-\mathcal{S}(v)) = v \times \mathcal{S}(v)$$ whereas for the second bracket one obtains: $$\left _{p(v|h)}\right>_{p(h|input)} = \left _{p(h|input)} = \mathcal{S}(1)\times \mathcal{S}(input) \neq \mathcal{S}(a_h)\times \mathcal{S}(input)$$. The essence: For $CDn$ with $n>1$ we always have several nested expectation values. We can only replace the very last sampling of the Gibbs chain by their corresponding activations. I think the above should explain 3.1 "It is very important to make these hidden states binary, rather than using the probabilities themselves. [...] For the last update of the hidden units, [...] use the probability itself" When doing reconstructions, one usually does only one step of propagation ($v\rightarrow h$ or $h\rightarrow v$). Hence one can directly use the activations (i.e. probabilities) to get an expectation value of the sampling error. As stated above, all of the above might be wrong. Therefore, I would be really glad if someone with more insight could comment on this explanation. [1]: Carreira-Perpinan, Miguel A., and Geoffrey E. Hinton. "On contrastive divergence learning." Proceedings of the tenth international workshop on artificial intelligence and statistics. NP: Society for Artificial Intelligence and Statistics, 2005.
