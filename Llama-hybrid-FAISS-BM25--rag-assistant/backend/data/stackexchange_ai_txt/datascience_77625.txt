[site]: datascience
[post_id]: 77625
[parent_id]: 77583
[tags]: 
I think what you are describing would be called anomaly detection. I suggest trying a different approach. There are several standard solutions to deal with this topic, here are a few. Main problems to address are: Setting a good threshold to balance false alarms with missed events. Selecting the model will influence this setting (see below for 2 typical models) Correct Labels/responses: If you have enough examples of alarms that are labelled correctly, you might look at clustering methods to determine the correct labels for un-labelled or mis-labelled examples. This will give you a larger dataset to use for training. Selecting the model: Model 1: Manual - Multivariate using the Covariance Matrix Alarm settings to decrease false alarms: You can use Euclidean (for spherical distributions), or better yet, Mahalanobis (for ellipsoidal distributions) distance and a n Sigma threshold from the centroid to determine what is the normal reading for the machine and then setting a cutoff for what is normal vs what is an anomaly. Model 2: Neural Network - Autoencoder Train on normal data (filter out alarm data) and test on new data looking at the probability distribution in the re-construction error in the model output (high MAE), and selecting a threshold based on the output Online reference (may need account to access): https://towardsdatascience.com/how-to-use-machine-learning-for-anomaly-detection-and-condition-monitoring-6742f82900d7
