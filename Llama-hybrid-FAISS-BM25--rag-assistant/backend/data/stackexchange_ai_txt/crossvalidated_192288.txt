[site]: crossvalidated
[post_id]: 192288
[parent_id]: 
[tags]: 
Is it possible to do random forest with multiple responses or combine such ensembles for multi-label classification?

I have a dataset which has numerous nominal responses, and many predictors. Each response is basically a pass/fail check of a certain test applied to the data. Multiple methods are applied to each sample, so some methods pass and some fail for each sample. We have measurements of each sample that are the predictors. X1 X2 X3 X4 ... Y1 Y2 Y3 0.3 0.7 0.2 1.3 ... 0 1 1 0.1 0.3 0.4 1.5 ... 1 1 0 0.4 0.5 0.6 1.0 ... 0 0 1 ... 0.3 0.3 0,7 1.2 ... 1 1 1 The idea is to create a decision tree which will identify which method is best under each condition (best being the method which will most pass with highest accuracy given the measurements). I've tried using randomForest in R and using the combine function but it cannot combine different responses. Am I going about this the wrong way? Random forests is the considered method because you can test the significance of each predictor. SVM is another idea but it's a somewhat black box method and no insight into the effect of each predictor on the outcome. Is there a way to chain the binary classifiers? Merge the binary classifiers for each method into one?
