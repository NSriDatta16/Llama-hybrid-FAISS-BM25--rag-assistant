[site]: stackoverflow
[post_id]: 5743979
[parent_id]: 5707353
[tags]: 
First of all, I would like to point you to the function that already implements Single-level Multi-dimensional Transform ( Source ). It returns a dictionary of n-dimensional coefficients arrays. Coefficients are addressed by keys that describe type of the transform (approximation/details) applied to each of the dimensions. For example for a 2D case the result is a dictionary with approximation and details coefficients arrays: >>> pywt.dwtn([[1,2,3,4],[3,4,5,6],[5,6,7,8],[7,8,9,10]], 'db1') {'aa': [[5.0, 9.0], [13.0, 17.0]], 'ad': [[-1.0, -1.0], [-1.0, -1.0]], 'da': [[-2.0, -2.0], [-2.0, -2.0]], 'dd': [[0.0, 0.0], [0.0, -0.0]]} Where aa is the coefficients array with approximation transform applied to both dimensions (LL) and da is the coefficients array with details transform applied to the first dimension and approximation transform applied to the second one (HL) (compare with dwt2 output ). Based on that it should be fairly easy to extend it to the multi-level case. Here's my take on the decomposition part: https://gist.github.com/934166 . I would also like to address one issue you mention in your question: There is one catch though: It represents the wavelet coefficients as an array of the same shape as the data. The approach of representing results as an array of the same shape/size as the input data is in my opinion harmful. It makes the whole thing unnecessarily complex to understand and work with because anyway you have to make assumptions or maintain a secondary data structure with indexes to be able to access coefficient in the output array and perform an inverse transform (see Matlab's documentation for wavedec/waverec). Also, even though it works great on paper, it does not always fit real world applications because of the problems you have mentioned: most of the times input data size is not 2^n and the decimated result of convolving signal with wavelet filter is larger that the "storage space", which in turn can lead to data loss and non-perfect reconstruction. To avoid these problems I would recommend using more natural data structures to represent the result data hierarchy, like Python's lists, dictionaries and tuples (where available).
