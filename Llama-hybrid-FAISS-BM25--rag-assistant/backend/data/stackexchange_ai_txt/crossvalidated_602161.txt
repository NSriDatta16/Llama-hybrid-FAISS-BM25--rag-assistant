[site]: crossvalidated
[post_id]: 602161
[parent_id]: 
[tags]: 
Should you scale the dataset (normalization or standardization) for a simple multiple logistic regression model?

I have read a lot of conflicting literature about scaling the dataset (using methods such as normalization or standardization) for a multiple logistic regression model, and I am wondering if scaling is necessary for this type of machine learning model. For example, this source ( Is it a good practice to always scale/normalize data for machine learning? ) supports the use of scaling methods for logistic regression: For machine learning models that include coefficients (e.g. regression, logistic regression, etc) the main reason to normalize is numerical stability. Mathematically, if one of your predictor columns is multiplied by 10^6, then the corresponding regression coefficient will get multiplied by 10^{-6} and the results will be the same. This source ( Is normalizing the features always good for classification? ) states that parametric algorithms such as logistic regression should implement scaling methods: Typically decision trees (for instance C4.5, implemented as J48 in Weka you used) are non parametric, that is they don't make any assumption regarding the distribution of the data. As long as the normalization doesn't change the ranks of the data (and I know of no normalization that does that), the results will be exactly the same (you will only get different splitting levels). Of course this doesn't hold for algorithms making parametric assumptions (logistic regression, etc.) So you shouldn't always normalize, but you should decide to do it or not depending on your algorithm. And this source ( When conducting multiple regression, when should you center your predictor variables & when should you standardize them? ) has an answer that also supports the use of scaling: In regression, it is often recommended to center the variables so that the predictors have mean 0. This makes it easier to interpret the intercept term as the expected value of Yi when the predictor values are set to their means. However, in the same source ( When conducting multiple regression, when should you center your predictor variables & when should you standardize them? ), another answer states that scaling is not necessary: You have come across a common belief. However, in general, you do not need to center or standardize your data for multiple regression. Different explanatory variables are almost always on different scales (i.e., measured in different units). This is not a problem; the betas are estimated such that they convert the units of each explanatory variable into the units of the response variable appropriately. Another source ( What algorithms need feature scaling, beside from SVM? ) referenced a list from dataschool.io that states that logistic regression does not need feature scaling unless it is regularized. The list from dataschool.io can be found here: https://www.dataschool.io/comparing-supervised-learning-algorithms/ Could someone clarify whether or not I should use scaling methods on the dataset for a multiple logistic regression model? Thank you so much for taking the time to read this.
