[site]: crossvalidated
[post_id]: 332246
[parent_id]: 
[tags]: 
Using a Neural Network as a replacement for Fractional Logit; Which Cost Function to Use?

I am working on a deep neural net model to estimate the monthly mortgage prepayment ratio for a large loan portfolio (this ratio is called $SMM$ in finance literature, all you need to know is that $0\leq SMM\leq1$). My basic approach is to extend the methodology in (Papke- Wooldridge 1996) paper on modelling fractional outcomes. So I started by replacing the $G(z)$ (sigmoid function in the above paper) by a deep NN. minimizing the negative Bernoulli log-likelihood function: $$\text{argmin}_\theta\left(-\sum_i y_i\log[G(X_i\theta)]+(1-y_i)\log[1-G(X_i\theta)]\right)$$ My question is: what is the conceptual difference between using the above cost function as opposed to the usual Mean Squared Error cost for a regular quantitative response $0\leq y \leq1$?
