[site]: crossvalidated
[post_id]: 166379
[parent_id]: 165235
[tags]: 
1.6(c) From the Central Limit Theorem we know that as the number of samples from any distribution increases, it becomes better approximated by a normal distribution. This is not what the central limit theorem says. The CLT does not hold for every distribution, and in its standard form it concerns properly scaled and standardized sample averages. The statement $\sum_{i=1}^n X_i \underset{n \to \infty}{\to}N(n\mu_x,.)$ is not quite correct, even if we take the mode of convergence to be understood from the context. If $n$ approaches infinity, you cannot have an $n$ left on the right hand side. Indeed, if the $X_i$ are independent and identically distributed geometric random variables, $\sum_{i=1}^nX_i \overset{a.s}{\to} \infty$ so certainly the sum cannot converge in distribution, which is a weaker form of convergence, to something else. You can save your argument by being more careful with the central limit theorem, however.
