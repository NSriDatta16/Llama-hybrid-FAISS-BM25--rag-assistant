[site]: crossvalidated
[post_id]: 306031
[parent_id]: 204646
[tags]: 
If you only have a few variables, like in the example, then you should have no problem with some variant of lme4 . Where machine learning techniques really shine is when you've got a lot of variables and you wish to model nonlinearities and interactions between your variables. Few ML approaches have been developed that can do this with longitudinal data. RNNs are one option, though these are generally optimized for time series problems, rather than panel data. In principle, a feed-forward neural network is a (generalized) linear model, with regressors that are nonlinear functions of the input data. If the derived regressors -- the top layer of the model before the output -- are considered the nonparametric part, then there is nothing stopping you from adding parametric structure along with it -- perhaps in the form of random effects. This hasn't been implemented however for classification problems, which I assume that you're doing because you're interested in SVM as a candidate.
