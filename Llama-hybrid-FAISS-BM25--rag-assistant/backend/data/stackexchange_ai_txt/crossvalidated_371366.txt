[site]: crossvalidated
[post_id]: 371366
[parent_id]: 371331
[tags]: 
You are right that the state space is $3^{64}$ . If you had a table of $Q$ values for each of these states, that would be valid RL. However, such a large table is probably infeasible to store. In the "learning from pixels" setting, the state size is $256^{3HW}$ , where $H$ and $W$ are the height and width of the display respectively. In these environments, instead of using a table to map $(s,a)$ pairs to a $q$ -value, it is more feasible to find a function $\hat q(s,a; \theta)$ which maps state and action to (an approximated) $q$ -value. The parameters $\theta$ of this function can be stored compactly compared to the table you would need. Also see this question on how CNNs are involved.
