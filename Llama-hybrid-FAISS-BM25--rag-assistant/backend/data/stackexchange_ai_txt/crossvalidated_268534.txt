[site]: crossvalidated
[post_id]: 268534
[parent_id]: 175271
[tags]: 
You can avoid inverting the matrix by generating draws by means of the eigendecomposition method. According to this method, the draws are generated by doing this product: $$ (V D)^\top X^\top \,, $$ where $V$ is the eigenvectors of the matrix, $D$ is a diagonal matrix containing the square roots of the eigenvalues and $X$ is a matrix containing draws from the standard univariate $N(0,1)$ distribution. It is straightforward to adapt this method and avoid recovering the original covariance matrix by using these results: 1) the eigenvalues of a matrix $A$ are the reciprocal of the eigenvalues of its inverse $A^{-1}$; 2) the eigenvectors of a matrix A are also eigenvectors of its inverse $A^{-1}$. Example: Let's say that the original covariance matrix is the following: $$ A = \left[ \begin{array}{rrr} 1 & 0.8 & -0.4 \\ 0.8 & 2 & 0.3 \\ -0.4 & 0.3 & 3 \end{array} \right] \,. $$ But you have the inverse of this matrix, $B=A^{-1}$: $$ A^{-1}= B = \left[ \begin{array}{rrr} 1.699 & -0.725 & 0.299 \\ -0.725 & 0.817 & -0.178 \\ 0.299 & -0.178 & 0.391 \end{array} \right] \,. $$ The eigendecomposition method based on the original matrix $A$ yields the following covariance matrix for a sample of draws: A Using the matrix that you have (the inverse of A ), you just need to invert the eigenvalues: B A covariance matrix closely matching the original one is obtained and we didn't need to invert B in order to recover the original covariance matrix A . A small simulation to check the validity of this approach: set.seed(3) niter We can see that the covariance matrix of the draws are on average very close to the original covariance matrix A .
