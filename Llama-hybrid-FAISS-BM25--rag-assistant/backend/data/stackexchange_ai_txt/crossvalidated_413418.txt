[site]: crossvalidated
[post_id]: 413418
[parent_id]: 
[tags]: 
Using the $Z$-test instead of the binomial test for small $n$ - effect on power and Type I error

Setup Let $M \sim \text{Bin}(p,n)$ . Let us then state the following two hypotheses: $$\begin{align} H_0: p = 0.5 \text{ vs } H_1: p > 0.5 \end{align}$$ To test these hypotheses, I could use the exact binomial test with the following decision function: \begin{align*} \delta(M) = \begin{cases} 1, & \text{if } M > q_{(H_0,1-\alpha)}; \\ 0, & \mbox{otherwise.}\end{cases} \end{align*} Here, $q_{(H_0,1-\alpha)}$ denotes the ( $1-\alpha$ )-quantile of the ${\text{Bin}(0.5,n)}$ -distribution. Alternatively, I could transform the variable into a $Z$ -statistic $$Z_n = \frac{\sqrt{n}(\hat{p}-0.5)}{\sqrt{\hat{p}(1-\hat{p})}} \xrightarrow{d} \mathcal{N}(\sqrt{n}\frac{\hat{p}-0.5}{\sqrt{\hat{p}(1-\hat{p})}},1)$$ with $\hat{p} = M/n$ and corresponding decision function \begin{align*} \delta(Z_n) = \begin{cases} 1, & \text{if } Z_n > z_{(1-\alpha)}; \\ 0, & \mbox{otherwise.}\end{cases} \end{align*} If $n$ is high enough, the two tests should have the same power and Type I errors. However, I am interested in how this transformation affects the Type I errors and the power of the my test if $n$ is low. Problem description I simulated 100'000 independent significance tests for each combination of $p_0 = 0.5$ and $p_1 \in [0.01,0.02,\dots,0.98,0.99]$ and calculated the average number of rejections (that is, $\delta(\cdot) = 1$ at $\alpha = 0.05$ ) for each pair of $p_0$ and $p_1$ . The simulations were done by simulating independent draws from $\text{Bin}(p_1,n)$ -distributions, followed by calculation of the two test statistics and comparison with the respective significance thresholds. The results for $n=5$ and $n=10$ are shown below: The dashed lines represent the theoretical power curves, the solid lines with circles represent the empirical ones (i.e. the ones I simulated). The two solid black lines indicate $1-\beta=0.05$ and $p_1=0.5$ , respectively. As expected, the Type I error of the binomial test is strictly below $\alpha = 0.05$ and the empirical curve nicely fits its theoretical counterpart. Also as expected (given that $n$ is too low for the normal approximation of $Zn$ to hold), the empirical power curve for $Z_n$ does not correspond to its theoretical counterpart. I did not expect, however, the considerable increase in power when using the $Z$ -test instead of the Binomial test. Granted, for $n=5$ , this increase in power is paid for by a considerable increase in Type I error. But already for $n=10$ , the Type I error rate is almost completely controlled at the $\alpha$ threshold. Hence, my question: Question Given the results of my simulations and if I want to maximise the power of my statistical test while controlling for a pre-defined Type I error rate, can I use the $Z$ -test for $n$ as small as $10$ ? And if yes, is there are any kind of theoretical argument backing up my simulations? I somehow feel like I've overlooked something obvious here, but can't seem to find out what...
