[site]: crossvalidated
[post_id]: 14639
[parent_id]: 14634
[tags]: 
Your suggested reporting for a table seems reasonable, although z-values and p-values are redundant. Many journals I am familiar with don't report the z-value/p-value at all and only use asterisks to report statistical significance. I have also seen logistic tables only with the odd's ratios reported, although I personally prefer both the log odds and odds ratios reported if space permits in a table. But different venues may have different guides as to reporting procedures, so what is expected may vary. If I'm submitting a paper to a journal I will frequently just see how other recent papers have made their tables and just mimic those. If it is your own personal paper, asking whomever may be reviewing it would be a reasonable request. As I mentioned above, space constraints in some venues may prevent you from reporting ultimately redundant information (such as both the log odds and the odds ratios). Some places may force you to report the results entirely in text! There is also the question of what other model summaries to report. Although many journals I am familiar with frequently report pseudo $R^2$ values, here is a thread on the site that discusses the weaknesses of various measures. I personally prefer classification rates to be reported, but again I suspect this varies by venue (I can imagine some journals would specifically ask for one of the pseudo $R^2$ measures to be reported). To get the odd's ratio just exponentiate the regression coefficient (i.e. take $e^{\hat{\beta}}$ where $e$ is the base of the natural logarithm and $\hat{\beta}$ is the estimated logistic regression coefficient.) A good guess in any statistical language to calculate this is exp(coefficient) . Also as a note, although this is the current accepted answer, lejohn and Frank Harrell both give very useful advice. While I would typically always want the statistics in the question reported somewhere, the other answers advice about other measures are useful ways to assess effect sizes relative to other estimated effects in the model. Graphical procedures are also useful to examine relative effect sizes, and see these two papers on turning tables into graphs as examples ( Kastellec & Leoni, 2007 ; Gelman et al., 2002 )
