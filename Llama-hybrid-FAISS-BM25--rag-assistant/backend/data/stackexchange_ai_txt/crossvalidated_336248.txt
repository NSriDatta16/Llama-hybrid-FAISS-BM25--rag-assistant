[site]: crossvalidated
[post_id]: 336248
[parent_id]: 
[tags]: 
Any two events that are independent implies that the time between them are independent

Theorem: By the Strong Markov Property, for a stopping time T and a Markov chain at state $X_{T_{n}} = y$, the state $X_{T_{n}+k}$ for $k\geqslant 0$ is independent of $X_{T_{n}}$ or $X_{T_{n}+k}$ is equivalent to the Markov chain with initial state $y$. Clearly, the above theorem implies that any two or more states are independent to one another. But how can I understand that the time between the occurrence of any two or more states are, thus, independent?
