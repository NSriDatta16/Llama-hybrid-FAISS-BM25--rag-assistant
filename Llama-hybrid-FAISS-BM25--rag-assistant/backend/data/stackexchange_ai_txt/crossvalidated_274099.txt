[site]: crossvalidated
[post_id]: 274099
[parent_id]: 
[tags]: 
How do I implement softmax in a neural network

I would like to know how does one go about to implement softmax in a neural network. I know that softmax is the exponential divided by the sum of exponential of the whole Y vector which is applied at output layer. Does this mean I do the softmax function to the vector after the processing in hidden layer? If yes, what does this softmax do? Isn't it just like multiply a scale to the vector?
