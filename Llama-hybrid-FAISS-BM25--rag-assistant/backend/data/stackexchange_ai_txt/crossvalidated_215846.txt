[site]: crossvalidated
[post_id]: 215846
[parent_id]: 215831
[tags]: 
One of the most famous capabilities of random forest is the ease to estimate the importance of a predictor. In fact, this is called "variable importance" in Leo Breiman's original paper. In the R package randomForest, after a model is fitted, you can get the variable importance by mod$importance which gives you a matrix of two columns. There are as many rows as the number of predictors. For any predictor row, the first column gives you an estimate of how much worse in terms of accuracy your model would have been had you omitted this predictor; the second column is the increase in MSE had this predictor not included in the model.
