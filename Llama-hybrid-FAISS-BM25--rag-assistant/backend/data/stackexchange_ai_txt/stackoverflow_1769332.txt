[site]: stackoverflow
[post_id]: 1769332
[parent_id]: 
[tags]: 
Script to remove Python comments/docstrings

Is there a Python script or tool available which can remove comments and docstrings from Python source? It should take care of cases like: """ aas """ def f(): m = { u'x': u'y' } # faake docstring ;) if 1: 'string' >> m if 2: 'string' , m if 3: 'string' > m So at last I have come up with a simple script, which uses the tokenize module and removes comment tokens. It seems to work pretty well, except that I am not able to remove docstrings in all cases. See if you can improve it to remove docstrings. import cStringIO import tokenize def remove_comments(src): """ This reads tokens using tokenize.generate_tokens and recombines them using tokenize.untokenize, and skipping comment/docstring tokens in between """ f = cStringIO.StringIO(src) class SkipException(Exception): pass processed_tokens = [] last_token = None # go thru all the tokens and try to skip comments and docstrings for tok in tokenize.generate_tokens(f.readline): t_type, t_string, t_srow_scol, t_erow_ecol, t_line = tok try: if t_type == tokenize.COMMENT: raise SkipException() elif t_type == tokenize.STRING: if last_token is None or last_token[0] in [tokenize.INDENT]: # FIXEME: this may remove valid strings too? #raise SkipException() pass except SkipException: pass else: processed_tokens.append(tok) last_token = tok return tokenize.untokenize(processed_tokens) Also I would like to test it on a very large collection of scripts with good unit test coverage. Can you suggest such a open source project?
