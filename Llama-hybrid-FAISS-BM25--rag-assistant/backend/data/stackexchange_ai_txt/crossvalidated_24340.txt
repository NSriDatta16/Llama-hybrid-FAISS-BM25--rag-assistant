[site]: crossvalidated
[post_id]: 24340
[parent_id]: 23858
[tags]: 
The precision/recall curve for KNN classifier consists of two points effectively (since KNN predicts binary values) so such curve is not very useful or meaningful. One could instead use the fraction of a given class in the neighborhood (i.e. non-smoothed density estimate; requires K > 1) as the model prediction which would make the precision/recall curve more meaningful. As for leveraging distance, one could try to use "distance-weighted voting" by relying on a distance-based kernel to get the weights (as one of the simplest kernel density methods) but that would not really qualify as KNN classifier since since KNN's kernel is just a step function.
