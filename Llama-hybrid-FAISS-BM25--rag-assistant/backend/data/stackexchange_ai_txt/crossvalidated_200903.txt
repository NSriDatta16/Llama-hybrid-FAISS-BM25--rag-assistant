[site]: crossvalidated
[post_id]: 200903
[parent_id]: 
[tags]: 
Machine learning: intuition behind perceptron learning algorithm

Given features x_1...x_n, weights w_1...w_n, calculated output y = Z dot X, and actual output y', the perceptron learning algorithm changes the weights after each iteration as follows: deltaZ_i = learningRate * (y' - y) * x_i I understand why we multiply by (y' - y): we want to change the weight to push the calculated output closer to the actual output. Similarly, the sign of x_i has to be taken into account: if x_i is negative, the weight should be shifted in the opposite direction than if it is positive. What I don't understand is why multiply by the value x_i, rather than just its sign. We multiply by the value of (y' - y) to produce a larger change when the deviation is large, but why produce a larger change when x_i is big in magnitude? We are already multiplying z_i and x_i, so x_i being large is taken into account. It seems that when multiplying deltaZ_i by x_i will cause x_i to be squared in the calculation of y, causing features with large magnitudes to be overrepresented.
