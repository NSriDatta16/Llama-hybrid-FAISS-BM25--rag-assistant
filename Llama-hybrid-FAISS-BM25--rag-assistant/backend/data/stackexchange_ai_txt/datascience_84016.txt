[site]: datascience
[post_id]: 84016
[parent_id]: 
[tags]: 
Equation of a Multi-Layer Perceptron Network

I'm writing an article about business management of wine companies where I use a Multi-Layer Perceptron Network. My teacher then asked me to write an equation that lets me calculate the output of the network. My answer was that due to the nature of multi-layer perceptron networks there is no single equation per se. What I have is a table of weights and bias. I can then use this formula: $$f(x) = (\sum^{m}_{i=1} w_i * x_i) + b$$ Where: m is the number of neurons in the previous layer, w is a random weight, x is the input value, b is a random bias. Doing this for each layer/neuron in the hidden layers and the output layer. She showed me an example of another work she made (image on the bottom), telling me that it should be something like that. Looking at the chart, I suppose that it is a logistic regression. So, my questions are the following: Is there any equation to predict the output of a multi-layer perceptron network other than iterating over each neuron with $w*x+b$ ? Should I just tell my teacher that a logistic regression is a different case and the same does not apply to this type of neural networks? Is the first formula correct to show that a value of a neuron is the sum product of the previous layers plus the bias? Edit 1 : I didn't wrote the formula but I do also have activation functions (relu).
