[site]: crossvalidated
[post_id]: 183840
[parent_id]: 
[tags]: 
Sum or average of gradients in (mini) batch gradient decent?

When I implemented mini batch gradient decent, I just averaged the gradients of all examples in the training batch. However, I noticed that now the optimal learning rate is much higher than for online gradient decent. My intuition is that this is because the averaged gradient is less noisy and could thus be followed faster. So maybe it also makes sense just to sum up the gradients of a batch. The values can be positive and negative anyway. I know it's just a constant factor that can be balanced using the learning rate. But I wonder which is the definition scientists have agreed on so that I can reproduce results from neural network papers. Does one typically divide the summed gradients of a batch by the batch size?
