[site]: datascience
[post_id]: 16550
[parent_id]: 16542
[tags]: 
There are algorithms that use Feature Selection to utilize only the "best" features for the given dataset (variants of adaboost for example). There are also algorithms randomly use subsets of the features (such as random forest). Finally there are algorithms that learn weigh your inputs and use them accordingly (Neural networks and the like) There is "common knowledge", but it is more related to the type of features and classification problem that you are facing (i.e. regression vs. classification, continuous vs discrete, binary vs. multi-class, etc.). If you have a specific problem that you can model using such a function then it is a completely reasonable approach to design such a function. Once you have modeled your problem with such a function and defined your loss function - you could use any optimization method that seems reasonable. However it is beneficial to try and find similar problems that others have solved before and understand how their solution relates to your problem.
