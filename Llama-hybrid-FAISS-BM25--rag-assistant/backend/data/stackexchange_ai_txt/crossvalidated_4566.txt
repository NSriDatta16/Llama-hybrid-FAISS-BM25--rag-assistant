[site]: crossvalidated
[post_id]: 4566
[parent_id]: 4561
[tags]: 
You're incorrect about the confidence intervals. Assuming they are 95% confidence intervals then they can overlap quite a bit and be statistically significantly different. What you need is for the confidence interval of the difference between the two to not overlap 0. The standard error of the difference is sqrt(2 *((var1+var2)/(2(n-1)))/n) and the df for the confidence interval is 2(n-1) (assuming you ran the test equal numbers of times for both programs). Alternatively you could average the w (one side of the confidence interval) from each condition and then multiply that by sqrt(2). That will give you a minimum difference for statistical significance. If the program can run quickly just run it 1e5 times or more (lots and lots) and call the resulting means and standard deviations approximate population values. Your standard error will be so small that a confidence interval will be almost 0 and any difference would be significant. You could even report overlayed histogram plots and CDFs. (while I would endorse this last method you might need to do the CIs anyway)
