[site]: crossvalidated
[post_id]: 340742
[parent_id]: 
[tags]: 
Calculating posterior for an intercept term with a normal prior in Bayesian regression

I'm trying to follow the calculation of a Bayesian posterior for an intercept term which is updated by a single observation using the example from the following slide deck. In this problem, the slope is fixed at 1. The intercept $b$ is a random variable. The posterior distribution for $b$ is obtained from a normal prior distribution and a single data point (3,2). I'm having a hard time figuring out how to actually calculate those posterior values of -0.5 and 0.5 for the posterior mean and standard deviation. I'm not sure how Bayes rule is used to calculate these parameters. Here are my attempts so far: P( b |(3,2)) = P( b )*P((3,2)|b) / P((3,2)) I believe the (3,2) is equivalent to b=-1 because that's the only way the line can pass through (3,2) since the slope is fixed to 1. So the equation transforms to: P( b |-1) = P( b )*P(-1|b) / P(-1) Now it looks like we have a simpler problem: basically one random variable b , with a prior N(0,1) and a single data point, -1. P(b) is the prior, so it is equal to N(0,1) P(-1|b) is the probability of getting a -1 from a N(0,1) distribution. I'm a bit confused about this because I thought that the probability of getting a single value from a continuous distribution is always 0. So I'm not sure how to calculate this. P(-1) --> Not sure where to start with this. I can't explain it conceptually let alone mathematically.
