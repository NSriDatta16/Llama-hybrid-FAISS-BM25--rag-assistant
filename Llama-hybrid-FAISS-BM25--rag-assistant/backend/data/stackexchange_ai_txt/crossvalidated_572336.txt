[site]: crossvalidated
[post_id]: 572336
[parent_id]: 572221
[tags]: 
Let's say there are 2 people in the world, me and my friend, who have a tattoo of my name on his/her arm. Let's say my friend got COVID. This gives me a 1 in 2 odds of getting COVID which dosen't make sense. This is not a problem with too many priors/features/parameters, but with too little observations. (Although having too many features can result in having few observations for a particular class) Say you would assume a Bernoulli distribution for an observation, sick or not sick with probability $p$ and $1-p$ , where our prior estimate of the parameter $p$ is a flat beta(1,1) distribution, then after one single observation of another person that happens to get sick then the posterior for $p$ would be a beta(2,1) distribution and the estimate for another person to get sick would be 66.6% (the expectation value of a beta-binomial distribution with parameters $\alpha=2$ , $\beta=1$ and $n=1$ ). So that 66.6% is in this application of Bayes theorem even higher than your guess of 50%. If that 66.6% is too high, then the reasons for the error of getting that high number are the choice of prior and the low number of observations. In this example it doesn't matter whether we are dealing with tattoos or not. When this type of error occurs, of having too little observations giving bad results, because we are dealing with too many variables, then we call this overfitting. Related: Is it true that Bayesian methods don't overfit?
