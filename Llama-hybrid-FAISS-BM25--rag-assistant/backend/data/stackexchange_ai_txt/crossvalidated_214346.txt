[site]: crossvalidated
[post_id]: 214346
[parent_id]: 214335
[tags]: 
This problem is related to Doddington's Zoo (cf. Introduction to Biometrics by Jain, Ross, Nandakumar ), which basically states that no (biometric) method will work equally well for all individuals in a population, but you will always have individuals for which it works better or worse. Consequently, it would be a good idea to report statistics over the individual results for the subjects that the approach has been tried with in the evaluation. Such could be mean, standard deviation, quantiles, etc. Those reflect the performance variation over individuals , hence give an idea of how likely it might be that the approach just does not work for certain individuals (e.g. if applied in an application scenario), and what good or bad results for such individuals might look like. This is also why such evaluation frequently use leave-subject-out-cross-validation (each partition is composed solely from one individual, hence cross validation is always done on data from an unseen individual) - therefore gives an idea of how the model would perform on data of unseen individuals. PS: this too is similar to what is frequently done with model selection, where statistics over results for different model types and model parametrizations over partitions are used to decide upon using a particular model type and parametrization. Usually, those too consider more than the average performance (like the performance spread).
