[site]: datascience
[post_id]: 40711
[parent_id]: 
[tags]: 
Transformation of categorical variables (binary vs numerical)

When using categorical encoding, I see some authors use arbitrary numerical transformation while others use binary transformation. For example, if I have a feature vector with values A, B and c. The first method will transom A,B and C to numeric values such 1,2 and 3 respectively, other researches use (1,0,0), (0,1,0) and (0,0,1). What is the difference between the first method and the second one? The only difference I can think of is, if you use binary values, the size of the training/testing data will increase linearly according to how many values you have, which may slow down the performance, while the first one will keep the size unchanged. Does either of these methods will effect the accuracy of your machine learning model (or classifier)?
