[site]: crossvalidated
[post_id]: 618258
[parent_id]: 
[tags]: 
Statsmodel multinomial logistic regression outputs all nan values

I'm trying to fit a multinomial logreg with statsmodel. import statsmodel as sm X = sm.add_constant(df) logreg_model = sm.MNLogit(y[:n], X).fit() Where df is a one row dataframe (just because I'm trying each variable isolately to find out which of them is causing the problem) with the following values: debt 0 0.00 1 0.00 2 0.00 3 0.00 4 0.00 5 0.00 6 0.00 7 4474.35 8 0.00 9 0.00 10 0.00 11 0.00 12 0.00 13 0.00 14 0.00 15 0.00 16 1587.51 17 0.00 18 0.00 19 0.00 20 0.00 21 0.00 22 0.00 23 0.00 24 0.00 25 0.00 26 0.00 27 0.00 28 0.00 29 0.00 30 0.00 31 0.00 32 0.00 33 0.00 34 0.00 35 0.00 36 0.00 37 0.00 38 0.00 39 0.00 40 0.00 41 0.00 42 0.00 43 0.00 44 0.00 45 0.00 46 0.00 47 0.00 48 0.00 49 0.00 The problem is that when I run that code, I get two warnings: RuntimeWarning: overflow encountered in exp eXB = np.column_stack((np.ones(len(X)), np.exp(X))) RuntimeWarning: invalid value encountered in divide return eXB/eXB.sum(1)[:,None] And the problem is that, whenever I get these warnings, MNLogit outputs this: Dep. Variable: y No. Observations: 50 Model: MNLogit Df Residuals: 12 Method: MLE Df Model: 19 Date: Thu, 08 Jun 2023 Pseudo R-squ.: nan Time: 14:19:33 Log-Likelihood: nan converged: True LL-Null: -138.74 Covariance Type: nonrobust LLR p-value: nan ============================================================================== y=6 coef std err z P>|z| [0.025 0.975] ------------------------------------------------------------------------------ const nan nan nan nan nan nan debt nan nan nan nan nan nan I checked out this thread but didn't find any useful answer. I also tried normalizing the variable with sklearn's StandardScaler or performing log transformation but didn't work either (actually, log transformation works with this data, but when I take a larger sample, it fails too). What can I do?
