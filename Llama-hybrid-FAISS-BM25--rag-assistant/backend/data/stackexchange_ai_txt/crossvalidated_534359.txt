[site]: crossvalidated
[post_id]: 534359
[parent_id]: 534356
[tags]: 
As noticed in the comment, random forest uses bootstrap resamples of the training data. What this means is that for each tree we sample randomly with replacement the max_samples number of observations from the training data. When using bootstrap in statistics you generally want the number of bootstrap observations to be equal to the number of observations in your data , because you want the bootstrap samples to resemble the original data. Using max_samples higher than the number of observations in the training data would be rather pointless, but sometimes people may choose it to be smaller to speed up the computations. This would be a bad idea in statistics because using smaller bootstrap samples would not give you an accurate estimate of things like standard errors, but when training random forest you are only concerned with making predictions, not inference . In such a case, you need to empirically verify what are the consequences for the quality of the predictions if you make the max_samples number smaller.
