[site]: crossvalidated
[post_id]: 230928
[parent_id]: 230904
[tags]: 
Larry Wasserman's All of Statistics is a nice book for getting a whirlwind tour of mathematical statistics. It was the first book on mathematical statistics I used myself. It includes the classics like hypothesis testing and maximum likelihood estimation, but it also has plenty of coverage of more recently developed but equally important topics like bootstrapping. Wasserman always has one foot in statistics and the other foot in machine learning, which I think all contemporary data analysts should do; if you're only familiar with one field of the two, you're going to be missing a lot. Also, the book has a lot of good exercises. If you have a background in real analysis and you want the raw, uncut stuff, by which I mean a measure-theoretic treatment of probability and statistics, try Mark J. Schervish's Theory of Statistics . Schervish is half of DeGroot and Schervish, whose less technical book Probability and Statistics is maybe the most popular book on mathematical statistics today. Theory of Statistics is a helpfully talky book for a topic usually reserved for graduate students who are supposed to do all the work themselves. To be quite honest, I found this book very hard (although not as hard as Jun Shao's Mathematical Statistics ) and eventually came to feel the immense effort required to master it wasn't a good use of my time as an applied data analyst. But I still learned a lot and came away with a good understanding of what measure theory is and how it can be used to clean up hairy theoretical difficulties that arise in the more naive traditional approach to probability theory. I also came to better appreciate the similarities and differences of exchangeability and independence.
