[site]: datascience
[post_id]: 124080
[parent_id]: 
[tags]: 
Using Embedding For Regularization

Is using embeddings for regularization a valid practice? My reasoning for that is that encoding training/tests datasets into smaller vectors would allow a smaller network with fewer parameters and consequently less prone to overfitting. This sounds as a reasonable approach to me, specially when dealing with data where the entries are vectors of large dimension that exibith high similarity. However, I could not find a reference of embeddings being used for regularization. Hard to believe that if it was indeed a valid approach, it wouldn't have appeared sooner.
