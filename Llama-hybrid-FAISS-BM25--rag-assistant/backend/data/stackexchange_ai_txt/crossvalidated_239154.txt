[site]: crossvalidated
[post_id]: 239154
[parent_id]: 239048
[tags]: 
This seems like a hard problem, especially considering how subjects might overestimate the number of symbols, which I'd previously thought you assumed not to happen. You may need some fairly informative priors in order to get precise posterior estimates. (Or you can add assumptions to simplify the model.) Here's one idea for a model. Let $k_i$ be the number of symbols that subject $i$ reports. Suppose $k_i = a_i + b_i$, where $a_i$ is the number of real symbols the subject noticed, and $b_i$ is the number of additional symbols the subject wrongly thought he saw. Each $a_i$ comes from a binomial distribution with $N$ trials and probability of success $θ_i$, which itself comes from a beta distribution with parameters $α$ and $β$. Each $b_i$ comes from a Poisson distribution with parameter $λ$. (For yet more complexity, you can replace the universal $λ$ with a per-subject parameter $λ_i$.) So you need priors for $N$, $α$, $β$, and $λ$, and you're primarily interested in the posterior distribution of $N$. I doubt it's possible to fit this model analytically. Use an MCMC sampler such as Stan instead.
