[site]: crossvalidated
[post_id]: 286781
[parent_id]: 210363
[tags]: 
the answer above helps but I was still confused on two metrics, which I've figured out: 1. max min_per_class_accuracy is where you get he highest (max) average accuracy (min error) across all classes. It specifies the threshold on which the average accuracy is the greatest. (Bad terminology IMHO, probably more like max avg. on min_per_class_error) 2. max mean_per_class_accuracy is where you get the min sum of error across all classes. It specifies the threshold on which the average accuracy is max and even balanced across all classes. Example might help (two class problem): The accuracy/error on Threshold 1: C1 - error = 0.0788, accuracy = 1-0.0788= 0.9212 C2 - error = 0.1885, accuracy = 1-0.1885= 0.8115 average accuracy is (0.9212+0.8115)/2 -> 0.86635 C1 accuracy - avg accuracy = abs(0.86635 - 0.9212) = 0.05995 C2 accuracy - avg accuracy = abs(0.86635 - 0.8115) = 0.04975 Threshold 1 is where max min_per_class_accuracy is. In no other threshold there is an average accuracy greater that 0.86635 . The accuracy/error on Threshold 2 : C1 - error = 0.1379, accuracy = 1-0.1379 = 0.8621 C2 - error = 0.1396, accuracy = 1-0.1396 = 0.8604 average accuracy is (0.9212+0.8115)/2 -> 0.86125 (smaller than in threshold 1) C1 accuracy - avg accuracy = abs(0.86125 - 0.8621) = 0.00085 C2 accuracy - avg accuracy = abs(0.86125 - 0.8604) = 0.00085 Threshold 2 is where max mean_per_class_accuracy is. No other threshold has a higher average with minimal spread (i.e. smaller than the average of 0.00085 and 0.00085 ). You can also see this as the closest accuracy on the two classes.
