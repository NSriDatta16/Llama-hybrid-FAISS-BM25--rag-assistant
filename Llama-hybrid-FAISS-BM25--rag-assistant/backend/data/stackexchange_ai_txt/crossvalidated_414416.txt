[site]: crossvalidated
[post_id]: 414416
[parent_id]: 
[tags]: 
Denoising autoencoders vs masked approaches

I am not an expert in language modelling domain. There are mainly two approaches that are being used nowadays. Denoising autoencoders and masking . Recent models like BERT use masking and outperforms other models on a number of tasks. Now, my questions are: 1) Why is masking so useful compared to stacking a bunch of denoising autoencoders? 2) Are there any disadvantages of masking that make it a worse approach compared to using a denoising autoencoder?
