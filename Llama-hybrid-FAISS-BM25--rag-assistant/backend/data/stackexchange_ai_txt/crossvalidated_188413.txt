[site]: crossvalidated
[post_id]: 188413
[parent_id]: 
[tags]: 
Test error of probability "prediction" for little league soccer

Background: I have multiple sets of team's little league soccer scores made up only of whole numbers [0-12 inclusive], eg: A: 1, 2, 4, 7 B: 0, 0, 0, 1, 1, 1, 4, 7 C: 0, 1, 2, 2, 2, 3, 4 Due to a positive skew, I would like to improve upon using the mean for prediction of next score. At about 4 or more pieces of data for a set, I can make a fairly accurate prediction using the mean average of the set, [diminishing returns for reducing error starts very rapidly]. But is definitely open to improvement at a fundamental level. Most sets will be made up of 4-60 numbers and have a very nice bell shaped distribution for 90% of the data from 0-5 inclusive but have a positive skew for the remaining 10% from 6+. The data points from 6+ are not outliers necessarily but they most certainly do interfere with the mean for future predictions [consistently over predicting on average by about 5-7%]. Using the mean of previous scores as a rudimentary prediction. "Next" is the next score achieved by the team in the set. Mean - Next - Error A: 3.50 4 0.50 B: 1.75 2 0.25 C: 2.00 0 2.00 Issue: How does one test the error of a probability based prediction without a specific number to compare against like a mean / median / mode? Probabilities are rounded [may not total to 100]. 0 1 2 3 4 5 6 7 - Next - Error - Intuition / aim? A: 0 25 25 0 25 0 0 25 4 ? 3.0 B: 38 38 0 0 13 0 0 13 2 ? ~0.8 ?? C: 14 14 43 14 14 0 0 0 0 ? 2.0 Obviously predicting probabilities like the above even with slightly larger sets that form smoother distributions is meant for a very different kettle of fish predictions eg Set C: ~71% chance of scoring less than 2.5 goals. Ideally a method to output a simple as possible [tacky is great] not necessarily best practise , it could be an estimated prediction of what a team will score higher than 50% of the time and lower than 50% of the time so that an error can be produced similar to the mean prediction and hence compared, or... Some other way without producing an exact prediction for the probabilities for each set but would allow direct comparison of error with the mean prediction. Most of the sets have 22-42 scores but the solution needs to work effectively even with a very limited number of data points [eg 4-9] if using the probabilities to infer some sort of approximate prediction. Already attempted / notes: Median / mode are not effective alone. Using mean but: Trimming / omitting semi-outliers [6+, 7+, 8+] has not reduced error in a useful manner either. Combining the opposition's defense into the fold is not an issue and does not change the problem at hand, it just means instead of measuring the error of the teams' attack it will be goal difference instead. Example of a tacky [and convoluted] solution and more difficult to implement than desirable: taking the two [or N] highest frequencies and averaging them based on their frequency. Unfortunately this falls apart almost immediately as can be seen by the above sets eg Set A, which two scores are the highest? Set B, (0*38+1*38)/(38+38)=0.5 is about as bad as the mean prediction of 1.75. Set C, what happens when the set has an odd number of unique data points?
