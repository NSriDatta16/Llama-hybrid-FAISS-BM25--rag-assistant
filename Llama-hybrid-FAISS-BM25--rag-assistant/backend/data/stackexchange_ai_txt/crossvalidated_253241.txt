[site]: crossvalidated
[post_id]: 253241
[parent_id]: 253230
[tags]: 
Since $J(\theta)$ is a function of $\theta$, $p_{model}(y|x)$ should be understood as the likelihood function of $\theta$, where $\theta$ is the model parameters, IMO. Therefore this loss is used for maximum likelihood estimation (MLE). Say we have a neural network that takes in $x$ and outputs $f_\theta(x)$, and we assume a Gaussian noise for $y\sim N(f_\theta(x), \sigma^2)$, then $p_{model}(y|x)=\frac{1}{\sqrt{2\sigma^2\pi}}\exp(-\frac{(y-f_\theta(x))^2}{2\sigma^2})$, then $$J(\theta)=\frac{1}{2\sigma^2}\frac{1}{m}\sum (y-f_\theta(x))^2+constant$$ minimizing $J(\theta)$ in this case equals to minimizing our favorite mean-squared-error.
