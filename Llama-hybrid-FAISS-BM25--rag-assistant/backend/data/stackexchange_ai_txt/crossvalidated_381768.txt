[site]: crossvalidated
[post_id]: 381768
[parent_id]: 
[tags]: 
Bayes estimator with weighted Loss

I have been working through a wide variety of problems involving Bayes risk and loss functions and I couldn't immediately solve the following From " The Bayesian Choice " , Consider $x \sim N(\theta,1)$ , $\theta \sim N(0,1)$ and the loss function $L(\theta, \delta)= e^{3\theta^{2}/2}(\theta-\delta)^{2}$ Then show that the Bayes estimator is $\delta^{\pi}(x)=2x$ My thoughts: If it was the usual quadratic loss, the Bayes estimator would simply be the posterior mean, the posterior is $\theta | x \sim N(\frac{x}{2},\frac{1}{2})$ However it is not usual quadratic loss. If $e^{3\theta^{2}/2}\pi(\theta|x)$ itself was a distribution then we could take the posterior mean of that to be the Bayes estimator. But it is not obvious that it is a distribution. So, $$\delta^{\pi}(x)=argmin_{\delta} \int_{-\infty}^{\infty} e^{3\theta^{2}/2}(\theta-\delta)^{2}\pi(\theta|x) d\theta$$ ie $$\delta^{\pi}(x)=\frac{E(w(\theta)\theta|X]}{E[w(\theta)|X]}$$ where $w(\theta)$ is the non negative weight. So how would we see the result to be true from this? Thanks
