[site]: crossvalidated
[post_id]: 481969
[parent_id]: 
[tags]: 
How come a Poisson GLMM predicts a higher overdispersion than in the observed data?

I am using package brms in R to fit a Bayesian generalized linear mixed model in which: the response variable is the count of a phenotypic structure (e.g., toes) that a species possesses ( trait.count ); the population-level (fixed) effects are two continuous variables and their interaction ( continuous1 and continuous2 ); intercepts can vary over the group-level (random) effect species , and species are correlated according to the phylogeny covariance matrix. Since the response variable is count data, I opted to choose a Poisson distribution. There is slight overdispersion in the data, as estimated by dividing variance by mean ( $\sigma^2/\mu$ = 1.1). This is how the distribution of counts ( trait.count ) looks like: The code that I used to fit the model is as follows: brm_count When I compare the distribution of counts predicted by the fitted model ( $y_{rep}$ ) to my observation ( $y$ ), here's what I get: pp_check(brm_count, type="bars", nsamples = 100) This seems reasonable to me except that zeroes are overestimated, as are values â‰¥ 3. What I found the weirdest is that the model overestimates the overdispersion observed in my data: dispersion The mean is accurately estimated by the model, which means that the source of overdispersion is the inflated variance ( $\sigma^2$ = 0.3 in the observed data, $\sigma^2$ ~ 0.6 in the posterior predictive samples), which, by its turn, is likely the consequence of overestimation of values > 3 that don't exist in the observed data. My question is: how come the overdispersion of my data ( $\sigma^2/\mu$ = 1.1) is inflated to ~ 2 by a model that assumes no overdispersion (i.e., $\sigma^2/\mu$ = 1)? Shouldn't I expect the opposite: for dispersion to be underestimated? Am I missing something? (By the way, I also fitted this model with zero-inflated Poisson, negative binomial and Poisson with observation-level random effects (1|OLRE) , and the issue persists.) Thank you so much for any help! EDIT: By fitting models starting from a simple trait.count ~ 1 and adding complexity layers, I found out that the main factor responsible for the inflated variance is the covariance structure among species . Models perform well as long as the covariance structure isn't included. I have no idea what this means.
