[site]: datascience
[post_id]: 51210
[parent_id]: 51007
[tags]: 
Overall, I agree with Andy M's suggestion. To address the issue you point out and get rid of words work and experience , you can probably ignore the n-most-frequent words in the general corpus that also appear in the data science corpus, and keep the rest as the data-science-related terms. So, in a more pythonic way: general_texts = [ ['a', 'sentence', 'about', 'experience'], ['another', 'sentence', 'typed', 'at', 'work'], ['work', 'experience'], ... ] data_science_texts = [ ['data', 'science', 'experience'], ['work', 'on', 'machine', 'learning'], ... ] freqdist_gnrl = Counter() freqdist_ds = Counter() for text in general_texts: freqdist_gnrl.update(text) for text in data_science_texts: freqdist_ds.update(text) mostfreq_words_gnrl = freqdist_gnrl.most_common(2) # 'work', 'experience' words_ds = [ w for w, _ in freqdist_ds.most_common() if w not in mostfreq_words_gnrl # every word other than 'work' or 'experience' ] In this example, I have used 2 as n for the n -most frequent terms to make it work but, over a larger corpus, you can probably take a few hundred words. After applying this filter, the first k words in the variable words_ds should all be related to data science to a reasonable extent. Hope this helps!
