[site]: datascience
[post_id]: 115119
[parent_id]: 
[tags]: 
Fraud labels for machine learning

I am working on a fraud detection classification model with a dataset from a sample of labelled data. When the model is on production, we will be blocking transactions when the prediction of fraud is above a certain threshold. Hence, we will have no data for True Positives and False Positives. How can we evaluate the performance of the model once it is on production given that the labels will be missing? In the past, I have used by an approach that does not take action on a sample of datapoints. Does anyone have any other ideas?
