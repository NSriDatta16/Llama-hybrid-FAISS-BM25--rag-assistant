[site]: crossvalidated
[post_id]: 566965
[parent_id]: 
[tags]: 
Any good method to identify the principal components on a low dimension timeseries dataset?

I have a low dimension (only 8 dimension) Time Series dataset of simple z-score standardized numerical data. Number of raw data point is about 2000 x 8. I tried running PCA on the dataset by splitting the data into 10 periods of time, and I got 8 PCs obviously for each 200 data points. My goal is not to reduce the dimension but instead want to see if I can get a set of stable Principal components loadings on the eigenvectors over the period of time, and can use the eigenvalue to understand the PCs behaviour over time. I understand PCA algorithsm will generate eigenvectors that potentially in exact opposite direction (i.e. +/- sign flipped), but my problem is in addition to that sometimes the PCs are switching positions, e.g. suddenly PC7 becomes next period's PC3. My "rough" thought is perhaps I can treat each of those period (total 10) the set of PCs being treated as 8-dimension point in a hypercube, and then I apply K-Mean Clustering with 8 clusters to see if I can group the nearest points together. But exactly how to do it, I am not immediately sure. I wonder whether there are any good method to help labelling the PCs. For example maybe the first period PC0 and the second period PC1 and the third period PC5 are actually the same component.
