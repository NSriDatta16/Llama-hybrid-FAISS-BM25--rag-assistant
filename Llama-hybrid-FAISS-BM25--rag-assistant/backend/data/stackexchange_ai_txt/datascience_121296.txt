[site]: datascience
[post_id]: 121296
[parent_id]: 
[tags]: 
What is the definition of convergence in the context of deep neural networks?

Suppose I have a feed forward neural network which approximates a value, say $Y_0$ . The analytical value of $Y_0$ is given. The plot of the network approximation of $Y_0$ each step is given as follows. We can see (visually) that the approximation of $Y_0$ converges to its analytical value. But, how can we mathematically say that the approximation converges? Note: There is a definition of the convergence of a sequence. A sequence $\lbrace x_n \rbrace_{n=1}^{\infty}$ in $\mathbb{R}$ is said to converge to $x \in \mathbb{R}$ if for every $\varepsilon > 0$ there exists a natural number $K(\varepsilon)$ such that for all $n \geq K(\varepsilon$ ), the terms $x_n$ satisfy $\lvert x_n - x \rvert . In this definition, the sequence is infinite and usually has certain rules , for example $\lbrace x_n \rbrace_{n=1}^\infty = \lbrace \frac{1}{n} \rbrace_{n=1}^\infty$ . In fact, usually the approximation result of a feed forward neural network (or deep neural network in general) is a finite sequence which has the same number as the epoch/step. Is there a definition of convergence in the context of deep neural networks?
