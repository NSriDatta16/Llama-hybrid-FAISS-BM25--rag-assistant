[site]: datascience
[post_id]: 47916
[parent_id]: 47870
[tags]: 
Thank you(Esmailian) so much for your answer. I agree with you that the author distinguished the two losses by the setting cnn.CalcLastLayerActDerivative=0/1 . However, in the original codes, the calculation of gradient for corss-entropy: yf′(x)/f(x)−(1−y)f′(x)/(1−f(x)) is not provided in bpcnn.m . Only the corss-entropy error ylogf(x)+(1−y)log(1−f(x)) is provided but sent to er1 only for plotting the losses: > if cnn.loss_func == 'cros' %cross_entropy' > if cnn.layers{cnn.no_of_layers}.act_func == 'sigm' > er1 = -1.*sum((yy.*log(cnn.layers{cnn.no_of_layers}.outputs) + (1-yy).*log(1-cnn.layers{cnn.no_of_layers}.outputs)), 1); > else > ... > end > cnn.loss = sum(er1(:))/size(er1,2); %loss over all examples > > else > er1 = er.^2; > cnn.loss = sum(er1(:))/(2*size(er1,2)); %loss over all examples > > end Thus, could you provide more detailed answer regarding to this? Thanks to @Esmailian! All the questions I had are now resolved.
