[site]: crossvalidated
[post_id]: 299236
[parent_id]: 299222
[tags]: 
how can I be sure that test dataset is good for testing You can't. Most things in statistics are only approximate, and the use of a train–test split to estimate predictive accuracy is no different. Since you're concerned by the fact that different train–test splits yield different results, why not use cross-validation? Cross-validation produces an average across several splits, reducing the risk of bias from an unlucky split. how can I be sure that… the model and tests results are objective? Objectivity is somewhat overrated (a more objectively conducted analysis need not be more accurate or useful), but it's just a matter of following a procedure that's transparent and justified a priori. For train–test splitting, that means you should decide how you're going to make the split in advance of making it and then stick with that decision instead of changing it based on your result. So to get the best test result, I can create a function, which would try out different seeds for data division into test and train samples. Then I would choose the seed which would maximise my test score. This would defeat the purpose of a train–test split, which is to estimate how well a model will perform on cases it hasn't been trained with. By choosing the test set to make the model perform as well as possible, you're effectively, albeit indirectly, training it on the test set. The better test results are and the more dissimilar datasets are, the better model it is, as it can explain truly new data. A dataset that is maximally distant from the training set need not be maximally representative of the population. In fact, the more representative your training set is, the less representative this data will be. Publish several most common classification tree structures produced using different subsamples of the data. You can do this as a sort of sensitivity analysis, showing how sensitive the model structure is to the training data, but it's a distinct question from predictive accuracy.
