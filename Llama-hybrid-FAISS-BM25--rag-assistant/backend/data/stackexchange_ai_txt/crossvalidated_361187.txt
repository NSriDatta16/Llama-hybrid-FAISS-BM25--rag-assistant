[site]: crossvalidated
[post_id]: 361187
[parent_id]: 
[tags]: 
Bayesian predictions

I have a more general query about some confusion ive been having lately deciding what the bayesian predictions are in my model. Suppose I have a model, $y_{j} = \mu_{j} + e_{j}$, (for which i have observed values $y_j$). I ran a bayesian approach, for which i have priors on $e_j$ and $\mu_j$. My data is distributed $y_j \sim N(\mu_j,e_j)$. If i were to simulate from the posterior distribution for $y_j$ (the posterior predictive distribution, conditioned on the data) using random number generator in RStan during the run, then is it correct to assume that these are my predictions for $y_j$. Or are my predicted values in fact the posterior predicted value for $\mu_j$ ? So, say if i wanted to plot observed vs predicted values, which quantity of the two (posterior mean for $\mu_j$ or posterior predictive distribution for $y_j$ from a random number generator $N(\mu_j,e_j)$) would make more sense to plot?
