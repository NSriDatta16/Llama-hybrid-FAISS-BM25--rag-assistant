[site]: crossvalidated
[post_id]: 465429
[parent_id]: 461218
[tags]: 
One of the conceptual advantages of using a multiscale architecture, in my opinion, is ability to model latent factors on different levels of abstraction. Consider random noise that gets injected near the flow's output. Much of the flow's computation has already been performed, and not much of the layers are left before the output is produced. Thus, we can assume such random noise would only affect some local texture, and would not, for example, introduce another big object to the scene. In contrast, the noise right in the beginning of the flow has all the layers to go through, and it's much easier for a neural network to decode some global properties out of it. Therefore, multiscale introduces groups of noise variables, and should make it easier to manipulate latent noise vectors. For example, suppose you work with faces and seek noise inputs that define gender and skin color. You are much more likely to find these features near the flow's input than its output. Also, such grouping is useful for feature extraction, since extracting a full feature vector of the same size as the observation $x$ is not helpful in semi-supervised learning scenarios where only a handful of labeled samples are available.
