[site]: crossvalidated
[post_id]: 503640
[parent_id]: 175087
[tags]: 
Gini index Main idea is here . We can make an example based on this statquest . Let's say there is a machine that can detect Heart Disease (HD). The machine can predict HD 30% of the time. Following is the sample we have: HD !HD Machine 30% 70% This means the following cases are possible: Machine classify as HD and it is HD (P = 0.3*0.3) Machine classify as !HD and it is !HD (P = 0.7*0.7) Machine classify as HD but it is !HD Machine classify as !HD but it is HD We pray that cases 3&4 happen less often. The sum of all probabilities is 1. P(3&4) is therefore given by 1-(0.3^2)-(0.7^2) =0.42. P(3&4) is the impurity or how bad the machines' prediction is, AKA GINI=0.42 . The alternative is to check if someone is clutching his chest or not due to chest pain (CP) and then guess based on probability data if he has HD or not. The following is the sample we have. For each case we calculate the GINI. Then we take the average of it (assuming similar sample size) and this estimates the GINI impurity using CP to predict HD. HD !HD GINI !CP 25% 75% 0.375 CP 80% 20% 0.32 avg NA NA 0.38 Smaller the impurity the better. So we decide instead of buying the machine (GINI=0.42) we can just use CP as an indicator (GINI=0.38). P.S. This is also an explanation of what happens at each node of a decision tree, which is where I came across GINI index.
