[site]: datascience
[post_id]: 58002
[parent_id]: 
[tags]: 
Explaining XGBoost functioning to non-technical people

I have been tasked to explain the principle of the XGBoost algorithm to non-technical people (think 1-2 slides in a powerpoint presentation to upper management). I am currently working with the original papers : here for the paper specific to XGBoost and here for the orignal boosting idea by Friedmann. I have come up with a short explanation for the boosting principle : the model is built iteratively, by concentrating on where the previous model made errors. XGBoost take advantage of the tree architecture and tools (splitting, pruning) to do so. What would you add to this short description ?
