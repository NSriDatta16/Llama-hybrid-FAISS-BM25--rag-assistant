[site]: crossvalidated
[post_id]: 595034
[parent_id]: 
[tags]: 
Why we can't report CV error as an estimate of performance when tuning hyperparameters?

Suppose we want to tune the hyperparameters of an algorithm. We perform $k$ -fold cross validation and we found the optimal hyperparameter values, lets say $p^*$ . Nevertheless, we don't have a separate test. Can we report the average error from folds as an estimate of the generalization error? Based on this Question we shouldn't.What I can't understand is the following. Lets say that another analyst wants to estimate the generalization performance of $p^*$ . He performs $k$ -fold cv with the same data we used for hyperparameter tuning. He doesn't want to tune parameters. Just by chance he selected $p^*$ and wants to get an estimate of its performance. Further, lets assume that his $k$ -folds are same to our $k$ -folds. Obviously the average cv error would be the same. Why he can report this error as an estimate of the generalization error while we are not allowed?
