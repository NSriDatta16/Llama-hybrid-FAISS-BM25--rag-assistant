[site]: crossvalidated
[post_id]: 389178
[parent_id]: 
[tags]: 
error of permutation feature importance

Feature importance can be calculated by permuting features. But it seems to suffer from instability. To be more accurate about the feature importance, chap 5.5.1 in interpretable machine learning suggests repeating the permutation many times to get the permutation error. Also, the author's R package iml makes the error plot using the percentile of the permutations. My question is when I permute the features, should I sample with replacement or without replacement? If I sample with replacement, it would be more like bootstrap rather than permutation, then is it safe to use bootstrapâ€™s approach to calculate the confidence interval? If I sample without replacement, how do I interpret the percentile of permutations? It somehow has a connection to the confidence interval but I could not find a reference to support this connection.
