[site]: datascience
[post_id]: 85645
[parent_id]: 85636
[tags]: 
In the case of CNN, you are correct that you cannot use the final layer weights if the number of categories is different. But you CAN reuse the weights in the initial layers. These recognise the lower-level objects in the image. There is no need to train all over again. You would only have to train the upper layers specific to the categorisation you want to do. So transfer learning helps the lower layers in the case of CNN. Let me give one more example. Say there is a trained model to recognize 100 categories of objects, including animals, plants, buildings, vehicles, etc. You want only to categorize vehicles. You could use the lower layers of the above model as-is and then add a couple of layers at the top, which learn the exact types of vehicle categorization. In the case of word embedding, the concept of transfer learning is more intuitive and may help understand the concept better. You can train a model on the entire Wikipedia and enable it to learn embeddings for the representation of words. These representations can then directly be used in other models - e.g., tweet sentiment classification, etc. BERT is one such pertained dataset of embeddings. It is a classic case of transfer learning. You no longer have to train on volumes of TeraBytes to learn the language embeddings. You can use it off the shelf.
