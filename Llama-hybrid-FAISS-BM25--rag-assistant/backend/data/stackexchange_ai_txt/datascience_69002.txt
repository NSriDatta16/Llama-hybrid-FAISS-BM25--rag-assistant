[site]: datascience
[post_id]: 69002
[parent_id]: 68988
[tags]: 
If you mean images classification networks like AlexNet (and I suppose images segmentation ones too), then at first layer they detect color-agnostic features as well as color-dependent ones: ( https://arstechnica.com/science/2018/12/how-computers-got-shockingly-good-at-recognizing-images/3/ ). Here blue color mean that blue component is necessary for the filter to fire stronger, but (I believe) that G and B and not important for it. For magenta (R+B) red and blue are necessary anb green is not important. If the filter is white on the left, black on the right, it will fire when intensity raises from right to left. Transfer learning has to work if your image has the same nature as the train photos (at least partially). So you want filter detecting legs to detect something similar to legs on your images. And it will detect if lower-level filters detect parts of leg (say rectangle - increase of intensity when background is darker than the leg and then decrease back – background-leg-background). If your leg is detected as a set of petals connected with dogs’ noses instead, there will be no sense in this, even if source net detect this as flowerbed with confidence. This will be a noise. So you of course could pack your color intensities into RGB triples. Say for simplicity in the form of C letter on the R+G plain. You will get 256*3 values. But this would break the correspondence with the nature of your image. Since the net will see the packed values. Even if everything is good when you move from RG (0, 0) -> (255, 0) -> (255, 255), instead of intensity raising, it will decrease on the way -> (0, 255). This will likely rotate inside out filters that should detect this exact raising of intensity. Sometimes maybe it’s not important, there are pairs of opposite filters or somehow else… But I think far from always so still… I would simply map your 0-N to gray (0, 0, 0)-(255, 255, 255), loosing of precision is so small and typical problem in real-life tasks... If you really need this resolution, maybe take windows of maximally appropriate size (e.g. v=0 for input 0-1000, linearly to 255 for input 1000-2000, 255 for bigger input values). Everything is MHO and as a first idea. More information about your task could help.
