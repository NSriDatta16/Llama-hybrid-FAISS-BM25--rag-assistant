[site]: datascience
[post_id]: 99587
[parent_id]: 46858
[tags]: 
The effect of adding a max pooling or convolutional layer to any FCN: I assume you are referring to a single path, fully convolutional neural network (FCN). In that case, let's refer to the stride rate in each of the consecutive layers $l$ as $s_l$ . If the size of the receptive field was $(n,n)$ after the first $L$ layers, then adding a max pooling or a convolutional layer of size $(k, k)$ will increase the size of the receptive field to $$ \left ( n + (k-1)\prod_{i=1}^{L} s_i,\ n + (k-1)\prod_{i=1}^{L} s_i \right ). $$ (Derivation below) The effect of adding a max pooling layer of size (2,2): If you add a max pooling layer of size $(2,2)$ (... therefore $k=2$ ) to a network with all strides rates set to one ( $s_i = 1$ ), then the receptive field size increases to $(n+1, n+1)$ . The receptive field size will then only increase by one in each dimension; the size of the receptive field will not be doubled. There are a few key points to understand this result: The receptive field of a node is the set of all input nodes that could possibly influence that node's response. In the absence of striding, neighboring nodes in a CNN are influenced by nearly the same set of inputs (i.e. - their receptive fields are nearly identical). Pooling these neighboring nodes' receptive fields creates an output with a receptive field that is essentially the same as any one of the neighboring nodes that feed into it. Worked out example to emphasize the above points: Let's consider a one-dimensional CNN consisting of a convolutional layer of size 3 followed by a max pooling layer of size 2: We note the following: The first node of the middle layer could be influenced by inputs 1, 2, and/or 3. Therefore the receptive field of the first node of the middle layer is the set $\left \{ \text{Input } 1, \text{Input } 2, \text{Input } 3 \right \}$ , and the size of the receptive field is three. The receptive field of middle layer node 2 is $\left \{ \text{Input } 2, \text{Input } 3, \text{Input } 4 \right \}$ and also has a size of three. The pattern continues with middle layer nodes 3 and 4. Output layer node 1 can be influenced by the receptive field of middle layer node 1 (which is influenced by inputs 1,2,3) and middle layer node 2 (which is influenced by inputs 2,3,4); its receptive field is simply the union of these two receptive fields. The receptive field of output layer node 1 is $\left \{ \text{Input } 1, \text{Input } 2, \text{Input } 3, \text{Input } 4 \right \}$ , and thus has a size of 4. Inputs 2 and 3 each count once toward the receptive field size despite influencing output node 1 from two different paths. The last pooling layer does little to expand the receptive field size since the middle layer has many overlapping elements. How exactly do strides come into play? Stride rates larger than one greatly reduce the number of common receptive field elements between neighboring nodes in all the layers that follow. With fewer common receptive field elements between neighboring nodes, adding a convolutional or pooling layer will increase the receptive field size more than it would have otherwise. Computing the receptive field size for a single path, fully convolutional neural network: For a single path, fully convolutional neural network, we can compute the receptive field size analytically. We consider such a network that has $L$ layers. The receptive field size of a node in the output layer along any one of the dimensions is given by $$ r_0 = 1 + \sum_{l=1}^L \left ( \left ( k_l - 1 \right ) \prod_{i=1}^{l-1} s_i\right ) $$ where $r_0$ is the receptive field size after $L$ convolutional / pooling layers, $k_l$ is the kernel size of the convolutional / pooling operation at layer $l$ , and $s_i$ is the stride rate at layer $i$ . Note: the product ends at $l-1$ . The stride rate $s_L$ in the last convolutional layer has no effect on the receptive field size. Deriving the results toward the top: Suppose we have a CNN with $L$ layers that has a receptive field of $(n,n)$ and each layer $l$ has a stride of $s_l$ . Then adding a max pooling layer of size 2x2 creates a $(L+1)$ layer with kernel size $k_{L+1}=2$ . Therefore, the receptive field size along either dimension will now be given as $$ \begin{align} r_0' &= 1 + \sum_{l=1}^{L+1} \left ( \left ( k_l - 1 \right ) \prod_{i=1}^{l-1} s_i\right )\\ &= 1 + \sum_{l=1}^{L} \left ( \left ( k_l - 1 \right ) \prod_{i=1}^{l-1} s_i\right ) + \left ( k_{L+1} - 1 \right )\prod_{i=1}^{L} s_i \\ &= n + \left ( k_{L+1} - 1 \right )\prod_{i=1}^{L} s_i \hspace{0.5 in} \text{(the first $L$ layers have a receptive field size of $n$)}\\ &= n + \prod_{i=1}^{L} s_i \hspace{1.4 in} \text{($k_{L+1} = 2$)} \end{align} $$
