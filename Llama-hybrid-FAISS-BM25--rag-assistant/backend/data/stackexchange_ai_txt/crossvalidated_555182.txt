[site]: crossvalidated
[post_id]: 555182
[parent_id]: 
[tags]: 
Taking percentage difference b/w average of values vs taking average of individual percentage differences

I have two sets of data points: List A [x1, x2, x3...xn] and List B [y1, y2, y3...yn]. If I were to calculate percentage difference between the two sets, what would be more accurate: a. Taking individual percentage differences (x1 vs y1...etc) and then taking an average over all individual percentage differences or b. Taking average value of List A, avg value of List B and then taking the percentage difference between the two average values? To add more context, both the lists are computational times for two different runs on same queries (times in A are for the version 1 of a program and B for the version 2). I'm running a performance analysis of the two programs and hence need to compare how much time on average it took for queries to run on different versions of the program.
