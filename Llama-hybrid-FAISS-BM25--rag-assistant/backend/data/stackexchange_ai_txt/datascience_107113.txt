[site]: datascience
[post_id]: 107113
[parent_id]: 19112
[tags]: 
In general, decision trees are easily understandable due to its structure. However, in most application they become so big that you easily lose sight. Additionally, in most cases you would want to use Random Forest as an ensemble method instead of a single Decision Tree and then again there is not one single tree that you can explain. For neural networks there is a new research approach is coming up called "Explainable AI" which tries to make us understand the reasons for a neural network prediction. One method is the so-called integrated gradient that calculates the importance of each input feature for the prediction.
