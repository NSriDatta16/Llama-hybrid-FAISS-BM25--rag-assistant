[site]: stackoverflow
[post_id]: 5013329
[parent_id]: 5010871
[tags]: 
The most likely reason for you error is that you are overflowing the accumulators neuronsHidden or weightsHidden . I know nothing about neural networks so I can't offer any explanation as to why this is so. As a side issue, I question the use of Extended floating point variables. Normally this simply results in extremely slow performance, much slower than when using Double . You may think it gives you more headroom for large numbers, but in reality, if this is a run-away overflow of the nature that I suspect, then using Extended would never save you. UPDATE OP points out that overflow results in a different exception class. So for EInvalidOp I suspect some square root or trig failure or something like that. Or perhaps a signaling NaN, but since you don't obviously use uninitialised data I'll not persue that. I can see now that you have been affected by Embarcadero's bizarre decision to break their implementation of Tanh . This used to work perfectly on older versions of Delphi (e.g. D6), but was broken recently. The version you use isn't quite right for large negative input, and uses two calls to Exp when one suffices. I use this version: const MaxTanhDomain = 5678.22249441322; // Ln(MaxExtended)/2 function Tanh(const X: Extended): Extended; begin if X>MaxTanhDomain then begin Result := 1.0 end else if X
