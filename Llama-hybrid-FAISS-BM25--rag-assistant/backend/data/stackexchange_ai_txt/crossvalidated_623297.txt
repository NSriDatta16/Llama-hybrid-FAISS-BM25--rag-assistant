[site]: crossvalidated
[post_id]: 623297
[parent_id]: 
[tags]: 
Difference between conducting PCA on $XX^\top$ vs $X^\top X$?

PCA: For a given set of centered data $\mathscr D =\{x_i\}_{i=1}^N \subset \mathbb R^d$ , i.e. the data has $N$ examples with dimension $d$ . Then the principal directions of PCA can be obtained from the columns of eigendecomposition V of $X^\top X = V\Lambda V$ such that $V^\top V = I$ . But when number of features is too big, such that $d>N$ , conducting eigen decomposition could be time-consuming. Why can we conduct eigen decomposition of $XX^\top$ instead? It is obvious that $X^\top X$ is a $d\times d $ matrix while $XX^\top$ is a $N\times N$ matrix. Would the calculated eigenvectors be the same for both matrixes? Why?
