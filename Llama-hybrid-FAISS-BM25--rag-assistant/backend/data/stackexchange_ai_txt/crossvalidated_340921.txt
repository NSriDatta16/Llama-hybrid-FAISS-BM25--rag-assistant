[site]: crossvalidated
[post_id]: 340921
[parent_id]: 
[tags]: 
-2 in the gradient of the loss function

I'm reading Humman-level control through deep reinforcement learning , at the beginning of Page 7, it defines a loss function (I omit some parameters to make it cleaner) $$ L(\theta)=\mathbf E\left[\left(r+\gamma \max_{a'}\hat Q(s', a';\theta^-)-Q(s, a;\theta)\right)^2\right] $$ Then I differentiate it with respect to the weights, I get $$ \nabla_\theta L(\theta)=\mathbf E\left[-2\left(r+\gamma \max_{a'}Q(s', a'; \theta^-)-Q(s, a;\theta)\right)\nabla_\theta Q(s, a;\theta)\right] $$ It is not consistent with the gradient in the paper. (my version has $-2$). What's wrong with my inference? Thanks in advance.
