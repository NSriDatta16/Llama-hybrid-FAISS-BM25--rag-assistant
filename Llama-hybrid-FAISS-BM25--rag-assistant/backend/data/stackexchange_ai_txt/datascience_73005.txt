[site]: datascience
[post_id]: 73005
[parent_id]: 56513
[tags]: 
You can apply the Wrapper Sequential Feature Selection (SFS) algorithm. SFS is a family of greedy search algorithms that are used to reduce an initial d-dimensional feature space to a k-dimensional feature subspace where k k_features (parameter). It will select those feature gives the highest accuracy for corresponding algorithm. clf = svm.SVC() # Build step forward feature selection sfs1 = sfs(clf, k_features=15, forward=True, floating=False, verbose=2, scoring='accuracy', cv=5) # Perform SFFS sfs1 = sfs1.fit(X_Train, Y_Train) feat_cols = list(sfs1.k_feature_idx_) print(feat_cols) One downside is- you have to fix the desired number of features, the algorithm will give you which those features better fits in terms of accuracy. For your scenario, you have 72 features. Let's say, you want to use only 15 features but you don't know which 15 features among these 72 features. SFS will tell you the best selection. Here, in the above code, feat_cols is the list of those 15 features.
