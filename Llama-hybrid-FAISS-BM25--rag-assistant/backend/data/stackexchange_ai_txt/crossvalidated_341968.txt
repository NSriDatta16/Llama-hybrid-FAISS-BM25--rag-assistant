[site]: crossvalidated
[post_id]: 341968
[parent_id]: 341954
[tags]: 
However, when I decrease the weight of the KLL loss by 0.001, I get reasonable samples: (...) The problem is that the learned latent space is not smooth. Looks like overfitting. Remember that KL loss on the latent space sort of corresponds to regularization. Are there any suggestions on how to balance these two loss terms or any other possible things to try so that my autoencoder learns a smooth, interpolatable latent space, while producing reasonable reconstructions? I recently bumped into this paper: $\beta$-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework (it actually uses your dataset in one example). From the paper ($\beta$ is the parameter you changed): We introduce an adjustable hyperparameter $\beta$ that balances latent channel capacity and independence constraints with reconstruction accuracy (...) $\beta$-VAE is stable to train, makes few assumptions about the data and relies on tuning a single hyperparameter $\beta$, which can be directly optimised through a hyperparameter search using weakly labelled data or through heuristic visual inspection for purely unsupervised data.
