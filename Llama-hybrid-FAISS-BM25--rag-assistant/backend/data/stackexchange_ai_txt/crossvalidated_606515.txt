[site]: crossvalidated
[post_id]: 606515
[parent_id]: 606507
[tags]: 
Your question is composed of multiple questions/issues. I can answer the first one, the second is still unclear to me. summary(lmer(grade ~ loudness + (1 | student), pane3)) What happened here is that the mixed effects model is effectively fitting three lines that have different (random) intercepts, instead of a single line. This results in the following output for fixed effects Fixed effects: Estimate Std. Error t value (Intercept) 76.521 11.866 6.449 loudness 0.111 0.119 0.933 the slope of $\beta = 0.111$ instead of $\beta = 1.94$ is more like an effect within subjects rather than between subjects. It could be possible that the effect of loudness has an effect within subjects, and by measuring the subjects many times, you could observe a significant effect. summary(lm.cluster(data = pane3, formula = grade ~ loudness, cluster = "student")) to be continued, it is not so clear what this method does, but giving a p-value of 0.12 is indeed weird In addition you have a third question How to fix the problem in this XKCD comic? You fix this by sampling more people. Alternatively, you can sample the same people multiple times*. This should reduce the noise in the case that there is not only an error from person to person, but also within the persons. If you sample the same person multiple times then you get more accurate information about that average performance of that person, and you reduce the influence of the noise due to the same person potentially having different exam results. In the first pane of the XKCD image, the results where highly variable. In the third pane it was still the same. The XKCD comic, stages the situation where the exam grade is not much variable within the same person. (Or it is even the same because they seem to have only repeated the loudness measurements and the variations in exam grade are due to your data scraping). That is not necessarily the case when some resampling is done. Consider the following Of course, it might be still doubtful whether inference with only three data points is a good idea. And possibly one should use a model that considers the error in the x-variable (like Deming regression). But the point is that repetitions within subjects can improve the accuracy of the estimates. *In fact, this way might be even better, because it allows you to observe the within subject error and assess the goodness of fit. This is why scientists in quantitative fields like to perform duplicate or triplicate measurements.
