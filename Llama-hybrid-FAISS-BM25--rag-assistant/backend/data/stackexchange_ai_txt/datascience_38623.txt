[site]: datascience
[post_id]: 38623
[parent_id]: 38619
[tags]: 
Not sure what the video said, but $T$ should not be the vocabulary size, but the training corpus size (number of all words). For example, if your training corpus is deep learning is popular . i love deep learning . i want to learn more about it. Then when you sume up over $T$ , you will sum up all the word pairs in the corpus including duplicates. The word pair (deep learning) is indeed calculated twice. For details please refer to the original skip-gram paper, and notice the definitoin (1) on page 2.
