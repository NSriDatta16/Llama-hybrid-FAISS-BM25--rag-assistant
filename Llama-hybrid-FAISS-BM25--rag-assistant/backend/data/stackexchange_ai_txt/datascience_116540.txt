[site]: datascience
[post_id]: 116540
[parent_id]: 116536
[tags]: 
That sounds like a multiclass task with possibly very unequal class distribution, focused upon overall statistically correct modeling rather than catching certain rare classes. If you wish to execute this properly, your evaluation metric should be both class independent and threshold independent. Of the listed ones, logloss suits the evaluation (in a sense of choosing the best performing model) task best. Confusion matrix and confusion matrix based metrics (precision, recall, F-measure etc) are threshold sensitive and thus not very suitable for evaluation . While you may easily select the 'best' threshold with respect to F-measure easily using precision/recall curve, threshold selection is a part of decision making and should not (ideally) be mixed with evaluation. For a school project however, you're pretty much expected to use those. ROC curves are worth plotting as well, however their interpretation in a multiclass case may be questionable. Average errors, being regression metrics, naturally do not qualify. TL;DR: evaluate by proper scoring rules, such as logloss; support your evaluation by presenting ROC/PR curves, as well as their respective AUCs; add confusion matrices and derive the dependent metrics at an optimal decision threshold example.
