[site]: datascience
[post_id]: 121846
[parent_id]: 
[tags]: 
How to implement a custom loss function acting differently on multiple instances with keras?

I want to reproduce the results in "Online Neural Networks for Change-Point Detection" Hushchyn et al. , but I'm having trouble implementing their loss function with Keras. The algorithm works on sequential data and computes the cross entropy between two segments of a time series separated by $l$ time steps, $X(t)$ and $X(t-l)$ , according to eq. 10 in their paper: $L(X(t-l), X(t)) = -\log(1-f(X(t-l),\theta)) - \log(f(X(t), \theta))$ where $f(X, \theta)$ is the neural network we want to train and $\theta$ are its parameters. I don't know how to implement this loss function in Keras, as the loss functions I'm used to working with compute the loss separately on each instance in the same way (i.e. MSE). Any suggestions?
