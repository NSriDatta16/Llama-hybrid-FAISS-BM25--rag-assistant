[site]: datascience
[post_id]: 71622
[parent_id]: 71558
[tags]: 
Currently BERT is the preferred method for many NLP tasks. GRUs are also used. https://medium.com/huggingface/multi-label-text-classification-using-bert-the-mighty-transformer-69714fa3fb3d There are some other methods that have been discussed which I haven't tried. https://paperswithcode.com/task/text-classification About the issue of a classifier being unable to determine a certain class, might be true to some extent. This often happens when you have a class that has significantly fewer instances than the rest of classes. Text classification with thousands of output classes in Keras It all depends on the quality of data you are working with and the amount of processing power available.
