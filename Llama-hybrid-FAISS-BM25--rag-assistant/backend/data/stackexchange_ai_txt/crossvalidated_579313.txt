[site]: crossvalidated
[post_id]: 579313
[parent_id]: 
[tags]: 
Average Error vs. Aggregate Error

I was reading this paper on the history of Bagging Estimators ( https://www.stat.berkeley.edu/~breiman/bagging.pdf ) and came across the following section: I am having difficulty understanding the difference between "Phi_A" and "Phi_B" - especially in understanding how the term "Phi_A" suddenly appears when you expand the "average prediction error" (epsilon). In this paper, it mentions that Phi_A refers to the "Aggregate Predictor" and Phi_B refers to the "Bagged Predictor". Until now, I always used to use these terms ("Aggregate" and "Bagging") interchangeably. For example, a Random Forest model can be thought of as aggregating Decision Trees on bootstrapped samples from the same dataset. This being said, the next point is particularly confusing to me : The inequality shows us that that the "average prediction error" (epsilon) must be greater than or equal to the error from the "aggregated predictor error". Thus, this brings me to my question: What is the difference between the "averaged prediction error", the "aggregated predictor error" and the "bagged error"? Thanks!
