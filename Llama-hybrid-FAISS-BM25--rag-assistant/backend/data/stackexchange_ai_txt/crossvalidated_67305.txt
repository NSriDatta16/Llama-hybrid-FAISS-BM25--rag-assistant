[site]: crossvalidated
[post_id]: 67305
[parent_id]: 
[tags]: 
Are direct Monte Carlo and Markov Chain Monte Carlo equivalent?

I'm not quite sure where to start... I'm trying to wrap my head around two methods for drawing samples from a parameter distribution, given a forward model and some distribution of the observable. I'll call these methods direct and Markov Chain Monte Carlo and describe them below. But to be clear on the parameters of my problem, I've got some observable $x$, with some normally-distributed error $\sigma_x$. e.g. I read a paper that said $x=1.2\pm0.1$ or whatever, presuming Gaussian errors. Now, I have a forward model that takes a parameter $\theta$ and returns a value of $x$. I'll call this a forward model $f$ and write $f(\theta)=x$. I think it's important to know that this is a horrible, difficult, complicated function that is not easily inverted. What I'd like to do is look at the distribution of the parameter $\theta$. Here are my two ways of doing so. Direct MC First, I construct a realization of the observation. i.e. I draw from the observed distribution. In practice, I would do this by inventing a number $1.2 + 0.1\times$ (a random number drawn from $N(0,1)$). Then, I do my best to invert the model, in practice probably with a gradient descent method or something similar. This produces an optimal $\theta$, which is one draw from the parameter distribution. To build a sample, I do this for a suitably large number of different (random and independent) realizations of the observation. Markov Chain MC Basically, I run an MCMC method. That is, I build a chain of $\theta$s, starting from some initial value and comparing a new value, drawn from a proposal distribution. The forward model is used to compute the probability of the new value, in terms of the distribution of the observations. i.e. $x$ is computed from $\theta$ and evaluated in $N(x,\sigma_x)$ or whatever. The new value is accepted if more probable than the current value, or randomly accepted even if worse. Otherwise the current value is kept. However the new value is assigned, it is added to the sample (the "chain") and the process is repeated. It's more detailed than this, but I'm not sure it's necessary to explain MCMC completely and accurately for the purpose of this question. Anyway, if the chain is "burned-in" and run long enough, it samples the distribution. So, finally, my question is: are the two samples reproduced in these ways the same? i.e. do the two methods produce the same results? I intend to do a small numerical experiment when I have some time. My understanding was that the two are the same, but I'm not sure why and can't prove it. Last, but not least, please let me know if I can clarify the question, because my experience on Stats.SE is that it's quite hard to make sure everyone is on the same page, and that I'm not very good at it!
