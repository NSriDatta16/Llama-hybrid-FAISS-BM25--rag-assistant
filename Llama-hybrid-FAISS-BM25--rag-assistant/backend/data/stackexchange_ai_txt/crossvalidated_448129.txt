[site]: crossvalidated
[post_id]: 448129
[parent_id]: 447528
[tags]: 
Weights in Deep Learning infer the connection strength between the neurons. They have a direct influence on the output. So if the weights are near to zero, that means changing this input will not have any significant influence on the output. In short, Positive weights indicate a positive influence on the output and vice versa. Bias, on the other hand, works as an intercept. It helps in adjusting the output along with the weighted sum of inputs. Output = Sum(Weights * Inputs)+ Bias Bias allows shifting the activation functions to left or right. It helps to fit the model to the data. In the absence of bias, the model will be a poor fit.
