[site]: crossvalidated
[post_id]: 260460
[parent_id]: 
[tags]: 
Optimization of a Random Forest model

I'm training a Random Forests regression model in R using the randomForest package. My total number of variables, $M$, is 30, and my training sample size $N$ has more than 10,000 observations. The model, in general, gives reasonable results (comparing to findings in literature) in terms of variable importance and non-linear interaction between the variables, with an overall decent performance (~80% var explained - don't think there is a threshold value determining good/no good tho, please correct me if I'm wrong). I'm now tuning the model in order to achieve the highest performance possible acting on two parameters: number of trees, and number of variables per tree. Quoting from Breiman & Cutler's website : "...it was shown that the forest error rate depends on two things: The correlation between any two trees in the forest. The strength of each individual tree in the forest. Reducing $m$ [number of variables per tree, mtry in R ] reduces both the correlation and the strength. Increasing it increases both. Somewhere in between is an "optimal" range of $m$ - usually quite wide. Using the oob error rate a value of m in the range can quickly be found." The model is little sensitive to changes in the number of trees, stabilizing after a certain threshold (as usually happens with RF - see also "How many trees in a random forest?" - Oshiro et al. 2012). Regarding the number of variables per tree, randomForest for regression uses a default value $m=\frac{M}{3}$ (which is consistent with literature - see for instance "The Elements of Statistical Learning" - Friedman et al 2001, chap. 15). I used the tuneRF to calculate the sensitivity of the model to changes in m , but this operator is pretty unstable (if you run it several times, the results are always different, even if the seeds are set set.seed(1234567) ). This was discussed also in another post on StackOverflow , but my question is more from the theoretical point of view. I tuned manually the mtry and found the one that minimizes my Mean of squared residuals and maximizes my % Var explained , but is pretty far from the default $m=\frac{M}{3}$. Moreover, my model's results are sensitive to variations in mtry (i.e. even setting the seeds to a specific value for achieving reproducible model settings, for every mtry value variable importance changes rather radically). Increasing the mtry value increases the internal correlation of each specific tree: how is it possible that doubling the default mtry , I have an overall improvement? Could this be biased by multi-collinearity within the trees? In general, I'm struggling to find the "Somewhere in between" Braiman and Cutler referred to. Any idea from more experienced practitioners (this is my first RF) would be much appreciated. Could somebody explain me also why the variable relative importance could be so radically different changing the mtry even only by 1 unit? Being the model an ensemble of randomized processes, shouldn't the results converge? Thanks.
