[site]: crossvalidated
[post_id]: 633225
[parent_id]: 633221
[tags]: 
Yes, looking at multiple questions and deciding "reject one or more null hypotheses" based on a Bayesian analysis (e.g. based on some cut-off for a Bayes factor, or if posterior credible intervals for some parameters exclude the values consistent with the null hypothesis), does result in a similar type I error inflation situation just the same as if you were using a frequentist approach. There's two things to point out though: Conservative priors and/or hierarchical shrinkage of parameters that you do tests about can (in some situations) make the type I error rate less badly inflated by multiple testing than a traditional frequentist approach might. However, it's hard to know in general how much this helps, while for any particular set-up one can explore this through e.g. simulations. Some would argue that type I error control is just not a relevant concept ("sure the type I error rate is inflated, but we don't care about type I error rate in the first place" - sometimes people will add that they don't believe any point null hypothesis is exactly true in the first place anyway), while others will argue that frequentist operating characteristics are how one should evaluate Bayesian methods.
