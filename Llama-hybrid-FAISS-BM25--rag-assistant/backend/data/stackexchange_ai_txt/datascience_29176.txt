[site]: datascience
[post_id]: 29176
[parent_id]: 29174
[tags]: 
By default, feature importance in xgboost is given by how many times a given feature appears as a split feature across all trees in the ensemble. When one-hot encoded, each newly created dummy variable can only take the values 0 and 1, and so can only appear once in each (sub)tree. However, when combining the values into one numeric feature by giving each category a different value, the feature can appear many more times on different levels in each tree, which brings up the importance score.
