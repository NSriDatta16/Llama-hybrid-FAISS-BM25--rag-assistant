[site]: crossvalidated
[post_id]: 546017
[parent_id]: 545990
[tags]: 
Any time you use a chunk of data to search through a possible space (whether that’s find best coefficients for a regression or choosing between RNN and CNN) you are by definition fitting to that data. Training data: Used to fit a particular model. Validation data: Used to search through the space of models to find best hyper parameters. Testing data: Used to check whether your best model from Validation performs well OOS. That’s the usual set up. However, as you said in your question you might want to take a couple of models from validation (say the top 5) and see which one generalises best on the testing. As I said above, you will now be fitting to the test data and introducing the chance that you picked a model which got lucky. In this case we would create a fourth data set: Holdout data: Kept completely separate and used for the sole purpose of assessing the OOS of a potential production model. Only one model should get to see this data.
