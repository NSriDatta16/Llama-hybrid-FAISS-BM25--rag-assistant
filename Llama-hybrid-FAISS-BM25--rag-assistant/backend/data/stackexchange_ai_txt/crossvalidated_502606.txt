[site]: crossvalidated
[post_id]: 502606
[parent_id]: 
[tags]: 
Inconsistency of logistic regression in a parametric dose finding model

The following problem is a simplified model of dose finding in combination clinical trials. Assume we have a matrix $p = (p_{ij}) \in [0,1]^{K_1 \times K_2}$ representing the probability of non-toxicity of dose combination $(i,j)$ for $i=1,\dots,K_1$ and $j=1,\dots,K_2$ . The $p$ matrix has this property that it generally decreases along the rows and columns (as either $i$ or $j$ increases). That is, $p_{ij} > p_{i, j+1}$ and $p_{ij} > p_{i+1, j}$ . To be concrete, let $K_1 = 4$ and $K_2 = 5$ , and let $K = K_1 K_2 = 20$ , the total number of dose combinations. We view $p$ as a $20 \times 1$ vector in the following, traversing it rowwise, in which case we write it as $\vec p$ . The observations are a collection of binary responses $$y_{k} \sim \text{Ber}(\vec p_{z_{k}}), \quad k=1,2,\dots,n$$ where $z_{k} \in \{1,2,\dots,20\}$ is the assignment of patient $k$ to one of the doses. For simplicity, we assume that we put $n_0 = 1000$ patients on each dose (this is unrealistic but useful to make the point), so that the total sample size is $n = n_0 K = 20,000$ . We can form a nonparametric estimator $$\widehat p^{(np)}_r = \frac1{|\{k: z_k = r\}|}\sum_{i=1}^n y_i 1_{\{z_k = r\}}$$ which is just the average response for each dose combination. We also consider a parametric approach, modeling the matrix $p = (p_{ij})$ as $$ p_{ij} = \text{logit}^{-1} \big( \alpha_0 + \alpha_1 x_i + \alpha_2 y_j + \alpha_3 x_i y_j \big) $$ where $\{x_i\}$ and $\{y_j\}$ are equispaced points say in $[\delta, 1]$ , and take $\delta = 0.1$ . (The value of $\delta$ does not matter that much). This parametric model can be fit using the logistic regression. Call the resulting estimate $\widehat p^{(GLM)}$ . The issue is that for certain true $p$ matrices, the GLM estimator seems to be inconsistent no matter how big the sample size is. This will be true even if we set $\alpha_3 = 0$ to have no interactions. Here is the R code to generate the resulting inconsistency: inv_logit = function(x) 1 / (1+exp(-x)) K1 = 4 K2 = 5 K = K1*K2 to_mat = function(x) matrix(x, nrow=K1, byrow=T) grid_lower_limit = 0.1 design_mat = expand.grid(x1 = seq(grid_lower_limit, 1, length.out = K1), x2 = seq(grid_lower_limit, 1, length.out = K2)) design_mat = as.matrix( cbind(const = 1, design_mat, x1x2 = design_mat $x1 * design_mat$ x2) ) p0 = c(0.66, 0.39, 0.19, 0.09, 0.07, 0.39, 0.19, 0.09, 0.07, 0.04, 0.18, 0.09, 0.06, 0.03, 0.02, 0.09, 0.06, 0.03, 0.02, 0.01) n = 1000*K z = rep(1:K, n/K) y = rbinom(n, 1, p0[z]) ph_np = sapply(1:K, function(j) mean(y[z==j] > 0)) # nonparametric estimate # to_mat(round(p0,3), K1) to_mat(ph_np) x1 = design_mat[z, 2] x2 = design_mat[z, 3] (mod = glm(formula = y ~ x1 + x2 + x1*x2 , family = binomial(link = "logit"))) # alpha = coef(mod) # ph_glm = round(inv_logit(design_mat %*% alpha), 2) ph_glm = round(predict(mod, as.data.frame(design_mat), type = "response"), 2) mod_noint = glm(formula = y ~ x1 + x2 , family = binomial(link = "logit")) ph_glm_noint = round(predict(mod_noint, as.data.frame(design_mat), type = "response"), 2) library(corrplot) par(mfrow=c(2,2)) corrplot(to_mat(p0), method = "square", is.corr = F, title = "Truth", mar=c(0,0,1,0)) corrplot(to_mat(ph_np), method = "square", is.corr = F, title = "Non-param", mar=c(0,0,1,0)) corrplot(to_mat(ph_glm), method = "square", is.corr = F, title = "GLM \n (with interaction)", mar=c(0,0,2,0)) corrplot(to_mat(ph_glm_noint), method = "square", is.corr = F, title = "GLM \n(no interaction)", mar=c(0,0,2,0)) Here are the results: As can be seen, the nonparametric estimator is very close to the true $p$ which is given in the code above. On the other hand, the GLM estimator has a large bias, for example for dose combination (1,5), even though we have 1000 samples on each of the doses. There seems to be a systematic bias and the parametric model seems to be incapable of capturing this $p$ . Is this expected and is there a simple fix?
