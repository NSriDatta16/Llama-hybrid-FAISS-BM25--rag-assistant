[site]: crossvalidated
[post_id]: 546067
[parent_id]: 546063
[tags]: 
This is a consequence of Jensen's inequality. Because the exponential function is convex, the expectation $\mathbb{E} \{ \exp(\beta_0 + \beta_1 x) \}$ is not the same as $\exp\{ \mathbb{E} (\beta_0 + \beta_1 x) \}$ . Instead, $\mathbb{E} \{ \exp(\beta_0 + \beta_1 x) \} = \exp(\beta_0 + \frac{\beta_1^2}{2} )$ For logistic regression, this doesn't matter because zeroes and ones are symmetric due to how the logistic function is defined. But in your multinomial case, you're using the softmax function to set the probabilities, and so using your example of 0.1, 0.2, and 0.3 for the coefficients: $ p(X=1) = \frac{ \exp(0.1^2/2 ) }{\exp(0.1^2/2 ) + \exp(0.2^2/2 ) + \exp(0.3^2/2 )} = 0.327$
