[site]: crossvalidated
[post_id]: 512570
[parent_id]: 
[tags]: 
Classification where only a small subset of all samples are actually predictive

Hello datascience community I have a classification task at hand where only a small subset ( For testing purposes, I created a toy data set where about 1% of all samples are predictive. Applying a neural network classifier (with binary-crossentropy as loss function) on it works quite well in the sense that the classifier is very confident on the predictive samples and outputs predictions close to 0.5 on all other samples. However, when I reduce the fraction of predictive samples to 0.01% and smaller and also add some noise to the predictive samples (meaning for example that a certain input pattern only leads to a predefined outcome in 3 out of 5 instances) the classifier fails to learn anything useful even though there are non-random relationships to be identified per construction of the dataset. Even increasing the number of total samples does not help which in theory it should. If I have unlimited samples, I should be able to detect any relationship, no matter how faint the signal is. This tells me that I am using an algorithm that is not perfectly suited to my problem. Could you point me in the right direction?
