[site]: stackoverflow
[post_id]: 2032432
[parent_id]: 2032396
[tags]: 
Here is one of the first google hits for limitations in Access. It's not completely clear to me which version that is for. Nonetheless, you can probably find the limits easily for the version of interest with a bit of searching. In reality, from a storage perspective, Access could likely store the records for 2000 patients a year ... but it doesn't seem like a good idea. It does not handle multi-user environments very well at all, which I assume would be likely in this case. As far as suggestions, you can get any number of people listing the one they like best. I would recommend Advantage Database Server . But my suggestion could be considered a bit biased since I am one of the developers on it. There are quite a few database engines that will work. You will need to study them and probably make your own choice based on requirements and functionality provided by the database engine. Edit I probably should have been a bit more clear that I was not singling out Access specifically as having problems. The issue is more with client/server versus non-client/server environments. It is a simple issue. With file-sharing database systems (of which MS Access is a member), the client makes the updates to the files. On a networked system, this introduces potential problems. Even Microsoft recognizes this . In the section of that article titled Additional best practices for network environments , it specifically says that the database can be corrupted if a client is stopped unexpectedly or if a network connection is dropped. For example, I just now opened northwind.mdb and deleted the first Orders record. This resulted in 19 file writes to the database file. I tested the same thing over the network and counted 19 individual writes across the network. If the connection is dropped in the middle of that, then there is potential for corruption. With a client/server solution such as SQL Server, a record delete would be one single command sent to the server. It either gets there or it doesn't. If it reaches the server, it can be handled "atomically" by the server. With database environments, the ability to make logically consistent updates is critical. A record update often involves multiple file updates. Not only must the record itself be udpated, but there are often index updates (possibly multiple indexes and multiple page writes for each one in a b-tree), transactions, referential integrity, meta-data (e.g., record counts), etc.
