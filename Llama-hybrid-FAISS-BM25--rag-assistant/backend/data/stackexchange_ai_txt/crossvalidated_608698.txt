[site]: crossvalidated
[post_id]: 608698
[parent_id]: 608694
[tags]: 
5% would not be the performance of the model making predictions “at random” or if you just classified everything as 1’s. I'm not sure if comparing it to the base rate makes sense here. It means comparing to the most primitive alternative possible. Why not try some other simple model (decision tree, logistic regression, $k$ NN) as a benchmark? Moreover, there's nothing magical about “70-80% precision”. For some problems, this would not be achievable, but for others way too low. Those numbers are arbitrary and there's no reason whatsoever to aim at them.
