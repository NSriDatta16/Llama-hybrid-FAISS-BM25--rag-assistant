[site]: crossvalidated
[post_id]: 10052
[parent_id]: 10044
[tags]: 
In effect, you are proposing to use linear regression as a mathematical procedure to condense a 10-variate observation into a single variable (the slope). As such it's just another example of similar procedures like (say) using an average of repeated measurements as a regression variable or including principal components scores in a regression. Specific comments follow. (1) Linear regression does not require the X's (independent variables) to be "independent." Indeed, in the standard formulation the concept of independence does not even apply because the X's are fixed values, not realizations of a random variable. (2) Yes, you can use the slopes as dependent variables. It would help to establish that they might behave like the dependent variable in linear regression. For ordinary least squares this means that a. Slopes may depend on some of the patient attributes. b. The dependence is approximately linear, at least for the range of observed patient attributes. c. Any variation between an observed slope and the hypothesized slope can be considered random. d. This random variation is (i) independent from patient to patient and (ii) has approximately the same distribution from patient to patient. e. As before, the independent variables are not viewed as random but as fixed and measured without appreciable error. If all these conditions approximately hold, you should be ok. Violations of (d) or (e) can be cured by using generalizations of ordinary least squares. (2'). Because the slopes will exhibit uncertainty (as measured in the regression used to estimate the slopes), they might not be good candidates for independent variables unless you are treating them as random in a mixed model or are using an errors-in-variables model. You can also cope with this situation by means of a hierarchical Bayes model .
