[site]: crossvalidated
[post_id]: 557528
[parent_id]: 
[tags]: 
Understanding Minimum Description Length for Time Series

I am trying to reproduce (in Python) the minimum description length work found near Figure 6 from this paper along with their sample Matlab code . function [bit_sz, dim_id] = get_bit_save(motif_1, motif_2, n_dim, n_bit) tot_dim = size(motif_1, 2); sub_len = size(motif_1, 1); split_pt = get_desc_split_pt(n_bit); disc_1 = discretization(motif_1, split_pt); disc_2 = discretization(motif_2, split_pt); [~, dim_id] = sort(sum(abs(disc_1 - disc_2), 1), 'ascend'); dim_id = dim_id(1:n_dim); motif_diff = disc_1(:, dim_id) - disc_2(:, dim_id); n_val = length(unique(motif_diff)); bit_sz = n_bit * (tot_dim * sub_len * 2 - n_dim * sub_len); bit_sz = bit_sz + n_dim * sub_len * log2(n_val) + n_val * n_bit; Unfortunately, the details are sparse and the first author has since graduated. From what I can understand, they start with a pair of multi-dimensional time series subsequences motif_1 and motif_2 (each row is a dimension): Example: motif_1 = np.array([[0.3, 0.8, 0.8, 0.3, 0.1], [0.8, 0.7, 0.5, 0.6, 0.8], [0.8, 0.3, 0.8, 1. , 1. ]]) motif_2 = np.array([[0.5, 0.9, 0.1, 0.8, 0. ], [0.3, 0.1, 0.6, 0.6, 0.5], [0.7, 0.8, 0.8, 0.7, 0.2]]) And the first step is to take each motif and apply a discretization (normalization) to each of them which essentially converts the motifs into integers based on some binning criteria. Using their 8-bit discretization function, the result is: disc_1 = np.array([[158, 201, 201, 158, 138], [201, 194, 177, 185, 201], [201, 158, 201, 215, 215]]) disc_1 = np.array([[177, 208, 138, 201, 127], [158, 138, 185, 185, 177], [194, 201, 201, 194, 148]]) Next, they perform an element-wise subtraction (a diff) between the discretized arrays, sum the rows, orders the sums, and store the corresponding row indices into dim_id (dimension ids): dim_id = np.argsort(np.sum(abs(disc_1 - disc_2), axis=1)) # array([1, 2, 0]) Basically, this determines which (corresponding) rows in disc_1 and disc_2 are most "similar" (i.e., rows with more different elements will have a higher sum and vice versa) and then, based on the value of n_dim , a subset of the n_dim top-most similar rows are selected. So, say, n_dim = 2 then: dim_id = dim_id[:n_dim] # array([1, 2]) Then, only this subset of rows is chosen from the discretized arrays to be diffed and the MDL process (described near Figure 6 from this paper ) begins: motif_diff = disc_1[dim_id] - disc_2[dim_id] # array([[ 43, 56, -8, 0, 24], [ 7, -43, 0, 21, 67]]) It is starting here where I don't understand the rationale for the remaining three lines of their Matlab code: n_val = length(unique(motif_diff)); bit_sz = n_bit * (tot_dim * sub_len * 2 - n_dim * sub_len); bit_sz = bit_sz + n_dim * sub_len * log2(n_val) + n_val * n_bit; From what I can tell, the first line is counting the total number of unique elements in motif_diff . However, from reading other MDL work regarding (discretized) time series compression: We should only count the non-zero elements. Here, they count zero elements too (I don't get this) The unique non-zero elements from each row should be counted independently from the other rows. Here, they are combining all rows together (I don't get this) Finally, in the second and third lines, they compute the bit size, bit_sz , which I think is suppose to represent either some amount of compression OR the amount of bits saved by using disc_1 to compress disc_2 . While I understand what tot_dim (total dimensions = 3), sub_len (subsequence length = 5), and n_bit (number of bits = 8-bits) mean, I have no idea what is being computed here as it relates to MDL. It appears that: bit_sz = n_bit * (tot_dim * sub_len * 2 - n_dim * sub_len); is keeping track of the number of bits or elements that could not be compressed. However, I don't understand what is happening in: bit_sz = bit_sz + n_dim * sub_len * log2(n_val) + n_val * n_bit; except that n_dim * sub_len * log2(n_val) + n_val * n_bit should account for the compressible elements. The same authors published a similarly related paper (see Equation 3) but it doesn't quite look like the equation above. Any help or assistance to understand this would be greatly appreciated!
