[site]: datascience
[post_id]: 41375
[parent_id]: 41356
[tags]: 
I will leave the bigger questions for wiser folks, but on the data science side, your on the right track for the reasons you state. Cosine Similarity is a good solution for classifying sparse information sets. Words are a sparse information set to start with. This appears to be labeling summary data. So a single, or few, terms against summary data is sparse on sparse. Done this more than a few times, it will be hard for you to find a better model than Cosine Simularity here.
