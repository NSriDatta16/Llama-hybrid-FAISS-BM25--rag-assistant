[site]: crossvalidated
[post_id]: 141005
[parent_id]: 
[tags]: 
Crossvalidation in hierarchical bayesian models (HBMs)

I am trying to find a way to cross-validate Hierarchical Bayesian Models used for predicting and modelling abundance in Species Distribution Models. For this purpose, I have tried posterior predictive checks proposed in Kéry & Schaub 2011, chapter 12.3.1 with the following modified $\chi^2$ discrepancy measure: $$\sum_i{{(Y_i - EY_i)^2}\over{var Y_i + 0.5}}$$ (the 0.5 is added to prevent division by zero - this is slighlty modified Gelman 2004 (2nd edition, pg. 175) $\chi^2$ discrepancy). As I want to test the predictive power of the model - at sites for which we don't have data - I split the data into fitting set and validation set and I did the predictive posterior checks in two variants: on the fitted set on the validation (i.e. cross-validation) set Very simplified, the JAGS model including posterior predictive checks looks like this: for (i in 1:sites) { log(lambda[i]) where Y[i,j] is the observed count of the species at site i on occasion j , N[i] is the actual latent abundance of the species at site i . First two thirds of the sites are used to fit the data, remaining third of the sites is reserved for crossvalidation only. Questions: 1. Is this approach OK? Kéry doesn't mention crossvalidation, and Gelman 2004 has a note in chapter 8.2 which I do not understand (especially the italic part): If a model is to be evaluated by its expected predictive fit to new data, a reasonable approach would seem to be cross-validation - fitting the model to part of a dataset and evaluating it on the rest - but it is not clear how to interpret this in terms of posterior inference. Conditional on a model being correct, we can directly assess it's predictive accuracy by comparing its fit to simulated replicated data sets $Y.new$ - but DIC and cross-validation attempt to do better and capture predictive error including model misfit. 2. Is the modification with + 0.5 OK for this purpose? I mean, couldn't it make any mess? 3. How to create easily interpretable measure to assess quality of the model? I mean something that would tell me 0% to 100% - from absolutely poor to absolutely perfect model. Kery is proposing two measures: bayesian p-value mean(simulations$fit.new > simulations$fit) , lack-of-fit ratio mean(simulations$fit / simulations$fit.new) But how to interpret those? Is e.g. a lack-of-fit ratio of 2 good or bad? I would like some measure which has clear scale like $r$ or $AUC$ where you can e.g. say that 1 is a perfect model, > 0.75 is good, Here are few examples of results and plots, where I plot fit or fit.cv on the X axis and fit.new and fit.cv.new on the Y axis. Example 1 - comparison of two models: linear model PPC - fitted data: p-value lack-of-fit ratio 0.9276667 0.9442094 linear model PPC - independent data: p-value lack-of-fit ratio 0.000000 1.820381 superpredictor PPC - fitted data: p-value lack-of-fit ratio 0.9810000 0.9213055 superpredictor PPC - independent data: p-value lack-of-fit ratio 0.000000 1.742552 Example 2 - comparison of two models: linear model PPC - fitted data: p-value lack-of-fit ratio 0.7705333 0.9245741 linear model PPC - independent data: p-value lack-of-fit ratio 0.002200 2.008853 superpredictor PPC - fitted data: p-value lack-of-fit ratio 0.7315333 0.9389283 superpredictor PPC - independent data: p-value lack-of-fit ratio 0.000000 2.985811 Example 3 - comparison of two models: linear model PPC - fitted data: p-value lack-of-fit ratio 0.6679667 0.9722895 linear model PPC - independent data: p-value lack-of-fit ratio 0.005516667 1.341490485 superpredictor PPC - fitted data: p-value lack-of-fit ratio 0.5848000 0.9869094 superpredictor PPC - independent data: p-value lack-of-fit ratio 0.000000 2.012136 In models 1,2 I can tell that the superpredictor is better than the linear model, but how to get any idea of how good/poor both of the models are on a scale (absolutely poor) - (absolutely perfect)? Would e.g. something like comparison with null model do the work? I have tried it:
