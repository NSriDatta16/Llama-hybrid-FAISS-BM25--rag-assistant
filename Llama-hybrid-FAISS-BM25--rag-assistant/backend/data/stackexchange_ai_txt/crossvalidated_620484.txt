[site]: crossvalidated
[post_id]: 620484
[parent_id]: 620483
[tags]: 
What are you trying to do? If these grouped input somehow represent a combined unit/entity (e.g. 4 measurements for a patient, or for a device you test from a production line, or ...), it may or may not make sense to have e.g. an embedding for each units or something like that, or to somehow capture this variability between units. You may or may not want to do is to make sure cross-validation splits respect that the 4 outputs for the same unit are always in the same part of the split (either train or validation). If you only want to predict the mean for new not seen inputs when the whole process is otherwise absolutely the same (e.g. a physics experiment with all measurements done with the exact same setup, just with each settings you do 4 measurements), then in a sense the variability is irrelevant (note that this would not necessarily be like that for e.g. binary data). Then, it may still make sense to always do CV-splits based on the 4 grouped measurements together (to test the ability to interpolate without seeing a measurement in training of the very same settings). You could certainly do conformal prediction. E.g. you could do quantile regression (setting confidence e.g. to be the difference between the estimates for two suitably chosen quantiles - one low and one high such as 0.25 and 0.75) and/or losses that target quantile regression (such as pinball loss when applied to predicted mean +- predicted standard deviation). Maybe these keywords will help finding more material, e.g. it may also be worthwhile to look at data science competitions that asked for prediction intervals and not just point predictions. There's quite a few of those, e.g. the competition where this discussion occurred or the "M5 Forecasting: Uncertainty" competition . Doing this may be helpful for two reasons: You are actually interested in the uncertainty in the prediction. You are not really interested in the uncertainty in the prediction, but you hope that the network having to "learn" about the extent of uncertainty will let it "learn more about the problem" and lead to better performance even on the mean prediction. I am not aware whether there's much information on whether this tends to help in this sense.
