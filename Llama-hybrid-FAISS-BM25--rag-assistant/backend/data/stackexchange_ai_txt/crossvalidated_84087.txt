[site]: crossvalidated
[post_id]: 84087
[parent_id]: 84079
[tags]: 
This is subjective, and doesn't directly address your question, but I hope it's helpful regardless. I think people too often conflate a statistical hypothesis with a scientific one, which leads to problems. Regarding the former, the statistical hypothesis being tested is almost always whether the parameter being estimated is zero or not. But with any deeper thought on the matter, one realizes this is often trivial, for all the reasons Peter stated. But because it's called a hypothesis, and it is falsifiable, it seems to satisfy people that something scientific has been achieved. It also tends to reduced a complex scientific question to the reporting of one key statistical hypothesis. This is further encouraged by how a lot of scientific research is published - thin-slice the bigger problem and report every slice/p-value in a different paper. Where I am going is this, with respect to your question? I am not offended by statistical hypothesis tests per se, as long as they are applied thoughtfully. In other words, the solution is not just about finding a better statistical approach, but rather about applying a better scientific approach; by clearly specifying a complete theory that can be tested, collecting the relevant data, and then ensuring any statistical modelling or testing directly follows from these, rather than the other way around.
