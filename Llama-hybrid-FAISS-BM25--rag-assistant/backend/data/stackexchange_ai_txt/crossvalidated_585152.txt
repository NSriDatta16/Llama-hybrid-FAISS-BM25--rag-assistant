[site]: crossvalidated
[post_id]: 585152
[parent_id]: 584918
[tags]: 
First of all, bnlearn "only" learns Bayesian networks , so the arrows cannot be interpreted as causal directions. The documentation claims that causality "is incorporated in Bayesian graphical models" but that is only true for causal Bayesian graphical models. Bayesian networks are mainly used to describe stochastic dependencies and contain only limited causal information. E.g., if you give a dataset of two dependent binary variables $X$ and $Y$ to bnlearn , it will either return $X\to Y$ or $Y\to X$ independent of whether $X$ caused $Y$ or $Y$ caused $X$ , because the causal relation cannot be deduced just from the observations of $X$ and $Y$ . Thus, if you say "I would have thought that all variables affect Survived", referring to the direction of the arrows, then this insinuates that you presume the arrows to indicate causal effect, which is not the case. Now to your question: "How has this structure been generated?" You have used the method Hillclimbing which is a greedy local method, i.e. it is fast but can lead to wrong results. Next, the NaiveBayes method: First, note that the documentation says: "Naive Bayes is a special case of Bayesian Model where the only edges in the model are from the feature variables to the dependent variable." If this was true, conditioning on the dependent variable would make all the features dependent. However, the defining property of Naive Bayes is that it is actually the other way around: conditioning on the dependent variable makes all the features independent . Summary : If you are interested in causation, don't use bnlearn , but causality software, see e.g. here , here , or here . If you are (only) interested in the probabilistic graphical models described by Bayesian networks, then I would rather suggest trying something more trustworthy like the R package bnlearn and friends .
