[site]: datascience
[post_id]: 96502
[parent_id]: 96458
[tags]: 
Following with the idea of building a classifier, one option is to use nltk library together with Keras-Tensorflow once you have a labeled dataset with the desired process categories . You can go on two main approaches: bag-of-words sequence-modeling As a quick resume of the steps to implement in a text classifier with the first approach, you could follow the ones below (you can find a worked pout example here ): Read and check that your raw input sentences (to be used for training, validating...) have the right format and correct label, something like: Preprocess your sentences as needed, which could be these steps: - lowercase all your words - remove punctuation characters - tokenize your words (here, your can define if you want 1-gram tokens, 2-grams tokens...) - stem your words (so as to eliminate singular/plurals, verbs tenses... (this point is not always straigtforward, because some stemmers like PorterStemmer, SnowballStemmer might offer different performance depending on the selected language), more info here - add more steps custom for your use case, the ones above are standard ones, but you can filter sentences wich you know do not offer value for you use case Once you have preprocessed your input data, you should be able top access your vocabulary, to have something like: and you are ready to vectorize your sentences, to end up with something like: build your classifier, where you can try out different models, like a convolutional neural network, a bi-directional LSTM, a transformer model...
