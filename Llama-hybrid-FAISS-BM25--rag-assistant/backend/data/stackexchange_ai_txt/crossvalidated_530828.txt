[site]: crossvalidated
[post_id]: 530828
[parent_id]: 
[tags]: 
Why ROC curves gives different ranking of classes than confsuion matrix?

I am applying logistic regression in a imbalance class datset which has 16 classes. When I see the confusion matrix I found that best predicted class is 5 having the score of 0.97 then class 15 having the score of 0.89 and then class 7 having score of 0.46. When I plot the ROC curve then I see the class predicted ordering 5, 15, and 14 according to AUC. What is wrong in my code or I am getting some confusion between ROC curve as I should not expect the same behaviour as confusion matrix from ROC. from sklearn.preprocessing import PolynomialFeatures, StandardScaler log_reg_model = LogisticRegression(max_iter=50000,penalty='l1',multi_class='ovr',class_weight='balanced',solver='liblinear') pipe=Pipeline([('polynomial_features',polynomial),('StandardScaler',StandardScaler()), ('logistic_regression',log_reg_model)]) y_test_dummies = pd.get_dummies(y_test, drop_first=False).values for i in range(n_classes): fpr[i],tpr[i], _ = roc_curve(y_test_dummies[:,i], pipe.predict_proba(x_test)[:,i]) roc_auc[i] = auc(fpr[i], tpr[i]) plt.plot(fpr[i], tpr[i], label='ROC(area = %0.2f)' % (roc_auc[i]))
