[site]: crossvalidated
[post_id]: 220927
[parent_id]: 220924
[tags]: 
I agree with your thinking. If you want to maximize predictive accuracy, then in general, when trying to minimize training error in order to select model parameters, you should use the same metric for training error that you'll use for test error. (You might want to do something other than just minimize training error, as in regularization , but deliberately mistmatching training-error and test-error metrics is probably not a good way to do this.) So why do we see mismatches in practice? Partly it's because, as you indicate, estimating parameters according to the test-error metric may just be more difficult than using another metric. It may also be tradition and inertia. For example, in the case of logistic regression, people are used to fitting with MLE but evaluating predictions by discretizing the model outputs and using zeroâ€“one loss rather than using a proper scoring rule . Scoring rules are an obscure topic although logistic regression is a very popular technique.
