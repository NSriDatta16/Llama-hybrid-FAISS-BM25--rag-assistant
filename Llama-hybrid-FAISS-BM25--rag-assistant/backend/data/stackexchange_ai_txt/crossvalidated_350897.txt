[site]: crossvalidated
[post_id]: 350897
[parent_id]: 
[tags]: 
Stacking without splitting data

I learned Stacking used in Ensemble learning. In Stacking, training data is split into two sets. The first set is used for training each model (layer-1, left figure), the second one is used for training of combiner of predictions (layer-2, right figure). In my project, I have two different multi-classification models. And I have a dataset (train/dev/test) which was used for training and testing two models. When I have learned Stacking, I thought I tried to use the whole training set for the blending training set (layer-2), then, test the blender with the test data. Though I read the book and other websites, and they mention the training set is splitted into subsets. Is it uncommon (or not recommended) to use the whole training set for both layer-1 and 2? I thought this is not wrong since test data has been already prepared. I have already trained my model by the whole training dataset. So if it is not recommended, should I train my models with splitted training dataset? The images are cited from "Hands on Machine Learning with scikit-learn and Tensorflow." (2017).
