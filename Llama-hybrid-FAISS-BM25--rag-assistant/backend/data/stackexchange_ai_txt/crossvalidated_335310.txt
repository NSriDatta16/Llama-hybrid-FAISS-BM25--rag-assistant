[site]: crossvalidated
[post_id]: 335310
[parent_id]: 
[tags]: 
Grid based piecewise-stationary Poisson process test

I'm trying to fit a set of data to a variety of Poisson-based models, and have hit a stumbling block when trying to fit a piecewise-stationary Poisson process. What I mean by this is a Poisson process that has intensity $\lambda_1$ for time interval $T_1$, then intensity $\lambda_2$ for the time interval $T_2 = T - T_1$, where $T$ is the total observational period. The likelihood function that I'm using for observing $N_1$ events in that first time interval and $N_2$ events in the second is: $${Pr(N_1, N_2 | \lambda_1, \lambda_2, \Delta T_1)} = \frac{\left(\lambda_1 \Delta T_1\right)^{N_1} \textit{e}^{-\lambda_1 \Delta T_1}}{N_1 !} \frac{\left(\lambda_2 (T-\Delta T_1\right))^{N_2} \textit{e}^{-\lambda_2 (T-\Delta T_1)}}{N_2 !}$$ For testing purposes I create a set of fake data that should have a very clear signal of a rate change by generating 20 events uniformly distributed within the interval $t=0$ and $t=4500$, then 500 events uniformly distributed within the interval $t=4500$ and $t=13500$. An example of this is below. If I fix the two intensities, $\lambda_1$ and $\lambda_2$, to be constant, and equal to their expected value based on the model (0.00445, 0.0556 respectively), then scan through various choices of $T_1$ we can see the one dimensional likelihood as a function of $T_1$ below. It shows that (as expected) the most likely hypothesis is one with $T_1 \sim 4500$ (dashed black line indicates the true simulation parameter). I then generate a 500x500x500 3D grid of likelihoods, spanning uniform ranges of $\lambda_1$, $\lambda_2$, and $T_1$, noting that $N_1$ and $N_2$ vary as a function of $T_1$. When I marginalise this probability grid over different combinations of parameters things start to not make sense to me any more. In doing this marginalisation I adopt bounded uniform priors on all three parameters (janky looking start/end points chosen to avoid some computational problems at boundaries of the grid): $$\lambda_1 \sim \text{Unif}(1\times10^{-4},\ 1.36\times10^{-2})$$ $$\lambda_2 \sim \text{Unif}(1\times10^{-4},\ 1.67\times10^{-1})$$ $$T_1 \sim \text{Unif}(1,\ 13499)$$ By marginalising over any two of the parameters, I should find the posterior distribution for the third parameter (up to a constant normalisation factor thanks to the uniform priors). I plot all of these, plus the 2D marginalised likelihood surfaces for all combinations of parameters below. It is self-consistent: the 2D plots, when integrated along either axis give you the 1D posteriors. The black dashed lines show the true simulation parameters for $\lambda_1$, $\lambda_2$, $T_1$. It's clear that the posteriors for $\lambda_2$ and $T_1$ do not adequately include the true simulation parameter. I'm not sure what's going wrong! The more events I test with the more extreme (sharp) the posteriors become, while getting no closer to the simulation parameter they should be estimating. I then tried to visualise the likelihoods on a 3d grid (see the gif linked here , each point in the grid is coloured and transparencied in proportion to the likelihood at that point, yellow/solid being most likely while purple/faint being least likely) it's clear that the maximum likelihood points do lie on the $T_1=0$ plane. There is a very slight local maximum away from the boundaries of the likelihood grid (hard to see in the gif due to the coarseness of that grid), at the true simulation parameters, but it is 10 times less likely than the points on the edge, and it drops off fairly fast in any direction away from that local maximum. Is this grid based method just the wrong way to go about this kind of test? Am I doing/missing something obvious/silly? Are the uniform priors causing problems? Do I have to move to a MCMC/other method for finding posteriors?
