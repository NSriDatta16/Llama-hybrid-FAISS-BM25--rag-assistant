[site]: datascience
[post_id]: 33624
[parent_id]: 33524
[tags]: 
A few comments on your questions What i dont understand is : why n this setting, $\hat{f}$ is often treated as a black box, in the sense that one is not typically concerned with the exact form of $\hat{f}$, provided that it yields accurate predictions for Y . This is a little inaccurate. The functional form of $f$ (or $\hat{f}$) is of interest, and may algorithms like neural networks do try to approximate $f$ (see Universal approximation theorem ). The problem is that many statistical/ML algorithms may not display the approximation in a way that is easily interpretable. While a neural network may try to approximate the form of $f$, it's architecture is difficult (or nearly impossible) to interpret. Therefore, many people see it as a "black box". Because the shift of interest may be more on prediction, and less on inference of parameter estimates, the fact that a user may have a "black box" is unimportant as long as the main goal of prediction is performed well. Also, not all statistical/ML algorithms have to be complex like neural networks. You can have simple architectures that work well, and are easily interpretable, like generalized linear models (i.e. linear regression/logistic regression). These algorithms can perform as well as neural networks on certain problems. So the difference in focus is really just due to the project/research goal, not a difference between statistics and Machine Learning. By the way, there's little difference between the two. The computer science/engineering community has borrowed many ideas from the statistical community long before the term "machine learning" was popular.
