[site]: crossvalidated
[post_id]: 108505
[parent_id]: 108462
[tags]: 
You should not touch the weights. The way to proceed is to center and scale the training data and apply that same transformation to the test data. They complement each other. You may have a look at this video where the topic is nicely explained. Scaling is relevant from a practical point of view, because large scale methods are sensitive to unnormalized data. Notice that SVMs are based on scalar products. If the scales of different features vary widely, (for example one has mean 1000 and variance 1000000) and another one is centered around 0 and variance 10, then the first is likely to drive the scalar products if not scaled. This idea also applies to gradient calculation (which is relevant for solvers).
