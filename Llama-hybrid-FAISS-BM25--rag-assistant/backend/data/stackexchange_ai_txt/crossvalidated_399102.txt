[site]: crossvalidated
[post_id]: 399102
[parent_id]: 
[tags]: 
How many bits of information on average are you receiving if you get this information each time you toss a coin?

Say I can psychically predict the result of a fair coin toss with probability 0.6. On average, how many bits of accurate information am I communicating each time I do it? I think the answer is ${\large 1-(-\Sigma} p_i \log_2(p_i){\large )} = 1+0.6 \log_2(0.6)+0.4 \log_2(0.4)$ $= 1-0.97095=0.02905$ where the sum is the information entropy function . The position can be regarded as one where for each throw I receive from my probabilistically more informed vantage point only 0.97095 bits, whereas if you were always to receive the correct answer you would from your point of view receive 1 bit, so from your point of view which is that of a world we assume to be sceptical about psychic abilities it is somehow as if I have produced 1- 0.97095 bits = 0.02905 bits. But is this the right way to go about calculating how many bits I am communicating? Even if it is, I am not sure why it is.
