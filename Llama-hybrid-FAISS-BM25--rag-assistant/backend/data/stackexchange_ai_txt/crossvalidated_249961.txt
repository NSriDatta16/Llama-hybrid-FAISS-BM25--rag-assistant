[site]: crossvalidated
[post_id]: 249961
[parent_id]: 249656
[tags]: 
If I understand correctly, your analysis is: Calculate the expected number of coin-flips required to get a head. Calculate the payout for the outcome where you get exactly the expected number. Value the game equal to that payout. ...OK, let's modify that game a little bit. Just like the original version, I will flip a coin and keep flipping until I throw heads. Only the payouts have changed: If I flip heads on the second throw, you get four dollars. On any other outcome, you lose everything you own and have to come work for me forever, for free. How many coins do we expect to flip before we get a head? 2, exactly the same as before. What is the payout for the outcome where we flip two coins to get a head? $4.00, exactly the same as before. How much would you be willing to pay for the 'privilege' of paying this game that has a 75% chance of bankrupting you and a 25% chance of returning $4.00? I suspect the answer is not "up to four dollars, exactly the same as before". Which means there's a hole in your logic. Taking a broader perspective, expected winnings are not necessarily enough information to answer this sort of question; usually it depends on some additional context. Is this a one-off opportunity or are you expecting to be offered this gamble many times? How much money do you have on hand? And how much money do you need to be happy? For example, if my total wealth is $100 but I urgently need a million dollars for a life-saving operation, I would be willing to pay all my money for a single shot at the St. Petersburg gamble. It only gives me a 1/2^19 chance of winning the money I need, but if I don't play I have no chance at all. On the other hand, if my total wealth is $1000,000 and I need exactly a million dollars for that operation, the most I'd be willing to pay for a single game is two dollars (which I'm guaranteed to win back). Anything more, and I have a 1/2 chance of ending up short of the million bucks I need to save my life. If I'm expecting to have many chances to play such games, then I probably want to choose a strategy that gives me a high probability of having lots of money at the end of all those games. For example: Game A is guaranteed to increase my wealth by 10% every time I play it. (Expected winning: +10% of my current wealth.) Game B has a 90% chance of doubling my wealth, and a 10% chance of bankrupting me. (Expected winning: +70% of my current wealth.) [edit: actually +80% because I fail at basic arithmetic, but the argument still holds.] If I play 100 iterations of Game A, I'm certain to multiply my wealth by 13,780 times. If I play 100 iterations of Game B, I have a 0.0027% chance of becoming unimaginably wealthy (about 10^30 x what I started with)... and a 99.73% chance of being bankrupted. Even though the average is better than for Game A, it's not a good option. For this sort of heavily-iterated game, rather than trying to maximise my expected winnings in each game, I'm better off trying to maximise expected value of ln(total wealth after game/total wealth before game). This ensures long-term growth without getting wiped out. If the stakes for every game are small relative to my total wealth, then this is approximately equivalent to maximising expected winnings in each game. So, if you're playing lots of games and never risking a large portion of your current wealth, then the expected value of the gamble tells you all you need to know. In just about any other situation, you need to think about other things too.
