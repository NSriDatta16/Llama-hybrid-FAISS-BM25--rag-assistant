[site]: crossvalidated
[post_id]: 206693
[parent_id]: 203103
[tags]: 
In general, I think it's more fruitful scientifically and statistically to start by asking a broader and different question, which is how far can a response be predicted from a circular predictor. I say circular here rather than directional , partly because the latter includes spherical and even more fabulous spaces, which can't all be covered in a single answer; and partly because your examples, time of day and time of year , are both circular. A further major example is compass direction (relevant to winds, animal or human movements, alignments, etc.), which features in many circular problems: indeed, for some scientists it is a more obvious starting point. Whenever you can get away with it, using sine and cosine functions of time in some kind of regression model is a simple and easy to implement modelling method. It is the first port of call for many biological and/or environmental examples. (The two kinds are often mushed together, because biotic phenomena showing seasonality are usually responding directly or indirectly to climate, or to weather.) For concreteness, imagine time measurements over 24 hours or 12 months, so that e.g. $\sin [2\pi (\text{hour}/24)],\ \ \cos [2\pi (\text{hour}/24)]$ $\sin [2\pi (\text{month}/12)],\ \ \cos [2\pi (\text{month}/12)]$ each describe one cycle over the entire day or year. A formal test of no relationship between a measured or counted response and some circular time would then be a standard test of whether the coefficients of sine and cosine are jointly zero in a generalized linear model with sine and cosine as predictors, an appropriate link and family being chosen according to the nature of the response. The question of the marginal distribution of the response (normal or other) is in this approach secondary and/or to be handled by family choice. The merit of sines and cosines is naturally that they are periodic and wrap around automatically, so the values at the beginning and end of each day or year are necessarily one and the same. There is no problem with boundary conditions, because there is no boundary. This approach has been called circular, periodic, trigonometric and Fourier regression. For one introductory tutorial review, see here In practice, Such tests usually show overwhelmingly significant results at conventional levels whenever we expect seasonality. The more interesting question is then the precise seasonal curve estimated, and whether we need a more complicated model with other sinusoidal terms too. Nothing rules out other predictors too, in which case we simply need more comprehensive models with other predictors included, say sines and cosines for seasonality and other predictors for everything else. At some point, depending jointly on the data, the problem and the tastes and experience of the researcher, it may become more natural to emphasise the time series aspect of the problem and build a model with explicit time dependence. Indeed, some statistically minded people would deny that there is any other way to approach it. What is easily named as trend (but not always so easily identifiable) comes under either #2 or #3, or even both. Many economists and other social scientists concerned with seasonality in markets, national and international economies, or other human phenomena are usually more impressed with the possibilities for more complicated variability within each day or (more commonly) year. Often, although not always, seasonality is a nuisance to be removed or adjusted for, in contrast to biological and environmental scientists who frequently regard seasonality as interesting and important, even the main focus of a project. That said, economists and others also often adopt a regression-type approach too, but with ammunition a bundle of indicator (dummy) variables, most simply $0, 1$ variables for each month or each quarter of a year . This can be a practical way of trying to catch the effects of named holidays, vacation periods, side-effects of school years, etc., as well as influences or shocks of climatic or weather origin. With those differences noted, most of the comments above also apply in economics and social sciences. Attitudes of, and approaches by, epidemiologists and medical statisticians concerned with variations in morbidity, mortality, hospital admissions, clinic visits, and the like, tend to fall in between these two extremes. In my view splitting days or years into halves to compare is usually arbitrary, artificial and at best awkward. It is also ignoring the kind of smooth structure typically present in the data. EDIT The account so far does not address the difference between discrete and continuous time, but I don't from my experience regard it as a big deal in practice. But precise choices depend on how the data arrive and on the pattern of change. If data were quarterly and human, I would tend to use indicator variables (e.g. quarters 3 and 4 are often different). If monthly and human, the choice isn't clear, but you would have to work hard to sell sines and cosines to most economists. If monthly or finer and biological or environmental, definitely sines and cosines. EDIT 2 Further details on trigonometric regression A distinctive detail of trigonometric regression (named in any other way if you prefer) is that almost always sine and cosine terms are best presented to a model in pairs. We first scale time of day, time of year or compass direction so that it is represented as an angle on the circle $\theta$ in radians, hence on the interval $[0, 2\pi]$. Then we use as many of the pairs $ \sin k\theta, \cos k\theta, k = 1, 2, 3, \dots$ as are needed in a model. (In circular statistics, trigonometric conventions tend to trump statistical conventions, so that Greek symbols such as $\theta, \phi, \psi$ are used for variables as well as parameters.) If we offer a pair of predictors such as $\sin \theta, \cos \theta$ to a regression-like model, then we have coefficient estimates, say $b_1, b_2$, for terms in the model, namely $b_1 \sin \theta, b_2 \cos \theta$. This is a way of fitting phase as well as amplitude of a periodic signal. Otherwise put, a function such as $\sin (\theta + \phi)$ can be rewritten as $$ \sin \theta \cos \phi + \cos \theta \sin \phi,$$ but $\cos \phi$ and $\sin \phi$ representing phase are estimated in the model fitting. That way we avoid a non-linear estimation problem. If we use $b_1 \sin \theta + b_2 \cos \theta$ to model circular variation, then automatically the maximum and minimum of that curve are half a circle apart. That is often a very good approximation for biological or environmental variations, but conversely we may well need several more terms to capture economic seasonality in particular. That could be a very good reason to use indicator variables instead, which lead immediately to simple interpretations of the coefficients.
