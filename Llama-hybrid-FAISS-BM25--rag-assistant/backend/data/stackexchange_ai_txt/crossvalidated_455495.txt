[site]: crossvalidated
[post_id]: 455495
[parent_id]: 455472
[tags]: 
Yes, standardisation should also use training data. Otherwise, it'll be data leakage. It maybe slight, but sometimes effective. Think about all the operations you do as a single pipeline, $\mathcal P$ : Step 1: Standardisation Step 2: Dimensionality Reduction Step 3: Classifier/Regression But, all together it is a model, $\mathcal M$ . All the validation and testing procedures you apply for a single model applies to this structure. For the covariance matrix, the answer is the same. You'll use your training set. Some libraries, such as sklearn has a good abstraction for this concept, namely Pipelines , where you put all the operations in a sequential manner, e.g. [ StdScaler , PCA , SVC ] and use a single fit function for the overall pipeline, making it act like a single unit/model. TL;DR : Any information you use from the test set is basically data-leakage .
