[site]: crossvalidated
[post_id]: 40367
[parent_id]: 40363
[tags]: 
A Survey of several of the variants can be found in the paper, 'Survey on Boosting Algorithms for Supervised and Semi-supervised Learning,' Artur Ferreira. Generally, the Original AdaBoost returns the binary valued class that is the ensemble sign result of several combined models. Real AdaBoost returns a real valued probability of class membership. The other variants are covered in the paper, but less frequently mentioned in common literature. As I understand it, Gentle Adaboost produces a more stable ensemble model. The AdaBoost.M1 and AdaBoost.M2 models are extensions to multi-class classifications (with M2 overcoming a restriction on the maximum error weights of classifiers from M1). "Experiments with a New Boosting Algorithm," Yoav Freund and Robert E. Schapire.
