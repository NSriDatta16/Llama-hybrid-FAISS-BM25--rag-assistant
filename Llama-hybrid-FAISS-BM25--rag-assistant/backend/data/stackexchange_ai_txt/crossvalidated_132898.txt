[site]: crossvalidated
[post_id]: 132898
[parent_id]: 132886
[tags]: 
You can reduce however many principal components you want...as long as you add a diagonal matrix to the k-reduced estimate you can match the variances exactly. For example, where $\mathbf{\widehat\Sigma}_{MOM}$ is the sample covariance matrix, we can write it as $$ \mathbf{\widehat\Sigma}_{MOM} = \mathbf{V\Lambda V^T} = \sum_{i=1}^{p} \lambda_i\mathbf{v}_i\mathbf{v}_i^T $$ Where $T$ is the transpose operator, $p$ the number of variables,$\mathbf{\Lambda}$ the diagonal matrix of eigen values,$\mathbf{V}$ a matrix of column eigen vectors and $\mathbf{v}_i$ the $i^{th}$ eigen vector. Suppose I choose the first $k $$ \mathrm{diag}(\mathbf{\widehat\Sigma}_{NEW}) = \mathrm{diag}(\mathbf{\widehat\Sigma}_{MOM}) $$ This is a very common approach in many high dimensional problems and can be thought of as a "shrinkage" technique. The problem with the answer given above is that it's a biased/inconsistent estimate of the variance (it will always underestimate the variance). This shrinkage technique will not suffer from such bias and allows you to specify however many principal components you want to keep. This comes in super handy when the rank of the covariance matrix is small. There are a lot of different methods for choosing $k$, this Wikipedia page highlights a few simpler ones. Personally I use Monte Carlo simulations predicated on Parallel Analysis. The method I use is robust to extreme rank deficiency, is reasonably quick, and predicts the correct number of significant principal components around 85% of the time at the 0.05 rejection level (and is usually pretty close when not exactly correct). If you want to be really quick you can use Random matrix Theory (RMT) techniques described here and here . The last reference also includes interesting Bayesian techniques if your into that sort of thing. RMT has a closed form solution, but it's based on asymptotics which may or may not hold up well with fewer observations or semi-definite covariance matrices.
