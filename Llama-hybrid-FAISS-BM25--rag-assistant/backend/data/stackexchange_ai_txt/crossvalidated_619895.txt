[site]: crossvalidated
[post_id]: 619895
[parent_id]: 
[tags]: 
Are machine learning performance metrics "collapsible"?

Are accuracy, AUROC and related measures (sensitivity, specificity) that are commonly used to estimate the performance of a supervised machine learning model using cross-validation etc. collapsible metrics? What I mean by that is suppose we want to estimate the accuracy of an ML classifier for some population composed of 100 individuals, 40 of which are men and 60 are women, and we can find that the accuracy of the classifier is 50% in men and 90% in women, will the test's accuracy in the population of 100 individuals be 50% * 0.4 + 90% * 0.60 = 74%? Or is this not the case?
