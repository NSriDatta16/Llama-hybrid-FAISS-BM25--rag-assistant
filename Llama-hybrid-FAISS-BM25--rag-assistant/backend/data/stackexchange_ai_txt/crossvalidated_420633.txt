[site]: crossvalidated
[post_id]: 420633
[parent_id]: 420597
[tags]: 
My question is, is the time step (the i^th step) at which a policy executes an action also a context? Contextual bandit algorithms should not use the time step as part of the context, they require state to be independent of time step. Making the state include time step relates features on $t$ and $t+1$ , making the state evolve predictably, so moves the problem definition from bandit algorithms to full reinforcement learning. As a result, your example: If one policy repeats actions 1, 2, 3 from the beginning so that the sequence of its actions is 123123123123 is not a policy for a bandit algorithm, because in order to create it you would need the policy to be a function of $t$ . suppose we have two polices A and B that are context-dependent. Also, let's say we pick A up to the k^th step and pick B for the rest of the steps. Then, the choice of the polices here is context dependent? No, because the time step is not part of the context. However, you could arrange data after collecting it so that the sequence did contain context - e.g. sort the data by one of the features. In which case your selection between the two policies would break the requirement.
