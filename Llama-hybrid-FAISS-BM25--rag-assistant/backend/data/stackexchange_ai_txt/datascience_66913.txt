[site]: datascience
[post_id]: 66913
[parent_id]: 
[tags]: 
How does attention mechanism learn?

I know how to build an attention in neural networks. But I don’t understand how attention layers learn the weights that pay attention to some specific embedding. I have this question because I’m tackling a NLP task using attention layer. I believe it should be very easy to learn (the most important part is to learn alignments). However, my neural networks only achieve 50% test set accuracy. And the attention matrix is weird. I don’t know how to improve my networks. To give a example: English: Who are you? Chinese: 你是誰？ The alignments are ‘Who’ to ‘誰’ ‘are’ to ‘是’ ‘you’ to ‘你’ How does attention learn that? Thank you!
