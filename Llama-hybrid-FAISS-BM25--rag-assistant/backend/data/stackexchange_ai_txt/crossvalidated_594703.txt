[site]: crossvalidated
[post_id]: 594703
[parent_id]: 
[tags]: 
How normalized, weighted composite score measaured?

How can we convert a vector of repeated measures of a variable into one value when the vector has varying length in different instances? For instance, let's assume V1 = {.95, .5, .95} but V2 = {.90} . How should these two vectors be treated to turn into two scalars? The first solution I found is taking average, but as you see above it penalizes longer vectors and creates average tendency. This is specially hurting the accuracy when doing Natural Language Processing. For instance, let's assume S1 = "Very good concert. I went there last night. It was awesome. but S2 = Very good concert. A human rater would recognize S1 as being more positive but taking the average would make S2 more positive. VADER , a package that measures the sentiment of text uses the term "Normalized, Weighted, Composite Score" to explain how it converts the sum of vectors with varying length to one scalar. Simply put, to measure the sentiment of a text, VADER converts it to a vector of words, then sums up the sentiment value of each word, and finally "normalizes" this value. How does this "normalization" happen? I use the term "normalization" in quotation marks to imply the broad definition of it.
