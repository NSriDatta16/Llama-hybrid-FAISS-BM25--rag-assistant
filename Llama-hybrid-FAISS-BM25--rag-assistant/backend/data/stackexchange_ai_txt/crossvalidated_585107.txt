[site]: crossvalidated
[post_id]: 585107
[parent_id]: 
[tags]: 
how is the KL divergence approximated for a mini batch of data?

I have a doubt regarding the computation of the KL divergence in the loss function of bayesian neural network. Assuming that $Q_\lambda(w)$ is the variational distribution and $P(w)$ is the prior distribution on the weights, how is this integral approximated? $$KL(Q,P)=\int Q_\lambda(w)\ln{\frac{Q_\lambda(w)}{P(w)}}$$ this is the first part of the loss function $$ \hat{\hat{ \mathcal{F}}}(\lambda)= \text{KL}[Q_{\lambda}(\bf{w})\Vert P(\bf{w})] -\frac{N}{M}\sum_{\substack{ i \in S \\ \epsilon \in P(\epsilon) }} \ln{P(\bf{y_i}|f^{g_{\lambda}(\bf{\epsilon})}(\bf{x_i}))} $$ Reading the definition of DenseLocalReparameterization i have found this advice: "When doing minibatch stochastic optimization, make sure to scale this loss such that it is applied just once per epoch (e.g. if kl is the sum of losses for each element of the batch, you should pass kl / num_examples_per_epoch to your optimizer)." this means the for each element of the mini batch the neural network calculate the KL divergence between the variational and the prior distribution and then sum it, but it still doesn't say how it is approximated the KL divergence for the single input $\bf{x}$
