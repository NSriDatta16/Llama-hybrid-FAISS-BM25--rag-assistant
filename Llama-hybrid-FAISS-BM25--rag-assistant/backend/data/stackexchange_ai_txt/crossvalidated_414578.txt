[site]: crossvalidated
[post_id]: 414578
[parent_id]: 
[tags]: 
When to prefer PCA over regularization methods in regression?

When dealing with the curse of dimensionality, regularization methods seem to be clear in their intuition. All "regularization" methods can be seen as a "squeezing" of one's variables towards 0 , when there exists too many of them. However, PCA dimensionality reduction is another way to handle the same curse of dimensionality, but it does not seem that PCA possesses any comparable interpretation . Essentially, does a similar intuitive interpretation exist for PCA as for regularization, which makes the former comparable to the latter? Any insights placing both frameworks on the same meta-footing would be appreciated.
