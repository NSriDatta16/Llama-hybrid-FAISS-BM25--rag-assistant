[site]: crossvalidated
[post_id]: 454449
[parent_id]: 454415
[tags]: 
Your question is an outstanding question that no one ever asks and worse yet that no teacher explains when teaching/explaining/promoting standard regression procedures in the presence of autocorrelated data. "I am searching for a pragmatic way to account for the recency of the observations and provide more weight into the most recent ones when building the model. " . In other words how to assess the "believability of the data" often if not always ignored in NN and ML procedures. I can think of three ways to possibly answer your question . I think that discussion #1 is where you are coming from but I include two others for generality and pedagogical reasons. 1) The problem with ordinary regressions that there is an equal weighting of every time period i.e. every row in the data matrix . Take a look at a piece I wrote a number of years ago to help understand the implications entitled "Regression vs Box-Jenkins" http://www.autobox.com/pdfs/regvsbox-old.pdf essentially using the arma structure of the model errors to transform the data matrix to meet the requirements of the standard regression approach. See "shuffling the deck" 2)Additionally to determining how to weigh each row in the data matrix , one might need to weigh differently based upon inherent non-constant error variance suggesting also employing Weighted Least Squares . A scheme to do this by testing the assumption that there is no deterministic change point on model error variance is suggested here http://docplayer.net/12080848-Outliers-level-shifts-and-variance-changes-in-time-series.html 3)Finally if a data point is an anomaly , it needs to be down-weighted by including a dummy variable in the model, This is generally referred to as Intervention Detection . See my back and forth comments (3/2/20) with @whuber for a peek at this . Detect abrupt change in time series
