[site]: crossvalidated
[post_id]: 349331
[parent_id]: 
[tags]: 
multinomial distribution aggregation property

Suppose we have multinomial distribution in which we have 4 categories, and each one is associated with a probability of being selected, say $\theta_i$, $i=1,..,4$. And I know for sure that $\theta_1=0.1, \theta_2=0.2$. Now I want to Bayesain inference the unknown $\theta_3$ (the $\theta_4$ can be deduced since $\sum \theta_i=1$) from evidence, say $n_i$ observstions for each category $i$. The problem is, I see two ways to do this: As the one here : multinomial model with some certain parameters . In other words, discard the evidence of $n_1, n_2$ and rescale the $\theta_3,\theta_4$ as a binomial distribution then do the Bayesian inference only with evidence of $n_3,n_4$. Use marginal distribution of $\theta_3$, i.e. define a new binomial distribution with probabilities $p_3=\theta_3$ and $1-p_3=0.7-\theta_3$. Then do Bayesian inference for $p_3$ with evidence $n_3$ and $(n_1+n_2+n_4)$. I guess these two ways are both correct and will reach the same results for a $E(\theta_3|data)$, am I right? just to confirm... PS, once I built a new binomial distribution, to do the Bayesian, I do not have to use Beta distribution as my prior for $p_3$, right? I can use whatever I want, e.g. a two-point one.. Thanks guys.
