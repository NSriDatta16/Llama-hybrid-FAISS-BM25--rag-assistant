[site]: datascience
[post_id]: 41480
[parent_id]: 41385
[tags]: 
Several questions and thoughts come to mind. What languages are in the corpus? This may impact what services you can leverage. I like the "Sentiment Idea" for languages that are supported natively by the services you mentioned. I would keep the "Language Idea" as the last resort as it is possible that the translation engine may not capture the sentiment of the original language. Mechanical Turk would be a good option if you can limit the number of samples sent for classification. For each language, you could try clustering the passages by, for example, word count into 30 (you pick) clusters and then perform sampling within the clusters to identify candidate passages to send to Mechanical Turk. I have used this technique to try to sample across the vector space more uniformly. Don't dismiss oW_'s comment. You should seriously consider breaking the articles into paragraphs. You can always aggregate the paragraph scores to the article, but it's hard to get one representative score as the text gets longer. HTH
