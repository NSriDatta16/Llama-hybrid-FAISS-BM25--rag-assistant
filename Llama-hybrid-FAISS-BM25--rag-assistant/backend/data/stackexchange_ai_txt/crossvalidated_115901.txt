[site]: crossvalidated
[post_id]: 115901
[parent_id]: 115892
[tags]: 
Which algorithm did you use for training with the two sequences? You can separately train a Hidden Markov Models for each sequence. At each given t , you find the hidden states, and based on the transition probabilities of these states, you can appoint a real-time probability (practically log probability due to underflow ) of belonging to model+ or model- . Please have a look at Rabiner's paper on HMM 's, especially the last two paragraphs on Pg. 261 that talk about training different HMM's for recognizing different words.
