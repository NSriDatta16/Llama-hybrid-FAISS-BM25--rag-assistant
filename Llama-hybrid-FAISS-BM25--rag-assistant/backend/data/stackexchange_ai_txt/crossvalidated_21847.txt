[site]: crossvalidated
[post_id]: 21847
[parent_id]: 
[tags]: 
Convergence of identically distributed normal random variables

I had this example in my machine learning lecture. Let $X_2,\ldots,X_n$ be identically distributed (but not independent) copies of $X_1$ drawn from $\mathcal N(0,1)$. Then $X_n$ converges to $Y = -X_1$ as $n \rightarrow \infty$. There isn't any explanation for why this sequence of random variables converges to $Y$. Convergence in the sense $\lim_{n \rightarrow \infty} F_{X_n}(t)$ where $F_{X_n}$ is the CDF of $X_n$. Can anyone help me out?
