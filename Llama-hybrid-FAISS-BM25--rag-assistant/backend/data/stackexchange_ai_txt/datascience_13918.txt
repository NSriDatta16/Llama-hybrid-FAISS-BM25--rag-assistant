[site]: datascience
[post_id]: 13918
[parent_id]: 13910
[tags]: 
The point of the layer depth and gradual pyramidal reduction is to build up a hierarchy of spatially invariant representations, each more complex than those of the prior levels. For example, at the lowest level, a convolutional may be able to pick out noteworthy arrangements of pixels; at the next level, it can condense these into particular spots, basic shapes, edges, etc.; then at higher levels it can recognize increasingly large and complex objects. I'll borrow an example from Gerod M. Bonhoff's thesis 1 on Hawkins' Hierarchical Temporal Memory (HTM), which is a closely related concept, one that also makes use of receptive regions to build invariant representations. At higher levels, the filtering process allows a convolutional or HTM to assemble individual lines and shapes into objects like "dog's tail" or "dog's head"; at the next stage they can be recognized as a "dog" or perhaps a particular variant, like "German shepherd." This is made possible not only by the stacking of multiple layers, but the divisions of neurons within them into separate receptive regions. The receptive regions mimic actual neuronal "cell assemblies" and cortical columns that learn to fire together in groups; this enables clustering around particular types of objects, while the additional layers allow them to be related together into objects of increasing sophistication. The decrease in spatial dimensions in the example you cited reflects the narrowing of the receptive regions as we move up the pyramid; the third dimension (i.e. depth within a layer, as opposed to the depth of the layers) increases in tandem so that we can provide a wider choice of spatially invariant representations to select from at each stage i.e., each filter in the output volume depth-dimension learns to look at something different. If we simply narrowed the pyramid at each stage along every dimension, eventually we'd be left with just a narrow range of objects to choose from; taken far enough, it might just leave us with a single node at the top reflecting a single yes-no choice between "is this a dog or not?" This more flexible design allows us to choose more combinations of the previous layer's spatially invariant representations. I believe that this also enables a convolutional net to take into account various orientation problems, including translation independence, by adding more cell assemblies/columns to deal with each reorientation of an invariant representation. As this excellent tutorial at github explains, First, the depth of the output volume is a hyperparameter: it corresponds to the number of filters we would like to use, each learning to look for something different in the input. For example, if the first Convolutional Layer takes as input the raw image, then different neurons along the depth dimension may activate in presence of various oriented edged, or blobs of color. We will refer to a set of neurons that are all looking at the same region of the input as a depth column (some people also prefer the term fibre). This type of design is inspired by various biologically plausible structures found in actual organisms, such as the eyes of cats. If what I've said here isn't clear enough to answer your question, I can add a lot of further detail, including more examples, some based on actual organs of that kind. 1 See pp. 26-27, 36 76 Bonhoff, Gerod M., Using Hierarchical Temporal Memory for Detecting Anomalous Network Activity. Thesis delivered March, 2008 to the faculty of the Air Force Institute of Technology at Wright-Patterson Air Force Base, Ohio.
