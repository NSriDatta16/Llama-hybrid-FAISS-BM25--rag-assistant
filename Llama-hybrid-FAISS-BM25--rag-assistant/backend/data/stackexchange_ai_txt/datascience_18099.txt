[site]: datascience
[post_id]: 18099
[parent_id]: 
[tags]: 
Interpretation of 'recall' as a conditional probability P( X=>+ | X=+ )

In the context of performance measures for classification, I have a question about recall and precision. Looking at the definition of recall:- $recall = \frac{T_p}{T_p+F_n}$ When I look at this, it sounds like a $conditional$ probability to me -- probability that a test instance will be classified as positive, given that it is indeed positive:- $ recall = Pr(X\hspace{1mm}is\hspace{1mm}predicted\hspace{1mm}as\hspace{1mm}positive | X=positive ) = \frac{T_p}{T_p+F_n}$ Here I am taking liberty to think (as it goes from the definition of $F_n$ ) that $F_n$ in the denominator is actually count of the test instances which are positive but got mis-classified as negative. In the same light, if I think of precision now, this is how I am thinking of it as a probabilitty that a new test instance actually being positive given that it is predicted as a positive:- $ precision = \frac{T_p}{T_p+F_p} = Pr(X=positive | X\hspace{1mm}is\hspace{1mm}predicted\hspace{1mm}as\hspace{1mm}positive)$ Is this interpretation of precision and recall correct?
