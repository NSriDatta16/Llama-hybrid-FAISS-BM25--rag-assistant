[site]: crossvalidated
[post_id]: 345277
[parent_id]: 
[tags]: 
Use CNN for training time-domain data

I have an EEG dataset which is 64 channel data with 1000 data points. I am using mean and standard deviation to extract the time-domain features. I have a very basic question. Can I use CNN to get good classification results for such time-domain data? I have calculated mean of each channel and subtracted it. I am taking standard deviation of each channel and then dividing each channel by SD. The CNN structure I am using is Conv1D. I know that generally EEG signal's feature extraction is done by taking its frequency features and time-frequency. But I would like to know if some used just the time domain data and did CNN training on such data. It is really important for me to know. I have edited the post to add the code. In this code I am trying to use CNN on 2 channels just to check if it works fine when merging the layers. The output is onehot encoded with 40 classes. from keras.models import Sequential, Model from keras.layers import Dense, Dropout, Flatten, Input, Embedding, concatenate from keras.layers import Conv1D from keras import optimizers inp1 = Input(shape=(1000, 1), dtype='float32', name='c1input') conv1 = Conv1D(128, kernel_size= 512, strides=256, input_shape=(1000, 1), name='audConv_l1')(inp1) conv1 = Flatten(name='audConv_l2')(conv1) conv1 = Dropout(0.3, name='audConv_l3')(conv1) a1 = Dense(256, activation='relu',name='rate_l1')(conv1) a1 = Dropout(0.15, name='rate_l2')(a1) inp2 = Input(shape=(1000, 1), dtype='float32', name='c2input') conv2 = Conv1D(128, kernel_size= 512, strides=256, input_shape=(1000, 1), name='audConv_21')(inp2) conv2 = Flatten(name='audConv_22')(conv2) conv2 = Dropout(0.3, name='audConv_23')(conv2) a2 = Dense(256, activation='relu',name='rate_21')(conv2) a2 = Dropout(0.15, name='rate_22')(a2) AV = concatenate([a1, a2], name='AVRate_l1') decOutput = Dense(40, activation='softmax', name='decOutput') model = Model(inputs=[inp1, inp2],outputs= decOutput) adam = optimizers.adam(lr=0.0001) model.compile(optimizer=adam, loss='mse',loss_weights=0.2, metrics=['accuracy']) print(model.summary()) lb = scipy.io.loadmat('label.mat') label = lb['label'] model.fit([c1,c2],label,batch_size=64, epochs=10, validation_data=None) The code works fine but the accuracy is coming as 1.0000 which seems a little too right. I have made some mistake for sure but I cannot understand it. If someone faced the same problem. please let me know
