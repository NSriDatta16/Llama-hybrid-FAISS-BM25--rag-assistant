[site]: datascience
[post_id]: 112611
[parent_id]: 
[tags]: 
Are feature importances of ensemble methods sensible interpretable?

As mentioned in the question, it is easy to interpret the meaning of features in algorithms like simple decision trees. But in the case of ensemble methods that are known to average/modify features, are these results still sensible interpretable/usable to argument about the feature(s)?
