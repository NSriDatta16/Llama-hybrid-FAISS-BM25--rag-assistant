[site]: datascience
[post_id]: 10011
[parent_id]: 
[tags]: 
Assessing significance / confidence of a crossvalidated performance measure

I have a prediction model $P$ and I use some performance measure $I$ to measure $P$'s accuracy. The distribution of $I$ is unknown (it's a custom metric, which is somehow similar to the precision metric). My validation prediction is as following: Randomly split the data to $k$ stratified folds Fit $k$ models Estimate each model according to $I$ (which results $k$-crossvalidated values of $I$) The final model prediction performance is calculated by the average of $k$-crossvalidated $I$ measures. I would like to perform some significance testing - to be able to say the confidence for the model prediction performance - to what extent I am “sure” in this $I$?
