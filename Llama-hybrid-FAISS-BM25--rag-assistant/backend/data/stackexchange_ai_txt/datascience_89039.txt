[site]: datascience
[post_id]: 89039
[parent_id]: 88919
[tags]: 
It seems very unlikely that centering would hurt , and so I'd suggest just to do it anyway. Theoretically, in a generalized linear model with regularization, no, centering won't change anything. This is because the intercept term can absorb any changes; shifting $x$ by 100 can simply be rewritten: $$ 15 + 0.2\cdot(x-100) = 15 - 0.2\cdot100 + 0.2x = -5 + 0.2x,$$ so that essentially the same model exists for the shifted data with the same coefficient penalty . Of course, that suggests the first nontrivial example where failing to center will hurt performance: if you don't fit an intercept term! However, in trying to test that in sklearn , I have some troubles ( notebook ): scaling with and without centering gives different results in penalized logistic regression, depending on the solver! ( saga gives different results, but lbfgs gives nearly-identical coefficients.) I'm not sure yet if this is some numerical issue (which I have seen before, but with datasets of much more varying scales) or a misunderstanding on my part. Penalized linear regression seems to work fine. Finally, to SVMs with the rbf kernel. My understanding of nonlinear-kernel SVMs is rather limited, but the rbf kernel should be invariant to centering. However, see Data Centering in Feature Space ( pdf ) which posits that centering in the kernel space can be helpful. Whether for theoretical or numerical reasons, both the classification and regression versions in the above-linked notebook show different results after centering.
