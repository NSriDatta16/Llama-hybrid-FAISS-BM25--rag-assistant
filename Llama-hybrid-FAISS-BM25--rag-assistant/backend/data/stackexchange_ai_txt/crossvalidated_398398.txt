[site]: crossvalidated
[post_id]: 398398
[parent_id]: 
[tags]: 
Theoretical results regarding the size of the training set for neural networks

Have you ever seen anything like a theoretical approach for determining the optimal size (or perhaps some bounds for it) of the training set for a neural network? I know that this is a very broad question, since the optimality should be considered with respect to a specific loss function; and there are several kinds of neural networks. Please feel free to consider the specific cases which you know about, if necessary - although I am particularly interested in perceptrons with 1 hidden layer for classification, reducing the cross-entropy loss function.- I would like to find something more rigorous than an empirical comparison of the classification errors over training and validation data for different sizes of the training set.
