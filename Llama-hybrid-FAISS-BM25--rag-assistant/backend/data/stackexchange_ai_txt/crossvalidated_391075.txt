[site]: crossvalidated
[post_id]: 391075
[parent_id]: 391064
[tags]: 
1)Which is better cross validation or ROC? ROC AUC is a metric, just as accuracy, F1-score etc., and shouldn't be confused with cross validation. You can still employ CV and use ROC AUC as your success metric for example. 2) Do you perform ROC on the test set, the training set or the whole dataset? When selecting models you plot ROC curves, report ROC AUC etc. You can also use ROC curve (e.g. AUC) to report the final success of your models. But, test data shouldn't be in your model selection. 3) If it is the training set or test set. Do I perform it using each fold from the cross validation or should I just split the data once? If your success metric is ROC AUC, then you calculate it for each fold and take the average. After model selection, you can finally plot ROC curve, calculate AUC, on the whole training (or test) data based on your choice of analysis.
