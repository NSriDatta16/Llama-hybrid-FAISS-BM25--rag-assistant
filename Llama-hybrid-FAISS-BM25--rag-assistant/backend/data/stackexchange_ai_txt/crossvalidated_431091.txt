[site]: crossvalidated
[post_id]: 431091
[parent_id]: 
[tags]: 
How do we determine marginal Pr(Data) in Bayesian Analysis?

I am trying to learn Bayesian Analysis and I am really confused as to how to calculate the required equations/values. From a very high level standpoint, I understand the concept. We basically use Bayes' Theorem to find the parameter value, θ, given the observed data. But when going into the details, I am having a lot of trouble understanding what's going on. I am using a mix of: John Krushke's Bayesian Analysis book and Morris DeGroot's Probability and Statistics book. So let's start. First, let's assume that the prior distribution is a gamma distribution with parameters ɑ and β. For simplicity sake, lets assume ɑ and β are constants and are given. Let's also assume the observed data we see, D, follows an exponential distribution with parameter θ. θ is random and is the subject of our Bayes analysis. Krushke tries to explain the concept via tables. The table he provides is: The bottom row, are the probabilities of the prior distribution for different values of θj. These marginal probabilities are given as they come from the gamma distribution with parameters ɑ and β. This I understand. Now I get to the first confusing part. What values are in the row headers, or in other words, what "D values" fill up the left most column? Are the "D values" all positive real numbers (the exponential distribution is defined for all D >= 0) and thus be an infinite number of values? Or are the "D values" the observed values that we see in real life, which would be a finite amount and equal to n, the sample size? If the former is true, i.e. an infinite number of values, when do we incorporate the observed n samples into our analysis? In either case, we use the joint probabilities to calculate the marginal Pr(D) by summing up each row. Then we take the joint probability and divide by the marginal to produce Pr(θ | D). If the former is true, it seems like we never use the observed data points. The former method also makes mathematical sense as if we want to double check our work and calculate the marginal Pr(θj)s by adding up the column probabilities, we could. sum(Pr(Di | θ) * Pr(θ)) = Pr(θ) * sum(Pr(Di | θ)) = Pr(θ) * 1 = Pr(θ) If the latter is true, i.e. a finite number of values, then how does it mathematically make sense? Let's take an extreme and say our sample size was n = 1. Thus, we only have one row of joint probabilities. Adding that row up vertically and we don't get back to the marginal Pr(θ). That is, Pr(D | θ) * P(θ) does not equal P(θ). Perhaps my math is wrong. To double check, to calculate Pr(Di | θj) for a specific joint distribution, is it determined by plugging the Di value into the PDF of an exponential distribution with parameter θj. Is this correct? Thanks!
