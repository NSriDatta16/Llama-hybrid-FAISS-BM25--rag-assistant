[site]: crossvalidated
[post_id]: 2306
[parent_id]: 
[tags]: 
Feature selection for "final" model when performing cross-validation in machine learning

I am getting a bit confused about feature selection and machine learning and I was wondering if you could help me out. I have a microarray dataset that is classified into two groups and has 1000s of features. My aim is to get a small number of genes (my features) (10-20) in a signature that I will in theory be able to apply to other datasets to optimally classify those samples. As I do not have that many samples ( Select one sample as the test set On the remaining samples perform feature selection Apply machine learning algorithm to remaining samples using the features selected Test whether the test set is correctly classified Go to 1. If you do this, you might get different genes each time, so how do you get your "final" optimal gene classifier? i.e. what is step 6. What I mean by optimal is the collection of genes that any further studies should use. For example, say I have a cancer/normal dataset and I want to find the top 10 genes that will classify the tumour type according to an SVM. I would like to know the set of genes plus SVM parameters that could be used in further experiments to see if it could be used as a diagnostic test.
