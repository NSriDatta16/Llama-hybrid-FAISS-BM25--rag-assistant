[site]: crossvalidated
[post_id]: 385375
[parent_id]: 
[tags]: 
Reducing Bias from a Random Forest - Feature Importance

I'm currently looking to show which of three variables is more important in classifying something as True or False. Everyone agrees that all three variables are important, but not all agreeing on what is more important. The three variables are correlated and I've created a spearman correlation matrix. I believe that Feature 0 has more significance on determining its classification compared to Feature 2. To test this I was told to create a random forest which I did using python. If I used my own personal opinion to classify each row before running the Random Forest (Ex: if Feature 0 is below "X", then mark that data point as "Busy") then that would be purposely adding bias to my answer. To try to remove any bias from my answer, I decided to randomly assign the value of True or False to whether the data point is "Busy" or not using the following python code. random_busy = np.random.rand(len(test_data)) I ran the Random Forest multiple times (n= 1,000 trees) for the dataset for whether I randomly chose 10%, 25%, 50%, 65%, and 75% of the data points and no matter what random % I chose to test, the answers were all within 0.5% of each other and I've included some of the data from my tests below. Before my analysis using the Random Forest, I expected on average Feature 0 to have the greatest importance, Feature 1 having the next, and Feature 2 having the least. However I was surprised to see Feature 2 being the 2nd most important. My data is collected from three different locations. To investigate further, I ran the Random Forest on each location separately and the data shown in the chart is when the split between Busy/Non-Busy is 50%. These results are interesting. Some locations had Feature 0 being much more important than others and one location had all three being about the same. But when you average those importance its almost exactly the same from when all data point locations were calculated within the same Random Forest. From what has been shown, am I correct to say that on average Feature 0 has greater importance to classification than the other features based on the data? I am concerned about the correctness of my method to remove bias by making my target variable randomly generated. Bonus: I really enjoy creative visuals and I made this image of one of the trees in the random forest. I created it using GraphViz that I discovered from this Towards Data Science article from Will Koehrsen.
