[site]: crossvalidated
[post_id]: 79752
[parent_id]: 79750
[tags]: 
I made a 3d version of John Myles White's nice code he shared here: http://www.johnmyleswhite.com/notebook/2012/06/26/bayesian-nonparametrics-in-r/ The only difference is the extra dimension and I added a normalization step for each dimension. This algorithm is nice because rather than setting the number of clusters beforehand you choose a parameter "lambda" that determines the minimum distance between a point and the center of a cluster. Any points farther than this distance will start new clusters. I see no reason you couldn't simply add additional dimensions as needed although it is somewhat tedious with this code. Once you have assigned a cluster to each data point you can fit lines/whatever to each separately. Modified data generating function: generate.data Modified clustering algorithm: dp.means.3d lambda) { k 0) { mu.x[j] Generate Data and find the clusters: #install.packages("rgl") require(rgl) dat Edit: The Results: So, as you can see it doesn't like that the results are not multivariate normal for larger lambda. Here is the part of the code that determines when to make a new cluster: for (j in 1:k) { distances[j] There may be a better way if we want to make no assumptions about the data at all. Perhaps it should also include a step that attempts to minimize the maximum distance to other points part of the same cluster. > fits Lambda Cluster n Intercept Slope SumSquared RMSE [1,] 1 1 98 0.47108474 0.037932047 0.03386304 0.01858874 [2,] 1 2 32 0.28115152 0.803120715 0.02721487 0.02916273 [3,] 1 3 66 0.01454559 0.523555233 0.06129777 0.03047547 [4,] 1 4 76 0.50312253 -0.004766139 0.02985764 0.01982079 [5,] 1 5 29 0.23240685 0.750050744 0.02459047 0.02911953 [6,] 1 6 19 0.30395055 0.944757052 0.01314973 0.02630762 [7,] 1 7 32 0.71040200 0.446582407 0.04330122 0.03678537 [8,] 1 8 27 0.61745795 0.637197982 0.02369394 0.02962353 [9,] 1 9 21 0.77826596 0.493610959 0.01757857 0.02893224 [10,] 2 1 37 0.24003453 1.101926169 0.03441819 0.03049953 [11,] 2 2 66 0.01454559 0.523555233 0.06129777 0.03047547 [12,] 2 3 174 0.49416121 0.005600235 0.06415743 0.01920211 [13,] 2 4 43 0.22599167 0.919170075 0.04074510 0.03078247 [14,] 2 5 41 0.68403859 0.734703194 0.05907046 0.03795712 [15,] 2 6 39 0.61635785 0.736739137 0.04078044 0.03233655 [16,] 3 1 174 0.49416121 0.005600235 0.06415743 0.01920211 [17,] 3 2 127 0.36147381 -0.130376879 0.94977762 0.08647869 [18,] 3 3 99 0.65870905 0.449620540 1.29255466 0.11426333 [19,] 4 1 174 0.49416121 0.005600235 0.06415743 0.01920211 [20,] 4 2 127 0.36147381 -0.130376879 0.94977762 0.08647869 [21,] 4 3 99 0.65870905 0.449620540 1.29255466 0.11426333 [22,] 5 1 174 0.49416121 0.005600235 0.06415743 0.01920211 [23,] 5 2 127 0.36147381 -0.130376879 0.94977762 0.08647869 [24,] 5 3 99 0.65870905 0.449620540 1.29255466 0.11426333 [25,] 6 1 300 0.27214072 0.247572658 1.96115772 0.08085291 [26,] 6 2 100 0.65807225 0.441094682 1.35260593 0.11630159 DP-means 2d algo: dp.means lambda) { k 0) { mu.x[j] Generate Data: N = 2e2 x = runif(N,0,1) y1 = matrix(nrow=N,ncol=1) y2 = matrix(nrow=N,ncol=1) n1 =0.4 & x =0.4 & x =0.4 & x =0.4 & x =0.4 & x =0.6)) y1[which(x>=0.6)] = 0.5+0.02*rnorm(n3,0,1) y2[which(x>=0.6)] = 0.5+0.02*rnorm(n3,0,1) y = c(y1, y2) x = rep(x,2)+0.02*rnorm(2*N,0,1) dat Find Clusters and fit lines: fits=NULL par(mfrow=c(3,2)) for(lambda in 1:6){ clusters
