[site]: crossvalidated
[post_id]: 339401
[parent_id]: 
[tags]: 
Using posterior in an expectation

I am studying (myself, not in class) the book of Rogers & Girolami, A First Course in Machine Learning. In working through a logistic classifier, I found the equation $$ p(t_{new} = 1| \mathbf{x}_{new}, \mathbf{X}, \mathbf{t}) = E_{p(\mathbf{w}|\mathbf{X,t})} \left\{ \frac{1}{1 + \exp(-\mathbf{w}^T \mathbf{x}_{new})} \right\} $$ So is this the expectation with respect to the posterior... of the probability of a new data point being 1? I do not recognize this expression. Does it have a name? My question: can someone describe this in a more generic form? For example is it equivalent $$ \int p(D=\text{const}|M)\, p(M|D)\, dM $$ where $D$ is "data" and $M$ is "model" ? If so, then the expression $\int p(D=\text{const}|M) dM $ does not integrate to 1 I think, it feels wrong.
