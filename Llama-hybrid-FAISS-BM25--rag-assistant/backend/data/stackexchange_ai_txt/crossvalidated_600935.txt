[site]: crossvalidated
[post_id]: 600935
[parent_id]: 
[tags]: 
R statistics: compare bayesian bootstrap to frequentist bootstrap for statistics: univariate odds ratio for small sample

Greetings to the community, I am seeking assistance in finding a solution to the challenges I am facing. OBJECTIVES: I aim to estimate the univariate odds ratio for a binary exposure in a population. This means that I will classify all subjects into one of four categories based on their exposure status and disease status. In the case of small sample sizes, I want to **compare **the performance of the Bayesian bootstrap and the frequentist bootstrap using a simulation study. In my evaluation, I will consider factors such as bias, the coverage of the confidence interval, and the convergence speed of the two methods. I will use these indicators to determine the relative usefulness of each approach. I may also want to compare the following parameters, if they are relevant: Precision: How close the estimated odds ratio is to the true odds ratio. I can compare the mean squared error or mean absolute error of the two methods. Robustness: How stable the estimated odds ratio is under different conditions. I can compare the variance of the estimates or the interquartile range. Power: How likely the two methods are to detect a true difference in the odds ratio. Computational efficiency: How long it takes each method to complete the estimation. - Sample size: How the performance of the two methods changes as the sample size increases or decreases. Confidence interval width: How wide the confidence intervals produced by the two methods are. Narrower confidence intervals are generally preferred because they provide more precise estimates. Confidence interval coverage: The percentage of the time that the true odds ratio falls within the confidence interval. I can compare the coverage probability of the two methods to see which one produces intervals that cover the true value more frequently. TL;DR: In summary, I am interested in comparing the performance of the Bayesian bootstrap and the frequentist bootstrap for estimating the univariate odds ratio in small sample sizes for binary exposure in population. I may compare several parameters to evaluate the relative usefulness of the two methods, including bias, precision, robustness, power, computational efficiency, sample size, confidence interval width, and confidence interval coverage. Through this simulation study, I hope to determine which method is more suitable for my research goals. My initial plan is: To compare the frequentist bootstrap and the Bayesian bootstrap for estimating the sampling distribution of a univariate odds ratio in a binary exposure-disease study with a small sample size: Simulate the data Create a function to calculate the univariate odds ratio Use the boot function to generate a large number of frequentist bootstraps of the statistic created in step 2. Use the bayesboot function to generate a large number of posterior samples of the univariate odds ratio using a Bayesian bootstrap. Compare the results of the frequentist bootstrap and the Bayesian bootstrap. Problem with this initial plan: When calculating the univariate odds ratio for a small sample, the following results are obtained: 0, Inf, or NaN. Possible reasons found: Division by zero: The odds ratio is defined as the ratio of two odds, and if one of these odds is zero, the ratio will be undefined (division by zero). This occurs if one of the cells in the contingency table has a number equal to zero. This can happen with a small sample or if one of the categories is rare. The odds ratio may be a very large or very small number, depending on the values. If the odds ratio exceeds the range of values that can be represented by a computer, it will be represented by Inf or -Inf. This can occur if one of the odds is extremely large or small compared to the other. Missing data: If data is missing for one of the categories (not our case). In this case, the result will be NaN. Strategie considered to avoid these problems: Maximum likelihood estimation: This technique involves fitting a statistical model to the data and estimating the odds ratio using maximum likelihood estimation. This can be more robust than other techniques, particularly when the sample size is small, as it allows for the incorporation of additional predictors and potential confounders. In R code: # set seed for reproducibility set.seed(3) # generate small sample with binary exposure and disease status n TL;DR 2: I am not sure if my initial code is actually addressing my problem. I am experiencing issues with obtaining 0, Inf, or NaN when calculating the univariate odds ratio for small samples. These issues may occur due to division by zero, extremely large or small odds ratios, or missing data. To address these problems, I am considering using maximum likelihood estimation, imputation, or the use of alternative estimators such as the ratio estimator or the inverse probability weighting estimator. I am also unsure why my frequentist bootstrap is finding 0 bias and 0 std.error. To simulate bootstraps for different distributions of small populations at once, I may consider using simulation techniques such as Monte Carlo simulation or bootstrapping the simulated data. I can also vary the parameters of the simulation, such as the sample size or the underlying distribution, to see how it affects the performance of the two bootstrap methods. I am seeking guidance on how to effectively address these problems and continue my simulation study to compare the Bayesian bootstrap and the frequentist bootstrap for estimating the univariate odds ratio in small sample sizes for binary exposure in population.
