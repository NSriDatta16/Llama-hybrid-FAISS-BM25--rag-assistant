[site]: datascience
[post_id]: 44462
[parent_id]: 44440
[tags]: 
Using federated learning the model training does not require the whole data to be present at a centralized server instead the model training is decentralized such that the model gets trained collectively on individual nodes and then summarizes the changes as a small focused update. Only this update to the model is sent to the cloud, using encrypted communication, where it is immediately averaged with other user updates to improve the shared model. All the training data remains on your device, and no individual updates are stored in the cloud. References- https://ai.googleblog.com/2017/04/federated-learning-collaborative.html PySyft is a library hooked into Pytorch that provides federated learning capabilities. PySyft github repository link- https://github.com/OpenMined/PySyft Demo code for federated learning using PySyft library- https://colab.research.google.com/drive/1F3ALlA3ogfeeVXuwQwVoX4PimzTDJhPy#scrollTo=PTCvX6H9JDCt
