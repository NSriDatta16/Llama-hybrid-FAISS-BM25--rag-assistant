[site]: crossvalidated
[post_id]: 610571
[parent_id]: 572369
[tags]: 
In short The Kullback-Leibler divergence is the expectation value of the log-odds of two distributions $$D_{KL}(A || B) = \textbf{E}_A\left[\log \left(\frac{P_A(x)}{P_B(x)} \right) \right]$$ or for continuous distributions $$D_{KL}(A || B) = \textbf{E}_A\left[\log \left(\frac{f_A(x)}{f_B(x)} \right) \right]$$ When you transform both $A$ and $B$ in the same way with a one-to-one function, then the events in both transformed and non-transformed representations are exchangeable while the log-odds for specific events remain the same, and that is why the divergence remains the same. Intuitive graphical view The transformations used with normalizing flows are invertible and that requires that they are one-to-one functions . This means that volume under the curve of transformed elements remains fixed. For example in the graph below the transformation is the quantile function of the standard normal which transforms the space $[0,1]$ to the line $\mathbb{R}$ . The events $0.18 and $0.45 transform to respectively $-0.915 and $-0.126 . What you see is that the area under the curves relating to these events change width and height, but the total area remains the same. In addition the relative ratio of the height two curves remains the same! The transformation changes the height of the distributions in the same way. The log-odds of events don't change. The computation of the divergence will be an integral expressing a weighted sum/average of the log-odds $\log \left(\frac{f_A(x)}{f_B(x)}\right)$ . For each contribution/weight of probability $f_A(x) dx$ you have an equivalent size weight $g_A(u) du$ with the same log-odds. $$ \begin{array}{} \int_{x \in \mathcal{X}} \log \left(\frac{f_A(x)}{f_B(x)}\right) f_A(x) dx &=& \int_{x \in \mathcal{X}} \text{LO}_X(x) f_A(x) dx \\ &=& \int_{u \in \mathcal{U}} \text{LO}_U(u) f_A(x(u)) \frac{dx(u)}{du} du \\ &=& \int_{u \in \mathcal{U}} \text{LO}_U(u) g_A(u) du &=& \int_{u \in \mathcal{U}} \log \left(\frac{g_A(u)}{g_B(u)}\right) g_A(u) du \\ \end{array}$$ where $x(u)$ is the value of $x$ when we apply the reverse transformation to $u$ . One-to-one An important requirement is that the transformation is one-to-one. This ensures that the transformation of the distribution density in terms of $x$ to the distribution density in terms of $u$ can be written as $$g(u) = f(x(u)) \frac{dx(u)}{du} du $$ If multiple values of $x$ transform to a single $u$ then we would get a sum over all those values of $x$ that transform to $u$ $$g(u) = \sum_{i} f(x_i(u)) \left|\frac{\text{d}x_i(u)}{\text{d}u}\right|$$
