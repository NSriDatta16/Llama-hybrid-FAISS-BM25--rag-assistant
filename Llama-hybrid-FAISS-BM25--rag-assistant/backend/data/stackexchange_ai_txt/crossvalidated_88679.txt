[site]: crossvalidated
[post_id]: 88679
[parent_id]: 88675
[tags]: 
There are goodness of fit tests (many, many), including the Kolmogorov-Smirnov test you mentioned; many goodness of fit test statistics can be seen as a measure of discrepancy between data and some distribution. The most obvious ones to consider first are the empirical-CDF -based tests, of which the Kolmogorov-Smirnov test is the simplest. The Kolmogorov-Smirnov test statistic is the largest distance between the hypothesized cdf and the ECDF of the data (or sometimes a standardized version of it) There are many others based on the ECDF. One example is the Cramer-von Mises test which (at least for the uniform) corresponds to a sum of squares of vertical distances between the two cdfs. Another related measure is the Anderson-Darling statistic, which weights by the inverse of the variance of the ECDF. There are many other kinds of tests. One common one is the the Shapiro-Wilk test, for example. The Shapiro-Wilk (and related tests) can also be treated as a measure of discrepancy between the distribution of the data and some hypothesized distribution (in the case of the Shapiro-Wilk test, that's the normal distribution). The Shapiro-Wilk, however, is invariant to changes in mean and variance. A full coverage of the goodness of fit territory could take a book -- indeed has taken several.
