[site]: crossvalidated
[post_id]: 465399
[parent_id]: 
[tags]: 
How to train Prediction model for longitudinal data, with large number of time points?

Given a longitudinal data, that has date (in month-year format) as one of the independent variables and other independent variables being Gross metric tonnes, Tensile strength(UTS), weight per unit length, Zone of rail track and dependent variable - number of rail failures for rail track, what is the good way for building a prediction model for the data. Date ranges from January-2010 to December-2019 (120 time points). The columns GMT, UTS, Zone, Weight are not time series but rather cross-sectional data. Data looks like - Zone | Time | GMT | UTS | Weight | RF | CR | jan-2010 | >100 | 880 | 52Kg | 90 | NR | feb-2010 | 100 to 200 | 1080 | 60 kg | 110 | NFR | jan-2010 | >100 | 880 | 52 kg | 112 | : I have thought about following ways - 1) Making seperate time series for each combination of independent variables. But this will lead to nearly 400 time series, making it tedious to study all the time series seperately. 2) Using time as regressor variable.If time is considered to be categorical variable and is encoded using integer encoding, then the effects like seasonality and auto-correlation in time series can't be modelled. If time is encoded with one-hot encoding method, then about 120 dummy variables need to be created. 3) Adding lag values to the data and using it as regressor along with time regressor. But, I am not sure is this the correct way as I read it is not good practice. 4) Using Fixed Effect / Random Effect model. It is mostly used in Econometrics and when T(number of time points) is lesser than number of parameters, which is not the case. Which from above mentioned ways is the best ? Is there any better way of doing panel data prediction?
