[site]: datascience
[post_id]: 53289
[parent_id]: 53199
[tags]: 
You are throwing away a lot of valuable data by dropping "duplicates" because these observations are not really duplicates at all; your data appears to be a collection of distinct time series from a variety of different stores. You can still use ARIMA here, but ARIMA is a univariate time series method. Some possible approaches off the top of my head; 1) Aggregate each individual time series/row by date (i.e. take the mean/median) so that you have an overall time series that is now independent of the store number. Depending on what you are trying to do, this might be okay, but you are still losing information here that could be useful. 2) Fit a single ARIMA/automated forecasting method to each individual time series you have in your dataset (so, fit a forecasting method to each individual store) and then use hierarchical time series methods to reconcile the fitted time series to the actual sum of all time series you observed in your dataset. Probably a more accurate method than 1), but more computation required. 3) Leave your dataset as you have shown, but change the date column to a time feature(s), example: 2017-03-15 is now 2017 + 74/365, or 2017-03-15 is now many columns; year = 2017, month = March, day = 15, week = 3, dayofWeek = Monday, or something like that. Now, treat the problem as a supervised learning (regression) problem. Incorporate lagged values of the target variable, or moving averages to (hopefully) capture short term trends. Indicate holidays/significant events on calendars, or promotional sales if you have access. Use store id's as a feature. In effect, you are trying to learn unique patterns specific to each store while also learning "global" patterns over all time series (if they exist). This is a more "machine learning" approach to time series forecasting and it works quite well for datasets that you appear to have; but it requires a lot of feature engineering (in general).
