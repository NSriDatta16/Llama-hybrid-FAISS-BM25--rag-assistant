[site]: datascience
[post_id]: 84751
[parent_id]: 
[tags]: 
Image regression problem

I've tried a number of experiments with machine learning. From trying to use GANs to upscale images to playing with auto-encoders. There is one problem that haunts me and always ends up ruining my experiments. My networks always seem to "learn" to ignore the input and always produce the same image output. This output is often an interesting blend of the input images. It seems that it's learning to cheat the test and produce the same image regardless of the input. Here are some examples: This has happened in both my GAN and Auto-encoder projects. How do I avoid this sort of thing happening?
