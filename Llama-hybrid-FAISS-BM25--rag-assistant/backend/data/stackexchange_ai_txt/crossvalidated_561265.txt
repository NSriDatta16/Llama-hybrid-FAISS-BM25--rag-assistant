[site]: crossvalidated
[post_id]: 561265
[parent_id]: 561236
[tags]: 
Let $time_{i}$ as $y_{i}$ and the $\{\mathbf{x}_i\}_{i=1}^{N}$ as your predictors (stops) where $\mathbf{x}_i$ is equal to the row $i$ of your dataset taking the last columns out and $i$ is the row index. Take a deterministic regression problem where you want to fit: $y=f(x;\mathbf{\Theta})$ , $\mathbf{\Theta}$ as an arbitrary dimensional parameter. Take $\mathbf{\hat\Theta}=argmin_{\mathbf{\Theta}}\displaystyle\sum_{i=1}^{N}L(y_i,f(\mathbf{x}_i;\mathbf{\Theta}))$ Where $L$ is any loss function that the minimum exists. A good idead is to choose the $k$ variables which increases $\displaystyle\sum_{i=1}^{N}L(y_i,f(\mathbf{x}_i;\mathbf{\Theta}))$ the most if we are not using then for example fit the model taking $stop_1$ out and fit the model taking $\mathbf{z}=(stop_2,...,stop_4)$ , and check the value of: $Q(stop_1)=\displaystyle\sum_{i=1}^{N}L(y_i,f(\mathbf{z}_i;\mathbf{\Theta}))-\displaystyle\sum_{i=1}^{N}L(y_i,f(\mathbf{x}_i;\mathbf{\Theta}))$ Now take $\mathbf{s}=(stop_1,...,stop_3)$ and evaluate $Q(stop_2)=\displaystyle\displaystyle\sum_{i=1}^{N}L(y_i,f(\mathbf{s}_i;\mathbf{\Theta}))-\displaystyle\sum_{i=1}^{N}L(y_i,f(\mathbf{x}_i;\mathbf{\Theta}))$ if $Q(stop_1)\geq Q(stop_2)$ so the variable $stop_1$ is more important than $stop_2$ since taking it out has increased the average loss the most. So the $k$ most important variables are: $\mathbf{MT}(k)=max^{(k)}\{Q(stop_1),...,Q(stop_4)\}$ , where this evaluates which the $k$ large values are.
