[site]: datascience
[post_id]: 112998
[parent_id]: 
[tags]: 
How can I build and train mode for Arabic word embedding from scratch using BERT and share the model on hugging face?

my project is (building an Arabic word embedding model). I want to build my own model on hugging face like (aubmindlab/AraBERT model) for Arabic language using Bert for word embedding. How can I start from scratch to collect data and a pre-training model? please, can anyone explain the steps to me?
