[site]: datascience
[post_id]: 14527
[parent_id]: 
[tags]: 
Xgboost predict probabilities

When using the python / sklearn API of xgboost are the probabilities obtained via the predict_proba method "real probabilities" or do I have to use logit:raw and manually calculate the sigmoid function? I wanted to experiment with different cutoff points. Currently using binary:lgistic via the sklearn:XGBClassifier the probabilities returned from the prob_a method rather resemble 2 classes and not a continuous function where changing the cut-off point impacts the final scoring. Is this the right way to obtain probabilities for experimenting with the cutoff value?
