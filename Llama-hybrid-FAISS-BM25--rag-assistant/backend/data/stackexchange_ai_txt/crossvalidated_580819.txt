[site]: crossvalidated
[post_id]: 580819
[parent_id]: 
[tags]: 
Nested sampling: What does "uniform sampling over the prior" mean?

I'm reading up on Nested Sampling in the book "Data Analysis - A Bayesian Tutorial" (Sivia and Skilling, 2006), and I do not understand the following: What I understand: Given a prior $\pi(\mathbf{x})$ and a likelihood $L(\mathbf{x})$ , where $\mathbf{x}\in \mathbb{R}^N$ are the parameters of a model, we want to compute $$Z=\int L(\mathbf{x})\pi(\mathbf{x})d\mathbf{x}.$$ For that, we define the function $$\xi(\lambda)=\int_{L(\mathbf{x})>\lambda}\pi(\mathbf{x})d\mathbf{x}$$ which is the proportion of prior with likelihood greater than $\lambda$ . It is argued that there is one-to-one correspondence between $\xi$ and $\mathbf{x}$ . What I don't understand: Nested sampling is explained as follows: "[...] [Nested sampling] uses a collection of $n$ objects, randomly sampled with respect to the prior $\pi$ , but also subject to an evolving constraint $L(x) > L^∗$ preventing the likelihood from exceeding the current limiting value $L^∗$ . [...] In terms of $\xi$ , the objects are uniformly sampled subject to the constraint $\xi$ $\xi^*$ , where $\xi^*$ corresponds to $L^∗$ ." My question: Why does sampling from $\pi(\mathbf{x})$ correspond to uniform sampling in $\xi\in [0,1]$ ? What is meant by "uniform sampling from $\pi(\mathbf{x})$ "? (How can sampling from a non-uniform distribution be uniform?)
