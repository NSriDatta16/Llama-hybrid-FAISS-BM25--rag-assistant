[site]: crossvalidated
[post_id]: 490165
[parent_id]: 489797
[tags]: 
It's probably a bad idea to use RFECV, as its Recursive Feature Elimination is generally very poor practice , often leading to results that don't generalize well to new data samples. Harrell's class notes provide a useful introduction to strategies for principled reduction of the dimension of the predictor space in the context of regression models, with much applicable to other modeling approaches. Critically, if your interest is in prediction you might be best off with including all predictors in your model provided that you take precautions like penalization (e.g., ridge regression) to avoid overfitting. For prediction, there's little to be gained by throwing away useful information. That said, much of your question would remain if you were using an approach that doesn't involve automated feature selection. I think that you might be making too strong of an analogy between depths of trees and levels in neural networks. The depths of trees in modeling approaches like gradient boosted trees just represent the number of interactions among predictors that are considered. That's no different from allowing interactions among predictors up to that depth in a "1 layer" logistic or survival model. In your case, with what seems to be a single event (redemption) and time-varying covariates, a survival model would seem most appropriate. You are not, however, limited to standard survival regression approaches, as xgboost has some capacity for modeling parametric accelerated failure time models .
