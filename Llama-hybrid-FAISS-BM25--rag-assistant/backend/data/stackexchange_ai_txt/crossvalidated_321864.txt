[site]: crossvalidated
[post_id]: 321864
[parent_id]: 147252
[tags]: 
I think the second method is wrong, both algebraically and conceptually. The third one is absolutely correct, while the first one presents a single mistake in the use of the Cholesky factor you report. To be clearer I try to explain it to you using an example. Say that we come up with a model that induces the following $SVAR$ (structural $VAR$) for $\mathbf{y}_{t} \in \rm I\!R^{n} $ \begin{equation} A\mathbf{y}_{t} = \Gamma \mathbf{y}_{t-1} + \mathbf{v}_{t}, \quad \mathbf{v}_{t} \sim WN(\mathbf{0}, \Sigma), \forall\, t \end{equation} and we want to be able to identify it using the usual reduced form $VAR$ that the data give us \begin{equation} \mathbf{y}_{t} = \Pi \mathbf{y}_{t-1} + \mathbf{u}_{t}, \quad \mathbf{u}_{t} \sim WN(\mathbf{0}, \Omega), \forall\, t \end{equation} Doing simple algebra, it is clear that $A^{-1}\Gamma = \Pi$ and $A^{-1}\mathbf{v}_{t}=\mathbf{u}_{t}$. From the latter, it is also true that $\Omega = A^{-1} \Sigma {A^{-1}}^{T}$. Now, using a Cholesky identification scheme (I suppose you were referring to the one proposed by Sims) requires assuming $\Sigma = I_{n}$ and $A$ lower triangular. Moreover, being $\Omega$ a p.d. matrix, you can always decompose it as $\Omega = GG'$ with $G$ lower triangular. It is easy to see now that $G=A^{-1}$ thanks to the assumption we made. More is actually true: we now have a bijection between our $SVAR$ and the rf $VAR$, indeed premultiplying the latter for the inverse of the Cholesky factor (and not for the Cholesky factor as you said in the first method) \begin{equation} \mathbf{y}_{t} = \Pi \mathbf{y}_{t-1} + \mathbf{u}_{t} \Rightarrow G^{-1}\mathbf{y}_{t} = G^{-1}\Pi \mathbf{y}_{t-1} + G^{-1}\mathbf{u}_{t} \Rightarrow A\mathbf{y}_{t} = \Gamma \mathbf{y}_{t-1} + \mathbf{v}_{t} \end{equation} using the relations described above. Notice now that this method is nothing more than the initial step you have to do to compute $IRFs$. Indeed, what people basically do it is using your third method as the final step to get $IRFs$. The $VMA(\infty)$ representation is the most used one because it simplifies notation and computation a lot, especially in higher order $VARs$. Therefore, assuming $A$ to have eigenvalues smaller than one in absolute value, you can rewrite your rf $VAR$ as \begin{equation} \mathbf{y}_{t}= \Psi(L)\mathbf{u}_{t}= \sum_{i=0}^{\infty}A^{i}\mathbf{u}_{t}= \sum_{i=0}^{\infty}A^{i}G\mathbf{v}_{t}=\Psi^{\star}(L)\mathbf{v}_{t} \end{equation} For what regards your second question, you just have to pay attention to what it is claimed to be structural and what is not. Using my notation, $\mathbf{v}_{t}$ is structural, $\mathbf{u}_{t}$ not. The mapping between the two is always the same just written in different ways \begin{equation} A^{-1}\mathbf{v}_{t}=\mathbf{u}_{t} \Rightarrow G\mathbf{v}_{t}=\mathbf{u}_{t} \Rightarrow \mathbf{v}_{t} = G^{-1}\mathbf{u}_{t} \Rightarrow \mathbf{v}_{t} = A \mathbf{u}_{t} \end{equation} In the initial step you go from reduced form to structural form so you use one direction, in the $VMA$ representation, instead, you go back to the structural model from the reduced form so you need to use the other direction. Everything is perfectly coherent, but I know that it is quite easy to get lost in it if you do not pay too much attention in what you are doing.
