[site]: crossvalidated
[post_id]: 586817
[parent_id]: 586281
[tags]: 
Since this is a machine learning problem, perhaps you can treat the selection of ages as additional hyperparameters and throw a lot of computing power at the problem. Encode each age as a hyperparameter which is either on or off. $i$ is an age. $a_i = 0, 1$ predicted age $= f(faces | a_1, a_2, ..., a_n)$ where the training data available is determined by which $a_i =1$ Fit your machine learning model of choice to the subset of the training data with the available ages. Cycle through all combinations of ages on and off (including all subsets) and determine the performance of the algorithm on the validation data. (Cross validate if you have time). Pick the age combination that has the best performance on the validation set. Evaluate the trained model with the final hyperparameter set on the test data. Since the model with all the ages included will perform the best as you indicated, you will need to "regularize" or penalize your cost function for including additional ages when evaluating performance on the validation set. This will prevent you from picking all the ages, but will also cause you to have another hyperparameter to tune.
