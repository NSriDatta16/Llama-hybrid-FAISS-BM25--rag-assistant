[site]: crossvalidated
[post_id]: 608447
[parent_id]: 607075
[tags]: 
So far I’ve tried comparing the raw values (cm) which are generally non-normally distributed... The raw values don't have to be normally distributed. A strict requirement (typically too strict) is that the residuals between observations and modeled values should be normally distributed. What's important for statistical interpretation of regression coefficients is that the distributions of the coefficient estimates are normally distributed. A normal distribution of error terms is sufficient but not necessary for that. Having no associations between residual distributions and modeled outcome values (homoscedasticity) in a large enough study is often good enough. See this page for more details. Often in biology and biochemistry the magnitudes of residuals tend to increase as a function of modeled outcomes. That can happen if error magnitudes are proportional to observed values instead of constant. A log transformation of the outcome values can sometimes solve that problem. Is there any kind of paired batch effect standardisation across scans, biological samples or comparison to the mean or average values you’d suggest, or any smoothing techniques I could apply to the perimeter (cm) values. Or any kind of way I could say model the likelihood of one perimeter being greater than the other ? A mixed model , in this case with biological sample as a random effect, is one good way to deal with systematic differences among samples that might need "standardization." Random intercepts allow for variation among biological samples in terms of the estimated baseline outcomes (here, at 0 mM sugar). They also can deal with missing data for particular combinations of samples and treatments. That's better than removing all observations from a biological sample just because of contamination in one trial involving it. These considerations seem to solve your problems. I show a start on your data below. You should work this through on your own, make sure that you understand what each step involves, and incorporate your understanding of the subject matter if there's something else that needs to be addressed. There also are more extensive tests of mixed-model quality, for example in the R DHARMa package , than what I describe. Start at modeling I took your data and changed some of the column names to fit better into R data frames. With only 3 treatment levels, it's best to model treatment with a categorical factor. colonyData $Sugar Sugar) colonyData $BioSample BioSample) colonyData $Bacterium Bacterium) I tried a simple mixed model without transforming outcomes. The interaction * allows the response to sugar to differ among bacterial strains. library(lme4) lme1 That plot indicated that the magnitudes of residuals tended to increase with modeled values. Working with log-transformed perimeter values worked better. lme2 When there are multiple levels of categorical predictors then the usual model summary (not shown here) can be difficult to interpret. For a categorical predictor, it displays coefficients for the difference between each of the individual factor levels and the reference level. Thus the apparent "significance" of one level can depend on the choice of the reference level. Use post-modeling tools to estimate the combined significance of all levels of a categorical predictor. The standard R anova() function doesn't handle unbalanced data well . The Anova() function in the R car package is one good alternative. car::Anova(lme2) # Analysis of Deviance Table (Type II Wald chisquare tests) # # Response: log(Perimeter) # Chisq Df Pr(>Chisq) # Sugar 59.9987 2 9.364e-14 # Bacterium 133.7860 4 This indicates that there are differences among levels of Sugar (treatment) and among bacterial strains. The overall Sugar:Bacterium interaction isn't "significant" but that doesn't mean that it's necessarily unimportant. That's illustrated by detailed analysis of the model predictions. The emmeans package can provide reports of detailed model predictions. Its "revparwise" comparison method, in this case, evaluates all 3 differences among Sugar levels for each of your bacterial strains. The type="response" specification lets these differences be expressed in terms of perimeter ratios . That makes sense for a model based on log-transformed perimeter values, as a difference in logs is the log of a corresponding ratio. emm2pairwise The report incorporates an appropriate correction for multiple comparisons within each bacterial strain. No strain showed a "statistically significant" difference at p The above doesn't deal with differences among assay dates. In principle, you could include them as random effects, also.
