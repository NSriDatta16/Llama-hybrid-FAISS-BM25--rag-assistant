[site]: crossvalidated
[post_id]: 508719
[parent_id]: 
[tags]: 
Testing for transformation-errors in different signals

Let's suppose I have two signals, or time series (for this matter). The first time series (let's call it "A"), is a collection of measurements made every 15 minutes. Time Value 08h00 2.6 08h15 2.4 08h30 2.6 08h45 3 09h00 2.5 The time series "B", is a collection of measurements of the same variable, but done every hour. Time Value 08h00 2.5 09h00 2.5 I won't go into specifics here, but assume that there's a rule to transform "A" into the "B" scale by taking the mean of the 4 values associated with every hour. So for example, transforming A would result in: Time Value 08h00 (2.6 + 2.4 + 2.6 + 3) / 4 09h00 2.5 "A", when transformed, is supposed to be approximately equal to "B", which is the "correct" signal. The problem: What if for some technical issue, whatever records the time that goes into "A" is broken, and now the time column is shifted by +- 15 min. If that happens, the transformation will be different, because the values were shifted, right? So how could one go about detecting this time shift? Using tools like cross correlation won't work, because you don't have "B" in the 15-minutes scale.
