[site]: datascience
[post_id]: 26024
[parent_id]: 26017
[tags]: 
It depends of the algorithm you are using. For a linear model (linear / logistic regression, SVM...), you need to create dummy variables meaning features "Sex_M" and "Sex_F" as you noticed. However, if you are using tree-based technics, create an integer typed column with Sex in [0, 1, 2] should be sufficient for these algorithms. Reason is, contrary to linear model, tree-based technics are non-linear and will evaluate all possible splits to partition your observations. However, the way you map your categorical variale into integers can lead to different trees structures. Below is an example. Suppose you want to predict y variable using indexed feature "Sex". On left chart, there is a slight difference between category 2 and categories 0 and 1 because categories are not oriented. It will results into two consecutive splits and should happen late in the tree building. However, on the right chart, the means difference between categories is larger that on left chart. So the split should happen earlier in the tree building. Moreover, you will only need 1 split to make the difference. To conclude, I think simple indexing can be used with tree-based technics. I would also recommend you to sort your categorical features in an orderly way to easy tree learning.
