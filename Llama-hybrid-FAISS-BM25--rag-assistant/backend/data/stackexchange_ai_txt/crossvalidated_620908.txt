[site]: crossvalidated
[post_id]: 620908
[parent_id]: 486912
[tags]: 
In short: it helps to measure both response and predictor variables precisely. This Wikipedia article on regression dilution should help. Measurement error in X 'flattens' the ordinary least squares line (increases the intercept and reduces the slope in your example): Is correction necessary? In statistical inference based on regression coefficients, yes; in predictive modelling applications, correction is neither necessary nor appropriate. I can add that regression dilution can't occur if the intercept is fixed ( e.g. regression through the origin) although I don't have a reference for that. You may then read the Wikipedia article on errors in variables models . However, as noted in Durden's answer, we don't always have repeated measurements of X. When we do have repeated measurements of predictor variables, it might be simpler to average those (being more precise: SE(mean) = SD(mean)/sqrt(n)) and then use OLS (or other common modelling approaches that ignore measurement error in X) rather than use an errors in variables model (which can be unfamiliar to readers). It depends on what the goal of the modelling is.
