[site]: crossvalidated
[post_id]: 332552
[parent_id]: 332526
[tags]: 
Let us make this concrete with an example. Let us say that we want to invest money into a company. We start to observe the value of the stock of that company on a daily basis: we start at day $t=0$ at 1 pm and then we receive (every day at 1 pm) real values $z_0, z_1, z_2, ...$. Let us assume that we want to invest money into the company if its stock value is above 7 dollars (I have no experience in finance, so please forgive me if this example is nonsense but lets stick to it in order to explain what the Kalman filter does). The approach of the kalman filter is that this time series actually originates from a different time series $x_0, x_1, x_2, ...$ (the so-called 'true' state). The idea behind that is that there exists an actual value of the stock $x_t$ and some disturbed variant $z_t$ of it. If we want to base decisions on whether or not we should do some investment we should know what the 'actual' value of the stock is (and not whether or not the 'current' value is high that migh easily change and might only be currently high due to some weird non-measurable short term effects of the market). In the most simple setup the model assumes that the 'true' state $x_t$ (that we can never observe) proceeds over the time as $$x_{t+1} = ax_t + \text{error}$$ i.e. the next state is a linear map of the current state (plus error). Notice that this looks as if this is a quite stupid model as $$x_t \approx a^t x_0 + \text{error}$$ so the value should either diverge to infinity (if $a > 1$) or converge towards $0$ quickly (if $a I.e. these very simple models can already model quite wiggly (and senseful) functions. So this would be the true stock value that is always hidden from us. What we can see is the observed value $z_t$. This is produced from the true state as $$z_t = bx_t + \text{error}$$ Let us assume that $b=1.2$ and the errors are $N(0,1)$-distributed here as well, then we will see a picture like this: I.e. we can only see the red line but the black line is hidden from us. Let us say that every day around 10am in the morning your boss approaches you and asks you: "Well, how is the state of that company? Should we invest money?". So now you need to make a prediction of the true state $x_t$. You look at the graph but as it is only 10am in the morning, you do not have the most recent observed value, i.e. you only have the observed value until yesterday [red line] and your estimations [grey line]: So, based on the recent past (nah, the observed value was low, my past estimations were low, I think the value goes down a little) you make some first prediction of the true state: This is $\hat{x}_t^{-}$. The hat means: its an estimation. The $x_t$ means: it it an estimation of $x_t$, the true state for today. The minus means: you did this prediction before you observed the observeable value $z_t$ for today (this might give you some important information, see below!). You predicted around 6.7 dollars, so the answer would be: no, do not invest money, the value is too low. However, at 1 pm the new observeable value $z_t$ comes in. It is really high. And since you know that $b=1.2$ (which means that the market tends to overestimate the trus value slightly but not by too much) you correct the prediction upwards a little bit: This is the $\hat{x}_t$, the 'a poszteriori', i.e. 'after you got access to the recent observeable value $z_t$'. All of a sudden your prediction changes and you tell your boss that he should invest money into that company. The task of the Kalman filter is to give you these predictions of the true state $\hat{x}_t$ and $\hat{x}^{-}_t$. I.e. it aims to reconstruct the black curve from the red one. The important fact one can prove about it is that with respect to some conditions (i.e. among the linear filters if I recall correctly) it does that as good as it is only possible, i.e. there is no better linear filter than the Kalman filter.
