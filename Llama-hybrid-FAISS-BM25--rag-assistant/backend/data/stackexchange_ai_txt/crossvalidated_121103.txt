[site]: crossvalidated
[post_id]: 121103
[parent_id]: 
[tags]: 
how to determine outliers in sample affected by ascertainment bias

I don't know if this is a really silly question as I'm in no way a statistician and I don't know if this is something that's actually quite rudimentary... Thanks for reading in advance too it got kind of wordy too since I don't have a sample data set. Essentially I have data that is plotted as a linear series that represents random sampling ( I'm essentially trying to determine true outliers from what would be an incorrect call based on ascertainment bias ). I'm plotting along an x-axis, where as x increases, my sample size increases (it's not actually a time-series, but is similar). Each of the data are sampled randomly (think percent heads vs # coin tosses plotted along a time series). I'm basically trying to pull out and record events that appear as an outlier to the trend. I am aware of interquartile ranges and moving averages. I can't use calculations involving interquartile range as some data are more heavily affected by ascertainment bias than others (esp at low sample size). THIS IS KEY: the goal is not for the algorithm to tell me that outliers occur at low sample sizes [as this is obvious], but I want it to specifically call outliers taking ascertainment bias into consideration (ie. a coin tossed twice, both times producing heads is NOT an outlier, even though heads is at 100% and expected average is 50%, yet a coin tossed 10000x and heads is at 80% would potentially be an outlier ). Note I only have one entry per sample size (so I definitely can't do IQR within a single sample size). I can't change this, my coin is flipped 10x only once before I move on to 11x and then 12x etc. I don't see the point in using moving average since, I already know what the presumed intended average is supposed to be (in a coin toss example, I know the average is to approach 50% as sample size increases). Is there a simple algorithm one could use for this? I don't have an actual example dataset yet, but essentially I'm sampling data completely randomly. The easiest applicable example is the coin toss example I have been using. If you can cater an answer to that I can just work on integrating that into my dataset after. Edit: To clarify, I'm tossing a different coin for each data point along the x axis (ie. all of the 10x tosses are with one coin, 11x a different coin, 12x a yet different coin, etc.). The point is to identify coins that are NOT at 50:50 heads vs tails. I know the immediate reaction is to wonder why I don't toss them all the same # of times, but this is something out of my control, that's the current situation I am working with. Also, I'm asking about the "best" method to pull out as many true outliers as statistically possible, I know I can't determine all of them (the coin tossed only once is clearly impossible to determine whether it is a 50:50 coin or not).
