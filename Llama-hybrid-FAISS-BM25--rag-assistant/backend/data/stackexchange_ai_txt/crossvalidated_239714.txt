[site]: crossvalidated
[post_id]: 239714
[parent_id]: 239267
[tags]: 
cross_val_score is a helper function that plugs your X and Y inputs into an estimator (that you specify), trains the model, and looks at the results. I suspect that what's happening here is that cross_val_score isn't calculating results directly on the X and Y that you've provided, but rather it's training the logistic regression and comparing the predicted results to your Y instead. Since your X only has a single feature, the resulting models probably aren't going to be very effective. To get the results you're expecting given those inputs, you'll want to use something like the classification_matrix function, which simply performs precision/recall calculations on whatever data you provide rather than training a model first. Here's what that looks like: import numpy as np from sklearn.metrics import classification_report #Example 1 print ('EXAMPLE 1 RESULTS:') X1 = np.array([[1], [1], [1], [1], [1], [1], [1], [1], [0], [0], [0], [0], [0], [0], [0], [0]]) #The line below was cut off in your example, but I think this is what it was supposed to be y1 = np.array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) print(classification_report(X1, y1)) print("") #Example 2 print ('EXAMPLE 2 RESULTS:') X2 = np.array([[1], [1], [1], [1], [1], [1], [1], [1], [0], [0], [0], [0], [0], [0], [0], [0]]) y2 = np.array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) print(classification_report(X2, y2)) This gives you the recall results you'd expect: EXAMPLE 1 RESULTS: precision recall f1-score support 0 0.80 1.00 0.89 8 1 1.00 0.75 0.86 8 avg / total 0.90 0.88 0.87 16 EXAMPLE 2 RESULTS: precision recall f1-score support 0 0.67 1.00 0.80 8 1 1.00 0.50 0.67 8 avg / total 0.83 0.75 0.73 16
