[site]: crossvalidated
[post_id]: 559247
[parent_id]: 
[tags]: 
Feature Selection and Propensity Score Matching

After reading the section on variable selection in OHDSI for population-level estimation effects, I set out to add additional covariates to my process. As suggested, I began looking at implementing regularized regression (elastic net) for what I eventually realized was basic feature selection. To clarify, the goal of my PSM implementation is to control for confounding effects for the calculation of ATT and eventually ITE. When I've approached this topic before, it seemed unclear (to provide a single example) and ultimately descends into a larger debate about using preprocessing and model evaluation techniques commonly found in prediction tasks verses what I'm trying to do: control for confounding for causal inference . Even Stack suggested I start there But my question is, what strikes the best balance? Does increased PS "accuracy" better control for confounding? More specifically: Should highly correlated features be removed prior to generating the propensity score? Afterall, PSM at its core is a logistic regression. Yet, that step does not appear common If we are or should be performing variable selection, are all methodologies on the table? It would seem that we'd want to use the highest performing method, be it RFE using decision trees or regularized regression. Per the above, does this require inclusion of goodness-of-fit / discrimination metrics for the resulting PS in subsequent reports to "validate" selected features? I can't imagine this being helpful to all but the most esoteric amongst us. If the above are true, shouldn't we also consider more advanced algorithms such as neural nets* for PS specification? This would also alleviate some of the correlation / selection issues from above, but it does not seem to be a popular method. Ultimately, if the resulting population is balanced prognostically does a better PS specification matter? PS matching seems to occupy a gray space as related to its use of regression. I've been content to explain away some of this incongruity as "prediction is not the goal, controlling for confounding is" and put it to bed with the larger "Explain v. predict" conversation. I'm simply trying to identify the most robust process without being superfluous. *Please don't mistake me for someone trying to throw a neural net at a simple regression problem.
