[site]: crossvalidated
[post_id]: 632389
[parent_id]: 
[tags]: 
Implement Nesterov's acceleration for SVM

I am trying to implement Nestrov's acceleration gradient descent for SVM. The objective function I need to minimize is $$\frac{1}{2}\lVert Au-Bv\rVert_2^2$$ with constraints $\sum_{i}u_i=\sum_{j}v_j=1$ and elements of both $u$ and $v$ are non-negative. The matrix $A$ contains observations that have the label +1 and matrix $B$ contains observations that have the label -1. My implementation never converges to the optimal point. How should I correct my code to get the optimal point? # Projected gradient descent with constraints sum x_i=1 and x>=0 # apply Nesterov's sequence to find the optimal point proj_gd_nesterov $A; B B Asize tol) { # Nesterov's method tr 50000) { return(cbind(u, v)) } } return(cbind(u, v)) } optimals $A), lab = 1), data.frame(train=t(train$ B), lab = -1)) plot(predictions $train.1, predictions$ train.2, col = predictions $lab + 2) points(rbind(t(train$ A%*%u), t(train$B%*%v)), col = "red")
