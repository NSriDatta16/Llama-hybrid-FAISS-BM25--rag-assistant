[site]: crossvalidated
[post_id]: 642001
[parent_id]: 638717
[tags]: 
Such a scoring rule cannot exist if you want it to be strictly proper. And if it's not strictly proper, it will be useless for your application. We usually want scoring rules to be (strictly) proper since it implies that predicting the true underlying probability of the event will give the lowest score/loss on average. More precisely, in the binary case the scoring rule $S : [0,1] \times \lbrace 0,1 \rbrace \to \mathbb{R}$ is proper if $$ \mathbb{E}_{Y\sim p} \, S(p, Y) \le \mathbb{E}_{Y\sim p} \, S(q, Y) $$ for all $q, p \in [0,1]$ . It is strictly proper if equality implies $p=q$ . Well-known examples are the Brier score and the log score. The expected score function is the mapping $p \mapsto \mathbb{E}_{Y \sim p} S(p, Y)$ and it gives the minimal achievable expected score for every probability $p \in [0,1]$ . For example, for the log score you mentioned the expect score function is simply $- p \log (p) - (1-p) \log (1-p)$ . Under weak regularity conditions it can be shown that a (strictly) proper scoring rule has a (strictly) convex expected score function. Hence, if you want to have a scoring rule where the expected score function is not dependent on the true $p$ , then it either fails to be proper (so it doesn't reward truthfulness) or it is constant. As mentioned in Dave's answer you can look at calibration instead. Or as recommended by Stephan Kolassa, you can deal with this issue by calculating the forecast skill, which results from comparing to a reference model, see for instance this question . References The mentioned result and some illustrations can be found in Gneiting and Raftery's Strictly Proper Scoring Rules, Prediction, and Estimation
