[site]: crossvalidated
[post_id]: 445307
[parent_id]: 
[tags]: 
Deep Q Learning best practice

I'm new in deep q-learning and I have understood its main concepts and I'm trying to solve problems with DQL. The problem is that I don't know how to initialize some key values (AKA hyperparameters) of the algorithm and the deep q network?! Here's my main questions: What is the best value for discount factor ? If it depends on problem, how can you define it? How can you define the best learning rate ? And about the DQN (Deep Q-Network): Normally how many layers are needed? Again, if it depends on problem, what is the best practice? What initializer function is more proper for weights initialization? Do we have to use mean squared error as loss function ? If it's not, what is alternatives and when to use them? Is it normal if loss value increases all the time? (absolutely I'm talking about q-learning, not other situations. And the reason of this question is that I had a working DQN that it's loss value increased all the time! but the algorithm works pretty well!) And finally, how can you find out how many steps are required for learning in partially observable problems? (problems that we don't have the entire of it's environment) Thanks in advance.
