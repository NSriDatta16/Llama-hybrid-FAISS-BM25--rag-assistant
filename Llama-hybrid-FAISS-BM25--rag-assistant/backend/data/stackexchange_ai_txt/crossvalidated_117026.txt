[site]: crossvalidated
[post_id]: 117026
[parent_id]: 115647
[tags]: 
Data can't be handled like that for a problem of this nature. Instead I would model each word like this. Each different existent word is accounted as a separate variable. (you might look up on efficient ways to represent a sparse dataset like this.) Word Achttien Goed Braaf Eerlijk Bejaard Oud ... | Class --------------------------------------------------------- | Eighteen 1 0 0 0 0 0 Achttien Good 0 0.45 0.25 0.3 0 0 Goed Old 0 0 0 0 0.25 0.75 Oud ... ... Normalizing the Frequency variable like I did would be a good idea to avoid scale problems, $freq_{n,i} = \frac{freq_{n,i}}{\sum{_{i=1}^j} (freq_{n,i})}$. The order variables should also be included, but I would also try some normalization on them, namely by range, like this: $ord_{n,i} = 1 - \frac{ord_{n,i}-1}{max(ord_n) - 1}$. (higher order words are attributed less value). I would then try to apply different machine learning methods, logistic regression, svm's or even neuronal networks (which will likely cost you much more given the problem dimensions). You might also check out multi class classification (one vs all method), you are gonna need it for this problem. Hope this answer point you into the right direction.
