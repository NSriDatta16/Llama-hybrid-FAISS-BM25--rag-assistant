[site]: crossvalidated
[post_id]: 60346
[parent_id]: 
[tags]: 
Adaboosted trees and q-learning

Question: Is there a solid mathematical connection between ADABOOST and Q-learning that can inform "higher performance" machine learning algorithms? Background: Q-learning references: http://www.autonlab.org/tutorials/rl.html http://mnemstudio.org/path-finding-q-learning-tutorial.htm http://www.autonlab.org/tutorials/rl06.pdf (pg 20) which comes from the (beautiful) autonlab tutorials . Adaboost references: http://rob.schapire.net/papers/explaining-adaboost.pdf http://arxiv.org/pdf/1212.1108.pdf http://www.site.uottawa.ca/~stan/csi5387/boost-tut-ppr.pdf https://en.wikipedia.org/wiki/AdaBoost The intuition: The "xgboost" is a great first step in kaggle. Tuning it wins contests. It can be argued that xgboost is a "very high performance" machine learning algorithm. Q-learning was a component of the deep learning topology that beat the Atari games. ( reference ) Q-learning has been called the dumbest of smart learning. It is kludgy and slow. Motivation: Gradient Boosted machines are amazingly fast and are the "winningest" on Kaggle. (Most online tutorials make the learning parameter high, which is very risky) Q-learning, while the "dumbest" or "slowest" learner, because of its use in things like deep learning (AlphaGo etc) makes it one of the most important to improve A clear and technically effective link between the two should allow something between a substantial acceleration in Q-learning and a substantial acceleration in deep-learning. Note to editors : I worked most of this out and am composing an answer.
