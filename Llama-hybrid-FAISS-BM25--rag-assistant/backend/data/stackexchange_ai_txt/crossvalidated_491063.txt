[site]: crossvalidated
[post_id]: 491063
[parent_id]: 
[tags]: 
How to tell how many learnable parameters there are in the neural network?

Given that $x{(i)} \in R^{100}$ . And the fully-connected layer $f(.)$ is $$f(x^{(i)}) = \sigma(Wx^{(i)})$$ where W is a 1000 $\times$ 100 weight matrix and $\sigma(.)$ is a point-wise nonlinearity. I was looking at this question: Number of parameters in an artificial neural network for AIC For this specific examples, there is an input layer, one hidden layer, and one output layer? How can I compute the number of learnable parameters here? The input dimension is $(100 \times 1)$ and the output dimension is $(1000 \times 1)$ I believe. Is the numbber of learning parameters just $(100 \times 1000) + (1000 \times 1) = 101000$ ? Or am i misunderstanding?
