[site]: datascience
[post_id]: 114613
[parent_id]: 114612
[tags]: 
If you obtained only 19 features it's likely because you used fit_transform instead of transform for your instance. It's important to understand what the 'TfidfTransformer' does: In the 'fitting' part, it assigns an index $i$ to every word in the training data vocabulary. 3792 is the size of your vocabulary. Note that it's common to restrict the size by using min_df in order to avoid overfitting. In the 'transforming' part, every document (tweet) is represented as a vector over the full vocabulary, with every word in the document represented by the TFIDF weight at the corresponding index $i$ . In your code the test set is correctly transformed using the previously fitted transformer (i.e. with the training vocabulary). You should do the same for any new document as well, so that they are represented in the same way (there might be out of vocabulary words which are ignored). Note that TDFIDF only provides a representation of the text. In order to train a model and apply it, you also need to use these TFIDF vectors with a classification algorithm, see for example sklearn documentation .
