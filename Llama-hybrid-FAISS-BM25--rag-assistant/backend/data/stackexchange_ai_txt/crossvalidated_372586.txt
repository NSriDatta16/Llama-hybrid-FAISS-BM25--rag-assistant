[site]: crossvalidated
[post_id]: 372586
[parent_id]: 372584
[tags]: 
There are a lot of things that would improve the performance on the minority class. The reason you "have a problem", is that your neural network has "realized" that the majority class is much more common. I.e. if the information you feed in reality tells it nothing about the class, it should predict the majority class to do well in terms of accuracy and the provided loss function (presumably cross-entropy). Even when the data can help you distinguish (to some extent) the two classes, the neural network predicts the majority class more often to the extent that it makes sense with respect to the loss function you optimized. If you don't like what happened you can change the data e.g. by oversampling or undersampling one class (in various ways, e.g. simple oversampling, SMOTE etc.). However, you need to realize that you would likely want to correct for that in the predictions, if you care about well-calibrated predicted probabilities. You could also change your loss function to induce your neural network to realize that you care more than your original loss function implied about whether it gets the minority class wrong.
