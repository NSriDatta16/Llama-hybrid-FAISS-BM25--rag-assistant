[site]: datascience
[post_id]: 40966
[parent_id]: 40729
[tags]: 
If you add a new feature to the perceptron, the perceptron actually gets one more parameter. So in some sense it is not the same model anymore. But lets ignore that. Correlation is the key problem. Assume the new feature is a random number which happens to have positive correlation with the desired output for the training dataset, but negative correlation with the test dataset. Then you would expect this new feature to influence the test error negatively, right? At least I would. But your question was about the training error . In that case I actually don't see a reason why it should be the case. I'd suggest to try it. And anyways, ask the person/organisation, where you found this question. (And post the answer back)
