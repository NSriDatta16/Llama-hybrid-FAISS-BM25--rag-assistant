[site]: crossvalidated
[post_id]: 586258
[parent_id]: 586083
[tags]: 
I would re-express the terminology: \begin{equation} \text{gain}=\frac{1}{2} \left[ \frac{G_L^2}{H_L+\lambda} + \frac{G_R^2}{H_R+\lambda}- \frac{(G_L+G_R)^2}{H_L+H_R+\lambda}\right] \\ \text{pruned gain}=\frac{1}{2} \left[ \frac{G_L^2}{H_L+\lambda} + \frac{G_R^2}{H_R+\lambda}- \frac{(G_L+G_R)^2}{H_L+H_R+\lambda}\right]-\gamma \end{equation} The purpose of $\gamma$ is to determine when the gain from a split is too small to be meaningful. It's one hyper-parameter that can help combat overfitting, or simply to encourage shallower trees. If $\text{gain} , equivalent to $\text{pruned gain} , then the improvement from the split is too small, and the proposed split is discarded.
