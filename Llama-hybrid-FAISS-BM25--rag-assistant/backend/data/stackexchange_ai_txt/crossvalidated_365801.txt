[site]: crossvalidated
[post_id]: 365801
[parent_id]: 
[tags]: 
Why does my kNN model achieve perfect performance on my test set?

I have trained a KNN model using cross validation to minimize a custom loss function. The model clearly overfits the training data, achieving a loss of zero but exhibits variation in 10-fold cross validation, achieving an average loss of -2,501,029.403. Here are what the learning curves looks like: With the observed variation in CV results, I would have expected the loss on the test set to be at least non-zero but it is not - it's zero. To create the train (~5K examples) and test splits (~1K examples) I used stratified sampling on the target. I have verified that data leakage is not at play here so I am left wondering why the classifier achieves perfect performance on the held-out test set. I understand that that the model is suffering from high variance and is overfitting on the training set but why does this persist in the test set when the model has never seen that data? Update (Solved) To take a step back - I have abstracted a model and operations on it into a class. To score the model, it looks like I was using a score function on this class which was written incorrectly: def score(self, X, y, scorer): model_predictions = self.get_model_pipeline().fit(X, y).predict(X) X_transformed = self.pipeline.fit_transform(X) score = scorer(self.model, X_transformed, y) return (score, model_predictions) You can see that the model is fit with X and then the score is calculated using the same X . So this was a coding error on my part.
