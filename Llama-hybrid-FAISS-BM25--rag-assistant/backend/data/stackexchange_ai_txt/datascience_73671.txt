[site]: datascience
[post_id]: 73671
[parent_id]: 
[tags]: 
Result of Reinforcement learning

I've started reading some literature about reinforcement learning and I can't understand what is the result of the application of RL. I'll be more specific: let's have a time series problem in continuous state space, finite numbers of actions, and a linear approximator of the policy function. So I follow an algorithm to find the best policy, that is, in this specific case, the optimal values of the weights of the linear function I've considered. Now my doubt is here: the so-called best policy is the one found in the process of applying the algorithm or I have to take the final optimal values and, for each period, I have to use them to find which action maximizes the action-value function? In other words, the result of RL is a classic function to (re)apply at each time step as if it was a regression? I think the answer to this question is No, but I would appreciate it if someone can confirm this. (to better explain what I meant with "policy found in the process of applying the algorithm" let's consider this stupid consideration: the best policy also include those time steps of exploration)
