[site]: datascience
[post_id]: 115194
[parent_id]: 69143
[tags]: 
Which statistic can show me model predictive power? It totally depends on the specific problem you're trying to solve. For example, either you have imbalanced classes or if making false negative mistakes will cost you more than false positives (not identifying the patient malignant tumor). Therefore, accuracy , precision aka positive predictive value, 'recall aka sensitivity or true positive rate, and etc could either show your model's true power in predicting the classes. Furthermore, in scikit-learn you can explicitly specify which scoring you're looking for. As an example for accuracy`: from sklearn.model_selection import cross_val_score from sklearn.linear_model import LogisticRegression from sklearn.datasets import make_classification # Generate features matrix and target vector X, y = make_classification(n_samples = 10000, n_features = 3, n_informative = 3, n_redundant = 0, n_classes = 2, random_state = 1) # Create logistic regression logit = LogisticRegression() # Cross-validate model using accuracy cross_val_score(logit, X, y, scoring="accuracy") array([ 0.95170966, 0.9580084 , 0.95558223]) More on scoring parameter from scikit-learn documentation. Which statistic can show me whether my model better predict event 1 or event 0 ? The Receiving Operating Characteristic (ROC) curve is a common method for evaluating the quality of a binary classifier. ROC compares the presence of true positives and false positives at every probability threshold. By plotting the ROC curve, we can see how the model performs. In scikit-learn , we can use roc_curve to calculate the true and false positives at each threshold, then plot them. Moreover, you can use predict_proba in logistic regression to see the soft classification. You can access them after fitting the model and they represent predicted probabilities for each observation. Following the example above: features_train, features_test, target_train, target_test = train_test_split( X, y, test_size=0.1, random_state=1) # Create another classifier logit = LogisticRegression() logit.fit(features_train, target_train) # Get predicted probabilities target_probabilities = logit.predict_proba(features_test)[:,1] # Create true and false positive rates false_positive_rate, true_positive_rate, threshold = roc_curve(target_test, target_probabilities) # Plot ROC curve plt.title("Receiver Operating Characteristic") plt.plot(false_positive_rate, true_positive_rate) plt.plot([0, 1], ls="--") plt.ylabel("True Positive Rate") plt.xlabel("False Positive Rate") plt.show()
