[site]: crossvalidated
[post_id]: 386556
[parent_id]: 
[tags]: 
Strategies for predicting 100 binary choices given the previous 100

Edit: this project ultimately resulted in the paper "The unpredictable Buridan's ass: Failure to predict decisions in a trivial decision-making task" . Background As an experimental psychologist, I've long had an interest in binary decision-making tasks. Typically, in such a task, I manipulate a few properties of some hypothetical or real decision, such as the probability of winning a gamble, and ask human subjects which of the two options they'd prefer. Now, however, I'm studying a task in which there is no meaningful difference between the two choices; subjects just make an arbitrary binary choice. The point is to see how well decisions can be predicted in the simplest possible case, as a kind of ceiling (or perhaps floor) for my accuracy in predicting more meaningful decisions. The problem I'm asking each subject to make 200 binary choices. The question is, using the first 100 as training data, how can I predict the latter 100, using simple accuracy (the proportion of predicted choices equal to the observed choice) as my loss function? I'm not expecting you guys to give me a complete answer so much as ideas of what kinds of methods I should read about. For example, I'm vaguely aware that stochastic processes and time series exist and that this problem can be modeled as one, but I'm not sure which of the many related methods would be most applicable. You can see many more details about this study, including my attempts so far, on my website , but here are the most relevant bits: I have only 3 subjects, but collecting more is easy since I'm on Mechanical Turk. Subject tend to choose one of the options about 50% of the time. So, there's lots of room for improvement over a trivial model. I have not only the binary choices but also the response times. While I'm not interested in predicting response times for their own sake, and I don't want to let a predictive model see the response time for a decision it's trying to predict, they might still be useful. I've framed my investigation as a separate predictive problem for each subject, but I'm open to using all 200 trials from some subjects in order to train a higher-level model used to predict the latter 100 trials in other subjects. (In such a case, I'd probably use cross-validation to let each subject get a chance to be in the test set.)
