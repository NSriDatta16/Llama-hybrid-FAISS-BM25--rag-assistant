[site]: datascience
[post_id]: 44411
[parent_id]: 
[tags]: 
How can one encode data of different dimensions into a tensor in Pytorch?

I'm relatively new to Deep Learning. In my Deep Learning class our input was always images or vectors of numbers which fit a nice rectangular format. My question is: if you have data that doesn't fit into nice rectangular shapes, how do you combine them to go through a single feed-forward network? In my case, I am trying to encode all the information about a game for a reinforcement learning task. This will include a grid/matrix of data (similar to a chess board), as well as metadata like time remaining and other information that's not part of the board. The tensor that goes into my network needs to maintain the spatial relationship with the board, but not imply a spatial relationship with the metadata. Tips?
