[site]: datascience
[post_id]: 118874
[parent_id]: 
[tags]: 
Is deep learning high initial validation accuracy a sign of problem?

I have a image classification model with 8400 images of class A and 1800 images of class B. I have used validation_split=0.2 with subsets of training and validation and batch sizes of 64. I'm using a Sequential model with Augmentations and Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout. Since my dataset is not equal I'm calculating the following weights: Weight for class A: 0.5629669156883672 Weight for class B: 4.470338983050848 I'm getting the following outputs: Or in a different try I got these: 105/105 [==============================] - 185s 2s/step - loss: 2.5790 - accuracy: 0.8461 - val_loss: 0.3223 - val_accuracy: 0.8874 Epoch 2/30 105/105 [==============================] - 179s 2s/step - loss: 0.1982 - accuracy: 0.9368 - val_loss: 0.1439 - val_accuracy: 0.9392 Epoch 3/30 105/105 [==============================] - 179s 2s/step - loss: 0.1279 - accuracy: 0.9594 - val_loss: 0.0714 - val_accuracy: 0.9744 Epoch 4/30 105/105 [==============================] - 177s 2s/step - loss: 0.0651 - accuracy: 0.9769 - val_loss: 0.0127 - val_accuracy: 0.9952 Epoch 5/30 105/105 [==============================] - 177s 2s/step - loss: 0.0864 - accuracy: 0.9749 - val_loss: 0.0532 - val_accuracy: 0.9869 Epoch 6/30 105/105 [==============================] - 176s 2s/step - loss: 0.0622 - accuracy: 0.9824 - val_loss: 0.0483 - val_accuracy: 0.9863 Epoch 7/30 105/105 [==============================] - 176s 2s/step - loss: 0.0325 - accuracy: 0.9878 - val_loss: 0.0177 - val_accuracy: 0.9929 Epoch 8/30 105/105 [==============================] - 180s 2s/step - loss: 0.0255 - accuracy: 0.9942 - val_loss: 0.0229 - val_accuracy: 0.9917 Epoch 9/30 105/105 [==============================] - 184s 2s/step - loss: 0.0706 - accuracy: 0.9815 - val_loss: 0.0239 - val_accuracy: 0.9905 Epoch 9: early stopping Can anyone help with these questions? Is it normal that the first validation accuracy in multiple runs starts from maybe 80% in most cases? Sometimes higher than training accuracy. Validation loss is decreasing in each epoch, but the validation accuracy just fluctuates, so I can't say it's improving. I have tried using kernel regularizers for this but it caused very high loss values. What would be an acceptable loss and validation accuracy for such a question and model? Are these signs of some issue or just my dataset is too easy?
