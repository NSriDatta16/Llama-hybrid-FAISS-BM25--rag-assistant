[site]: crossvalidated
[post_id]: 378647
[parent_id]: 
[tags]: 
Getting accurate interpolated probability from logistic regression equation

I have to ascertain what specific rasch item a student needs to attain to have a 70% probability of passing a future criterion test (the tests are correlated, the results below are output from the logistic regression equation). I ran a logistic regression equation on a series of rasch items. Because the rasch items represent discrete ability scores, and the number of items was not very large (15-items per student) I have to interpolate what rasch item would be needed to have a 70% probability of passing a criterion. Below is the output and code I have tried to use to create the probability. intercept = -0.8392 slope = 0.4120 Finding probability of 0.70 given the above intercept/slope: #Eq1 exp((log(0.70) - intercept)/slope) #Output: 3.225788 This output would indicate a rasch score of 3.225788 would represent a probability of 0.70. But when I use that output to assess the probability of 3.225788, it comes out to a probability of 0.62. #Eq2 exp(-0.8392+0.4120*(3.225788)) / (1 + exp(-0.8392 + 0.4120*(3.22578))) #Output: 0.62 I also tried repeating equation 1 by first assigning the log(0.7) to an object (p) in the hopes that this could solve a rounding error that I read about in McElreath's "Statistical Rethinking" but it didn't appear to help. Please do let me know if you need a reproducible dataset. I thought perhaps the intercept/slope would be enough, but can put together more if needed.
