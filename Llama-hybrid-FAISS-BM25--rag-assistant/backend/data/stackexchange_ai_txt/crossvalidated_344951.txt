[site]: crossvalidated
[post_id]: 344951
[parent_id]: 322163
[tags]: 
I am confused why EM doesn't encouter this problem, as fitting GMM with Dirac delta functions is not typically discussed in textbooks. The unboundedness of the likelihood of a Gaussian mixture model is discussed in many textbooks (incl. mine). It is rarely a problem for EM as the corresponding modes are very narrow and hence do not constitute domains of attraction for most starting values of EM (unless one starts with $\mu_1=x_1$, say). the singularity problem occurs for whatever algorithms we use to fit GMMs. But still, MLE is a practical criterion for learning GMMs. The problem only occurs when considering the likelihood function alone. Moment estimators are not facing this difficulty and neither do Bayesian methods, since the vicinity of $\sigma_1$ gets zero prior probability. Here is an illustration from Chopin and Robert (2010) of a posterior sample obtained by nested sampling for the Gaussian mixture $$0.3{\cal N}(0,1)+0.7{\cal N}(\mu,\sigma^2)$$ While some particles are located close to $\sigma=0$, they soon escape this vicinity and concentrate on another mode of the likelihood. Note also that a result by Redner and Walker (1984) demonstrate that there exist consistent EM solutions.
