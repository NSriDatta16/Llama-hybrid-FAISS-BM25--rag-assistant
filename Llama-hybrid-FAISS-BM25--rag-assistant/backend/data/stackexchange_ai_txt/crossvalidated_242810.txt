[site]: crossvalidated
[post_id]: 242810
[parent_id]: 66027
[tags]: 
The two approaches to time series classification There are two ways on how to deal with temporal structured input for classification tasks: Dedicated Time Series Model: The machine learning algorithm incorporates the time series directly. I count the KNN with DTW model in this category. Feature based approach: Here the time series are mapped to another, possibly lower dimensional, representation. This means that the feature extraction algorithm calculates characteristics such as the average or maximal value of the time series. The features are then passed as a feature matrix to a "normal" machine learning such as a neural network, random forest or support vector machine. This approach has the advantage of a better explainability of the results. Further it enables us to use a well developed theory of supervised machine learning. I was also successfully deploying KNN with DTW successfully in the past. However, I was nearly always able to beat its accuracy with a model that uses well designed features. Also, KNN with DTW for binary classifications scales with O(n_t · m_{train} · m_{test}) with n_t being the length of the time series, mtrain and mtest being the number of devices in the train and test set, respectively. This means that the calculations take quite long.. Therefore, I would recommend to pursue a feature based approach. tsfresh calculates a huge number of features The python package tsfresh calculates a huge number of such features from a pandas.DataFrame containing the time series. You can find its documentation at http://tsfresh.readthedocs.io . You can try it to calculate a huge amount of features. Later you can filter the features for their significance and identify promising candidates. Disclaimer: I am one of the authors of tsfresh.
