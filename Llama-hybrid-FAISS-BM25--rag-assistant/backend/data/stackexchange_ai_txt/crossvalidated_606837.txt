[site]: crossvalidated
[post_id]: 606837
[parent_id]: 275328
[tags]: 
The semipartial correlation of a predictor measures the (square root) of the decrease in R² when said predictor is removed from the full model. If, for some reason, you have highly correlated predictors (e.g. independent variables, regressors, features, covariates), the semipartial correlation will often be small. The most extreme example of this would be if the covariance of your predictors isn't full rank. In this case, you'd need to add regularization to fit the least-squares model, which will encourage the fit to distribute weights over redundant predictors. In this case, any single predictor can be removed without reducing the information in your predictors, (or the R² in your model), so the semipartial/part correlation could show zero, even if each predictor is quite informative individually.
