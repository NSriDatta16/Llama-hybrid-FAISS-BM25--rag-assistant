[site]: crossvalidated
[post_id]: 223224
[parent_id]: 
[tags]: 
Is there a way to extract the topics and/or get the SVD matricies after using PCA on a document matrix?

I'm comparing various topic modeling algorithms on a data set and I'm hoping to compare them via looking at the log-likelihood of held out documents. I'm using SKLearn and I can see that PCA allows for a log-likelihood score (it uses the interpretation in this paper ). However, PCA doesn't allow me to easily figure out what the topics are. In contrast, with LSA (via SVD) I can easily extract the topics by looking at the columns of U where $$ A= U\Sigma V^T $$ So I'm wondering if there is a way to either: (1) go back and forth between the two; (2) extract the topics from PCA; or (3) get a log-likelihood of new documents after SVD? I looked for answers here and I saw this: but I'm not able to use it derive an equation to go from the PCA to the SVD or vice-versa. Alternatively, could I just calcuatle the SVD and PCA of the matrix and use the SVD to get the features and PCA to get the log-likelihood (i.e. would they correspond to each other)?
