[site]: crossvalidated
[post_id]: 324672
[parent_id]: 
[tags]: 
How to select the regularization parameter between two losses?

In deep learning, the total loss commonly consists of a task-specific loss and a weight regularized loss: loss = loss_specific + lambda * reg_loss In my case (set lambda=1.0 ), I have the following observations. The loss_specific decreases at a faster speed than the reg_loss , for example: step 1: loss_specific=0.77, reg_loss=1.9033 step 100: loss_specific=0.50, reg_loss=1.8997 step 200: loss_specific=0.30, reg_loss=1.8930 step 300: loss_specific=0.20, reg_loss=1.8920 Then, is this case related to the selection of lambda ? In general, the lambda may be manually selected from {1.0, 0.1, 0.01, 0.001, ...} . Is this the principle to select this parameter? or use the n-fold cross-validation? To my limited knowledge of regularization, the lambda seems to have specific physical meaning in inverse problems, such as image denoising, image restoration or compressed sensing, which may correspond to the noise levels or some others. But I'm not sure.
