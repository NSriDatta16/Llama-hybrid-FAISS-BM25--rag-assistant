[site]: crossvalidated
[post_id]: 420071
[parent_id]: 419714
[tags]: 
Further to the answer from user11852 above - I also recently learned from Kubat's excellent book "An Introduction to Machine Learning" that the scenario described in the question above is called Imbalanced Training Sets. There are two ways in which this can typically handled: Majority-Class Undersampling ("the mechanical approach"). In cases where we are mainly interested to model the phenomena in the under-represented class (e.g. oil spills vs non-oil spills), then we can deliberately under-sample from the over-represented class and this could improve our model depending on our objectives. Oversampling the Minority Class - if the training set is so small that any reduction of the under-represented class is impractical. In this case, rather than removing majority class observations, we add examples of the minority class. According to Kubat's book, this can be done by simply adding copies of the minority class observations, or by creating slightly modified versions of it. I am sure option 2 needs to be approached with care. Details are in the book. I hope this helps someone.
