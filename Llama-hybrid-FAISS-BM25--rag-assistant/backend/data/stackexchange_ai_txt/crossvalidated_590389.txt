[site]: crossvalidated
[post_id]: 590389
[parent_id]: 590385
[tags]: 
Simulating the Data Splits I recreated your data in R and split your data three times: first by 100 rows, then 200 rows, then finally 300 rows. After I plotted them in histograms and arranged them on a grid to compare them: #### Read Data #### df % gather() %>% select(-1) %>% as_tibble() #### Split 1 #### short.1 % slice(100:382) #### Split 2 #### short.2 % slice(200:382) #### Split 3 #### short.3 % slice(300:382) #### Make Histograms #### raw.data $value, bins = 8, title = "Raw Data") short.data1 value, bins = 8, title = "Raw Data -100 Rows") short.data2 $value, bins=8, title = "Raw Data - 200 Rows") short.data3 value, bins=8, title = "Raw Data - 300 Rows") #### Arrange Data into 4 Plot Grid #### ggarrange(raw.data, short.data1, short.data2, short.data3) Plot Interpretation You can see below that removing the rows doesn't automatically fix the problem and is a great way to remove important info about your real distribution. In the last split, you have essentially destroyed a ton of power you would have otherwise had in your design had listwise deletion not been employed: This would be especially damning if you ran some form of inferential test on the data. For example, if you were comparing the means of this group and another with a t-test, the shifting mean and SD here would cause issues of interpretation, and this would vary a lot by what distribution you are working with: #### Mean Values #### mean(tibble $value) # 2.519 mean(short.1$ value) # 2.594 mean(short.2 $value) # 2.654 mean(short.3$ value) # 2.719 #### SD Values #### sd(tibble $value) # .910 sd(short.1$ value) # .925 sd(short.2 $value) # .938 sd(short.3$ value) # .886 Of course if you have defensible reasons for removing these values, feel free to do so, but always remember that you should have a pretty strong case if somebody asks why. There are also alternatives to redistributing data you already mentioned, such as applying a log or square root transformation to skewed data distributions, but these are not miracle solutions and may present their own problems which should be checked as well. One Last Takeaway You have a final thing to consider...if you remove a ton of values from this data, is it truly representative of what it measured? Consider for example a class of students who were going to take a test today. Let's say the teacher decides to remove the first row of students in the class, forces them to take a standardized test, and then runs descriptive stats on the test scores of those people remaining. There are two issues here. First, what were these first row students like? Maybe they sat at the front because they were overachievers or they learned better by being closer to the teacher. This would undoubtedly bias the data and make it less generalizable. Second, do the descriptives truly represent normal classes if a large portion of normal students go missing? I can't imagine the average test score from this example would be reflective of monthly academic achievement. These are important points to consider.
