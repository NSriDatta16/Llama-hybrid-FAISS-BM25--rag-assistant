[site]: crossvalidated
[post_id]: 109157
[parent_id]: 108928
[tags]: 
I suspect the reason for the claim that LDA is more likely to overfit than the SVM is because the SVM incorporates regularisation (i.e. a penalty term) that allows you to control the complexity of the model, and hence avoid over-fitting. However, there are also regularised versions of LDA (the Least-Squares SUpport Vector Machine is equivalent to one form of regularised LDA and uses the same form of regularisation as the SVM). So strictly speaking the claim is probably incorrect. As to non-linear SVMs, as mentioned by Jacques, there are non-linear variants of LDA as well (e.g. Kernel Fisher Discriminant analysis), so for a fair comparison, you would compare SVM and KFD with Gaussian kernels, and in that case I'd say that neither was a-priori more likely to overfit, as both have the same form of regularisation to avoid over-fitting.
