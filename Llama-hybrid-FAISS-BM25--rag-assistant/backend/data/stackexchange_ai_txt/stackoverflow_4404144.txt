[site]: stackoverflow
[post_id]: 4404144
[parent_id]: 4403627
[tags]: 
Judging from your last question, it looks like you could use a shell script instead, and just place it in Automator. In that case, the following Bash script would work: #!/bin/bash mkdir -p ~/Desktop/URLs n=1 while read mp3; do curl "$mp3" > ~/Desktop/URLs/$n.mp3 ((n++)) done The mkdir -p creates the folder (without erroring if it already exists); n=1 sets up your counter for the filenames. Then while read mp3; do loops over every line in the file, reading each one into the variable mp3; curl "$mp3" > ~/Desktop/URLs/$n.mp3 downloads the file at that address and stores it in the desired file. Then ((n++)) increments n by one; ((..)) mark off math mode, and ++ is the self-increment operator. Finally, the tells the while loop to pretend its standard input (what it's checking with read ) is from that file. My guess is that this'll be cleaner than using AppleScript, since AppleScript's strengths mainly run towards interoperating with other applications, which this task isn't about. Edit: While that script works fine from the command line, Automator imposes some sort of restriction which causes it to not finish with large numbers of files. I couldn't find any explanation or a way to circumvent it in my Googling, so I think your best bet is to use AppleScript instead. 1 It's longer, and I think you'll see why I used a bash script before, but here it is: property desktopPath : path to desktop as string try tell application "Finder" to ¬ make folder at (path to desktop) with properties {name:"URLs"} on error number -48 -- The folder already exists end try set n to 1 repeat with urlLine in paragraphs of (read alias (desktopPath & "URLs.txt")) set qURL to quoted form of urlLine if qURL ≠ "''" then set dest to quoted form of ¬ (POSIX path of desktopPath & "URLs/" & n & ".mp3") do shell script "curl " & quoted form of urlLine & " > " & dest set n to n + 1 end if end repeat As you can see, it's bulkier, but it's basically the same. We first set desktopPath to be the path to the desktop (surprise), since we'll be using it a lot. The try - on error block attempts to create the URLs directory, ignoring the error if it already exists. We then initialize our counter, and read every paragraph (that is, line) in URLs.txt (on the desktop). We then quote the URL so we can use it in the shell (where a stray & or ; could have an undesired meaning), and make sure that there's actually a URL there, and not empty quotes. (That can happen, for instance, if the file ends with a newline.) We then use curl to download the file, and increment n . If you think you'll have a lot of files, you might add a say "Done!" line to the end of the script, so you'll know when it's done. You'll notice that I used do shell script and curl to download that a file, rather than calling out to Safari. Whenever I write AppleScripts that need to download a file, I prefer using curl for two reasons. One, I can download the file directly, rather than opening it in Safari and then saving it (which would also reflect itself in ugly AppleScript that I'm not 100% sure how to write); two, you might not have Safari open, either because you have no webpages open (unlikely, at least for me :-)), or because you don't use Safari as a browser. Sure, you do now , but you never know when you might change your mind. 2 I've also seen reference to something called "URL Access Scripting", but I can't tell if that's still supported or not, and I've never used it. Since I can't find any mention of it on Apple's website, I erred on the side of documentation and went with curl instead. 1: One way of doing this is to wrap the whole bash script in a do shell script . That'd work, but it'd be sort of stupid. You could do it if you wanted, though :-) 2: Case in point: I had used Safari since either Jaguar or Panther, and didn't see myself switching—until earlier this semester, when I switched over to Google Chrome in the space of one week.
