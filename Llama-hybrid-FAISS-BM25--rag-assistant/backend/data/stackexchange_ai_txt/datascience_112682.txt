[site]: datascience
[post_id]: 112682
[parent_id]: 112665
[tags]: 
I'm not sure this will be a comprehensive answer but an opinion to give a push to the reasoning. There are only 3 negative cases. I could create a custom cross validation scheme: create a test case with one negative case and the rest 2 of them to put to the train set. Then iterate through the negative cases, giving a chance to everyone to be in the test set. Any test set I would enrich with positive cases keep the ratio of positive/negative cases fixed: 36/3 * 1 = 12 positive observations in each test set. I'm not sure this technic would work in any way but at least this can be a solution for the CV scheme problem. I would definitely be prepared that the problem doesn't have any adequete solution with so poor data. I stress this idea in order to make a reasonable expectation on time, money budget as well as risks of the project. I'm not sure it's reasonable to do so intensive overfitting. You may approximately count how many times you used any specific negative class observation in order to get a feeling of the degree of contamination of your model with overfitting. This is not strict or correct terminology, I just want to share my intuition. Each time you use the negative observation for training or assessment you increase you changes that a good model will fool you eventually. You have high risks with so few examples. You may treat the problem as an anomaly detection problem. Split a observations in train-test set. For example, 10 observations in the test set, 3 of them are negative cases. Train a clustering model then look how it works on the test set. Does it group negative cases in one separate group or not? https://scikit-learn.org/stable/modules/clustering.html Another approach is to add your own knowledge of the world to the problem if this is applicable to your case. For example, imagine we have titanic data, only 39 observations with 3 survivors and 2 columns: Name and Survived. I could suggest that gender is important and create a new column based on my world knowledge. Looks like I'm reinventing the wheel and feature engineering but anyway this may be useful for you. The last point is that when you have so few data use data visualization intensively. Make your own, maybe even hardcoded if-else model, based on the plots where you painting data points by target (color=target). This could be more reliable and less prone to overfitting comparing with CV and complex models.
