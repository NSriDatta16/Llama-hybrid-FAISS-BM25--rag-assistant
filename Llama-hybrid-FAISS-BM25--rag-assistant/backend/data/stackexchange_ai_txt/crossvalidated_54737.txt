[site]: crossvalidated
[post_id]: 54737
[parent_id]: 30604
[tags]: 
I don't know which of the two ways to calculate the variance is to prefer but I can give you a third, practical and useful way to calculate confidence/credible intervals by using Bayesian estimation of Cohen's Kappa. The R and JAGS code below generates MCMC samples from the posterior distribution of the credible values of Kappa given the data. library(rjags) library(coda) library(psych) # Creating some mock data rater1 The plot below shows a density plot of the MCMC samples from the posterior distribution of Kappa. Using the MCMC samples we can now use the median value as an estimate of Kappa and use the 2.5% and 97.5% quantiles as a 95 % confidence/credible interval. summary(mcmc_samples)$quantiles ## 2.5% 25% 50% 75% 97.5% ## 0.01688361 0.26103573 0.38753814 0.50757431 0.70288890 Compare this with the "classical" estimates calculated according to Fleiss, Cohen and Everitt: cohen.kappa(cbind(rater1, rater2), alpha=0.05) ## lower estimate upper ## unweighted kappa 0.041 0.40 0.76 Personally I would prefer the Bayesian confidence interval over the classical confidence interval, especially since I believe the Bayesian confidence interval have better small sample properties. A common concern people tend to have with Bayesian analyses is that you have to specify prior beliefs regarding the distributions of the parameters. Fortunately, in this case, it is easy to construct "objective" priors by simply putting uniform distributions over all the parameters. This should make the outcome of the Bayesian model very similar to a "classical" calculation of the Kappa coefficient. References Sanjib Basu, Mousumi Banerjee and Ananda Sen (2000). Bayesian Inference for Kappa from Single and Multiple Studies. Biometrics , Vol. 56, No. 2 (Jun., 2000), pp. 577-582
