[site]: datascience
[post_id]: 95062
[parent_id]: 95061
[tags]: 
As the answer from 10xAI notes, n in the loss function refers to the number of samples over which you are calculating the loss, meaning that you are basically calculating the average loss for a specific batch of data. Your error is that you are dividing by the number of output neurons, which is incorrect as the number of output neurons/number of classes has no impact on the loss (in the case of MSE). The loss function you are referring to, mean squared loss, is only applicable to regression problems, whereas your example makes use of classes and is therefore a classification problem. In regression problems there is often only one continuous value you're trying to predict (and only one output neuron), there therefore is no need to divide by the number of output neurons. For your example something like the cross-entropy loss would make more sense, and there you are summing the losses over the different classes, but then still divide them by the number of samples to get an average loss for a batch.
