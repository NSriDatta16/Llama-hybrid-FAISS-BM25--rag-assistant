[site]: crossvalidated
[post_id]: 311027
[parent_id]: 
[tags]: 
Does this strategy work or is it considered overfitting?

Imagine I have X_train , y_train and X_test , y_test . I was studying neural networks and so I came up with the following strategy, however I don't know whether it is considered overfitting or not. Create Neural Network number 1, call it NN1. a.) Train NN1 on X_train and y_train . b.) Test NN1 on X_test and y_test . Call the score test_score_1 and the respective predictions test_pred_1 . c.) Just for later reference, evaluate NN1 on training set, calling train_score_1 the score and the respective predictions train_pred_1 . Create a secon Neural Network and call it NN2. a.) Train NN2 with input X_train and train_pred_1 and with output y_train . (Basically the only difference is that there is a new feature. This new feature are the training predictions of NN1). b.) Test NN2 on inputs X_test and test_pred_1 , with output y_test . Keep the score as test_score_2 and the predictions as test_pred_2 . c.) Now evaluate NN2 on the training set, calling train_score_2 the score, and the respective predictions train_pred_2 . My questions Does this make sense (especially if we imagine to repeat this with multiple NN, say NN3, NN4,...)? Is this overfitting? If we compare test_score_1 and test_score_2 , and we have that the second score is better (lower) than the first, does it mean we are not overfitting?
