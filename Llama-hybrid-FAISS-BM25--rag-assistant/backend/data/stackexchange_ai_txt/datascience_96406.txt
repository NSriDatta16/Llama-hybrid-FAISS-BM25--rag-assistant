[site]: datascience
[post_id]: 96406
[parent_id]: 96399
[tags]: 
In the aforementioned image, we can see that even if Resnet-34 has more Convolutional layers, it still has 7-8 times fewer parameters and FLOPs than VGG-19. Clearly, Convolutional layers are not at fault. But fully connected layers are!! In VGG-19 there are 3 big fully connected layers after the backbone. On the other hand, Resnet has a global average pooling layer which dramatically reduces the size of output (H and W dimensions) from the backbone. And following it there is only one fully connected layer. The global average pooling trick saves a lot of parameters and hence the absence of this layer in VGG results in a very big output from the backbone. And as a result, VGG needs wider fully connected layers, and adding more such layers again adds up lots of parameters.
