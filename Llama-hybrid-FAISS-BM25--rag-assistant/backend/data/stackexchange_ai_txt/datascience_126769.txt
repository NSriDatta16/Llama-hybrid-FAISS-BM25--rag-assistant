[site]: datascience
[post_id]: 126769
[parent_id]: 126768
[tags]: 
Feature selection and hyper-parameter tuning have different purposes. If you consider the entire workflow of data to the ML model and what the model is doing you can get to some intuition what to do first. The model will learn some patterns that are in your data, and the hyper-parameter will slightly dictate what the patterns that will be learned are, especially in a random forest. So, the hyper-parameter tuning will depend on the features that you have. The act of feature selection will be before the model training, the feature selection results will have a direct change on the hyper-parameters of the model itself. So, in theory you should do feature selection before hyper-parameter tuning as there may be patterns that you do not want your model to learn which can be removed. Or redundencies within the data can be removed so the hyper-parameter tuning could be faster.
