[site]: crossvalidated
[post_id]: 446748
[parent_id]: 
[tags]: 
Different scales of input features for stacking ensembles?

I have two models to predict future stock market behavior based on historical data: ARIMA time series model lstm model (including data from various other sources) ARIMA tries to model the daily diffs in stock market ('removed trend of time series'), while LSTM predicts the absolute value. To combine both predictions I use an xgboost model. Is it necessary to normalize the input features of xgb to either diffs or absolute value? Is this irrelevant since xgb runs a regression model at every leaf - or is scaling necessary?
