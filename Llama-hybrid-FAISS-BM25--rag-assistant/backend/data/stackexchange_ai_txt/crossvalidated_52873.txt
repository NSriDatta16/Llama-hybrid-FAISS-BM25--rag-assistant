[site]: crossvalidated
[post_id]: 52873
[parent_id]: 
[tags]: 
Homework: Bayesian Data Analysis: Priors on both binomial parameters

The following is a problem from Bayesian Data Analysis 2nd ed , p. 97. Andrew Gelman has not included its solution in the guide on his website and it has been driving me crazy all day. Literally all day. For some data $y$, modeled as a binomial distribution with population $N$ and probability $\theta$ parameters, both of which are unknown. The problem sets up the question with this information: (1) Setting a prior on $N$ is difficult, as it only takes on positive natural numbers, so it is treated as $\Pr(N|\mu) = Poisson(\mu)$, where $\mu$ is unknown. (2) To define the prior on $(N, \theta)$, we have $\lambda=\mu\theta$. (The logic here is that it may be easier to formulate a prior considering the unconditional expectation of the observations, rather than the mean of the unobserved $N$.) (3) A potential noninformative prior is $p(\lambda, \theta) \varpropto 1/\lambda$. The part of the problem that I am hung up on is how to transform the variables and determine $p(N, \theta)$. The approach that I have attempted is to write $p(N,\theta|\lambda)p(\lambda, \theta)$, and eliminate the unwanted $\lambda$ via integration, that is $p(N,\theta)=\int_0^\infty C\mu^N/(exp(\mu)\lambda N!)d\lambda$, and substituting out $\mu$ with the relation $\mu=\lambda/\theta$. This approach reduces to $p(N,\theta)=C/(N+1)$, where $C$ is the constant of proportionality introduced from (3). This result concerns me, because it implies that the joint probability of some values of $\theta$ and $N$ only depends on $N$, and not on $\theta$. Furthermore, some vague bells are ringing from my quite decrepit multivariable calculus, attempting to remind me about Jacobians and coordinate transformations, but I am uncertain that this integration approach is even appropriate. I appreciate your help and insight.
