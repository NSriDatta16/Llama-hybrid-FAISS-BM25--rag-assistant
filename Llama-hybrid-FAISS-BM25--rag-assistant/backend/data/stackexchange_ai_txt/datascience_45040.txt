[site]: datascience
[post_id]: 45040
[parent_id]: 31572
[tags]: 
More concretely, say for instance, you train a GAN on MNIST to teach it to draw realistic digits. Say, the generator learns to draw a perfect 9 and always draws it independently of noise. Then, the discriminator will quickly learn to discard all 9s, genuine or fake: better be off on 1/10 of the real set (1/20 of the full set) resulting in 5% total error, than guessing (50% proba) over the fake nines (the entire fake set, 1/2 of the full set) resulting in 25% total error. So, the generator will have to learn to draw something else, perhaps it will try all 5s or something, but it will have to snap out of this pattern: only by matching the distribution of the real set (generate 1/10 of each digit) will it prevent the discriminator to quickly and effectively discard all its productions. I had a (very) simple implementation, and, effectively, it started by always drawing the same digit independently of the noise, and then, it quickly snapped out of this pattern and started drawing multiple digits. In the end, it drew approx 1/10 of each :)
