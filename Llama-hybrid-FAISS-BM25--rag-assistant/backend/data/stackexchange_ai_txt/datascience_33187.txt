[site]: datascience
[post_id]: 33187
[parent_id]: 33170
[tags]: 
I feel you are mixing few things: 1:20 is not exactly a class imbalanced data. Classification algorithms work well with this ration also. If you still feel so, you can oversample your positive class or undersample negative class. AUROC generally to compare different models. Like one from logistic and other from Xgboost.( It also ensures robustness of models), Generally AUROC is not used for model accuracy/ getting cut-off values. Logloss/ misclassification rate/ F1 score/ MCC any of these can be used based on your requirement of classification. If you are predicted cancer , then you might not want to miss any patient and might be Ok to false positive, then focus should be on recall. f1 gives balance of precision and recall. Log loss is used (Log Loss heavily penaltises classifiers that are confident about an incorrect classification) when you don't want to have false positive. These links might help. https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/ https://www.r-bloggers.com/making-sense-of-logarithmic-loss/ https://towardsdatascience.com/evaluation-metrics-for-classification-409568938a7d
