[site]: crossvalidated
[post_id]: 344844
[parent_id]: 18891
[tags]: 
To recap in short, Bagging and Boosting are normally used inside one algorithm, while Stacking is usually used to summarize several results from different algorithms. Bagging : Bootstrap subsets of features and samples to get several predictions and average(or other ways) the results, for example, Random Forest , which eliminate variance and does not have overfitting issue. Boosting : The difference from Bagging is that later model is trying to learn the error made by previous one, for example GBM and XGBoost , which eliminate the variance but have overfitting issue. Stacking : Normally used in competitions, when one uses multiple algorithms to train on the same data set and average(max, min or other combinations) the result in order to get a higher accuracy of prediction.
