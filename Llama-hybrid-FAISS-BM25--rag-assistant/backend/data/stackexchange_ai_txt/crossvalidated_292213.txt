[site]: crossvalidated
[post_id]: 292213
[parent_id]: 292206
[tags]: 
Question 1. This is totally doable, and ANOVAs and t-tests are one way that you could go about comparing groups on their scores. Typically, this would involve you calculating some average or sum score for each individual to represent their standing on a given factor. Given that you have already run a CFA on all the factors, however, this approach would miss several opportunities for more rigorous analyses. The t-testing/ANOVA approach above makes two particularly relevant assumptions: When you calculate a sum or average score, you assume that each item within a given factor is equally important for the individual's factor score--that all items are equally representative of the factor You assume that the underlying factor(s) you are comparing are the same between groups--not that they are at the same level, but that you are effectively comparing apples to apples, so to speak. If you look at the results of the CFA you already ran, it is likely that you can already rule out the tenability of the first assumption: different factor loading values across items imply that some items are stronger indicators of the factor than others (you could perform a statistical test to evaluate this assumption formally, though this is often not done). The second assumption is one that you can--and in my opinion should--formally test, especially given that you already have the CFA analysis in hand: this is how you evaluate measurement invariance between groups (see Vandenberg & Lance, 2000; Little, 2013, or Beaujean, 2014 for accessible overviews). If you were to compare latent means of groups and find significant differences, it might be because the groups actually have different average levels of the latent factor, but it also might be because you're inadvertently assessing different factors in each group--this is what testing measurement invariance allows you to rule out. If all checks out (and to validly compare latent means, you want to establish configural, weak/metric, and strong/intercept invariance) you can actually do a latent version of an ANOVA (or a t-test) in SEM, which is a more accurate and statistically powerful test of those comparisons. This process, in its totality, is too complicated to walk through step-by-step here, but you might find my answer on this thread to be helpful (and I refer to the same resources that I've cited here, among others). But in a nutshell, you are in a position to perform more rigorous analyses that make fewer assumptions about the measurement of your factors, so you might want to take advantage of what a latent variable modelling approach could afford for testing your questions. Question 2 It sounds like your second question could mean testing two different things. With the first, you could compare mean levels of all factors across participants (or within a group) if you consider factor a within-subject factor, which would require you to model the dependency between indicators of your factors within-person. Otherwise the process could proceed in the same way that I've described above: establishing measurement invariance, and then proceeding with a latent ANOVA (or t-test). As for the second possibility--"compare how the 4 factors vary within any individual..." will likely be much more complicated. I'm not terrifically knowledgable about these kinds of analyses, but if this is what you want, it sounds like you may want to look into the literature on fitting intensive individual longitudinal models. References Beaujean, A. A. (2014). Latent variable modeling using R: A step-by-step guide . New York, NY: Routledge. Little, T. D. (2013). Longitudinal structural equation modeling . New York, NY: Guilford Press. Vandenberg, R. J., & Lance, C. E. (2000). A review and synthesis of the measurement invariance literature: Suggestions, practices, and recommendations for organizational researchers. Organizational Research Methods , 3 , 4-70.
