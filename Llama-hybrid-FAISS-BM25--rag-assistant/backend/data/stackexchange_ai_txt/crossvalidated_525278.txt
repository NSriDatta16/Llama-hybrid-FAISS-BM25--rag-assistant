[site]: crossvalidated
[post_id]: 525278
[parent_id]: 486637
[tags]: 
This is not exactly answering the question, but to me the major problem here is the obsession with finding "the best" and focusing on interpreting what "the best" is (and what may be a "correct" criterion to decide what is the best), while disregarding the simple truth that the data, particularly because of the small sample size, cannot distinguish between these proposals, whatever criterion was used to pick one over the other. Both approaches generate fits that are compatible with the data (quite certainly more can be had), and deciding between them is a pretty meaningless task. On top of that, it isn't even clear what "best" means - what is the aim? Prediction (a two step model can hardly be used for reasonable prediction as another step may come at any point in the future)? Giving some knee-jerk pseudocausal interpretation (in which case one should probably discourage branding any of these as "best")? Dependence over time issues and more detailed knowledge on what causes whatever "trend" is seen will be important here, and I'm not sure whether anything ignoring this can lead to any insight. In fact, regarding model selection, different methods come with different implicit definitions of what "best" actually means, and as there are different aims of model selection, this is legitimate. We should get off the idea that whatever method can make the data on their own tell us what "the best fit" is, without any input from our side such as a proper formalisation of what we want to achieve. Actually for the given data I'd think it better to just show the points without any eye-guiding descriptive fit - I suspect they do more harm than helping. Alternatively one should show more than one.
