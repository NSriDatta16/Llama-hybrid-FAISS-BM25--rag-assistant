[site]: crossvalidated
[post_id]: 352465
[parent_id]: 
[tags]: 
Is there any point in splitting data before applying hypothesis testing?

If I have understood correctly, Null Hypothesis Significance Testing(NHST) is a device, which eats data and a conservative model, and outputs a 'probability' that the data was generated by the hypothesized process. In that, H0 can produce any p-value, while alternative hypotheses are probable only at low p-values. That's why we are encouraged to repeat an experiment in which we think we have found an effect. Now for the question. Suppose we have 100 measurements and no way to obtain more. Let approach A be to input the in a NHST device and compare the p-value with the significance level. Let approach B be to split the sample into two parts (with random selection, bootstrapping or other algorithm), use two NHST devices and check if their results are in agreement. Of course power will be reduced. Are approaches A and B somehow equivalent or is one of them 'better' - always or in certain situations?
