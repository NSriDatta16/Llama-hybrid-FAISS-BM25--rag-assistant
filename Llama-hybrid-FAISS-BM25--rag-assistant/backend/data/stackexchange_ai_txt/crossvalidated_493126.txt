[site]: crossvalidated
[post_id]: 493126
[parent_id]: 
[tags]: 
Clustering mixed data based on text anlysis: Sparse Matrix problem

Good day/evening/any other time of the day! As part of my project, I've been trying to analyse (and hopefully make some konwlegable conclusions about) the movie database dataset, which consists of the following columns: Movie ID - ID of a particular movie, for example: 123123 Subtitles - list of the subtitles available for said movie from the set of [English, French, Spanish, Chinese] Maturity - maturity level assigned to the movie from the set [3+, 7+, 12+, 18+] Genres - list of genres, for example [comedy, romantic, european] Runtime - length of a movie in minutes, for example: 90 Directors - list of directors responsible for movie, for example [Anna Migotto, Sabina Fedeli] Actors - List of major actors, which played in said movie, for example [Helen Mirren, Gen Ghergatti] Synopsis - short description of the movie plot, for example: ' John Keating, a progressive English teacher, tries to encourage his students to break free from the norm, go against the status quo and live life unapologetically. ' My aim is to be able to cluster the movies based on those parameters, to both: " Reduce dimensionality " - a bit wrongly stated, but the idea is to be able to use said clusters to reduce the number of data used in further analysis of vierwership. As of now dataset even after some work containes more than 200 unique genres, not to mention actors and/or directors. Analyse and discover relations in the dataset - the underlying knowledge about the relations between the movies and how the recommendations could be made based on this is strongly needed. As of now I was able to do the following: Clear the data : there are no NA's in the dataset (or at least no in any "major" area, like genres and/or synopsis). Also synopsis has been both lowerecased, lemmatized and cleared from any stopwords and is now a list of tokens. Moreover, subtitles and genres have been made lowercased. In case of genres, they have been uniformized (ie, there are no commedy and comedies as separate genres). Get descriptive statistics - word counts, unique word counts, most common words, number of genres etc. Make TF-IDF analysis with PCA/K-means - that one is a bit tricky. My first attempt to the affromentioned problem was to make a "soup" from the above data, after some "grouping" (in that case, making groups for runtime, like sklearn , pandas and to some extent sparse matrices. What is my aim: Make a proper analysis - in that regard I have read about Gowers distance, as well as PAM ( https://www.kaggle.com/flubber/clustering-gower-distance-pam , https://medium.com/analytics-vidhya/gowers-distance-899f9c4bd553 , https://www.cs.umb.edu/cs738/pam1.pdf ) algorithm and both of them seem to fit my problem perfectly, not to mention that they shouldn't put everything to "one bag" as it happens now. What is my problem : Lack of knowledge in "how-to" field, especially when it comes to dealing with sparse matrices. Most of the movies have no more than 6 genres out of 200, not to mention how sparse the matrix representation of director/actors relations with movies could be, and pandas won't cut it. But if my knowledge is correct I need to create humngous matrix which contains this data in some format. And to top it off I need to join this matrix with TF-IDF'ized synopsis (using TfidfVectorizer from sklearn), which as of now is a total abstract to me. The Question: How to make sparse matrix from my data, and how to join two sparse matrices (one mentioned above and one created by TF-IDF vectorizer) without the loss of the information of what each column means? I will appreciate any help, starting with links to some sklearn tutorials, and ending with criticism of my approach. If any data/code example is needed I will post it on short notice. Thank you in advance!
