[site]: datascience
[post_id]: 82725
[parent_id]: 67040
[tags]: 
You might be interested in this paper and python implementation of various other feature selection for clustering tools and papers: http://www.public.asu.edu/~huanliu/papers/pakdd00clu.pdf https://github.com/danilkolikov/fsfc An excerpt sumarizing the approach: We address the problem of selecting a subset of important features for clus tering for the whole data and not just for clusters unlike in [1,2] This helps in knowing the important features before doing clustering and the clustering task becomes more ecient and focused as only the important features can be used Finding the important original features for the whole data helps in under standing the data better unlike principal components Data storage collection and processing tasks become more efficient and noise is reduced as the data is pruned Our approach is a 2-step method we first rank and then select a subset of important features. Ranking of features is done according to their importance on clustering An entropy based ranking measure is introduced We then select a subset of features using a criterion function for clustering that is invariant with respect to different numbers of features A novel scalable method based on random sampling is introduced for large data commonly found in data mining applications Additionally, this paper gives an overview of different methods available: https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.295.8115&rep=rep1&type=pdf
