[site]: crossvalidated
[post_id]: 596536
[parent_id]: 424803
[tags]: 
Kaggle has a really good answer to this. In short: Use k-1: For algorithms that look at ALL the features at the same time, for example linear regression, support vector machines, neural networks, clustering . BUT, this is true for training, for feature selection see below Use k: For algorithm that look only at a subset of features, for example tree algorithms (random forest) Feature selection = k Finally, if you are planning to do feature selection, you will also need the entire set of binary variables (k) to let the machine learning model select which ones have the most predictive power.
