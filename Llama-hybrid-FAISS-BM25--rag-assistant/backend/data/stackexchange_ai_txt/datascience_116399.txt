[site]: datascience
[post_id]: 116399
[parent_id]: 116384
[tags]: 
It seems more like a weighting issue because the labeled data would be more differentiated than the other ones. To avoid this problem, a solution is to generate labels automatically using Bert or any other NLP classification algorithm. It should be quite simple: you have to write some summaries that would be the objective of a summary model. The labels would be the input features. https://towardsdatascience.com/extractive-summarization-using-bert-966e912f4142 The summary model would be able to generate the missing paragraphs. Once you have even labels, the results with Roberta would be much better.
