[site]: datascience
[post_id]: 117681
[parent_id]: 
[tags]: 
Transformer model with same input fed into the encoder and decoder

I need a model to process an list (Tx = T but variable across samples) of vectors to get another list of vecotrs (Ty = Tx = T so also different across different samples). I would like to use the transformer so that in the mapping the neighboring information could be extracted; the CNN method also works but for my application the transformer handles the variable length input better. Specifically, it's a model to predict the system response given the control signal. For example, for a system I can have a control input of X and the system will quickly stablize with a response of Y. Both X and Y are vectors; they might be of different lengths, but given a X we are guaranteed to have a Y. I am thinking about instead of feeding the decoder the shifted output, I can feed the input directly. In this case, the encoder encodes information in the K, Q, V matrices and the decoder can use it appropriately. Does this make sense?
