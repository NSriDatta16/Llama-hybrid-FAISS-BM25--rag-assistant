[site]: crossvalidated
[post_id]: 616051
[parent_id]: 
[tags]: 
MCMC on a clump of data and then updated with single data point

Suppose I wish to fit a fairly complicated hierarchical model, say twelve nodes in a Bayesian network. I have an initial set of data I can fit to this model, this data has an ordering, meaning data that is more recent is more important. I then have a second set of data which I must predict but I can predict sequentially. Initially I wanted to use belief propagation but I'm winding up with intractable integrals. So now my plan is to use MCMC on all the initial data (since I imagine that even in belief propagation the order of the updates would not affect the posterior) and then update my priors at each new data point running an MCMC simulation on each. Does this sound like a reasonable thing to do? Is there any fundamental difference in how this would perform if I used belief propagation instead (If the integrals could be done)?
