[site]: crossvalidated
[post_id]: 449476
[parent_id]: 449468
[tags]: 
The support vectors are just the points that are used to define your hyperplane. These are basically the points of the two classes that are the closest together, and that are used to define the margins. From a visual perspective, your support vectors are the points that sit on your margins. Indeed, if you add training data to an SVM, any point that does not change the support vectors (i.e. any new point for which $y_i(w^Tx_i+b)>1$ ) does not entail any computation or additional training. New training is needed only if you add a training point for which $y_i(w^Tx_i+b) , and in that case the margins will need to be recomputed and this new point will become most likely a support vector, so $y_i(w^Tx_i+b)=1$ (here $w$ and $b$ are changed) I really suggest listening to this MIT lecture, I really found it eye-opening at the time: MIT SVM lecture
