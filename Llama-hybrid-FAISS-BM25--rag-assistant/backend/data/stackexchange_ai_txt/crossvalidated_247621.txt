[site]: crossvalidated
[post_id]: 247621
[parent_id]: 247551
[tags]: 
I have not heard of any method that gives a confidence interval for a neural network prediction. Despite a lack of formal methodology, it seems like it might be feasible to construct one. I have never attempted this due to the compute power that would be needed and I make no claims on this working for certain, but one method that might work for a tiny neural net (or with blazing fast GPU power it could work for moderate sized nets) would be to resample the training set and build many similar networks (say 10,000 times) with the same parameters and initial settings, and build confidence intervals based on the predictions for each of your bootstrapped net. For example, in the 10,000 networks trained as discussed above, one might get 2.0 (after rounding the neural net regression predictions) 9,000 of those times, so you would predict 2.0 with a 90% CI. You could then build an array of CIs for each prediction made and choose the mode to report as the primary CI.
