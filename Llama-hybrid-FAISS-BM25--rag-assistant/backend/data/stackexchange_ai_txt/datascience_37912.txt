[site]: datascience
[post_id]: 37912
[parent_id]: 37827
[tags]: 
There are a few approaches to this off the top of my head: 1. Trivial case You can first check if the images are identical by simply using numpy's functions, either numpy.array_equal(A, B) or numpy.allclose(A, B) . Where A and B are the two images stored as numpy arrays. To check if images are semantically similar, you need to compute a similarity measure . First let me back up a bit... 2. Latent representations In deep learning, we can represent data such as images, voice recordings, text etc. in a latent space . This is an unobservable ("not real") space, where we attempt to capture the essence of the data. For words, we might create a 300-dimensional vector that should encode the information that a given word represents. For images, we could use an Auto Encoder . The idea is to distill the images into a matrix that really contains all the core information in an image. This would be your latent representation of an image, and this is where you compare images. Here is a schematic of such a model, where the "bottleneck" in the middle is where you have achieved a dense representation of an input image: The model is trained end to end, by trying to expand that condensed middle section into an array the same as the input array (input image). You create the latent, encoded representation of two images to be compared by running them just through the first half of your trained model (i.e. just the encoder), and calculate a distance or similarity metric between the resulting arrays. You could perhaps use a simple cosine-similarity (of flattened arrays) or even just the $L_2$ norm (sum of squared differences). Hopefully that all provides enough guidance and keywords for you to find relevant tutorials :-)
