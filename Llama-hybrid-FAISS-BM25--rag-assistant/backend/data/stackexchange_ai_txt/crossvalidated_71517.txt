[site]: crossvalidated
[post_id]: 71517
[parent_id]: 
[tags]: 
Evaluating a logistic regression model

I've been working on a logistic model and I'm having some difficulties evaluating the results. My model is a binomial logit. My explanatory variables are: a categorical variable with 15 levels, a dichotomous variable, and 2 continuous variables. My N is large >8000. I am trying to model the decision of firms to invest. The dependent variable is investment (yes/no), the 15 level variables are different obstacles for investments reported by managers. The rest of the variables are controls for sales, credits and used capacity. Below are my results, using the rms package in R. Model Likelihood Discrimination Rank Discrim. Ratio Test Indexes Indexes Obs 8035 LR chi2 399.83 R2 0.067 C 0.632 1 5306 d.f. 17 g 0.544 Dxy 0.264 2 2729 Pr(> chi2) |Z|) Intercept -0.9501 0.1141 -8.33 Basically I want to assess the regression in two ways, a) how well the model fits the data and b) how well the model predicts the outcome. To assess goodness of fit (a), I think deviance tests based on chi-squared are not appropriate in this case because the number of unique covariates approximates N, so we cannot assume a X2 distribution. Is this interpretation correct? I can see the covariates using the epiR package. require(epiR) logit.cp I have also read that the Hosmer-Lemeshow GoF test is outdated, as it divides the data by 10 in order to run the test, which is rather arbitrary. Instead I use the le Cessie–van Houwelingen–Copas–Hosmer test, implemented in the rms package. I not sure exactly how this test is performed, I have not read the papers about it yet. In any case, the results are: Sum of squared errors Expected value|H0 SD Z P 1711.6449914 1712.2031888 0.5670868 -0.9843245 0.3249560 P is large, so there isn't sufficient evidence to say that my model doesn't fit. Great! However.... When checking the predictive capacity of the model (b), I draw a ROC curve and find that the AUC is 0.6320586 . That doesn’t look very good. So, to sum up my questions: Are the tests I run appropriate to check my model? What other test could I consider? Do you find the model useful at all, or would you dismiss it based on the relatively poor ROC analysis results?
