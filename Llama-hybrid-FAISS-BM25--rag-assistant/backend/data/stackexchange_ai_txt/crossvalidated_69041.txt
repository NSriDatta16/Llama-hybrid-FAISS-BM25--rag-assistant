[site]: crossvalidated
[post_id]: 69041
[parent_id]: 69019
[tags]: 
Initial communality of a variable is its variance, the diagonal element of the analysed matrix. In your case it is 1 for both variables because you analysed a correlation matrix (which is equivalent to saying that you analysed standardized variables). Extraction communality of the variable, also called "extraction sum of squared loadings", is the portion of its variance that is explained, accounted for, by the extracted principal components. You extracted one principal component of two possible (you have just two variables). The extracted PC1 has variance ("eigenvalue", in PCA's jargon) 1.092 which is ("explains") 1.092/(1+1) = 54.579% of the total (summative) variance of the two variables. The remaining component PC2 - which you chose to leave out (not to "extract") - has variance .908 which would eat up the remainder of the total variance: so, (1.092+.908) = (1+1) = 100%. See also this for "explained variance", and this for exhaustive "chew over" of PCA. There isn't anything difficult about PCA, for a layman or a monk to get it equally. PCA itself does not answer questions about "statistical significance", because it is an exploratory and data transformation technique dealing with the data at hand without reference to some "population". P.S. As @NickCox truly points out in a comment, there is little practical use for PCA when the variables are almost uncorrelated. PCA is meant to be a dimensional-reduction technique for several (usually >2) correlated variables. In your (your friend's) case the two variables are only weakly correlated - which can be seen from the fact that PC1 and PC2 have almost equal variance. (One can easily compute from your output what was that correlation, and believe me it was not far from 0.) So in your example of very weak-correlated variables extracting only one of the two possible components would be a too gross simplification of real data. However, as an educational or theoretical case your example is all right.
