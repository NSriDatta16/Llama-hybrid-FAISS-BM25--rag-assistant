[site]: crossvalidated
[post_id]: 463619
[parent_id]: 
[tags]: 
Weighted importance sampling (WIS) and Importance sampling (IS)

I am currently reading papers about off-policy evaluation (or counterfactual evaluation) of reinforcement learning policies, including ones about the doubly robust estimator. As in this paper https://arxiv.org/abs/1802.03493 , many papers say that "the weighted importance sampling (WIS) estimator or its stepwise (per-reward) version is considered more practical than the importance sampling (IS) estimator or its stepwise (per-reward) version, especially where being biased is not crucial". I understand this is true because WIS has lower variance than IS even though it is biased (it is consistent though). But what I am curious about is exactly when or where the bias of WIS becomes crucial so that the IS estimator can perform better than WIS. Could you give any example scenario when this happens?
