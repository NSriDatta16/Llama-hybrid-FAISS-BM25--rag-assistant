[site]: crossvalidated
[post_id]: 351589
[parent_id]: 
[tags]: 
Regularized parameter overfitting the data (example)

Possible duplicate of (Why) do overfitted models tend to have large coefficients? How does regularization reduce overfitting? In the Coursera's machine learning course by Andrew Ng, I came across the following example. $C = 1/ \lambda$ i.e. the inverse of the actual regularization parameter. The L2 regularization cost expression is $ R = \Sigma_{i=1}^{n} \theta_i^2 $ For black classifier, we have $h_{\theta}(x) = -3 + x_1\;\; \theta = [-3, 1, 0] \;\; R = 10$ For magenta classifier, we have $h_{\theta}(x) = -1 + x_1 - x_2 \;\; \theta = [-1, 1, -1] \; \; R = 3$ Regularization cost for magenta classifier is low but still it seems to overfit the data and vice-versa for the black classifier. What's going on? L2 regularization tend to make the coefficients close to zero. But how does that helps in reducing overfitting? The intuition what I think of is that not much weight is given to a particular feature. But isn't it sometimes necessary to focus on one feature (like in the above example $x_1$)?
