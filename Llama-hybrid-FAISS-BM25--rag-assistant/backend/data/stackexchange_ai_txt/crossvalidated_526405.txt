[site]: crossvalidated
[post_id]: 526405
[parent_id]: 
[tags]: 
Why was the reconstructed error for one-hidden layer autoencoder much smaller than that of stacked autoencoders?

I want to compare the reconstructed error from the traind autoencoder and stacked autoencoder within MATLAB. The following is my MATLAB code using the 'Deep Learning' toolbox: load trainData.mat % 7-by-13457 %% Input data = load([path, 'inPut\', 'trainData.mat']); X = data.trainData; %% Stacked autoencoder hiddensz1 = 32; autoenc1 = trainAutoencoder(X, hiddensz1,'MaxEpochs',400); feature1 = encode(autoenc1, X); hiddensz2 = 16; autoenc2 = trainAutoencoder(feature1, hiddensz2,'MaxEpochs',400); feature2 = encode(autoenc2, feature1); %% decode1 XReconstructed1 = predict(autoenc1, X); %% decode2 rfeature1 = decode(autoenc2, feature2); XReconstructed2 = decode(autoenc1, rfeature1); % reconstructed input mseError1 = mse(X - XReconstructed1); mseError2 = mse(X - XReconstructed2); The first error term ' $mseError1$ ' was 5.9781, while the second error term ' $mseError2$ ' is 190.0479. Why is the error from the shallow network is much smaller than that of stacked autoencoder? Could someone give some explanations on this?
