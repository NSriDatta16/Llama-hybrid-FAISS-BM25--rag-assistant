[site]: datascience
[post_id]: 61581
[parent_id]: 
[tags]: 
Training data requirements for NLP models

Are there general guidelines for how much data is required for natural language processing (NLP) classification models? I understand this may depend on the text quality, text length, how accurate the labels are, the event frequencies, the chosen algorithm, etc. Are there any general frameworks I can use to estimate how much data I would need? I'm going through an exercise of having data owners labeling their text data and i'd like to give them a recommendation for how much data they should label other than more is better.
