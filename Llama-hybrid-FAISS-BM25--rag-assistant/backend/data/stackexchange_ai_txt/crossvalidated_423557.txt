[site]: crossvalidated
[post_id]: 423557
[parent_id]: 423548
[tags]: 
Consider the situation in which you have $n = 20$ observations of a binary (2-coutcome) process. Often the two possible outcomes on each trial are called Success and Failure. Frequentist confidence interval. Suppose you observe $x = 15$ successes in the $n = 20$ trials. View the number $X$ of Successes as a random variable $X \sim \mathsf{Binom}(n=20; p),$ where the success probability $p$ is an unknown constant. The Wald 95% frequentist confidence interval is based on $\hat p = 15/20 = 0.75,$ an estimate of $p.$ Using a normal approximation, this CI is of the form $\hat p \pm 1.96\sqrt{\hat p(1-\hat p)/n}$ or $(0.560, 0.940).$ [The somewhat improved Agresti-Coull style of 95% CI is $(0.526, 0.890).]$ A common interpretation is that the procedure that produces such an interval will produce lower and upper confidence limits that include the true value of $p$ in 95% of instances over the long run. [The advantage of the Agresti-Coull interval is that the long run proportion of such inclusions is nearer to 95% than for the Wald interval.] Bayesian credible interval. The Bayesian approach begins by treating $p$ as a random variable. Prior to seeing data, if we have no experience with the kind binomial experiment being conducted or no personal opinion as to the distribution of $p,$ we may choose the 'flat' or 'noninformative' uniform distribution, saying $p \sim \mathsf{Unif}(0, 1) \equiv \mathsf{Beta}(1,1).$ Then, given 15 successes in 20 binomial trials, we find the posterior distribution of $p$ as the product of the prior distribution and the binomial likelihood function. $$f(p|x) \propto p^{1-1}(1-p)^{1-1} \times p^{15}(1-p)^{5} \propto p^{16-1}(1-p)^{6-1},$$ where the symbol $\propto$ (read 'proportional to') indicates that we are omitting 'norming' constant factors of the distributions, which do not contain $p.$ Without the norming factor, a density function or PMF is called the 'kernel' of the distribution. Here we recognize that the kernel of the posterior distribution is that of the distribution $\mathsf{Beta}(16, 6).$ Then a 95% Bayesian posterior interval or credible interval is found by cutting 2.5% from each tail of the posterior distribution. Here is the result from R: $(0.528,0.887).$ [For information about beta distributions, see Wikipedia .] qbeta(c(.025,.975), 16, 6) [1] 0.5283402 0.8871906 If we believed the prior to be reasonable and believe that the 20-trial binomial experiment was fairly conducted, then logically we must expect the Bayesian interval estimate to give useful information about the experiment at hand---with no reference to a hypothetical long-run future. Notice that this Bayesian credible interval is numerically similar to the Agresti-Coull confidence interval. However, as you point out, the interpretations of the two types of interval estimates (frequentist and Bayesian) are not the same. Informative prior. Before we saw the data, if we had reason to believe that $p \approx 2/3,$ then we might have chosen the distribution $\mathsf{Beta}(8,4)$ as the prior distribution. [This distribution has mean 2/3, standard deviation about 0.35, and puts about 95% of its probability in the interval $(0.39, 0.89).$ ] qbeta(c(.025,.975), 8,4) [1] 0.3902574 0.8907366 In that case, multiplying the prior by the likelihood gives the posterior kernel of $\mathsf{Beta}(23,7),$ so that the 95% Bayesian credible interval is $(0.603, 0.897).$ The posterior distribution is a melding of the information in the prior and the likelihood, which are in rough agreement, so the resulting Bayesian interval estimate is shorter than than the interval from the flat prior. qbeta(c(.025,.975), 23,7) [1] 0.6027531 0.8970164 Notes: (1) The beta prior and binomial likelihood function are 'conjugate`, that is, mathematically compatible in a way that allows us to find the posterior distribution without computation. Sometimes, there does not seem to be a prior distribution that is conjugate with the likelihood. Then it may be necessary to use numerical integration to find the posterior distribution. (2) A Bayesian credible interval from an noninformative prior essentially depends on the likelihood function. Also, much of frequentist inference depends of the likelihood function. Thus is is not a surprise that a Bayesian credible interval from a flat prior may be numerically similar to a frequentist confidence interval based on the same likelihood.
