[site]: datascience
[post_id]: 115705
[parent_id]: 
[tags]: 
Strange behaviour around zero for predicted distributions from a deep learning regression model

Can somebody help make sense of these very odd distributions that I obtained from my trained deep learning regression model? The model was trained with either MAE or MSE loss, which is what the labels in the figure are referring to. The problem is the very odd 'jump' around zero... Has anyone encountered predicted distributions like this before and know how to might come about? Due to the fact that this is a regression task on continuous-valued data, zero should carry no special meaning... The MSE and MAE loss functions also do not cause any issues around zero. As such it is really not apparent to me why the model exhibits this behaviour around zero i.e. why the distribution over (-5, 0) is so different from the distribution over (0, 5) and why this latter part is modelled so much better. Any help to make sense of this is greatly appreciated! Technical Infos: the model in question is a multi-layered convolutional-LSTM network (ConvLSTM). the model has an encoder-decoder network structure and serves as a spatio-temporal wind speed regressor, taking in 12 frames of (continuous-valued) wind speed data over a grid, encoding the data, and then forecasting the subsequent 12 frames. the model is trained and validated on a large wind speed dataset over a 64x64 grid. This wind speed data is highly skewed and was therefore transformed with a Yeo-Johnson power transform to make the data more Gaussian, and subsequently standardised locally using zero-mean, unit-variance normalisation, before training. the model was trained using mini-batch gradient descent with a batch-size of 16 and used the adaptive moment estimation (Adam) as optimiser. The loss function was either the standard MAE or MSE loss as computed from the 12 predicted frames and the 12 target frames. what you see in the figure is the distribution of the model's predictions on the test set.
