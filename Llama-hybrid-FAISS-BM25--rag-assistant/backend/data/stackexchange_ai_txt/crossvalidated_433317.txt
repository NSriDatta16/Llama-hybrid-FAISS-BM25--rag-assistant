[site]: crossvalidated
[post_id]: 433317
[parent_id]: 
[tags]: 
How does size of test set affect the performance of a model?

My data set is divided into 80:20 train and test...i have performed 10 fold cross validation on the train data set and tested the 20 % dataset on each iteration ( so that test set is not touched while training). Finally i get the scores by averaging the scores in each iterations. I have been trying classification on a 7 class problem. I have 8 sensors generated data .(8features). Every time the classifier misclassifies the last class. I tried decreasing the number of classes, still the last class got miss classified. Finally i started decreasing the test set to increase training. I got good results (90%accuracy) when test data is only 8%. Is any other way around or any scope of increasing scores without further decreasing the size of the test set? following are the snipets of the two cases
