[site]: crossvalidated
[post_id]: 143811
[parent_id]: 143810
[tags]: 
This is not really an answer but too long for a comment, so I post this anyway. I was able to get a coefficient greater than 1 two times out of a hundred for a sample size of 100 (using "R"): N=100 # number of trials T=100 # length of time series coef=c() for(i in 1:N){ set.seed(i) x=rnorm(T) # generate T realizations of a standard normal variable y=cumsum(x) # cumulative sum of x produces a random walk y lm1=lm(y[-1]~y[-T]) # regress y on its own first lag, with intercept coef[i]=as.numeric(lm1$coef[1]) } length(which(coef Realizations 84 and 95 have coefficient above 1, so it is not always below one. However, the tendency is clearly to have a downward-biased estimate. The questions remains, why ? Edit: the above regressions included an intercept term which does not seem to belong in the model. Once the intercept is removed, I get many more estimates above 1 (3158 out of 10000) -- but still it is clearly below 50% of all the cases: N=10000 # number of trials T=100 # length of time series coef=c() for(i in 1:N){ set.seed(i) x=rnorm(T) # generate T realizations of a standard normal variable y=cumsum(x) # cumulative sum of x produces a random walk y lm1=lm(y[-1]~-1+y[-T]) # regress y on its own first lag, without intercept coef[i]=as.numeric(lm1$coef[1]) } length(which(coef
