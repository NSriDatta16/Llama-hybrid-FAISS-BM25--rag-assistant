[site]: datascience
[post_id]: 6386
[parent_id]: 253
[tags]: 
Data Science is a field demanding a variety of skills. Having knowledge of Hadoop is one of them. The main tasks of a Data Scientist include: Gathering data from different resources. Cleaning and pre-processing the data. Studying statistical properties of the data. Using Machine Learning techniques to do forecasting and derive insights from the data. Communicating the results to decision makers in an easy to understand way. Out of the above points knowledge of Hadoop is useful for points 1,2 and 3, but you also need to have strong mathematical/statistical background and strong knowledge of Computational techniques to work in data science field. Also Hadoop is not the only framework that is being used in Data Science. Big Data ecosystem has a range of frameworks, each specific to a particular use case. This article gives introductory material regarding major Big Data frameworks that could be used in Data Science: http://www.codophile.com/big-data-frameworks-every-programmer-should-know/
