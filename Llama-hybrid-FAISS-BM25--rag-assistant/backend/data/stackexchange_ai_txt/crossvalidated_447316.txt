[site]: crossvalidated
[post_id]: 447316
[parent_id]: 446748
[tags]: 
Any Gradient Boosting Machine (GBM) method that uses trees as its base-learners is not strongly affected by the scale of the input data. In that sense, using differences or absolute values is somewhat unimportant. If the GBM algorithm uses linear models as its base-learner (i.e. in XGBoost we use gblinear as a base-learner) then the scale of the input features is relevant. This said, it would be potentially beneficial for debugging and/or comparing feature importances to use data that are on the same scale, the comparison would be more straightforward. On a somewhat parallel note, I would suggest being very careful how time-series cross-validation is performed especially when ensembling models. It is important not to have future information "leak" in our training procedure.
