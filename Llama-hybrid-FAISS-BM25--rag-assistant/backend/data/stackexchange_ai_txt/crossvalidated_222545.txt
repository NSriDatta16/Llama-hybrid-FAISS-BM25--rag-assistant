[site]: crossvalidated
[post_id]: 222545
[parent_id]: 222455
[tags]: 
It is not possible to test whether a model is 'true' or not with hypothesis testing. Null hypothesis here would be better verbalized as "There is no difference between the fit of model 1 and model 2." If it is not rejected, it is reasonable to choose the simpler model. How AIC works is explained by Agresti in the following section in the book. I'd suggest you read it as it seems to answer the questions you have posed above. Briefly, yes, the smaller the AIC the better. There wouldn't be a straight forward answer for your last question that would hold in general. However, it seems that you are considering to come to a conclusion about this matter and carry that information on. I think it may be useful to direct your attention to a cautionary note about variable selection in general: Hypothesis testing as is applied commonly does not take the model selection procedure into account. Hence if you build several models and pick one of them based on a certain criteria and move on to use hypothesis testing without taking this procedure into account, you are more likely to err than not. Chatfield (1995) outlines some of the problems as follows (there is a good deal of detail in the paper, would be useful as well): Least squares theory does not apply when the same data are formulated and fit a model. After model selection, estimates of the model parameters and residual variance are likely to be biased. The analyst typically thinks that the fit is better than it really is and diagnostic checks rarely reject the best fitting model. Prediction intervals are generally too narrow.
