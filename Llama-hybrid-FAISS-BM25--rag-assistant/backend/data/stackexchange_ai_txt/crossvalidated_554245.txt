[site]: crossvalidated
[post_id]: 554245
[parent_id]: 553987
[tags]: 
No, you don't want to label every slice. It sounds like you're doing classification , as opposed to segmentation . For a segmentation problem, you need to classify every pixel , which can be laborious work. I'll assume you're doing classification. Get started with 2D images While you're learning, it might be to treat this as a 2D problem. Choose the most representative slice for each patient and train a 'regular' 2D convolutional neural network to classify the images. This would be a good learning experience, and will let you try a lot of different neural networks. Note that if you choose to use multiple images per patient, you must be careful not to mix them across training and validation datasets. This would constitute 'leakage' of information from training to validation (e.g. see this famous example ). Once you have got to grips with the data, the problem, etc... Then move to 3D This is really a 3D problem, and the state of the art would be to apply a 3D convolutional neural network. Here's a recent survey of such methods ; there are plenty. The labels are still just whatever classes you have ('fractured', 'not fractured', etc), and you will have one label per 3D training image. Each training image will be a 3D array/tensor â€” so all your training images will stack into a 4D hypercube. Disclaimer: I don't deal with 3D medical images, but I do deal with 3D geophysical images.
