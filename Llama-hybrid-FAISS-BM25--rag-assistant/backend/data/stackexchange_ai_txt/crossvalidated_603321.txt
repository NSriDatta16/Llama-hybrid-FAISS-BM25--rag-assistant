[site]: crossvalidated
[post_id]: 603321
[parent_id]: 602493
[tags]: 
It looks to me like the heart of the question is: how can I use unlabeled data to estimate the performance of a model? It's reasonable that the baseline to beat is not using the unlabeled data at all, e.g., a cross-validation estimator applied to the labeled data. Something helpful to search online is "unsupervised accuracy estimation" or (even simpler) "estimate accuracy no labels". Here is a reference to get you started . 1 See the KEY IDEA and section 4.2.1 for a quick scan. I haven't read much else of the paper or the ones it cites in the Related Works section. But it looks like information is gained from unlabeled data by analyzing agreement rates (in classification tasks) between different, independent approximators . That seems starkly different than what's done in your code example b/c: your approximators are all LightGBM w/ the same hyperparameters your model errors are highly statistically dependent (almost perfectly correlated?) b/c the second model is fit on predictions from the first. I don't see how information is gained going from model to model_eval , or from model_eval to model_eval1 and back. At a very high level, if you're acquiring information from sources which are all talking to each other in the exact same way, how can the sum of that information be much greater than that from just one of the sources? A separate thing to be clear about is the problem of estimating error on in-(training)-distribution vs out-of-(training)-distribution data. These terms are more specific than "in-sample" vs "out-of-sample" data, which could have the same or different distributions. In your code example, we know the unlabeled data is drawn from the same distribution as labeled data, b/c you randomly split the whole dataset. So for that example, and in the context of out-of-distribution error estimation, it's wrong to be concerned about ignoring unlabeled data. That being said, you're right that out-of-sample data is usually unlabeled and may be non-identically distributed wrt labeled data. (Though we can only really refer to the marginal distribution of features changing, which is called "covariate shift". I like the introduction of this paper 2 if you wanna read more.) This problem is indeed real and well-motivated, as you mentioned. And this is one paper 3 which addresses it. References Platanios, Emmanouil Antonios, Avrim Blum, and Tom Mitchell. "Estimating accuracy from unlabeled data." (2014). Lipton, Zachary, Yu-Xiang Wang, and Alexander Smola. "Detecting and correcting for label shift with black box predictors." International conference on machine learning. PMLR, 2018. Chen, Jiefeng, et al. "Detecting errors and estimating accuracy on unlabeled data with self-training ensembles." Advances in Neural Information Processing Systems 34 (2021): 14980-14992.
