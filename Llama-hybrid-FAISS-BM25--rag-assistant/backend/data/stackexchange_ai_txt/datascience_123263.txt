[site]: datascience
[post_id]: 123263
[parent_id]: 
[tags]: 
How to generate synthetic data samples of Raman Spectroscopy by using GAN?

I am working on the Raman Spectroscopy dataset. The wavenumber/frequency range used by Raman spectra starts from 151.25 and ends at 1999.17. These values are used on the x-axis. While amplitude/intensity range from 100 to 1675 that is used on the y-axis. I have a dataframe named “data_df” consists of 62 rows and 1871 columns. It means I have store my 62 data samples in this dataframe “data_df”. I have already done the preprocessing and also normalized it. The first entire column from row 1 to 62 of this dataframe contain the class label “D”. The column from 2 to 936 of each 62 rows has the same frequency values that is used on the x-axis. Moreover, each 62 rows from column 937 to column 1871 contains the amplitude values that is used for y-axis. Each row and columns (from 937 to 1871) contains different amplitude values. In this way, we have total 935 values for frequency (which is same in each 62 row) and 935 values for amplitude (different values in each 62 row) and one column for class label containing ‘D’ as a label. [935+935+1 =1871 columns] I used the GAN code available on this website GAN Code This GAN code is for generating synthetic images, But I have modified it according to my scenario as i have mentioned earlier. the modified GAN code to generate synthetic Raman Spectra is as follow #Extracting relevant columns from the DataFrame frequency data = data_df.iloc[:, 1:936].values # Frequency values (same for all data) amplitude_data = data_df.iloc[:, 936:].values # Amplitude values Defining the standalone discriminator model** def define_discriminator(input_shape): model = Sequential() model.add(Conv1D(128, 3, strides=2, padding='same', input_shape=input_shape)) model.add(LeakyReLU(alpha=0.2)) model.add(Conv1D(128, 3, strides=2, padding='same')) model.add(LeakyReLU(alpha=0.2)) model.add(Flatten()) model.add(Dense(1, activation='sigmoid')) opt = Adam(lr=0.0002, beta_1=0.5) model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy']) return model # Defining the standalone generator model def define_generator(latent_dim, n_outputs): model = Sequential() model.add(Dense(128 * 7, input_dim=latent_dim)) model.add(LeakyReLU(alpha=0.2)) model.add(Reshape((7, 128))) model.add(UpSampling1D(2)) model.add(Conv1D(128, 3, padding='same')) model.add(LeakyReLU(alpha=0.2)) model.add(UpSampling1D(2)) model.add(Conv1D(128, 3, padding='same')) model.add(LeakyReLU(alpha=0.2)) model.add(Conv1D(n_outputs, 3, padding='same', activation='tanh')) return model # Defining the combined generator and discriminator model def define_gan(generator, discriminator): discriminator.trainable = False model = Sequential() model.add(generator) model.add(discriminator) opt = Adam(lr=0.0002, beta_1=0.5) model.compile(loss='binary_crossentropy', optimizer=opt) return model # Loading real samples (frequency and amplitude data) def load_real_samples(): return frequency_data, amplitude_data # Generate real samples (frequency and amplitude data) def generate_real_samples(dataset, n_samples): ix = np.random.randint(0, dataset.shape[0], n_samples) X = dataset[ix] y = np.ones((n_samples, 1)) return X, y # Generate points in latent space as input for the generator def generate_latent_points(latent_dim, n_samples): return randn(n_samples, latent_dim) # Generate fake samples using the generator def generate_fake_samples(generator, latent_dim, n_samples): x_input = generate_latent_points(latent_dim, n_samples) X = generator.predict(x_input) y = np.zeros((n_samples, 1)) return X, y # Train the GAN model def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=64): bat_per_epo = int(dataset.shape[0] / n_batch) half_batch = int(n_batch / 2) for i in range(n_epochs): for j in range(bat_per_epo): X_real_freq, X_real_amplitude = generate_real_samples(dataset, half_batch) d_loss1, _ = d_model.train_on_batch(X_real_freq, X_real_amplitude) X_fake_freq, X_fake_amplitude = generate_fake_samples(g_model, latent_dim, half_batch) d_loss2, _ = d_model.train_on_batch(X_fake_freq, X_fake_amplitude) X_gan = generate_latent_points(latent_dim, n_batch) y_gan = np.ones((n_batch, 1)) g_loss = gan_model.train_on_batch(X_gan, y_gan) print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss)) # Size of the latent space latent_dim = 100 # Create the discriminator discriminator = define_discriminator((935, 1)) # Create the generator generator = define_generator(latent_dim, 935) # Create the GAN gan_model = define_gan(generator, discriminator) # Load real Raman Spectra data dataset_freq, dataset_amplitude = load_real_samples() dataset_freq = dataset_freq.reshape((-1, 935, 1)) dataset_amplitude = dataset_amplitude.reshape((-1, 935, 1)) # Train the GAN model train(generator, discriminator, gan_model, dataset_freq, latent_dim) I am using jupyter notebook for my implementation. I have received an error of dimensions of the generator' s output with the discriminator's input: Input 0 of layer "dense_16" is incompatible with the layer: expected axis -1 of input shape to have value 29952, but received input with shape (None, 896) How to fix this error?
