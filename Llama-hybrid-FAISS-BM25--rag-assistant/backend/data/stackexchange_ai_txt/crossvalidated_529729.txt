[site]: crossvalidated
[post_id]: 529729
[parent_id]: 529683
[tags]: 
I honestly can't tell how many tests are contemplated or what is the right course of action. First the technical question: The idea of coding for no adjustment, but later using an altered threshold for the P values is always a workable option when applying the Bonferroni correction, because all you have to do is divide your required threshold (say, 0.05 -- which people very, very seldom give any serious thought) by the number of tests. However, if you are dealing with an audience that is accustomed to basing their decisions on adjusted P values, that approach is highly problematic because as soon as people see numbers, their attention is immediately diverted from whatever cautionary words accompany them. So, we have 5 responses and 4 independent variables. Some of those independent variables are factors. The number of tests performed depends on the numbers of levels of the factors. And there is the possibility that some of them interact, leading to more detailed comparisons, stratified by levels of other factors. So who knows how many tests are to be performed in total? And is it truly advisable to view the whole shootin' match as a single family of tests, for which we want to control the error rate? That is a question that should be addressed in the context of the subject matter. And how tightly should the error rate be controlled? The probability of making any type-I error, as is done with Bonferroni? Or something less stringent such as the false discovery rate? These kinds of questions are actually no much unlike our current controversies about face masks: How much protection is reasonable, and over what group? All that said, I very rarely have seen people apply the concept of a "family of tests" beyond one dependent variable. I usually see people consider a "family" defined as comparisons of levels of one factor, for one dependent variable. And even when other factors are involved, I think I most often see families of comparisons conditioned on the levels of other factors, each separately adjusted. That is what seems the most common practice. It may or may not be the best practice. And it depends too on those separate dependent variables; are they different measures of the same thing? Or completely different? But it is clear that it is possible to go too far in protecting an overall error rate. So I wouldn't go too far overboard, because you'll find yourself serving some priggish external objectives rather than reporting useful findings. And remember that no research should be the final say on a particular topic. So your goal is to avoid over-stating the importance of your results, but leave room to invite others to consider what may be most important and worthy of future investigation.
