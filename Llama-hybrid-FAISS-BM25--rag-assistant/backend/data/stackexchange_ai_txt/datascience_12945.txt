[site]: datascience
[post_id]: 12945
[parent_id]: 4942
[tags]: 
Aleksander has given a very comprehensive answer but there are a few that are sued very widely: For dimensionality reduction, PCA is used.This, however, does only a linear transformation and for non-linear dimensionality reduction, Manifold learning is what you are looking for. Projecting a lower dimensional data to higher dimensions can be done using kernels. You usually do this, when your classifier is unable to find a linear plane of separation in current dimension but will be able to find a linear hyperplane that separates the classes in a higher dimension. Kernels are used widely in SVM's.
