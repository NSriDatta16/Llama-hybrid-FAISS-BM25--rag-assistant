[site]: crossvalidated
[post_id]: 237490
[parent_id]: 237386
[tags]: 
It's because neural networks are easy to parallel, for common network layers, the same operations are applied to the input and parameters, and the order of executing these operations doesn't affect the output. GPUs are good at parallel processing as they have thousands of cores. AFAIK the GPU doesn't reduce the number of flops required for matrix operations compared with the CPU. If a layer involves some operation that doesn't gain much from parallel processing (say the insertion sort), then using GPUs won't be so fast.
