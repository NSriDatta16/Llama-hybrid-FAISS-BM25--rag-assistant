[site]: crossvalidated
[post_id]: 314477
[parent_id]: 314463
[tags]: 
There are many algorithms for training "unnormalized" models (e.g., score matching, minimum probability flow, noise contrastive estimation, contrastive divergence ). In the following, I explain the basic idea behind persistent contrastive divergence (PCD). Assuming our distribution is positive, we express it in terms of an energy function $E$ and normalization constant $Z$: $$\textbf{P}_\text{model}(x \mid \theta) = \frac{e^{-E_\theta(x)}}{Z_\theta}$$ The maximum likelihood gradient is \begin{align} \nabla \mathbb{E}_\text{data}[\log \textbf{P}_\text{model}(x \mid \theta)] &= \mathbb{E}_\text{data}[-\nabla E_\theta(x)] - \nabla \log Z_\theta \\ &= \mathbb{E}_\text{model}[\nabla E_\theta(x)] - \mathbb{E}_\text{data}[\nabla E_\theta(x)] \end{align} since $$ \nabla \log Z_\theta = \frac{1}{Z_\theta} \nabla \int e^{-E_\theta(x)} \, dx = - \int \frac{e^{-E_\theta(x)}}{Z_\theta} \nabla E_\theta(x) \, dx = -\mathbb{E}_\text{model}[\nabla E_\theta(x)]. $$ The problem with this gradient is that we cannot easily estimate an expectation over the model distribution, since it is difficult to sample from an unnormalized model. We can try to run an MCMC sampler to sample from the model, but this can take a long time and we have to do it for every gradient step. So in PCD we initialize our sampler with the samples from the last gradient step, which if the model hasn't changed much should already be close to the desired distribution. We then only apply one or a few MCMC updates before using the samples. A commonly used sampler is Hamiltonian Monte Carlo . One example paper which used deeper nets to represent the energy function and which used PCD is Learning Deep Energy Models (Ngiam et al., ICML, 2011).
