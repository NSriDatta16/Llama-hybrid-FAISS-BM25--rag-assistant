[site]: datascience
[post_id]: 107196
[parent_id]: 
[tags]: 
What can be the approaches to merge (ensemble) a NON-Probabilistic model with RandomForest?

I have a RF for Text classification and it gives me accuracy. Almost same metric is given by another model built using ElasticSearch and it gives you a score, which you can not relate to. For example, For sample X it gave me 4 prediction results with some scores as A 10,B 9,C 8,D 7 (for each prediction as pred1, pred2, pred3...) and for Y , it gave me B 4,A 3,D 2,C 1 and for Z , it gave me C 90,A 65,B 43,D 20 . You simply can not say if scores of sample X is better than Y or vice versa. But you can definitely say that pred1 is better than pred2 is better than pred3 .... What I observed is that my RandomForest gave better results for some N classes and the other model gave better results for P classes. When I compared the cumulative accuracy, it was say 95% but alone for any of the approach, it was 85%. Is there any way where I can merge these two approaches? Suppose I make One-Hot encoded Class ids (Vector of N classes * 4 (results) + metadata / extra features from data) of all the Five results returned by the Elastic Algo and then use them in Logistic Regression with Voting Classifier of this and my Random Forest ?? Just thinking out loud. For example, let us suppose in a 4 class classification, if the model returned [A,B,C,D]as classes (in ORDER means A is better than B > C > D Total 4 classes), feature for that sample would be [ 00 01 10 11 ], I would pass it to a logistic Regression model and maybe use Voting Classifier along with my RF !! ?? Any good suggestions and approaches?
