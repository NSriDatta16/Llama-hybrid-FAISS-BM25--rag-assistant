[site]: crossvalidated
[post_id]: 316085
[parent_id]: 316056
[tags]: 
I agree with @jlesuffleur that a set of algorithms with randomization should be used. Be aware though, that ideally a MLP should converge to a set of weights and random initialization is only supposed to accelerate getting there faster. If the results of your MLP vary a lot between different weight initialization that could be a hint that it does not learn a lot about the data at all. Make sure that the number of training samples is larger than the number of independent parameters (number of weights), which can go into the thousands for MLPs. Otherwise, there is little hope of getting meaningful predictions from the MLP. On the topic of error measures, the mean average percentage error is readily understood by laymen and therefore quite suitable when talking to customers etc. For model selection, you should use a different measure, such as the mean absolute error or root of mean squared error. The reason is that the MAPE is more susceptible to errors in locations where the original value is small. A deviaton of 10 units contributes 10% when the true value was 100, but only 2% when the true value was 500. The MAE and RMSE give you values that are hard to interpret, but better suited for comparing differnt models. The RMSE punishes large deviations more than the MAE, but which of the two to emphasize is up to you and the project's requirements.
