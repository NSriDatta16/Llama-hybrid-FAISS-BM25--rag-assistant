[site]: datascience
[post_id]: 28671
[parent_id]: 28613
[tags]: 
Choosing the learning algorithm depends on the problem type: Linear regression is typically used for regression problems (i.e., predicting results within a continuous output) Logistic regression is typically used for classification problems (i.e., predicting results in a discrete output) In our scenario, we want to predict if patients with certain causes (features) are highly likely to be diagnosed with infertility ("yes"), are often diagnosed with infertility ("often"), are sometimes diagnosed wit infertility ("sometimes"), or are highly likely to be not diagnosed with infertility ("no"). So, as a result, we can have one of the four discrete outputs: "yes", "often", "sometimes", "no". That is, we have a classification problem and therefore we should choose logistic regression over linear regression. Now, logistic regression does binary classification (two classes) and we have four classes. Still, we can use logistic regression by learning four different models: Predicts "yes" or "the rest" ("the rest" includes "often", "sometimes", "no") Predicts "often" or "the rest" ("the rest" includes "yes", "sometimes", "no") Predicts "sometimes" or "the rest" Predicts "no" or "the rest" For a given patient, all four models are then evaluated. Ideally, three of the models will predict "the rest" and one will predict the actual class for the patient. This strategy is called one-vs.-rest transformation . There is also one-vs.-one transformation . Alternatively, we can use one of the learning algorithms that natively support multiclass classification and do not require a transformation: decision trees, support vector machines, neural networks, multinomial logistic regression, etc.
