[site]: crossvalidated
[post_id]: 441214
[parent_id]: 441125
[tags]: 
A partial answer: in the paper you reference, the unbiasedness is essentially a byproduct of the equality \begin{align} \int \int p ( x ) q ( x, y ) \cdot \rho ( x, y ) g ( y ) \, dx \, dy &= \int \int p ( x ) p ( y ) g ( y ) \, dx \, dy \\ &= \int p ( y ) g ( y ) \, dy. \end{align} Note that: Finite-time unbiasedness will generally not hold, unless the Markov chain is initialised at equilibrium (i.e. with a draw from $p$ ), which is typically difficult. Moreover, the importance sampling estimator you include is a ratio of estimators, which typically makes it difficult to establish unbiasedness for finite $n$ . Fortunately, this is usually less of an issue when considering $n$ going to $\infty$ . If I remember correctly, it's also the case that the weights used in the paper are not quite $\rho = p / q$ , but a constant multiple of this expression, where the constant is unknown. This doesn't get in the way of showing unbiasedness, but does explain why the ratio-type estimator is used; one is doing something a bit closer to self-normalised importance sampling. To make other choices of weights, the following advice might be useful: To obtain unbiasedness, one should construct weights $\rho$ which admit some sort of simplification, as in the integral expression at the beginning of this answer. When performing importance sampling, one is comparing a distribution which you can sample from to one from which you cannot sample. The latter is usually your target distribution, i.e. $p$ , and the former is some distribution which you have algorithmic access to. As such, it is simpler to think in terms of 'which importance distributions are available for me to sample from?' rather than 'which importance-weighting scheme should I use?'. Basic importance sampling generally performs worse as the dimensionality of the problem increases, and so in some sense, you would like your importance distribution to be as low-dimensional as possible. As such, if one constructed importance weights involving more points (e.g. looking at $\{ X_{t-2}, X_{t-1}, Y_t \}$ , then one could reasonably expect the weights to become more singular, and worsen the variance of the estimator.
