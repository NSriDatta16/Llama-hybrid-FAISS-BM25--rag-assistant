[site]: crossvalidated
[post_id]: 589203
[parent_id]: 316911
[tags]: 
Replying to Zhang Kin Question: Consider a k-armed bandit problem with k = 4 actions, denoted 1, 2, 3, and 4. Consider applying to this problem a bandit algorithm using ε-greedy action selection, sample average action-value estimates, and initial estimates of Q1(a) = 0, for all a. Suppose the initial sequence of actions and rewards is A1 = 1, R1 = −1, A2 = 2, R2 = 1, A3 = 2, R3 = −2, A4 = 2, R4 = 2, A5 = 3, R5 = 0. On some of these time steps the " case may have occurred, causing an action to be selected at random. On which time steps did this definitely occur? On which time steps could this possibly have occurred? Answer: It’s given that Q1(a)=0 for all =1,2,3,4 *Note when A1=1 means A1 means ‘Action at 1st iteration’ and =1 means “Action = 1st”, and so on is for A2=2, it means at 2nd iteration the action was 2. The first action A1=1, this action can be either exploration or exploitation (Choosing randomly between maximum values of (1) which are zero or randomly choosing between all slots 1,2,3,4). The second action A2=2 is the exploration, as we have the value of (1) = -1,0,0,0. The third action A3=2 should be greedy since we have Q(2)= −1,1,0,0 and 1 is the maximum (although it can be an exploration). The fourth action, A4=2, is an exploration because the values of Q are Q(3)= −1,−0.5,0,0, and if we had followed the greedy method, we would have chosen action 3 or 4. And at last, for the fifth action, which is A5=3 again, it is an exploration. Because Q(4)= −1,1/3,0,0 and if we had taken maximum, we would choose the action of A5=2.
