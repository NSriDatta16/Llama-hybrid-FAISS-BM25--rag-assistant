[site]: crossvalidated
[post_id]: 468366
[parent_id]: 
[tags]: 
Precise definition of the confidence interval - sources?

I always thought that the CI is defined as the set of parameter values corresponding to hypotheses which we can retain . But I struggle to find a source for this definition. Is it not correct? Most sources (including Wikipedia) seem to define the 95% CI by the requirement that for a fixed true value of the parameter, there's 95% probability that the CI resulting from a random experiment will cover it. Some sources give wrong and/or murky definitions (or definitions specific to for example the t-test), but the Wikipedia definition seems to be the consensus. I have two problems with this definition. First, by this definition the CI simply wouldn't exist in many cases. For example, consider the throw of a single coin with a true head probability of, say, 0.42. There's only two possible outcomes of our experiment. If CI(X=head) contains 0.42 but CI(X=tail) does not, then our CI() function satisfies the definition if a 42% confidence interval (at least for the true value theta=0.42), but there's no way the CI function could ever give you a coverage probability of 0.95. Second, it is not obvious that the Wikipedia definition uniquely defines anything. What would be wrong with the following stochastic process? With 95% probability, return ]-inf;Inf[. With 5% probability, return the empty set OK, maybe one can prove that the above silly definition creates a CI() function that will never be a function of a minimal sufficient statistic for the estimation of the parameter of interest, and then deem it illegal for that reason. But it strikes me as wrong to provide a "definition" of the CI by requiring to have some property, without making it obvious that this property uniquely defines the CI.
