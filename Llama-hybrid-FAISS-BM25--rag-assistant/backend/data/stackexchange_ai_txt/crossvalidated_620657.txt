[site]: crossvalidated
[post_id]: 620657
[parent_id]: 
[tags]: 
Do I need to take additional log det Jacobians for every PDF that uses the reparameterization trick?

Consider the - ELBO objective with reparameterization which is also used in VAE's: $$ \mathcal L_{\theta,\phi}(x)=\log p_\theta(X|Z)+\log p_\theta(Z) +\log q_\phi(Z) $$ The reparameterization trick makes use of $g(\epsilon, \phi)$ such that $\epsilon$ is not dependent of $\phi$ so we can push the gradients to optimize the ELBO (single Monte Carlo sample). Now due to transformation of variables, I need to take $$ \log q_\phi(Z)=\log p(\epsilon) +\log\left|\det \frac{\partial Z}{\partial \epsilon} \right| $$ My question is, do I need to add another log det jacobian for the term $\log p_\theta(Z)$ ? $P_\theta(Z)$ is the prior for $Z$ . I am sampling $Z$ from $g(\epsilon,\phi)$ to make the ELBO backpropagable. However, in the usual algorithms for VAE (like in Kingma's), there is no log det Jacobian for $P_\theta(Z)$ Also, if I take the log det Jacobian for $p_\theta(Z)$ , the log det Jacobians would cancel as in the ELBO
