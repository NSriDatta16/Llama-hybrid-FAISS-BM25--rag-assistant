[site]: crossvalidated
[post_id]: 541716
[parent_id]: 
[tags]: 
Why a minimiser of a subset of training dataset is that of the whole training set

In section 3.3 of Bottou et al (2018), under the 'intuitive motivation' paragraph, the authors claim that 'a minimiser of empirical risk for the larger set $S$ is clearly given by a minimiser for the smaller set $S_{\text{sub}}$ ', thereby arguing that the stochastic optimisation is sufficient over batch optimisation. However I am aware that the loss function surface may contain multiple local minima. Is that where the stochastic method might run into trouble?
