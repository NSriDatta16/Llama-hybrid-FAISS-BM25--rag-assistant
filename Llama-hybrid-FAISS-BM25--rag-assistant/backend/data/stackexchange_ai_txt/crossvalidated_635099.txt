[site]: crossvalidated
[post_id]: 635099
[parent_id]: 417408
[tags]: 
The token (query) to token (key) connection in the self attention mechanism captures word to word relation. But how about the relation between the parts of the words? Jane play ed piano and John dance d . Jane play s piano and John dance s . When we talk, our brain is conscious of the correspondence of the tense and matching the plural/singular forms and we modify the part of the words (non-stem) so that it follow the grammatical rules. Hence, the Transformer is not only attending to entire word to entire word relation, it is attending to parts of the words to find the relations (e.g. tense match, singular/plural match). It further enriches the understanding of the language, hence in my understanding, computation speed will be secondary.
