[site]: crossvalidated
[post_id]: 242994
[parent_id]: 
[tags]: 
Do researchers ever put Bayesian priors onto different sets of assumptions?

Econometric analyses of causal effects often hinge on assumptions that authors leave unverified ("my model controls for everything important"). Discussions of the analyses often involve equally unverified criticisms ("well, maybe you didn't control for everything important"). This leaves most work in econometrics unconvincing and unsatisfying. Econometricians are also not very rigorous in the way they quantify the plausibility of their arguments. Mostly Harmless Econometrics , for example, quotes Orley Ashenfelter as saying that the evidence linking education and income is "pretty convincing", and while he makes (what seems to me) a strong case for this assertion, this is presumably as rigorous as he knows how to be about whether evidence is convincing or not. Orley Ashenfelter is also a more careful researcher than most econometricians. In a field where the best practicioners use quantifiers like "pretty" and "not very" to describe the strength of evidence, and the link between evidence and hypothesis is very uncertain, it seems that authors could make better use of Bayes' Rule: the plausibility of different assumptions could be described using priors, and the strength of evidence for one assumption versus another could be described using likelihoods. Are there examples of econometricians (or anyone else who needs to reason statistically under uncertain assumptions) using Bayes' Rule in such a way?
