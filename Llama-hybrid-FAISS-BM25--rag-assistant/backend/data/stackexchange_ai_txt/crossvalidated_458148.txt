[site]: crossvalidated
[post_id]: 458148
[parent_id]: 458140
[tags]: 
The answer is already given in the other answer (+1), the dataset you describe is not that big and should not need any specialized software or hardware to handle it. The only thing that I'd add, is that you rather should not use Spark . You can check those benchmarks , Spark "is slower and has a larger memory footprint" and for some versions of Spark "random forests having low prediction accuracy vs the other methods", so basically, the Spark implementation of random forest is poor.
