[site]: datascience
[post_id]: 122940
[parent_id]: 
[tags]: 
Disadvantages of using just Vector Stores

I've just started with langchain, and one thing baffles me. For starters, I'm using an in-memory vector store created from a local csv file from langchain.document_loaders import CSVLoader loader = CSVLoader(file_path=file) from langchain.indexes import VectorstoreIndexCreator index = VectorstoreIndexCreator(vectorstore_cls=DocArrayInMemorySearch).from_loaders([loader]) ... response = index.query(query) I've seen that under the hood is using embeddings API from OpenAPI, and for my specific use case (meaning specific domain knowledge) I find it more powerful than OpenAI's API completions endpoint (tried multiple models). I feel that using a Vector Store or DB with embeddings API is way better than using completions API. I feel that the similarity search does all the magic, and I cannot see the value of an LLM (at least at this point). What are the disadvantages or bottlenecks of using just a Vector DB and an embedding model?
