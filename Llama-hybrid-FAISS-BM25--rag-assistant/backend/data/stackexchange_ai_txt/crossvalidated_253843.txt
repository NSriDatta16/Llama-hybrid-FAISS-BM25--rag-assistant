[site]: crossvalidated
[post_id]: 253843
[parent_id]: 253839
[tags]: 
Random uncertainty decreases the precision of an experiment. Systematic uncertainty decreases the accuracy of an experiment. The Standard deviation , $s$ equals the square root of the sum of squares of differences $/ N$ (population). The standard deviation of the mean value of a set of measurements $σ_m$ , (“sigma-em”) $σ_m=s/√N$ When we speak of the uncertainty σ of a set of measurements made under identical conditions, we mean that number $σ_m$ and not $s$. There are two common ways to state the uncertainty of a result: in terms of a $σ$, like the standard deviation of the mean $σ_m$, or in terms of a percent or fractional uncertainty, “epsilon”, $\epsilon$. If the uncertainty of results does not change with quality or experience then the rate of change of standard deviation of the mean value with growing data set size will be small. It is both an indicator of process quality and significant population size. Referring to Shannon's Law and digital communication we know that the Noise to Signal ratio or standard deviation is arithmetically related to the error rate is directly proportional on a log-log scale ( although we usually use the inverse or S to N ratio (SNR)) where 10:1 or 10dB to 15 dB or 30:1 is usually the threshold of noise where you have a 50/50 chance of error depending how how you discriminate the results "good or bad" and 20dB is 1% noise, the error rate is quite small. (more astute statisticians are welcome improve or correct this description) You must decide your own population size and and error threshold and thus population size for significant results depending on the weight of the error. ( longer recovery period vs loss of added cost, infection or whatever) A typical calculation is a measure of the improved recovery time with a standard deviation with and without additional treatment. Then plotting the standard deviation over time for each medical team is an indicator of their treatment efficacy improvement rate. IMHO, blinding the test is less important than defining the measurement methods of observation of recovery accurately, confidence in skill , if this can be measured somehow with measurable thresholds, tolerances and bias inputs. (neglect or more attention may bias the results in either direction) (blind test results are somewhat meaningless without these details because they only apply to the team that repeated the process and not all teams unless a larger measurement takes place.) Even with a large sample base, every precedure must be a measurable parameter with a tolerance to obtain a reliable prediction of the outcome. ( e.g. placement, adhesion secured, patient motion etc.) Reducing the deviation improves the success rate. Design of Experiments (DoE) can be done to optimize the process. (beyond scope of this answer)
