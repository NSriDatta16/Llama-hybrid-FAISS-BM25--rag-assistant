[site]: crossvalidated
[post_id]: 122060
[parent_id]: 
[tags]: 
Assessing predictor contribution to model output

Many of machine learning methods are considered as "black boxes". Examples of such methods are SVM, Neural Networks, Random forests etc. One may apply sensitivity analysis techniques (as described for example in this paper by Paulo Cortez ) in order to assess the importance of each predictor to the entire model. However, this analysis does not answer the (very tricky) question "What are the top predictors that contributed to a given single prediction?". Provided several criteria are met, one may obtain such answer from Naive Bayes models by comparing the individual posterior values. In linear models, comparison of $a_i \times x_i$ values will also provide good answer to the above question. But what about more complex models?
