[site]: datascience
[post_id]: 52741
[parent_id]: 
[tags]: 
Fixed effects or random effects in RNN

Lately, I have been concerned to implement fixed effects and random effects (from econometrics) in deep learning. After reading some articles, I realized that most of them just used only the neural network based on RNN with panel data. They were not considered to panel data structure such as fixed effects or random effects. In my knowledge, in the case of LSTM, the weights in one cell are the same for all panel subjects. There is no consideration of the group average. This seems inappropriate from the viewpoint of panel data analysis. I believe that it should be considered to fixed effects, or random effects, or multi-level model in deep learning. Although there are some articles to apply those models in deep learning( https://arxiv.org/pdf/1702.06512.pdf , http://willwolf.io/2017/06/15/random-effects-neural-networks/ ) , most data scientists seem to think that it is not important or not necessary. So I would like to hear opinions from experts about using fixed or random effects in deep learning. Thank you.
