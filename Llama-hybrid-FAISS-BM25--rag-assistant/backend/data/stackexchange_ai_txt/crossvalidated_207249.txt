[site]: crossvalidated
[post_id]: 207249
[parent_id]: 206806
[tags]: 
The dilemma whether one should include or not the Don't know response option into a questionnaire consisting of rating scales of Likert type is eternal. Often, when the items ask about opinion, the DK is included because having no opinion is an important status on its own and the option as such is expected by respondents. In personal trait inventories where people ascribe qualities to a target DK option is typically dropped because a respondent normally is expected to be able to assess the extent of affinity of a characteristic (i.e. respondent is always seen qualified); and when he occasionally finds difficulty he is allowed (by instruction) to skip that item. In personal trait inventories where people describe a target (behavioural items) DK (or don't remember) could be incorporated or dropped depending on the scale design and the specific question of the study. @Hatim in his answer, @Maarten and some other commentators of the OP question have sensibly put up that a large amount of DK responses observed in the current study indicate problems (content validity or face valitity) in the items or that the subjects don't fit in with the questionnaire ordered to them. But you can never tell the story, ultimately the interpretation of the impediment is on you (unless you address it in a separate investigation). One could claim, for example, that the inclusion of DK option to the likerts in that questionnaire (say, it is a trait ascription inventory) serves bad, not good. It didn't give you information (of which the commentators say, that it proves that the [rating] model is inadequate ) but rather distracted/seduced a respondent. Be it not supplied the rating decision guided by the implicit cognitive trait schema could have been elicited; but seeing the cooling option precludes the schema and makes one hastily to withdraw. If you further admit - on your risk, but why not? - that an easily distracted or lazy subject is the one whose potential, held back view is valid but tends to be weakly differentiated - that is, he would easily invoke conventional das Man , in place of personal Erlebnis , schema - then you may tentatively speculate that his missing response is around the sample's or population's mean for that item. If so, why not do mean (+noise) substitution of the missing responses? Or you might do EM or regressional (+noise) imputation to take correlations into account. To repeat: the imputation decision is possible but risky, and is unlikely, given the large amount of missing data, to restore "truly" the absent data. As @rumtscho said, surely that the new questionnaire with DK is not equivalent to the original one without DK, and the data is no longer comparable. These were speculations. But first of all, you ought to attempt to investigate the observed patterns of missingness. Who are those subjects who selected DK? Do they cluster together in subtypes? How they are different on the rest of the items from the "okay" subsample? Some software have Missing Value Analysis package. Then you could decide whether to drop the people entirely or partly, or to impute, or to analyze them as a separate subsample. P.S. Also note that respondents are "stupid". They often just mix up with the scale grades. For example, if the DK point was placed close to one pole of the scale it would often get confused by inattention with that pole. I'm not joking.
