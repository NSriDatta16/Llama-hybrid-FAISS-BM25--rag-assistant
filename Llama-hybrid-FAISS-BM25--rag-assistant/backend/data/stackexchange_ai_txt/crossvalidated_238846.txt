[site]: crossvalidated
[post_id]: 238846
[parent_id]: 
[tags]: 
Setting up simulation algorithm to check calibration of Bayesian posterior probabilities

Figuring out how to simulate something is often the best way to understand the underlying principles. I am a bit at a loss on exactly how to simulate the following. Suppose that $Y \sim N(\mu, \sigma^{2})$ and that $\mu$ has a prior distribution that is $N(\gamma, \tau^{2})$. Based on a sample of $n$ observations $Y_{1}, \dots, Y_{n}$ abbreviated by just $Y$, I am interested in showing to a non-Bayesian that the posterior probability that $\mu > 0 | Y$ is well calibrated, e.g., Prob$(\mu > 0 | P) = P$ where $P$ is the posterior probability. A related discussion is here What I really want to show is that if one were to do sequential testing and stop sampling when the posterior probability exceeds some level such as 0.95 the probability that $\mu > 0$ is not $ I am trying to convince frequentists that Bayesian probabilities are meaningful without getting into any discussion about type I error. I suppose there is a philosophical problem when talking to a frequentist who entertains null hypotheses in that if the prior is continuous (as above) the probability that $\mu = 0$ is zero and simulations are not needed. I would appreciate some suggestions about how to think of the whole problem and how to design demonstration simulations. I am used to doing frequentist simulations where $\mu$ is just set to a single constant; Bayesians don't condition on $\mu$. For the sequential situation we set a maximum possible sample size, e.g., $n=1000$. There is a subtlty to the problem that I always have trouble thinking about. A real skeptic is sometimes worried about a false claim of effectiveness ($\mu > 0$) when the process really has exactly no effect ($\mu=0$). The subtlty is that the skeptic is "singling out" zero as a special value, and perhaps is giving non-zero probability to the event $\mu = 0$ (?). Our method of showing that the posteriors is calibrated may not make such a skeptic happy because the skeptic really seems to want to condition on $\mu = 0$ and as Bayesians we only condition on what is knowable. Perhaps this is a case where the prior distribution that the statistician is using conflicts with a discontinuous prior distribution the skeptic is using?
