[site]: datascience
[post_id]: 54711
[parent_id]: 
[tags]: 
Is there a python library for reformatting names?

I have a list of several hundred thousand electrical assets named in multiple databases which I am trying to reformat to fit into a universal naming convention. I know I could solve this problem hard-coding and using regex, but I wanted to try to solve this using machine learning in python and wanted to know if anyone could recommend me a library or method to try tackling this task. The idea is that there are a bunch of devices for clients we serve which are indexed in multiple databases with different names and I'd like to rename them all to have the same name for all current and future devices added in. For the most part, it should be relatively easy for the human eye to match up the different names and it is not complicated to write a function that does the same, but as I mentioned I think it would be fun to try to do this as an NLP task: Example of my training data of before -> after: MALIBU BEACH 4KV CIRCUIT BREAKER -> MALIBU BEACH 4KV CB MALIBU BEACH CIRCUIT BREAKER -> MALIBU BEACH 4KV CB MALIBU BEACH CB -> MALIBU BEACH 4KV CB MALIBU BCH CB -> MALIBU BEACH 4KV CB BEVERLY HILLS 3N -> BEVERLY HILLS NO.3N BANK BEVERLY HILLS BK 3N -> BEVERLY HILLS NO.3N BANK BEVERLY HILLS NO.3N BK -> BEVERLY HILLS NO.3N BANK BEVERLY H BANK 3N -> BEVERLY HILLS NO.3N BANK From the perspective of writing a function to do this, I'd use regex to capture things like the voltage level, the device type, and city name and then reformat it to the fixed format. From an NLP perspective, if I create a bunch of before -> after cases to train a model, would it be able to handle things like the abbreviations? Such as figuring out on its own that MALIBU BCH is a reference to MALIBU BEACH like a human would, and apply the logic of matching abbreviations in training to future information passing through Or do I need to create a separate dictionary for the model to reference something like a list of possible abbreviations? Would a library like NLTK be the right choice for handling a problem such as this? The upside I see to this method is that by building a ML solution, I would lay out the framework to have a more robust tool to fix other similar non-uniform data issues on the system rather than just this specific one by going the hard-coding method.
