[site]: crossvalidated
[post_id]: 600780
[parent_id]: 584041
[tags]: 
GLMs are a very large class of models, even for general count data so that, by using a GLM, there are likely a few ways to "do it right" and to "do it wrong". Certainly, if you Google "GLM for count data" you'll likely be pointed to Poisson regression, which is a classic and well understood type of model. A simple trend test can be constructed by fitting exactly the model described by @Allan. $$ \log(E[\text{Count} | \text{Year} ]) = \beta_0 + \beta_1 \text{Year}$$ Where year is continuously coded. The interpretation of $\exp(\beta_0)$ would be the expected Count at Year 0 (if you're starting at, say, 2000, best to center the variable at this value so that Year=1 corresponds to 2001 and so forth). $\exp(\beta_1)$ is then the average proportional increase in Count each subsequent year. So a value of 1 indicates no change at all, and a value of 1.1 indicates a 10% increase year-to-year. This is exactly the inference you will find in the standard model output. Is the trend parameter $\beta_1$ different from 0? A probabilistically interesting trait about Poisson models is that the variance is exactly equal to the mean. Because of this, few observations with very large counts can lead to overly precise inference. A remedy with surprisingly implications in small sample sizes - specifically a small number of rows - is the use a quasi poisson model. In this case, we allow the variance to be proportional to the mean through a dispersion parameter. Unlike a parametric Poisson regression, the semiparametric quasipoisson method is not invariant to disaggregation. This means the number of rows in the dataset tell us something about our precision, which in many cases is an appropriate safeguard to overly precise inference.
