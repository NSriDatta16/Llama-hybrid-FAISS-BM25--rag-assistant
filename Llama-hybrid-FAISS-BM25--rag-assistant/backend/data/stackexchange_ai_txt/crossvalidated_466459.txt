[site]: crossvalidated
[post_id]: 466459
[parent_id]: 
[tags]: 
Bayesian Estimation, What is Equivalent Sample Size or Imaginary Sample Size?

I am trying to understand the formula given in the book Bayesian Networks, With Examples in R , by Marco Scutari & Jean-Baptiste Denis. The formula estimates the parameters of a categorical distribution " in a Bayesian setting " (pages 12-13). I am simplifying the formulas to get to the point, so let's suppose we have a binary variable $X$ , and that we want to estimate, "in a Bayesian setting" and with a uniform prior, $\hat{P}(X = 1)$ . The book uses this formula (Formula 1.7) $$\hat{P}(X = 1) = \frac{iss}{n + iss}\pi + \frac{n}{n + iss }\hat{p} $$ where $\hat{p}$ is the MLE estimator, i.e. $\hat{p} = \frac{k}{n} $ , where $k$ is the number of successes (1); and $n$ is the dataset size. $\pi$ is said to be the uniform prior, and therefore $\pi = \frac{1}{2}$ , since this is a binary variable we are dealing with. Now, I am having trouble completely understanding the rationale of what the author calls equivalent sample size or imaginary sample size , $iss$ in the formula above. The formula is, of course, a weighted mean of the expected value of the uniform prior $ \pi$ and $\hat{p}$ , and the bigger the $iss$ the bigger the influence of the prior. But I want to derive the rationale behind $iss$ in the Bayesian context, if there is one. So let's derive the formula: For a binary variable we take a flat prior, i.e. $\theta \sim Beta(1,1)$ . Then the posterior of $\theta \sim B(1+k, 1+n-k)$ , whose expected value is $$\frac{1 +k}{2+n} = \frac{1}{2+n} + \frac{k}{2+n}= \frac{1}{2+n} + \frac{n}{2+n}\hat{p}$$ This clearly corresponds to the formula above for $iss = 2$ . So, how does one give more or less "weight" to the prior distribution? Of course I can just weight these two terms as I want, but what does it means in terms of Bayesian estimation? To me it seems like giving more weight to the prior would be like reducing the sample size $n$ , something like, in the above formula, letting $n = \tilde{n}-1$ , but the math does not work. Any formal explanation of what is equivalent/imaginary sample size applied to this example?
