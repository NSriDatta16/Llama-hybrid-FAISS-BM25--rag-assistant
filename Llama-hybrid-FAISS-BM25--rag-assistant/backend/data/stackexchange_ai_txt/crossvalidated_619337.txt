[site]: crossvalidated
[post_id]: 619337
[parent_id]: 619191
[tags]: 
BMI is calculated from two other measurements, so does it need adjusting for multiple comparisons? ... I.e. Two tests were performed 1) height and 2) weight You have multiple measurements but you perform only one test with the statistic that results from the multiple measurements. So there is no need to correct for multiple comparisons (unless there are other ways that one makes multiple comparisons, but the multiple measurements is not a reason). This is similar to this question: Why is ANOVA not p-hacking? Another issue with ratios There can be problems with spurious correlations between ratios such as the ones described by Karl Pearson in "Mathematical Contributions to the Theory of Evolution – On a Form of Spurious Correlation Which May Arise When Indices Are Used in the Measurement of Organs" https://doi.org/10.1098/rspl.1896.0076 A relevant element of the spurious correlation is that there is a use of two ratios that contain both the same measurement, for example "x/y and z/y" or "x/y and y/z". In the case of BMI this can be any other measurement that relates to weight it height. For example consumed vitamins per weight. Example: Let's test some causal model where the effect is zero, ie we sample random $$\begin{array}{rcl} W/L^2&=& \text{BMI [kg/m^2]} &\sim& N(\mu = 25,\sigma = 3)\\ S/W &=& \text{vitC/bodyweight [mg/kg]} &\sim& N(\mu = 1,\sigma = 0.2)\\ W&=& \text{weight [kg]} &\sim& N(\mu = 70,\sigma = 10) \end{array}$$ So far the variables $W/L^2$ and $S/W$ will be unrelated. But now, let the weight be measured with some error, such that we do not observe $W$ but instead $W'$ $$W' = W + \epsilon \qquad \text{with} \quad \epsilon \sim N(\mu = 0, \sigma = 2)$$ and this measurement error will make us observe a correlation between the ratios because the errors of the two ratio variables become correlated. The correlation that we observe is not related to an underlying pattern in the deterministic part of the model, but related to the correlation in the random part of the model. R-code to generate the image: set.seed(1) n = 10^4 BMI = rnorm(n,25,3) SW = rnorm(n,1,0.2) W = rnorm(n,70,10) epsilon = rnorm(n,0,2) Wp = W + epsilon L = sqrt(W/BMI) S = SW*W BMIp = Wp/L^2 SWp = S/Wp cor(BMI,SW) cor(BMIp,SWp) mod1 = lm(SW ~ BMI) mod2 = lm(SWp ~ BMIp) summary(mod1) summary(mod2) plot(BMI,SW, xlab = "BMI \n [kg/m^2]", ylab = "vitamin c consumption per bodyweight \n [mg/kg]", pch = 20, cex = 0.1, main = "without measurement error") lines(BMI, predict(mod1), col = 2) text(14,0.3,"slope -0.00031 [p = 0.628]", col =2, cex = 0.85, pos = 4) plot(BMIp,SWp, xlab = "BMI \n [kg/m^2]", ylab = "vitamin c consumption per bodyweight \n [mg/kg]", pch = 20, cex = 0.1,main = "with measurement error") lines(BMIp, predict(mod2), col = 2) text(14,0.3,"slope -0.00213 [p = 0.000907]", col =2, cex = 0.85, pos = 4) Sidenote: I would see this as the smallest problem with BMI. Already when BMI is used in comparisons without other ratios, then it might lead to problematic interpretations. The BMI is a very rough measure, but it is given a relatively large importance in popular scientific literature and advice about nutrition and lifestyle. The arbitrary BMI boundary of 25 kg/m² for overweight versus normal weight (which originates around the time of the first publications from the seven countries study ) is an example. That boundary came from a rough binning of the BMI (like 20-25 and 25-30), but when the BMI is considered as a continuous variable a much more nuanced view emerges (the risk for several serious diseases is minimal around 25 or 26 but when considered as bins this disappeares and the relatively higher risk close to BMI 30 makes the entire bin look bad).
