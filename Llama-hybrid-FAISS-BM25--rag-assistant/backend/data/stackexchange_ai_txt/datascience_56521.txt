[site]: datascience
[post_id]: 56521
[parent_id]: 56513
[tags]: 
So, to be clear, you observe $N$ samples with $P$ measurements at $T$ times (where $P = 6$ and $T = 12$ ). I would first determine whether or not you expect the joint distribution of your $P$ features to change over time. For example, if these features are $X$ , does $\mathcal{P}(X) = \mathcal{P}(X | T)$ for all values of $T$ ? If so, you could do something like stack your data over time (so, you'd have $NT$ samples of $P$ features) and perform PCA, then use the top $k$ loadings to rotate the measurements at individual timepoints, leaving you with $N$ $k$ -dimensional time series of length $T$ . You could choose $k = 1$ if necessary, and use it to visually identify outliers or set a simple cutoff. If not, you'd want to be more careful with this technique - especially if the covariance changes. If it's the variance that's changing but correlation is remaining the same, perhaps some procedures can be done (e.g. perform PCA on the correlation matrix/standardized data) and this technique would still work. What form do you expect your outliers to take? If it's a temporary deviance from the rest of the sample (e.g. only at one or two measurement times), your technique of PCA on the concatenated data will not be very sensitive. The technique I just described would be more sensitive.
