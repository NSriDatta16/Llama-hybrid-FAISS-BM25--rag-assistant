[site]: crossvalidated
[post_id]: 217906
[parent_id]: 
[tags]: 
Understanding results of xgboost, parameter tuning

I ran xgboost with below parameter setting: xgb But when i predicted the output it is giving double the rows as in test data. So I assume, first set of rows are for class '0' and other set of rows for class '1'. But the probabilities all look same: For '0': 1 0.1536680 2 0.1536112 3 0.1537747 4 0.1536112 5 0.1535096 For '1': 211523 0.153667971 211524 0.153611213 211525 0.153526306 211526 0.153611213 211527 0.153774679 How do I go about interpreting the results? Or am I doing something wrong? Also train-merror keeps on changing as I change the nrounds. For nrounds=25 if, the minimum is at 15th round and I reran it with 15 rounds, it shifts again. How can I tune this parameter? Ok, this seemed to be the error: eval_metric = "merror", it should have been logloss for binary.
