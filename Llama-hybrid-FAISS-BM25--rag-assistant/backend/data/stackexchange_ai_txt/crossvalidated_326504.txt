[site]: crossvalidated
[post_id]: 326504
[parent_id]: 326497
[tags]: 
The answer is Yes. For almost all the models, there are parameters / coefficients / weights in there. However, the major difference between statistical model and modern machine learning model is that machine learning models emphasize much less on variable importance, and the interpretation of the coefficient, but focusing on more for the classification accuracy. For example, in Neural Network, for a deep structure, it is common to have hundreds thousands of coefficients. These parameters are learned from data. If we talk about MLP neural network, the coefficients are $W$ (weight) matrices for each layer. For decision tree, where to split are the parameters (for example, we have a tree "if age is smaller than 20 and gender is male", this $20$ is a parameter in the model). For support vector machine, $\alpha$ and $C$ are parameters. Note that, these definitions are really different from regression setting, where in regression setting, usually we have one parameter for one independent variable. This is not true for machine learning models. Suppose we have 2 independent variables, neural network can still haven thousands of parameters. In SVM, number of $\alpha$ is as same as number of data points. For python sklearn, check get_params in this page for examples on SVM
