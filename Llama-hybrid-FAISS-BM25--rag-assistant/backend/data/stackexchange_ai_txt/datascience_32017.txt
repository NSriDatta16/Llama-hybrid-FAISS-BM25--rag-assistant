[site]: datascience
[post_id]: 32017
[parent_id]: 32015
[tags]: 
Assuming we have a lot of data, just not many data are labeled. Try to tackle the problem first by using an unsupervised approach, following that, use the learned features for any downstream task. see Deep Generative Models . generate training labels based on some pre-determined experts rules If you have some function that can generate the data distribution then why you bother yourself with such finding yet another function that approximate the former. you could use this approach for evaluation purposes, e.g. compare different models regarding the problem being solved. What are the approaches to label more data for training you could aggregate (average) different models that tackle the same problem but with a different dataset. Could Maximum Likelihood Estimator be used here. As I said, we could maximize the likelihood of the data, giving high probability to samples that are very similar to the training data is very useful at exploiting the internal structure (learning the data manifold) that could potentially disentangle the factors that are responsible for generating the data which presumably part of them could be a direct signal for predicting the target y that you are trying to predict.
