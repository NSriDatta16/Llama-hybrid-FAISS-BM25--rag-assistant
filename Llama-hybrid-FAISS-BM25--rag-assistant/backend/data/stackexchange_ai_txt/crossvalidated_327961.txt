[site]: crossvalidated
[post_id]: 327961
[parent_id]: 327646
[tags]: 
Random kitchen sinks (or random Fourier features) and other related methods don't endeavour to perform inference but rather they try to reduce the bottleneck of kernel based inference methods. Kernel methods are great in many settings but they usually rely on the manipulation of matrices, for example solving linear systems of equations and finding matrix determinants. If the matrix is $n \times n$ then naively these computations generally cost $O(n^3)$ which limits the applications they can be applied to problems with only a few thousand observations. The most popular way around this bottleneck tends to be low rank methods (although other approaches exist such as Kronecker based methods, H-matrices and Bayesian committee machines to name but a few). Random Fourier features (Rehimi & Recht 2007) considered creating low rank approximations of shift invariant kernels by sampling only a random subset of the kernels Fourier components. As Fourier space is shift invariant, this property was preserved but now an explicit finite dimensional reproducing kernel Hilbert space was formed by the union of these Fourier components. The once infinite dimensional RKHS is approximated by the degenerate approximate kernel. Notes on code snippet: There are a few details brushed over in the 5 lines. The most important is that the Gaussian function is also a Gaussian function in Fourier space, just the variance is inverted. That is why they are sampling from randn and then multiplying by variance. Then they produce alpha which is only a sub-procedure to find $z_test$ . Essentially the normal kernel prediction looks like, $ z_{test} = K(x_{test}, x)(K(x, x) + \lambda I)^{-1} y. $ $ z_{test} = \Phi(x_{test})^T\Phi(x)(\Phi(x)^T\Phi(x) + \lambda I)^{-1} y. $ Where $\Phi(\cdot)$ is the evaluated random Fourier feature vector. Side comment: Should you use it? The answer isn't a clear yes. It depends completely on what you are modelling. The use of the Fourier space is not necessarily appropriate for non-stationary non-shift invariant kernels. The guys never claimed it would work in this setting but if you are just starting out in that area sometimes the nuances aren't obvious.
