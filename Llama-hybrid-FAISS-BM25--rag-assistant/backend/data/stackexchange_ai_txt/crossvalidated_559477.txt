[site]: crossvalidated
[post_id]: 559477
[parent_id]: 
[tags]: 
trace class of prior covariance operator in Bayesian inference problem

I'm interested in certain Bayesian inference problems where the vector space $Q$ where the parameters $\theta$ live is infinite-dimensional. These show up all the time in the geophysical sciences -- estimating the density of material within the earth through seismic measurements, the friction underneath a flowing glacier from measurements of the surface velocity, etc. The parameters to be estimated are fields that live in a Sobolev space defined on a domain $\Omega$ . Let $u$ be the observable field, $M$ the mapping that takes $u$ to the finite-dimensional vector of observations $d$ , $\Sigma$ the covariance matrix of the observations, and let $G(\theta)$ be the mapping that takes the parameters to the observable field $u$ . The solution map $G$ is often nonlinear. I'm accustomed to thinking of this as an optimization problem -- the objective functional is $$J(\theta) = \underbrace{\frac{1}{2}\langle \Sigma^{-1}(d - M\cdot G(\theta)), d - M\cdot G(\theta)\rangle_{\mathbb{R}^m}}_{\text{model-data misfit}} + \underbrace{\frac{\alpha^2}{2}\langle A(\theta - \theta^*), \theta - \theta^*\rangle_Q}_{\text{regularization}}$$ where $\langle\cdot,\cdot\rangle$ denotes the inner product, $\alpha$ is real, and $A : Q \to Q^*$ is a symmetric and positive-definite linear operator. From the inverse problems viewpoint, the problem is ill-posed and so Tikhonov regularization is our only hope, and that's where the second term comes from. To be concrete, for a seismic sensing problem, the parameters $\theta$ describe the shear and compressional wave speeds in the earth, the operator $G$ is the solution operator for the elastic wave equation, the solution $u$ is the displacement of the medium, and $M$ describes the mapping between displacement and what your seismophones will record. The most common choice of the regularization operator is $$\langle A\theta, \phi\rangle = \int_\Omega\nabla\theta\cdot\nabla\phi\; dx,$$ where $\Omega$ is the spatial domain. This choice of regularization operator represents the fact that we expect our solution to not be too oscillatory. But we could also have used $$\langle A\theta, \phi\rangle = \int_\Omega\Delta\theta\cdot\Delta\phi\; dx$$ where $\Delta$ is the Laplace operator. This is a different assumption -- we now expect the solution to have small curvature rather than small gradients, which gives very different solutions. In practice, we always discretize the problem using spectral or finite element methods, i.e. we approximate $\theta$ and $u$ from finite-dimensional subspaces. I've found (through 10 years of experience now) that it's much better to think of the problem as fundamentally infinite-dimensional and to postpone discretization until as late a stage as possible. There's also an interpretation of this problem in terms of Bayesian inference. The "model-data misfit" term corresponds to the log-likelihood and the "regularization" term corresponds to the log-prior, and the posterior distribution is proportional to $\exp(-\beta J(\theta))$ for some normalizing constant $\beta$ . Solving the optimization problem corresponds to finding the maximum a posteriori probability estimate. My question is about the precision operator $A$ ; its inverse $C = A^{-1}$ is the covariance for the prior distribution. All of the literature I can find on infinite-dimensional Bayesian inference problems assumes that $C$ is of trace class -- the eigenvalues of $C$ (resp. the reciprocals of the eigenvalues of $A$ ) have finite sum: $$\sum_{k = 1}^\infty\lambda_k(C) = \sum_{k = 1}^\infty\lambda_k(A)^{-1} The thing that weirds me out is that lots of papers use a prior covariance that is not of trace class. By far the most common choice in the literature is $$\langle A\theta,\phi\rangle = \int_\Omega\nabla\theta\cdot\nabla\phi\;dx$$ i.e. $A$ is the weak form of the Laplace operator. The Weyl formula tells us that $$\lambda_k(A) \sim 4\pi\Gamma\left(\frac{n}{2} + 1\right)^{2 / n}\cdot\text{vol}(\Omega)^{-2 / n}\cdot k^{2 / n},$$ where $n$ is the dimension of $\Omega$ . The sum of $k^{-2 / n}$ is only finite for $n = 1$ whereas most of the problems we're interested in are posed on physical domains in dimension 2 or 3. By contrast, using the Bilaplacian $\Delta^2$ as the precision operator does give a trace-class covariance. What happens if the prior covariance is not of trace class? Is the posterior even well-defined as a probability measure on the parameter space $Q$ ? Several papers [ 1 , 2 , 3 ] stress the importance of using a trace-class prior covariance. Of the papers that I read, only this one addressed the potential consequences of using a covariance that's not of trace class, i.e. that the solutions will exhibit mesh dependence in the limit of finer and finer discretization. In short, I'm concerned that half the papers in my field (including some of my own) are subtly wrong.
