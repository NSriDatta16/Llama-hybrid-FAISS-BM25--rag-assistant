[site]: datascience
[post_id]: 118911
[parent_id]: 118260
[tags]: 
Amazing how much dissonance exists on this very basic question-- are GPT2 based LLM's (GPT3 and ChatGPT) encoder-decoder or decoder only models? Googled ranked answers are all over the map with most converging on the responses here that they are "decoder only" models. Well...... you can't decode data without first starting with encoded data. So the answer is.... OpenAI's GPT2 and subsequent models are encoder-decoder, but are commonly referred to as decoder models because the decoder part (right side of diagram) makes them distinct from the seq2seq -> BERT model evolutionary path from which they descended. But that does not mean they are "decoder only" or lack an encoder. It means that in contrast to BERT models which are "encoder only," they also invoke decoding. All the above hypothesis only.
