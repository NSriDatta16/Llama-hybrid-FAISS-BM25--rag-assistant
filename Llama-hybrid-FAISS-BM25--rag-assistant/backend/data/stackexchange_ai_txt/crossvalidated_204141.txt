[site]: crossvalidated
[post_id]: 204141
[parent_id]: 
[tags]: 
Difference between selecting features based on "F regression" and based on $R^2$ values?

Is comparing features using F-regression the same as correlating features with the label individually and observing the $R^2$ value? I have often seen my colleagues use an F regression for feature selection in their machine learning pipeline from sklearn : sklearn.feature_selection.SelectKBest(score_func=sklearn.feature_selection.f_regression...)` Some please tell me - why does it give the same results as just correlating it with the label/depedendent variable? It is not clear to me the advantage of using F_regression in feature selection. Here's my code: I'm using the mtcars dataset from R : import pandas as pd import numpy as np from sklearn import feature_selection from sklearn.linear_model import LinearRegression #....load mtcars dataset into a pandas dataframe called "df", not shown here for conciseness # only using these numerical columns as features ['mpg', 'disp', 'drat', 'wt'] # using this column as the label: ['qsec'] model = feature_selection.SelectKBest(score_func=feature_selection.f_regression,\ k=4) results = model.fit(df[columns], df['qsec']) print results.scores_ print results.pvalues_ # Using just correlation coefficient: columns = ['mpg', 'disp', 'drat', 'wt'] for col in columns: lm = LinearRegression(fit_intercept=True) lm.fit(df[[col]], df['qsec']) print lm.score(df[[col]], df['qsec']) As suspected, the ranking of the features is exactly the same: scores using f_regression: [ 6.376702 6.95008354 0.25164249 0.94460378] scores using coefficient of determination: 0.175296320261 0.18809385182 0.00831830818303 0.0305256382746 As you can see, the second feature is ranked the highest, the first feature is second, the fourth feature is third, and the third feature is last, in both cases. Is there ever a case where the F_regression would give different results, or would rank the features differently in some way? EDIT: To summarize, I'd like to know if these two rankings of features ever give different results: 1) ranking features by their F-statistic when regressing them with the outcome individually (this is what sklearn does) AND, 2) ranking features by their R-squared value when regressing them with the outcome , again individually.
