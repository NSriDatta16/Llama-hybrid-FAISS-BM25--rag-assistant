[site]: crossvalidated
[post_id]: 504555
[parent_id]: 
[tags]: 
What exactly is Batch Normalization doing?

I have recently read about Batch Normalization for Deep Learning online. Unfortunately, the notation is really inconsistent and confusing, so perhaps someone can help. Main Question: Let's assume we have a neural network $\mathcal{N}$ consisiting of $D_{l}$ neurons in the $l$ th hidden layer and a dataset of $N$ samples from some $d$ -dimensional space, organized in a matrix $X \in \mathbb{R}^{N \times d}$ . Then, the outputs (activations) of the $(l-1)$ th layer are given by a matrix $H_{l-1} \in \mathbb{R}^{N \times D_{l-1}}$ . The input of the $i$ th neuron of the next layer is hence the $i$ th column of $Y_{l} = H_{l-1}W_{l} + \theta_{l}$ with each entry corresponding to one instance in the dataset. Now what exactly is being normalized? I would assume the following: $$\hat Y_{l}^{ij} = \gamma \cdot \frac{Y_{l}^{ij} - \mu_{j}}{\sigma_{j}} + \beta$$ for $\mu_{j} = \frac{1}{N} \cdot \sum_{i=1}^{N} Y_{l}^{ij}$ and $\sigma_{j}$ accordingly. Is this correct? Finally, do the scale and offset parameters $\gamma$ and $\beta$ depend on $j$ also, or are they computed for each neuron individually? Please can someone just give me a formula... Bonus: If someone can explain how this arithmetic is extended to the case if our input is a tensor used in image classification where $\dim(X) = (N,C,W,L)$ where $C$ is the number of channels, I would be very grateful, but if not I am also happy. I usually post on the mathematics-stackexchange but this really seemed to be more appropriate here.
