[site]: datascience
[post_id]: 15460
[parent_id]: 15457
[tags]: 
You can use SVD to build a recommendation engine, but I don't think it's the best way to get intuition around what's going on under the hood. Regardless, here's a presentation with more details, I'd recommend reviewing slide 9 . And to answer your questions: A_k represents an embedding dimension (i.e. the low-rank approximation) that is used to predict the user-rating matrix. The cosine similarity is just the dot product for user $i$ and item $j$, which maps to the predicted rating for user $i$ and item $j$. The dot product is what defines the users and items as being similar. Yes, you should use the MAE on A and A_k . You may prefer to use MSE instead. This measures the quality of your predictions for user $i$ and item $j$. Note, this is obviously the MSE of a matrix , which is the Frobenius Norm. I think an easier way to understand SVD is to see it applied to image compression for different components. See this presentation here .
