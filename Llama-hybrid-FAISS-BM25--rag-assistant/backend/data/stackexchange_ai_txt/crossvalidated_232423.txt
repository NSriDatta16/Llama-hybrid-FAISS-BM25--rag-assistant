[site]: crossvalidated
[post_id]: 232423
[parent_id]: 232106
[tags]: 
All of the above answers are correct, but they don't explain why they are correct, and why you can ignore so many details and avoid having to solve a complicated recurrence relation. The reason why the other answers are correct is the Strong Markov property , which for a discrete Markov Chain is equivalent to the regular Markov property. https://en.wikipedia.org/wiki/Markov_property#Strong_Markov_property Basically the idea is that the random variable $\tau:=($the number of times until the die does not land on 4 for the first time) is a stopping time . https://en.wikipedia.org/wiki/Stopping_time A stopping time is a random variable which doesn't depend on any future information . In order to tell whether the $n$th roll of the die is the first one which has not landed on a 4 (i.e. in order to decide whether $\tau=n$), you only need to know the value of the current roll, and of all previous rolls, but not of any future rolls -- thus $\tau$ is a stopping time, and the Strong Markov property applies. What does the Strong Markov property say? It says that the number which the die lands on at the $\tau$th roll, as a random variable, $X_{\tau}$, is independent of the values of ALL previous rolls . So if the die rolls 4 once, twice, ..., 50 million times, ..., $\tau -1$ times before finally landing on another value for the $\tau$th roll, it won't affect the probability of the event that $X_{\tau} > 4$ . $$\mathbb{P}(X_{\tau}>4|\tau=1)=\mathbb{P}(X_{\tau}>4|\tau=2)=\dots = \mathbb{P}(X_{\tau}>4|\tau=50,000,000)=\dots $$ Therefore we can assume, without loss of generality, that $\tau=1$. This is just the probability that the die lands a value greater than 4 given that it does not land on 4, which we can calculate very easily: $$\mathbb{P}(X_1>4|X\not=4) = \frac{\mathbb{P}(X_1 > 4 \cap X_1 \not=4)}{\mathbb{P}(X_1 \not= 4)} = \frac{\mathbb{P}(X_1 > 4)}{\mathbb{P}(X_1 \not=4)}=\frac{\frac{1}{3}}{\frac{5}{6}}=\frac{1}{3}\cdot\frac{6}{5}=\frac{2}{5} $$ which of course is the correct answer. You can read more about stopping times and the Strong Markov property in Section 8.3 of (the 4th edition of) Durrett's Probability Theory and Examples , p. 365.
