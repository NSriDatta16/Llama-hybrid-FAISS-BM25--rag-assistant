[site]: stackoverflow
[post_id]: 1364574
[parent_id]: 1364483
[tags]: 
There are two factors that affect whether messages can be fragmented: Message length Read length You must write the message atomically - a single write for the whole message. If the message is longer than the pipe buffer size (which need not be very big), then your message will be fragmented into a sequence of bits. The first will fill up the buffer, the next few will be the buffer size, and the last will be whatever is left over. You must read the message atomically too. That is, your read must be big enough to get the whole message in one go. If you have a single reader process (or thread), then you probably can read, say, a 2-byte length from the start of the message and then read the rest of the data atomically. (A 4-byte length would be overkill; the maximum buffer size is normally in the 512-5120 sort of range, though it does vary by system.) Complications include the fact that if there are multiple processes that can write on the pipe, then other processes may manage to interleave their data into the pipe while your oversize message is being sent. Strictly, this applies to Unix-based systems. However, my understanding is that the WinAPI closely reflects Unix in this area.
