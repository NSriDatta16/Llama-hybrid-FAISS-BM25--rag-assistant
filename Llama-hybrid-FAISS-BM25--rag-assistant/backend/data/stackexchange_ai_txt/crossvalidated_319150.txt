[site]: crossvalidated
[post_id]: 319150
[parent_id]: 
[tags]: 
Is it better to have one neural network per feature, or a single neural network for everything?

I'm working on a simple audio-classification program, which is intended to indicate whether the most-recent n seconds of audio in an audio stream are "Speech" or "Music". My program extracts various features from the audio (fundamental frequency, loudness, rolloff frequency, etc) and uses them to build up histograms that I can then feed to one or more neural networks (using the FANN API) as input data. Each neural network has a single output node whose value indicates whether it thinks its input data represents speech or music. My question is: am I likely to get better results by feeding all of my different types of feature-data into One Really Big Neural Network, or am I better off training up a smaller, separate neural network for each feature/data type, and then combining the results of all of the small neural networks' output together (e.g. by addition) afterwards? Is one approach typically more effective than the other, or is this more a case of "It Depends, You'll Just Have To Try It Both Ways And See"?
