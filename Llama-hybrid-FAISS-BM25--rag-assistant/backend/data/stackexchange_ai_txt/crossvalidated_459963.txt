[site]: crossvalidated
[post_id]: 459963
[parent_id]: 459929
[tags]: 
Each node in the hidden layers or in the output layer of a feed-forward neural network has its own bias term. (The input layer has no parameters whatsoever.) At least, that's how it works in TensorFlow. To be sure, I constructed your two neural networks in TensorFlow as follows: model1 = tf.keras.models.Sequential([ tf.keras.layers.Dense(4, activation = 'softmax', input_shape = (5,))]) model2 = tf.keras.models.Sequential([ tf.keras.layers.Dense(4, activation = 'relu', input_shape = (5,)), tf.keras.layers.Dense(3,activation = 'softmax')]) Here is the summary of these two models that TensorFlow provides: The first model has 24 parameters, because each node in the output layer has 5 weights and a bias term (so each node has 6 parameters), and there are 4 nodes in the output layer. The second model has 24 parameters in the hidden layer (counted the same way as above) and 15 parameters in the output layer. Each node in the output layer has 4 weights and a bias term (so 5 parameters per node in the output layer), and there are 3 nodes in the output layer.
