[site]: crossvalidated
[post_id]: 61211
[parent_id]: 61209
[tags]: 
"Division" is really very broad because there's all sorts of things we divide by other things, for different reasons, but they just about all have, in some way, something to do with 'scaling' the numerator to adjust for something. As such, my answer won't be 'high level'. But let's start with one of the most basic examples, the average. We try to find a 'typical' value, and the average is the sum of observations scaled by the count - just adding them would mean we ended up with a number that got bigger the more terms we added - not much use. But as the number of observations in the average grows, it tends to converge on the population mean (under some basic conditions we won't explore) - the scaled quantity is useful, the unscaled one much less so. The variance itself is basically a kind of average, but an average squared distance from the mean (it's also related to the average squared distance between pairs of observations). In the case of the $t$, the variability in the numerator depends on the variability in the original data. But by dividing the numerator by its standard deviation , we can compare t-statistics with a standard table, rather than having to recompute a new one for every data set! That is, the unscaled numerator is not as useful (at least not without a lot more effort) as the standardized version. Indeed, we can pretty much judge significance of a t-ratio 'by eye', whereas doing it for a raw t-numerator would not really be possible.
