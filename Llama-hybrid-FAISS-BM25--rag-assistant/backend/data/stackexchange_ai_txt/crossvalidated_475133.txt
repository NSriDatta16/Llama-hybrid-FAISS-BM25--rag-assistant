[site]: crossvalidated
[post_id]: 475133
[parent_id]: 
[tags]: 
Bias and Variance of a Decision Tree for Classification

There are lot of discussion about bagging and boosting in the context of decision trees and how Random Forest and other methods helps to tackle bias and variance. But how exactly can I measure bias and variance in a decision tree ? If I am performing a k-fold cross validation, similar to a least squares regression can I calculate Bias and Variance ? I see many packages allows the user to input a parameter for folds in a Random Forest algorithm. Is the output of cross validation (which will be a confusion matrix) be used to create a bias and variance metric of some sort ? Can you please explain the bias and variance in the context of a binary classification using decision tree and how cross validation helps ?
