[site]: crossvalidated
[post_id]: 130826
[parent_id]: 130809
[tags]: 
I don't have enough rep to comment, so I will put this into in answer. I don't know exact reason, however: The pattern in bottom left region looks similar to your second example, and pattern in right bottom corner seems very like to your first example, when inspected closely. The question is, how much variety is in your source data? If all 50 000 images are variations of same pattern, these 3 meaningful feature maps we see can be quite enough for autoencoder to explain and reconstruct all your data. Second, you might want to look at reconstruction error and actual reconstructed images. How good results are? If reconstruction error is low, you have might have an overfit, perhaps due to resons described below (or maybe combination of these 3 patterns is just enough to describe all data in interested in). Otherwise, autoencoder just can't learn how to reconstruct your data and you need larger autoencoder or better training algorithm.
