[site]: crossvalidated
[post_id]: 97620
[parent_id]: 97511
[tags]: 
Posterior probabilities as statistics $T$ is some statistics of the data observed - and as such has a sampling distribution. This is actually not the case. $T = P \left(\theta > 0 \mid \text{data}\right)$ as you have defined it is just a posterior probability. It is, strictly speaking, not a statistic. That is, it is not a measure of the data. It does change with the data observed, but it does not have a sampling distribution in the classical sense. Here's another way to look at the issue. Given that you believe in your likelihood & prior specification, your uncertainty about $\left( \theta \mid \text{data} \right)$ is completely characterized by the posterior distribution . The more data you collect, the more confident the posterior of $\left( \theta \mid \text{data} \right)$ will be by a mathematically appropriate amount. For an example, consider a beta-binomial model. $y \sim \text{Binomial}(n, \phi)$ where $\phi = 0.8$ secretly, but we give the prior $\phi \sim \text{Beta}(1,1) = \text{Uniform}(0,1)$. We can simulate $y$ for different $n$ (which generalizes to the size of the data) and watch our posterior distribution on $\left( \phi \mid \text{data} \right)$. Here are some horizontal-scale-constant plots for $n = 10, 50, 1000$. As you can see, our belief about $\phi$ given the data changes dramatically in shape with the data size. This corresponds to the natural idea that the data is changing our ideas about $\phi$ in such a way that we grow more and more confident about what $\phi$ is with more and more data. With this particular model the posterior variance decreases with the data size. The useful idea of looking at a high-probability range of $\phi \mid \text{data}$ is analogous (and in special cases mathematically equivalent to) the confidence interval under the frequentist paradigm. You might want to look at Bayesian credible intervals . Bayesian credible intervals have Frequentist coverage probabilities which are often very close to the Bayesian coverage level. This book (which I found relatively approachable) has a small discussion on the topic and can point you towards academic sources. Testing with posterior probabilities The cool thing would be having a frequentist test proceedure and instead of messing around with 'almost' significant p-values you just report the statistic $T$ itself? You certainly could report $T$, as that would be your posterior belief that $\theta > 0$. Since the Bayesian paradigm doesn't take into account hypothesis preference (i.e., favor the null), when making decisions it is useful to consider the cost of a particular decision. For example, a particular super market chain may have a posterior belief that a certain kind of cereal will sell worse this upcoming season, but they wouldn't want to remove this cereal completely from stock unless their posterior belief were high enough. They can minimize their risk by assigning different costs to each decision (e.g., accept/reject the null). For example., you might prefer the null hypothesis 7 times as much as the alternative. This lecture is an excellent primer on this particular aspect of Bayesian inference/decision-making (and actually brings up a way to deal with the null-hypothesis-is-a-point concern of queenbee). Bayes factors are another notable model selection approach which can be used to assess the relative merits of different models in the Bayesian paradigm. They have been compared to Frequentist p-values in the sense that they can quantify the weight of evidence on each side of the hypothesis tug-of-war.
