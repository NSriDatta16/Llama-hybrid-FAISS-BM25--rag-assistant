[site]: crossvalidated
[post_id]: 545421
[parent_id]: 545418
[tags]: 
I have seen some papers that are removing f from test data but not the training data. In that case, say a model m trained on the original train data has a performance of p" on the modified test data and p" is still not significantly different from p. From that, they are saying that f is not important for m to solve C. Is this a valid conclusion? How is even possible to evaluate the model? When you remove a feature from the test set you should encounter a shape mismatch error. Let consider a simple Logistic Regression with training data having n_features. The model weights will have shape (n_classes, n_features) and the test data (n_features -1 ). So you will not be able to get predictions. Not possible to multiply matrix of size (n_classes, n_features) and (n_features-1, n_examples). Instead, I propose to use a more sophisticated method to measure a feature's importance. There are plenty of methods to measure the importance of an input feature. The brightest idea that I came across is called SHAP . In this approach, you leverage Shapley's value, which is a cooperative game theory concept used to fairly distribute a profit of a given coalition. I think it is a little bit pointless to copy-paste the content of the Shap paper, so I just share a link to it. EDIT: Replacing with constant value is, in my opinion, not a good idea. Let consider a dummy problem of predicting if a person is pregnant. Our data consist of the following features: Sex Age Health conditions Let say, that you would like to measure the importance "AGE" feature. The outcome of your experiments will depend on the value that you pick. Let say that you replace AGE:= 70. In this case, you may come to the conclusion that this feature is irrelevant since the model will always return a correct value, regardless of the rest of the features. However, if you replace AGE:=25 the outcome will be different. Shap allows you to measure feature importance as a function of a feature value. For instance, a feature RM (see attached figure) is meaningless if its value is less than 6 and becomes significant when it is above 7.
