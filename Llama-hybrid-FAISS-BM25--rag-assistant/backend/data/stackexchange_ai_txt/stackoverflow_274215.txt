[site]: stackoverflow
[post_id]: 274215
[parent_id]: 274196
[tags]: 
Perhaps the answer is to pre-filter the arrays in a way analogous to the Filtering used to create small PNG images . Here are some ideas right off the top of my head. I've not tried these approaches, but if you feel like playing, they could be interesting. Break your ints up each into 4 bytes, so i 0 , i 1 , i 2 , ..., i n becomes b 0,0 , b 0,1 , b 0,2 , b 0,3 , b 1,0 , b 1,1 , b 1,2 , b 1,3 , ..., b n,0 , b n,1 , b n,2 , b n,3 . Then write out all the b i,0 s, followed by the b i,1 s, b i,2 s, and b i,3 s. If most of the time your numbers differ only by a bit or two, you should get nice long runs of repeated bytes, which should compress really nicely using something like Run-length Encoding or zlib. This is my favourite of the methods I present. If the integers in each array are closely-related to the one before, you could maybe store the original integer, followed by diffs against the previous entry - this should give a smaller set of values to draw from, which typically results in a more compressed form. If you have various bits differing, you still may have largish differences, but if you're more likely to have large numeric differences that correspond to (usually) one or two bits differing, you may be better off with a scheme where you create ahebyte array - use the first 4 bytes to encode the first integer, and then for each subsequent entry, use 0 or more bytes to indicate which bits should be flipped - storing 0, 1, 2, ..., or 31 in the byte, with a sentinel (say 32) to indicate when you're done. This could result the raw number of bytes needed to represent and integer to something close to 2 on average, which most bytes coming from a limited set (0 - 32). Run that stream through zlib, and maybe you'll be pleasantly surprised.
