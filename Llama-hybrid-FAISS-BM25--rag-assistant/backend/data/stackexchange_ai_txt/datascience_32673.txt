[site]: datascience
[post_id]: 32673
[parent_id]: 32671
[tags]: 
A Generative Adversarial Network (GAN) takes the idea of using a generator model to generate fake examples and discrimator model that tries to decide if the image it receives is a fake (i.e. from the generator ) or a real sample. This was originally shown with relatively simple fully connected networks. A Deep Convolution GAN (DCGAN) does something very similar, but specifically focusses on using D eep C onvolutional networks in place of those fully-connected networks. Conv nets in general find areas of correlation within an image, that is, they look for spatial correlations. This means a DCGAN would likely be more fitting for image/video data, whereas the general idea of a GAN can be applied to wider domains, as the model specifics are left open to be addressed by individual model architectures. The linked paper that proposed DCGANs specifically raises the topic of unsupervised-learning , and essentially wanted to marry the (at the time) recent success of conv nets with the new idea of GANs. I also couldn't find any direct comparisons of when to use them, but there are plenty of articles that explain both models. This is a good place to start - after reading that, you could probably decide for yourself. Regarding dimensions - I don't think the dimensions of your data would dictate which of the two variants to go for, other than of course influencing things that we always have to consider, such as training time, model complexity, capacity to learn and so on.
