[site]: crossvalidated
[post_id]: 317167
[parent_id]: 
[tags]: 
Is reward function needed to be continuous in deep reinforcement learning

Is reward function needed to be continuous in deep reinforcement learning? It should be noted that the reward is used for gradient computation The algorithm I used is Proximal Policy Gradient(Schulman J, Wolski F, Dhariwal P, et al. Proximal policy optimization algorithms [J]. arXiv preprint arXiv:1707.06347, 2017.) The objective function is as follows: The advantage is denoted as A^hat above, and it is derived from: And you can see that A is from state-action value and state value, which are derived from immediate reward.
