[site]: crossvalidated
[post_id]: 126439
[parent_id]: 
[tags]: 
Full batch backpropagation implementation

I am trying to wrap my head around using batch backprop in a neural network. I have a very code-oriented mind, and I'm trying to figure out whether it's possible to parallelize the full batch backpropagation algorithm. Say, if the dataset is split up in 100. 100 threads are spawned, and each thread will accumulate the gradients. In the next step, these accumulated gradients are averaged. How would something like this look in pseudocode, not in math equations?
