[site]: datascience
[post_id]: 81853
[parent_id]: 
[tags]: 
Matrix notation in Sutton and Barto

On pg. 206 of Barto and Sutton's Reinforcement Learning , there is a curious statement about the result of a scalar product: As I interpret it, A is the expectation of a scalar product of two d -dimensional vectors: which should be a scalar, right? So how do they get a dxd -matrix from it? Is it a shorthand for a scalar matrix (diagonal with the repeated coefficient, namely this scalar product)?
