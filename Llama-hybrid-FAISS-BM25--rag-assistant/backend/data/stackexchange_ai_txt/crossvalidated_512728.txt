[site]: crossvalidated
[post_id]: 512728
[parent_id]: 
[tags]: 
Sigmoid function in logistic regression

Normally I used $g(z)= \frac{1}{1+e^{-z}}$ as the sigmoid function, what is the difference when modify it to $g(z) = \frac{e^{-z}}{1+e^{-z}}$ ? Both are using the binary cross entropy loss to train the model. For the logistic regression model $h() = {({^} )}$ , and modify the original sigmoid function to $g(z) = \frac{e^{-z}}{1+e^{-z}}$ . I have never seen the new sigmoid function, so I would like to know the model prediction rule, and the learnt model parameters differ from the conventional logistic regression.
