[site]: crossvalidated
[post_id]: 429754
[parent_id]: 277643
[tags]: 
The beta distribution can be seen as the distribution of probabilities in the center of a jittered distribution First of all, I am not good in mathematically precise descriptions of concepts in my head, but I'll try my best using a simple example: Imagine you have a bow, many arrows and a target. Let's further say your hit rate $\lambda$ (for hitting the target) is precisely a function of the distance to the center of the target and of the following form \begin{eqnarray} \lambda=g(x)=\lambda_{max}-(q|x-x_0|)^\frac{1}{q},~q > 0,~0 \leq \lambda \leq \lambda_{max} \end{eqnarray} where x is the distance to the center of the target ( $x_0$ ). For $q=1/2$ this would be a first order approximation of a Gaussian. That would mean that you most frequently hit the bull-eye. Similarly, it approximates any bell-shaped curve, for example, resulting from diffusion of Brownian particles. Now, let is furthermore assume that somebody really brave/stupid tries to trick you and displaces the target on every shot. Thereby we make $x_0$ itself to be a random variable. If the distribution of that person's movements can be described by a (p-1)-power of $g(x)$ (that is $P(x_0) = C\cdot g(x)^{p-1})$ ), a simple transformation of random variables (remember $P(\lambda)d\lambda=P(x_0)dx_0$ ) leads to a Beta distributed $\lambda$ : \begin{eqnarray}P(\lambda) = P(g^{-1}(\lambda)) \biggl|\frac{dg^{-1}(\lambda)}{d\lambda}\biggl| = C' \cdot \lambda^{p-1} \cdot (\lambda_{max} - \lambda)^{q-1}\end{eqnarray} where the normalization constant $C'$ is the beta function. For the standard parametrization of the beta distribution we would set $\lambda_{max} = 1$ . In other words the beta distribution can be seen as the distribution of probabilities in the center of a jittered distribution. I hope that this derivation gets somewhat close to what your instructor meant. Note that the functional forms of $g(x)$ and $P(x_0)$ are very flexible and reach from triangle like distributions and U-shaped distributions (see example below) to sharply peaked distributions. FYI: I discovered this as a side effect in my doctoral work and reported about it in my thesis in the context of non-stationary neural tuning curves leading to zero-inflated spike count distributions (bimodal with a mode at zero). Applying the concept described above yielded the Beta-Poisson mixture distribution for the neural acticity. That distribution can be fit to data. The fitted parameters allow to estimate both, the distribution $g(x)$ as well as the jitter distribution $p(x_0)$ by applying the reverse logics. The Beta-Poisson mixture is a very interesting and flexible alternative to the widely used negative binomial distribution (which is a Gamma-Poisson mixture) to model overdispersion. Below you find an example the "Jitter $\rightarrow$ Beta" - idea in action: A : Simulated 1D trial displacement, drawn from the jitter distribution in the inset ( $P(jitter)\propto g(x)^{p-1}$ ). The trial-averaged firing field (solid black line) is broader and has a lower peak rate as compared to the underlying tuning curve without jitter (solid blue line, parameters used: $\lambda_{max} = 10, p = .6, q=.5$ . B : The resulting distribution of $\lambda$ at $x_0$ across N=100 trials and the analytical pdf of the Beta distribution. C : Simulated spike count distribution from a Poisson process with parameters $\lambda_i$ where i denote the indices of the trials and the resulting Beta-Poisson distribution as derived as sketched above. D : Analogous situation in 2D with random shift angles leading to the identical statistics.
