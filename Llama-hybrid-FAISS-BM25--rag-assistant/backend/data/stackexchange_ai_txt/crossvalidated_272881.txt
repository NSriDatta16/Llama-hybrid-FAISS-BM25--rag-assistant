[site]: crossvalidated
[post_id]: 272881
[parent_id]: 
[tags]: 
regression with constraints

I have some domain knowledge I want to use in a regression problem. Problem statement The dependent variable $y$ is continuous. The independent variables are $x_1$ and $x_2$. Variable $x_1$ is continuous and positive. Variable $x_2$ is categorical, ordered, and takes only few different values (i.e, less than 10). I want to fit a regression function $f$ so that $y = f(x_1,x_2)$, with the constraints $f(x_1,x_2)$ is monotonically increasing in $x_1$ $f(x_1,x_2)$ is bounded in $[0,1]$ $f(x_1,x_2)$ is "smooth" in $x_2$ These constraints come from domain knowledge of the problem. Samples are evenly distributed among $x_2$ but not $x_1$. My question: which techniques do you recommend for such regression problem? I'm currently ignoring the last two constraints, and using the monreg package . (I run one regression for each possible value of $x_2$) I can not give a formal definition of "smooth" in this context. I can assume that $f(x_1,x_2)$ does not change much along $x_2$ values that are consecutive. I have found some SO questions regarding this issue but it looks like they have not raised much attention, or are very focused on specific R packages. Q1 Q2 Problem context: This regression will be used as a function approximation of (a component) the value function in a reinforcement learning algorithm . Because of that the constraints have to be enforced by the regression model, and can not be hand controlled. Moreover, the regression will be run several times with increased number of samples.
