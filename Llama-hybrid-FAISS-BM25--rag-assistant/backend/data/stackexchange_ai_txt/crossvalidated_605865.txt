[site]: crossvalidated
[post_id]: 605865
[parent_id]: 
[tags]: 
What is fixed and what varies in the bias-variance decomposition?

I am reading about the bias-variance decomposition from An Introduction to Statistical Learning with Applications in R (Second edition at page 34). It states that $$Y = f(X) + \epsilon$$ where the term $\epsilon$ is random. Does $Y$ vary? It then calculates the expected test MSE at $x_0$ as: $$ E (y_0 - \hat{f}(x_0))^2$$ Well since $Y$ depends on $\epsilon$ shouldn't also be random irrespectively of the fact that we conditioned on $x_0$ ? Shouldn't the expected test MSE be: $$E(Y - \hat{f}(x_0))^2 = \text{Var}(\hat{f(x_0)}) + [\text{Bias}(\hat{f}(x_0))]^2 + \text{Var}(\epsilon)$$ That is, we not only averaging over the training sets that produce $\hat{f}$ but also over the different values of $Y$ given $x_0$ ? Is the training set size fixed? Furthermore, authors say that: this expected test MSE is the average test MSE that we would obtain if we repeatedly estimated $f$ using a a large number of training sets and each test at $x_0$ . But they don't specify if the size of the training sets is fixed or varies. If it varies shouldn't the term $\text{Var}(\hat{f(x_0)})$ decrease as the training set size increases? Can someone help me understand what is fixed and what varies in the bias-variance decomposition?
