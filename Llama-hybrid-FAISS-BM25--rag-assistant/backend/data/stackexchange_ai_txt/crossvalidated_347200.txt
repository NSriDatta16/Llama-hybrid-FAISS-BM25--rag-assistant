[site]: crossvalidated
[post_id]: 347200
[parent_id]: 
[tags]: 
Can't Validate Model Result

This is my first question and I am still new to data science and statistics, so please forgive me if this is a dumb or ill-posed question. I have two ensemble tree classifier models built on the same set of about 40 mixed continuous/categorical features - one a random forest, the other an XGB model. Both models rank a particular continuous feature (call it X1) very highly on the feature importances list; but when I look at X1 vs. Y, or any plausible X1 vs. X2 I can think of, I can't see any separation or pattern in the classes. I also don't see strong correlation/association between X1 and any other features. In other words, I don't understand why the models select this feature as important, and thus how I can use this insight to help take action based on the model. The other features the models select do suggest some interesting actions, but this one does not. I will work on non-tree-based models to see if they also select X1, but in general, do you have any advice for how to handle situations like these? What should I do next, to investigate and validate what the model says is important? Thanks in advance for any advice to a newbie.
