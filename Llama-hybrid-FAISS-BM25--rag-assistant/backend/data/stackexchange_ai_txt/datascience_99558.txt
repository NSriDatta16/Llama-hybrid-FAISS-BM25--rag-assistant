[site]: datascience
[post_id]: 99558
[parent_id]: 98361
[tags]: 
First of all: probably you should not train with the loss you propose, because with MSE you will train to minimize the total error, not to keep the features as they were, which is what CNNs are good at detecting; this is the same problem as what happens when you train an image autoencoder on MSE, that you obtain blurry images . Instead, configure the network as you want, reusing layers from the networks you deem appropriate, with the needed adaptation layers, and then train the whole network on the task that you need your network to do (e.g. classification). When doing so, you can choose to only train some parts of the network, or train them at different learning rates. These are some potential alternatives: Freeze all the layers except the adaptation ones. The original weights of the reused layers will remain as they originally were. Train the adaptation layers at a normal learning rate and the other layers at a very small learning rate. This is typical of transfer learning setups and it aims at making the learning more flexible.
