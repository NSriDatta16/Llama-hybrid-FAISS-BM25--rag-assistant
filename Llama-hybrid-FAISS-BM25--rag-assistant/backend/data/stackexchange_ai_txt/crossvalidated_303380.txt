[site]: crossvalidated
[post_id]: 303380
[parent_id]: 250277
[tags]: 
Following up on mkt's excellent response: From my own personal experience developing predictive models in the health insurance field, incorporating random effects into predictive models (including machine learning models) has a number of advantages. I'm often asked to build models predicting future claims outcomes for (e.g., future health expenses, length of stay, etc.) based on an individual's historical claims data. Frequently there are multiple claims per individual with correlated outcomes. Ignoring the fact that many claims are shared by the same patient would be throwing out valuable information in a predictive model. One solution would be to create fixed effect indicator variables for each member in the dataset and use a penalized regression to shrink each of the member-level fixed effects separately. However, if there are thousands or millions of members in your data, a more efficient solution from both computational and predictive standpoints may be to represent the multiple member-level fixed effects as a single random effect term with a normal distribution.
