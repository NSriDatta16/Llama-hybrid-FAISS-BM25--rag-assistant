[site]: datascience
[post_id]: 114310
[parent_id]: 
[tags]: 
RNN for continuous, real-time learning without pre-training

I am learning ML and I'm trying to solve this problem Create a rock paper scissors game where the AI is able to beat the player more than 50% of the time. My initial intuition was to use an RNN with an LSTM. I imagined my AI analyzing the history of the moves made by P1 and guessing what the next one might be. Now, here's my problem. I did not want to come up with a bunch of data to train the model with beforehand but rather, have the model learn in real-time how each player plays and gradually get better during the game until it can reasonably well predict that player's moves. After struggling for a while thinking about this, I googled the prompt and read up on others' solutions. All 3 I looked at went with the route of pre-training. Creating complex algorithms that could generate a semi-random sequence of moves ( r,p,s,s,p,etc.. ) and using that to train the model. My concern with doing it this way is that it causes a heavy reliance on prior data to be good vs. how the player in front of me is playing right now. In order for my AI to be good, I would need to spend a significant amount of time creating (broad) training data to train it instead of learning from the player I'm up against. Is this the way things must be done? Is what I'm envisioning possible, and is that the right approach to solve the problem?
