[site]: datascience
[post_id]: 84287
[parent_id]: 
[tags]: 
Custom loss function with both min(y, p) and max(y,p)

I'm creating a neural network in tensorflow and need to minimize the following loss function: $\frac{max(y,p)}{min(y,p)}$ Where $y$ represents the true value and $p$ the predicted value. Since the loss function is not differentiable it becomes a problem when using gradient descent. Update, now I'm trying to implement: $p > y \rightarrow loss = log(p)-log(y)$ $p $p = y \rightarrow loss = log(y)-log(y) = log(p)-log(p)$ This is my code: def custom_loss(y_true, pred): if pred > y_true: custom_loss = K.log(pred) - K.log(y_true) elif pred But I get the following error: tensorflow.python.framework.errors_impl.InvalidArgumentError: The second input must be a scalar, but it has shape [32] [[{{node gradient_tape/custom_loss/cond/StatelessIf/gradient_tape/custom_loss/weighted_loss/Mul/_17}}]] [Op:__inference_train_function_1040] The code can run when I have batch_size = 1
