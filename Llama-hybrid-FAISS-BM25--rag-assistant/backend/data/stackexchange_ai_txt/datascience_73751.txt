[site]: datascience
[post_id]: 73751
[parent_id]: 57639
[tags]: 
In convolution layers, weights are the filter values. Weights of a CNN network is determined by the number and size of filters. Weights doesn't depend on shape of input image. Filters of pre-trained network are capable of detecting different features in an image. Consider sobel filter which detects edges in an image. A 3x3 sobel filter can be used to detect edges in an image of any size. Similarly, those filters can be reused instead of again learning from scratch. That's why, weights of CNN network can be transferred to another CNN network with different input shape. However, number of layers, no. of filters, filter sizes and number of image channels must be same. For transfer learning, best practices would be to use pre-trained model for similar task and don't change the input shape to very small or large. On the other hand, weights of Fully Connected(Dense) layer can't be transferred. Because, those weights depend on image size. Dense layers at the end of CNN network should be cut off and recreated to adopt to change in image size. It would be more clear if you get to know how the trainable parameters are calculated in CNN and Dense layers. It would be very long if I try to explain in this answer. You can google search on that.
