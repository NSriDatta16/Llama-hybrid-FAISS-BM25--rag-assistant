[site]: crossvalidated
[post_id]: 16526
[parent_id]: 13114
[tags]: 
This will not be an answer, since it will reduce your problem to another one, but I think it might be useful. Your question is basically about consistency of M-estimator. So first we can look at the general results. Here is the result from van der Vaart book (theorem 5.7, page 45): Theorem Let $M_n$ be random functions and let $M$ be a fixed function of $\theta$ such that for every $\varepsilon>0$ $$\sup_{\theta\in\Theta}|M_n(\theta)-M(\theta)|\xrightarrow{P}0,$$ $$\sup_{\theta:d(\theta,\theta_0)\ge\varepsilon} M(\theta) Then any sequence of estimators $\hat\theta_n$ with $M_n(\hat\theta_n)\ge M_n(\theta_0)-o_P(1)$ converges in probability to $\theta_0$ In your case $\theta_0=\mu$ , $M(\theta)=E\rho(|X-\theta|)$ and $M_n(\theta)=\frac{1}{n}\sum \rho(|X_i-\theta|)$ The key condition here is the uniform convergence. In page 46 van der Vaart says that for averages which is your case this condition is equivalent to set of functions $\{m_\theta, \theta\in\Theta\}$ ( $m_\theta=\rho(|x-\theta|)$ in your case) being Glivenko-Canteli . One simple set of sufficient conditions is that $\Theta$ be compact, that the functions $\theta\to m_\theta(x)$ are continuous for every $x$ , and that > they are dominated by an integrable function. In Wooldridge this result is formulated as theorem called Uniform Weak Law of Large Numbers, page 347 (first edition), theorem 12.1. It only adds measurability requirements to what van der Vaart states. In your case you can safely pick $\Theta=[\mu-C,\mu+C]$ for some $C$ , so you need to show that there exists function $b$ such that $$|\rho(|x-\theta|)|\le b(x)$$ for all $\theta\in\Theta$ , such that $Eb(X) . Convex function theory might be of help here, since you basicaly can take $$b(x)=\sup_{\theta\in\Theta}|\rho(|x-\theta|)|.$$ If this function has nice properties then you are good to go.
