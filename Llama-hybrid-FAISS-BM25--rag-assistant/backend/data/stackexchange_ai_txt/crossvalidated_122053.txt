[site]: crossvalidated
[post_id]: 122053
[parent_id]: 121990
[tags]: 
Why invent new/untested methodology when there are appropriate methods for dealing with this situation? In particular, there is the binomial-normal model that does not invoke the usual normal approximation for the sampling distribution of the estimates and instead is directly based on the binomial distribution (the 'normal' part only comes in for the random effects used to model heterogeneity). See, for example: Stijnen, T., Hamza, T. H., & Ozdemir, P. (2010). Random effects meta-analysis of event outcome in the framework of the generalized linear mixed model with applications in sparse data. Statistics in Medicine, 29, 3046â€“3067. Here is an example using R: library(metafor) dat This yields the output: Random-Effects Model (k = 14; tau^2 estimator: ML) logLik deviance AIC BIC AICc -32.6054 30.1105 69.2109 70.3018 70.4890 tau^2 (estimated amount of total heterogeneity): 0.5893 tau (square root of estimated tau^2 value): 0.7677 I^2 (total heterogeneity / total variability): 67.79% H^2 (total variability / sampling variability): 3.10 Tests for Heterogeneity: Wld(df = 13) = 25.0979, p-val = 0.0224 LRT(df = 13) = 42.2324, p-val The analysis is done on the log-odds scale. For easier interpretation, one can back-transform the results: predict(res, transf=transf.ilogit) This yields: pred ci.lb ci.ub cr.lb cr.ub 0.7984 0.6924 0.8746 0.4426 0.9518 So, an estimated improvement rate of almost 80% (CI: 69% to 87%). Due to considerable heterogeneity, the credible/prediction interval is much wider (44% to 95%). If you want to stick to Stata, the following syntax should work: xtmelogit xi || id:, binomial(ni) ( xi and ni are the number of cases and trials and id is a study id variable). Here are the results from Stata using the same data: Mixed-effects logistic regression Number of obs = 14 Binomial variable: ni Group variable: id Number of groups = 14 Obs per group: min = 1 avg = 1.0 max = 1 Integration points = 7 Wald chi2(0) = . Log likelihood = -32.605433 Prob > chi2 = . ------------------------------------------------------------------------------ xi | Coef. Std. Err. z P>|z| [95% Conf. Interval] -------------+---------------------------------------------------------------- _cons | 1.3766 .2883857 4.77 0.000 .8113745 1.941826 ------------------------------------------------------------------------------ ------------------------------------------------------------------------------ Random-effects Parameters | Estimate Std. Err. [95% Conf. Interval] -----------------------------+------------------------------------------------ id: Identity | sd(_cons) | .7676753 .279763 .375816 1.568122 ------------------------------------------------------------------------------ LR test vs. logistic regression: chibar2(01) = 12.12 Prob>=chibar2 = 0.0002 Except for the LRT (which is calculated in different ways in R and Stata), the results match up nicely.
