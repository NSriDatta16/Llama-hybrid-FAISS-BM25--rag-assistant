[site]: crossvalidated
[post_id]: 440457
[parent_id]: 
[tags]: 
Regression problem where target has Gaussian distribution

I am trying to build a regression model where the target values from the training dataset have a gaussian-like distribution. When I try different types of models (MLP, RandomForest, etc), they all end up predicting values close to the mean and fail to predict values that are further away from the center of data. My input data is normalized floating-point values with 15 features and with using neural networks I'm using mean squared error as loss function. How should I change my model (or data) so that it learns to predict outliers? I've considered a loss function that adds an extra penalty when the ground-truth value is an outlier but haven't tried it yet.
