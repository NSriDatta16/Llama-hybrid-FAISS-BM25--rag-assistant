[site]: datascience
[post_id]: 58263
[parent_id]: 
[tags]: 
Interpretation of PCA visualisation

I am trying to build a classifier to predict the ratings of a show during a specific time. I have extracted around 109 features, some relating to the time field namely, Day of Year Month of year Is on a weekend? During business hours? Public Holiday? I also included some categorical features and used a label binariser for which channel it appeared on, and the broadcaster. I wanted to check the linearity of the dataset, which would inform me as to whether a linear regressor could be used or something non-linear like a neural network. I decided to do dimensionality reduction using PCA in order to visualise if the dataset was linearly separable in 2D. from sklearn.decomposition import PCA pca = PCA(n_components=2) data_scaled = pca.fit_transform(df[cols]) plt.plot(data_scaled[:,0], data_scaled[:,1], 'ro') plt.xlabel('first component') plt.ylabel('second component') plt.show() I am very confused by the result and am not able to interpret this. The plot of the first component: The plot of the second component: What could the PCA results tell? What would cause these graphs?
