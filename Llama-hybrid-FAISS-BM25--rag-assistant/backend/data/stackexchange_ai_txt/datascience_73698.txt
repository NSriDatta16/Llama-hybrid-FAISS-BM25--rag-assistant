[site]: datascience
[post_id]: 73698
[parent_id]: 73390
[tags]: 
If anyone's wondering, yes it is right. The weight-clipping WGAN is very sensitive to changes in the weight-clipping hyperparameter, which is probably causing this. Upgrading to the gradient descent version fixed it. Loss should look like this btw
