[site]: crossvalidated
[post_id]: 322802
[parent_id]: 
[tags]: 
Per Image Normalization vs overall dataset normalization

I am confused whether the standardization (subtract mean and divide by std) should be done per image basic or across the overall dataset. While overall dataset makes more sense, popular libraries like TensorFlow provide functions like tf.image.per_image_standardization that does the following. Linearly scales image to have zero mean and unit norm. This op computes (x - mean) / adjusted_stddev, where mean is the average of all values in image, and adjusted_stddev = max(stddev, 1.0/sqrt(image.NumElements())). stddev is the standard deviation of all values in image. It is capped away from zero to protect against division by 0 when handling uniform images. Is this good enough?
