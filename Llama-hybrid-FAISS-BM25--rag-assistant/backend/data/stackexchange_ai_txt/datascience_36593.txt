[site]: datascience
[post_id]: 36593
[parent_id]: 
[tags]: 
Own Implementation of Neural Networks heavily under fitting the data

I tried to implement a Basic Deep Neural Network Algorithm for a classification problem on my own. I have tried on the iris data set for this test but, my implementation has been giving me very poor results, it's heavily under-fitting the data, the best accuracy I get is 66 % and the least even goes to 0 %, for every run of my algorithm , I get heavily varying results even after I've set a low randomness seed. I've chosen a tanh activation function, a learning rate of 0.01, a softmax activation for the output layer and a Standard Scalar normalization on the input variables. So, I'm wondering whether I'm doing any of the math part wrong, or missing any fundamental part of this algorithm, any advice or correction is much appreciated. Thank you so much in advance. Here's the code: data = load_iris() X = data.data y = data.target class Neural_Network: def __init__(self, n_hlayers, n_nodes, lr): #No. of hidden layers self.n_layers = n_hlayers #No. of nodes in each of the hidden layer self.n_nodes = n_nodes #Learning rate of the algorithm self.lr = lr # Dictionary to hold the node values of all the layers self.layers = { } # Dictionary to hold the weight values of all the layers self.weights = { } def _softmax(self,values): '''Function to perform softmax activation on the node values returns probabilities of each feature''' exp_scores = np.exp(values) probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) return probs def _derivate_tanh(self,values): '''Function that performs derivative of a tanh activation function''' #Derivative of tanh is 1 - tanh^2 x return (1 - np.power(values, 2)) def fit(self,X,y): '''This function constructs a Neural Network with given hyper parameters and then runs it for given no. of epochs. No. of nodes in all the hidden layers are the same for simplicity's sake. returns: None / NA''' print('Fitting the data ') try: X = np.array(X) y = np.array(y) except: print('Could not make sense of the inputs') # No. of examples and the dimensions of each sample self.num_examples, self.features = X.shape #Setting default layers #Input layer self.layers['input'] = np.zeros(shape=[1,self.features]) #Hidden layers for i in range(1, (self.n_layers+ 1 )): self.layers['layer-1' + str(i)] = np.zeros(shape=[1,self.n_nodes]) #Output layer self.layers['output'] = np.zeros(shape=[1, len(np.unique(y)) ]) #Setting random weights for i in range(1, (self.n_layers+2)): #Weights for first layer if i == 1: self.weights['weight-1' + str(i)] = np.random.uniform(low=0.1, high = 0.2, size=[self.features, self.n_nodes]) #Weights for hidden layer elif i 1: #Delta / Error values for the weights in the hidden layers self.delta['delta_1' + str(i)] = self.delta['delta_1' + str(i+1)].dot( self.weights['weight-1' + str(i+1)]) * self._derivate_tanh(self.layers['layer-1' + str(i)]) #Gradient / Slope values for the weights of hidden layers self.gradients['grad_1' + str(i)] = self.layers['layer-1' + str(i-1)].T.dot( self.delta['delta_1' + str(i)]) #Adjusting weights of the hidden layer self.weights['weight-1' + str(i)] = self.weights['weight-1' + str(i)] - ( self.lr * self.gradients['grad_1' + str(i)]) #Adjusting weights which are matrix-multipled with the input layer else: # Delta / Error values for the weights that come after the input layer self.delta['delta_inp'] = self.delta['delta_1' + str(i+1)].dot( self.weights['weight-1' + str(i+1)]) * self._derivate_tanh( self.layers['layer-1' + str(i)]) #Gradient / Slope values for the weights that come after the input layer self.gradients['grad_1' + str(i)] = self.layers['input'].T.dot(self.delta['delta_inp']) #Adjusting weights self.weights['weight-1' + str(i)] = self.weights['weight-1' + str(i)] - ( self.lr * self.gradients['grad_1' + str(i)]) Here's a sample result: ob = Neural_Network(5, 50, 0.01) ob.fit(X,y) Please choose no.of epochs: 800 Accuracy in epoch 0 is : 0.17333333333333334 Accuracy in epoch 100 is : 0.18 Accuracy in epoch 200 is : 0.18 Accuracy in epoch 300 is : 0.18 Accuracy in epoch 400 is : 0.18 Accuracy in epoch 500 is : 0.18 Accuracy in epoch 600 is : 0.18 Accuracy in epoch 700 is : 0.18
