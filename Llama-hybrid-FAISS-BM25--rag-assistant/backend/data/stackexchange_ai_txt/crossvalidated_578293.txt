[site]: crossvalidated
[post_id]: 578293
[parent_id]: 
[tags]: 
Initialize weights with the same value

I know that there are a lot of topics about it but I still don't understand something. People say that if we initialize weights of a neural network with the same value there is no learning because the gradient is the same for each weight (so the weights are updated in the same way). However, for me, this assumption is false. Let's introduce an easy example : 2 neurons in input and 1 neuron in output. The weights are $w_1$ and $w_2$ and are initialized with the same value (different of zero). The output of the network is equal to $w_1x_1 + w_2x_2$ . For a single data, the loss is $(y-w_1x_1 - w_2x_2)^2$ . The gradient of the loss with respect to $w_1$ is $-2(y-w_1x_1 - w_2x_2)x_1$ and with respect to $w_2$ is $-2(y-w_1x_1 - w_2x_2)x_2$ . The fact that the value of the weights is the same doesn't change this, the gradient is with respect to a variable, not a value. These two gradients are different so the two weights won't be the same after the update of the stochastic gradient descent. So where is the problem ? Thank you !
