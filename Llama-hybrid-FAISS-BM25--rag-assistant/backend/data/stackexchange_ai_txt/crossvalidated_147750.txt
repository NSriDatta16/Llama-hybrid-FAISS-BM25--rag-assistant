[site]: crossvalidated
[post_id]: 147750
[parent_id]: 147745
[tags]: 
Yes, the result should be the same (aside from any computation round-off error). Go ahead and try it! PCA is simply a singular-value decomposition on the centered data matrix, X . Thus, it amounts to an additive representation of orthogonal components: $$\textbf{X} = \textbf{U}\textbf{D}\textbf{V}^T = \sum_{i=1}^n \sigma_i\textbf{u}_i\textbf{v}_i^T$$ Where $\textbf{D}$ is a diagonal matrix with diagonal elements $\{\sigma_1,\dots,\sigma_p\}$ and $\textbf{u}_i$ are the left singular vectors (columns of $\textbf{U}$) and $\textbf{v}_i^T$ are the right singular vectors (rows of $\textbf{V}$). Therefore, the n-m dimensional representation truncates this sum after n-m terms. The n-1 representation truncates this sum after n-1 terms. By taking away the last term in the sum, you've reduced the dimensions by 1. If you were to compute another SVD on the resulting matrix, you'd end up with the same exact terms in the summation. (Of course when trying this out, you have to keep in mind that singular vectors (and thus PCs and scores) are unique up to a sign (+/-) (in most practical cases, that is - when geometric multiplicity of all eigenvalues is 1, if people want to get pedantic - otherwise they are not unique at all) So try this out on the iris data in R: x=princomp(iris[,1:4]) y=princomp(x$scores[,1:3]) round(abs(x$scores[,1:2])-abs(y$scores[,1:2]),13)==0 Take the absolute value because the sign of second PC of y is actually opposite the second PC of x. Round the difference between the values to 13 decimal places because, like I said, roundoff error bound to be an issue. Then test that there is no difference. Comp.1 Comp.2 [1,] TRUE TRUE [2,] TRUE TRUE [3,] TRUE TRUE [4,] TRUE TRUE [5,] TRUE TRUE [6,] TRUE TRUE [7,] TRUE TRUE [8,] TRUE TRUE [9,] TRUE TRUE [10,] TRUE TRUE [11,] TRUE TRUE [12,] TRUE TRUE [13,] TRUE TRUE [14,] TRUE TRUE [15,] TRUE TRUE ETC.
