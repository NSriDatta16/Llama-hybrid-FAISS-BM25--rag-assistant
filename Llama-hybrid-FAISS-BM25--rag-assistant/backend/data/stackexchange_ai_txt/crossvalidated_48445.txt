[site]: crossvalidated
[post_id]: 48445
[parent_id]: 
[tags]: 
Predicting continuous variables from text features

I want to predict a continuous variable from text features. Lets say I have some student essays and I want to predict their quality, as measured by a human grader, using text features (mostly words they use). Linear regression is an obvious candidate, but if I have substantially more features than graded essays, this probably won't do well. If I wanted to classify them into good/bad, I might try the Naive Bayes classifier. I don't, but maybe I can draw inspiration from that. As I understand, Naive Bayes draws its power from assuming feature independence. Is there such a thing as Naive Multivariate Linear Regression, where you assume feature independence? I think this is the same as using Univariate Linear Regression for each regression coefficient. I would expect that to run into problems quickly, though. Is there something halfway between these two models? Putting a prior distribution on feature covariance that mostly expects conditional independence? Other models I should consider? Bayesian models preferred.
