[site]: datascience
[post_id]: 25509
[parent_id]: 25348
[tags]: 
You can train xgboost, calculate the output (margin) and then continue the training, see example in boost from prediction . Iâ€˜ve not tried it myself, but maybe you could train on the first subset of your data (say 10%) and then continue on another subset, etc. Update Step by step procedure Split the data into N manageable subsets, set n=1 Train xgboost on n-th subset Calculate the prediction (margin) for n+1 subset using the model obtained from previous Add the margin into the n+1 subset via setinfo Increment n Steps 2-5 to be repeated N times.
