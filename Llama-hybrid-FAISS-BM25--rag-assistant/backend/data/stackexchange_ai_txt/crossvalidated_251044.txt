[site]: crossvalidated
[post_id]: 251044
[parent_id]: 242560
[tags]: 
The reason is that there is sort of a proof. The initial important paper is, "Stein, C. (1956). "Inadmissibility of the usual estimator for the mean of a multivariate distribution". Proceedings of the Third Berkeley Symposium on Mathematical Statistics and Probability. 1. pp. 197â€“206." What is important about it is that it shows that you can construct a simple estimator that always stochastically dominates both the maximum likelihood estimator and minimum variance unbiased estimator for the mean of a multivariate Gaussian. What is interesting is that this estimator can also always be dominated. It does not appear that there is an estimator that you can construct using this method that you cannot then dominate yet again. This proves that the bias that is created for this one case stochastically dominates the usual estimator. What is interesting about this method is that it maps to a Bayesian solution with an empirical prior distribution. There are an infinite number of priors and if you played improper games, then you could construct dominating priors although this would violate Bayesian theory. The prior should describe prior knowledge and not improve the value of the sample estimator. In Bayesian theory, the job of the prior is to normalize the data against prior information. Because Stein estimators map to a constrained Bayesian solution, it gives a hint as to what is really going on. Bayesian estimators condition on the information in a sample, whereas non-Bayesian estimators do not. An empirical prior uses a sample statistic that you are not interested in to inform you about a parameter you are interested in. The argument against this is that you are using the same data twice. In the case of a Stein estimator, you condition each individual mean on the grand mean. The argument for this is that you are gaining information about the overall system through the grand mean. The bias is information based and not just random bias. The variance is declining because you are including more information rather than less. The danger in this is that a Stein estimator does not require the means have any relationship whereas the Bayesian method would require it under many axiom systems. Jaynes also discusses this in his book Probability: The Language of Science, in his discussion on the problems with using the word "unbiased." I don't think it is all sources of bias that reduce variability in the estimator, rather it is those take advantage of sample properties that would normally be missed in standard unbiased methods and which are the equivalent to Bayesian information extraction. As to model selection, Bayesian model selection methods are intrinsically admissible, which would deal with your problem explicitly. An admissible model stochastically dominates an inadmissible model. The topic you are looking for is called admissibility and there are two flavors. The Bayesian version is slightly different from the non-Bayesian version because the former operates in the parameter space and the latter in the sample space. Nonetheless, the reason it solves your problem is that it solves a more profound general problem. A statistic is any function of the data, so that $\sum\sin(x_i)$ is a statistic. It is a useless statistic for almost any if not all problems, but how do you prove it? There are an infinite number of statistics that are possible, but how do you prove that almost every one is useless. Indeed, there are an infinite number of unbiased estimators for the mean, yet why use $\bar{x}$? If there is one admissible estimator, for example, then all others with all other combinations of bias and variability are excluded. In fact you can create a partial ordering of all possible rules. Do note though that an admissible estimator when there are multiple admissible estimators is not intrinsically a good estimator, where "good" might be some common sense understanding of good. Inadmissible estimators are bad, but not all admissible ones are good. It merely reduces your set down that you have to evaluate. There are pointless admissible estimators that no one would use. The base paper for admissibility is at https://projecteuclid.org/euclid.aoms/1177730345 It is open source.
