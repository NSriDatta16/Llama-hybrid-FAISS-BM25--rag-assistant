[site]: crossvalidated
[post_id]: 579399
[parent_id]: 
[tags]: 
Extracting factors of a large (dimension m,n) matrix M which correlate with a vector P (length m)

So I'm dealing with a large gene expression dataset (m sample by n genes, where m ~ 1000 and n ~ 20,000). For each of these samples, a phenotype of interest P exists. I'd like to be able to say something like 'this group of genes is associated with P in this group of samples, this other group in these other samples'. The samples come in replicate groups, call them treatments, so for each sample row in the matrix there are another 3 samples with the same treatment which aught to differ only by some noise term. Note that there is noise with respect to both the gene expression values in M, and in the phenotype values P. Given that there are 20k variables per sample we can of course get perfect prediction of our phenotype with with e.g. multivariate regression. Approach is to just train e.g. lasso or random forrest on those 20k samples, using cross validation to regularize the model, and indeed this works and gives us a predictor that works okay on out of bag data. And in general similar treatments do tend to have similar P. However, I have reason to think that: a) there are a small number of latent factors F that mediate the relationship between treatment and P b) Most of the treatments are going to have 1 or 0 of these factors applying to them (so sparsity) c) Most of these factors are going to be sparse with respect to genes - they'll probably be specific groups 100s of genes. d) There are probably other latent factors B (batch) in the data that are NOT correlated with P (these are probably less sparse) A simple approach to find the latent factors would be factor analysis, or PCA (I understand they should give similar results on large data modulo rotation?). Followed by regression with the PCA scores. However this would only do what i want it to do if the latent factors I'm interested in were the only ones behind the data. If instead d) above is true, then the PCAs will contain a mixture of the F and B factors (Notably, I have control samples I know aren't effected by F). So what I want to do is basically a kind of 'supervised factor analysis'. This is kind of similar in structure to some things people do to remove covariates from gene expression data, e.g. if I were to put P into the software PEER it would do something similiar, but ignoring uncertainty in P, which not quite what I want. I can also imagine doing something like putting in P as another gene expression value, doing PCA on the m,n+1 matrix, and then rotating the PCAs to maximize their loading on the value of P. All of this feels like it should be a solved problem with out of the box methods, but I can't seem to find them if so. Wondering if anybody knows, before I embark on writing something in stan or whatever.
