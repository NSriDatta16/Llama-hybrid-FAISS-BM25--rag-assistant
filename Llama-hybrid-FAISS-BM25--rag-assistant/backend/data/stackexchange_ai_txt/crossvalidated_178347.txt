[site]: crossvalidated
[post_id]: 178347
[parent_id]: 178174
[tags]: 
I would suggest that the bias depends on the variance of the model selection criterion, the higher the variance, the larger the bias is likely to be. The variance of the model selection criterion has two principal sources, the size of the dataset on which it is evaluated (so if you have a small dataset, the larger the bias is likely to be) and on the stability of the statistical model (if the model parameters are well estimated by the available training data, there is less flexibility for the model to over-fit the model selection criterion by tuning the hyper-parameters). The other relevant factor is the number of model choices to be made and/or hyper-parameters to be tune. In my study, I am looking at powerful non-linear models and relatively small datasets (commonly used in machine learning studies) and both of these factors mean that nested cross-validation is absolutely necessary. If you increase the number of parameters (perhaps having a kernel with a scaling parameter for each attribute) the over-fitting can be "catastrophic". If you are using linear models with only a single regularisation parameter and a relatively large number of cases (relative to the number of parameters), then the difference is likely to be much smaller. I should add that I would recommend always using nested cross-validation, provided it is computationally feasible, as it eliminates a possible source of bias so that we (and the peer-reviewers ;o) don't need to worry about whether it is negligible or not.
