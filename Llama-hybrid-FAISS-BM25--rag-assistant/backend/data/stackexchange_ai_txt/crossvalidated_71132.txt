[site]: crossvalidated
[post_id]: 71132
[parent_id]: 71005
[tags]: 
I'll give a general idea with a bit of hand-waving. $R^2$ is defined as $$R^2=1-\frac{\sum_{t=1}^T(Y_t-\hat{Y_t})^2}{\sum_{t=1}^n(Y_t-\bar{Y})^2}$$ where $\hat{Y_t}$ is the regression fit. Now the denominator in the fraction goes to infinity at a rate of $T^3$, due to the presence of the trend, while the numerator goes to infinity at the rate of $T$ since the trends cancel each other. Hence we get that $R^2$ goes to one. Both statements can be checked directly. For the denominator we have $$\sum_{t=1}^T(\delta_0+\delta_1t+u_t-\frac{1}{n}\sum_{t=1}^n(\delta_0+\delta_1t+u_t))^2$$ and the dominating term is $t^2$ which when summed gives the order $T^3$. Now for the numerator the calculations are more complicated, but it is possible to show that the slope coefficient $\hat\beta$converges to $\frac{\delta_1}{\gamma_1}$ at a rate $O(1/T)$. Since the dominating term in the numerator is $(\delta_1-\hat\beta\gamma_1)t$ we get the desired result. Here are more mathematical details. For simplicity, suppose $Y_t=\delta t+u_t$ and $X_t=\gamma t+v_t$. Then we have \begin{align*} \begin{bmatrix}\hat\alpha\\\hat\beta\end{bmatrix}&=\begin{bmatrix}T & \sum X_t\\ \sum X_t& \sum X_t^2\end{bmatrix}^{-1}\begin{bmatrix}\sum Y_t\\\sum Y_t^2\end{bmatrix}\\ &\sim\begin{bmatrix}T & \gamma \frac{T^2}{2}\\ \gamma \frac{T^2}{2} & \gamma \frac{T^3}{3}\end{bmatrix}^{-1}\begin{bmatrix}\delta\frac{T^2}{2}\\\gamma\delta\frac{T^3}{3}\end{bmatrix}\\ &=\left(\begin{bmatrix}\frac{1}{T} & 0\\ 0 & \gamma\end{bmatrix}\begin{bmatrix}1 & \frac{1}{2}\\ \frac{1}{2} & \frac{1}{3}\end{bmatrix}\begin{bmatrix}T^2 & 0\\ 0 & \gamma T^3\end{bmatrix}\right)^{-1}\begin{bmatrix}\delta\frac{T^2}{2}\\\gamma\delta\frac{T^3}{3}\end{bmatrix}\\ &=\begin{bmatrix}4T & -6T\\ -6 & \frac{12}{\gamma}\end{bmatrix}\begin{bmatrix}\frac{\delta}{2}\\\frac{\delta}{3}\end{bmatrix}\\ &=\begin{bmatrix}0 \\ \frac{\delta}{\gamma}\end{bmatrix} \end{align*} Here by $\sim$ I mean that I omit terms which are one order of $T$ less. This is a general idea which can be made rigorous. If we include the intercepts in trends, this would change the intercept of the regression, since the intercepts of trends would appear in the terms of order $\frac{1}{T}$ and they will not cancel when multiplied by $T$. For more details look at chapter 16 of "Time Series Analysis" by J.D. Hamilton.
