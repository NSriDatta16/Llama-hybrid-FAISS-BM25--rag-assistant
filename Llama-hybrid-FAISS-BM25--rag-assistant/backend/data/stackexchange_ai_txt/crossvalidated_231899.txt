[site]: crossvalidated
[post_id]: 231899
[parent_id]: 
[tags]: 
Neural Network Model Complexity Metric

Generally speaking, the pervasive idea (AFAIK) in predictive modeling is to use the simplest model that performs the best. This is relatively easy with some algorithms such as random forest (less variables at each split = less complex). This is also easy at first with simple neural networks. A neural network with 5 nodes is clearly more complex than a 3 node network. But what about when we get in to multiple layers? For example, is a 100 node, single layer network considered less complex than a two layer network with 10 nodes in each layer? Or are the layers multiplicative (10*10 = 100) and we would say they are the same complexity? Naturally there are many different combinations which increase as more layers are added. I am curious about this as I have seen discussions regarding very wide versus very deep networks and want to know if there is any consensus on what defines a 'simpler' network.
