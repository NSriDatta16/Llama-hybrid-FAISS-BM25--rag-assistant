[site]: crossvalidated
[post_id]: 13090
[parent_id]: 
[tags]: 
Switching from unsupervised to supervised learning

Disclaimer: This is reposted from stackoverflow . I am working on a research-oriented system of collaborating agents. The agents perform many stochastic experiments (thousands per second), interacting with each other, in a complex high-dimension environment. Each experiment is reproducible and deterministic. The system is trying to learn optimal collaboration patterns. Previous attempts (several skilled PhDs) have tried both rule-based algorithms, and also unsupervised learning. Both approaches topped out at between 10-20% of brute-force optimal scoring. I now want to try to use supervised or reinforced learning. Previously, this was impossible because just labeling the data required NP runtime (per experiment!). I have now devised a new set of faster P-time labels/classifiers. And I have a large amount ($10^9$ experiments) of labeled training data. My questions are: Can I hope for significantly better results with supervised or reinforced learning ( vs. unsupervised learning)? In general, has unsupervised learning been able to match the result of supervised learning? ADDED COMMENT1 Yes i realized unsupervised and supervised are different domains Bur consider the typical problem of OCR, which we can approach with or without labeling... obviously labeling gives us more information... but we are still trying to solve the same problem, no? ADDED COMMENT2 Some of the agents were hand coded with rule-based algorithms Complex rules are progressively harder to write AND more cpu-intensve (the rule itself often involves an NP search of a constrained solution space) We have many samples from simulated AND production runs. The production runs include noise, non-optimal agents, and external changes With unsupervised learning, we are able to isolate clusters of agent interactions Some clusters was manually selected and "converted" into a rule (In a nutshell, this rule tries to "approximate" some of the NP decisions made by agents) Some rules turn out to be good heuristics for agent behavior. NOW, i (might) be able to actually score/label agent interaction. So if i relabel all previous runs, i can now run _supervised_learning_ And i am hoping to be able to find rules
