[site]: crossvalidated
[post_id]: 402984
[parent_id]: 
[tags]: 
Cross Validation versus Ensemble Learning

After performing $k$ -fold cross validation to find the optimal model, and or hyperparameter choices etc, it is common to re-train your (best) proposed model on the full training set, and quote this as your final model. I am wondering if there is any merit instead in using the previously trained $k$ distinct models as a set of $k$ ensemble predictors, or even instead if we average over the $k$ distinct set of model coefficients (in the example of linear regression). I feel like intuitively this latter approach gives more of a Bayesian flavour (averaging over model coefficients is like integrating over the space of coefficients, or alternatively the proposed ensemble method will give us $k$ different model predictions and so the prediction will have an associated probability). Whereas the initial approach feels more frequentist. I am just wondering why then people never seem to use this "Bayesian" approach (loose terminology). Are there any studies to study the difference between these approaches?
