[site]: crossvalidated
[post_id]: 421967
[parent_id]: 
[tags]: 
Can MAE be interpreted as the average standard deviation around the true value of a prediction?

MAE is defined as the Mean Absolute Error, that is how far on average the prediction (derived from some prediction model) lies from the real value. The standard deviation is usually interpreted as how far on average we deviate from the mean value of some distributed data. If we assume a normal distribution, the rule of thumb is that 95% of data should fall between two standard deviations of the mean value. I'm curious as to whether this can be applied to regression accuracy. I.e. is the true value of some prediction $y$ within the range $(y\pm(2*MAE))$ with 95% probability?
