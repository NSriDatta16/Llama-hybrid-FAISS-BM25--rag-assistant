[site]: crossvalidated
[post_id]: 612617
[parent_id]: 
[tags]: 
Handling "missing" data, when the missing variable is the most informative feature

I'm working on a project developing a predictive model for whether or not an individual has a (rare) disease based on some non-invasive test results. The idea is that this could help patients avoid lengthy and invasive tests. One of the non-invasive techniques is very predictive for this particular disease; if a patient has received this test and has a certain combination of results (the test returns several different results), it can be very predictive for this disease. However, only a small subset (10-20%) of patients in the dataset have received the test, as it is not offered at all facilities. What would be an appropriate way of modeling these data? I could be wrong but my intuition is that imputation doesn't make sense here. Would a random forest or gradient-boosted model work best, since they can handle "missing" data well? A colleague suggested building two models, one with and one without the data in question, but I'm not sure how that would work. Thank you!
