[site]: crossvalidated
[post_id]: 599911
[parent_id]: 599909
[tags]: 
Convolution operation in neural networks also has a channel dimension. The kernels will always have a channel dimension equal to the input channel dimension. The input and weight channel dimension are multiplied and accumulated as well, thus disappear. First layer: 28 x 28 input image with only 1 channel is filtered with 32 3 x 3 kernels. 32 is also referred as output feature maps (i.e. output channels). So, the output will be 26 x 26 image as you said, but with 32 channels. Second layer: this is pooling, and as you mentioned, the output 13 x 13 images with 32 channels. Third layer: There are 64 3 x 3 kernels, so the number of output channels is 64 . It's not stated, but the kernel also has a hidden channel dimension which must be equal to the input channel dimension. Thus each kernel is of 3 x 3 x 32 shape (channels last notation). The channel dimension is also accumulated while sliding the kernel, so it disappears. There are 64 kernels, then, the output of this layer is 11 x 11 images with 64 channels.
