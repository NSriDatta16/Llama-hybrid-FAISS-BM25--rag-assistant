[site]: stackoverflow
[post_id]: 957793
[parent_id]: 312003
[tags]: 
I don't think pessimization is rare. From my experience doing performance tuning, a lot of the poor performance is caused by "good programming practice" justified in the name of "efficiency". Examples: Map collections or "dictionaries" These usually make use of some kind of hash-coding, so they will have O(1) performance, but will only break even when filled with far more items than are typically used. Iterators These are justified as being possibly optimized into efficient inline code, when it is seldom checked to see if they actually are. Notifications and event handling as a way to keep data consistent Since data structure is seldom normalized, inconsistency must be managed, and notification is the usual method because it supposedly takes care of the problem "immediately". However, there is a big difference between immediacy and efficiency. Also "properties", when Get or Set, are encouraged to reach deep into the data structure to try to keep it consistent. These "short leash" methods can cause large amounts of wasted computation. "Long leash" methods, such as periodically cycling through the data structure to "repair" it, can be a little less "immediate" but much more efficient. Examples
