[site]: datascience
[post_id]: 124317
[parent_id]: 
[tags]: 
Feeding more data to a neural network

I watched a video on Tesla's FSD where the drive was really smooth but required one intervention when the traffic light changed to green but the car wouldn't go because it looked like the light was for the other lane. The FSD is currently End to End neural network, and in order to fix the case above they would have to bring in more examples. This means that the weights will change. This got me thinking: when bringing in new data to a NN, how do we know that previous optimized weights are not "broken" such that things that were already robust will get messed up?
