[site]: datascience
[post_id]: 15579
[parent_id]: 
[tags]: 
How to chose training sample for neural network in fraud detection?

I am working on a personal project sponsored by a data scientists, he offered some data sets to me. And I have built a neural network system based on my own theory. But when I tried to train it, I always can't get a ideal result. I think carefully chose the training data set samples may help. So I would like to know if there are some principles or theories things which can guide researchers choosing samples. Any books, papers or blogs would help. by the way, I am working on a fraud detection project. UPDATE Ok, I think there are some misunderstandings in the question. What I am looking for is a systematical theory which explains how to organize the training set . For a naive example: I have example data set from US. There are tons of data, so it is not possible to train the machine with all the example set. Here comes the question, how should I pick carefully the training data set from the example data set? how to do that is a reasonable way? and a logical way? For a further example: Choose the training set according to states evenly? or choose training set according to their population as weight? Thanks, and I will provide more information if it is needed.
