[site]: crossvalidated
[post_id]: 142557
[parent_id]: 
[tags]: 
Is dimensionality reduction almost always useful for classification?

Is singular value decomposition almost always useful in practice for enhancing the predicative power of a trained classification model? E.x. A dataset for classification has 20,000 features. Run SVD to convert them to top principal components and transform them to 300 features, and trained a classification model. When predict the class of a test instance, convert it to a 300d principal component feature vector, and use the trained model to predict its class. Are there some notable real datasets of numerous features (variables) in which dimension reduction by SVD would hurt the predictive power of trained classification models?
