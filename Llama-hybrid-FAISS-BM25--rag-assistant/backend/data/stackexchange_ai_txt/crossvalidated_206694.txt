[site]: crossvalidated
[post_id]: 206694
[parent_id]: 
[tags]: 
Neural Network for Reverberation Decay Rate Prediction (Keras)

I'm not sure if this is the right place to post this question, sorry if it's not. Essentialy Iâ€™m trying to use a neural network to predict decay rate from a reverberant audio sample. I have taken a single word utterance, and used a simple convolution reverb to create 10,000 examples with decay rates of 0 to 10. This has been done twice, so I have a second 10,000 example dataset for testing. There are 20 inputs to the neural network, corresponding to the points in the FFT of the envelope of the reverberant sample with frequency Graphs of inputs to neural network (features): Prediction results on unseen dataset for different activation functions, same hyperparameters: Dataset generation: import numpy as np import numpy.random as rdm import matplotlib.pyplot as plt import scipy.io.wavfile as wav """Read wav file and append zeros to end for 'space' for reverb""" rate, wave = wav.read('ting.wav') pad = np.zeros(len(wave)*5) wave = np.append(wave, pad) """create gaussian white noise of duration equal to padded wav""" dur = len(wave)/rate noise = rdm.normal(loc=0, scale=5000, size=len(wave)) b = np.linspace(0, dur, len(noise)) """Create decay curve, multiply with noise and convolve the result with the wav for reverberated samples""" n = 10000 data = np.empty([n, len(noise)]) dec = np.empty(n) for i in range(0,n): dec[i] = 10 * rdm.ranf() env = np.exp(-b*dec[i]) rev = np.multiply(noise, env) revfft = np.fft.fft(rev) wavefft = np.fft.fft(wave) data[i, :] = np.fft.ifft(np.multiply(revfft, wavefft)) """Define a low-pass filter""" def butter_lowpass(dat, cutoff, rate, order=4): nyq = 0.5*rate norm_cutoff = cutoff/nyq b, a = sig.butter(order, norm_cutoff) passed = sig.lfilter(b, a, dat) return passed """Take the envelope of the reverberated sample, low-pass it, then take the FFT. Take FFT results for frequencies 0)] lf = pd.rolling_mean(lf, len(lf)-19) lf = lf[~np.isnan(lf)] X[i,:] = lf np.save('X2_new2', X) np.save('dec2_new2', dec) Neural Network and prediction: import numpy as np """Load training dataset""" X = np.load('X_new2.npy') dec = np.load('dec_new2.npy') """Define standardisation function and standardise features""" def standardise(X): for i in range(0, len(X[0, :])): mean = np.mean(X[:, i]) sd = np.std(X[:, i]) for j in range(0, len(X[:, 0])): X[j, i] = (X[j, i] - mean)/sd return X X = standardise(X) """Define and fit neural network""" from keras.models import Sequential from keras.layers import Dense, Dropout, Activation from keras.optimizers import RMSprop model = Sequential() model.add(Dense(input_dim=20, output_dim=10)) model.add(Activation('linear')) model.add(Dense(input_dim=10, output_dim=1)) model.add(Activation('linear')) rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-6) model.compile(loss='mean_absolute_error', optimizer='rmsprop') model.fit(X, dec, nb_epoch=10, batch_size=1) """Load test dataset, standardise and predict decay rates""" X2 = np.load('X2_new2.npy') dec2 = np.load('dec2_new2.npy') dec2 = dec2.reshape(-1, 1) X2 = standardise(X2) pred = model.predict(X2) """Plot results""" import matplotlib.pyplot as plt plt.scatter(dec2, pred, label='linear') plt.plot(range(0,11),range(0,11)) plt.xlabel('True Decay Rate') plt.ylabel('Predicted Decay Rate') plt.grid() plt.legend() plt.show()
