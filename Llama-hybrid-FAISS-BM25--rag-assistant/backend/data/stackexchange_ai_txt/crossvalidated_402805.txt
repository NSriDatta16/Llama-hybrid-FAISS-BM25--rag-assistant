[site]: crossvalidated
[post_id]: 402805
[parent_id]: 402796
[tags]: 
I want to remind you that, this is merely a simple guideline of what you should consider/be careful while applying the listed algorithms. Random Forest, XGBoost and Naive Bayes doesn’t require feature scaling, but it doesn’t harm also. SVM needs it and logistic regression might or might not need it depending on the implementation, especially in your case because variable ranges are not even close to each other. So, first scale your data and apply these algorithms to be safe. You can use StandardScaler for example. Note: Writers in Elements of Stat. Learning recommend feature scaling for logistic regression (with regularization) (Pg. 63). But, depending on your implementation it might not be required, however doing so will not harm you.
