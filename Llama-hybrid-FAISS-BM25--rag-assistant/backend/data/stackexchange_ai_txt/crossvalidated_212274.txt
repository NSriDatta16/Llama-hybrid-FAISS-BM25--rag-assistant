[site]: crossvalidated
[post_id]: 212274
[parent_id]: 212228
[tags]: 
From your question I'm assuming that you have trained a few logistic regression models for classification by fitting them on different independent variables of the same training data. Now, you wish to compare the performance of each model. Since you need a cutoff to arrive at a confusion matrix, hence the query on choice of cutoff. Choosing cutoffs is not straightforward since the optimal cutoff is based on the costs of false positives and false negatives, which are most often asymmetric in real world problems. Hence, it might need to be calibrated according to acceptable tradeoffs decided along with end users; and fine tuned periodically. Usually, due to high class imbalance, a cutoff of 0.5 is not appropriate as the output may be skewed heavily. If the different models you're comparing are using different independent variables , then cutoffs will usually vary for the same true positive rate since the output ratio of probabilities will span a different range of values for each model. In general, it is simpler and more effective to compute an ROC curve and compare the AUC (Area under the curve) for each model on the same test set; and select the model with the highest AUC.
