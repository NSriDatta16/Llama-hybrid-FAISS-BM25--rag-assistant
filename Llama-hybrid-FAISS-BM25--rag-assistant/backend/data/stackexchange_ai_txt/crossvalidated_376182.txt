[site]: crossvalidated
[post_id]: 376182
[parent_id]: 376152
[tags]: 
The least squares estimator is the solution to the estimating equation: $$ 0 = \mathbf{X}^T \left( Y - \mathbf{X}\beta \right)$$ Where $\mathbf{X} = [1, x_1, x_2, \ldots, x_p]$ is a $n \times p$ model matrix of covariate(s). This is a trivial result, but a more general discussion on estimating equations can be found in Wakefield "Bayesian and Frequentist Regression Methods". Estimating Equations are also called M-estimators. Another reference would be Boos, Stefanski "Essential Statistical Inference" ch. 7.
