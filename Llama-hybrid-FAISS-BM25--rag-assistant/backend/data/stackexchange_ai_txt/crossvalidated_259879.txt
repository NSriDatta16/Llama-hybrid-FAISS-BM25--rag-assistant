[site]: crossvalidated
[post_id]: 259879
[parent_id]: 
[tags]: 
Imputation (consistent with a given correlation matrix) of missing values in a time series

There is a model which is based on N factors which are correlated through a correlation matrix of size NxN. For a subset of M factors the corresponding values are explicitly given over a specific time period [A,B]. Which methods are recommended to obtain the most appropriate "missing" values for remaining N-M factors over that time period [A,B]? The problem is a little different compared to "imputing missing values for a time series", since these missing values have to be consistent with a given correlation matrix. I am looking at various alternatives, and any relevant reference would be appreciated. On a side note, a promising avenue (with some enhancements needed) is 2013 the article "How to Combine Long and Short Return Histories Efficiently" by S. Page
