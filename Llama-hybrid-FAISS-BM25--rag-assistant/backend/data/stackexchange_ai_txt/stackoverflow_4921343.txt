[site]: stackoverflow
[post_id]: 4921343
[parent_id]: 4919080
[tags]: 
Just some ideas: You could use the jsonP approach and use the tag to set the 302-chains mode. You won't find a lot of js disabled clients in the human part of your web clients. But the web crawlers will mostly fall in the 302-chain mode, and if you care about them you could maybe implement some user-agent checks in sessionSync to give them specific instructions. For example give them a 301 permanent redirect. Your session synchronistation needs are maybe not valid for web crawlers, maybe you can redirect them permanently (so only the first time) without handling any specific session synchronisation for them. Well it depends ofg your implementation of this 302-chains but you could as well set something in the crawlers session to let them crawl domain-1 without any check on domain-2, as this depends on the url you generate on the page, and that you could have something in the session to prevent the domain-2 redirect on url generation.
