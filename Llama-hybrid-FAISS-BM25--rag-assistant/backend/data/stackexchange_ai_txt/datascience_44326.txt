[site]: datascience
[post_id]: 44326
[parent_id]: 26451
[tags]: 
The answers here give figures that work, but they don't mention that there are multiple possible output shapes for the convolution-transpose operation. Indeed, if the output shape was completely determined by the other parameters then there would be no need for it to be specified. The output size of a convolution operation is # padding=="SAME" conv_out = ceil(conv_in/stride) # padding=="VALID" conv_out = ceil((conv_in-k+1)/stride) where conv_in is the input size and k is the kernel size. In OP's link these padding methods are called 'half padding' and 'no padding' respectively. When calling tf.nn.conv2d_transpose(value, filter, output_shape, strides) we need the output_shape parameter to be the shape of a tensor that, if convolved with filter and strides , would have produced a tensor of the same shape as value . Because of rounding, there are multiple such shapes when stride>1 . Specifically, we need dconv_in-1 (dconv_in-1)s + k If dconv_in = 7, k = 4, stride = 3 # with SAME padding dconv_out = 19 or 20 or 21 # with VALID padding dconv_out = 22 or 23 or 24 The tf.layers API automatically calculates an output_shape (which seems to be the smallest possible for VALID padding and the largest possible for SAME padding). This is often convenient, but can also lead to shape mismatches if you are trying to recover the shape of a previously convolved tensor, eg in an autoencoder. For example import tensorflow as tf import numpy as np k=22 cin = tf.placeholder(tf.float32, shape=(None, k+1,k+1,64)) w1 = tf.placeholder(tf.float32, shape=[4,4,64,32]) cout = tf.nn.conv2d(cin, w1, strides=(1,3,3,1), padding="VALID") f_dict={cin:np.random.rand(1,k+1,k+1,64), w1:np.random.rand(4,4,64,32)} dcout1 = tf.nn.conv2d_transpose(cout, w1, strides=(1,3,3,1), padding="VALID", output_shape=[1,k,k,64]) dcout2 = tf.nn.conv2d_transpose(cout, w1, strides=(1,3,3,1), padding="VALID", output_shape=[1,k+1,k+1,64]) dcout_layers = tf.layers.conv2d_transpose(cout, 64, 4, 3, padding="VALID") with tf.Session() as sess: sess.run(tf.global_variables_initializer()) inp_shape = sess.run(cin, feed_dict=f_dict).shape conv_shape = sess.run(cout, feed_dict=f_dict).shape lyrs_shape = sess.run(rcout, feed_dict=f_dict).shape nn_shape1 = sess.run(dcout1, feed_dict=f_dict).shape nn_shape2 = sess.run(dcout2, feed_dict=f_dict).shape print("original input shape:", inp_shape) print("shape after convolution:", conv_shape) print("recovered output shape using tf.layers:", lyrs_shape) print("one possible recovered output shape using tf.nn:", nn_shape1) print("another possible recovered output shape using tf.nn:", nn_shape2) >>> original input shape: (1, 23, 23, 64) >>> shape after convolution: (1, 8, 8, 32) >>> recovered output shape using tf.layers: (1, 22, 22, 64) >>> one possible recovered output shape using tf.nn: (1, 22, 22, 64) >>> another possible recovered output shape using tf.nn: (1, 23, 23, 64)
