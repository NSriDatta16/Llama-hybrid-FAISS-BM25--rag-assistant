[site]: crossvalidated
[post_id]: 591228
[parent_id]: 591226
[tags]: 
If you work with time-to-event data, then using proportions for the sample size calculation is not the obvious thing to do. It would be better to do the sample size calculations for e.g. a log-rank test assuming some suitable survival distribution. This is preferable, because for a survival analysis there is a huge difference between 100% of individuals having an event within seconds vs. within hours vs. within days vs. months. Obviously, what happens in 6 individuals is incredibly variable, so ignoring the uncertainty around observed proportions (or estimated parameters of survival distributions) is going to make anything further you do (whether it's sample size calculations for future studies or something else) very fragile. It might be more reasonable to get a distribution of values for the parameters going into the sample size calculation and to average across the calculated powers for these (and pick the sample size to achieve an acceptable power on this basis). To do so, you could do a Bayesian analysis that gives you samples from the posterior distribution of samples (or a closed-form distribution from which you can then sample), then you calculate power for a given sample size by calculating the power for each of these samples. Furthermore, you did not say, but there might be variation between studies (different study length, different inclusion criteria, or various other things) and that might have to be accounted for. For that, things like meta-analytic predictive approaches might be a good idea.
