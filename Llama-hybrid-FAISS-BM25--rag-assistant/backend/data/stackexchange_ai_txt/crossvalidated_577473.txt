[site]: crossvalidated
[post_id]: 577473
[parent_id]: 577431
[tags]: 
The goal is to have an unbiased estimator for the error your model makes on average. Let's call that $\bar \epsilon$ . Now let's see what's the relationship of the two estimators you asked about with the $\bar \epsilon$ : $\hat y_{i} - y_{i} = \epsilon_{i}$ $\frac{1}{n}\sum_{i=1}^{n}(\hat y_{i} - y_{i})^2 = \frac{1}{n}\sum_{i=1}^{n}(\epsilon_{i})^2 = \bar \epsilon^2$ thus $ \sqrt{\frac{1}{n}\sum_{i=1}^{n}\left(\hat{y}_{i}-y_{i}\right)^{2}} \approx \bar \epsilon$ which is what we aimed for. Now let's see what the other estimator will give you: $\frac{1}{n} \sqrt{\sum_{i=1}^{n}\left(\hat{y}_{i}-y_{i}\right)^{2}} = $ $\frac{1}{n} \sqrt{n \times \frac{1}{n}\sum_{i=1}^{n}\left(\hat{y}_{i}-y_{i}\right)^{2}} = $ $\frac{\sqrt{n}}{n} \times \bar \epsilon$ As you can see the second estimator has a bias of $\frac{\sqrt{n}}{n}$ in estimating the average error you aimed for. For example, if for a data generating process of $f(x) = 0$ you always predict 2 then you would want the estimator to give you $\bar \epsilon = 2$ which is given by the first estimator while the second estimator (assuming n = 10) will give you ( $2 \times \frac{\sqrt 10}{10}$ ).
