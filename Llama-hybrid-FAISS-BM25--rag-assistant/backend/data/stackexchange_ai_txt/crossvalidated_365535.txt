[site]: crossvalidated
[post_id]: 365535
[parent_id]: 73950
[tags]: 
If the only problem you're trying to solve is to have more than 500 distinct prediction values, then this is most easily solved by just fitting more trees. Adding additional trees to a forest doesn't overfit. The only practical concerns with this method is that fitting additional trees can consume additional time or memory. For more information see: Do we have to tune the number of trees in a random forest? As an aside, randomForest uses binary leafs -- each leaf can only predict 0 or 1. Some other implementations, most notably sklearn , use "proportional leafs", which means that the leaf emits a value in $[0,1]$, the proportion of samples belonging to class $k$ for all classes $k=1,2,\cdots,K$. Since each leaf in a tree will likely have a different proportion belonging to class $k$, this provides another route to yield a more diverse range of scores for your samples. For more information, see: How to make the randomforest trees vote decimals but not binary
