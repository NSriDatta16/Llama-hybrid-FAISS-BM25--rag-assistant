[site]: crossvalidated
[post_id]: 275515
[parent_id]: 
[tags]: 
When using Jeffrey's prior for Normal model, what is $p_J(\theta, \sigma^{2} | y_{1}, ..., y_{n})$ supposed to be?

I'm reading A First Course in Bayesian Statistical Methods by P. Hoff where he is using Jeffrey's prior (J) and Unit information prior (U) for Normal model. For example we can derive Jeffrey's prior for Normal model and get $p_{J}(\theta, \sigma^2) = (\sigma^2)^{-3/2}$ and then obtain a posterior $p(\theta, \sigma^2 | y_{1}, ..., y_{n})$ as the product of prior and likelihood. I don't understand what he means by probability density with subscript J, for example: $p_{J}(\theta, \sigma^{2} | y_{1}, ..., y_{n})$ or $p_{J}(\theta | \sigma^2, y_{1}, ..., y_{n})$. Can someone please explain?
