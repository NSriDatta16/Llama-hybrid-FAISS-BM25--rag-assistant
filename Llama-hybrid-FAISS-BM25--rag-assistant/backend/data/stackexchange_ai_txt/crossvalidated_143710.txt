[site]: crossvalidated
[post_id]: 143710
[parent_id]: 
[tags]: 
Degeneracy paradox

Say I have a highly biased coin that lands heads with $p_h=0.01$ and tails with $p_t=0.99$, and I flip it $98$ times. The probability of zero heads is ${p_t}^{98} \approx 0.373$. The probability of one head is $98 \times {p_t}^{97} \times p_h \approx 0.370$ as any of the 98 coin flips could have given H. The probability decreases for larger numbers of heads. The expected number of heads is $\Sigma xp_{xH} = 0.98$ where $p_{xh}$ is the probability of getting $x$ heads (this is also of course $p_h \times 98$). But the expected number of heads appears to be different to the most likely number of heads. How do we account for this? Is the answer that if I had to bet on how many heads would come up in a single 98-flip experiment, I should place my bet on zero, but if I had to bet on the long run average of many 98-flip experiments I should bet on 0.98?
