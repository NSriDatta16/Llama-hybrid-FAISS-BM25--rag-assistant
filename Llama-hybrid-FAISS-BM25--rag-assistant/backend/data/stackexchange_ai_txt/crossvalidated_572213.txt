[site]: crossvalidated
[post_id]: 572213
[parent_id]: 
[tags]: 
In a multioutput deep learning model, is there a benefit to normalizing the output dimensions if they are of different magnitudes?

I am building a multi output deep learning model where the output consists of five dimensions (the specific architecture is a modification of YOLO). These have different magnitudes (ranges: [0, 1.2], [0, 20], [0, 1.2], [0, 1.5, 0, 2000])as shown in . I was wondering if scaling the output dimensions, for example by using max-min or standard scaling, such that each predicted dimension is roughly in [0, 1] improves training (as opposed to having different scales of magnitudes in each output dimension)? Currently, the largest dimension of the (un-scaled) output monopolizes the loss value but I'm not sure if that hampers the training in some way. Details Input consists of a sequence of real numbers, each number is in [0, 1] example input: [0.15, 0.8, 0.67, 0.43] Fully convolution network with ReLU activations and BatchNorm Output layer is linear Loss function is MSE for all outputs.
