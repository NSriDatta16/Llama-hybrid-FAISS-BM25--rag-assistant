[site]: crossvalidated
[post_id]: 247351
[parent_id]: 246990
[tags]: 
The cross_val_score() function applies Cross Validation to obtain an unbiased measure of the accuracy of a classifier (or pipeline in sklearn). In the example you provided, the second block of code performs a 3-fold cross validation. The whole dataset $X$ is randomly divided into 3 non-overlaping subsets $X_1, X_2, X_3$. Then, the following experiments are automatically performed: Train a StandarScaler on $X_1,X_2$ and use it to transform $X_1, X_2, X_3$. Train a SVM on the scaled versions of $X_1,X_2$, test on the scaled version of $X_3$. Train a StandarScaler on $X_1,X_3$ and use it to transform $X_1, X_2, X_3$. Train a SVM on the scaled versions of $X_1,X_3$, test on the scaled version of $X_2$. Train a StandarScaler on $X_2,X_3$ and use it to transform $X_1, X_2, X_3$. Train a SVM on the scaled versions of $X_2,X_3$, test on the scaled version of $X_1$. The accuracies obtained on these three experiments can be averaged to obtain an unbiased estimate of the generalization accuracy of your pipeline: StandardScaller() + SVC(C=1) . However, if you started playing with the hyperparameters of your classifier (e.g. trying different C values) the best accuracy obtained would not be an unbiased estimate. Nested CV is necesary if you want to perform hyperparametrer/model selection (inner loop) and obtain an unbiased estimate of the accuracy of your method (outer loop). These topics have been already discused in more detail here and here . In short: "the outer loop is to assess the performance of the model, and the inner loop is to select the best model".
