[site]: datascience
[post_id]: 10122
[parent_id]: 10121
[tags]: 
You do not have to normalise features used in logistic regression, but sometimes it can help. You should normalise features used in logistic regression, if you are using a gradient-based optimiser (e.g. SGD) to find the optimum weights. That is because the optimiser will perform better when partial derivatives of the cost function are of similar magnitude in each direction. When the derivatives vary too much, you will need a lower learning rate to compensate (making learning slower, and more likely to get stuck) or the optimiser will not converge - it may oscillate or start to diverge instead.
