[site]: datascience
[post_id]: 9530
[parent_id]: 9509
[tags]: 
I'd suggest first visualize your data. The time to archive a partition could be defined as a difference between the partition start (first possible insert) and archiving time (last possible update). Plot the total distribution of this data for some time interval - check if it follows some distribution. Is the average, median or sd meaningful? Make a boxplot for each hour to see inter quartile interval and the outliers. Plot it as a time series - does it have a trend or daily/weekly pattern? In your simple set up (with one predictor and one response) this will give you impression about the accuracy that you can expect from a model. The choose of the model depends on the result of the visualization. I personally would start with the simplest models: all partition archived after $N$ hours; independent model for each hour predicting say $.9$ quantile of some history interval; more advanced 2.: consider the weekday and/or trend and/or ignoring outliers. Always check the accuracy and stop if expectations are met.
