[site]: crossvalidated
[post_id]: 540733
[parent_id]: 540341
[tags]: 
I believe you're looking for a metric of (relative) variable importance (see also this thread ). Many available methods rely on the decomposition of the $R^2$ to assign ranks or relative importance to each predictor in a multiple linear regression model. A certain approach in this family is better known under the term "Dominance analysis" (see Azen et al. 2003). Azen et al. (2003) also discuss other measures of importance such as importance based on regression coefficients, based on correlations of importance based on a combination of coefficients and correlations. A general good overview of techniques based on variance decomposition can be found in the paper of Grömping (2012). These techniques are implemented in the R packages relaimpo , domir and yhat . Here, I'm going to illustrate a method that is model-agnostic (i.e. it can be applied to a variety of model types) and has intuitive appeal: Variable importance based on permutation. The idea is very simple: Decide on a performance metric that is important to you. Examples include: Root mean square error (RMSE), mean absolute error (MAE), $R^2$ etc. This also is somewhat dependent in the model type. Calculate the metric on your dataset, $M_{orig}$ . This serves as baseline performance metric. For $i = 1, 2, \ldots, j$ : (a) Permute the values of the predictor $X_i$ in the data set. (b) Recompute the metric on the permuted data and call it $M_{perm}$ . (c) Record the difference from baseline using $imp(X_i)=M_{perm} - M_{orig}$ . Do this repeatedly, say 1000 times, and take the average of the importance values. Intuitively, the permutations break the relationship between the predictor $X_i$ and the outcome. The larger the change in the performance metric, the higher the predictors' importance. More information can be found in this chapter of an online book by Christoph Molnar. The R package vip implements this procedure (see the documentation (PDF) for more information). The following code applies the idea to your dataset. I chose the $R^2$ and the mean absolute error (MAE) as performance metrics and permute each predictor 1000 times: library(vip) # The model mod 1 transportation 0.198 0.0492 2 clean 0.177 0.0465 3 edu 0.0462 0.0237 4 location 0.0449 0.0250 # Calculate permutation-based importance with mae as metric p_mae 1 transportation 0.166 0.0413 2 clean 0.144 0.0400 3 location 0.0396 0.0214 4 edu 0.0368 0.0219 According to the $R^2$ , permuting transportation leads to the largest change in $R^2$ , followed by clean . Using the mean absolute error shows a similar ordering with transportation and clean being most important while location and edu being least important. References Azen R, Budescu DV (2003): The Dominance Analysis Approach for Comparing Predictors in Multiple Regression. Psychological Methods 8:2, 129-148. ( link ) Grömping U (2012): Estimators of relative importance in linear regression based on variance decomposition. Am Stat 61:2, 139-147. ( link )
