[site]: datascience
[post_id]: 72764
[parent_id]: 
[tags]: 
Can Random Forest regressor or Decision trees handle missing values and outliers?

I have below assumptions about RF & Decision trees in general, please correct me if the assumptions are incorrect. It takes care of missing values It handles outliers It handles skewness in the data so the transformation is not required. Feature scaling is not required Feature selection is not required. Please correct if my observations are incorrect as you can see there is a nan value error in the dataset. Also how to rectify it? import numpy as np import matplotlib.pyplot as plt import pandas as pd importing dataset share3.info() share2.isnull().sum() XRD = share2.drop(['Close'], axis = 1) YRD = share2['Close'] training & test set from sklearn.model_selection import train_test_split X_trainRD, X_testRD, Y_trainRD, Y_testRD = train_test_split(XRD,YRD,test_size = 0.2, random_state = 0) fitting random forest regresson to the dataset from sklearn.ensemble import RandomForestRegressor regressor = RandomForestRegressor(n_estimators= 350,random_state = 0) regressor.fit(X_trainRD, Y_trainRD) ***ValueError: Input contains NaN, infinity or a value too large for dtype('float32')*** ```
