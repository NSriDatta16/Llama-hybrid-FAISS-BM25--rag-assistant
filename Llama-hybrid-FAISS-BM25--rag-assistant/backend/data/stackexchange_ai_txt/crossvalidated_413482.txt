[site]: crossvalidated
[post_id]: 413482
[parent_id]: 
[tags]: 
Normalizing data before or after extracting time domain features

I have 100 time series (with 200 instances each) datasets each corresponding to a particular activity. I want to perform supervised classification for the activity. I want to use time domain (time-invariant) features for each time series to perform the classification. Example dataset | Time | Column A | Column B | |------|----------|----------| | 1 | 19.45 | 0.32 | | 2 | 22.5 | 0.89 | | ... | ... | .. | | 200 | 33.11 | 1.23 | 100 such files. After extracting time-invariant features from each time series I get 100 s rows as below. | Column A minimum | Column A mean | Column B minimum | Column B mean | Label | |------------------|---------------|------------------|---------------|-------| | ... | ... | ... | ... | Push | | ... | ... | ... | ... | Pull | I have 100 rows (1 row corresponding to each dataset originally) in this new dataset. Now I perform classification on this generated dataset. My question is, if I want to normalize/standardize the dataset, which would be a better way? Scaling before the extraction of time-invariant features or after generating the time domain features?
