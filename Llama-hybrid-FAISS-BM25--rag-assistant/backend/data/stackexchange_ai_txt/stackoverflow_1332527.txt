[site]: stackoverflow
[post_id]: 1332527
[parent_id]: 
[tags]: 
what are the fast algorithms to find duplicate elements in a collection and group them?

Say you have a collection of elements, how can you pick out those with duplicates and put them into each group with least amount of comparison? preferably in C++, but algorithm is more important than the language. For Example given {E1,E2,E3,E4,E4,E2,E6,E4,E3}, I wish to extract out {E2,E2}, {E3,E3}, {E4,E4,E4}. what data structure and algorithm you will choose? Please also include the cost of setting up the data structure, say, if it's a pre-sorted one like std::multimap Updates To make things clearer as suggested. there's one constraint: the elements must be compared by themselves to be certain they are duplicates. So hashes do not apply, because virtually they shift the comparison to from heavy elements(e.g. chunks of data) to light elements(integers), and reduce some comparison, but not do away with them, and in the end, we are back to our original problem, when are inside one collision bucket. Pretend you have a bunch of potentials duplicate files of GBs each, they bear the same hash value by every hash-algorithm human beings know. Now you are going to spot the real duplicates. No, it can't be a real-life problem(even MD5 is enough to generate unique hash for real-life files). But just pretend so that we can focus on finding the data structure + algorithm that involves least amount of comparison . What I am doing is to represent into a STL std::list data structure(in that 1) its element-deletion is cheaper than, say, a vector 2) its insertion is cheaper, not requiring sort.) pop out one element and compare it with the rest, if a duplicate is found, it's pulled out of the list. once the end of the list is reached, one group of duplication is found, if any. repeat the above 2 steps until the list is empty. It needs N-1 in the best case, but (N-1)! in the worse case. what are the better alternatives? My code using method explained above: // algorithm to consume the std::list container, // supports: list ,list > template struct consume_list { groups_type operator()(list & l) { // remove spurious identicals and group the rest // algorithm: // 1. compare the first element with the remaining elements, // pick out all duplicated files including the first element itself. // 2. start over again with the shrinked list // until the list contains one or zero elements. groups_type sub_groups; group_type one_group; one_group.reserve(1024); while(l.size() > 1) { T front(l.front()); l.pop_front(); item_predicate ep(front); list ::iterator it = l.begin(); list ::iterator it_end = l.end(); while(it != it_end) { if(ep.equals(*it)) { one_group.push_back(ep.extract_path(*(it))); // single it out it = l.erase(it); } else { it++; } } // save results if(!one_group.empty()) { // save one_group.push_back(ep.extract_path(front)); sub_groups.push_back(one_group); // clear, memory allocation not freed one_group.clear(); } } return sub_groups; } }; // type for item-item comparison within a stl container, e.g. std::list template struct item_predicate{}; // specialization for type path_type template <> struct item_predicate { public: item_predicate(const path_type& base)/*init list*/ {} public: bool equals(const path_type& comparee) { bool result; /* time-consuming operations here*/ return result; } const path_type& extract_path(const path_type& p) { return p; } private: // class members }; }; Thanks for the answer below, however they seem to be misled by my example that it's about integers. In fact the elements are type agnostic(not necessarily integers, strings or any other PODs) , and the equal predicates are self-defined, that is the comparison can be very heavy . So maybe my question should be: using which data structure + algorithm involves fewer comparisons. Using a pre-sorted container like multiset, multimap is not better according to my test, since the sorting while inserting already does the comparisons, the following adjacent finding does comparison again, these data structure prefer less-than operations to equal operations, they perform 2 less-than(a I do not see how it can save comparisons. one more thing that's ignored by some answers below, I need to differentiate the duplicate groups from one another, not just keep them in the container. Conclusion After all the discussion, there seem to be 3 ways my original naive method as explained above Start with a linear container like std::vector , sort it and then locate the equal ranges start with an associated container like std::map > , pick out the duplicates during the setup of associated container as suggested by Charles Bailey. I've coded a sample to test all the methods as posted below. the number of duplicates and when they are distributed may influence the best choice. Method 1 is best when they fall heavily at the front, and is worst when at the end. Sort will not change the distribution, but the endian. Method 3 has the most average performance Method 2 is never the best choice Thanks for all who participating in the discussion. one output with 20 sample items from the code below. Test with [ 20 10 6 5 4 3 2 2 2 2 1 1 1 1 1 1 1 1 1 1 ] and [ 1 1 1 1 1 1 1 1 1 1 2 2 2 2 3 4 5 6 10 20 ] respectively using std::vector -> sort() -> adjacent_find(): comparisons: [ ' comparisons: [ ' using std::list -> sort() -> shrink list: comparisons: [ ' comparisons: [ ' using std::list -> shrink list: comparisons: [ ' comparisons: [ ' using std::vector -> std::map>: comparisons: [ ' comparisons: [ ' using std::vector -> std::multiset -> adjacent_find(): comparisons: [ ' comparisons: [ ' Code // compile with VC++10: cl.exe /EHsc #include #include #include #include #include #include #include #include #include #include #include using namespace std; struct Type { Type(int i) : m_i(i){} bool operator struct Test { void recursive_run(size_t n) { bool reserve_order = false; for(size_t i = 48; i > { string Description() { return "std::vector -> sort() -> adjacent_find()"; } private: void sort_it() { std::sort(m_container.begin(), m_container.end()); } void locate_duplicates() { using std::adjacent_find; typedef vector ::iterator ITR; typedef vector ::value_type VALUE; typedef boost::tuple TUPLE; typedef vector V_TUPLE; V_TUPLE results; ITR itr_begin(m_container.begin()); ITR itr_end(m_container.end()); ITR itr(m_container.begin()); ITR itr_range_begin(m_container.begin()); while(itr_begin != itr_end) { // find the start of one equal reange itr = adjacent_find( itr_begin, itr_end, [] (VALUE& v1, VALUE& v2) { return v1 == v2; } ); if(itr_end == itr) break; // end of container // find the end of one equal reange VALUE start = *itr; while(itr != itr_end) { if(!(*itr == start)) break; itr++; } results.push_back(TUPLE(start, itr_range_begin, itr)); // prepare for next iteration itr_begin = itr; } } }; struct List : Test > { List(bool sorted) : m_sorted(sorted){} string Description() { return m_sorted ? "std::list -> sort() -> shrink list" : "std::list -> shrink list"; } private: void sort_it() { if(m_sorted) m_container.sort();////std::sort(m_container.begin(), m_container.end()); } void locate_duplicates() { typedef list ::value_type VALUE; typedef list ::iterator ITR; typedef vector GROUP; typedef vector GROUPS; GROUPS sub_groups; GROUP one_group; while(m_container.size() > 1) { VALUE front(m_container.front()); m_container.pop_front(); ITR it = m_container.begin(); ITR it_end = m_container.end(); while(it != it_end) { if(front == (*it)) { one_group.push_back(*it); // single it out it = m_container.erase(it); // shrink list by one } else { it++; } } // save results if(!one_group.empty()) { // save one_group.push_back(front); sub_groups.push_back(one_group); // clear, memory allocation not freed one_group.clear(); } } } private: bool m_sorted; }; struct Map : Test > { string Description() { return "std::vector -> std::map >" ; } private: void sort_it() {} void locate_duplicates() { typedef map > MAP; typedef MAP::iterator ITR; MAP local_map; BOOST_FOREACH(const vector ::value_type& v, m_container) { pair mit; mit = local_map.insert(make_pair(v, vector (1, v))); if(!mit.second) (mit.first->second).push_back(v); } ITR itr(local_map.begin()); while(itr != local_map.end()) { if(itr->second.empty()) local_map.erase(itr); itr++; } } }; struct Multiset : Test > { string Description() { return "std::vector -> std::multiset -> adjacent_find()" ; } private: void sort_it() {} void locate_duplicates() { using std::adjacent_find; typedef set SET; typedef SET::iterator ITR; typedef SET::value_type VALUE; typedef boost::tuple TUPLE; typedef vector V_TUPLE; V_TUPLE results; SET local_set; BOOST_FOREACH(const vector ::value_type& v, m_container) { local_set.insert(v); } ITR itr_begin(local_set.begin()); ITR itr_end(local_set.end()); ITR itr(local_set.begin()); ITR itr_range_begin(local_set.begin()); while(itr_begin != itr_end) { // find the start of one equal reange itr = adjacent_find( itr_begin, itr_end, [] (VALUE& v1, VALUE& v2) { return v1 == v2; } ); if(itr_end == itr) break; // end of container // find the end of one equal reange VALUE start = *itr; while(itr != itr_end) { if(!(*itr == start)) break; itr++; } results.push_back(TUPLE(start, itr_range_begin, itr)); // prepare for next iteration itr_begin = itr; } } }; int main() { size_t N = 20; Vector().run(20); List(true).run(20); List(false).run(20); Map().run(20); Multiset().run(20); }
