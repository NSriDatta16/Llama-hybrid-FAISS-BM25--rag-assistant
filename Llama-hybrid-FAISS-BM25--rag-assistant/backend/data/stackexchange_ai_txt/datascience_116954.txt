[site]: datascience
[post_id]: 116954
[parent_id]: 
[tags]: 
Time-series feature enrichment before or after train-test split?

I am dealing with a time-series that represents the CPU usage registered on Azure Virtual Machine. The historical data include a period of 19 months and its granularity is a 10 minute one (each 10 minute the CPU usage level had been registered). My principal objective is the long-term (one week ahead) forecasting of trend. At the beggining, only one column - usageLevel is available in my raw data set. Naturally, before struggling with any prediction model (I am about to test XGBoost, LSTM, transformers etc.) the common practice is to perform a wide feature enrichment. There are multiple strategies and ideas recommended - some of them include moving average features and calendar ones. I have decided to use 15 months as training set and the rest (4 months) as testing set. To avoid any leakage of information from training set to the testing one, should I perform feature enrichment (and outliers handling/removal) only after split and only against the training set? My concern is how the models will cope with the different shape of training and test data if I perform data enrichment only against the training set - or just after the split the same set of transformations should be performed against test set to preserve the same shapes? Thanks in advance!
