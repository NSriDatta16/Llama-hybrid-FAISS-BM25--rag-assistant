[site]: datascience
[post_id]: 36958
[parent_id]: 
[tags]: 
Simple explanation of LSTM data set and training phase

I cannot understand the training procedure of the LSTM (and other recurrent nets). My data is time series of length 2000 points. As suggested on the internet (and keras framework), this should be split into subsequences of 200-400 and fed into LSTM (due to performance issues). How is this justified? According to the maths of back-propagation, we should take 1 sequence (all 2000 points) and feed it to LSTM, which internally will compute the forecast using all 2000 points when spread through time, and update weights in 1 gradient descent step. Thus, we generally feed 1 sequence of 2000 points into LSTM until the optimization converges, which again is the same as having the training set of 1 sample, and each loss function calculation and weight update is 1 epoch. When we have subsequences (say, 4 subsequences of 500 points each from 2000 point time series), they are not connected to each other. We feed them to LSTM as 1 dataset of 4 samples. Are they passed to LSTM as separate samples, or a batch (with weights adjusted for the whole batch per 1 epoch)? Why is this operation justified? Does it not influence the output, since the samples of 500 points are actually connected to each other?
