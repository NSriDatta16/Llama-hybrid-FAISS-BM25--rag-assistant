[site]: crossvalidated
[post_id]: 308779
[parent_id]: 308777
[tags]: 
DeepBlue has already beaten Kasparov so this problem is solved with much simpler approach. This was possible because the number of possible moves in chess is much smaller then in go , so it is a much simpler problem. Moreover, notice that both NN and brute force need huge computing resources ( here you can find a photo of the computer behind AlphaGo, notice that it uses not even GPU's, but TPU's for computation). The whole fuss with go was that when Deep Blue beat Kasparov, the go community has argued that this would not be possible with go (for lots of different reasons, but to summarize the arguments I'd need to give a detailed introduction to the game of go). Yes you can teach NN to play chess, Mario , or try teaching it to play Starcraft ... I guess that the reason for it is that you simply don't often hear in mainstream media about cases when people solve problems that were already solved. Moreover your premise is wrong, Deep Learning is used to play chess, e.g. as described in Deep Learning Machine Teaches Itself Chess in 72 Hours, Plays at International Master Level . See also the corresponding paper, Giraffe: Using Deep Reinforcement Learning to Play Chess .
