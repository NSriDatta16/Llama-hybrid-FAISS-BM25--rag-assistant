[site]: crossvalidated
[post_id]: 532566
[parent_id]: 413652
[tags]: 
I will just provide a counter-point to Robert's answer by building on the comment by User11852. In fitting generalized linear models, the normality of residuals is not necessarily assumed. Often, in large samples, the residuals of a GLM will trend to normally distributed; however, standard residual analyses can produce false positive rejections of a correctly specified model. There are alternative kinds of residuals for GLMs, like deviance residuals and Anscombe residuals, that do tend to be normally distributed. Standard Pearson residuals, however, are often not normal. There are several StackExchange questions talking about this: example 1 , example 2 , example 3 , and example 4 . In short, it is not appropriate to use the assumption of non-normal residuals as a basis for rejecting a GLM since it's not an assumption of the GLMs. You can check the assumptions for a gamma regression like you've run here . The much more important aspect of model building is that you select a model that is appropriate to the data generation process you're modeling. The gamma distribution, for example, is appropriate when your data are continuous, restricted to only positive values, and when you expect the variance in your data to increase as the mean increases. Even if all the assumptions of a standard ordinary least squares regression are met, it doesn't mean that the model is appropriate to your data. For example, it looks like all of your data are positive, so a model that predicts observing negative values does not make sense because those predictions are meaningless and could (potentially) never be observed. Regardless of whether the assumptions are satisfied, the model is misspecified if it is predicting values that can't be observed. Many models are robust to assumption violations, and there are ways to adjust parameter estimates to address assumption violations (e.g., heteroskedastic-consistent standard errors, bootstrapping standard errors). Those kinds of corrections are important when you want to do inference on your model parameters, but a fundamental assumption of all linear models is that the model is correctly specified. You don't want to do inference on a model that is making non-sensical predictions. Long story short, use whatever kind of (G)LM that is appropriate to your outcome data generation process and then tweak the model to make valid inferences (e.g., compensate for assumption violations).
