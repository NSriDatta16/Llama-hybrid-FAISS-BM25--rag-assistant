[site]: crossvalidated
[post_id]: 569474
[parent_id]: 162323
[tags]: 
You've made an important observation that many miss by noticing that so-called classifiers like logistic regressions and neural networks return class membership probability values instead of discrete classes. And I am with you that it is misleading to say that your classifier is really accurate at, say, $98\%$ if you have a $99:1$ class imbalance and could get $99\%$ accuracy by always guessing the majority class. Take it a step further and directly evaluate the probability values. Two common metrics are log loss and Brier score. I'll give the equations for each of those in the binary case, where $y$ is the $0/1$ vector of observed classes and $\hat y$ is the vector of predicted probabilities of class $1$ . $$ \text{Log Loss}(y, \hat y) = -\dfrac{1}{n}\sum_{i=1}^n\left[ y_i\log(\hat y_i) + (1-y_i)\log(1-\hat y_i) \right]\\ \text{Brier Score}(y, \hat y) = \dfrac{1}{n}\sum_{i=1}^n\left( y_i - \hat y_i \right)^2 $$ By looking at the probability values, we do away with hard classifications and can make decisions based on how bad it is to make wrong classifications. For instance, even in a balanced problem, it might be the case that it is much worse to call a $0$ a $1$ than to call a $1$ a $0$ , so we might require extreme evidence to call a case a $1$ , say $P(1)>0.9$ , in order to keep to a minimum the number of times a $0$ gets called a $1$ . This is an example of changing the threshold like you mention in your question, but this has the advantage of being driven by the cost of misclassification, not arbitrary goals about misclassification rate that might be fairly unrelated to actual costs of misclassifications. Further, the cost of misclassification might be different for different subjects. By forcing a discrete choice, you lose the useful information contained in the probabilities. Frank Harrell has two good blog posts on this topic (1) (2) and often writes about it here on Cross Validated.
