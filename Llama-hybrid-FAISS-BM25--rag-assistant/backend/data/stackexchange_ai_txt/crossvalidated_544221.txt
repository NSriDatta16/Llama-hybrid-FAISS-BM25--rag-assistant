[site]: crossvalidated
[post_id]: 544221
[parent_id]: 544216
[tags]: 
This is very general question and there are many factors that can effect model accuracy and the differences between the models. In order to answer about your specific problem, many details are missing (problem types, hyper parameters of the models, dataset size, train\test split etc) I'll explain about some key factors that can affect the results in the general case. generalization: Maybe some models generalize better. You can check it by measuring the performance on the train set and see if it changes the result. If it does, you can improve generalization. Each model can have different ways to improve generalization (e.g. early stopping, regularization, dropout etc) Is the problem linearly separable? - If not, linear models like logistic regression, linear SVM, will not perform well. In this case you either use non linear models or to create non-linear features and feed them to linear models. Note that this, by itself, can't explain the poor performance of non linear models like random forest. Model capacity - if the learnt function is complex, maybe you need large model capacity. Again different for each method\model (e.g. number of layers in deep NN, number of trees and trees depth in random forest etc) Hyper parameters - In many cases you can improve accuracy dramatically by tuning parameters for each model. e.g. number of trees in random forest, regularization term coefficient, learning rate, number of estimators in adaboost etc. If i have to guess, with further tuning you can improve the accuracy of your non linear models like ada boost and random forest.
