[site]: crossvalidated
[post_id]: 375031
[parent_id]: 374954
[tags]: 
First of all, I wouldn't use: $\bar{e_H} = \frac{\sum^{H}_{h=1}e_{t+h}}{H}$ Because negative and positive error terms will cancel each other out. Instead I would use: $MSE = \frac{\sum^{H}_{h=1}e_{t+h}^2}{H}$ or $RMSE=\sqrt{MSE}$ Also frequently used for time series problems is the MAPE: $\bar{e_H} = \frac{\sum^{H}_{h=1}|{e_{t+h}}|}{H}$ . I am struggling with is collecting them in a way that gives me independent results so that I can get a statistically significant measurement of my results and make a meaningful parameter selection. For this, you need to specify first was it the purpose of your forecast in the first place. There are many ways of evaluating error and depending on the domain you are applying your forecasting approach to, one method might be more suitable than the other (See here for some details, and here for some discussion). For example, if you are forecasting weekly demand for a product being shipped from a supplier, and your lead time for that supplier is 3 weeks then all you care about is the forecast values for $H=3$ , so your cross validation split should look like: [1, 2, 3], [6] [1, 2, 3, 4], [7] [1, 2, 3, 4, 5], [8] etc... And your evaluation metric should be: $|e_{t+3}|$ or $e_{t+3}^2$ . However, If you need to forecast values over multiple steps in the forecast horizon, then the above mentioned MSE and MAPE should work. Note also that if you are performing recursive forecasting using traditional methods like ETS or ARIMA, then you can forgo CV all together and use the AIC or the BIC as a model selection criteria. Regarding independence, CV is a little bit tricky in that regard but your overall approach is still correct, because you are preserving the order of the time series when you do a CV split of the type: [1, 2, 3], [4, 5] [1, 2, 3, 4], [5, 6] [1, 2, 3, 4, 5], [6, 7]. Independence would have been an issue for some time series models like ARIMA and ETS if you had used normal CV instead of time series CV, for example, leave one out CV approach such as: [1, 2, 4, 5, 6], [3] [1, 2, 3, 5, 6], [4] [1, 2, 3, 4, 6], [5] Wouldn't work with most time series methods because it ignores the ordered nature of time series data, i.e. prediction the value at [3] using values from [4] and [5] means we are using the future to predict the past, which doesn't make sense. I think this maybe why independence was pointed out to you as an issue for time series. But things get more interesting. Recently, Bergmeir, Hyndman and Koo, have shown that for purely auto-regressive models, such as AR(p) models, Neural Networks, or Support Vector Regression, even normal CV can be used, be used, as long as you format your training data so that it looks like a supervised machine learning problem instead of a time series problem. To understand how this works, first you need to note that pure autoregressive method use only a fixed number of previous periods, so that instead of: [1, 2, 3], [4] [1, 2, 3, 4], [5] [1, 2, 3, 4, 5], [6] [1, 2, 3, 4, 5, 6], [7] You would have for example (for an order 3 (i.e. 3 lags) autoregressive model): [1, 2, 3], [4] [2, 3, 4], [5] [3, 4, 5], [6] [4, 5, 6], [7] Then you need to think of your data in the ML format instead of the time series format: [1, 2, 3 | 4] [2, 3, 4 | 5] [3, 4, 5 | 6] [4, 5, 6 | 7] So that that your data point is not just a single value like [4] but instead a vector with 3 inputs and one target value: [1, 2, 3 | 4] In this case, using normal cross validation (instead of time series cross validation) is valid, because dependence is no longer an issue, and you can train your model on: [2, 3, 4 | 5] [3, 4, 5 | 6] [4, 5, 6 | 7] And test with: [1, 2, 3 | 4] then train the model on: [1, 2, 3 | 4] [3, 4, 5 | 6] [4, 5, 6 | 7] And test with: [2, 3, 4 | 5] And so on.... See "A Note on the Validity of Cross-Validation for Evaluating Autoregressive Time Series Prediction", by Christoph Bergmeir, Rob J Hyndman, and Bonsoo Koob for details. Addressing the additional final part of the question: Yes, you can use a similar K-fold CV approach for multistep forecasts, as long as you are using purely auto-regressive methods . Which means AR models (or ARMA/ARIMA models with q=0) and ML models will work, but not ARIMA models (q â‰  0) or Exponential Smoothing models. Then again ARIMA models and Exponential Smoothing models are inherently sequential, so I don't know that you can use them for direct forecasting at all, and the question is probably moot.
