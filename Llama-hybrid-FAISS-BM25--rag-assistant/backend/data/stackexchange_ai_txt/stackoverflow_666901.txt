[site]: stackoverflow
[post_id]: 666901
[parent_id]: 666528
[tags]: 
If you have thousands of integers and every one occurs roughly three times, your algorithm should find the set of N unique integers pretty quickly, roughly in N(1+e) steps for small e (assuming the integers are ordered relatively randomly). This means that your algorithm would insert N times a random integer into the uniques array. Insert number K would on the average shift K/2 elements in the array, yielding (N^2)/4 move operations. Your binary search would take roughly N * (log(N)-1) steps. This yields total complexity of (N^2)/4 + N(log(N)-1) + N(1+e) for your algorithm. I think you could better e.g. by the following: int num_uniques = 0, startpos = 0, k, element; int uniques[16]; /* Allocate and clear a bit table of 32 * 32 = 1024 bits. */ uint32 bit_table[32], hash; memzero((void *)(&bit_table), sizeof(bit_table)); while (num_uniques > 16); hash *= 0x19191919; hash >>= 22; hash &= 1023; /* Map the hash value to a bit in the bit table. Use the low 5 bits of 'hash' to index bit_table and the other 5 bits to get the actual bit. */ uint32 slot=hash & 31; uint32 bit=(1u > 5)); /* If the bit is NOT set, this is element is guaranteed unique. */ if (!(bit_table[slot] & bit)) { bit_table[slot] |= bit; uniques[num_uniques++] = element; } else { /* Otherwise it can be still unique with probability num_uniques / 1024. */ for (k=0; k This algorithm would run in expected time of N + N^2 / 128 because the probability of running the inner loop (index variable k) is low.
