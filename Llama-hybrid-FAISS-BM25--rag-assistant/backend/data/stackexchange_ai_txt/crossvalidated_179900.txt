[site]: crossvalidated
[post_id]: 179900
[parent_id]: 
[tags]: 
Optimizing a Support Vector Machine with Quadratic Programming

I'm trying to understand the process for training a linear support vector machine . I realize that properties of SMVs allow them to be optimized much quicker than by using a quadratic programming solver, but for learning purposes I'd like to see how this works. Training Data set.seed(2015) df Finding the Maximum Margin Hyperplane According to this Wikipedia article on SVMs , to find the maximum margin hyperplane I need to solve $$ \arg\min_{(\mathbf{w},b)}\frac{1}{2}\|\mathbf{w}\|^2 $$ subject to (for any i = 1, ..., n) $$ y_i(\mathbf{w}\cdot\mathbf{x_i} - b) \ge 1. $$ How do I 'plug' my sample data into a QP solver in R (for instance quadprog ) to determine $\mathbf{w}$?
