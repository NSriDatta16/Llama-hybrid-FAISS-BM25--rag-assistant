[site]: crossvalidated
[post_id]: 90385
[parent_id]: 90378
[tags]: 
This is almost certainly a repeat question, but it remains a good one. It is also a question that is likely to elicit contradictory answers, some of which might be misleading. The "NHST" in your question is not a 'real' thing, but is a hybrid of the frequentist hypothesis test and the Fisherian significance test. The hybrid is very confusing as, according to Gigerennzer, it is a mishmash. The distinction between the two approaches is made clear in a paper of mine that is intended to be accessible to non-statistically sophisticated readers: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3419900/ (another link to the same: https://bpspubs.onlinelibrary.wiley.com/doi/full/10.1111/j.1476-5381.2012.01931.x ) The short answer to your question is that the result of a Neyman-Pearsonian hypothesis test is not a type of evidence and so it is not able to support inferences about the truth or falsehood of hypotheses. Within a strictly frequentist paradigm there is no such thing as evidence because, as Neyman and Pearson said quite clearly in their original paper about frequentist hypothesis tests, their approach relates to long-run error rates and not to how data reflect on the truth or otherwise of a particular hypothesis: We are inclined to think that as far as a particular hypothesis is concerned, no test based upon the theory of probability can by itself provide any valuable evidence of the truth or falsehood of that hypothesis. But we may look at the purpose of tests from another view-point. Without hoping to know whether each separate hypothesis is true or false, we may search for rules to govern our behaviour with regard to them, in following which we insure that, in the long run of experience, we shall not be too often wrong. However, the p-values in your question do not have to be seen as Neyman-Pearson things that served as criteria for dichotomous accept or reject decisions. When interpreted as a continuous scale they serve as an index of the strength of evidence against the null hypothesis. Not a measure, but an index. As a number they directly they quantify the probability of observing data as discrepant as those observed if the null hypothesised parameter value is true, but that is not often exactly what is wanted by an experimenter, and it is not a useable numerical value of the strength of evidence. Statistics doesn't have a clear agreed and unambiguous conception of evidence. However, the statistical object that has, to my mind, the best claim to being a quantification of evidence is the likelihood function. P-values serve as one-to-one index to members of the relevant family of likelihood functions and so in that sense they are indices to the evidence functions. I've written about that too, but it has so far been rejected by several journals, although its arguments have not been refuted and its evidence not contested. I've put a version on ArXive: http://arxiv.org/abs/1311.0081 If you want to be able to evaluate the evidence for and against various hypothesised parameter values, including the null hypothesis, then the likelihood function that the p-value points to is your friend. The strength of evidence in favour of one hypothesis over another is measured by the ratio of the likelihoods at those two parameter values. If you want to change your opinion on the merits of various hypotheses, then you need to use a Bayesian approach, as Patrick Coulombe points out in his brief comments. In such an approach the likelihood function has to be multiplied by your prior probability distribution and scaled to yield the Bayesian posterior probability distribution. The likelihood function is the same as the one that is pointed to by the p-value and so, while it is true that the probability of the hypo[thesis can only be calculated by a Bayesian approach, it is not true to think that the p-value has nothing to say about it. A very small p-value says that the data speak strongly against the null hypothesis, whereas a large p-value says that the data do not contradict the null hypothesis. That is more than nothing, even while it is not exactly what you might want.
