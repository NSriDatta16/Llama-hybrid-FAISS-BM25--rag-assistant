[site]: datascience
[post_id]: 10382
[parent_id]: 10369
[tags]: 
Purging columns with >80% zeros might have been a mistake. Those non-zero values may be the most significant bits in your data. There's a whole field of study in text mining dedicated to discovering knowledge from bag of words models which are tables like yours except can be hundreds of thousands of features wide and >99% empty (i.e. sparse). That said, an idiots approach to feature selection is to fit a linear curve (with linear or logistic regression; or another simple model) to the data, then extract the individual feature coefficients from the model. Those are your influence weights. A simple tool to visualize feature importances is Orange . I find it's Rank widget works for me most of the time.
