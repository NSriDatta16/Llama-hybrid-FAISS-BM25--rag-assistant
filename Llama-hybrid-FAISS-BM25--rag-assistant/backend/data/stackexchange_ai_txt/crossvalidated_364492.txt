[site]: crossvalidated
[post_id]: 364492
[parent_id]: 
[tags]: 
RNN: Why is my loss declining although my gradients are zero?

I am using a recurrent neural network in Tensorflow with an AdaGradOptimizer. For understanding of RNNs I set the gradients to zero manually like this: gvs = optimizer.compute_gradients(cost) gvs[0] = (tf.zeros((5002,2), dtype=tf.float32), tf.trainable_variables()[0]) gvs[1] = (tf.zeros((2,), dtype=tf.float32), tf.trainable_variables()[1]) train_op = optimizer.apply_gradients(gvs) I only have two trainable variables, so above quick-and-dirty approach should set all gradients to zero: tf.trainable_variables() Out[8]: [ , ] When I run the network the loss is still declining. How can that be? As far as I understand the new variable values should be old value + learning rate * gradients.
