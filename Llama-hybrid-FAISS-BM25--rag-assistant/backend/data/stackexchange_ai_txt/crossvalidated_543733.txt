[site]: crossvalidated
[post_id]: 543733
[parent_id]: 
[tags]: 
Why doesn't Logistic Regression require heteroscedasticity and normality of the residuals, neither a linear relationship?

I was reading this link when I got stuck trying to understand. Not even Wooldridge in Introductory Econometrics, or O'Reilly Data Science from Scratch explored this question. And I was surprised I couldn't find any explanation for this question. So, the problem is related to Logistic Regression assumptions. Why doesn't Logistic Regression require the error and linear relationship assumptions that Linear Regression require? I will try to explain better, but if the question get messy, the title is the short question and the thing that got inside my head... So, I know that Logistic Regression is about category targets, but the regression actually predicts the probability of an event/category, right? Isn't that something that would require linear relationships? Regarding the errors, the normality assumption isn't required because the errors will be zero or 1? I thought some assumption would be required, so we don't get any bias (e.g.: we have a logit to predict if someone will pay the debt, but our model gets most of NYC people prediction right, but not from NJ, idk). Well, I think my question got a little messy because I tried to explain better, but hopefully, people will understand and the assumptions will be more explored than most tutorials we have. Thanks in advance
