[site]: crossvalidated
[post_id]: 511862
[parent_id]: 511726
[tags]: 
They all refer to something being " non-neutral ", but, apart from that, I wouldn't say they are related. To my understanding, (2) refers to the computational method, irrespective of the data. For example MLE vs. unbiased estimator of the variance, whether you use $N$ or $(N-1)$ as the denominator. (4), on the other hand, is about the sampling process. Regarding (3), based on my professional experience and acquaintance with machine learning history, I believe the usage of " bias " with the meaning of " intercept " comes from electronics: The early research on what we today call "machine learning", in the 1950's-60's, often involved building specialised hardware or, later, simulating that hardware in computers. " Bias " in electronics means the intentional shift of the operating voltage away from zero, in order to achieve desired response characteristics (typically: linearity) of a component, like transistor or vacuum tube . This is probably also the reason why the intercept in machine learning is often denoted by $b$ and the predictor coefficients (" weights " in neural network terminology) by $\textbf{w}$ .
