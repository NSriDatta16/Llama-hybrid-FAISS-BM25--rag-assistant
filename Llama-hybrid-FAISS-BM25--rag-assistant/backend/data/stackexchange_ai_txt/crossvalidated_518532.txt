[site]: crossvalidated
[post_id]: 518532
[parent_id]: 
[tags]: 
Does it make sense to do PCA before a Tree-Boosting model?

All I could find about this was this answer , which verifies my initial intuition that Decision trees, by virtue of doing recursive splitting of your samples, with splits being based on a single variable, can only generate decision boundaries parallel to the axes of your co-ordinate system. So by rotating the data to directions of maximum variance/diagonalizing your covariance matrix as best you can, it might be easier to put decision boundaries between your class distributions but starts with Disclaimer: I'm usually wrong at things. I want some more validated answer regarding this: Will this improve accuracy? Will this improve time or steps to convergence? Does it make sense in general? Edit: Please notice I said nothing about dimension reduction using PCA. If there is a difference in answer depending on weather PCA reduces dimension or not, please also explain why that is.
