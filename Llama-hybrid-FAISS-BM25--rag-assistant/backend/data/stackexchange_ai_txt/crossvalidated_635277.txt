[site]: crossvalidated
[post_id]: 635277
[parent_id]: 455334
[tags]: 
I figured these "eight principal components" would be some kind of transformed versions of the original variables, thus not making it directly valid to apply this insight to the variables in their original form. Please correct me if I'm wrong! it depends on the fitting tool (package, library, solver implemented) that you're using. With Python sklearn you can use sklearn.decomposition.PCA - with this class you can find pca.explained_variance_ratio_ and if then you need to return from components to the original space of your data you can use inverse_transform(X) after you have done transform(X) - dimensionality reduction to X ( explained ) When you call transform you're asking sklearn to actually do the projection. That is, you are asking it to project each row of your data into the vector space that was learned when fit was called.
