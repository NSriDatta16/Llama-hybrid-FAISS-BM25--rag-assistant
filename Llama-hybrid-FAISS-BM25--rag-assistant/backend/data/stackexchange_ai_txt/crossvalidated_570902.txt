[site]: crossvalidated
[post_id]: 570902
[parent_id]: 
[tags]: 
Why can de-noising diffusion models be sampled with Gaussian distributions?

In de-noising diffusion models 1 the latent is typically sampled with a unit normal distribution, and then the sample (e.g. image) is generated by iteratively removing noise during the backwards process. Whereas in the diffusion (forward) process, the random Gaussian latent is predicted by iteratively adding Gaussian noise to the original image. So is the implication that this iterative addition of gaussian noise to the image (in the forward process) eventually leads back to an approximately unit gaussian distribution for the resulting random variable? In other words, assuming the sample/image distribution itself is not Gaussian, is there some reason to expect that adding a large number of gaussian distributions to an initial non-Gaussian random variable would lead back to a unit Gaussian distribution, at least in the limit of this Gaussian random walk? Denoising Diffusion Probabilistic Models by Jonathan Ho, Ajay Jain, Pieter Abbeel
