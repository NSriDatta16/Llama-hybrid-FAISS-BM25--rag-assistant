[site]: crossvalidated
[post_id]: 549539
[parent_id]: 
[tags]: 
Simulating matrix vector multiplication using a neural network

I am trying to simulate a matrix vector multiplication $Av=u$ using a neural network implementation in Tensorflow. I have testing and training data that consist of the $u$ and $v$ vectors and I am trying to train a network that looks like this: n_test = 20 n_train = 20000 opt = keras.optimizers.Nadam(learning_rate=0.0005) model_s = keras.models.Sequential() model_s.add(keras.layers.InputLayer(input_shape=(2**L,))) model_s.add(keras.layers.Dense(16, use_bias=False)) model_s.compile(optimizer=opt, loss='MeanSquaredError') model_s.fit(v_train, u_train, batch_size=800, epochs=100) model_s.evaluate(v_test, u_test, verbose=1) u_tilde = model_s.predict(v_test) where $u,v$ are 16 by 1 matrices. The $A$ matrix is a representation of $y=\int{sin(s-x)ds}$ I am getting about $10^{-11}$ relative error for most of the $u$ vector components, but some of the components only get about $10^{-4}$ error. I am curious as to why the results are not more uniformly accurate, as my network is structured exactly like the problem i am trying to solve, and I have a large number of training samples.
