[site]: crossvalidated
[post_id]: 67415
[parent_id]: 47821
[tags]: 
The decision rule for a (linear kernel) SVM is given by $f(x_{new}) = \textrm{sign}(\sum_{i}\alpha_{i}x_{i}^{T}x_{new} + b)$, where $\alpha_{i}$ is non-zero for only a subset of the $x_{i}$ (the support vectors) and I lump the training label $y_{i}$ in with $\alpha_{i}$ as part of the "weight" for support vector $x_{i}$. The decision rule is generally never expressed as $f(x_{new}) = \textrm{sign}(w^{T}x_{new} + b)$, with $(w,b)$ being the parameters for the optimal separating hyperplane from the SVM optimization. If you're looking for algorithms where representing the decision rule in that particular inner-product format is desirable, SVM may not be appropriate for you. You could instead use constrained logistic regression if you want to enforce the hyperplane coefficient condition $w_{i} > 0, \forall{} i$, but you make the optimization much harder and lose guarantees on properties of the classifier. I haven't thought too much about it, but you may also lose feasibility. At the very least, you must by definition produce a classifier that has a worse margin than the traditional SVM. Suppose you were only considering a linear kernel. SVM will pick out the line (among all lines) that yields maximum margin in the data (in the case it is linearly separable). If you add a constraint like $w_{i} > 0, \forall{} i$, then you are asking the SVM algorithm to search only over a special subset of lines, with positive coefficients. So the best achievable margin there will be no better than the best margin among all possible lines, and probably a lot worse. And you will lose the ability to use the same Lagrangian dual representation that allows for the support-vector based decision rule I mentioned above, since the dual will now involve new constraints. Can you share more information about the nature of your problem and why it requires this constraint? Lastly, as far as I can tell, the mention of SVM-struct is entirely non-sequitur. That is a method for having vector- or structure-valued outputs instead of merely having class labels (some scalar enumeration data type) as the outputs.
