[site]: stackoverflow
[post_id]: 3270866
[parent_id]: 3270794
[tags]: 
There is no easy way to prove that any given algorithm is asymptotically optimal. Proving optimality (if ever) sometimes follows years and/or decades after the algorithm has been written. A classic example is the Union-Find/disjoint-set data structure . Disjoint-set forests are a data structure where each set is represented by a tree data structure, in which each node holds a reference to its parent node. They were first described by Bernard A. Galler and Michael J. Fischer in 1964, although their precise analysis took years. [...] These two techniques complement each other; applied together, the amortized time per operation is only O(α(n)) , where α(n) is the inverse of the function f(n) = A(n,n) , and A is the extremely quickly-growing Ackermann function. [...] In fact, this is asymptotically optimal: Fredman and Saks showed in 1989 that Ω(α(n)) words must be accessed by any disjoint-set data structure per operation on average. For some algorithms optimality can be proven after very careful analysis, but generally speaking, there's no easy way to tell if an algorithm is optimal once it's written. In fact, it's not always easy to prove if the algorithm is even correct. See also Wikipedia/Matrix multiplication The naive algorithm is O(N 3 ) , Strassen's is roughly O(N 2.807 ) , Coppersmith-Winograd is O(N 2.376 ) , and we still don't know what is optimal. Wikipedia/Asymptotically optimal it is an open problem whether many of the most well-known algorithms today are asymptotically optimal or not. For example, there is an O(nα(n)) algorithm for finding minimum spanning trees. Whether this algorithm is asymptotically optimal is unknown, and would be likely to be hailed as a significant result if it were resolved either way. Practical considerations Note that sometimes asymptotically "worse" algorithms are better in practice due to many factors (e.g. ease of implementation, actually better performance for the given input parameter range, etc). A typical example is quicksort with a simple pivot selection that may exhibit quadratic worst-case performance, but is still favored in many scenarios over a more complicated variant and/or other asymptotically optimal sorting algorithms.
