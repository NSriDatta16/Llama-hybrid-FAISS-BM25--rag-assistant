[site]: datascience
[post_id]: 78316
[parent_id]: 
[tags]: 
How do we know a neural network test accuracy is good enough when results vary with different runs?

In every paper I read about prediction models, the training accuracy and the test accuracy (sometimes also the validation accuracy) is stated as a discrete number. However, in experience, depending on how the weights are initialized, different training runs result in different testing results. How does a standard data science researcher pinpoint the accuracy metric to be written in a paper, and how does ze get certain about its validness?
