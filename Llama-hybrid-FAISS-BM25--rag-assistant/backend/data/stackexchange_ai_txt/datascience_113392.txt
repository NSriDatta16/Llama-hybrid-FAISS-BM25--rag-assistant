[site]: datascience
[post_id]: 113392
[parent_id]: 72371
[tags]: 
"Is there a golden standard for equalizing time series observations?" Ans.: No. But there are some approaches. A time-series where the events occur in arbitrary time can be approached modeling the distribution of the number of events occcuring in a given time interval and the distribution of time intervals between the events. This is a point process . Another approach is you resample the time-domain aggregating the values in fixed intervals of time, and look for this new time-series for make your forecast. Maybe the new time-series will be "well-behaved", enabling that statistical methods such as linear models to be applied directly. Your approach with LSTM can be a good choice, because the pre-requisites of this machine learning algorithm are less restrictive (compared to ARIMA, e.g.). There many studies about combination of methods for this type of problem. A good reference about point process in this context is https://books.google.com.br/books?id=eMuCDwAAQBAJ&hl=pt-BR . Another good reference about point process, with Python, is this Github: https://github.com/MatthewDaws/PointProcesses They have some Jupyter notebooks, as this: https://nbviewer.org/github/MatthewDaws/PointProcesses/blob/master/Temporal%20points%20processes.ipynb
