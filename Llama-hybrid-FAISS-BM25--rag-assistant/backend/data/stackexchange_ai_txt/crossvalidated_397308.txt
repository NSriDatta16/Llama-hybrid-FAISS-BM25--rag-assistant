[site]: crossvalidated
[post_id]: 397308
[parent_id]: 396524
[tags]: 
Thanks to God! I finally found the issue and here it is . First of all, since this is a sequence generation example, and all samples do not have the same length, we cant use batches of samples. so we use batch of 1. Technically speaking we can use batches, but there is a catch! One solution is to use the biggest length for all sequences. This will only work in two cases : Your sequence is very short when you are dealing with vanilla rnn. If you have long sequences, you must use LSTM or GRU units. Since we are using the vanilla rnn, and our sequences are relatively long (between 11 to 27 characters long), we cant use the same length for everyone. This means that in the back-propagation part, we wont be subtracting the whole output from the corresponding label, rather we only check the index of the correct word in our output against our label( np.argmax() of our label) and see if at that index, our output was correct or not(or simply subtracting that index in our output from 1) output[0,np.argmax(label)] -= 1 or output[0,np.argmax(label)] -= label[0,np.argmax(label)] I also made a mistake in backpropagation section here : instead of using the h_previous, I used dh_previous. so the correct form was : def rnn_cell_backward(self, xt, h, h_prev, output, true_label, h_gradient_or_dh): """ h: is the next state output: is the output of the current cell! true_label: is the true label for the current output h_gradient_or_dh: is the dh which in the beginning is zero and is updated as we go backward in the backprogagation remember the backward pass is essentially a loop! so have that in mind and you will be fine! """ e = np.copy(output) e[0,np.argmax(true_label)] -= true_label[0,np.argmax(true_label)] per_ts_loss = e[0,np.argmax(true_label)] # must have shape of W3 which is (vocabsize_or_output_dim_size, hidden_state_size) dW3 = np.dot(e.T, h) dh = np.dot(e, self.W3) + h_gradient_or_dh # from later cell # dbo +=e.1, we use sum, because we have a batch #e is a vector, when it is subtracted from label, the result will be added to dbo # since batchsize is always 1 we dont need to do np.sum(e, axis=0) dbo = e.reshape(e.shape[1]) # the input part dtanh = (1 - h**2) * dh # compute the gradient of the loss with respect to W1 dxt = np.dot(dtanh, self.W1.T) # must have the shape of (vocab_size, hidden_state_size) dW1 = np.dot(xt.T, dtanh) # compute the gradient with respect to W2 dh_prev = np.dot(dtanh, self.W2) # shape must be (HiddenSize, HiddenSize) dW2 = np.dot(h_prev.T, dtanh) #print('dtanh.shape = ',dtanh.shape) # dbh += dtanh.1, we use sum, since we have a batch dbh = np.sum(dtanh, axis=0) return dW1, dW2, dW3, dbh, dbo, dxt, dh_prev, dh, per_ts_loss There was also something wrong in the forward pass. Since the sequence length is not the same, we cant have a prespecified H, and O. and thus making them a class field serves nor purpose. Also, we can have 2 options when feeding the h_previous to the calculations. use zero initialized h_previous always use the last hidden state of calculated by previous sample. Since our examples are not related in anyway, we should use the first option. My first impression was that if we go the second route, we will see the network cant perform decently at all and fails to create meaningful outputs, whereas in the case of the first method, it can quickly learn to produce good outputs. I was wrong!! at least in this example, they create the same exact outputs! So the rnn_layer_forward should look like this instead : def rnn_layer_forward(self, Xt, H=None): batch, input_dim_size, T_x = Xt.shape # allocate H, and O for the first time H = np.zeros(shape=(batch, self.hidden_state_size, T_x)) O = np.zeros(shape=(batch, self.outputsize, T_x)) if (self.mode == 1): h_previous = np.zeros(shape=(batch, self.hidden_state_size)) else: h_previous = self.H[:, :, -1] for t in range(T_x): output, h_t = self.rnn_cell_foward( Xt[:, :, t], h_previous) self.H[:, :, t] = h_t self.O[:, :, t] = output # Our current/new hiddenstate will be the previous hiddenstate for the next round, h_previous = h_t return O, H
