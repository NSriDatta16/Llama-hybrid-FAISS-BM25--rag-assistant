[site]: crossvalidated
[post_id]: 568938
[parent_id]: 
[tags]: 
Is there such a thing as intra-sample modal collapse in GANs?

Mode collapse is a known issue in generative adversarial networks (GANs) whereby the generator only learns a subset of the real data distribution. In those cases, it only outputs variations of a small number of images. For example, in the MNIST handwritten digit dataset, the generator might only learn to produce 7s and 9s. In my experiments, the generator replicates similar square patches of pixels within the same output image , and not necessarily across multiple images. Has this phenomenon been studied in GANs, and is it still called mode collapse?
