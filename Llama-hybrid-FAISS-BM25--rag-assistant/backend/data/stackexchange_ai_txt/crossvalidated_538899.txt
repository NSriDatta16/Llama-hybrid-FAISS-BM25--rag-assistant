[site]: crossvalidated
[post_id]: 538899
[parent_id]: 538891
[tags]: 
From the documentation : A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. [â€¦] bootstrap: bool , default=True Whether samples are drawn with replacement. If False, sampling without replacement is performed. bootstrap_features: bool , default=False Whether features are drawn with replacement. Random forest is just a bagging classifier (or regressor) using trees as base classifiers. It by default resamples both rows (samples) and columns (features). Notice that you don't want to use the same random seed for each tree, because you want the base classifiers to be randomly different. Other arguments like max_depth can be passed to random forest directly. Almost always you should just use the random forest, rather than constructing it yourself since the build-in implementation is already tested and optimized for the task.
