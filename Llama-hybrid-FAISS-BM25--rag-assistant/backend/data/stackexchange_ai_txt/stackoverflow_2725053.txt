[site]: stackoverflow
[post_id]: 2725053
[parent_id]: 2724937
[tags]: 
It seems as if your input set must be very large, if a lookup table will be too large to store on the disk. I assume that that the data will not fit in RAM then, which means that whatever algorithm you use should be tuned to minimize the amounts of reads and writes. Whenever disks are involved space == time, because writing to disk is so slow. The exact algorithm you should use depends on what kind of graph you have. This research paper might be of interest to you. Full disclosure: I have not read it myself, but it seems like it might be what you are looking for. Edit: If the graph is (almost) connected, which a small-world network is, a lookup table can't be smaller than V^2. This means that all lookups will require disk access. If the edges fit in main memory, it might be faster to just compute the path every time. Otherwise, you might compute the path from a table containing the lengths of all shortests paths. You can reconstruct the path from that table. The key is to make sure that the entries in the table which are close to each other in either direction are also close to each other on the disk. This storage pattern accomplishes that: 1 2 1 2 5 6 3 4 3 4 7 8 9 10 13 14 11 12 15 16 It will also work well with the cache hierarchy. In order to compute the table you might use a modified Floyd-Warshall , where you process the data in blocks. This would let you perform the computation in a reasonable amount of time, especially if you parallelize it.
