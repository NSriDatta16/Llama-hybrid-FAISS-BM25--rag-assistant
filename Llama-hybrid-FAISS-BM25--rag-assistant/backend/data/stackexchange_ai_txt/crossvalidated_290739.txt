[site]: crossvalidated
[post_id]: 290739
[parent_id]: 
[tags]: 
Cross validation and predicting models in R

Im having a few issues with understanding cross validation and how to apply this to produce predictive models. Im am currently working on Neural Networks (in r) and i'm using the caret package to perform a k-fold cross validation (k=10) on the train portion of my dataset (70% of entire dataset). I have three questions: 1) Can i use Cross validation to determine the best hyperparametres of a model? 2) Once the hyperparametres are selected using the ROC value would i then need to test this final model against a test set (my remaining 30% unseen data) or is this the whole point of cross validation in that i do not need a separate test set? 3) If i do need to test the final model, how exactly do i do this. For example if the cross validation determines that a neural network with size=10 and decay =0.01 has the highest ROC value, would i rewrite this model and run it with all the train data and test this model on my test set to determine its true predictive power on unseen data?
