[site]: crossvalidated
[post_id]: 299199
[parent_id]: 299120
[tags]: 
Suppose you have a binary classification problem with $p$ features (including bias) and you do Multi-class regression with softmax activation. Then, the probability of an observation, $x,$ representing class $1$ is, $$ \begin{split} p_1(x) &= \frac{\exp(\beta_1^T x)}{\exp(\beta_1^T x) + \exp(\beta_2^T x)} \\ &= \frac{1}{1 + \exp[(\beta_2 - \beta_1)^T x]} = \sigma\left([\beta_1 - \beta_2]^T x\right). \end{split} $$ where both $\beta_1$ and $\beta_2$ are $p \times 1$ parameters, and I simply multiplied both numerator and denominator by $\exp(- \beta_1^T x).$ Note that the RHS of the above expression is simply the sigmoid function. Thus, the $p \times 1$ parameter $\beta$ you would get from doing ordinary binary logistic regression with sigmoid activation is analogous to $\beta_1 - \beta_2,$ where the latter parameters are from multiclass softmax regression.
