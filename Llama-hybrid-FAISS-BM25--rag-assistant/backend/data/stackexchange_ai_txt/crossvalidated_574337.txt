[site]: crossvalidated
[post_id]: 574337
[parent_id]: 574333
[tags]: 
The runs test ( NIST page ) is a nonparametric test designed to identify unusual frequencies of runs. If we observe $n_1$ heads and $n_2$ tails, the expected value and variance of the number of runs are: $$\mu = {2n_1n_2 \over n_1+n_2} + 1$$ $$\sigma^2 = {2n_1n_2(2n_1n_2 - n_1 - n_2) \over (n_1+n_2)^2(n_1+n_2+1)}$$ As a rule of thumb, for $n_1, n_2 \geq 10$ the distribution of the observed number of runs is reasonably well-approximated by a Normal distribution. Edit: (incorporating Eric Duminil 's work below) For sequence 1, we have 148 heads, 152 tails, 205 runs, and for sequence 2, we have 148 heads, 152 tails and 154 runs. Plugging these numbers into our formulae above give us $z$ -scores of 6.5 for the first sequence and 0.58 for the second sequence - extremely strong evidence that the first sequence is fake. When people fake sequences like this, they tend to greatly underestimate the probability of longer runs, so they don't create as many long(ish) runs as they should. This in turn tends to increase the number of runs beyond that which would be expected. Consequently, when testing for faked data, we might prefer a one-sided test of the alternative hypothesis that there are "too many" runs vs. the null hypothesis that the number of runs is average - at least if we think the sequence was created by a human being.
