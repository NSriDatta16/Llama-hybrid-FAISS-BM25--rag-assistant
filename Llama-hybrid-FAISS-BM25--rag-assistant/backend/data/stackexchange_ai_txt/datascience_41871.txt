[site]: datascience
[post_id]: 41871
[parent_id]: 
[tags]: 
How to use Statistical Learning theory in real analysis

I begin the post trying to say that I don't know if this post is in compliance with community rules, so pardon me for any abuse. I studied statistical learning theory back at university. Specifically, PAC learning, VC Dimension, Uniform convergence, etc. Recently. I watched this talk , with Vapnik, in which he claims that deep learning is essentially "a bla bla interpretation" and also claims that "every problem can be solved with statistical learning theory." I am very confused about this. I can't see how I can apply statistical learning theory to real problems. Let's suppose I'm facing a new dataset with a clear task of binary classification, with many features and lots of training data. How am I supposed to check for example, if a hypothesis class H is PAC learnable, or in other words if it has a finite VC dimension? Don't take my example too literally, I just would like to know if someone can point me out to an article, blog, or some kind of answer that clearly shows how we can use these theorems and results in real analysis. Thank You.
