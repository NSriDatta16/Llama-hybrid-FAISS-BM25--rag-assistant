[site]: stackoverflow
[post_id]: 678871
[parent_id]: 678771
[tags]: 
I'll bet that your hardware vendor is asking how many MIPS you need. As in "Do you need a 1,000 MIPS processor or a 2,000 MIPS processor?" Which gets translated by management into "How many MIPS?" Hardware offers MIPS. Software consumes MIPS. You have two degrees of freedom. The processor's inherent MIPS offering. The number of seconds during which you consume that many MIPS. If the processor doesn't have enough MIPS, your algorithm will be "slow". if the processor has enough MIPS, your algorithm will be "fast". I put "fast" and "slow" in quotes because you need to have a performance requirement to determine "fast enough to meet the performance requirement" or "too slow to meet the performance requirement." On a 2,000 MIPS processor, you might take an acceptable 2 seconds. But on a 1,000 MIPS processor this explodes to an unacceptable 4 seconds. How many MIPS do you need? Get the official MIPS for your processor. See http://en.wikipedia.org/wiki/Instructions_per_second Run your algorithm on some data. Measure the exact run time. Average a bunch of samples to reduce uncertainty. Report. 3 seconds on a 750 MIPS processor is -- well -- 3 seconds at 750 MIPS. MIPS is a rate. Time is time. Distance is the product of rate * time. 3 seconds at 750 MIPS is 750*3 million instructions. Remember Rate (in Instructions per second) * Time (in seconds) gives you Instructions. Don't say that it's 3*750 MIPS. It isn't; it's 2250 Million Instructions.
