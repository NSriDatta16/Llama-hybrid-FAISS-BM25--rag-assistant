[site]: crossvalidated
[post_id]: 329703
[parent_id]: 271768
[tags]: 
This is an interesting question. I guess that you have observed the effect of using a nonproper scoring rule. Accuracy is a noncontinuous (and nonproper) scoring rule, it will only change when the parameters under learning have changed sufficiently to actually change the decision. What you call Loss in the plot, cross-entropy, is akin to logistic regression, it is a continuous function of the parameters, and a proper scoring rule. So the difference you see in the plots is kind of expected, though the magnitude is interesting! Some other posts with more information is Why isn't Logistic Regression called Logistic Classification? and Alternative notions to that of proper scoring rules, and using scoring rules to evaluate models Here is another post which seems to run into the same problem: Probability Calibration messes Reliability
