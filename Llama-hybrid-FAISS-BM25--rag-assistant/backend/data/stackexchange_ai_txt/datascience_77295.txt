[site]: datascience
[post_id]: 77295
[parent_id]: 
[tags]: 
How to determine sample rate of a time series dataset?

I have a dataset of magnetometer sensor readings which looks like: TimeStamp X Y Z 1.59408E+12 -22.619999 28.8 -22.14 1.59408E+12 -22.5 29.039999 -22.08 1.59408E+12 -22.32 29.039999 -21.779999 1.59408E+12 -22.38 29.16 -21.6 . . . And so on The timestamp is in milliseconds where 1.59408E+12, 1.59408E+12, 1.59408E+12 is 1594076006983, 1594076006994, 1594076007004 and so on. So what will be the sampling rate/ frequency of the data?
