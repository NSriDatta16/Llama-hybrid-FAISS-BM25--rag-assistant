[site]: crossvalidated
[post_id]: 509216
[parent_id]: 
[tags]: 
Is it possible to recover original normal distributions from observations of sums of normally distributed variables?

I have been trying to solve the following problem for several weeks. I would greatly appreciate it if you help me solve the following problem. Problem description Assume that there are seven iid normal distributions with zero means and different standard deviations. They are $$X_A \sim N(0,\sigma_A)$$ $$X_B \sim N(0,\sigma_B)$$ $$X_C \sim N(0,\sigma_C)$$ $$X_{D} \sim N(0,\sigma_{D})$$ $$X_{E} \sim N(0,\sigma_{E})$$ $$X_{F} \sim N(0,\sigma_{F})$$ $$X_{G} \sim N(0,\sigma_{G})$$ Assume that we have observations of the sums of them as $$Y_A = X_A + X_{D}+X_{E}+X_{G}$$ $$Y_B = X_B + X_{D}+X_{F}+X_{G}$$ $$Y_C = X_C + X_{E}+X_{F}+X_{G}$$ My question is: Is is possible to recover $\sigma_A$ , $\sigma_B$ , $\sigma_C$ , $\sigma_{D}$ , $\sigma_{E}$ , $\sigma_{F}$ , and $\sigma_{G}$ from $Y_A$ , $Y_B$ and $Y_C$ ? If so, how? What I have tried I built several matrix equations based on moments and correlation coefficients, but the matrix equation's rank is always 6, which is a rank-deficient problem. I missed one more condition to make a matrix equation regular... I am stuck here. Update 1 I came up with the following approach, but the result is still rank = 6. The variances of $Y_A$ , $Y_B$ , and $Y_C$ are given as $$ \begin{split} \mathrm{Var}(Y_A) &= \mathrm{Var}(X_A) + \mathrm{Var}(X_{D})+\mathrm{Var}(X_{E})+\mathrm{Var}(X_{G})\\ &= \sigma^2_{A}+\sigma^2_{D}+\sigma^2_{E}+\sigma^2_{G}\\ \mathrm{Var}(Y_B) &= \sigma^2_{B}+ \sigma^2_{{D}}+\sigma^2_{{F}}+\sigma^2_{{G}}\\ \mathrm{Var}(Y_C) &= \sigma^2_{C} + \sigma^2_{{E}}+\sigma^2_{{F}}+\sigma^2_{{G}}\\ \end{split} $$ Similarly, using the property of variance, I derived expressions for $\mathrm{Var}(Y_A-Y_B)$ , $\mathrm{Var}(Y_B-Y_C)$ , $\mathrm{Var}(Y_C-Y_A)$ , $\mathrm{Var}(Y_A-Y_B)$ , $\mathrm{Var}(Y_A+Y_B-Y_C)$ , $\mathrm{Var}(Y_A-Y_B+Y_C)$ , and $\mathrm{Var}(-Y_A+Y_B+Y_C)$ . Using the above expressions, I built a matrix expression in the form of $Ax =b$ where $$ x^T = \begin{bmatrix} \sigma^2_{A} & \sigma^2_{B} & \sigma^2_{C} & \sigma^2_{D} & \sigma^2_{E} & \sigma^2_{F} \end{bmatrix} $$ $$ b^T = \begin{bmatrix} \mathrm{Var}(Y_A) & \mathrm{Var}(Y_B) & \mathrm{Var}(Y_C) & \cdots &\mathrm{Var}(-Y_A+Y_B+Y_C) \end{bmatrix} $$ $$ A = \begin{bmatrix} 1 & 0 & 0 & 1 & 0 & 1 & 1 \\ & & & \vdots & & & \\ 1 & 1 & 1 & 0 & 0 & 4 & 1 \\ \end{bmatrix} $$ and the rank of A is $\mathrm{rank}(A) = 6$ . Update 1 End Update 2 I thought it might be impossible to estimate all variances from $Y_*$ , so I wrote a Bayesian model using stan to estimate $\sigma_*$ from $Y_*$ . If a Bayesian model does not recover the variances, it might be impossible to estimate $\sigma_*$ analytically. Due to a proprietary reason, I am not allowed to provide the stan model, but I can show the result. import numpy as np import pandas as pd import matplotlib.pyplot as plt import pystan import arviz import sys %matplotlib inline def generate_sample_data(num, seed=100): # target variance trueValues = [0.1, 0.3, 0.5, 0.02,0.08,0.03,0.01] np.random.seed(seed=seed) values = np.zeros((4,num)) print(values) ln_A = np.random.normal(0,trueValues[0],num) ln_B = np.random.normal(0,trueValues[1],num) ln_C = np.random.normal(0,trueValues[2],num) ln_AB = np.random.normal(0,trueValues[3],num) ln_BC = np.random.normal(0,trueValues[4],num) ln_AC = np.random.normal(0,trueValues[5],num) ln_ABC = np.random.normal(0,trueValues[6],num) values[0,:] = ln_A+ln_AB+ln_AC+ln_ABC values[1,:] = ln_B+ln_AB+ln_BC+ln_ABC values[2,:] = ln_C+ln_AC+ln_BC+ln_ABC return values,trueValues num = 100000 values, trueValues = generate_sample_data(num) print(np.std(values[0])) print(np.std(values[1])) print(np.std(values[2])) sample_code2 = """ // stan code with a trick here """ sm2 = pystan.StanModel(model_code=sample_code2) sample_data = { 'N': num, 'Y_A': values[0], 'Y_B': values[1], 'Y_C': values[2] } fit2 = sm2.sampling(data=sample_data, iter=10000, chains=8,thin=3, control=dict(adapt_delta = 0.99, max_treedepth=32)) print(fit2) and the result is mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat sigma_A 0.1 4.0e-5 3.7e-3 0.09 0.1 0.1 0.1 0.11 8706 1.0 sigma_B 0.3 1.6e-5 1.6e-3 0.3 0.3 0.3 0.3 0.3 9525 1.0 sigma_C 0.5 9.7e-6 9.7e-4 0.5 0.5 0.5 0.5 0.5 9861 1.0 sigma_D 0.01 8.0e-5 7.9e-3 5.5e-4 6.1e-3 0.01 0.02 0.03 9599 1.0 sigma_E 0.08 6.2e-5 6.0e-3 0.07 0.08 0.08 0.08 0.09 9522 1.0 sigma_F 0.03 1.5e-4 0.01 2.3e-3 0.02 0.03 0.04 0.05 8215 1.0 sigma_G 0.01 7.7e-5 7.9e-3 7.3e-4 6.7e-3 0.01 0.02 0.03 10494 1.0 sigma_Y_A 0.11 2.1e-6 2.4e-4 0.11 0.11 0.11 0.11 0.11 13159 1.0 sigma_Y_B 0.31 5.5e-6 6.4e-4 0.31 0.31 0.31 0.31 0.31 13413 1.0 sigma_Y_C 0.51 1.0e-5 1.1e-3 0.5 0.5 0.51 0.51 0.51 10927 1.0 The Bayesian model can estimate $\sigma_*$ accurately if large numbers of samples are available. I now think it is possible to estimate $\sigma_*$ from $Y_*$ . Update 2 End In the literature, I believe that a similar problem must have been studied, but I could not find any yet. Thank you for your help and kindness.
