[site]: crossvalidated
[post_id]: 442127
[parent_id]: 441847
[tags]: 
Convolutional Neural Networks (such as the one you utilize) tend to increase the information density per neuron from the lower layers to the higher ones. Therefore, it is useful to decrease the kernel size when reaching deeper layers as you already did. From experience, I can tell you that $5\times 5$ kernels in early layers with $3 \times 3$ kernels in subsequent layers are a very good starting point. Also it is usual to put a Dense layer as the last layer of your network (with Softmax activation) since arrangement of the labels in the last layer should be independent of the spatial information that is carried by the CNN layers. My question now is: why don't you use more advanced features such as MFCCs, PCEN ( https://arxiv.org/pdf/1607.05666.pdf ), Constant-Q-Transform (for music mostly), or Modulation Domain approaches ( https://pdfs.semanticscholar.org/62d6/954ddf58aa9420bbe59146f7e632f4df01b1.pdf ) that have been shown to achieve better results in general on audio tasks?
