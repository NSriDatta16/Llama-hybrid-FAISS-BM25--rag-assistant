[site]: datascience
[post_id]: 81548
[parent_id]: 
[tags]: 
Use predicted data to improve Multinomial Naive Bayes model for text classification

For a small project, I am making use of Naïve Bayes Multinomial Model to do some text classification. It has shown some very promising results, especially since I don't have a lot of Training data. Currently, it happens that some predictions are false, but would it be possible to reuse the text and the corrected class to "improve" the model ? E.g.: My model has to classify text as either sports, or politics. Let's image that the model classifies text t = "Ronaldo plays at Juventus." as being politics, which is not the case. Would it be possible to "reinject" text t with the correct class into the model, in order to improve it ? Is it good practice within Machine Learning ? My model is a basic Multinomial Naïve Bayes (using Sklearn) and makes use of TFIDF and SpaCy to remove unnecessary words from the text (like stop-words, etc.).
