[site]: crossvalidated
[post_id]: 319923
[parent_id]: 
[tags]: 
When building a convolutional neural network, why is 32 the typical number of feature maps ("activation maps") generally chosen?

I've noticed that in multiple tutorials showing how to create a convolutional neural network using the MNIST dataset, the number of feature maps (or "activation maps"), chosen is typically 32. I am wondering if 32 feature maps is arbitrary or if there's an underlying purpose for using 32 specifically. Here's an example tutorial that uses 32 feature maps in the first convolution: https://www.tensorflow.org/get_started/mnist/pros#deep-mnist-for-experts
