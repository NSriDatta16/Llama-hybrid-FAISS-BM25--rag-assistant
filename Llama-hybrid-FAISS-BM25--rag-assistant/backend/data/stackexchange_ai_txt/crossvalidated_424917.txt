[site]: crossvalidated
[post_id]: 424917
[parent_id]: 424209
[tags]: 
No, this is not overfitting but overconfidence, which is a common property of normal CNNs. Bayesian CNNs and models that include uncertainty quantification would give you something closer to the effect you want, with increased entropy in the output probabilities for out-of-distribution examples. For this problem you can take a look at two papers: A Baseline for Detecting Misclassified and Out of Distribution Examples in Neural Networks . Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles .
