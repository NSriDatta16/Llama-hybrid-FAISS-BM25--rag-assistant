[site]: datascience
[post_id]: 112612
[parent_id]: 112607
[tags]: 
Answer to your exact question: I assume that you duplicated these unique-class instances only once, right? If so, the full dataset contains 2 instances for each of these classes. Since I see that the test set is made of 20% of the instances, then it's normal that there's not always one such instances in the test set: even stratified, 20% of 2 instances is only 0.4 instances in average in the test set, so it can be zero. More importantly, I think that your design is flawed: these single-class instances are irrelevant and should be removed before training the model. The training data is supposed to contain a representative sample for every class, and one instance is never a statistically representative sample. Moreover, the performance is completely biased for these cases since the test set contains a single instance which is a duplicate of the single training instance. This can in turn bias the overall evaluation, especially if macro-average of any kind is used. Normally classes which are rare (for instance $N\leq 5$ ) should be removed, they can only cause overfitting in the model. The goal of a model is to recognize patterns which are sufficiently frequent, not extremely rare events. it's already hard enough for the model to distinguish between many classes: keep in mind that a baseline model would only reach 0.001 accuracy with 1000 possible classes.
