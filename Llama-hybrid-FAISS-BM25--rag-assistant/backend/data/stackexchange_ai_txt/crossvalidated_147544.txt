[site]: crossvalidated
[post_id]: 147544
[parent_id]: 
[tags]: 
Posterior predictive for Gamma distribution with unknown scale and shape

I have a question that needs clarification. The posterior predictive distribution can be described as the distribution that a new i.i.d. data point $\tilde{x}$ would have, given a set of $N$ existing i.i.d. observations $\mathbf{X} = \{x_1, \dots, x_N\} $ In the Bayesian context this means that we have to calculate the integral: $ p( \tilde{x} | X, \alpha ) = \int_{\theta } p( \tilde{x}| \theta) p(\theta| X, \alpha) d\theta$ Now if I understood correctly how to do that, this means the following: Suppose I have a sequence of i.i.d. datapoints $ X_1,...,X_n \sim Poisson(\lambda)$ and I want to find the $\lambda $ that best fits the data. In the bayesian context I can assign a Gamma prior to the $\lambda$ with hyperparameters $\alpha$ and $\beta$. Now $ \lambda \sim Gamma(\alpha, \beta) $ and $ \lambda| \textbf{X} = Gamma( \sum x_i + \alpha , n + \beta )$ . This leads to a posterior predictive of $ p( \tilde{x} | X, \alpha ) = \int_{\theta } p( \tilde{x}| \theta) p(\theta| X, \alpha) d\theta \Rightarrow $ $ p( \tilde{x} | X, \alpha ) = \int_0^{\infty} [\frac{\lambda^{x_new} e^{-\lambda}}{x_{new}!}][ \frac{(n+ \beta)^{\sum(x_i + \alpha)}}{ \Gamma ( \sum x_i + \alpha)} \lambda^{\sum x_i + a - 1} e^{-(n+ \beta)\lambda}] d\lambda $.. As soon as I integrate out my parameters, I will end up with the posterior predictive that I need. I now want to apply the same process on data distributed by a Gamma distribution with unknown shape $\alpha$ and scale $\beta$ parameters. The model is then the following: $ X_1,...,X_n \sim \Gamma(\alpha, \beta)$ $\alpha, \beta \sim exponential(p,q,r,s) $ Where exponential means that the conjugate prior belongs to the exponential family of functions. My problem is how to calculate the posterior predictive distribution for this model. I have found a paper that defines(page 25) what the conjugate prior for Gamma with unknown parameters should be. So the model becomes the following $ p( \tilde{x} | X, \alpha ) = \int_0^{\infty} [ \frac{ x^{ \alpha-1}e^ { \frac{-x}{\beta}} }{ \Gamma(\alpha) \beta^{\alpha}} ] [ \frac{1}{K} \frac{ p^{\alpha -1 } e^{\beta q}}{ \Gamma(\alpha) ^ r \beta^{-\alpha s}} ] d\alpha d\beta$ Where K is a normalization factor, and p,q,r,s are hyperparameters. My problem is that I now have both $\alpha$ and $\beta$ that I need to integrate over both to get my posterior predictive. Is acquiring an analytical closed form posterior predictive plausible in this case? Cheers, P.
