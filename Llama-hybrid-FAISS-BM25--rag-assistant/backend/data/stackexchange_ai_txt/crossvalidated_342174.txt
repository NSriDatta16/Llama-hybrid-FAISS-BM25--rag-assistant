[site]: crossvalidated
[post_id]: 342174
[parent_id]: 
[tags]: 
Word2Vec : Difference between the two Weight matrices

In Word2Vec algorithm, two weight matrices are learnt : W : Input-hidden layer matrix W': Hidden-output layer matrix For reference, CBOW model architecture: Why is W chosen to represent the word vectors and not W' ? They both seem to encode the same information. What is the interpretation of the W' matrix? Just like W represents word embeddings.
