[site]: crossvalidated
[post_id]: 572450
[parent_id]: 572443
[tags]: 
The linear regression model is $$ Y_i = \beta_0 + \beta_1 X_1 + \dots + \beta_k X_k + \varepsilon_i $$ with $\varepsilon_i$ being i.i.d. Gaussian noise with mean equal to zero. The model estimates the conditional mean of $Y_i$ . Intercept-only model is $$ Y_i = \beta_0 + \varepsilon_i $$ the model would estimate the mean on $Y_i$ , the result would be equal to the arithmetic average of $Y_1, Y_2,\dots, Y_n$ . You can write the same model as you did with $X = (1 ~1~ 1)^T$ . The model has only one parameter $\beta_0$ that is equal to the average of $Y_i$ 's. If you make predictions from such a model, it will predict the average for each $Y_i$ value. Recall that the same arithmetic mean minimizes the squared error , the same loss function is used by linear regression, so the single parameter model needs to predict the average. I don't know how did you get the 15 result, but the answer is 5. julia> X = [1, 1, 1] julia> Y = [6, 5, 4] julia> inv(X'X)X'Y 5.0 julia> sum(Y)/length(Y) 5.0
