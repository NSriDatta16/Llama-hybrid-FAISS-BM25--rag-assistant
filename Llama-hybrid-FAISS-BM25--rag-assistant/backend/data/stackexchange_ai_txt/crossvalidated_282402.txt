[site]: crossvalidated
[post_id]: 282402
[parent_id]: 
[tags]: 
Others ways of feature selection aside from sparcity inducing linear algorithms and or random forests

What are other ways of feature selection within a dataset $X$ for classifying a binary response variable $y$. I know such tools as logistic regression / linear SVMs with an l1 penalty, and sparse PCA. Then in the nonlinear category I only know of random forest / extra trees ensembles using feature importance metrics. What are other techniques, linear or otherwise that allow one to select a subset of features within $X$ for improving classification metrics. Aside from standard "off the shelf" techniques like the suggestions above what are more "sophisticated" or involved procedures for feature selection ?
