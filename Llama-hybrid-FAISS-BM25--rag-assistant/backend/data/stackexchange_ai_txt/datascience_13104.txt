[site]: datascience
[post_id]: 13104
[parent_id]: 
[tags]: 
How to further improve the kaggle titanic submission accuracy?

I am working on the Titanic dataset. So far my submission has 0.78 score using soft majority voting with logistic regression and random forest. As for the features, I used Pclass, Age, SibSp, Parch, Fare, Sex, Embarked. My question is how to further boost the score for this classification problem? One thing I tried is to add more classifiers for the majority voting, but it does not help, it even worthens the result. How do I understand this worthening effect? Thanks for your insight.
