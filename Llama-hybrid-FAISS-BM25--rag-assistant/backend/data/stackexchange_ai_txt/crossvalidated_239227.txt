[site]: crossvalidated
[post_id]: 239227
[parent_id]: 239225
[tags]: 
Both paragraphs delve around the same idea. Object detection should be invariant to the object pose. In the first case, you have an array of detectors for different orientations. You just want to know if the object is present, so you just go for the orientation giving you the best possible match. You can regard this bank of detectors as a whole, and handle it as a orientation invariant detector. They take this same idea to the case of position invariance. You take that orientation independent detector and sweep it across the image, and keep the best resulting scores. This way you are position invariant, because you employ the same filters for all image positions. Hence, you end with a position and rotation invariant detector.
