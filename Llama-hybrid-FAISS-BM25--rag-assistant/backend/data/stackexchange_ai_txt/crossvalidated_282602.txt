[site]: crossvalidated
[post_id]: 282602
[parent_id]: 
[tags]: 
Coding categorical variables in logistic regression (and similar tool)

Let us consider first case. I have logistic regression with one categorical variables with 3 distinct values. I can code as Value A -> (0,0) Value B -> (1,0) Value C -> (0,1) And with intercept my variables would look like Value A -> (1,0,0) Value B -> (1,1,0) Value C -> (1,0,1) Now once I have regression done, it is easy to interpret coefficients of regression. Value A will serve as base case. Let $x_B$ denote vector of value where B outcome of our categorical variable is present (and so on for other outcomes) and $\beta_B$ is the coefficient of B value $odds(x):=p(x)/(1-p(x))$ $\frac{e^{x_B}}{e^{x_A}} = e^{\beta_B} = \frac{odds(x_B)}{odds(x_A)}$ So interpretation of $\beta_B$ is log of ratio of odds of B to A. Now let us consider another case. I have two categorical variables. First variable is $Z$ with values $A,B,C$ and another categorical variable is $W$ with values $E,F,G$. Now let us try to code it similar to the first case (with intercept) value A -> 1,0,0,0,0,0 value B -> 1,1,0,0,0,0 value C -> 1,0,1,0,0,0 value E -> 1,0,0,1,0,0 value F -> 1,0,0,0,1,0 value G -> 1,0,0,0,0,1 With this coding I no longer get the same simplification as in the first case and interpret $\beta_E$ as before. Simplification works, but I get to compare value A and value E from different variables, while I rather compare outcomes within one variable. Is there workaround, am I missing something? UPDATE Here is example using R to clarify my question x Print out of results Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -0.3449 1.2934 -0.267 0.7897 xgreen -2.9008 1.6541 -1.754 0.0795 . xred -1.5273 1.4097 -1.083 0.2786 ynorth 1.7580 1.5611 1.126 0.2601 ywest 3.3712 1.8804 1.793 0.0730 . What are interpretations of coefficienst and how interpretations are derived?
