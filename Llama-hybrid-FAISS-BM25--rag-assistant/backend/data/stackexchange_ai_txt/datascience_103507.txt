[site]: datascience
[post_id]: 103507
[parent_id]: 103022
[tags]: 
Answering your four questions Warm up steps: Its used to indicate set of training steps with very low learning rate Warm up proportion ( $wu$ ): Its the proportion of number of warmup steps to the total number of steps 3 Selecting the number of warmup steps varies depending on each case. This research paper discusses warmup steps with 0%, 2%, 4%, and 6%, which are all reflect significantly fewer warmup steps than in BERT. This particular user had better performance with warmup steps of 165k. Kindly refer to this forum As per this deep-learning documentation its warmup per epoch References : Research paper which discusses on warm steps and warmup proportion How to choose warm-up steps depending on the train steps during pre-training? deep-learning documentation on learning rate schedule
