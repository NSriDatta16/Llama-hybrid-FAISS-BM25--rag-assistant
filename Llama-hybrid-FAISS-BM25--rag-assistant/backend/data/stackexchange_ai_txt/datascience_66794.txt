[site]: datascience
[post_id]: 66794
[parent_id]: 
[tags]: 
Does K - Means clustering on data reduced using PCA and the original data make any difference?

I am working on clustering and I have 90 features with 13500 data points and after removing the correlated variables which had pearson correlation more than 90% my feature space reduced to 70. Also, almost all my original 90 features has lot of values as zeros (more than 70-80% of data points). What I did in terms of algorithmic implementation is : Ran K-Means on original data with 70 features (all numerical) by selecting number of clusters based on Silhouette index. Ran K-Means by reducing the dimensions to 2 by selecting the number of clusters based on silhouette index. What I observed and my corresponding question is : K-Means on pca reduced data gave better clusters. Is there any way I can use this clusters that would make sense ? Like assigning the cluster labels from pca reduced data to the original data How is the K-Means on original data and K-Means on pca reduced data different ? I understand that the pca would have reduced the data to two dims that I chose and has preserved the components with max variance. But can I assign the cluster labels from the pca reduced data to the original data ? would it be a right approach ? I guess not. Also, there are many implementation of K-Means like Lloyds (Python), Elkan(Python), Hartigan-Wong(R), Forgy(R), MacQueen(R). Which of these can be used for numerical vars and which one for categorical ? I think, wong is used for categorical variables not sure though. Also, which of these Implementations can I simply rule out ?
