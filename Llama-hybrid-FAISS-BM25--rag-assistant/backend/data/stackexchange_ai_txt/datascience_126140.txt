[site]: datascience
[post_id]: 126140
[parent_id]: 
[tags]: 
Interpretation of Evaluation Values of Augmented SBERT Training with EmbeddingSimilarityEvaluator()

I train a BI-Encoder to get an Augmented SBERT and I get a final training result. How can I interpret the following output of the final training result? EmbeddingSimilarityEvaluator: Evaluating the model on test dataset: Cosine-Similarity : Pearson: 0.8115 Spearman: 0.7777 Manhattan-Distance: Pearson: 0.7318 Spearman: 0.6822 Euclidean-Distance: Pearson: 0.7332 Spearman: 0.6835 Dot-Product-Similarity: Pearson: 0.7780 Spearman: 0.7543 0.7777387754875323 # output of test_evaluator(...) The output result out of the following code snipped: # load the stored augmented-sbert model bi_encoder = SentenceTransformer(bi_encoder_path) test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name='sts-test') test_evaluator(bi_encoder, output_path=bi_encoder_path) Is a high or low Person resp. Spearman better? They give information about the correlation.
