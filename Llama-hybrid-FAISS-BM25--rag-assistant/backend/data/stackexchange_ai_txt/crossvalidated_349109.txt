[site]: crossvalidated
[post_id]: 349109
[parent_id]: 347931
[tags]: 
If your goal is to remove variations due to the subjectivity of the judges, the simplest way to do this is via some kind of regression model (including GLMs, etc.) where your response score is modelled using the participant and the judge as explanatory variables. This will estimate coefficients for each of the judges, and you can then create an adjusted score that removes the estimated effect of the judge. Alternatively, you could do a similar thing using a linear mixed model using lmer with a random effect for the judges. Here is an example of some R code to fit a simple linear-mixed-model with a random effect for the judges. The model can then be used to create an adjusted score by taking the predicted score of an entrant which removes the random effect of the judge. Adjusted scores can then be aggregated by participant (averaging their two adjusted scores) to get an overall score for each participant. library(dplyr); library(stats); library(lme4); #Assume we have a data-frame DATA with variables Participant, Judge, Score # Participant has values 1:10000 # Judge has values 1:200 # Score has values 0:100 #Fit a linear-mixed-model with random effects for the judges #Use this to obtain adjusted scores corresponding to each actual score SCORE_MODEL % group_by(Participant) %>% summarise(Avg_Score_Adjusted = mean(Score_Adjusted)) %>% ungroup() %>% arrange(desc(Avg_Score_Adjusted)) %>% as.data.frame(); This analysis will give you a data-frame containing a ranked list of participants with their average adjusted-scores (after removing the estimated effect of the judge). This can be used as a basis to estimate the "true" ability of each participant. From your question it appears that you are looking for point estimates for a "true score" for each of the participants, but if you need to augment this with interval estimates, you can obtain these using the standard-error estimates for the participant effects in your model.
