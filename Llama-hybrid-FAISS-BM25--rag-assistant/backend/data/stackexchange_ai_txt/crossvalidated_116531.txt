[site]: crossvalidated
[post_id]: 116531
[parent_id]: 116514
[tags]: 
The standard effect size for a one-sample t-test is the difference between the sample mean and the null value in units of the sample standard deviation: $$ d = \frac{\bar x - \mu_0}{s} $$ The interpretation here is essentially the same as for the two-sample version of the standardized mean difference: it is the number of standard deviations that your distribution diverges on average. As in most cases with effect sizes, you can think of it as taking the $N$ out of your test statistic. Thus, with a test statistic / $p$-value you get a sense of the confidence you have in your result, but these conflate the size with $N$, so from a small $p$ you don't know if you have a big effect with a small $N$ or a small effect with a big $N$. Here, you would get a point estimate of the magnitude of the shift, but you don't know from $d = .5$ whether or not you can be confident that the true effect isn't $0$.
