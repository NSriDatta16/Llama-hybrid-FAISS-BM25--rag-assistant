[site]: crossvalidated
[post_id]: 548447
[parent_id]: 548434
[tags]: 
If you really want to use deep learning for this, then I'd consider a character-level recurrent neural network (such as a bidirectional LSTM) or if you want a transformer, which would take as the input the sequence of characters and would use as its output a category (either 1) if you have a fixed list of possible outputs, those categories, 2) categorical output for the words in an appropriate dictionary, or 3) a sequence of characters). Using a model pre-trained on some English language corpus would seem obvious, because that would likely give the model a lot of relevant context beyond your training data (e.g. https://huggingface.co/transformers/v3.4.0/model_doc/longformer.html ). In fact, DistilGPT2 is a pretty good at this task with just a few examples (few shot learning). I provided this input Input:banana Output:banana Input:raw strawberry Output:strawberry Input:llemon Output:lemon Input:pear Output:pear Input:aple Output:apple Input:rotten fig Output:fig Input:raw banana Output: and the model (gpt2-large, temperature 0, max-time 5) auto-completed this to Input:banana Output:banana Input:raw strawberry Output:strawberry Input:llemon Output:lemon Input:pear Output:pear Input:aple Output:apple Input:rotten fig Output:fig Input:raw banana Output: banana Input:raw So, it seems like a transformer model can deal with this in a few shot fashion. What you tried in terms of data augmentation (i.e. adding some extra characters) sounds sensible, but I'd also consider other ideas (e.g. adding extra random words from a dictionary - perhaps making sure not to pick any fruit words - and randomly swapping letters). There's various packages for data augmentation with text data that you could try.
