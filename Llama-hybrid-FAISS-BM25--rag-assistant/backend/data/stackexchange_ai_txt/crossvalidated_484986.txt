[site]: crossvalidated
[post_id]: 484986
[parent_id]: 483842
[tags]: 
Before answering the question about an intuitive way to think about Hamiltonian Monte Carlo, it's probably best to get a really firm grasp on regular MCMC. Let's set aside the satellite metaphor for now. MCMC is useful when you want an unbiassed sample from a distribution where you only have something available which is proportional to the PDF, but not the PDF itself. This arises in (eg) physics simulations: the PDF is given by the Boltzmann distribution, p ~ exp(-E/kT), but the thing that you can calculate for any configuration of the system is E, not p. The constant of proportionality is not known, because the integral of exp(-E/kT) over the whole space of possible configuration is usually too difficult to calculate. MCMC solves that problem by doing a random walk in a specific way, where the probability of taking ("accepting") each step is related to the ratio of p values (the constant of proportionality cancels out). Over time, the distrubution of accepted samples from the random walk converges to the PDF that we want, without ever needing to explicitly calculate p. Note that in the above, any method of taking random steps is equally valid, as long as the random walker can explore the whole space. The acceptance criterion guarantees that the selected samples converge to the real PDF. In practice, a gaussian distribution around the current sample is used (and the sigma can be varied so that the fraction of accepted steps stays relatively high). There would be nothing wrong in principle with taking steps from any other continuous distribution ("jumping distribution") around the current sample, although the convergence may be a lot slower. Now, Hamiltonian Monte Carlo extends the physics metaphor by specifically trying to take steps in a direction which is more likely to be accepted than a gaussian step. The steps are what a leapfrog integrator would take, if it was trying to solve the motion of a system where the potential energy was E. These equations of motion also include a kinetic energy term, with a (not literally physical) "mass" and "momentum". The steps that the leapfrog integrator takes in "time" are then passed as proposals to the MCMC algorithm. Why does this work? The gaussian MC takes steps the same distance in every direction with equal probability; the only thing that biases it towards more densely populated areas of the PDF is that steps in the wrong direction are more likely to be rejected. The Hamiltonian MC proposes steps both in the direction of E gradient, and the direction of accumulated motion in recent steps (direction and magnitude of the "momentum"). This enables faster exploration of the space, and also higher probability of reaching more densely populated regions faster. Now, the satellite metaphor: I think this is not a very useful way to think about it. Satellites move in an exact orbit; what you have here is quite random, more like a particle of gas in a container with other particles. Each random collision gives you a "step"; over time the particle will be everywhere in the container with an equal probability (since the PDF here is equal everywhere, except the walls which represent very high energy / effectively zero PDF). Gaussian MCMC is like a effectively zero-mass particle doing a random walk (or non-zero mass particle in a relatively viscous medium): it will get there through brownian motion, but not necessarily fast. Hamiltonian MC is a particle with a non-zero mass: it may gather enough momentum to keep going in the same direction despite collisions, and so it may sometimes shoot from one end of the container to another (depending on its mass vs the frequency/magnitude of collisions). It would still bounce off the walls, of course, but it would in general tend to explore faster.
