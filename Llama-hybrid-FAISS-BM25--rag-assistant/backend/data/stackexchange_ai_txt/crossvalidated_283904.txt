[site]: crossvalidated
[post_id]: 283904
[parent_id]: 282896
[tags]: 
As you are not interested in using your model estimates to make predictions, I don't thin cross-validation is relevant in your case (You don't really seem to care about data over-fitting). I think you've already pointed out the major limitations of the data - Underpower means that some your results are likely to suffer from type II error (i.e., not rejecting the hypothesis of coeff nullity while you should). Model log-likelihood in itself is not very informative, except if you use it to compare diff model specifications. For example, you could compare the perf of your "target" model with an empty model (i.e., intercept only), it would tell you something about explanatory power of your independent variables. You could also look at alternative to R-squared in context of logistic regression (e.g., McFadden Pseudo R2 => McFadden's Pseudo-R2 Interpretation ). You could also compute the % of correctly predicted events (0/1) using your model estimates and compare it to pure chance level (~50%) - It would also tell you something "interesting" about your model.
