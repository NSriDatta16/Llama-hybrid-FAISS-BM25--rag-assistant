[site]: crossvalidated
[post_id]: 397515
[parent_id]: 
[tags]: 
Markov chain: how to estimate the transition matrix? I don't have the underlying observations, just the sum by state and time

I have a matrix for data that (supposedly) follows a Markov process with an absorbing state; I have 3 possible states and 50 periods (discrete states, discrete time). Element [t,s] of the matrix tells me how much of my population is in state s at time t. Something like: 90 10 0 80 10 10 The question is: how can I estimate the transition matrix? I use Python but might use R or Julia for this - or I'd be happy to consider converting an algorithm to Python if not too complex. Note that I only have this matrix as described - I do not have the underlying individual observations ; in other words, I do not know which item went from which state to which state - only the total number of items in each state at each time. The answers/comments I have found refer to cases where you know the underlying observations, which I don't in this case. I understand there is a package for R: https://cran.mtu.edu/web/packages/markovchain/ But, if I understood it correctly, it requires the actual observations, and cannot really be used with my kind of data - is that right? I have put together a few lines of Python to simulate the kind of data I want to estimate. Thoughts / ideas / suggestions? Thanks! import numpy as np import pandas as pd # the initial state s=[0.9,0.1,0] # One matrix is applied in 15% of the cases; I do this to introduce # some 'noise' m1=np.array([[0.91,0.09,0 ], [0.3,0.4,0.3],[0,0,1] ]) m2=np.array([[0.9,0.1,0 ], [0.32,0.4,0.28],[0,0,1] ]) periods = 50 ran = np.random.rand(periods) evol= np.zeros((periods,3)) evol[0,:]=s for t in np.arange(1, periods): if ran[t]
