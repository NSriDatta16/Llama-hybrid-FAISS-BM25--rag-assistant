[site]: datascience
[post_id]: 107096
[parent_id]: 50913
[tags]: 
Solution 1 : Target Encoding using Weight of evidence Weight of evidence would be a good candidate for this scenario. Initially when you have train data calculate weight of evidence on train data as follows; Calculate the number of events and non-events in each group (bin) Calculate the % of events and % of non-events in each group. Calculate WOE by taking natural log of division of % of non-events and % of events This takes care of high cardinality also. ** We very cautious while using weight of evidence as they tend to lead to overfitting ** Now in futue when you receive new classes, as you dont know anything about them you can have average weight of evidence applied so that your predictions function dont fail. Once you have collected enough data for new classes you can just retrain your model to accomodate those. Solution 2: Use Senetence Embedding to replace You may use encoding of job description from a NLP model like BERT/wiki vectors etc to encode it in feature space of lets vector size 50. This will also introduce some contextual understanding and works even for New classes. The only problem with be increase in dimensionality.
