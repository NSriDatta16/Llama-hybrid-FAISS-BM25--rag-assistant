[site]: datascience
[post_id]: 109904
[parent_id]: 
[tags]: 
Can I use Bert on data subsets and get a compatible representation for the whole dataset?

I need to build an embedding for a massive amount of phrases. I want to use BERT (through the library https://www.sbert.net/ ). Can I build a partial representation of the data, say encoding 1000 sentences and then another 1000 and join the matrices at the end? If I generate the embeddings by parts (of the whole dataset), will I get a compatible vector representation between the different results? Or, on the contrary, should I build the representation with the whole dataset at the same time? My final goal is to cluster and analyze the sentence vectors of the whole dataset. I would appreciate any suggestions on what to read or how to better approach this question. Thanks!!!
