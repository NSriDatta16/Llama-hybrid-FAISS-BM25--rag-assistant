[site]: datascience
[post_id]: 114073
[parent_id]: 114062
[tags]: 
Especially for time series work, yes, use your full dataset for training your final model. Keep your number of epochs the same as the best performance on your val_loss. If you want, you can remove the same period of time from the start of the training data, to ensure the model is given a consistent number of samples to learn over. This is a big challenge when shipping models to production, as you now have no validation set, how do you know how well it is performing? This is where you need to get creative, and use different time-series k-fold splitting strategies. When working on TS problems that you want to ship to production, I like to use a training, validation and holdout set. So you can test your models true performance. Otherwise you will be over-fitting on your validation set, through early stopping. (You are leaking information from your validation set, into the keras model training process) Hope this helps.
