[site]: datascience
[post_id]: 122506
[parent_id]: 67317
[tags]: 
A few GAN training tricks, mainly taken from here : Normalize images in [-1,1] use tanh as final layer activation Train the generator on $\max \log(D)$ instead of $\min \log(1-D)$ Perform an optimization step of the Discriminator every $n$ Generator steps Avoid sparse gradients: avoid max pooling, use LeakyReLU Use label smoothing 0 → [0,0.3], 1 → [0.7, 1.2] or 0, 0.9 instead of 0,1 Use Adam optimizer for Generator and SGD for Discriminator
