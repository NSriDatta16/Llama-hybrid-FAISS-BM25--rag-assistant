[site]: datascience
[post_id]: 97796
[parent_id]: 
[tags]: 
Concerns regarding small dataset with too many features

I have dataframe with 322 observations with 224 features. The observations has two classes, 0 or 1,which i'm trying to predict. class 0 has 168 observations and class 1 has 154 observations. I was required to check which features were the most important for the classification task (xgboost), however, despite the fact that the script runs and I get feature importance , I am worried as it seems to me not correct as there are so many features (224) and so little observations (322),yet, there are more observations than features. I did not reduce the dimensions (PCA) as in this case I was asked to specify the important feature from all the 224, and as I understand it, if I do PCA i'll lose the specific features and won't be able to tell which feature was more crucial for the classification task. So my question here is, is it wrong to point out what are the important features for classification when using relatively small dataframe with so many features?
