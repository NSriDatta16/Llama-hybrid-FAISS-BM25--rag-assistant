[site]: crossvalidated
[post_id]: 363409
[parent_id]: 
[tags]: 
Derive p value from t distribution

I have difficulty of understanding p-value from An Introduction to Statistical Learning by Gareth James • Daniela Witten • Trevor Hastie Robert Tibshirani (2015) : 67 Consider simple linear regression equation $$Y= β_0+ β_1 X$$ Null hypothesis states Y doesn't relate to X, Mathematically $β_1\approx0$ To reject Null hypothesis, we should prove $β_1 >> 0$ After performing linear regression I calculated coefficient to be $\hat{β_{1}}$ .But since number of samples are limited, There is no confidence to reject null hypothesis. So I calculate t-statistic as $$t_{statistic}=\frac{\hat{β_{1}} - 0}{SE(\hat{β_{1}})}$$ It is trivial to understand that higher t-statistic implies more confidence in $β_{1}$ since $β_{1}$ is larger than error in calculation of itself, hence we can reject Null hypothesis for high t-statistic values From: https://en.wikipedia.org/wiki/Student%27s_t-distribution $$t=\frac{\hat{β_{1}} - {β_1}}{SE(\hat{β_{1}})}=\frac{Error\,in\,calculated\,β_{1}}{(Estimated\,Variance)/(\sqrt{n})}$$ Note here that ${β_1}$ & ${SE(\hat{β_{1}})}$ are random variables and vary with batch of samples observed. Let's denote t-distribution as $T(t,n)$ and ${t\,statistic}$ as $T_{st}$ Probability of observing ${t_{obs}}\ge{t\,statistic}$ is p-value $${p}{-}{value} = \int_{|t|>|T_{st}|}T(t,n)$$ What is mathematical derivation for ${p}{-}{value}\approx 0 \implies β_1 >> 0$ is large ? I have a quantitative explanation that t-statistic follows t-distribution, if we assume $H_{0}$ is true, and ${p}{-}{value}$ i.e. $\int_{|t|>|T_{st}|}T(t,n)$ denotes probability of getting a value of "t" $\ge T_{st}$ which being less implies hypothesis is false
