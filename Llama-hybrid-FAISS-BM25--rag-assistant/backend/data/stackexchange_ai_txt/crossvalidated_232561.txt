[site]: crossvalidated
[post_id]: 232561
[parent_id]: 232559
[tags]: 
It's not entirely correct to say that inverse methods are impossible to compute. There are perfectly good numerical approximations to the inverse Gaussian CDF . As far as I'm aware, plenty of methods use it to generate gaussian random variables. There are of course plenty of other , possibly simpler methods of generating Gaussians. Concerning rejection sampling, this is a mixed bag. If $f(x)$ is the Gaussian pdf, then in rejection sampling, you need to find a PDF $g(x)$ which dominates $f(x)$: $f(x)\leq Mg(x)$, for some $M>0$. One interpretation for $M$ here is the expected number of rejections you need to make before accepting a sample, so the smaller $M$ is the better. This issue can make rejection sampling a huge pain because sometimes $M$ is huge. The rule here is, if you can't find a $g$ that makes $M$ tractable, you'll need to look at other methods, for example, the inverse transform method. For example, the exponential distribution works for the normal distribution (actually the one sided normal, after which you can flip a coin to decide on the sign). In this case, you can work out $M=\sqrt{2\pi/e}=1.32$, which is great because the exponential is very easy to generate using the inverse cdf method and you only need to throw out roughly 2 samples on average. The nice thing about rejection sampling combined with MCMC is, when used in a clever way , you can simulate rare events without actually having to wait the lifetime of the universe for the event to occur.
