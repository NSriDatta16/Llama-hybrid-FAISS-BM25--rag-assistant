[site]: crossvalidated
[post_id]: 224508
[parent_id]: 
[tags]: 
Using Monte Carlo simulations with subsequent element removal

I'm attempting to build an evaluation set for a logistic regression classifier and I've run into a statistical problem. The study involves a very large population (G) that has two properties of interest, a True/False property (P) and an numeric field (Q). These two fields are not independent. So far I have collected: X, a representative sample of the elements of G for which P = True. Y, a non representative group from G with a bias towards P being True. (size > size of evaluation set) I'm attempting to make a group of m items out of Y that has similar properties to X via the method. However having run the Monte Carlo method I then remove all the elements with P = False (this is only possible for small groups as this identification is manual and time consuming). This changes the distribution of Q so that it is no longer similar to X. Is there a clever way of avoiding this problem (or a sensible iterative method to keep things quick?) Thank you for your help, and obviously I'm happy to answer questions/queries in the comments. EDIT: Summary - I'm trying to create a group of rare objects (P=true) within the population. Testing P accurately is very slow so I created Y, a group for which P = True is quite common. I then use a Monte Carlo simulation to reduce the size of Y and match it's the properties to X. I then remove the P = False items (which have statistically lower values of Q). Now my evaluation group is not representative (we've biased Q upwards). Is there a sensible way to work around this?
