[site]: crossvalidated
[post_id]: 418473
[parent_id]: 348592
[tags]: 
I don't see my answers to the two questions as inconsistent with each other. There are a couple of basic ideas about feature selection that are two sides of the same coin: Avoid selecting amongst a large number of options, and avoid using entirely empirical methods like stepwise selection routines (even based on the AIC). Build models of substantive interest based on background knowledge. I try to explain the problems with stepwise selection in my answer to Algorithms for automatic model selection . In the Model Selection: Logistic Regression thread, the OP describes a manual version of stepwise selection by selecting all the variables that are significant in univariate models and putting them into the final multiple regression model. The issue with that is that the problem with stepwise selection isn't primarily that the computer does it instead of you. The problems are intrinsic to selecting amongst large numbers of variables based on the same data for selecting and fitting / testing. Instead, in the latter thread I suggest: ... evaluate models of substantive interest to you. Then use an information criterion that penalizes model flexibility (such as the AIC) to adjudicate amongst those models. That is, you make only a few models (@FrankHarrell suggested you limit that to $2$ models) that are based on prior knowledge. Then, you can decide which seems to be better by the AIC. In this way, you are selecting amongst only a small number of options, each of which could be justified theoretically, and making only a single decision. If you only care about out of sample predictive performance, it doesn't matter if you have the 'right' model, or if the variables in the model actually have true relationships with the outcome. It only matters if the model 'works' to give accurate predictions when you use it. The connection between the height of one twin and the height of their sibling is spurious / confounded, but who cares? You can predict the height of an unseen sibling with great accuracy and that's all you care about. In this type of situation, you can use cross validation and select the model with the best out of sample performance.
