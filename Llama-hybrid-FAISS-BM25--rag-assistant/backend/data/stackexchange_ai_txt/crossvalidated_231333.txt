[site]: crossvalidated
[post_id]: 231333
[parent_id]: 230479
[tags]: 
Based on @amoeba's suggestion, we have decided to go back to the raw, logical data and conceptualize similarity differently, than we did in the question; we can now use the familiar (and simple) correlation coefficients and Principal Components Analysis (PCA) to summarize the data. Instead of co-occurence counts , inspired by Barton's Z, we transformed the TRUE FALSE values in the logical raw data into their respective deviations from their expected value. The expected value of some (inductive, participant-defined) category to be assigned TRUE on some item is, simply, the total number of TRUE s on that category, divided by the number of items. We take these simple expected values as a weighted means of the outcomes, because draws of items (category assignments on items) are independent : just because you've assigned some TRUE already doesn't mean you can't assign it some more. The resulting deviations from their expected TRUE value can be interpreted as a surprisal value of TRUE ishness. For example, if some item has a positive value (close to 1), this means that it has been assigned TRUE despite that being very unlikely. We thereby weight more heavily those cells, that are less likely to occur, and thereby carry more informational value. We count TRUE as 1 , FALSE as 0 , and thereby conveniently get surprisal values scaled between -1 and 1 . We can simply find an item x item correlation matrix, where we correlate the surprisal values of some item-pair over the observed categories , thereby, oddly, treating categories as observations. This yields an informative correlation matrix, where high values imply an item pair that was surprisingly co-/non-assigned , and a high negative value implies that of the pair, one item had high, the other a low surprisal value, that is, surprising disagreement about some item pair. A low value around 0 implies, appropriately, that the item pair showed no consistent pattern across the observed categories, or that many assignments were unsurprising. This correlation matrix is also still quite overwhelming, but can be easily reduced in dimensionality using PCA. Here's what we did: Azra 1, though this may be overstated, and need a parallel analysis to be safe # we know that some of the underlying surprisal value correlations might just be random chance; after all, 18 observations (categories in this case, over 35 variables is weird and not very reliable) # we're not yet sure how to do this, but let's say we rotate Quartimax # we preliminarily opt for Quartimax, because we like items to be *on* the axes library(GPArotation) rotated_Azra There's a bunch of things we're not sure about yet, especially how to rotate this result, and how to appropriately deflate it (by a parallel analysis or something like that?), but that's all details. P.S.: A fuller, though preliminary exposition with some context can be found at http://pensieve.maxheld.de/q-cat.html . P.P.S.: The surprisal value is inspired by Barton's Z, full source in Burton, Michael. 1972. “Semantic Dimensions of Occupation Names.” Multidimensional Scaling: Applications in the Behavioral Sciences 2: 55–72.
