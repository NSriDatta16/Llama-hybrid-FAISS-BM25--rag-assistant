[site]: crossvalidated
[post_id]: 471353
[parent_id]: 61911
[tags]: 
Composition method is used in @SecretAgentMan's answer. Instead, inverse transformation is used in the following Python function. import random as rd import math from scipy.optimize import fsolve def sim_exp_hyper(pmf:list, expects:list, n:int, whi_seed:int=123) -> list: """Simulate realisation of hyper-exponentially distributed random variables using inverse transformation method. Keyword Arguments ================= pmf: probability mass function expects: expectation of each individual exponential distribution n: number of realisations whi_seed: seed """ if len(pmf) != len(expects): raise ValueError("len(pmf) != len(expects).") elif sum([i 0: raise ValueError(f"There are negative values in the probablity mass " f"function {pmf}.") def get_eq(u, x): eq = 1 - sum(pmf[i] * math.exp(- x / expects[i]) for i in range(len(pmf))) - u return eq rd.seed(whi_seed) us = [rd.random() for i in range(n)] xs = [fsolve(lambda x: get_eq(u, x), 0.1)[0] for u in us] return xs, us This method is inefficient because a nonlinear equation is solved to generate one realisation. There is no way to express the inverse of CDF of hyper-exponential distributions. So we can only obtain $x$ by solving: $$ F(x)=1-\sum_{i=1}^{m} p_{i} e^{-\lambda_{i} x}=\sum_{i=1}^{m} p_{i}\left(1-e^{-\lambda_{i} x}\right) = u $$ where $u$ is a simulated random number from uniform distribution over $[0, 1]$ . However, one random number (instead of two in composition method) is used for every realisation, which is essential in common random number method for variance reduction.
