[site]: crossvalidated
[post_id]: 268153
[parent_id]: 266505
[tags]: 
Fundamentally, I think you are asking if there is a statistically sigificant difference between the preference for the two algorithms (Potentially given a number of factors like the image being scored, and the person scoring the algorithm). To keep this simple, I might propose to try to test the following null hypothesis: The expected odds that a person prefers algorithm 1 is no different than the expected odds they prefer algorithm 2 . I provide some R code to test this hypothesis based on the numbers you gave. #Generate data rawResults I do not find that there is a significant difference. This is a simplistic test. I think that an alternative, like a t-test would be asking the wrong question since it would ask about the mean vote per algorithm. Logistic regerssion asks something similar, but it comes closer to what we are interested in, which is "the chance someone picks an algorithm." Logistic regression will also more naturally extend to include the interviewer information. Regarding your question about whether it matters who voted on what question, this is a good point. There might be a pattern in their answering between images. This could be included using a random effect, but since the data for this is not posted, I have not run that analysis. Accounting for the voter effect will improve the precision of your estimates on the main effect of interest: the power of alg1 vs alg2. It could also be interesting to test if there is a difference in the performance of the algorithms on the different pictures. Do you see a pattern there? For this, I think it would be useful to have the voter IDs as a random effect again.
