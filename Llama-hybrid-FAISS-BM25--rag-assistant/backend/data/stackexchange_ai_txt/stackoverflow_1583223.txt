[site]: stackoverflow
[post_id]: 1583223
[parent_id]: 1583211
[tags]: 
The whole point of a binary search is that, since the data is already sorted, you can quickly locate the information you want. Take the phone book, which is sorted by last name. How do you find someone in the phone book? You open it up to a page which you assume will be close to what you want, and then start flipping pages. But you don't flip one page each time, if you missed by a lot, you flip a bunch of pages, and then finally start flipping one at a time, until finally you start looking at a single page. This is what binary search does. Since the data is sorted, it knows it can skip a lot and do another look, and it'll focus in on the information you want. A binary search does 1 comparison for every doubled number of items. So a 1024 element collection would require around 10 comparisons, at the most, to find your information, or at least figure out that it's not there. If you, before running the actual binary search, does a full run-through to check if the data is sorted, you might as well just do a scan for the information. A full run-through + the binary search will require N + log2 N operations, so for 1024 elements, it would require around 1034 comparisons, whereas a simple scan for the information will on average require half, which is 512. So if you can't guarantee that the data is sorted, you should not use binary search, as it will be outperformed by a simple scan. Edit : I will say this though, you could add a debug-only code step to verify this, to catch bugs in the code that is supposed to prepare the data for binary search, but know that, due to what I've written above, this will make the total running time a lot higher, so depending on what you want to do with this check, you might or might not want to add it. But it should not be present in release code.
