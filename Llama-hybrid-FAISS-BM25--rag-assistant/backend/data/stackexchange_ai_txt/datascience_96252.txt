[site]: datascience
[post_id]: 96252
[parent_id]: 95233
[tags]: 
It's linear by Feature. In the end, we are modelling the Features. So, A linear model is the one that plots a linear function in the Feature-Label space. e.g. LinearRegression, Linear SVM, LogisticRegression. Confusion arises when we try to look at the True relation but we should look at the modelled relation. Let's say we have a True relation $y = w_r*x^2$ and we don't know this. The feature I got is $x$ , so the model that I will build is $y = w_p*x$ and it is a linear model with the given feature. Definitely, by doing EDA I will realize that the relationship is violating the Linear assumption. So, I will create a new Feature i.e. $x^2$ Let's assume, $x^2 = F$ . Its a new space now i.e. $x {\rightarrow} y$ to $x^2 {\rightarrow} y$ My new model will be $y = w_r*F$ and again it is a Linear relationship. On weights , Weights are the parameters to learn i.e. slope for a LinearRegression . It represents the significance of each Features. On polynomial , Although we use polynomial plot to develop intuition but we use polynomial features(as explained above) to fit the model. So, it is still a Linear model. $\hspace{6cm}$ Excerpt from ISL(Page - 91)
