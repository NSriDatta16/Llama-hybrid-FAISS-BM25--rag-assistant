[site]: crossvalidated
[post_id]: 579768
[parent_id]: 579759
[tags]: 
Firstly, I'd question why it has to be a neural network. Something like a traditional logistic regression (or a multi-category version thereof), a GAM, or a gradient boosted decision tree (LightGBM, XGBoost or Catboost) will often perform better for tabular data than a neural network (except for in some specific circumstances such as very high dimensional category input, sequence data, using images or free text information etc.). Additionally, more complex models are harder to inspect, interrogate and understand. I've had bad experiences with things going on inside models that we fail to notice e.g. here is an example from Richard Caruana on this , on which he has also talked on YouTub (could not find it at the moment), and I've had similar problems where a XGBoost does something on the inside that is very hard to diagnose. Neural networks are even more notorious for this, of course. If for some "it's a academic learning exercise, so it needs to be a neural network" reason it has to be, then +1 for the proposal by Henry to describe your design parameter search strategy based on cross-validation and perhaps some of Bayesian hyperparameter search. For possible candidate NN models, if you have a fixed dimensional and not really enormous set of predictors, a basic go-to-model for me has been a 2-layer MLP as implemented in the fastai Python library (see e.g. here https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb and https://docs.fast.ai/tabular.learner.html ). Esp. if you have variable dimensional input (e.g. sequence of events in a patient's medical history that could be anything from no events at all to a large number of events), then that's a less obvious choice and things that model sequences (e.g. transformers, LSTMs etc. may become attractive instead), or you need to create features that somehow deal with this (e.g. by counting things in time windows). I.e. for some types of inputs a MLP is just not so sensible.
