[site]: crossvalidated
[post_id]: 351862
[parent_id]: 249940
[tags]: 
If you take a careful look at the recent state-of-the-art results on some standard problems (language models, computer vision), you'll notice that the number of parameters in a network scales with the number of examples in the training data. (This is not the main thesis of this paper, but it is discussed in a few paragraphs of " mixup: Beyond Empirical Risk Minimization " by Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, David Lopez-Paz.) Stated another way, you can model a small data set with a small model. Or, looking at the problem from the other end, for any network which achieves state-of-the-art results for some problem, you could just remove any number of parameters and accept the drop in performance as the cost if training a smaller network.
