[site]: datascience
[post_id]: 17017
[parent_id]: 
[tags]: 
Feature selection where adding features are deteriorating model

k I am training a kNN classifier with 144 features and graphed the accuracy vs number of features used and got this. What might be the reason for the drops in the accuracy at some points of the graph? I am using accelerometer-gyroscope-magnetometer fusion to recognize human activities. The one presented is validation accuracy. Should I use training accuracy instead? And why? I ranked the features using ReliefF feature selection algorithm. I used time domain features such as mean, standard deviation, rms, median, variance, iqr, mad, zcr and mcr, and frequency domain features such as skewness, kurtosis and pca Here are the top 8 features chosen. Peak accuracy occurs at 8 features.
