[site]: crossvalidated
[post_id]: 523797
[parent_id]: 
[tags]: 
Measuring (Un)likelihood of Random Preferences

Suppose we have a set of users who are interacting with posts on a social media feed. Any post $p_i$ can be clicked on, and we collect clicks for each user. Also, each post $p_i$ has a summary statistic of click-thru-rate $r_i$ defined as: $$r_i:=\frac{\mbox{# clicked on }p_i}{\mbox{# impressions of }p_i}.$$ Let $u_i$ be a set of "real" users, and $v_j$ be a set of "bot" users. Real users $u_i$ , on average, click on a post $p_j$ at roughly rate $r_j$ . Whereas bot users flip a biased coin for each post, clicking on it if it comes up as heads. Most likely the bias is fixed across clicks, but perhaps some bots vary the bias. For any given user, define their history binary indicators on whether or not they clicked a post. E.g. $H(u_1)=[(p_1,1),(p_{24},0),...]$ means that user $u_1$ clicked post $p_1$ but not post $p_{24}$ (the history includes only posts that were impressed on $u_1$ ). Main Question: Using only summary statistics such as $r_i$ and the history of each user, what is the optimum measure whose score separates real users from bots? For simplicity we can assume the bot coin flips have individual but fixed biases. As an example, we can use negative loglikelihood: $$L(H(u_i))=-\frac{1}{|H(u_i)|}\sum_{(p_i,c_i)\in H(u_i)} 1_{c_i=1}\log(r_i)+1_{c_i=0}\log(1-r_i).$$ High scores of the above metric would correspond to unlikely sequences of clicks, thereby correlating with bot users. My question is, is the above measure optimal in some sense? I could instead try using Wasserstein (Earthmover) distance, by binning user clicks by buckets of click-thru rate, and then measure the deviation from an average good user instead. On the one hand, I'm guessing most of these measures are equivalent, in the sense that any two measures $M,N$ would satisfy $c_1N . On the other hand, there's obviously information lost in terms of specific user preferences (e.g. correlations between pairs of pages and a given users preferences), so I'm wondering if something like the earthmover distance would theoretically work better here? Overall, I'm just interested in what the best measure is given as little actual features about the pages and users as possible.
