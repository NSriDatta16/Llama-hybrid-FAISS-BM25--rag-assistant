[site]: datascience
[post_id]: 51167
[parent_id]: 
[tags]: 
How does the meta Random Forest Classifier determine the final classification?

I am trying to understand exactly how the meta random forest classifier determines the final prediction, I understand that there is a voting system and an aggregation from the decision trees is used to find the final prediction, I have read from here: Classification Random Forests in Python : "Random forest is an ensemble decision tree algorithm because the final prediction, in the case of a regression problem, is an average of the predictions of each individual decision tree; in classification, it's the average of the most frequent prediction" I read in the RFC source code: Ensemble/Forest : "The predicted class of an input sample is a vote by the trees in the forest, weighted by their probability estimates. That is, the predicted class is the one with highest mean probability estimate across the trees" Does this mean that for example: We have 3 Classes (A, B and C) with 4 estimators, each tree has a certain amount of final leaf nodes with a class prediction; Probabilities of Class A, B or C are a result of the number of the class prediction from the leaf nodes, i.e Tree1: Class A is predicted 3 times out of 10 possible times, the other 7 times a different class was predicted. Class A: [0.30, 0.25, 0.30, 0.25] | mean = 0.275 Class B: [0.10, 0.40, 0.10, 0.40] | mean = 0.250 Class C: [0.70, 0.65, 0.70, 0.65] | mean = 0.675 So the Meta Classifier would predict Class C as it has the highest mean probabilities. Is this correct? Or am I looking at this completely the wrong way?
