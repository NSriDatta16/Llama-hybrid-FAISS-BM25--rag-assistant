[site]: crossvalidated
[post_id]: 286015
[parent_id]: 285379
[tags]: 
No, it's wrong. The nested cross-validation do a k1-fold-validation splitting the data in a training set and a test set(a fold). Later for the training set it is make another k2-fold-validation (the inner loop). This inner loop is make for each parameter combination for find the best model.In the outer loop is done the same thing for the others splitting combinations of the data and in this way at the end k2 models are found. With the rispective test set it is measured the performance of each found model. These k2 measures are averaged. In this way you do performance evaluation of the method. The purpose of nested cross validation isn't find the best model (parameters) but a measure of the method(SVM,etc..)(not a measure of the model). For do performance evaluationan and model selection too I have to do: Split the data in training set,validation set and test set. I have to do cross validation on the training set and validation set with for example grid search to find the best model. Measure this found model performances with the test set.
