[site]: crossvalidated
[post_id]: 475009
[parent_id]: 474992
[tags]: 
You may be suffering from a common issue of neural networks failing to generalize to numerical inputs unseen in training. The best display of this behavior I know is the figure from this paper : Caption from the paper: MLPs learn the identity function only for the range of values they are trained on. The mean error ramps up severely both below and above the range of numbers seen during training. To solve this, you can change the input format of your data so that the higher values aren't "unseen" in the training. You could have it take in and predict relative increases/decreases instead of the absolute value. I think this is what you meant by your third suggestion? ("standardize the time windows").
