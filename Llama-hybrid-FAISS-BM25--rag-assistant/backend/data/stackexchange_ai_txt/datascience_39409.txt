[site]: datascience
[post_id]: 39409
[parent_id]: 
[tags]: 
Target feature in training set or not?

If I analyse a random forest in python with scikit I do: target = "time" dataIn = data[features + [target]] # Splitting data into x % training data and Hyperparameter.TestSize % test data X, y = dataIn[dataIn.columns.difference([target])], dataIn[target] X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=TestSize, random_state=42) If I do a gradient boosted random forest in R I do: #split data into training and test data sets trainIndex = createDataPartition(daten$target, p=0.9, list=FALSE, times=1) train = daten[trainIndex,] test = daten[-trainIndex,] rownames(train) As you see in the scikit implementation I have the target not in the data set. There will be created a new dataframe that has only the target feature as column. In the gbm R implementation instead the dataframe train contains my target and I communicate to it with train$target. Therefore I want to ask if you split the data in train and test parts in machine learning algorithms in general (I mean I am comparing two different models), do the target has to be a column in the train data set or do the target has to be a dataframe for it's own?
