[site]: crossvalidated
[post_id]: 531997
[parent_id]: 531981
[tags]: 
Apart from literal meaning of interpolation, this is related to something called deep learning models totally memorize the training data . Hence, both interpolating and memorisation in this paper/context means zero training loss but still not overfitting on the test set. Hence the curious phenomena, that normally we would call an overfitting (overtraining actually), which is not resolved yet.
