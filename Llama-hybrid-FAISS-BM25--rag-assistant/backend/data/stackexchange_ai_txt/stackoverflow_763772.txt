[site]: stackoverflow
[post_id]: 763772
[parent_id]: 763656
[tags]: 
Bad example – the decision whether to use ++i or i++ doesn't involve any kind of trade-off! ++i has (may have) a net benefit without any downsides . There are many similar scenarios and any discussion in these realms are a waste of time. That said, I believe it's very important to know to what extent the target compiler is capable of optimizing small code fragments . The truth is: modern compilers are (sometimes surprisingly!) good at it. Jason has an incredible story concerning an optimized (non-tail recursive) factorial function. On the other hand, compilers can be surprisingly stupid as well. The key is that many optimizations require a control flow analysis which becomes NP complete. Ever optimization thus becomes a trade-off between compilation time and usefulness. Often, the locality of an optimization plays a crucial role because the computation time required to perform the optimization increases just too much when the code size regarded by the compiler increases by just a few statements. And as others have said, these minute details are still relevant and always will be (for the forseeable future). Although compilers get smarter all the time and machines get faster, so does the size of our data grow – in fact, we're losing this particular battle; in many fields, the amount of data grows much faster than computers get better.
