[site]: crossvalidated
[post_id]: 348855
[parent_id]: 
[tags]: 
How can a deep neural network learn anything?

When training a network, gradients are back-propagated throughout the entire network, updating parameters such as weights and biases. So the last layer $n$ sees features proposed by the previous layer $n-1$, and decides, based on their performance as measured by the loss, to give a little more weight to this one and a little less to that one -- changing its output. Simultaneously, layer $n-1$ does the same thing, and also changes its parameters, meaning that the features layer $n$ will see at the next round are not exactly the same that were used to compute an update. But wait, layer $n - 2$ also changes its parameters... and so on till the first layer. So, at the next round, layer 1 has changed and produces slightly different features, which are then provided to layer 2, which has also changed, and so on. When features reach layer $n$, how can they have anything in common with the features that have been used to optimize it? Furthermore, in practice, the first layers typically have much less parameters than the last ones. It seems to me that all downstream layers depend on those first convolutions, and that any change in them deeply affects all downstream features based on them. Now, it would be reasonable to say, " Stop thinking too hard. These are gradients. If you take a step small enough, maybe a very very small step indeed, features will change only oh so slightly. The cost will go down, this is mathematical. " But, in deep learning, the learning rate is taken as large as can be during the first phase, precisely when features are shaped . How, in these conditions, can a network learn anything?
