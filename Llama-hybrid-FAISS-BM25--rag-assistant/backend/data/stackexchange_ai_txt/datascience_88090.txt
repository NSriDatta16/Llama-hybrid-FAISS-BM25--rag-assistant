[site]: datascience
[post_id]: 88090
[parent_id]: 
[tags]: 
Advice on using Recurrent Neural Networks for non-time series dataset

I'm testing different machine learning algorithms for predicting week-to-week fantasy football scores for individual players. For those who don't know, fantasy football is a game in which players pick a "team" of American football players each week and based on their statistical performance that week they are asigned a score. Each position scores points based on their own statistics, so for instance a QB gets 4 points for each touchdown pass it throws, a RB gets 1 point for each 10 yards it runs, etc. What I am doing is taking the last 5 years of stats for each player in each position (filtering for those who started more than 5 games each season) and calculate the 1, 5 and 10 moving average of each particular statistic. So, for instance, for each game of player X who is a QB I have the previous game number of touchdown passes thrown, the 5 game moving average of touchdown passes thrown and the 10 game moving average of touchdown passes thrown. Repeat for every statistic. I also added each of their rivals' defensive statistics for each game, in the same vein: 1, 5 and 10 moving averages of every relevant statistic. I used this dataset to run linear regression, SVM, Bayesian regression and MLP models, with results similar to the benchmark of "fantasy football experts" that give their predictions each week. I split the datasets 70-30 randomly for train-test, and used 20% of the train set for validation. The problem is that the error is very large anyway: MRE is over 50%, with a std of 30-50% too (it's the same for experts, but still). I was wondering if RNNs wouldn't perform better. The problem is that I don't know if I should feed the NN with the same dataset (with the moving averages instead of each game's statistics) or if I should build a time series for each player instead. In which case: with 5 seasons for each player (each season 16 games or less) I have at most 90 datapoints for each player. Would that be enough for a RNN? And would it be fair to compair the performance of the RNN with the performance of the other models, which I trained with a different training set and validated with a different validation set and test set, since in this case I'll have to set apart one season (or a number of seasons) for prediction? I'm new to deep learning models, so I'm basing this on what I read on the subject: I'll have to build a time series of each game of each player and starting with one game I'll let the model predict the performance of each subsequent game in the series like this? t_1 t_2 t_i t_(i+1) t_(i+2) t_n _________ _________ _________ _________ _________ _________ | full | | full | | full | | empty | | empty | | empty | | game |----| game |---- ... ----| game |----| game |----| game |---- ... ----| game | |_________| |_________| |_________| |_________| |_________| |_________| ^ ^ ^ ^ ^ ^ | | | | | | use to use to use to predict predict predict train train train Or is this not necessary and I can feed the neural network with my samples the same way I fed the other models their samples? I'm mostly confused because I've seen these sort of models applied to samples that don't necessarily fit a "time series" frame, like image processing where each sample doesn't have a time condition relation with other samples.
