[site]: crossvalidated
[post_id]: 508476
[parent_id]: 213609
[tags]: 
The p-value is used to express the outcome in a test of a model and it's parameters (to test a hypothesis). Typically it relates to some statistic that measures a discrepancy (e.g. distance from the expected mean). $P(T> t_{observed}|H_0)$ The probability that an observation of the statistic $T$ given the null hypothesis $H_0$ is larger than the observed value of the statistic $t_{observed}$ . The Bayesian p-value is much the same. It is used in the tests of the assumptions that are used to fit the model. And in this way is like a test for goodness of fit (for instance like a Pearson's Chi-squared test). The main difference with the Bayesian p-value/hypothesis is that the model is not with fixed parameters, but instead the parameters are variables themselves. I don't quite understand why it makes sense to have the test statistic be a function of the parameters, $\theta$ The statistic that is used to compared the observation with the hypothetical model is often a pivotal quantity . You do not compare two observations. E.g. whether $Y_{rep} > Y$ But instead you compare two observations in relation to the hypothetical model. E.g. whether $|Y_{rep}-\mu| > |Y-\mu|$ . Whether the difference of the observation $Y$ from the mode of the model, is comparable to a likely random fluctuation $Y_{rep}$ or whether it is an unlikely value for which the we should consider the observation as a anomaly. I hope this difference of observation and model makes intuitive sense. These statistics used for computing p-values can be somewhat arbitrary. The likelihood ratio test makes this a bit more formal. Why don't we use the following test statistic instead, relying purely on the data? $$ T(y, \theta) = | y_{(61)} - \bar y | - |y_{(6)} - \bar y | $$ We do not make the statistic purely based on data because we want to test the data with relation to the model . It needs to be dependent on $\theta$ or otherwise it will not be a goodness of fit for $\theta$ . You can have in some way an expression for a statistic that tests data with "data". $$ T(y, \theta) = | y_{(61)} - \hat y | - |y_{(6)} - \hat y | $$ here $\hat y$ is the estimated value of $y$ .
