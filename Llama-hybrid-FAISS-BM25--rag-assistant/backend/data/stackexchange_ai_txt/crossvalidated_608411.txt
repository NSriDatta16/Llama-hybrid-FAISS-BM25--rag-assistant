[site]: crossvalidated
[post_id]: 608411
[parent_id]: 
[tags]: 
How do LLMs transform tokens into vectors?

I know about tokenization algorithms like BPE and some other basics of tokenization from the Hugging Face course. I've also heard about word2vec and other algorithms for assigning words to vectors. I'm very confused about how these two fit together, if at all, in LLMs. What are some common practices for converting tokenized text into input tensors? I believe one approach is to randomly initialize a matrix of shape (embedding dimension, token vocabulary size). Multiplying with the one-hot encoded column vector for a given token will select a particular column of the matrix; thus the matrix functions as a lookup table that assigns vectors to tokens in the vocabulary. During training, update this matrix normally via backpropagation. (This approach makes no use of word2vec.)
