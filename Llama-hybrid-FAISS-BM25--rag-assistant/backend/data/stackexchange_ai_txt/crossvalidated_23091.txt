[site]: crossvalidated
[post_id]: 23091
[parent_id]: 
[tags]: 
Steps to figure out a posterior distribution when it might be simple enough to have an analytic form?

Possible Duplicate: Steps to figure out a posterior distribution when it might be simple enough to have an analytic form? I must admit this is an embarrassing question. I do a lot of programming for statistics work, but rarely do I ever deal with analytical formulas for things (it's usually all just based on algorithms for processing the data). In this case, I am trying to compute a Bayesian estimate of some coefficients for an autoregression, with 11 data samples: $$ Y_{i} = \mu + \alpha\cdot{}Y_{i-1} + \epsilon_{i} $$ where $\epsilon_{i}$ is Gaussian with mean 0 and variance $\sigma_{e}^{2}$ The prior distribution on the vector $(\mu, \alpha)^{t}$ is Gaussian with mean $(0,0)$ and a diagonal covariance matrix with diagonal entries equal to $\sigma_{p}^{2}$. Based on the autoregression formula, this means that the distribution of the data points (the $Y_{i}$) are normal with mean $\mu + \alpha\cdot{}Y_{i-1}$ and variance $\sigma_{e}^{2}$. Thus, the density for all of the data points $(Y)$ jointly (assuming independence, which is fine for the program I am writing), would be: $$ p(Y \quad | (\mu, \alpha)^{t}) = \prod_{i=2}^{11}\frac{1}{\sqrt{2\pi\sigma_{e}^{2}}}\exp{\frac{-(Y_{i} - \mu - \alpha\cdot{}Y_{i-1})^{2}}{2\sigma_{e}^{2}}}.$$ By Bayes' theorem, we can take the product of the above density with the prior density, and then we'll just need the normalizing constant. My hunch is that this should work out to be a Gaussian distribution, so we can worry about the normalizing constant at the end rather than explicitly calculating it with integrals over $\mu$ and $\alpha$. This is the part I am having trouble with. How do I compute the multiplication of the prior density (which is multivariate) and this product of univariate data densities? The posterior needs to be purely a density of $\mu$ and $\alpha$, but I cannot see how you'll get that out of such a product. Any pointers are really helpful, even if you just point me in the right direction and then I need to go and do the messy algebra (which is what I've already attempted several times). As a starting point, here is the form of the numerator from Bayes' rule: $$ \frac{1}{(2\pi\sigma_{e}^{2})^{5}\cdot{}2\pi\sigma_{p}^{2}} \exp{\biggl [ \frac{1}{2\sigma_{e}^{2}}\sum_{i=2}^{11}(Y_{i} - \mu - \alpha\cdot{}Y_{i-1})^{2} - \frac{\mu^{2}}{2\sigma_{p}^{2}} - \frac{\alpha^{2}}{2\sigma_{p}^{2}} \biggr ] }.$$ The issue is how to see that this reduces down to a Gaussian density of $(\mu, \alpha)^{t}$.
