[site]: crossvalidated
[post_id]: 443971
[parent_id]: 
[tags]: 
Analysis of imputed data

I have 3 questions regarding the analysis of imputed data. I have an idea how to do the analysis, but want to confirm with you guys that it's the correct way. 1) I had a dataset with missing data for baseline variables and outcome variables. Through multiple imputation in SPSS (10 imputations, 50 iterations, PMM for scale variables) I imputed the missing data for the baseline variables. When I analyse the data (i.e. only the 10 imputation data sets) and use the independent sample t-test for a continuous variable results are pooled. This includes mean and p-value, but not standard deviation. Is it correct that I can take the average of the 10 standard deviations calculated for the imputed data sets to calculate the pooled standard deviation? 2) The pooled p-value from the independent t-test on 10 imputation data sets in SPSS is not the average of the 10 p-values that are calculated: am I correct? As I believe a correction is made for the fact that the p-value is based on imputed data? 3) I want to impute the missing data for the outcome variables as well. I did not include those variables in the first imputation process since one of the outcome variables is affected by the value of one of the baseline variables for which data was missing. So I figured that I would first impute the baseline variable, create a 'complete' data set for it and than impute the outcome variables using that data and the other baseline variables. Is it actually possible to impute a second time? And how would I do that? Now (after the first imputation process) I have a dataset which is 11 times as large as originally (original data set + 10 x imputed data set). Do I use all 10 imputation data sets to run the imputation process again which would result in another tenfold of that data set (so 100 fold of my original data set size)? And is it true this would lead to a larger standard deviation for scale variables? Kind regards, Tom
