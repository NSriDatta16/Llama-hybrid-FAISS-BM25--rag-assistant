[site]: datascience
[post_id]: 112808
[parent_id]: 
[tags]: 
Understanding Isolation Forest predictions

I'm running sklearn's IsolationForest on a dataset containing 2 classes of data, one that I know is the anomaly (~1.5% of the entire dataset), the other is the normal dataset. I'm using this (shuffled) dataset to gauge if my isolation forest model is accurate, i.e. I would expect to see most of the anomaly data flagged by the model. However, that is not the case, as out of the 1.18% flagged as anomalous, only about 7% of those flagged belongs to the anomalous class - most of the anomalous data was not flagged. I'm trying to understand how my model is doing the predictions. Besides SHAP, can I look at the feature importance or visualize one of the trees? IsolationForest doesn't seem to have the feature_importances_ attribute like Random Forest. On a more fundamental level, does my approach of using this mixed dataset to test the performance of my model even make sense? (I'm not using a supervised model because this is the only time I would have data I know should be anomalous, and I'm using this as an opportunity to see how my model performs.)
