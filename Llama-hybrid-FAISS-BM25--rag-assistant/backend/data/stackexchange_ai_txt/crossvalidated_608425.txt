[site]: crossvalidated
[post_id]: 608425
[parent_id]: 608386
[tags]: 
Just as a side note, because you are new to both R and logistic regression, I highly recommend reading through Practical Guide to Logistic Regression in R by Joseph Hilbe, which covers how to do logistic regression in R. Given you are new to statistics in general, Learning Statistics with R by Daniel Navarro should also precede this so you have a base understanding of how statistics work. I also strongly advise against using really complicated procedures like splines or lasso regression if you are new to stats, as it requires a solid understanding of a lot of statistical principals before employing them. As Demetri already pointed out, the need to select predictors should be heavily theory-driven or at least based on some research. I find it difficult to believe there isn't some research on your idea or what predictors you need, even if it isn't directly comparable. For example, my field has decades of research on the effects of morphological awareness on reading ability. This has been teased apart a bazillion ways. Morphological awareness can be sub-typed by three varieties in European scripts, can be categorized as a single construct in written scripts like Chinese, and is sometimes lumped together with other predictors of reading using factor analysis. Suppose I believe there is some element of morphological awareness that simply hasn't been tested yet. We can call it Factor M. Factor M hasn't been tested yet, but we as researchers believe it has some effect on reading. To study this, we include it into a regression using a novel measure to identify it's effects. We create a candidate model to the effect of something like this: $$ \text{Reading Comprehension} = \beta_0 + \beta_1\text{Factor M} + \epsilon $$ Perhaps we also believe that while the effect of Factor M alone is meaningful on reading comprehension, perhaps the influence of a second variable is important to control for, so we also create a candidate model with this effect, defined below with Factor N as the control variable. $$ \text{Reading Comprehension} = \beta_0 + \beta_1\text{Factor M}+ \beta_2\text{Factor N}+ \epsilon $$ With these two candidate models, we can test their effects. Thereafter we can perform model comparisons using AIC, BIC, etc. However, at no point have we invented variables out of thin air or just grabbed whatever variables we could. This is because of the following reasons: It is a huge waste of time . In the case where we have 50 variables, we could spend forever trying to clean the data, check assumptions like linearity, estimate outliers, etc. Why waste all that effort when one can simply select predictors that have already been researched and are far more likely to yield results you believe exist? Better to save time on all of this by selecting only what you need. It is very unscientific. This verges on HARKing (Hypothesizing After Results are Known), in that you are just applying whatever regression gives you some nice p values and then shipping your baked p-values to the nearest journal. Yet without hypothesizing before the fact what you achieved, you are conveying that you already knew this relationship existed when in fact you didn't. More importantly, you may capitalize on totally chance findings that will never be replicated with future testing. The meaningfulness of the model may be questionable at best. Let's say we find that wind speed, the amount of oxygen I breathe, and the number of letters I type in a day all are significant predictors of math ability. Why? What could we possibly derive from such a model without at least some assumptions of what relationship actually exist? A regression of this variety would be pointless to entertain. So to summarize and answer your main question: What method do you suggest for reporting significant variables? The answer is the normal way.
