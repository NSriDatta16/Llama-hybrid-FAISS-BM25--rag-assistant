[site]: crossvalidated
[post_id]: 256825
[parent_id]: 256813
[tags]: 
the user didn't create any files during 17 of these days. Do I need to include these days in the data set and set the value to zero Probably, but it depends on what you are trying to achieve. If you're trying to predict what happens on any day, then "no files were created" is a possibility and you should model that. If you're trying to predict what happens only on the days when at least one file is created, then you would omit the zero-files days. When I do a Cullen and Frey graph, my observation is placed in the gray area (denoting a Beta distribution). That confuses me since I read that this is typically for values between 0 and 1. Since the graph uses squared skewness and kurtosis as a basis to suggest distributions, the distributions considered may be arbitrarily multiplied by a scale factor (of either sign) and shifted (since that doesn't change skewness or kurtosis). So if you're looking at a beta distribution you're really looking at a four-parameter beta model, not the two parameter beta. The "Cullen and Frey" graph is basically just an old Pearson plot with some bootstrap details added. As such, most of the distributions listed are Pearson-family, with a few completely-arbitrarily chosen ring-ins added on top. All of them are continuous . You have discrete data which mostly takes small non-negative values (75% of values are 0-5). In general you should not try to approximate small non-negative integers by a continuous distribution. (Even if you did have continuous data, I would be very cautious about using the Pearson plot in general as a tool for choosing distributions.) It's unlikely any single simple-form distribution will provide a good fit to the distribution of number of files (though with so little data you probably can't rule out some simple distributions); this is because the process is likely a mixture of different things (i.e. if you had a lot of data you'd probably need some some kind of mixture distribution but even the components wouldn't necessarily fit any simple distribution very well). It is possible to generate predictions without assuming any single distributional form; it's worth keeping the possibility of some nonparametric approaches in mind. If you're doing prediction you should probably consider the possibility of using predictor variables (IVs) -- such as day of week effects for example - and even of serial-dependence (e.g. if we did a lot of files yesterday maybe there's a good chance we'll have more than average tomorrow). There may also be trends over time. Such things may lead to somewhat more useful predictions, especially if you can get more data. (If you're going to look at doing this kind of thing, you really need the zeros in there.) If you're determined to fit a single distribution in any case, I'd suggest an initially reasonable approximation would be had from the negative binomial distribution. Supplementing your data with the zeros, we have: That looks like it might be adequate as a basis for very simple applications. However, note that we have not yet considered the fact that - even if our model were correct (that the data were generated as a set of iid negative binomials) - the parameter estimates are uncertain, but we haven't yet incorporated that. As a result our fit is closer to the data (in a particular sense) than it is to the notional population from which the data were drawn. If we were interested in something like a prediction interval we would need to incorporate that parameter uncertainty into our interval (there are ways to do this at least approxmiately). Ideally we'd also want to incorporate the fact that the choice of distributional model was itself uncertain -- there's a variety of roughly-as-plausible distributional choices that are also reasonably simple, and that uncertainty about which to use also leads to some uncertainty in prediction intervals (the effect of model-specification uncertainty/model selection uncertainty). It is possible to incorporate at least some of that into prediction intervals as well, though this kind of uncertainty is often ignored. If you have other purposes in mind this may be less important to worry about -- note that to some extent regularization (such as shrinkage) and incorporation of parameter uncertainty will tend to pull in opposite directions.]
