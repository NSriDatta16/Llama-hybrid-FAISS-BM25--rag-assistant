[site]: crossvalidated
[post_id]: 491451
[parent_id]: 192418
[tags]: 
I need a good, intuitive explanation for why not explicitly accounting for these potential sources of variation will lead to a worse model In my experience it is fairly easy to justify the use of mixed models to a non-techincal audience, at a level that they will be able to understand. I generally try to do this with real-world examples. The main justification for mixed model that I use is that it controls for non-independence of the observations due to repeated measures within a subject or group. Independence is one of the main assumptions of linear regression and should be familiar to anyone who has encountered regression. A good example is an investigation into the effect of a medication used to lower blood pressure. Let's say that we take 2 measurements, one at baseline and one at followup, say 1 month after starting the medication. It is obvious that if we had only 1 subject, not only would the result not be generalisable to any reasonable population, but with only 2 observations the model would be overfitted, indeed it would have perfect fit, so no inference would be possible. So right here, we can establish that fitting models to subsets of the data is not a good idea. Also, anyone who has even a rudimentary experience of statistics knows that a large sample is better. This does not require graduate level education at all (if the audience was not convinced on this point I would simply use another basic example, continuing on the blood pressure example, asking how we would estimate the average blood pressure of all the employees in the client's company. The larger the sample, the better the estimate, etc.) Having discarded the idea of subsets, based on overfitting, and statistical power, we then consider a regression model ignoring the repeated measures within groups. Here, continuing on the blood pressure theme, I point out that there if we measure different people over a few points in time, the measures for each person will be more similar to each other than to measures of another person. Again, no advanced statistical knowledge is needed for this. It violoates the assumption of independence in linear regression. A person with high blood pressure today, will likely have high blood pressure tomorrow. Fitting models with random intercepts for subjects specifically accounts for this non-independence. Furthermore, we might expect that these correlations within individuals would diminish over time, or that the response to a drug may be different in different individuals. Again, no advanced statistical knowledge is needed. Mixed models allow for this to be explicitly modelled using random slopes. and sterling references for that contention The use of mixed models is well established in lots of different areas of applied research, so I would just point to some of the classic textbooks: (eg Bryk & Raudenbush (1992), Snijders & Bosker (2011) and Pinheiro & Bates (2000)). Between them, these 3 books have around 45,000 citations according to Google Scholar, which I believe qualifies them as "sterling" references. Bryk, A. S., & Raudenbush, S. W. (1992). Hierarchical linear models: Applications and data analysis methods. Sage Publications, Inc. Pinheiro, J., & Bates, D. (2000). Mixed-effects models in S and S-PLUS. Springer Science & Business Media. Snijders, T. A., & Bosker, R. J. (2011). Multilevel analysis: An introduction to basic and advanced multilevel modeling. Sage.
