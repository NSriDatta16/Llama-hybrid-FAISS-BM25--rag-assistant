[site]: crossvalidated
[post_id]: 521275
[parent_id]: 521269
[tags]: 
This is an unnecessary trade-off, as data don't have to be "missing completely at random" (MCAR) to include cases with missing values in the analysis. In practice, you often have data "missing at random" (MAR) in the technical sense defined in Stef van Buuren's Flexible Imputation of Missing Data (FIMD): If the probability of being missing is the same only within groups defined by the observed data, then the data are missing at random (MAR). MAR is a much broader class than MCAR." Put another way, MAR means missingness doesn't depend systematically on information not included in your data set. In that case, often a reasonable assumption, you use the information in the observed data to make multiple sets of estimates of the missing data (multiple imputations), fit your model to all of the imputed data sets, and then combine all the resulting models in a way that incorporates the uncertainty in both the imputations and the coefficient estimates. In general, you don't want to omit any covariate associated with outcome from a logistic regression, as omission biases coefficients for included predictors downward in magnitude even if the omitted predictor is uncorrelated with those included. To estimate what would happen from listwise deletion of cases having missing values, you would need to have some model in mind for the missingness as a function of the cases and their covariate values. That essentially is an assumption of MAR, anyway. Section 1.3 of FIMD explains the dangers of listwise deletion and other solutions that seem "simple" at first but only work in limited circumstances. So why not explore multiple imputation and see where it leads? In response to comment: If you nevertheless want to compare listwise deletion of cases against covariate omission when MAR cannot be assumed, then you can draw from van Buuren's suggestion in Section 6.2 of FIMD when missing not at random (MNAR) is suspected: perform a concise simulation study ... customized for the problem at hand with the goal of finding out how extreme the MNAR mechanism needs to be to influence the parameters of scientific interest. You apply the same principles. Instead of performing and evaluating multiple imputation, however, you evaluate your alternative deletion strategies on sets of simulated data. There is, however, no way to do this just "mathematically." As van Buuren notes later in discussing this type of sensitivity analysis : In sensitivity analysis, imputations are generated according to one or more scenarios ... we should attempt to make an educated guess about both the direction and the magnitude of the missing data had they been observed. By definition, this guess needs to be based on external information beyond the data. (Emphasis added.) The critical issue is not mathematical. The sensitivity analysis itself depends on your assumptions about why and how the data in your situation are missing beyond what you can glean from the observations themselves . That's particularly important for your logistic regression scenario with its inherent omitted-variable bias.
