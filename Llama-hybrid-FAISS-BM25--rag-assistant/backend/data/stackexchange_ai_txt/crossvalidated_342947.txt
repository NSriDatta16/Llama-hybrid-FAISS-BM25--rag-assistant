[site]: crossvalidated
[post_id]: 342947
[parent_id]: 342578
[tags]: 
Yes, this is data leakage . Whenever your model has information about your testing set that it would not have during real-time inference, that is data leakage. For example, if you asked me to predict yield and told me the day was 735250 or 735265, I would have a pretty good accuracy. But if I needed to perform real-time inference, e.g. predict yield when the day was 735999, I would be a lot less accurate. A large caveat, just because you have data leakage does not mean you will overfit . It depends entirely on whether or not your model would be able to exploit the information. A high capacity model like a neural network or a random forest would likely be able to, whereas a logistic regression may not be. But why trust strangers on the internet? If you have enough data, take the most recent 20% of data as one test set, then shuffle the remaining data and take another 20% as a second test set. Train a model and compare performance between these two test sets. If there's no significant difference, then you shouldn't worry too much about it.
