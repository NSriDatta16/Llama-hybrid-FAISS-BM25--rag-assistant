[site]: crossvalidated
[post_id]: 604616
[parent_id]: 189449
[tags]: 
This is not a 100% confident answer but my thoughts on this question. I have the same confusion as @max regarding Andrew Ng's discussion on bias/variance and training error/testing error. I suppose @einar is correct - Andrew doesn't use the training set error to estimate bias. Instead, Andrew compares training set and test set error to figure out whether the error of the model is dominated by bias or variance. But the side effect is, it may cause confusion for beginners (for example, me, when I first attended Andrew's machine learning module on Coursera). To estimate the bias and variance of the machine learning model, my recommendation is to use the mlxtend library , which comes with some good tutorials, such as this . Essentially, the bias_variance_decomp function uses a bootrapping function to sample the training data for multiple rounds, and in each round, the sampled training data is used to train a model, which is then applied to make predictions on the given and fixed testing data. Based on this process, the bias of the algorithm is estimated as the average prediction of the testing data (across multiple rounds), and the variance is estimated as the variance of predictions across multiple rounds. These two estimations are consistent with the theory of bias and variance. Any comments or critiques are highly welcome!
