[site]: datascience
[post_id]: 122835
[parent_id]: 
[tags]: 
Exploding loss in unstable model

I am training a classifier (based on transformer encoders), on top of some complex data. My data is extremely imbalanced (although I do undersample the higher concentration class somewhat) and rather limited (generally few training and validation examples). I am generally satisfied with the performance of the model, however models trained with the sample hyperparameters can vary significantly, and more concerning to me is that sometimes loss will explode, while yielding similar results. I am using a focal loss function, and I am having trouble understanding why these values are reaching the magnitudes they do. For example, here are the accuracy and loss I sometimes recieve: While other times train loss explodes anywhere from magnitudes of -10^4 to -10^15 and higher. While not as pronounced with validation loss, sometimes it stays in a reasonable range as in the first example, and sometimes it can reach values in the -1000s I thought I understood how exploding / vanishing gradients work, yet model performance seems to be improving significantly, even while this problem occurs. While the figures below show negligible performance gains after loss drops significantly, some results I receive can have high magnitude loss on epoch one. The data between runs is somewhat different because of the samples that are chosen in the undersampling process, but everything else is seeded similarly, and I would not expect that to impact the model results in this way. How can I explain these results, and create more stability in my model & results? I have attempted changing learning rates and such with no significant success.
