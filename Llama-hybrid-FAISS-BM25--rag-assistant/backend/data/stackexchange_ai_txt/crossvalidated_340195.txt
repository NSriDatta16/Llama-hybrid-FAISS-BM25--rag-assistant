[site]: crossvalidated
[post_id]: 340195
[parent_id]: 
[tags]: 
What is the correct operation to compute feature crosses on equal size vectors?

In working through Google's Machine Learning Crash Course , I am a little stuck in my understanding of the concept of feature crosses for one-hot encoded features. For example, they take two binned values: binned_latitude = [0, 0, 0, 1, 0] binned_longitude = [0, 1, 0, 0, 0] and combine them to get "a 25-element one-hot vector (24 zeroes and 1 one)". According to the course, the name feature crosses is taken from the cross product, but my understanding is that the cross product doesn't work for arbitrarily shaped vectors. I am able to get a correct-looking result by using numpy's outer function and flattening the result, but is this the correct way to do a feature cross? >>> x = np.outer(binned_latitude, binned_longitude).flatten() >>> x.shape (25,) >>> x array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])
