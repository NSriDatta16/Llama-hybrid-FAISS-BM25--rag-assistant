[site]: crossvalidated
[post_id]: 213900
[parent_id]: 
[tags]: 
Multi-Channel Attribution Models: How to Measure Accuracy?

What methods are there, if any, that measure or approximate the accuracy of attribution models ? I'm looking for something purely based in (real) data; preferably something analogous to typical cross validation for machine learning. I realize that there is probably no perfect way to do this since the underlying truth is very obscure, but as a statistician I'd like to be able to compare one model to another in a better way than just 'this intuitively seems to be more accurate'. Everybody talks about first/last click attributions to be the worst, but can that actually be proven? There are three answers that I have observed throughout my online research: No comments on measuring accuracy (by far the most prevalent one) Testing in practice (model the attribution, act on the results by adjusting marketing, see if ROI increases, repeat) Artificially modeling click-streams and outcomes, then running attribution models and comparing results with the underlying parameters of the click-stream models (highly biased)
