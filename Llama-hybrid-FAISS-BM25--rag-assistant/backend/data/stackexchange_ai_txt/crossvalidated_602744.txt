[site]: crossvalidated
[post_id]: 602744
[parent_id]: 602550
[tags]: 
One option is to just treat this as a standard multiclass classification task. After training a model, you can use methods that look for overlapping labels like this to determine whether you might want to merge some of your classes, or define them a bit more distinctly. Another option after training a standard multi-class classifier, is to use an assymetric loss function to evaluate the resulting model (eg. for tuning its hyperparameters). The loss used for evaluation could more heavily penalize a prediction of "filthy" vs a prediction of "moderately dirty" when the annotated label is "a little dirty". A third option that is most "proper" is to use ordinal classification models. However in my experience, this is just mathematically more elegant but in practice does not give better results than a properly-applied standard multi-class classifier.
