[site]: crossvalidated
[post_id]: 45826
[parent_id]: 
[tags]: 
What is a good way to measure how well a set of data fits to a set of functions

I got a set of data sets as reference data, each comprised of 14 non-independent variables that is to be used as a basis for developing a method to compute data of that kind with fewer computational resources. So basically a set of points in 14-dimensional space. What I need to do is parametrize my new method so that the output data, again points in 14-dimensional space, fits the reference data as well as possible. I've done a Principal component analysis, which reduced my 14-dimensional point cloud to a set of 5 linear functions that contain 98% of the variance of my reference data. What I'm looking for now is a way to generate some kind of measure that tells me how well the new data fits to the reference data, either using the original data set or the PCA-derived linear functions. And this is where my knowledge ends right now, so I would be grateful for pointers towards good methods to derive such a "how well does the new data fit the reference data" measure of any kind that I can use as benchmark for my parameters.
