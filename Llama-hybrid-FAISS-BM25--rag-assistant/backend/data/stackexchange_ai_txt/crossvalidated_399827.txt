[site]: crossvalidated
[post_id]: 399827
[parent_id]: 
[tags]: 
How do hidden layer of a trained network look like?

Suppose I have a deep feed-forward neural network with sigmoid activation $\sigma$ already trained on a dataset $S$ . Let's consider a training point $x_i \in S$ . I want to analyze the entries of a hidden layer $h_{i,l}$ , where $$h_{i,l} = \sigma(W_l ( \sigma (W_{l-1} \sigma( \dots \sigma ( W_1 \cdot x_i))\dots). $$ My intuition would be that, since gradient descend has passed many times on the point $x_i$ updating the weights at every iteration, the entries of every hidden layer computed on $x_i$ would be either very close to zero or very close to one (thanks to the effect of the sigmoid activation). Is this true? Is there a theoretical result in the literature which shows anything similar to this? Is there an empirical result which shows that?
