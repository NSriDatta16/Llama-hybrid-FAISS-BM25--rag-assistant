[site]: crossvalidated
[post_id]: 9562
[parent_id]: 9533
[tags]: 
Your setting is pretty hard. I have no solution, but a couple of points. Energy based models can give you a scalar corresponding to a "grade of belief" that an input is generated by the distribution of your data. It comes down to chosing a model and a good loss function. Check out Yann Lecun's tutorial on energy based models . Also, there is Ranzato's energy based unsupervised framework paper where they use sparse autoencoders. Sparseness is generally desirable given your tiny dataset, I guess. A restricted Boltzmann machine might work. You can train your RBM on the data with less than 25 hidden features (which you might anyway because of your lack of data) enabling you to write down the probability of any new input to belong to the data given by your distribution. Actually, an RBM is a energy based model as well. I have a feeling that SVM with Kernels might be a too complex model for what you are doing. Do you get acceptable scores on a test set?
