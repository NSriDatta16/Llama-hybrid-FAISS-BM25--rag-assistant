[site]: crossvalidated
[post_id]: 451
[parent_id]: 26
[tags]: 
When describing a variable we typically summarise it using two measures: a measure of centre and a measure of spread. Common measures of centre include the mean, median and mode. Common measure of spread include the variance and interquartile range. The variance (represented by the Greek lowercase sigma raised to the power two) is commonly used when the mean is reported. The variance is the average squared deviation of variable. The deviation is calculated by subtracting the mean from each observation. This is squared because the sum would otherwise be zero and squaring removes this problem while maintaining the relative size of the deviations. The problem with using the variation as a measure of spread is that it is in squared units. For example if our variable of interest was height measured in inches then the variance would be reported in squared-inches which makes little sense. The standard deviation (represented by the Greek lowercase sigma) is the square-root of the variance and returns the measure of spread to the original units. This is much more intuitive and is therefore more popular than the variance. When using the standard deviation, one has to be careful of outliers as they will skew the standard deviation (and the mean) as they are not resistant measures of spread. A simple example will illustrate this property. The mean of my terrible cricket batting scores of 13, 14, 16, 23, 26, 28, 33, 39, and 61 is 28.11. If we consider 61 to be an outlier and deleted it, the mean would be 24.
