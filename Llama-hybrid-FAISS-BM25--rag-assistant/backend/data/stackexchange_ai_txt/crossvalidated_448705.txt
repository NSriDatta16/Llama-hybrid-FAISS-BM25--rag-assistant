[site]: crossvalidated
[post_id]: 448705
[parent_id]: 436759
[tags]: 
To answer your second question first: your graphs look absolutely fine to me. Odds ratios typically have a skewed distribution - for one thing they lie in $[0, \infty)$ and the 'neutral' value is 1. That's one reason for analysing their logs, for which the range is $(-\infty, \infty)$ and which typically have a reasonably symmetric distribution. Short answer to your first question: Take the posterior means and HPDIs of the log -odds ratios, then exponentiate them to give odds ratios for interpretation if you wish. It makes more sense to look at geometric means rather than arithmetic means of ratio measures – ½ and 2 are equally far from 1 on a ratio scale. The geometric mean of a set of ratios is the same as the exponential of the arithmetic mean of their logarithms ( see e.g. Wikipedia ). As much of statistics centres around (arithmetic) means and expectations, statistical analysis of ratios is usually conducted on their logarithms, and the results then transformed back to the ratio scale only for interpretation. From a Bayesian perspective, you'd want a Bayes estimator of a ratio measure to be based on a loss function that punishes ½ and 2 equally if the true value is 1. Working on the log scale means you can use the posterior mean or median ( the posterior mode is harder to motivate ). There's a nice illustration in your case: for consistency you'd hope that the Water:Coffee odds ratio should be equal to Water:Decaf $\times$ Decaf:Coffee, implying that the log -odds ratio for Water-Coffee should equal Water-Decaf $+$ Decaf-Coffee. That doesn't work for the posterior means of the odds ratios: $0.4 \ne 3.9 \times 0.2$ . It does work for the posterior means of the log-odds ratios: $-1.3 = 1.0 + (-2.3)$ . (It doesn't work for the endpoints of the HDPIs because stats ain't that simple – you can't add standard errors or endpoints of uncertainty intervals even when estimates are independent, and here they're definitely not...)
