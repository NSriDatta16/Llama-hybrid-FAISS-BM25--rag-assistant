[site]: crossvalidated
[post_id]: 73139
[parent_id]: 
[tags]: 
Why does Naive Bayes outperform Support Vector Machines?

I have a dataset composed of about 36000 attributes and 550 samples, the dataset is generated from text communication between people in some chatrooms. The questions is when I try to classify these samples, a Naive Bayes classifier always outperforms a support vector machine, both in speed and accuracy. But in literature it is always noted that SVM is better in text-mining classification tasks. Can anyone please explain in which situations Naive Bayes is better and in which situations SVM? For more information about the question: I am using the RapidMiner tool, I'm using 10 fold cross validation with stratified sampling. for Naive Bayes, the Laplacian correction is applied and for SVM I use a dot kernel and other parameters are all in their defaults, but when I change the parameters and try again, I get same result; Naive Bayes still outperforms SVM.
