[site]: crossvalidated
[post_id]: 519642
[parent_id]: 519597
[tags]: 
From 100 experiments you will not get exactly 95% of CIs to contain the true value, sometimes it will be less, sometimes more, in the same way, as when you do two coinflips, you will not get always 1 head and 1 tail. If you mean exact in a statistical way that 95% of infinite repetitions of the same sampling procedure will give you CIs that contain the true parameter then that is the definition of the CI so by definition yes. In practice, you might not get close to this number, because some procedures to construct confidence intervals are approximate, and the confidence intervals also depend on the model assumptions. E.g., normality, independent random samples and so on. Each individual CI does not have 50% chance of either yes or no, in the same way how you don't have a 50% chance to win a lottery, either you win or you don't. Statisticians sometimes say that, and it is really annoying and does not help anybody. What they want to say, is that strictly speaking the 95% is defined for many repetitions, but not for a single interval, so (in their view) it's not meaningful to talk about the probability of a parameter to be in one specific or sometimes called realized interval unless you convert to bayesianism. Here is an example why 95% of all intervals containing the true value does not imply that a specific interval has a 95% chance to contain the true value. If I report 95% of the times that an interval is from -infinity to infinity, and 5% that the interval is empty, this procedure will correctly contain the true value 95% of the times, but if I look at the interval -inf to inf I know that it has 100% chance of capturing the true value. This is however not how confidence intervals are usually constructed and in practice, the difference between long-running frequencies and individual probabilities is just a needless pedantry (although many people smarter than me will disagree, they are also bigger pedants)
