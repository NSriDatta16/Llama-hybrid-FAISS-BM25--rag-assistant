[site]: crossvalidated
[post_id]: 638324
[parent_id]: 139419
[tags]: 
In statistics, there are three major errors: bias, variance, and contaminations. Sample mean is a consistent estimator, however, its variance and robustness is not desired in many scenarios, so historically, many attempts have made to reduce the overall errors of mean estimation. For example, trimmed mean, Winsorized mean, Hodges-Lehmann estimator, Huber M-estimator, and median of means. Comparing the performance of these estimators is still a hot topic in statistics research. Recent advances suggested that the bias bound of Winsorized mean is better than that of the trimmed mean (Mariusz Bieniek (2016) Comparison of the bias of trimmed and Winsorized means, Communications in Statistics - Theory and Methods, 45:22, 6641-6650, DOI: 10.1080/03610926.2014.963620 ) Also, the concentration bound of median of means nears the optimum of sub-Gaussian mean estimator (Luc Devroye. Matthieu Lerasle. Gabor Lugosi. Roberto I. Oliveira. "Sub-Gaussian mean estimators." Ann. Statist. 44 (6) 2695 - 2725, December 2016. https://doi.org/10.1214/16-AOS1440 ) Statistics is undergoing a trend from nonparametrics to semiparametrics, because these research are new, so they are not emphasizing in current textbooks. In my paper, I defined two new classes of semiparametric distributions, introduced several new mean estimators and further explain why the Winsorized mean is better than the trimmed mean in most cases. Also, the median Hodges-Lehmann mean is proposed as the optimun nonparametric robust mean estimator. If you are interested, you can watch my youtube videos or read my paper https://www.youtube.com/@Iobiomathematics . https://zenodo.org/records/8127703 https://zenodo.org/records/6629988
