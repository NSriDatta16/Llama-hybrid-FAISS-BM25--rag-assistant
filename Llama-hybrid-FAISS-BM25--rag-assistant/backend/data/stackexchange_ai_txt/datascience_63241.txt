[site]: datascience
[post_id]: 63241
[parent_id]: 
[tags]: 
Derivative of logarithm of loss function. Logistic regression

I am reading machine learning literature. I found the log-loss function of logistic regression algorithm: $$ l(w) = \sum_{n=0}^{N-1}\ln(1+e^{-y_nw^Tx_n}) $$ Where $ y \in {-1;1}, w \in R^P, x_n \in R^P$ Usually I don't have any problem with taking derivatives. Think that derivatives w.r.t. to a vector is something new to me. I can't figure out on how to take derivative w.r.t w. My try was: $$ \frac{dl(w)}{dw}=\sum_{n=0}^{N-1}\frac{e^{-y_nw^Tx_n}y_nx_n}{1+e^{-y_nw^Tx_N}} $$ Is it possible that: $$ \begin{bmatrix} ... \\ \frac{dl(w)}{w_i} = \sum_{n=0}^{N-1}\frac{-e^{-y_nw^Tx_n}y_nx_n}{1+e^{-y_nw^Tx_n}}x_i \\ ...\\ \end{bmatrix} $$ I suspect that here is something wrong. Can you please show me some example, some hints on how to do that. Thanx
