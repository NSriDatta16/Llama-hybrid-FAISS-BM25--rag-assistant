[site]: datascience
[post_id]: 76382
[parent_id]: 
[tags]: 
Data scaling for large dynamic range in neural networks

The usual strategy in neural networks today is to use min-max scaling to scale the input feature vector from 0 to 1. I want to know if the same principle holds true if our inputs have a large dynamic range (for example, there may be some very large values and some very small values). Isn't it better to use logarithmic scaling in such cases?
