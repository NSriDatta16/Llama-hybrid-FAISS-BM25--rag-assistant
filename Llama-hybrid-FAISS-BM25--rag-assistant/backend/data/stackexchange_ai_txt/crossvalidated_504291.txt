[site]: crossvalidated
[post_id]: 504291
[parent_id]: 
[tags]: 
Show that posterior distribution is proportional to likelihood times prior when both y and X are in the equation

Reviewing MCMC for my work, I have got a problem with the very fundamental equation for the posterior: $$ P(\theta |y, X) = \frac{P(y|X, \theta)P(\theta)}{p(y|X)} = \frac{P(y|X, \theta)P(\theta)}{Z} $$ I found the equation above in this lecture note (first equation on page 3) and also in this lecture note (page 3). As well-known, the equation simply says the posterior is a product of the likelihood and the prior divided by a normalization constant. As I try to derive the equivalence, however, I have reached a different end: $$ P(\theta |y, X) = \frac{P(y, X, \theta)}{p(y, X)} = \frac{P(y, X, \theta)}{P(X, \theta)}\frac{P(X, \theta)}{P(X)}\frac{P(X)}{P(y, X)} = \frac{P(y|X, \theta)P(\theta|X)}{p(y|X)} $$ Here, instead of the prior P(theta), I have P(theta|X) which is not the same as the prior unless theta is independent of X. How do I prove that the posterior is proportional to likelihood times prior in this setting? I will appreciate your help in advance!
