[site]: crossvalidated
[post_id]: 613126
[parent_id]: 
[tags]: 
How do you find the gradients of weights and biases in neural network during back propagation?

I have been trying to create a neural network from scratch. I have been trying to calculate the gradients of the weights and biases of the neural network by watching videos and reading papers, but still have been unable to get a good grasp on it. z is all the weights multiplied by the nodes of the previse layer plus the bias of the node. a is the sigmoid of z I believe I having trouble with the w(L-number) calculations in the formula. Because I believe there should be more w(L-number) and does not work otherwise. I have added some pictures for clarification:
