[site]: datascience
[post_id]: 58560
[parent_id]: 
[tags]: 
Models after word2vec outputs

I am originally using a bag of word (2-gram) model to approach a classification problem. The one hot encoding of the 2-gram output was sent to a logistic regression or neural network to build a classification model. Now, I am experimenting the gensim word2vec approach, each word is now a vector from word2vec. That is, if my sentence have 10 words, it would become a 10x30 array (assume word2vec embedding dimension is 30). It's not clear to me how do I send such outputs to a logistic regression or neural network model like before ... What type of model should I use after the gensim word2vec outputs to solve a classification problem? Thanks!
