[site]: crossvalidated
[post_id]: 239380
[parent_id]: 239379
[tags]: 
Squared difference divided by $n$ or by $n-1$ are both variance . The only difference is that in the second case it is an unbiased estimator of variance. Taking square root of it leads to estimating standard deviation . I guess that mean squared deviation and root mean squared deviation are used more commonly in machine learning field where you have mean squared error and it's square root that are often used. I also guess that some people prefer using mean squared deviation as a name for variance because it is more descriptive -- you instantly know from the name what someone is talking about, while for understanding what variance is you need to know at least elementary statistics. Check the following threads to learn more: How exactly did statisticians agree to using (n-1) as the unbiased estimator for population variance without simulation? Why is sample standard deviation a biased estimator of $\sigma$? Intuitive explanation for dividing by $n-1$ when calculating standard deviation?
