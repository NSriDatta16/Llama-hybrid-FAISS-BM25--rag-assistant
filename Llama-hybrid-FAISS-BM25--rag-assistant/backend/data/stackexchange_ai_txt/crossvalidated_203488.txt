[site]: crossvalidated
[post_id]: 203488
[parent_id]: 193538
[tags]: 
The tuning parameter alpha controls the tradeoff between the complexity of the tree and its accuracy/fit. 'alpha' being the penalty and 'T' the number of terminal nodes of the tree, as you increase alpha, branches get pruned in a predictable fashion ground up i.e there exists a different subtree that minimizes the cost complexity criterion for each value of the penalty. As you mentioned, you can select an optimal value of alpha by using K-fold cross validation - build as large a tree as you can on each fold while aiming to minimize the cost complexity criterion for a different value of alpha. Averaging the results of all the trees and predicting on the kth fold would give you error rates for each alpha. Pick the penalty that minimizes the cross validation error. Equation 9.16 in the 4th printing of ESL is simply a different representation of the same (cost complexity) criterion.
