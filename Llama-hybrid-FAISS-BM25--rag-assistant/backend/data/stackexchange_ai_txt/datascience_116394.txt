[site]: datascience
[post_id]: 116394
[parent_id]: 116337
[tags]: 
One of the most common uses of k-fold cross-validation is for model selection (i.e. what type of model - such as linear regression, random forest, neural network) is best for the problem and/or what are the appropriate hyperparameter settings. We train models using K-fold cross-validation for each model type and/or set of hyperparameters we want to test, and select the best one based on the cross-validation results. Then we use all the training data to train another model, with the hyperparameters set to the values found by the cross-validation process. This last model is one evaluated using the test data.
