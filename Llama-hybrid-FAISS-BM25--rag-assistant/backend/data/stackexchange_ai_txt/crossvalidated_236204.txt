[site]: crossvalidated
[post_id]: 236204
[parent_id]: 232562
[tags]: 
Partial answer: Focusing on SVMs for a while, I got to this reference (pointed by @DikranMarsupial in Bias term in support vector machine ): Poggio, T., Mukherjee, S., Rifkin, R., & Rakhlin, A. (2001). Verri, A. b . In Proceedings of the Conference on Uncertainty in Geometric Computations . Excerpt: This paper is devoted to answering the following questions: When should b be used? Is there a choice of using or not using b ? What does the choice mean? Are the answers different for RNs (Regularization Networks) and SVMs? [...] In their conclusion, they mention the use of a bias term is related to not privileging certain values for classification thresholds in SVMs. Also: For infinite conditionally positive definite kernels the b term is de facto required allowing a natural interpretation of the optimizer. For positive definite kernels the natural choice is without the b term, however it's possible to use one, actually leading to another kernel interpretation different of the one without it. See that the minimizer is written including an explicit parameter b to be optimized.
