[site]: crossvalidated
[post_id]: 463939
[parent_id]: 
[tags]: 
Understanding deterministic models via probabilistic graphical model

I have read a few tutorials how we can think of deterministic neural networks with the help of probabilistic graphical models. Very often they would offer an image as seen bellow and say, our model is P(y|x,w) where y are labels, x are features and w weights. But as far I have studied Graphical models, we would denote model equation with joint probability: P(Y, X, W) = P(Y|X, W)*P(X)*P(W). And if we combine "Tutorial" model with my model, we would get P(y|x,w) = P(y|x,w)*P(x)*P(w) , which is obviously not true and not the case. I am almost certain they are correct and I am wrong and I am missing some elementary understanding and I would appreciate if you could help me understand/derive the logic.
