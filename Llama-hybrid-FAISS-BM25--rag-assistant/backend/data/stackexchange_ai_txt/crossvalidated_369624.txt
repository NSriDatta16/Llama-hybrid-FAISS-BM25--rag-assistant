[site]: crossvalidated
[post_id]: 369624
[parent_id]: 369045
[tags]: 
Fun question. The key problem as noted by @MartijnWeterings is that the number of trees at phase 2 is only a partial measurement of the total number of trees. If we knew the total number of trees, however, we could solve the problem by building a model of the number of nuts observed at stage 1 given the number of trees at stage 1, and then predict the number of nuts at stage 2 using the number of trees at stage 2. Our strategy in this answer is therefore to first estimate the number of trees at stage 2 and then build a model of nuts given trees at stage 1. Notation and assumption In the following, I assume that the sampling of trees and squirrels is random at all stages. Let $n_{1i}$ denote the sum of all nuts collected by squirrel $i$ in phase 1. Let $t_{1i}$ denote the total number of trees squirrel $i$ stored nuts at in phase 1. Let $n_{2j}$ denote the unobserved sum of nuts collected by squirrel $j$ in phase 2 and let $t_{2j}$ denote the number of trees squirrel $j$ stored nuts at in phase 2. Finally let $k_{2j}$ denote the partial number of trees observed, where $k_{2j} \le t_{2j}$ , Number of trees at stage 2 As noted by @MartijnWeterings $k_{2j}$ is always smaller or equal to the total number of trees $t_{2j}$ at phase 2, which is unknown. Our goal thus becomes that of estimating $t_{2j}$ as closely as possible. Fortunately, we have some information on $t_{2j}$ . Depending on your sampling design in phase 2, there is a probability $p$ that a squirrel is captured at one of the total $t_{2j}$ trees that it visits. The probability of $k_{2j}$ is thus binomial with parameters $t_{2j}$ and $p$ . However, we observe binomial $k_{2j}$ ; the number of trees $t_{2j}$ , however, is not binomial distributed given $k_{2j}$ . I was not sure about its exact distribution and therefore I asked a question about it on Mathematics-StackExchange . I received the useful reply that the probability mass function of $t=t_{2j}$ with $k=k_{2j}$ and $p$ is given by $$P(t; k ,p) = \binom{t-1}{k} p^t (1-p)^{(t-k)}, \quad t \in \{k,...,\infty\}.$$ for all $j$ which has expectation $E(t)=k/p$ . Hence if we know $k_{2j}$ and $p$ we could estimate $\hat{t}_{2j}=k_{2j}/p$ . As said, probability $p$ depends on your sampling design, but fortunately we can estimate it from the data as $$\hat{p}=\frac{\sum_{j} k_{2j}}{\sum_{i} t_{1i}}$$ so that $\hat{t}_{2j}=k_{2j}/\hat{p}$ . Estimation under proportionality assumption Let $$ \pi = \frac{1}{\#S_1} \sum_{i} \frac{n_{1i}}{t_{1i}}$$ be the average proportion of nuts left by a squirrel at a tree. A first estimate of the total number of nuts of squirrel $j$ is $$ \hat{n}_{2j} = \pi \hat{t}_{2j}.$$ Estimation using relationship between nuts and trees at phase 1 This may seem unsatisfactory, because it does not take into account that there may be a relationship between $n$ and $t$ other than a simple proportional one. For example we may imagine squirrels having the strange behavior of leaving less nuts per tree the more nuts they have at their disposal. Then the total number of nuts $n$ would not proportionately increase with $t$ and instead flatten off. Hence we could decide to model $$ n_{1i}= f(t_{1i},\theta) + \epsilon_i$$ where $f$ is a non-linear function with parameters theta and $\epsilon_i$ is a measurement error term. An obvious choice might be $$ n_{1i} = \theta_0 + \theta_1 \log(t_{1i}) + \epsilon_i$$ with $\epsilon_i$ iid normal with 0 expectation. The model could be fit by non-linear least squares or maximum likelihood. An estimator would then be $$ \hat{n}_{2j} = \hat{\theta_0} + \hat{\theta_1} \log(\hat{t}_{2j})$$ Of course other functional forms could be used or you could use flexible modeling techniques to approximate the functional relationship, such as random forests (pun intended). Simulations Does this work? Let's try it. I simulate data in R according to the following ideas. The probability that a squirrel collects $n+1$ nuts is given by $n \sim \text{Poisson}(20)$ . A squirrel then arrives at the first tree and hides $h_1+1$ nuts where $h_1 \sim \text{Poisson}(\lambda)$ and $\lambda \sim \Gamma(60/n,1)$ . It continues hiding at $1 + (h_2,...,h_t)$ nuts until it arrives at tree $t$ and is out of nuts. It does so regardless of whether you observe it in phase 1 or 2; however in phase 1 you observe all $h_t$ , whereas in phase 2 you observe a sample from $\{h_1,...,h_t\}$ . As said I assume you have a simple random sample of trees at phase 2 and so you observe $h_{kj}$ (the k-th tree visited by squirrel j) with probability $p$ (below in the code I call this truncation). I now sample 1000 squirrels at phase 1. The plot below illustrates the relationship of the total number of trees and total number of nuts collected. It can be seen that there is a decay in that relationship across $t$ . I now sample at stage 2 with $p=0.5$ and consider three estimators. First the estimator under proportionality. Second, I create an estimator which uses the conditional mean of $n_1$ at each observed level of $t_1$ as an estimate for $n_2$ at $\hat{t}_2$ . For benchmarking I use again the conditional mean of $n_1$ at each observed level of $t_1$ as an estimate for $n_2$ , but now at the true number of trees $t_2$ at phase 2. This estimator is of course not available in practice. For two samples, one from each of phase 1 and 2, respectively, and the three estimators I arrive at the following biases, respectively: 5.61, -0.19, and 0.24. Furthermore we observe the following root mean square errors: 15.3, 4.07, 3.32. We see that the conditional mean estimator with an adjusted estimate for the number of trees at phase 2 has almost as good performance as the estimator using the unknown true number of trees at phase 2. The remaining error is variance which can perhaps be reduced a bit further by using a better model for $n_1$ given $t_1$ than the non-parametric conditional mean model. Here is a function creating the data for the simulation I made. # A squirrel collects nuts squirrel_set = function(n, trunc= FALSE){ nuts = rpois(n, 20) + 1 nut_seq = list() for(i in 1:n){ j = 1 nuts_left = nuts[i] nuts_hidden = numeric() # squirrel hides nuts at tree j while(nuts_left>0){ if(j == 1) {lambda = rgamma(1,60/nuts_left,1) } if(lambda And here the code used in analysis: set.seed(12345) n = 1000 # Phase 1 nut_seq1 = squirrel_set(n) # Phase 2 nut_seq2 = squirrel_set(n, trunc = TRUE) nut_seq2_true = nut_seq2[[1]] nut_seq2_trunc = nut_seq2[[2]] # Trees and nuts at phases 1 and 2 t1 = sapply(nut_seq1,length, simplify = TRUE) # Trees seen at phase 1 k = sapply(nut_seq2_trunc , length) # Trees seen at phase 2 nut_seq2_trunc = nut_seq2_trunc[k>0] # Squirrels with k=0 have avtually not been observed nut_seq2_true = nut_seq2_true[k>0] k = k[k>0] n1 = sapply(nut_seq1,sum, simplify = TRUE) # Trees seen at phase 1 n2 = sapply(nut_seq2_true,sum, simplify = TRUE) # Trees at phase 2 (unobserved) t2 = sapply(nut_seq2_true,length, simplify = TRUE) # Trees at phase 2 (unobserved) # Plot plot( t1, n1, xlab='Trees at phase 1', ylab='Total number of nuts at phase 1') mnuts = numeric() for(i in 1:max(t1)){ mnuts[i] = mean(n1[t1 == i]) } lines( 1:max(t1), mnuts, col=2) legend("bottomright",lty=1, lwd=2, col='2', legend='Conditional mean') # Estimators p = sum(k) / sum(t1) # Estimate of observational probability at phase 2 t2_est = k/p # Estimate of total number of trees for each squirrel at phase 2 n2_prop_est = t2_est * mean(sapply(n1,sum, simplify = TRUE)/t1 ) # proportionality mnuts = numeric() for(i in 1:max(t1)){ mnuts[i] = mean(n1[t1 == i]) # Conditional mean at each level of trees at phase 1 } n2_regest = mnuts[round(t2_est)] # Non-parametric regression estimate of n2 n2_regest_truet2 = mnuts[t2] # Bias and Variance mean( n2_prop_est - n2) sqrt(mean( (n2_prop_est - n2)^2 )) mean( n2_regest - n2 , na.rm=TRUE) sqrt(mean( (n2_regest - n2)^2 , na.rm=TRUE)) mean( n2_regest_truet2 - n2 , na.rm=TRUE) sqrt(mean( (n2_regest_truet2 - n2)^2 , na.rm=TRUE))
