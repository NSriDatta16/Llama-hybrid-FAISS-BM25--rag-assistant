[site]: crossvalidated
[post_id]: 55383
[parent_id]: 
[tags]: 
Evaluation of LMT (Logistic Model Tree) classifier results

I have been using the LMT Logistic Model Trees algorithm in some classification experiments. However, after reading the reference/documentation regarding the algorithm (Niels Landwehr, Mark Hall, Eibe Frank (2005). Logistic Model Trees. Machine Learning. 95(1-2):161-205.) and implementing it myself, I would still require some more clarification on the best way to evaluate the trees that are produced, especially in the manner of observing/evaluating how each leaf can contribute to a particular classification. Here is an example of a result: Logistic model tree : LM_1:12/12 (453) // Number of Leaves : 1 Size of the Tree : 1 LM_1: Class 0 : 0.45 + [[cue_1]] * -72.14 + [[cue_2]] * -2.71 + [[cue_3]] * -3.88 + [[cue_4]] * 54.6 + [[cue_5]] * -12.28 + [[cue_12]] * -0.57 + [[cue_18]] * -7.24 Class 1 : -0.45 + [[cue_1]] * 72.14 + [[cue_2]] * 2.71 + [[cue_3]] * 3.88 + [[cue_4]] * -54.6 + [[cue_5]] * 12.28 + [[cue_12]] * 0.57 + [[cue_18]] * 7.24 In the leaf above, these are the cues that were taken into consideration from a list of 20. Thus, I suppose that these were the cues that had viable information, correct? From what I understand, each leaf is representative of a logistic regression model. In this sense, do the pluses and minuses that occur signify positive or negative weights toward that particular class? Does it signify the amount of weight that a particular cue (either positive or negative) provides toward classification toward one class or another? Any information regarding the topic would be extremely appreciated. Thank you, in advance, for any assistance you would be able to lend me.
