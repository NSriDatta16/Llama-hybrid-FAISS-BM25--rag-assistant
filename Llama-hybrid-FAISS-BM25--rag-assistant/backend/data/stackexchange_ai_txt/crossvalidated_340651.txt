[site]: crossvalidated
[post_id]: 340651
[parent_id]: 
[tags]: 
How does backpropagation work in the case of reinforcement learning for games?

If we want a neural network to learn how to recognize e.g. digits, the backpropagation procedure is as follows: Let the NN look at an image of a digit, and output its probabilities on the different digits. Calculate the gradient of the loss function w.r.t. the parameters, and adjust the parameters. But now let's say we want the NN to learn how to play Pong . Then the situation is different: We can't really split the game up in "cycles", as we can for recognizing digits. Success in Pong is defined by (a) hitting the ball, and (b) getting the ball into the opponent's wall. But whether this succeeds depends on a succession of choices. Let's say that at time $t$, the NN manages to hit the ball. This was only possible because he made the right decisions at time $t-k, t-k+1, ..., t$, not just at time $t$. So how does the backpropagation procedure take this complex sequence of decisions into account when changing the parameters?
