[site]: crossvalidated
[post_id]: 303048
[parent_id]: 302840
[tags]: 
For a Bayesian approach, you're asking for something like $$ p(A | y') $$ where $y'$ is the new data and $A$ is the hypothesis that the data are generated by process A. Bayes' theorem gives us $$ p(A | y') \propto p(y' | A) \cdot p(A), $$ the likelihood of $A$ times the prior on $A$. The likelihood can also be understood as the probability that process A would produce data (that look like) $y'$. So that suggests either (a) running process A repeatedly, generating 500-1000 data sets that can be compared to $y'$, or (b) assuming your fitted model is correct and using it to computational generate 500-1000 simulated datasets that can then be compared to $y'$. Option (b) involves a substantial assumption, but is somewhat in the spirit of a posterior predictive check .
