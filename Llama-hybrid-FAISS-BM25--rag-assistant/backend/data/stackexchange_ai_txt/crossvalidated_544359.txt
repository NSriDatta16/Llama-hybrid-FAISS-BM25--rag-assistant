[site]: crossvalidated
[post_id]: 544359
[parent_id]: 544356
[tags]: 
After feature engineering (be it manual or deep learned), syntactically different images of conceptually the same digit may end up encoded with identical feature vectors. In the spirit of data balancing, since some techniques may randomly duplicate the minority classes while others may fiddle with their vectors to synthesize new data-points, is it wrong then to de-duplicate these vectors as well? Yes, it's wrong. Consider an extreme case, prediction from a model is also a kind of representation. Would you say that it is ok, to de-duplicate the binary classification data into two samples after making hard predictions because the data got represented into two categories? Obviously not. Consider an example, say that you have a written digit recognition data, something like MNIST. You gathered samples written by 500 people for each of the digits. Would it be ok to leave only the digits written by a single person "because they conceptually represent same digits"? Obviously not. You want to have the data written by different people because while they all wrote the same digits, you want your algorithm to be able to recognize the small differences in the writing styles. On the opposite, you want to have a lot of samples from each of the categories representing the same thing, to learn the natural variability. Without this data, your algorithm would easily overfit to the training samples and would not be able to deal with real-life data.
