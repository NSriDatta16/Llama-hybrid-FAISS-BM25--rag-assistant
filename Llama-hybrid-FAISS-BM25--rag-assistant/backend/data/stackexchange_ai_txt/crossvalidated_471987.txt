[site]: crossvalidated
[post_id]: 471987
[parent_id]: 471448
[tags]: 
There are ways to use linear regressions to model survival, but they aren't what you seem to be expecting from the way your question is worded, and they aren't as generally reliable as maximum (partial) likelihood methods. First, there is no single " $h_0(t)$ for human beings" that applies in all situations. This page shows a plot of hazard of death as a function of age from birth to age 100 for the US in 2003. But this hazard necessarily represents an average over the population, which would be hard to translate to a hazard function representing the baseline covariate values for your study. Furthermore, many applications of survival analysis don't cover the entire lifespan. For example, survival studies of adult cancer patients would be restricted to the latter parts of the age range. You want to have a baseline $h_0(t)$ that is as specific as possible to the population of interest, estimated from your sample of the population. For example, comparing different cancer treatments would use hazard functions for patients with that particular type of cancer, not hazards for the general population. Second, the hazard function $h(t)$ is the instantaneous hazard: the risk of an event given that you haven't yet had an event . So at any time $T$ you have to consider the entire history of $h(t)$ up to that time, the cumulative hazard, to get the probability of having already survived that long. So the simple OLS approach you seem to be proposing wouldn't work. If you have observed all cases having the same set of covariate values until they have events, there are ways to use linear regression to estimate survival characteristics if you assume a functional form for the hazard. You put the cases in order of event times, providing empirical estimates of the quantiles that they represent of the cumulative hazard. You then use the assumed functional form of the cumulative hazard to find a linearizing transformation of the quantile distribution over time, plot the quantiles and corresponding event times for all cases according to that linearization, and estimate the distribution's parameter values for that set of cases from the slope and intercept of a linear fit to the (appropriately transformed) observed values. Before the age of readily accessible digital computers, this was a standard approach often based on an underlying Weibull distribution , a distribution that handles many situations with either continually increasing, constant, or continually decreasing hazards over time. If you have just a few groups (e.g., treatment and control), you could do separate plots for each group and compare the estimated distribution parameter values among the groups. You can still get graph papers for Weibull and other underlying distributions to generate these plots. But the usual assumptions of OLS aren't likely to be met with these linearizations, so you won't have reliable error estimates for the parameter values. If there are continuous covariates or multiple groups, this approach becomes unwieldy at best. Furthermore, if some cases haven't yet had events you need to take into account the censoring of event times for those cases: all you know is that they survived at least as long as you observed them. Chapter 8 of the NIST handbook provides examples of linearized plots for survival analysis, but the authors note that maximum likelihood methods are highly preferable when you have an underlying functional hazard form in mind. Cox regression uses maximum partial likelihood to estimate both the entire non-parametric baseline hazard and the relative hazards associated with the covariates.
