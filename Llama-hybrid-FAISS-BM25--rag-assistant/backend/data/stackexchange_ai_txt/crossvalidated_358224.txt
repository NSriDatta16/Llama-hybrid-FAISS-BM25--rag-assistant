[site]: crossvalidated
[post_id]: 358224
[parent_id]: 185134
[tags]: 
As dontloo mentions, an autoencoder can be used to initialize weights for a CNN and thus act as an additional layer before the CNN. In particular, the the hierarchical nature of a stacked autoencoder allows us to encode different types of (progressively more complex) features in each hidden layer, similarly to CNNs. Stanford's UFLDL has a great explanation of this: The first layer of a stacked autoencoder tends to learn first-order features in the raw input (such as edges in an image). The second layer of a stacked autoencoder tends to learn second-order features corresponding to patterns in the appearance of first-order features (e.g., in terms of what edges tend to occur together--for example, to form contour or corner detectors). Higher layers of the stacked autoencoder tend to learn even higher-order features.
