[site]: crossvalidated
[post_id]: 519255
[parent_id]: 519219
[tags]: 
tl;dr: Because it's 1) not possible and 2) not necessary. Long answer: Your question is posed from a statistical perspective, where testing the parameters is a standard thing to do. This makes it sound as if the way Machine Learning does it is in need of justification. But we can equally well pose the question in the opposite direction: "Why are parameters being tested in statistics?" The answer differs slightly, depending whether you're into inferential or predictive modelling. If you are doing inference, you want to know ( understand! ) which parameters are relevant to the output. If you're doing prediction, you want to avoid overfitting, and eliminating superfluous parameters helps with that. However, tests make assumptions regarding the probability distribution behind the parameters, and these assumptions may be more or less hard to justify. AIC (and BIC, too) also make assumptions. Your test and parameter elimination strategies work only as good as your assumptions are satisfied. Machine Learning is not an inferential toolbox. It was, from the beginning, meant to generate automated systems ("machines") which can make decisions ("predictions") without human intervention. Interpretability was never an issue, and this allows the models to be of arbitrary complexity (up to, but not necessarily, billions of parameters, as mentioned in a comment). So, the information which parameters are relevant ("significant") would be only relevant to ensure generalisation. However, machine learning makes much weaker assumptions about the data and, as a rule, we know (almost) nothing about the underlying probability distributions. This makes reasonable statistical tests next to impossible. Instead, generalisation in machine learning is ensured by cross validation and testing on a separate (test) data set. But, in order for that to work half-way reliably, you need much more data then for statistical modelling.
