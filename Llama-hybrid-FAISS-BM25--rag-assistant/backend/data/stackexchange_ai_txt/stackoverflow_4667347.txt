[site]: stackoverflow
[post_id]: 4667347
[parent_id]: 2409899
[tags]: 
There are many ways to detect the crawls but its difficult when we need to differentiate between good crawlers and bad ones. But there is a way to do this. Its actually you have to use the hidden link on your website this will detect the all crawlers and for good crawlers on the bases of user agent dont let them read the hidden links. This will help you lots not 100% but more then 70%. I have tried it.
