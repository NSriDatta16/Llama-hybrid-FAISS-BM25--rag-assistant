[site]: crossvalidated
[post_id]: 17128
[parent_id]: 17119
[tags]: 
I'll give an example of how "lift" is useful... Imagine you are running a direct mail campaign where you mail customers an offer in the hopes they respond. Historical data shows that when you mail your customer base completely at random about 8% of them respond to the mailing (i.e. they come in and shop with the offer). So, if you mail 1,000 customers you can expect 80 responders. Now, you decide to fit a logistic regression model to your historical data to find patterns that are predictive of whether a customer is likely to respond to a mailing. Using the logistic regression model each customer is assigned a probability of responding and you can assess the accuracy because you know whether they actually responded. Once each customer is assigned their probability, you rank them from highest to lowest scoring customer. Then you could generate some "lift" graphics like these: Ignore the top chart for now. The bottom chart is saying that after we sort the customers based on their probability of responding (high to low), and then break them up into ten equal bins, the response rate in bin #1 (the top 10% of customers) is 29% vs 8% of random customers, for a lift of 29/8 = 3.63. By the time we get to scored customers in the 4th bin, we have captured so many the previous three that the response rate is lower than what we would expect mailing people at random. Looking at the top chart now, what this says is that if we use the probability scores on customers we can get 60% of the total responders we'd get mailing randomly by only mailing the top 30% of scored customers. That is, using the model we can get 60% of the expected profit for 30% of the mail cost by only mailing the top 30% of scored customers, and this is what lift really refers to.
