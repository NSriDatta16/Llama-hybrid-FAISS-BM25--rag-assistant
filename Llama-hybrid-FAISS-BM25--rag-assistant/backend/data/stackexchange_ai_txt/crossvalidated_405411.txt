[site]: crossvalidated
[post_id]: 405411
[parent_id]: 
[tags]: 
Techniques to apply Discrete Wavelet Transform (DWT) to denoise and predict time series

I just started playing with wavelets and have been using this library ( https://github.com/rafat/wavelib ) to further my understanding and see if 'denoising' the series at all possible levels is beneficial for predicting the next data point. I've been playing with DWT and MODWT (the time series length does not need to be a power of 2), but I'm having a hard time reconciling how to properly apply the 'denoised' time series for training and prediction. So the question is basically, "What is the proper way to apply DWT to a time series with respect to creating training and testing sets for future prediction". I'd like the following for inputs and outputs to a Random Forest: Inputs: (1) 1-period log return of 'denoised' time series (2) 1-period log return of 'noise' in the time series (original series - denoised series = noise) Output/target: 1-period log return of original time series - which will be categorical value 1 or 0 (positive or negative) Now, I noticed with the wavelet transform that the length of the time series selected affects the 'denoised' final values. Furthermore, future values can 'leak' into the training data depending on the wavelet type being used (i.e. db4 --> daubechies with 4 vanishing moments). SO basically, I'm unsure if I should do one of the following scenarios for training and testing (we will focus on just the denoised series): Original time series to break into training and testing --> TS = { 1, 2, 4, 2, 8, 6, 5, 0, 1, 2 ... } (A) (1) Wavelet transform the entire series to get a new denoised series TS' [...] (2) Train on first 80% of values TS' { n0, n1, n2, n3, n4, n5, n6, n7, ... } (3) Test on last 20% of values TS' { n-1, n } I'm worried about certain wavelets including future values into the train set (i.e. daubechies db4), but I believe something like the Haar wavelet does not. (B) (1) Wavelet transform first 80% of TS into TS' as train set (2) Wavelet transform last 20% of TS into TS'' as test set (3) Train on TS' and predict TS'' Now, the denoised values will be different when compared to scenario (A) when I concat TS' and TS''. (C) Repeat for each future value we want to predict, one-by-one, up to desired count: (1) Create a sliding window of size N to perform a wavelet transform to get a denoised series for training (2) Predict next value N + 1 (2) Validate predicted value from above at N + 1 by either: create a new denoised series of size N + 1 (original N window size + one more value) or create a new denoised series of size N that is shifted in time by 1 instead, where the last value is the one to compare against our prediction ^ both of these create different denoised values and ultimately the Random Forest trains on certain denoised values from a wavelet transform. When I see that the denoised series is changed by simply incorporating the next subsequent value I get worried. Hopefully there is some good insight on how to proceed. I'm reading many research papers, but am struggling because the verbiage/phrases are different and I feel like some of the research papers are 'cheating' from what I can observe in the sense of leaking future values into the training set. I wish I could find papers that discuss how the wavelet transform is different as you expand the series length or shift it, and how that relates to training, but I can't find anything. thanks. EDIT: adding concrete example below Concrete example of scenario (C) above with wavelib and some helper fuctions I wrote below. struct DenoisedWavelet final { const vector DenoisedSignal; const vector Noise; DenoisedWavelet(const double* signal, const double* denoisedSignal, size_t signalSize) : DenoisedSignal(CreateDenoisedSignal(denoisedSignal, signalSize)), Noise(CreateNoise(signal, denoisedSignal, signalSize)) { } private: vector CreateDenoisedSignal(const double* denoisedSignal, size_t signalSize) const { vector denoised; for (size_t i = 0; i CreateNoise(const double* signal, const double* denoisedSignal, size_t signalSize) const { vector noise; for (size_t i = 0; i & signal, const char* wname, const char* thresh, int iterations) { double* sig; double* inp; double* oup; int N = signal.size(); // yes, yes, int vs size_t... will fix later denoise_object obj; sig = (double*)malloc(sizeof(double)* N); inp = (double*)malloc(sizeof(double)* N); oup = (double*)malloc(sizeof(double)* N); for (size_t i = 0, i { 278.62, 280.07, 282.38, 282.38, 281.84, 282.21, 282.66, 284.36 }, "haar", "hard", 3); auto modwt2 = MaximalOverlapDiscreteWaveletTransform(vector { 278.62, 280.07, 282.38, 282.38, 281.84, 282.21, 282.66, 284.36, 283.50 }, "haar", "hard", 3); auto modwt3 = MaximalOverlapDiscreteWaveletTransform(vector { 278.62, 280.07, 282.38, 282.38, 281.84, 282.21, 282.66, 284.36, 283.50, 285.18 }, "haar", "hard", 3); //modwt1.DenoisedSignal --> { 284.00875000000002, 282.57375000000002, 282.05312500000002, 282.05312500000002, 281.95625000000001, 281.95625000000001, 280.67687500000005, 279.24187500000005 } //modwt2.DenoisedSignal --> { 283.96375000000000, 282.87625000000003, 282.27656250000007, 282.26953125000000, 282.11875000000003, 281.74406250000004, 281.74406250000004, 281.13484375000007, 279.89218750000003 } //modwt3.DenoisedSignal --> { 284.82578125000003, 283.24921875000001, 282.59890624999997, 282.55218750000000, 282.31437500000004, 282.30421875000002, 282.50328124999999, 282.47562499999998, 280.99765624999998, 279.37874999999997 } As you can see, the values at time index T are different for modwt1/2/3 as I expand the window to get the last denoised value to predict the next categorical output value of 1 or 0. Same occurs if you slide the window with time and keep it size N. We trained the Random Forest with modwt1, we create modwt2 and use the last value as an input into the Random forest to predict our categorical output value 1 or 0. BUT the series has changed in modwt2... is this valid for prediction? And so on training with modwt2 and using last value of modwt3 to predict the next subsequent categorical output value.
