[site]: crossvalidated
[post_id]: 97007
[parent_id]: 
[tags]: 
What does Language Model look like?

I am working on a machine learning + NLP project. The corpora is from a very specific domain . Someone tells me I need a language model for that specific domain. So I decide to build one myself since there's none yet. My questions are: What does a language model look like? Is it in the form of a bunch of n-gram words and probabilities? Maybe like this? term 1, probability 1 term 2, probability 2 term 3, probability 3 term 4, probability 4 ... How to obtain a language model? Should I get a corpus of the domain and just summarize the term frequencies? How to use the language model? Suppose I get a new document for the domain, and I want to vectorize the document, should I directly assign probabilities from the language model to the terms in the document? and generate. If so, the same terms from different documents will have identical probabilities.
