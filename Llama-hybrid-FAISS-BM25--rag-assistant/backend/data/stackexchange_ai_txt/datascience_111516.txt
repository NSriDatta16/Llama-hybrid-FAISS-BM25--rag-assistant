[site]: datascience
[post_id]: 111516
[parent_id]: 111514
[tags]: 
Yes, it is actually that simple :) The ROC curve is made of all the points obtained by varying the classification threshold on the predicted score (usually a probability) above which instances gets predicted as positive. Increasing the thresholds causes less instances to be predicted as positive (higher precision, lower recall) and decreasing it causes the opposite. Usually this is done by iterating across the unique predicted probabilities, calculating the performance (typically precision or recall) corresponding to using this value as threshold, and selecting the desired level of performance: [edit: added detail below] Take the unique values among all the probabilities for the instances in the test/validation set, then sort them Then for each value considered as the threshold, calculate the performance on the full test/validation set. pick the threshold which matches the required precision/recall Actually a slightly more efficient version is to count the TP/FP/FN/TN instances directly on the instances sorted by probability, similarly to the short example in this answer . Note: this is not specific to logistic regression, it applies to any binary classifier which provides scores/probabilities.
