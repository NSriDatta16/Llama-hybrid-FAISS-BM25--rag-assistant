[site]: datascience
[post_id]: 78222
[parent_id]: 
[tags]: 
How can I easily retrieve the latent space encodings in tensorflow?

Here is where I'm at. I built and trained an autoencoder in tensorflow. The model summary looks like so: Model: "model_3" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_3 (InputLayer) [(None, None, None, 3)] 0 _________________________________________________________________ conv2d_4 (Conv2D) (None, None, None, 4) 112 _________________________________________________________________ conv2d_5 (Conv2D) (None, None, None, 16) 592 _________________________________________________________________ dense_5 (Dense) (None, None, None, 32) 544 _________________________________________________________________ dense_6 (Dense) (None, None, None, 8) 264 _________________________________________________________________ dense_7 (Dense) (None, None, None, 32) 288 _________________________________________________________________ conv2d_transpose_2 (Conv2DTr (None, None, None, 16) 4624 _________________________________________________________________ conv2d_transpose_3 (Conv2DTr (None, None, None, 3) 435 ================================================================= Total params: 6,859 Trainable params: 6,859 Non-trainable params: 0 _________________________________________________________________ The layer 'dense_6' is my latent space. Now, I am passing through a (256,256,3) image into the encoder part and am getting out (1, 252, 252, 8) tensor. Obviously, the output shape is listed as (None, None, None, 8), so it makes sense that I am getting this tensor out, but I was expecting to get just an 8-dimensional vector out. Did I design my autoencoder wrong maybe? I'm quite confused and could definitely use some clarification. Thanks!
