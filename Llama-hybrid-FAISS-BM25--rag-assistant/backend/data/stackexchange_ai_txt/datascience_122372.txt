[site]: datascience
[post_id]: 122372
[parent_id]: 29067
[tags]: 
XGBoost's defaults are pretty good. I'd suggest trying a few extremes (increase the number of iterations by alot, for example) to see if it makes much of a difference. If you do see big changes (for me it was only ~2% so I stopped) then try gridsearch. XGboost trains very quickly. Tree classifiers like this are great in that normalization isn't needed. I like the feature_score tracking you can do (not sure how in python, check the docs) if you want to see which of your features is contributing most to the result. This is especially useful if some metrics are expensive to compute, so you can see what to bother with, but can also be useful in a business sense (e.g. maybe how long they've been a customer or time since last sale doesn't contribute at all).
