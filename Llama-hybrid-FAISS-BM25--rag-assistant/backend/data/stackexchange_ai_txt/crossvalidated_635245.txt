[site]: crossvalidated
[post_id]: 635245
[parent_id]: 
[tags]: 
Fine-tuning naive bayesian model for text classification (multi-categorical outcomes)

I have a dataset of thousands of reddit posts on economic issues in the U.S. We selected a random sample of 40% of total posts where each post contained a "Blame" indicator with three possible values "Republicans", "Dems", the "Federal Reserve," or "Neither" which captures who is being blamed in each in a given post. My goal is to use the 40% of human-annotated posts to predict the value for the "Blame" variable in the remaining 60% of posts in my dataset. I have seen research papers that use a Naive bayesian model to predict a categorical variable, but the results in my case were not impressive. Specifically, the classifier performed well in predicting class 1 with an 81% precision rate, but performed poorly with other classes. Here is my code: #Loading packages library(tidyverse) require(readxl) require(writexl) library(quanteda) library(quanteda.textmodels) library(caret) #data example: dput(reddit_corpus[1:5,c(1,2,3,4,8)]) output: structure(list(id = c(1933, 7161, 4661, 2885, 5102), username = c("the_dog", "Empyrean Cobalt", "Engineeer", "AuraKUPO", "kyo_465"), post = c("Think jhk AT Pinoy etc all should be grateful to cecas for taking the heat off them", "Scamdetector said I hope you all realised that UOB actually didnt answer Clement question Click to expand UOB is just using the same template to reply like robotic mode", "netzach said this Daniels guy Click to expand I think people are not understanding WP and Daniel Goh in their entirely", "TS is still a student Companies must pay FT CPF in cash instead Only sinkies need to pay CPF a cut of their pay", "ponpokku said at least they dun downgrade like CECA pose no threats to locals CECA ish u have to double work to kio their sai Click to expand I dun want to hire people who tell me there are those who are worse than them" ), date = c("2021-07-13 00:00:00 UTC", "2020-09-22 00:00:00 UTC", "2021-08-07 00:00:00 UTC", "2021-04-07 00:00:00 UTC", "2021-07-23 00:00:00 UTC" ), collective_action = c(0, 0, 0, 0, 0)), row.names = c(NA, -5L ), class = c("tbl_df", "tbl", "data.frame")) #Building the model: #Generating 1109 numbers (38% of 2913) without replacement set.seed(300) id_train #Inspecting how well the classifier worked actual_class results predicted_class actual_class 1 2 3 4 1 240 6 5 45 2 67 2 1 7 3 79 0 10 15 4 128 6 5 75 #Confusion matrix confusionMatrix(tab_class, mode = "everything", positive = "pos") output: Overall Statistics Accuracy : 0.4732 95% CI : (0.4355, 0.5112) Class: 1 Class: 2 Class: 3 Class: 4 Sensitivity 0.4669 0.142857 0.47619 0.5282 Specificity 0.6836 0.889217 0.85970 0.7468 Pos Pred Value 0.8108 0.025974 0.09615 0.3505 Neg Pred Value 0.3063 0.980456 0.98126 0.8595 Precision 0.8108 0.025974 0.09615 0.3505 Recall 0.4669 0.142857 0.47619 0.5282 F1 0.5926 0.043956 0.16000 0.4213 Prevalence 0.7438 0.020260 0.03039 0.2055 Detection Rate 0.3473 0.002894 0.01447 0.1085 Detection Prevalence 0.4284 0.111433 0.15051 0.3097 Balanced Accuracy 0.5753 0.516037 0.66795 0.6375 ```
