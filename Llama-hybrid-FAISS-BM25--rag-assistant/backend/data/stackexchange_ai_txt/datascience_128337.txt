[site]: datascience
[post_id]: 128337
[parent_id]: 
[tags]: 
ML Methods For Modelling Latent Variables

I have some time series predictor variables, $\{\mathbf{X}_t\} = \{\mathbf{X}_0, \ldots, \mathbf{X}_n\}$ , and some other time series data $\{\mathbf{Z}_t\} = \{\mathbf{Z}_0, \ldots, \mathbf{Z}_n\}$ . The goal is to estimate some latent variables $\mathbf{Y}$ , as functions of $\mathbf{X}_t$ . So for e.g. the model's I want to train are: $$ Y_1 = f_1(\mathbf{X}), \; Y_2 = f_2(\mathbf{X}) $$ However I don't have any true values for what $Y_1$ or $Y_2$ should be. I do have true values for $g(\mathbf{Y}, \mathbf{Z})$ . How can I go about setting up my model for training? I had some ideas using PyTorch, where we can fairly easily set this up in the forward pass (PyTorch Lightning syntax): class MyModule(nn.Module): def __init__(self): super().__init__() self.f_1 = ... self.f_2 = ... def forward(self, X, Z, target): y_1_pred = self.f_1(X) y_2_pred = self.f_2(X) g_pred = y_1_pred * Z[:, 0] + y_2_pred * Z[:, 1] return g_pred class MyModel(L.LightningModule): def __init__(self): super().__init__() self.my_model = MyModule() def forward(self, inputs, target): return self.my_model(inputs, target) def training_step(self, batch, batch_idx) inputs_X_Z, target_g = batch output_g = self.my_model(inputs_X_Z, target_g) criterion = torch.nn.MSELoss() loss = criterion(output_g, target_g) return loss Are there any other alternative ways/methods? I want to fit several models with low complexity, and deep learning architectures are probably not applicable for my data. I believe that a simple linear regression model could be done with this by setting up my NNs with no hidden layer, but I would like to explore other options too.
