[site]: crossvalidated
[post_id]: 393916
[parent_id]: 393479
[tags]: 
I have been dealing with very similar problem recently, the two differences were that the descriptions were shorter and training set was larger. We tried several approaches, including random forest, recurrent neural network, and cutoffs by TF-IDF -like weights. If you are recognizing products, then I guess that among those 250k samples, you have thousands of products, so samples to products ratio can be quite small (less then thousands of descriptions per product). This means that your training set can be too small for for neural network. To use classification (random forest, XGBoost, or something else), you would first need to come up with reasonable features. Your target variable would be binary, for each word in description if it is a part of product name, or not. As about features, you can consider things like length of the word (in characters), if it is a number or not, if it is a brand name, same features for preceding and following words. In our case we decided to remove special characters and split strings like "dx-9078gl" to three words ("dx", "9078", "gl"). So in the end, given the features of word and neighborhood words you make a binary decision about a word if you include it, or not. If you wanted to use neural networks, you can transform data in similar fashion as above, but may need less feature engineering, use embeddings with recurrent networks, and/or attention. In my case, heavy regularization was crucial so that network does not overfit to some strange patterns in product descriptions. Another possibility is to simply weight words using TF-IDF and take the words with highest weights, with empirical cutoff (take the proportion of "accepted" words among all words, then use appropriate quantile from distribution of TF-IDF scores). In our case, the descriptions were short, so we used similar score inspired by work of Mika Timonen , where words from the end of the description were downweighted and with several additional tweaks, but this may, or may not apply to your problem. In the end, we decided to use TF-IDF-like scores, because they were cheap and easy to implement, while all the approaches had very similar performance. The performance could probably be better, but there were problems with sample size (still considerably larger then yours) and quality of the data (probably similar to yours, e.g. esoteric names, as in your examples).
