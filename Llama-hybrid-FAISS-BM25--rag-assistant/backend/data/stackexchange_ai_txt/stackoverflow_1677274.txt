[site]: stackoverflow
[post_id]: 1677274
[parent_id]: 1673729
[tags]: 
Rather than focusing on the code, how about the method. Building a little on what swillden said... If your lists are consumed by human users, you could ask them to correct you when you make a mistake (this correction is visible either to the person entering the text or to a later user viewing the text). If a given input looks a lot like a list but not enough to be sure, you show them the list and the raw input and ask them to choose. To automatically categorise inputs as lists or as text you could create several metrics to base your decision on : Given the separators (i.e [' ', '\t', ',', '.', 'and'] ) how many does this phrase use? expect one or two. Which ones? Is the input composed of fragments (use some sort of grammar system) - fragments tend to indicate lists. Does this input field (or context in your input) tend to have list items The words in the list itself (some words might turn out to always mean a sentence or a list in your domain) You then pass this information into a Bayesian filter and train it using your user's suggestions. Most of the items I mention would boil into special "keywords" that you tag an item with before you pass it into the filter. If the filter has a clear answer either way, treat it as a list or string. If the filter is uncertain, ask the user and use their answer to train the filter. Edit You could always train the system manually (i.e without exposing your system to the users) by first classifying lists using your existing scripts and then checking them by hand. Take a list of 500 inputs, run a filter looking for , or other easy lists and classify them as lists. Train the Bayesian filter on those (with everything else non-list) and then check the output by hand for all 500 for further training. Each day someone could receive an email with all the edge cases for that day and could clink links in the email to correct the system if necessary. As a side issue (relating to OP comment), in general Bayesian filters are much easier to implement, debug, test, analyse and scale than Neural networks.
