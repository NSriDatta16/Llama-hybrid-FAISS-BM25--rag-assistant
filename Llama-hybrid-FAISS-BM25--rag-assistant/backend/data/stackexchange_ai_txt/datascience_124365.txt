[site]: datascience
[post_id]: 124365
[parent_id]: 
[tags]: 
Validity of using raw time series data for training of xgboost/random forest classifier

I am currently working on a project aiming of classification of process states based on time series data. For this, we are looking at different models, such as XGBoost-based classifiers or RandomForest-based classifiers. I am aware of that both models are expecting tabularized data. Now, however, I am faced with two different points of view: Cutting the raw data into shorter windows, and treat them as "tabularized" data before feeding it into the training algorithm, resulting in Time block Series data 1 [0.5, 0.6, 0.7, 0.8, 0.9] 2 [1.0, 1.1, 1.2, 1.3, 1.4] 3 [1.5, 1.6, 1.7, 1.8, 1.9] 4 [2.0, 2.1, 2.2, 2.3, 2.4] 5 [2.5, 2.6, 2.7, 2.8, 2.9] 6 [3.0, 3.1, 3.2, 3.3, 3.4] from a time series of [0.5, ..., 3.4] Cutting the data into shorter windows, followed by feature extraction (such as mean(), abs(mean()), skewness() or similar data) from these windows. This then can be used for generating a table, such as Time block mean() median() 1 0.7 0.7 2 1.2 1.2 3 1.7 1.7 4 2.2 2.2 5 2.7 2.7 6 3.2 3.2 from the same time series as given above, which then is used for training the classifier. An argument for the first approach is that it is the simpler and easier approach, especially as one does not have to calculate all features. Another point of view I've seen is that the first approach should not work at all, but up to now without specific proof. Thus, which of those sides are correct? Is it possible at all to use the first approach, or will it get wrong/incorrect/inaccurate results? And which resources could I use to check that?
