[site]: crossvalidated
[post_id]: 584289
[parent_id]: 232741
[tags]: 
This correction term isn't really about de-biasing the exponentially-weighted moving average filter, it is just that the optimum EWMA filter should have a transient component -- this is well known within signal processing: see, e.g., Sophocles J. Orfanidis, Applied Optimum Signal Processing , ch 6 . Consider the following (convex) optimization problem, parameterized by $t$ , which attempts to find $\mu(t)$ to minimize the exponentially weighted sum of squared errors: \begin{equation*} \underset{\mu \in \mathbb{R}}{\text{minimize}} \quad \frac{1}{2}\sum_{\tau = 0}^{t - 1} \lambda^{t - \tau - 1} \bigl(x(t - \tau) - \mu\bigr)^2. \end{equation*} Differentiating the objective w.r.t. $\mu$ we get the optimum filter: \begin{align*} \sum_{\tau = 0}^{t - 1} \lambda^{t - \tau - 1} x(t - \tau) &= \mu \sum_{\tau = 0}^{t - 1} \lambda^{t - \tau - 1}\\ \implies \mu(t) &= \frac{\sum_{\tau = 0}^{t - 1} \lambda^{t - \tau - 1} x(t - \tau)}{\sum_{\tau = 0}^{t - 1} \lambda^{t - \tau - 1}}\\ \implies \mu(t) &\overset{(a)}= \frac{1 - \lambda}{1 - \lambda^{t}}\sum_{\tau = 0}^{t - 1} \lambda^{t - \tau - 1} x(t - \tau), \end{align*} where $(a)$ follows by the formula for finite geometric sums. This is exactly the "de-biased" EWMA filter.
