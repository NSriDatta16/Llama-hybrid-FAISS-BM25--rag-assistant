[site]: crossvalidated
[post_id]: 635205
[parent_id]: 635201
[tags]: 
Usually, in most cases, practically speaking, the posterior distribution will be a bunch of normal distributions on each of the parameters. For example, suppose you have data for the height of men and women in some population. You will have 4 parameters, mean_men , mean_women , sigma_men , sigma_women . To keep things as simple as possible we will assume these 4 parameters are normally distributed. However, when using Bayesian inference, each of those 4 parameters will follow a posterior distribution. So we treat them as random variables and not as fixed unknown quantities. You use your data to fit a posterior distribution on each of those 4 parameters. In practice, you often use MCMC and if you have enough data then it is pretty common that each of the parameters themselves is normally distributed. Therefore, let us say, that you estimate from your MCMC simultion that mean_men is 70 inches but with a deviation of 3 inches. This means your prior will become $\mathbf{Normal}(70, 3^2)$ on the mean_men parameter only. Just be careful, sigma_men is a different parameter, so you should not use the number of 3 inches from before in its estimate. Rather the number here will follow from a different calculation.
