[site]: stackoverflow
[post_id]: 1818728
[parent_id]: 1818699
[tags]: 
While the Date object returns times in milliseconds, that's not actually the resolution of the timer behind it. As an example, the timer might tick over once every 10 ms. If your process only takes 3 ms, then most of the time you won't see a nonzero measurement (and sometimes you'll see 10 ms). The solution is to run your function many times, and time the whole thing. For example, run it a million times and divide the total time by 1000000 to get the average time of one run.
