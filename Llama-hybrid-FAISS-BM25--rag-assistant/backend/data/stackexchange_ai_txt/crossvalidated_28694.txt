[site]: crossvalidated
[post_id]: 28694
[parent_id]: 28665
[tags]: 
It is hard to answer your needs without more detail. In text analysis, word frequencies are replaced by tf*idf which stands for "term frequency times inverse document frequency". This is an empirical score that corrects for the occurrence of terms that are frequent in the corpus and thus do not discriminate documents. It is widely used to compare texts, in particular through the cosine similarity measure. In practice, you compute the frequency of the term in the document (tf) and multiply it by the log of the inverse fraction of documents containing the term (idf). The site of Python 's NLTK (natural language toolkit) contains an implementation of it, along with other tools and a good deal of explanations. That said, if what you really want is an estimator of the probability of occurrence of the word, I don't know if you can get better than the frequency. And if 0 count is an issue, you can use the the Bayesian estimator (k+1) / (n+1), where k and n are word count and text size respectively. Edit: for a great read about IDF, take a look at S. Robertson's paper Understanding Inverse Document Frequency
