[site]: crossvalidated
[post_id]: 597701
[parent_id]: 215616
[tags]: 
Just to add my two cents, the goodness of fit is how well your data fits the assumptions used to make the model. For example if you are fitting your data to a linear regression model, the goodness of fit answers the question does your data fit a linear regression model according to the assumptions used to create a linear regression model? If the answer is no, then you will certainly have problems with the statistical inference of the regression coefficients amongst other problems. The goodness of fit can be done by visualizing the data(looking the the QQ plots and various other plot for the normality assumptions ( for linear regression and even for logistic regression), or by performing goodness of fit test Hypothesis Testing Procedure _: the model fits the data vs _: the model does not fit the data Over here the test statistic is [1]: https://i.stack.imgur.com/L1wm0.png And the test statistic should follow a chi-squared distribution to pass the _. My recommendation is that the data or test data should pass the goodness of fit test before going on to the prediction or predictive power test. Otherwise you can get a model that doesn't fit your assumption that the model is based upon. This might be ok if you are NOT interested in the meaning of the coefficients of the model or you not interested in prediction out of the population of your dataset. The predictive power is how well can your model predict data it has not seen. Various matrices can be used to judge the predictive power 1.Mean squared prediction error (MSPE) 2.Mean absolute prediction errors (MAE) 3.Mean absolute percentage error (MAPE) 4.Precision error (PM) 5.Confidence Interval error (CIM) 6.You can even use R2 or adjusted R2 You can use on of these matrices to select one among many models. In summary the goodness of fit test makes sure the model you are using align with the assumptions used to generate that model. The predictive power is what it is: how well your model accounts for the variation of of the observations of errors in the data set. So you can get a model that doesn't pass the goodness of fit test, but does predict very well.
