[site]: crossvalidated
[post_id]: 169205
[parent_id]: 3931
[tags]: 
I think it's worth pointing out the connection to Bayesian estimation. Suppose you assume your data is Gaussian, and so you measure the mean $\mu$ and variance $\sigma^2$ of a sample of $n$ points. You want to draw conclusions about the population. The Bayesian approach would be to evaluate the posterior predictive distribution over the sample, which is a generalized Student's T distribution (the origin of the T-test). This distribution has mean $\mu$, and variance $$\sigma^2 \left(\frac{n+1}{n-1}\right),$$ which is even larger than the typical correction. (It has $2n$ degrees of freedom.) The generalized Student's T distribution has three parameters and makes use of all three of your statistics. If you decide to throw out some information, you can further approximate your data using a two-parameter normal distribution as described in your question. From a Bayesian standpoint, you can imagine that uncertainty in the hyperparameters of the model (distributions over the mean and variance) cause the variance of the posterior predictive to be greater than the population variance.
