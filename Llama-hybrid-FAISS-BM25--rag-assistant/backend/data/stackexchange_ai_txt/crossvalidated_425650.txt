[site]: crossvalidated
[post_id]: 425650
[parent_id]: 
[tags]: 
Analyzing a survey with branch logic

I'm interested in analyzing a survey with conditional/branching questions. All the questions are answered with Yes/No, but some some of the questions are follow-up questions after a main topic question is answered Yes. For example, if you answer Yes to Q5 you are shown follow-up questions Q5.1, Q5.2 and Q5.3, but if you answer No to Q5 you will never see the follow-up questions. The main questions are about different subject areas, and the follow-up questions are more specific inquiries about the same area. It may be that respondent answers Yes to a main question and No to all the follow-up questions. I would like to run a regression with a separate continuous dependent variable, but I'm unsure about how to treat the follow-up questions. There is a clear dependency between the main questions and the follow-up ones. Is there some model which is able to take this dependency into account? This question seems to be asking a similar question. But it is not exactly the same problem. It tried to follow the advice in the answer and treat the "unanswered" followup questions as missing values in a Bayesian linear regression model. But I did not get satisfactory results, and I do not think it is the correct approach since the values are not missing at random. Here is an example implementation of the model for one question in pymc3. The variables Q1_1, Q1_2, Q1_3, Q1_4 are pandas Series with "unanswered" questions marked with NaNs, Q1 is the main question and only contains ones and zeros (no missing values). import pandas as pd import pymc3 as pm with pm.Model() as model: # Impute follow-up questions p_Q1_1 = pm.Beta('p_Q1_1', 1., 1.) Q1_1_imp = pm.Bernoulli( 'Q1_1_imp', p_Q1_1, observed=Q1_1) p_Q1_2 = pm.Beta('p_Q1_2', 1., 1.) Q1_2_imp = pm.Bernoulli( 'Q1_2_imp', p_Q1_2, observed=Q1_2) p_Q1_3 = pm.Beta('p_Q1_3', 1., 1.) Q1_3_imp = pm.Bernoulli( 'Q1_3_imp', p_Q1_3, observed=Q1_3) p_Q1_4 = pm.Beta('p_Q1_4', 1., 1.) Q1_4_imp = pm.Bernoulli( 'Q1_4_imp', p_Q1_4, observed=Q1_4) sigma = pm.HalfCauchy('s', 5.) beta = pm.Normal('beta', mu=0., sd=100., shape=6) # Expected value mu = (beta[0] + beta[1]*Q1 + beta[2]*Q1_1_imp + beta[3]*Q1_2_imp + beta[4]*Q1_3_imp + beta[5]*Q1_4_imp) like = pm.Normal( 'like', mu=mu, sd=sigma, observed=y) with model: trace = pm.sample(1000, njobs=1) ```
