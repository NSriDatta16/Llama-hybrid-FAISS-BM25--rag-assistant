[site]: crossvalidated
[post_id]: 65260
[parent_id]: 65222
[tags]: 
Using o if you check the execution times of the following constraint optimization algorithms you'll find that nlminb is the fastest for your problem, L-BFGS-B being a close second. I would recommend using one of the two. I tried also some quadratic approximation procedures ( bobyqa ) but it was not fast enough for this. Given your problem it seems that a trust-region optimizer is best ( nlminb ). I don't know if you are able of getting analytical derivatives out. In such case I would assume that the quasi-Newton method ( L-BFGS-B ) would be even faster because now it needs to compute derivatives numerically. Run1 Also a word of advice: I see you give a hard limit for the execution time of your optimization routine("I really need to get it down to something more like 3 or 4 seconds"). Is that realistic? I mean on my old computer (Intel T7400 @ 2.16GHz) a single function evaluation usually takes 5 seconds. Undoubtedly you will need some number of function evaluations $n \geq$ 2 so don't give yourself task that just can't be done. (EDIT: I just tried the same checks on Intel i5-2500 CPU @ 3.30GHz; it was twice as fast, so on average 2.5 seconds. Nevertheless I hope you still see that this a 3-4 seconds target is almost prohibited by the computational complexity of your original function.) In general I would suggest you take a look at the CRAN Task View on Optimization to have a look at available packages. There is definitely a chance that some not so standard optimization routine is better for your task. Always though try to be realistic, unless you have an extremely strong CPU you won't be seeing any 3-4 seconds solutions any time soon. Reformulating your original function so it computes faster is probably your best bet for a faster optimization procedure because as your problem is just a 1-D and your function appears pretty smooth anyway, no sophisticated algorithm will give you a huge edge over what you already have now.
