[site]: crossvalidated
[post_id]: 107683
[parent_id]: 
[tags]: 
Simulating non-causal time series?

I'm looking into the possibility of using a non-causal time series filter for some data. The goal is filtering (for the purpose of anomaly detection). However, this is not particularly relevant. I'm wondering how simulation of such a time series would work? Say for example your time series model were: $$y_t = y_{t-1}+y_{t+1}+\eta_t$$ where $\eta$ corresponds to some standard random noise ($N(0,1)$ or something). My initial thoughts are to just simulate the random noise $\eta_t^*$ and then solve a linear system to get the $y_t$. However, this also sounds slow.. and I can't help but feel someone has probably already thought about this problem. So, what is the standard practice here?
