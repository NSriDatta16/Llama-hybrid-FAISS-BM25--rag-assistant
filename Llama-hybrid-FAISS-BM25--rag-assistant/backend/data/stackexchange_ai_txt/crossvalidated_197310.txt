[site]: crossvalidated
[post_id]: 197310
[parent_id]: 197296
[tags]: 
You should do an eigen value/vector decomposition of the covariance matrix (a.k.a diagonalization ) Let $\Sigma$ be the covariance matrix, then you can write; $$ \Sigma = PDP^{-1} $$ where $$D=\begin{bmatrix} \lambda_1&0&0\\ 0&\lambda_2&0\\ 0&0&\lambda_3 \end{bmatrix}\;\;\;\mathrm{and}\;\;\;P=[\mathbf{v}_1\;\mathbf{v}_2\;\mathbf{v}_3] $$ $\lambda_i$ and $\mathbf{v}_i$ are the $i^{th}$ corresponding Eigen value and Eigen vector of the covariance matrix. Since covariance matrices are positive semi-definite by design, the rank of the covariance matrix (and of $X$) is equal to the number of positive Eigen values. The rank determines the dimension of the subspace $\mathcal{S}$ in which the observations of $X$ exist. The Eigen vectors that corresponding to positive Eigen values define the subspace. Diagonalization can be done by hand for a 3 dimensional covariance matrix, but I do it in R below; > rm(list=ls()) > ?eigen > > M=cbind(c(1,1,0), + c(1,4,-3), + c(0,-3,3)) > > E=eigen(M) > print(E) $values [1] 6.645751 1.354249 0.000000 $vectors [,1] [,2] [,3] [1,] 0.1355099 0.8051731 -0.5773503 [2,] 0.7650553 0.2852315 0.5773503 [3,] -0.6295454 0.5199416 0.5773503 $values corresponds to the Eigen values and $vectors corresponds to the matrix $P$ (the values are normalized so that the vectors are of length one, but this makes no difference for your purposes). Notice that only two Eigen vectors are greater than zero. Thus you can define the subspace $\mathcal{S}$ as follows: For $$\mathbf{v}_1=\begin{pmatrix}{0.1355099 \\ 0.7650553 \\-0.6295454}\end{pmatrix} \;\;\mathrm{and}\;\; \mathbf{v}_2=\begin{pmatrix}{0.8051731 \\ 0.2852315 \\ 0.5199416}\end{pmatrix}$$ $\mathbf{w} \in \mathcal{S}$ if and only if there exists $a,b\in\mathbb{R}$ such that $\mathbf{w}=a\mathbf{v}_1 +b\mathbf{v}_2$. In other words, every element of $\mathcal{S}$ must be a linear combination of $\mathbf{v}_1$ and $\mathbf{v}_2$. It will then be true that $P(X \in \mathcal{S})=1$. For more information on this type of analysis, and intuition on why exactly this is the case, you should research Principal Component Analysis (PCA)
