[site]: crossvalidated
[post_id]: 581641
[parent_id]: 
[tags]: 
Can predicting negative regression values increase the chance of dying ReLUs?

Since ReLUs have zero gradient around negative values, we know that if a neuron outputs a negative value, the corresponding ReLU activation will cause it to die. Therefore, if I use a neural network to predict negative values, would that increase the likelihood of neurons in my network dying? I understand that having a linear output activation (with hidden ReLUs) will still allow me to output negative values, but I'd like to know about the hidden units.
