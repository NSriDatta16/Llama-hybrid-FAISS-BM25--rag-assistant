[site]: crossvalidated
[post_id]: 168906
[parent_id]: 168837
[tags]: 
Most posteriors prove to be difficult to optimize analytically (i.e. by taking a gradient and setting it equal to zero), and you'll need to resort to some numerical optimization algorithm to do MAP. As an aside: MCMC is unrelated to MAP. MAP - for maximum a posteriori - refers to finding a local maximum of something proportional to a posterior density and using the corresponding parameter values as estimates. It is defined as $$ \hat{\theta}_{MAP} = \text{argmax}_{\theta} \, p(\theta \, | \, D) $$ MCMC is typically used to approximate expectations over something proportional to a probability density. In the case of a posterior, that's $$ \hat{\theta}_{MCMC} = n^{-1} \sum_{i=1}^{n} \theta^{0}_{i} \approx \int_{\Theta}\theta \, p(\theta \, | \, D)d\theta $$ where $\{\theta^{0}_{i}\}^{n}_{i=1}$ is a collection of parameter space positions visited by a suitable Markov chain. In general, $\hat{\theta}_{MAP} \neq \hat{\theta}_{MCMC}$ in any meaningful sense. The crux is that MAP involves optimization , while MCMC is based around sampling .
