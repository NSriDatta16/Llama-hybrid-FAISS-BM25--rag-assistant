[site]: crossvalidated
[post_id]: 347164
[parent_id]: 
[tags]: 
When is weighted average of $F_1$ scores $\simeq$ accuracy in classification?

Example where accuracy $\simeq$ weighted average of $F_1$ scores I have a classifier which classifies between 2 classes, $\mathbf{A}$ and $\mathbf{B}$ . Say we have the confusion matrix below: Predicted A B -------- -------- A | 103 | 5 Actual -------- -------- B | 3 | 97 The support for class $\mathbf{A}$ is $103 + 5 = 108$ . The support for class $\mathbf{B}$ is $3 + 97 = 100$ . The total number of data instances is $108 + 100 = 208$ . The accuracy can be calculated as follows: $ \frac{103\,+\,97}{208} = 0.961538462. $ The precision for class $\mathbf{A}$ can be calculated as $\frac{103}{103\,+\,3} = \frac{103}{106}$ . Similarly, the precision for $\mathbf{B}$ is $\frac{97}{97\,+\,5} = \frac{97}{102}$ . The recall for $\mathbf{A}$ is $\frac{103}{103\,+\,5} = \frac{103}{108}$ . The recall for $\mathbf{B}$ is $\frac{97}{97\,+\,3} = \frac{97}{100}$ . The $F_1$ score for class $\mathbf{A}$ is the harmonic mean of its precision and recall: $\left(\frac{1}{2}(\frac{106}{103} + \frac{108}{103})\right)^{-1} = \frac{103}{107}$ . The $F_1$ score for class $\mathbf{B}$ is the harmonic mean of its precision and recall: $\left(\frac{1}{2}(\frac{102}{97} + \frac{100}{97})\right)^{-1} = \frac{97}{101}$ . Finally, the weighted average of the $F_1$ scores where the weights are the support values : $\frac{\frac{103}{107} \cdot 108 + \frac{97}{101} \cdot 100}{208} = \frac{135089}{140491} = 0.96154913837$ . This value is very close to the accuracy. In fact they are equal up to 4 decimal places. Classifier details The classifier in question was trained by splitting the labeled data into a training and test set randomly. The training set was used to train the classifier and then the performance was measured on the test set. This was repeated for different splits of the data into training and test sets. For every permutation, the accuracy and $F_1$ score are different but they are always close. They seem to fluctuate in the range $[0.9,0.97]$ , and they fluctuate together. Question What does the accuracy and weighted average of $F_1$ scores with the support values as weights being so similar imply in a classification over 2 classes? Are the values always similar or does this observation imply something about my data or classifier? If the values are not always so similar, in what scenarios would they be significantly different? Notes I have checked this question which has a somewhat similar title, but it’s unrelated to what I’m asking.
