[site]: crossvalidated
[post_id]: 412136
[parent_id]: 412135
[tags]: 
The main advice for dealing with it, usually is regularization. Is there other practical advice to avoid overfitting? I thought what you are actually asking is what is the relation between regularization and overfitting. The answer is that the strategies designed to reduce overfitting or test error are known collectively as regularization. So I thought the short answer to your question is an emphatic "no". And here are some regularization strategies listed in the Chapter 7 of the Deep Learning book : Parameter norm penalties Norm penalities as constrained optimization Dataset augmentation Noise robustness Semi-supervised learning Multi-task learning Early stopping Parameter tying and parameter sharing Sparse representation Bagging and other ensemble methods Dropout Adversarial training Tangent distance, tagent prop, and manifold tagent classifier
