[site]: crossvalidated
[post_id]: 264886
[parent_id]: 264811
[tags]: 
First the empirical proof to motivate the long explanation: We can get the answer with a one-line Monte Carlo simulation, corresponding to $1$ million trials, which in R would be made simple thanks to rle() and the suggestion in this answer : > set.seed(0) > mean(replicate(1e6, TRUE %in% (with(rle(sample(c(0,1),100,T)), lengths[values==1]) >= 7))) > [1] 0.317231 Now the closed, algebraic solution: I am going to assume lack of familiarity with Markov chains , and make it very easy to follow. The idea is that we go through $100$ steps, and at each transition, there is a given probability distribution for things to stay as they are or to change. Here by "things" I simply mean the number of consecutive heads ( $\text H$ 's). So we start tossing the coin and we have the following distribution of events: $$\small\begin{bmatrix}s_0=\text{T}&s_1=\text{H}_1\\1/2&1/2\end{bmatrix}$$ either tails or heads, and it is a fair coin... The key is to realize that if it was tails, we are back to were we began - let's call it state $0$ or $s_0.$ Otherwise, we are taking the first step towards building a sequence of $7$ consecutive heads, i.e. $s_1.$ We toss again. And this is now really critical to appreciate... If we had actually built up the beginning of a run (i.e. if we had a head in the first toss) we would be in the blue position right before the second toss: $$\small\begin{bmatrix}s_0&\color{blue}{s_1}\\1/2&\color{blue}{1/2}\end{bmatrix}$$ and we would have, naturally, a probability of $1/2$ to build up a longer run (a run of $2$ consecutive $\text{H}$ 's, or $s_2$ ) by simply getting another head, or we could go back to the beginning by getting a $\text{T}$ . We have no interest in runs that are less than $7$ as per your initial question. So we can either obtain a head and keep building up our sequence of $7$ heads, or go back to $s_0$ . If we are lucky we land in $s_2$ - a "cumulative" run of $2$ heads, which would look like this: $$\small\begin{bmatrix}\quad&s_0&\color{blue}{s_1}&\color{green}{s_2}\\\text{1st toss}&1/2&\color{blue}{1/2}&0\\\text{2nd toss} &1/2&0&\color{green}{1/2}\end{bmatrix}$$ Now we are either back to "square one" or $s_0$ , with nothing to account for, if a tail came up on the second toss, or we have advanced to $s_2$ , and each scenario has $1/2$ probabilities. Notice that there is no scenario in which we could find ourselves in $s_1$ : we either built up a sequence of two consecutive heads, i.e. $s_2=\{\text{H,H}\}$ if we got a head, or we are back to zero. Next round... $$\small \begin{bmatrix}\quad&s_0&\color{blue}{s_1}&\color{green}{s_2}&\color{red}{s_3}\\\text{1st toss}&1/2&\color{blue}{1/2}&0&0\\\text{2nd toss} &1/2&0&\color{green}{1/2}&0\\\text{3rd toss}&1/2&0&0&\color{red}{1/2}\end{bmatrix}$$ That's right... We either have a run of $3$ heads or we are back to zero. So we keep on going and we get... $$\small \begin{bmatrix}\quad&s_0&\color{blue}{s_1}&\color{green}{s_2}&\color{red}{s_3}&\cdots&\color{orange}{s_7}\\\text{1st toss}&1/2&\color{blue}{1/2}&0&0&\cdots&0\\\text{2nd toss} &1/2&0&\color{green}{1/2}&0&\cdots&0\\\text{3rd toss}&1/2&0&0&\color{red}{1/2}&\cdots&0\\\vdots&\vdots&\vdots&\vdots&\vdots&\cdots&\vdots\\ \text{7th toss}&1/2&0&0&0&\cdots&\color{orange}{1/2}\end{bmatrix}$$ But we are not done, because we are going to multiply this transition matrix $T$ over and over again $100$ times by itself - i.e. we are going to $T^{100}$ (more on this below). And we have to prevent that the ongoing probability tally of $s_7$ in the last column gets modified by itself. How do we do it? We add a row of all zeros except for a $1$ in the last entry as below. Why? Because it will consistently guarantee that the last column, which is what we really want (our "accounting column" or the probabilities of $s_7$ ), does not have any influence from one step to the next in the recalculation - only the columns to the left of $s_7$ will influence or contribute to updating $s_7$ at every pass: $$\small T=\begin{bmatrix}\quad&s_0&\color{blue}{s_1}&\color{green}{s_2}&\color{red}{s_3}&\cdots&\color{orange}{s_7}\\\text{1st toss}&1/2&\color{blue}{1/2}&0&0&\cdots&0\\\text{2nd toss} &1/2&0&\color{green}{1/2}&0&\cdots&0\\\text{3rd toss}&1/2&0&0&\color{red}{1/2}&\cdots&0\\\vdots&\vdots&\vdots&\vdots&\vdots&\cdots&\vdots\\ \text{7th toss}&1/2&0&0&0&\cdots&\color{orange}{1/2}\\\quad&0&0&0&0&\cdots&\color{purple}1\end{bmatrix}$$ This is the transition matrix or stochastic matrix , $T$ . Check absorbing states here . In multiplying this matrix times itself, you can observe that the last entry of each row will be multiplied by $0$ (except for the last row we just added), leaving the last, column $\color{orange}{s_7}$ completely nullified in the $[\text{row}]\cdot[\text{column}]$ dot product. Now for the home stretch... We have built this matrix as a story, with the implicit logic that we went from $s_1$ to $s_2$ as we transitioned from the one-element, $s_1$ , to the two-element run, $s_2$ (or went back to $s_0$ ) in the second toss with certain probabilities. However, we never considered the probability of transitioning to $s_1$ on the fourth toss, for example, which is going to depend on the probabilities of all possible prior states. The probability distribution at each point in time will depend on the prior distribution, explaining why we have to raise $T$ to the $100$ power. Let's hone down on one of these multiple dot products within the powers of $T$ : we focus on the evolution of probabilities in the first row and see that when we dot it with the third column in the process of calculating $T^2$ $$\small \begin{bmatrix}s_0&\color{blue}{s_1}&\color{green}{s_2}&\color{red}{s_3}&\cdots&\color{orange}{s_7}\\1/2&\underbrace{\;\color{blue}{1/2}\;}_{\text{step } t}&0&0&\cdots&0\\\end{bmatrix}\cdot\tiny\begin{bmatrix}\color{green}{s_2}\\0\\\text{step }t+1:\;\color{green}{1/2}\\0\\0\\0\\0\end{bmatrix}$$ we split (multiply by $\color{green}{1/2}$ ) the probability associated with a run in the immediate prior state ( $t=s_1$ ) (at this point $\color{blue}{1/2}$ ) to assign a probability to a run that is one element longer ( $t+1=s_2).$ We can find the final result after calculating $T^{100}$ in exactly this position: $$\small T^{100}=\begin{bmatrix}\quad&s_0&\color{blue}{s_1}&\color{green}{s_2}&\color{red}{s_3}&\cdots&\color{orange}{s_7}\\&&&&&&\bbox[5px,border:2px solid red]{\text{answer}}\\&&&&&&&\\&&&&&&&\\&\vdots&\vdots&\vdots&\vdots&\cdots&\vdots\\ &&&&&&&\\&0&0&0&0&\cdots&\color{purple}1\end{bmatrix}$$ after performing $T^{100}$ . Notice how in every calculation step, we dot the first row with each column, in what is really a bunch of and and or statements to calculate the probability of each state in the first row. This ends up being $\bbox[5px,border:2px solid red]{T^{100}[1,8]= 0.31752}$ . Calculated in R: require(expm) m= matrix(c( .5, .5,0,0,0,0,0,0, .5, 0, .5,0,0,0,0,0, .5, 0,0, .5,0,0,0,0, .5, 0,0,0, .5,0,0,0, .5, 0,0,0,0, .5,0,0, .5, 0,0,0,0,0, .5,0, .5, 0,0,0,0,0,0, .5, 0, 0,0,0,0,0,0, 1), nrow = 8, byrow=T) t(c(1,0,0,0,0,0,0,0)) %*% (m%^%100 %*% c(0,0,0,0,0,0,0,1))
