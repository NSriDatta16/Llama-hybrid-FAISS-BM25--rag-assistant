[site]: crossvalidated
[post_id]: 376451
[parent_id]: 376439
[tags]: 
Autoencoders take as input some data, say image, then encode it into some representation and decode it into same form as input. This is illustrated on the figure coming from this great tutorial on Keras blog . We are usually aiming at finding such representation that (a) leads to compression of original input (smaller dimensionality) and (b) returns outputs that are as close as possible to inputs. Those are also the two properties of "good" encodings. Autoencoders are trained by minimizing some kind of loss that measures how much does the reconstruction differs from the original image (e.g. mean squared error, logistic loss). The measure of disparency between the true and reconstructed data gives you direct measure of quality of the results. If you are working with images, you should always look at the predicted representations as a sanity check.
