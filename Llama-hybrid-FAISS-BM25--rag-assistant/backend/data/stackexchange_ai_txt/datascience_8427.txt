[site]: datascience
[post_id]: 8427
[parent_id]: 
[tags]: 
What is the best way to split a sentence for a keyword extraction task?

I'm doing a keyword extraction using TF-IDF on a large number of documents. Currently, I'm splitting each sentence based on n-gram. More particularly, I'm using trigrams. However, this is not the best way to split each sentence into ints constituting keywords. For example a noun phrase like 'triple heart bypass' may not always get detected as one term. The other alternative to chunk each sentence into its constituting elements look to be part of speech tagging and [chunking][1] in [Open NLP][2]. In this approach phrase like 'triple heart bypass' always gets extracted as a whole but the downside is in TF-IDF the frequency of extracted terms (phrases) dramatically drops. Does anyone have any suggestion on either or these two approaches or have any other ideas to improve the quality of the keywords?
