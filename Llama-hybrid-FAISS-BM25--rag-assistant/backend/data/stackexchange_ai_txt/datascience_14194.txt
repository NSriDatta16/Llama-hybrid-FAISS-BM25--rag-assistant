[site]: datascience
[post_id]: 14194
[parent_id]: 14187
[tags]: 
Hyperparameters and parameters are often used interchangeably but there is a difference between them. You can call something a 'hyperparameter' if it cannot be learned within the estimator directly. However, 'parameters' is a more general term. When you say 'passing the parameters to the model', it generally means a combination of hyperparameters along with some other parameters that are not directly related to your estimator but are required for your model. For example, suppose you are building a SVM classifier in sklearn: from sklearn import svm X = [[0, 0], [1, 1]] y = [0, 1] clf = svm.SVC(C =0.01, kernel ='rbf', random_state=33) clf.fit(X, y) In the above code an instance of SVM is your estimator for your model for which the hyperparameters, in this case, are C and kernel . But your model has another parameter which is not a hyperparameter and that is random_state .
