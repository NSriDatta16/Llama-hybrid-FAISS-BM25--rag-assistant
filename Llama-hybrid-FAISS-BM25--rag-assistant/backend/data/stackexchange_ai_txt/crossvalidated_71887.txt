[site]: crossvalidated
[post_id]: 71887
[parent_id]: 
[tags]: 
Understanding the information lost during PCA on classification

I am testing a self-implemented PCA on a set of image data ($N \times d$, $N = 10000$ sample size, $d = 28 \times 28$ feature size). When I observed the classification accuracy, I found the accuracy increase somehow with the increased target reduced dimension $k$ and decresed from then on. See the image below: The maximum accuracy corresponded to $PoV = 89\%$. I also tried reducing the data to $k = d$, the accuracy was still much lower than the maximum showed in the graph. Is these what is expected for PCA ? Or my classifier is not working? How can I interpret the "information lost" for different $k$ in PCA? ps: I even tried the "princomp' built-in function, it yield similar result. UPDATE: Sorry for not stating clearly. For both training set itself and a separate test set as test set, I got similar result as in the graph.
