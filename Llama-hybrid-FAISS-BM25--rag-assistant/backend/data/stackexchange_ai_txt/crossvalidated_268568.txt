[site]: crossvalidated
[post_id]: 268568
[parent_id]: 
[tags]: 
How to convert a Johnson normalized variable back to a marginal variable

Edit after @eric_kernfeld answer. I'd like to do Generate a time-series, for example, from a uniform distribution. Transform of non-normal variable to standard normal distribution. Fit an arima model to standard normal variable. Simulate from the arima model with the fitted parameters (in this case errors should be standard normal). Apply the back transformation that converts simulated arima output to marginal variable. On the steps 2 and 5 I'm going to use the Johnson transformation and the back Johnson transformation respectively. I have a time series and I'd like to do a simulation of log-returns using the normalization with Johnson distribution . library(JohnsonDistribution) library(moments) rm(list=ls(all=TRUE)) set.seed(1) n I have used the code and fitted my random data and log-returns were fitted with ARIMA(3,0,2) model. Then I applied some test to check the model quality. # Fitting ARMA model ArimaModelFit Then I simulated data with the ARIMA model #ARMA Simulation sim Finally, I'd like to back the fitted data to marginal variable. I have applied the Kolmogorov-Smirnov test and plotted Cumulative Distribution Functions (CDFs) of marginal ( log-returns ) and simulated ( y ) data to check the quality of 2, 3, 4, 5 step of simulation (normalization, arima, back transformation). # Applying inverse of Johnson transformation y The p-value of Kolmogorov-Smirnov test is 0.9283 and CDFs are close each to other. But according to the documentaion of the JohnsonDistribution package I should use the z JohnsonDistribution function instead of the y JohnsonDistribution function. Also I confused with sim series. In my case, sim is the normal distributed variable, but it is should be uniformly distributed on the unit interval [0, 1] . Questions. Am I correct in my steps? How to inverse correctly the Johnson normalized variable to a marginal variable? Should I use the qnorm() function? Edit 2. I have changed the library to do the direct/back Johnson transformation: Edit 3. library(Johnson) set.seed(1) n The p-value of Kolmogorov-Smirnov test is $0.97$ ks.test(log_mydata1, inv_jt_mydata1) # D = 0.043651, p-value = 0.97 # alternative hypothesis: two-sided and CDFs are close each to other:
