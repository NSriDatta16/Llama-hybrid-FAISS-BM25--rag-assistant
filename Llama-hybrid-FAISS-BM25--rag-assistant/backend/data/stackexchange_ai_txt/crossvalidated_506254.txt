[site]: crossvalidated
[post_id]: 506254
[parent_id]: 
[tags]: 
Lost in the introduction discussing probability/likelihood

I have some questions about the following paragraph which introduces a masters level course. In this unit we consider the Frequentist (i.e. counting) approach to statistical inference and computing the probability/likelihood of the data $y$ given the parameters $\theta$ , $P(y|\theta)$ . Under this approach we use Maximum Likelihood Estimation (MLE) to estimate the parameters of probabilistic/likelihood models, i.e. $\hat{\theta} = > arg max_{\theta}P(y|\theta)$ . If we are dealing with a known probability distribution of the data then we use $P(y|\theta)$ , but in general we are interested in the probability $P(y|x, u, \theta)$ where $u$ can be 'predictor' variables and $x=x(u,\theta)$ can be intermediate variables dependent on $u$ and $\theta$ . In this unit we primarily focus on the cases of $P(y|\theta)$ and $P(y|u=x, \theta)=P(y|x, \theta)$ . Q1) I understand that big P means a discrete distribution. Does this statement only apply to discrete distributions? Q2) Why is it talking about likelihood of data? I understood likelihood to pertain to parameters as in MLE?
