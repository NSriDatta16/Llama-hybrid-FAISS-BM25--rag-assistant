[site]: crossvalidated
[post_id]: 198572
[parent_id]: 
[tags]: 
Large Neural Networks have zero bias in the bias-variance tradeoff?

We know that neural networks are universal approximators. That means that they can approximate ANY function (with a large enough number of hidden neurons). Error can be broken down into two components: bias and variance. Bias is error due to your model's inability to represent the target function. Since neural networks are universal approximators, there should be no error due to bias. There will only be error due to variance. Can anyone confirm?
