[site]: crossvalidated
[post_id]: 219424
[parent_id]: 
[tags]: 
In Bayesian networks does hard evidence make P(evidence) = 1?

I've been attempting to understand how Bayesian networks work when evidence is applied to them, and in the book I'm currently reading, there are what appear to be contradictory statements, and I don't get what I'm missing. My assumption before reading this book was that when hard evidence on some variable E (it is definitely one state) is applied, then P(E) = 1. The book provides an example about a chest clinic, where 5% of all patients are diagnosed with lung cancer, and 50% of all patients are smokers. By analyzing records, they know that the probability that someone was a smoker given that they had lung cancer was 80%. A new patient comes in, and they know the patient is a smoker, so they want to find the probability that the patient will be diagnosed with lung cancer. The formula they give for this is just Bayes Theorem, where H is "patient has lung cancer" and evidence E is "patient is a smoker": $$ P(H|E) = \dfrac{P(E|H) \times P(H)}{P(E)} $$ Then, plugging in the numbers, they have: $$ P(H|E) = \dfrac{0.8 \times 0.05}{0.5} $$ What I don't understand is why P(E) = .5 in the formula. If you know for a fact that they ARE a smoker, wouldn't that change P(E) = 1? Obviously this would be a problem then if you knew for a fact that they weren't a smoker, because that makes P(E) = 0 and you're dividing by zero, so then what IS the P(E) on bottom and how does observed evidence actually change anything? What does the bottom of the fraction represent? Later on in the book, when it starts explaining how probabilities in an actual network are calculated, it mentions that if something is known for certain on a node, then the probability for that state of the node is considered to be 1. Why is that not the situation in the chest clinic example? Is there something fundamental to Bayes theorem I'm just not understanding? All help is greatly appreciated!
