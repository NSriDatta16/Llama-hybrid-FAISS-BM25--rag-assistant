[site]: datascience
[post_id]: 10722
[parent_id]: 
[tags]: 
Standard Deviation of Classifier Models

I am coming from the world of linear/logistic regression where residuals are assumed to be normal and the output includes some sort of standard error of residuals that one can use to make forecasts. Admittedly, I have very little experience in fitting and interpreting multinomial models.. Anyways, I am thinking about a specific problem: Let's say we have lots of data on voters that have already cast a vote. With this data we wish to train a model to forecast future elections. From the world of normal regression, there seems to be standard errors in forecasting each vote that could potentially be summed to create a random variable for the sums of votes for each candidate. These random variables could then be used to try to forecast the probability of each candidate winning. My question is, what is the standard way of assessing the "standard error" of classifier models using tools like Stochastic Gradient Descent Classifiers for example. Or any of the more modern tools for classification. Some sort of bootstrapping approach?
