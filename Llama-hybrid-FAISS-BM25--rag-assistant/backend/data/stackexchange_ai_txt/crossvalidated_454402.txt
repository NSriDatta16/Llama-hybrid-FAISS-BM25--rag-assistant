[site]: crossvalidated
[post_id]: 454402
[parent_id]: 454380
[tags]: 
If you understand Lemma 2 and Equation (6), the rest is just linearity of expectation: $$\begin{align}m_{ij}(n)&=E[N_n(j)|X_0=i]=E\left[\sum_{m=0}^n I_m(j)\bigg\vert X_0=i\right]=\sum_{m=0}^n E[I_m(j)|X_0=i]\\&=\sum_{m=0}^np_{ij}^{(m)}\end{align}$$ Intuitively, $p_{ij}^{(m)}$ represents how certain we're at $j$ -th state at our $m$ -th step. If it's $0.1$ , we'll be at $j$ -th state $0.1$ of the time if we do an experiment, i.e. run the markov chain multiple times. So, summing these expected occupation numbers will yield the mean occupation. For the simplest case, take all $p_{ij}^{m}=1$ , which means the mean occupation is $n+1$ because at every step (out of $n+1$ steps) we're guaranteed to be there.
