[site]: crossvalidated
[post_id]: 109533
[parent_id]: 109504
[tags]: 
You don't necessarily need to change $U$ and $V$ to be binary as well; in fact, doing so will probably be somewhat harmful. Remember that $\mathbb{E} R_{ij} = \sum_k U_{ik} V_{jk}$, so that if $U$ and $V$ have binary entries, for $\mathbb{E} R_{ij}$ to be 0 or 1, at most one corresponding pair of entries can be 1. One thing you could do is just to use the BPMF model as-is, probably centering your data (subtracting the mean) beforehand. I would expect this to work reasonably well. A better option might be to keep the same distributions on $U$ and $V$, but change the mean of $R$ to be "squashed" through, say, a logistic function $\mathbb{E} R_{ij} = 1/(1 + \exp(- U_i^T V_j)$ (and still modeling R as normal); this is what was done in the original (non-MCMC) PMF paper. This makes the model predictions not actually binary, but at least they're in the right range. I'm not sure how easily pymc allows you to model this (I've never used it). A more "pure" option, to keep the data types of the models correct, would be to model $R$ as Bernoulli with parameter based on $U_i^T V_j$; probably squash it as above, or at least make sure that in your code it's truncated into [0, 1]. I don't know how the different options will affect the efficacy of the simple Metropolis-Hastings algorithm that the current version of pymc uses. I believe it would be less of an issue with the more powerful algorithms in the alpha version (pymc3), but I have no idea how stable or usable that code is yet.
