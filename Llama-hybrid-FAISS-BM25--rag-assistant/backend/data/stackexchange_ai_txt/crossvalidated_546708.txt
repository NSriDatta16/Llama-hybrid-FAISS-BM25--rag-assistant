[site]: crossvalidated
[post_id]: 546708
[parent_id]: 
[tags]: 
efficient method for sentence similarity

I have a file with about 25000 rows. I want to find sentences that are near duplicates (sentences which have difference of just one or two words/symbols or ones which are just paraphrasing of another). To accomplish this, I'm using a very naive solution by comparing every row to every other row using the model bert-base-cased-finetuned-mrpc . Now the thing is that this is obviously very inefficient as it comparing for $25000^2$ pairs, and the task won't complete on my device. Is there a way I can first find sentences which are candidates for being near duplicate, and then put the pairs into the model, or is there another approach which is efficient? I'm new to this, so any suggestions are appreciated.
