[site]: datascience
[post_id]: 53440
[parent_id]: 
[tags]: 
Converting wave to vector and vice versa creates noise

I’m a long time data scientist that works mainly with texts. I’m now trying to apply my knowledge into voice and I’m struggling with some simple tasks in python. As far as I understood I can manipulate voice (converting voice to vectors for neural networks) using mfcc of the voice file. However, when I try to convert it back to voice I got tons of noise. My pseudo code: class wav2vec: mfcc = None org_shape = None wave_shape = None sr = None max_len=50 feature_dim_1 = 20 channel = 1 feature_dim_2 = 50 filename = 't1.wav' def wav2mfcc(file_path, max_len): wave, sr = librosa.load(file_path, sr=None) mfcc = librosa.feature.mfcc(wave, sr=16000) org_shape = mfcc.shape if (max_len > mfcc.shape[1]): pad_width = max_len - mfcc.shape[1] mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant') else: mfcc = mfcc[:, :max_len] objWav2vec = wav2vec() objWav2vec.mfcc = copy.deepcopy(mfcc) objWav2vec.result = copy.deepcopy(mfcc) objWav2vec.org_shape = org_shape objWav2vec.wave_shape = wave.shape objWav2vec.sr = sr return objWav2vec def mfcc2wav(objWav2vec, file_path, max_len): mfcc = objWav2vec.mfcc.reshape(objWav2vec.org_shape[0],max_len) mfcc = mfcc[:, :objWav2vec.org_shape[1]] n_mfcc = mfcc.shape[0] n_mel = 128 dctm = librosa.filters.dct(n_mfcc, n_mel) n_fft = 2048 mel_basis = librosa.filters.mel(objWav2vec.sr, n_fft) bin_scaling = 1.0/np.maximum(0.0005, np.sum(np.dot(mel_basis.T, mel_basis),axis=0)) recon_stft = bin_scaling[:, np.newaxis] * np.dot(mel_basis.T,invlogamplitude(np.dot(dctm.T, mfcc))) excitation = np.random.randn(objWav2vec.wave_shape[0]) E = librosa.stft(excitation) recon = librosa.istft(E/np.abs(E)*np.sqrt(recon_stft)) librosa.output.write_wav(file_path, recon, objWav2vec.sr) t = wav2mfcc(filename,max_len) t.mfcc = t.mfcc.reshape(1,feature_dim_1, feature_dim_2, channel) mfcc2wav(t, 't2.wav', max_len) Can anyone explain why I don’t get the same sound as the original file?
