[site]: crossvalidated
[post_id]: 563590
[parent_id]: 
[tags]: 
XGBoost heavily overfitting when containing the minimum/maximum of a variable?

I've been building an XGBoost Regressor model with some good success. Currently, the training accuracy is 68% and testing 66% - indicating some, but not too much, overfitting. However, I've noticed today a strange behaviour: Let's say the model had 2 independent features, I'll call them X and Z, and then it's trying to predict the likelihood of event Y (either 1 or 0). We'll say X and Z are normally distributed between 0 and 1. Let's also assume that X is highly +correlated to Y, and Z is less so but still +correlated. We have also added monotonic constraints to X and Z, so that if all else is equal then increasing them will only increase the model prediction of Y. What I'm seeing is that in a "normal" prediction if X is say, 0.1 and Z is 0.1 then the model predicted probability of Y is 10% If you increase Z to 0.5, then the model predicted probability of Y goes to 15%.. If you increase Z to 0.95, then the model predicted probability of Y goes to 20%.. But when Z is 1 then the model predicted probability of Y is suddenly 90% likely! The reason, I think, is because in the training dataset the maximum value of Z is 1, and when Z was this value, Y was 1. So it's like the model has hyper overfit to this one row of data? It's very strange, as like I say the model in general doesn't seem overfit - but it has this very weird interaction with the row that contains the maximum value? Is there a specific type of parameter or technique that can help defend against this type of interaction? Reshuffling the train/test dataset isn't possible as it's timebased and so they are split by a date (before date = train, after date = test). A Partial Dependency Plot (from the actual model), where X=feature[0] and Z=feature[20]. It shows what I expect to see from the model - however the prediction still jumps (from 16% to 73%!) after Z (feature[20]) goes higher than the training set maximum of 2.16.
