[site]: crossvalidated
[post_id]: 407073
[parent_id]: 342367
[tags]: 
So the way I view feature engineering ala-box cox is that we have a model that requires normality, we don't have normal data, so we do a transform to get us to normal Data. So on the one hand its true that neural network do not require normalized data so why feature engineer. On the other hand, while a neural net might eventually get there, sometimes feature engineering done by humans can hugely help the initial convergence rate. For example, in case of multichannel signal data, doing the Fourier decomp and computing the cross correlations beforehand greatly increases the speed at which the Neural Net can get to classification (to give a really specific example). Or to give a more sane example, if you know your data has many outliers and these are not important, removing outliers is a form of feature engineering. The network could eventually learn to ignore then, but it might take forever. So when you are fairly sure that the transformation is going to highlight something important about your data, then transform it, if not, then maybe not.
