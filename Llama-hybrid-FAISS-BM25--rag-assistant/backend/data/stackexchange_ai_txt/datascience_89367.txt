[site]: datascience
[post_id]: 89367
[parent_id]: 89345
[tags]: 
Welcome to the community. If I understood correctly: you have a dataset whose target labels (aka ground truth) you don't know, so you figured these out by assigning the output of another model from someone else --> I guess this pre-trained model was built with the same dataset right ? you built a new model on this dataset, using as target values the other model's output as your ground truth, giving you a 100% accuracy --> you convert the predicted probability to the corresponding label is it? This might mean: your model is providing the same output labels as the other model trained on the same dataset; this is not strange, mainly if the models are of the same type (e.g. tree-based models as your xgboost), mainly assuming the pretrained model outputs fit the real target values the data is quite easy to "learn" , so both models provide similar results over the same target labeling to take into account: accuracy might not be an optimal metric , taking a look at how much unbalanced the dataset is (it is, what is the ratio between the different classes). Nevertheless, I would make sure to find the real and precise corresponding targets to go on with confidence on your problem.
