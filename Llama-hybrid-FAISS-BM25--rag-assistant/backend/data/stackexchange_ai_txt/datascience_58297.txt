[site]: datascience
[post_id]: 58297
[parent_id]: 57542
[tags]: 
This shows you did not properly flatten your output before the final dense layer. Your first model.add should be an embedding layer since that represents word vectors that'll be trained. The last layer should be the dense one. Hard to tell on the spot which hidden layers to consider, but try GlobalAveragePooling and Dense with the relu activation.
