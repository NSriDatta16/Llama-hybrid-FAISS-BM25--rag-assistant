[site]: crossvalidated
[post_id]: 55262
[parent_id]: 
[tags]: 
Volatility model combined with different distributions?

I am working on fitting distributions to financial data using different volatility models. The simplest case of a gaussian distribution I do understand: The data is $\mathcal{N}$$(\mu,\sigma^2)$ distributed. So at each day I use a certain amount of data to estimate the $\mu$ and the $\sigma$. If I apply the "normal" ML I get as solution the empirical mean and empirical standard deviation. There I implement a volatility model, by not using the classical formula for the standard deviation and the full data set, but e.g. by using an exponentially weighted moving average. So I calculate a value for $\sigma$ with a model for each day and plug this into the formula of my normal distribution, ok. But what is in case of a more complicated distribution? E.g. the generalized hyperbolic distribution. How can I implement a volatility model? I mean, how can I combine it with the distribution? If I use classical ML approach, this does not use a volatility model, but in case of the generalized hyperbolic distribution, there is no $\sigma$ in the parameters, so I cannot just plug it in? This master thesis http://www.math.chalmers.se/~palbin/mattiasviktor.pdf is doing it, but I do not understand how they do it? On page 48 they just say "Over a 1300 day period, the parameters of the probability density functions are estimated every five days, using a 500 day window" And on page 50 they give the generalized hyperbolic distribution which uses e.g. a GARCH-AR volatility model? The only way I can imagine is, that I calculate a value for $\sigma$ at each day, at for each day I match the moments of the distributions. But this is not ML? On page 84 you can see a nice picture, for each day the hyperbolical distribution is combined with a volatility model. I am interested in doing this, since I want to calculate the VaR over a time period with fitting a distribution and using a time volatility model. ok edit, so in more detail: I have financial data ( http://uploadeasy.net/upload/cdm3n.rar ). These are the losses (negative returns) of, I think the last 10 years of a company. I want to calculate the VaR using a distribution with a volatility model. So first of all, I assume a normal distribution: $\mathcal{N}(\mu,\sigma)$. The VaR is nothing else, than the quantile: $VaR_\alpha=F^{-1}(\alpha)$ So I have a volatility model for my $\sigma$, I get for each day a value, so $\sigma_1,\sigma_2,...,\sigma_n$. For simplicity reasons I set $\mu$ to zero. So I have for each day a normal distribution with mean zero and a sigma which comes from the volatility model. Lets use a very simple volatility model, e.g. the (empirical) standard deviation of the last 10 days. So I use the first 10 days the calculate the volatility for the 11th day and so on. I plug this into my normaldistribution to compute the quantile. The R code would be e.g. volatility How can I do this in case of a non standardized t distribution with $\nu,\mu,\beta$. Or in case of a generalized hyperbolic distribution?
