[site]: datascience
[post_id]: 24850
[parent_id]: 24839
[tags]: 
I think you misunderstood the fundamental of RNN. fix their weights to all be the same". Yes that's exact what RNN is suppose to be. In any type of RNN, you always only have one real RNN cell. The unrolled RNN cells are merely representations of that RNN cell overtime. In a single training step, the weights of those unrolled RNN cells are always the same. Sp are RNN's any use in learning in real-time for temporal data? Yes, you can train an RNN in real-time with a catch. Although in theory the sequence is arbitrary long, but in practice we can only backprop a certain step back due to
