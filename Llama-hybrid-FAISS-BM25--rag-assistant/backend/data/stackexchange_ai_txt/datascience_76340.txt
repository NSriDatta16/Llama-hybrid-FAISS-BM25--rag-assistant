[site]: datascience
[post_id]: 76340
[parent_id]: 75182
[tags]: 
I understand you are looking for some interpretability. But if you recall Feature engineering, we mostly remove features which are of less value. What it means is that all the remaining features are contributing. What you may do a trade-off between Accuracy and Interpretability - Logistics Regression and Decision Tree will give you a clear picture on how the model arrives at the decision. You may try that
