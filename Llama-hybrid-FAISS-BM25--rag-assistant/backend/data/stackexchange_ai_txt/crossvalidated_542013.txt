[site]: crossvalidated
[post_id]: 542013
[parent_id]: 
[tags]: 
Providing a neural network with different kinds of neurons?

I was wondering how NN could possibly resolve specific problems (let's say trigonometry). So, in order to compute some more complex data, why not "propose" our NN several sorts of neurons to use (or not), such as arithmetic or calculus functions, instead of using only the "classic" neuron model (weighted sum + ReLu). Imagine, for example, sin/cos as activation. Or making possible to divide some inputs by other ones. And, after all, are we forced to limit the neuron ouputs to [-1; 1] ?
