[site]: datascience
[post_id]: 12353
[parent_id]: 12347
[tags]: 
So your data-set of 155000 records has 403 records where B=1, and B=0 for the remaining 154597 records. You could try splitting your data-set into 2:1 training/test sets sampled by each class of B. After you've done this, then only for the training set use SMOTE to over-sample the records with B=1 along with under-sampling the B=0 training records to bring the class ratio to something like 4:1. Over/under sampling for the test set is not required as it is supposed to mimic real world uncertainty to test your model's performance. Your model's AUC will definitely get reduced since (as rightly pointed out by stmax), you've leaked test records into the training set by over sampling B=1 cases before splitting the train-test sets. The answers to each of your questions are: Yes, class imbalance does effect a random forest model's accuracy. How severely depends on the severity of the imbalance as well as the nature of the data-set itself. Yes, you are biasing the training by over sampling the minority class, but if these are large enough samples in the original set, then hopefully they are close representations to the entire population. I would recommend two metrics/techniques you could use here: Kappa Statistic (refer to this article ) and the precision-recall curves to compare different models.
