[site]: stackoverflow
[post_id]: 2704038
[parent_id]: 2703938
[tags]: 
This might fall dangerously close to arm-chair optimization, but here are some ideas that might rationalize your results: Fork/exec: almost anything useful that is done by a shell script is done via a shell-out, that is starting a new shell and running the a command such as sed , awk , cat etc. More often then not, more then one process is executed, and data is moved via pipes. Data structures: Perl's data structures are more sophisticated then Bash's or Csh's. This typically force the programmer to be created with data storage. This can take the forms of: use non optimal data structures (arrays instead of hashes) store data in textual form (for example integers as strings) that needed to be reinterpreted every time. save data in a file, and re-parse it again and again. etc. Non optimized implementation: some shell construct might not be designed with optimization in mind, but with user convenience. For example, I have reason to believe that the bash implementation of Parameter Expansion in particular ${foo//search/replace} is sub-optimal relative to the same operation in sed . This is typically not a problem for day-to-day tasks.
