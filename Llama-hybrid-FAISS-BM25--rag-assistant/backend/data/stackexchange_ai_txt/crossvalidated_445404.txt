[site]: crossvalidated
[post_id]: 445404
[parent_id]: 445307
[tags]: 
Yes, these are all part of hyperparameter selection and optimization, but there are some good rules of thumb. Discount factor: Somewhere between 0.9 and 0.99999. The sparser and farther away rewards are, the higher you probably want this. Learning rate: between 0.1 and 0.00001. Layers: At most 3 in most cases. Initializer: you can't really go wrong as long as you choose a reasonably well known initialization. Loss: no, you could also use L1 loss or any other regression loss. Number of steps for POMDP: use domain expertise, ask yourself how many steps of an environment it would take you to infer most of the hidden state.
