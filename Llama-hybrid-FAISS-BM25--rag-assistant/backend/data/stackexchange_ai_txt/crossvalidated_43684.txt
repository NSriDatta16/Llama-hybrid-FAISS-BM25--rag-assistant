[site]: crossvalidated
[post_id]: 43684
[parent_id]: 43603
[tags]: 
A variable that achieves a better classification performance is not necessarily a variable that is correlated or relevant to the target class labels (i.e. Y in your case). So, optimality does not imply relevance and vice versa. If the relevance metric you are using does not apply any transformation or pre-processing to the data and independent of any learning model, then you can infer some direct relation between the selected feature and the target variable. A good metric is one that leads to selection of features related to the target variable and that are not redundant. mRMR is an example of such a metric. On the other hand, if your evaluation metric is not independent of the classification model which is known as the wrapper model, then selection of relevant features is based on the type of the classifier. For example, Naive Bayes Classifier and Decision Trees are methods that reflects relevance between the feature and the target variable. However, SVM with an RBF kernel might not lead to the selection of relevant features but rather, the optimal ones.
