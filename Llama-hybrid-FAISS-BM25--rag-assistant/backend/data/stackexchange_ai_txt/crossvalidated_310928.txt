[site]: crossvalidated
[post_id]: 310928
[parent_id]: 310911
[tags]: 
If you predict a new observation, you send it through all trees and then bundle the results by majority votes. You seem to do it like this, which is good. OOB predictions are relevant to guess the model performance on the training data. This is of key importance since random forests usually grossly overfit on the training data. Thus, missclassification rates would be much too good. If your implementation cannot do this, you can estimate the model performance through cross-validation.
