[site]: crossvalidated
[post_id]: 422898
[parent_id]: 153599
[tags]: 
Recurrent Neural Networks (RNN) basically unfolds over time. It is used for sequential inputs where the time factor is the main differentiating factor between the elements of the sequence. For example, here is a recurrent neural network used for language modeling that has been unfolded over time. At each time step, in addition to the user input at that time step, it also accepts the output of the hidden layer that was computed at the previous time step. A Recursive Neural Networks is more like a hierarchical network where there is really no time aspect to the input sequence but the input has to be processed hierarchically in a tree fashion. Here is an example of how a recursive neural network looks. It shows the way to learn a parse tree of a sentence by recursively taking the output of the operation performed on a smaller chunk of the text. [ NOTE ]: LSTM and GRU are two extended RNNs types with the forget gate, which are highly common in NLP. LSTM-Cell Formula:
