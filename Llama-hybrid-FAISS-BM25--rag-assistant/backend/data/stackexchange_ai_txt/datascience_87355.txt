[site]: datascience
[post_id]: 87355
[parent_id]: 
[tags]: 
Fast AI Lesson 4 - MNIST. Confused about multiplying weights by pixels?

I’m on lesson 4 of the Fast AI "Deep Learning for Coders" course, and have been back through the same lesson a few times now but I don’t think I’m quite getting a few things. I want to have an understanding of what’s going on before moving on. This lesson is on MNIST - and Jeremy is recognising 3s vs 7s. So he has 12000 images (ignoring mini-batches) of about 800 pixels each, and his tensor has a shape of (12000, 800) . He randomly generates 800 weights, 1 for each pixel, plus a bias (which I don’t quite understand the purpose of either). So then for the first image, he multiplies the image’s value by the weight for that pixel. So if the pixel value is 0.9 and the weight is 0.1, 0.9*0.1 = 0.09 . Or if the pixel value is 0.5 and the weight is 0.6, 0.5*0.6 = 0.3 . (and then a bias is added, and this is done for every image) I don’t understand what the purpose or benefit is of multiplying these numbers together. If I wanted a score of how accurate is our weight to the pixel value, I’d do abs(value - weight) . And then adding these up would give me a score of how accurate my weights are. This is where I’m confused. what am I missing?
