[site]: crossvalidated
[post_id]: 152295
[parent_id]: 106225
[tags]: 
My intention on how this problem might be solved is: Calculate linear model to receive the regression line $r$. Calculate the normal vector $v$ to the resulting regression line. Shift $r$ by $v$ till all data points are under $r$. To optimize $r$, you might rotate it by some angle $\alpha$ and stop for the best $\alpha$ you found, maybe using the Residual Sum of Squares as reference term. Like I tried to show in this figure: Another approach could be to use Support Vector machines . I don't know if this is possible with your data, but maybe you can produce some dummy points located above your data and split them from your original points using a SVM. This is just some idea I came up with. Though, I would prefer the first method.
