[site]: crossvalidated
[post_id]: 52577
[parent_id]: 52572
[tags]: 
You are doing a (chemical) calibration, and the search phrase you are looking for is method validation in analytical chemistry . There actually exist norms how to validate methods in analytical chemistry, and certain measures of performance like limit of detection (LOD), limit of quantitation (LOQ, probably more relevant for you), recovery rate, etc. If you can read German, the Wiki page about method validation is a decent starting point (unfortunately, there is no English version). I like Handbuch Validierung in der Analytik but I'm not aware of an English translation. Have a look through the analytical chemistry section of your library (if that exists). And you probably should look up the difference between the confidence interval of a calibration and prediction intervals. We won't be able to give you any more detailed advise without knowing how you arrive at your concentration: some of the "standard" techniques to calculate e.g. the LOD, or the confidence and prediction intervals in linear calibration are valid only for ordinary least squares (which in chemometrics is usually suitable only for univariate calibration). See e.g. Klaas Faber and Bruce R. Kowalski: Propagation of measurement errors for the validation of predictions obtained by principal component regression and partial least squares, Journal of Chemometrics, 11, Issue 3, 181â€“238, 1997. We observed quite different LODs for the "blank" method vs. the "relative error" method here: S. Dochow et al. : Raman-on-chip device and detection fibres with fibre Bragg grating for analysis of solutions and particles. Lab Chip, 2013, 13, 1109-1113. One common difficulty is that the usual methods for calculating confidence (and prediction) intervals assume all calibration samples to be independent. But this is frequently not the case, e.g. when calibration samples are prepared by diluting stock solutions (unless for each calibration sample a new stock is prepared). However, the problems can be avoided if validation is done with a distinct series of samples with is prepared from a new stock. The univariate methods usually calculate these intervals from within the training data. But the more sophisticated multivariate methods like principal component regression or partial least squares regression do a rotation/projection of the data first and then calculate the regression in scores space. Confidence intervals need to take into account that this projection is also derived from the calibration data, and thus has uncertainty. This source of variance is not covered by the analytical solutions for confidence intervals for ordinary least squares. In any case, what you can do is: bootstrap/cross validate your calibration (with respect to stock solutions/independent samples) and derive confidence intervals, RMSE and (relative) error and from that the figures of merit you need. However, if you do a univariate calibration, work in R and all measurements are from independent samples, package chemCal will give you the figures of merit and calibration plots.
