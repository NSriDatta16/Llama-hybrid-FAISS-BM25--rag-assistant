[site]: datascience
[post_id]: 104403
[parent_id]: 
[tags]: 
Model doesn't know German well enough

I have a model that generates questions and answers based on input text. The texts are in German and based on observations it seems like the model doesn't know German well enough. I need to pretrain the T5 transformer "better", so I was thinking what possibilities I have: is there a better version of T5? A German pre-trained version? Isn't multilingual mT5 too much since I'm only interested in German? And last but not least, can't I just use my current code for pretraining and use the c4 dataset in German to make it better?
