[site]: crossvalidated
[post_id]: 599712
[parent_id]: 598676
[tags]: 
This is most likely to (qualitatively) repeated sample instances of the positive class. About 60% of the positive instances have the same characteristics for the purposes of the classifier so either we get them "all" in one go or nothing. That's why we go from 0 to 60 in a single step and this appears as a single step in the PR curve graph. At the same time, as we make the first "positive" classifications, we lump up some false positives so our precision goes down too. We can see from baseline of the PR curve that more that 50% of the all samples are indeed positive (the confusion matrix corroborates that too) so the potentially "high-ish" PR-curve AUC (average precision) is not necessarily indicative of good performance. I suggest looking at the paper Unachievable region in precision-recall space and its effect on empirical evaluation by Boyd et al. (2012) to get more in-depth view of these implications.
