[site]: crossvalidated
[post_id]: 436593
[parent_id]: 300296
[tags]: 
Since the marginal density writes as $$m(x)=\int_\Theta f(x|\theta),\pi(\theta)\,\text{d}\theta$$ a possible numerical approximation is $$\frac{1}{T}\sum_{t=1}^T f(x|\theta_t)\qquad\theta_1,\ldots,\theta_T\sim\pi(\theta)\tag{1}$$ but this Monte Carlo approximation based on simulations does not use kernel estimation. As stressed by Juko Kokkala 's comments, the use of a kernel estimator of $m(x)$ would require observations from the marginal, while the classical Bayesian framework only involves observations from $f(x|\theta_0)$ for an unknown $\theta_0$ . Plus, (1) is a parametric estimator that converges at the rate $\sqrt{T}$ , as opposed to a non-parametric estimator that converges at the rate $ T^{âˆ’4/2(d+4)}$ where $d$ is the dimension of $x$ . Note also that an intractable posterior is usually understood as associated with an intractable product 'prior x likelihood' rather than having an unknown normalisation constant $m(x)$ , since simulation techniques (like MCMC, importance sampling, &tc.) can bypass this missing term and still deliver. (This issue is also discussed in the post the OP linked to .)
