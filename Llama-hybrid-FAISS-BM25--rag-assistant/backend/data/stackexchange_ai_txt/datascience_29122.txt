[site]: datascience
[post_id]: 29122
[parent_id]: 
[tags]: 
Encog neural network multiple outputs

I am a little confused with using encog to create a neural network. I am trying text classification with a basic feed forward network. For the input data I have 200 unique words (features/inputs) to input into the network and 100 different pieces of text. so I have a matrix of 100x230, essentially 100 different training items each with the frequency of 230 words. I then have an output which classifies the data as A, B, C, D or E, so one column and 5 different outputs, therefore this is an ordinal column and is part of the CSV data set I read in thus I actually have a matrix of 100X231 where the 231 column is the output I desire to classify. I can train and run this neural network no problem but I am confused about the number of output neurons to have. I would have thought there are 5 different classifications therefore I should have 5 different neurons, however I can't setup the code like that, as it complains: IMLDataSet trainingSet = new BasicMLDataSet(input, ideal); My input variable is a double[100][230] and the ideal is just the column of expected classifications so double[100][1]. Because I only have one column and the data is normalised those A,B,C... values are turned into numbers between -1 and 1 and therefore when I run the neural net with 5 output neruons it complains that it should be only 1. When I run the neural net with one neuron output it gives me what looks like correct and accurate answers but the value it gives is between -1 and 1. I am assuming the activation level is being matched to the output? My question therefore is either how to denormalise this output to get back to my actual letter classification or how to use 5 neurons on the output so the network chooses the appropriate classification. My neural network is as follows: BasicNetwork network = new BasicNetwork(); network.AddLayer(new BasicLayer(null, true, 230)); network.AddLayer(new BasicLayer(new ActivationTANH(), true, 16)); network.AddLayer(new BasicLayer(new ActivationTANH(), false, 1)); network.Structure.FinalizeStructure(); network.Reset();
