[site]: crossvalidated
[post_id]: 324601
[parent_id]: 64991
[tags]: 
Using a SVM with fixed hyperparameters ($\gamma$ and $C$) is a machine learning algorithm. A procedure that optimizes these hyperparameters and trains a SVM with these is also just a machine learning algorithm . Instead of only optimizing the internal parameters of the SVM (the support vectors) it also optimizes the hyperparameters. Now you have two problems [that can be solved independently]: How to perform hyperparameter optimization/model selection? How to estimate generalization error of a machine learning algorithm? Read Cross-validation misuse (reporting performance for the best hyperparameter value) to make sure that you don't mix them up. A specific (probably not optimal) solution to the concrete problem of your question: k = 5 loss_CV = zeros(k) for i in 1:k Xi_train, Xi_test = folds(X,k)[i] loss = zeros((3,3)) for lambda in {0.1,0.2,0.5,1.0} for C in {10,100,1000} for j in 1:k Xj_train, Xj_test = folds(Xi_train,k)[j] model = SVM(Xj_train,lambda, C) loss[lambda,C] += test_error(model,Xj_test) lambda, C = argmax(loss) model = SVM(Xi_train,lambda, C) loss_CV += test_error(model,Xi_test) loss = zeros((3,3)) for lambda in {0.1,0.2,0.5,1.0} for C in {10,100,1000} for j in 1:k Xj_train, Xj_test = folds(Xi_train,k)[j] model = SVM(Xj_train,lambda, C) loss[lambda,C] += test_error(model,Xj_test) lambda, C = argmax(loss) model = SVM(Xi_train,lambda, C) Here, model would be your "best model" and loss_CV a "proper estimate of its generalization error" (although biased upward, but you cannot have the cake and eat it too).
