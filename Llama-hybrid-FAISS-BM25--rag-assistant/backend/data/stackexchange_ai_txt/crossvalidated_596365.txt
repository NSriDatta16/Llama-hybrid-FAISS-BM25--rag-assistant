[site]: crossvalidated
[post_id]: 596365
[parent_id]: 596364
[tags]: 
When I say that a difference is "statistically significant at the 95% confidence level" (or that "p really means is... "If, in reality, the difference in question were actually zero, and I had repeated this exact same analysis 100 different times, each time on a different random sample of the same size drawn from the same population, then only 5 of those 100 analyses would have (incorrectly) found a difference as large or larger than the one I actually observed." So you can see that the concept of "taking repeated samples" is built right into the idea of statistical significance (and null hypothesis testing). In other words, saying something is statistically significant is really just making a claim about what would happen if you repeated the analysis you just did a large number of times. It doesn't really make sense to worry about whether Frequentism is "true" or not. Frequentism and Bayesianism are two philosophical ways to think about this fuzzy concept called probability, but there is no way to ever prove that one of them is right or wrong. Of course, people often argue about which is more useful in particular contexts. But it is true that standard statistical tests, p values, and confidence intervals all presuppose a frequentist view of statistics.
