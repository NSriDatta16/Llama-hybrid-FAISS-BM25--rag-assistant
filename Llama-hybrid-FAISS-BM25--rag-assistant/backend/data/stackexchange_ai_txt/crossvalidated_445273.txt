[site]: crossvalidated
[post_id]: 445273
[parent_id]: 
[tags]: 
Neural Network with incresing number of output and task difficulty

Is it possible to design a network to solve a multiple-output regression task with increasing number of outputs, so the difficulty of the task? I am trying to solve the problem of frequencies estimation for sum of sine waves with NN. From $$ x(t) = \sum_{k=0}^K a_k sin(2 \pi f_k t) + \text{noise}$$ predict $a_k$ and $f_k$ . However there is an order in the data: $a_k > a_{k+1}$ and $f_k . I am familiar with the solution presented in the paper Neural networks for sinusoidal frequency estimation . I implemented it: the input is the signal with $K$ sine waves. The output are the $\{a_k, f_k\}_{k=0}^{K'}$ with $K' \leq K$ . For $K' = 2$ is working fine. For $K' > 2$ the estimation error is not as good, no metter the architetture (It tried with RNN and CNN or simple Feedforword NN). I noticed that also the prediction of $a_1, f_1$ for $K' > 2$ is worst then when $K'=2$ . The question: is there a DNN technique to start the learning with $K' = 2$ and then sequentially increase it? I was thinking: is it right to use an NN with an output layer of dimension $2K$ , and predict only 2 values, while $2K-2$ are forced to be zeros. So train for some epochs, then unfreeze the next 2 values, then repeat?
