[site]: crossvalidated
[post_id]: 112223
[parent_id]: 
[tags]: 
Applying autoencoders for dimensionality reduction in audio: Why does this create a low-pass effect?

I've been playing around with framing audio data and training a single-layer autoencoder to find a dimensionality-reduced form (say 128-sample frames to 32-dimension frames). When I test the audio after going through the encode/decode layers (trying both sigma and tanh activation functions for what it's worth), it appears to have a low-passed effect. Why might this be? For reference, an FIR low-pass filter is just a moving average.
