[site]: crossvalidated
[post_id]: 223931
[parent_id]: 
[tags]: 
Predict probability when model was trained in balanced dataset

I have a dataset of about 1M observation and I had to predict a response that occurs only about 10.000 times (1%). I decided to train a random forest, but this takes a lot of time to train because the data is too large for my hardware. So I decided to take a sample, but an aleatory sample would be already too large to have a minimum quantity of response. (If I take 10% aleatory, i would have only 1000 response) Then I took a stratified sample. All responses and 10.000 aleatory non-responses, and trained my model in this dataset. But now I need to rescale the probability so I have the real probability of the observation to be response. I tried to simulate this problem with this code in R. Training a model in a balanced dataset and another one in the unbalanced data. But those models are not very correlated and I didn't find a good way to tranform the probabilities to the original unbalanced scale. I found that for logistic regression I can do this by just changing the intercept this way: $$ \hat{\beta_0} = \hat{\beta_0^*} - log(\frac{\gamma_1}{\gamma_2})$$ Where $ \gamma_1 = Pr(Z=1|Y=1)$ and $ \gamma_2 = Pr(Z=1|Y=0)$. $Z$ is the an aleatory variable indicating if the observation is in the reduced dataset. This was found in this book (in portuguese) page 216 simulate_data % pnorm(mean = 13)) %>% as.factor() ) } balance % sample_n(length(Y[Y == "1"])) ) return(list( X = X, Y = as.factor(c(rep(c(1,0), each = length(Y[Y == "1"])))) )) } train Code for plot library(ggplot2) data.frame( unbalanced = predict(modelo_desb, newdata = test$X, type = "prob")[,2], balanced = predict(modelo_bal, newdata = test$X, type = "prob")[,2] ) %>% ggplot(aes(x = balanced, y = unbalanced)) + geom_point(size = 0.3) + xlim(0,1) + geom_smooth() + geom_hline(yintercept = m_desb, linetype = "dashed") + geom_vline(xintercept = m_bal, linetype = "dashed")
