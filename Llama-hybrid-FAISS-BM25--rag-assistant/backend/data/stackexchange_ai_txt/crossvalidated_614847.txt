[site]: crossvalidated
[post_id]: 614847
[parent_id]: 614723
[tags]: 
As J. Delaney's comment says, the Bayesian approach already allows both the data and the parameters to be random. I think the confusion arises because "the parameters are fixed and the data is random" is not true under the frequentist approach, and "the parameters are random and the data is fixed" is not true under the Bayesian approach either. (See the answers to this question for more details.) What is going on? In both cases you choose a family of models, for example a $N(\mu, \sigma^2)$ , which could have generated your data $X$ . In the Bayesian case, you treat $\mu$ and $\sigma^2$ as random variables and calculate their conditional distribution given your observed data $X$ . In order to do this, you must choose a prior distribution for $\mu$ and $\sigma^2$ . Sometimes you don't want to do this. In the Frequentist case, you are not allowed to treat $\mu$ and $\sigma^2$ as random variables. Instead, you seek to make statements which are valid no matter what the true values of $\mu$ and $\sigma^2$ happen to be. These statements are constructed by considering what kind of data might have been generated by different values of $\mu$ and $\sigma^2$ . But whatever result you get is still conditional on your observed data $X$ . It's just that it's not called a conditional distribution in the frequentist case. For example, suppose your frequentist confidence interval for $\mu$ is $[2, 3]$ . Then if you had collected a different data set $X'$ on a different day, you would probably end up with a different confidence interval. Similarly, say your Bayesian credible interval for $\mu$ is $[2, 3]$ . If you had collected a different data set $X'$ on a different day, you would probably end up with a different credible interval as well.
