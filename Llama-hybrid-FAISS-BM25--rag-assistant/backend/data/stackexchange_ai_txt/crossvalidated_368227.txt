[site]: crossvalidated
[post_id]: 368227
[parent_id]: 
[tags]: 
Bilinear and K-Mapping Basis in Linear Algebra

I am reading a machine learning paper which has some mathematical terminologies that are proving a little hard for me to understand. I am going to write the lines from the papers here. The policy is synthesized with a bilinear mapping $\qquad \qquad \pi(a|s)=exp(\phi^t A(e_t, e_k) \theta)$ The bilinear mapping given by the matrix $A$ is parameterized as the linear combination of $K$ mapping $\Theta_k$ $\qquad \qquad A(e_t, e_k)=\sum^K_{k=1}\alpha_k(e_t, e_k)\Theta_k$ where the coefficient function $\alpha_k(\cdot,\cdot)$ are parameterized by one hidden layer MLP Questions What does bilinear mapping mean here? What does $K$ mapping mean here? Assuming if $A(e_t, e_k)$ is a $4\times4$ , is $\Theta_k$ one single matrix or there are $K$ different $4 \times 4$ matrices? What is the purpose $\Theta_k$ ? Since $\alpha_k(\cdot,\cdot)$ is a coefficient function represented by a MLP, are there $K$ different MLPs as well?
