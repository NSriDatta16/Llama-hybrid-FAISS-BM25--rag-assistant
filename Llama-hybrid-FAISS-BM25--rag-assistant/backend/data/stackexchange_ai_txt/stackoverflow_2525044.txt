[site]: stackoverflow
[post_id]: 2525044
[parent_id]: 2524792
[tags]: 
Unless you are using a profiler that none of us know about, heap is the major concern. This is because most people just react to whatever a highly acclaimed tool tells them. Please get to the end of this post to see that most profiling tools that point out statically allocated memory errors are usually correct. Profiling should go beyond simple leaks and garbage collection. Let me give you an example in C: #include #include int main(void) { char *am_i_leaking; am_i_leaking = strdup("Now, that's subjective!"); return 0; } If the OS that runs this program does not automatically reclaim heap, I've caused a problem. I can't think of a modern OS that does not do that which is actually in use. Now lets look at this: char *foo(void) { static char bar[1024]; memset(bar, 0, sizeof(bar)); snprintf(bar, sizeof(bar -1), "Do wa diddy diddy dum diddy do"); return bar; } How your compiler allocates that is, well, up to your compiler. If you use it and can fiddle with the result, you probably have a broken compiler. Yet, if I have 100 threads entering that function at once, surely, the result is rubbish, unless my compiler magically figures out what I meant and introduces mutual exclusion or dynamic allocation without me having to worry about it, at which point we're back to profiling heap. In short, in our lifetime, garbage collection pertains to heap. Count on some taking stabs at the stack in the future and trying to 'optimize' things, then count on that effort becoming an interpreted language that a bunch of CEO's will demand. That doesn't mean ignoring memory errors is a good thing, no matter what the storage happens to be.
