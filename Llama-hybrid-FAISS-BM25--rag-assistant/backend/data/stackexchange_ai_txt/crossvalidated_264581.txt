[site]: crossvalidated
[post_id]: 264581
[parent_id]: 
[tags]: 
validity of hypotheses unnecessary when cross-validation is used?

I had recently a big discussion with my collegues regarding the need for hypotheses validation in the context of cross validation for model comparison. Here is the case: I'm using a repeated cross validation procedure (50 repeats, 2 folds) to compare prediction capabilities ( MAE & MBE ) of a dozen types of models (including linear and machine learning). I was told that I still have to validate hypotheses (normality of residuals, heteroscedasticity, colinearity, etc.) even in case a linear model comes first. My opinion is rather that whenever a model hits first in prediction capability, we can disregard any violation of assumptions of linear models. Thanks for your help, and if possible an link to an article backing your opinion (i couldn't find any)
