[site]: crossvalidated
[post_id]: 539079
[parent_id]: 43471
[tags]: 
A very obvious case where it makes a difference is when there is a relevant prior information, but we are trying to analyze a small dataset. An example that I found quite useful (and used in my thesis , full details of the analysis below are given there) is the TGN1412 first in human trial. During that first-in-human trial of a monoclonal antibody (i.e. TGN1412), all 6 of 6 the healthy volunteers in the test group ended up in a critical care unit due to cytokine storms, while this occurred for 0 of the 2 placebo subjects. Adverse event TGN1412 (N=6) Placebo (N=2) Patient in ICU due to Cytokine storm 6/6 (100%) 0/2 (0%) As Stephen Senn pointed out , Fisher's exact test results in a one-sided p-value of 0.0357 (i.e. above 0.025). Also, if you do an exponential time-to-event model using exact Poisson regression, you get a median unbiased estimate of 1.05 (95% CI -0.62 to $\infty$ ) for the log-hazard ratio with a two-sided p-value of 0.3308. So, two somewhat reasonable frequentist analyses would normally be interpreted as (ignoring that this analysis was not pre-specified etc.) having not enough data to reject the null hypothesis that the drug increases the likelihood of the cytokine storms. Nevertheless, when people talk about this trial, you will not here any doubt that the drug caused these adverse events. Why is that? Let's use historical discharges or deaths from intensive care units from around then (2001, the trial was in 2006) for the UK (both trial and historical data). That's probably an upper bound for the expected rate, because this is the general population including more frail individuals (rather than the young and healthy volunteers in the trial) and the ICU stays were for any case rather than for cytokine storms. From that I get a Gamma(1270614; 4808670538) prior for the control group exponential rate per patient year (probably reasonable to use an exponential distribution). If I take a Cauchy(0, 0.25) prior for the log-hazard ratio of TGN1412 vs. placebo, then I get a posterior median log-hazard ratio of 12.2 (95% CrI 11.3 to 13.0) with a posterior probability in excess of 99.999% that TGN1412 increased the hazard rate for the admission to critical care. I.e. the prior knowledge on the rarity of the specic adverse event (a cytokine storm requiring admission to an intensive care unit) in young and healthy individuals means that these adverse events have been attributed to the TGN1412, because we a-priori would expect to see zero such cases with very high probability in such a short small trial. The fact that we saw 6 cases in the TGN1412 out of 6 patients is so implausible unless the drug caused it, that people are very convinced of a causal drug effect in this case. Other examples were Bayesian methods make a huge difference is when your data tells you very little (or essentially nothing) about certain parameters in your model, but when there is prior information on these parameters. Especially when we do not know the exact value of the parameters, a Bayesian treatment often becomes important. E.g. a lot of phyisis constants such as the speed of light are known with so little error that for many purposes it makes very little difference whether we take a Bayesian approach that accounts for the uncertainty around them or whether plug in a constant. However, other quantities we know a decent amount about, but still have a non-negligible amount of uncertainty about. In those situations a Bayesian approach is a good way of propagating the uncertainty into an analysis.
