[site]: datascience
[post_id]: 94047
[parent_id]: 94022
[tags]: 
This question is definitely opinion-based and so is my answer, but let me try to clarify a few things: Don't count blindly on AI/ML to become more accurate in general, and even less for a particular project. Imho for your project to be future-proof, you need to test the current technology with a sample of your data (or some similar data) and make sure that the results are at least "encouraging", i.e. decent enough. If the result are terrible or cannot be obtained at all, then there's probably a problem with the whole design and it's unlikely that future technology will solve this. It's not always by providing more detailed information to ML that it gives better results, it strongly depends on the task. This is why I recommend testing first (see point 1). Technically it's always possible to downsize resolution but not the opposite, so from this point of view it's clear that the higher the resolution the better. A simple estimation says that with your characteristics a single daily video would require around 2GB, so 2 years would require around 1.5TB.
