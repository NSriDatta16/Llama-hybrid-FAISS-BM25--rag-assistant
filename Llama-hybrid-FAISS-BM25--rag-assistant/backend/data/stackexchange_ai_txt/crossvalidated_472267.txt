[site]: crossvalidated
[post_id]: 472267
[parent_id]: 472224
[tags]: 
An LSTM takes a time series as an "example," or "instance." The word "input" is overloaded, because an LSTM can be viewed as operating on a single timestep at a time or multiple examples of multiple time steps, or several different segments of the same time series, depending exactly on what you mean by "input." There are 26 channels and 100 units, so the LSTM layer's weight matrices are $26 \times 100$ . Matrix multiplication is used to take the 26 channels and represent them as 100 channels. If you want to think in terms of units instead of layers, then each of the 100 units has a vector of 26 weights, so that the dot-product with the 26 channels for one time-step represents the 26 input channels in a single channel. Then each of the 100 units has its own channel. All 100 units are used -- there's no padding or anything.
