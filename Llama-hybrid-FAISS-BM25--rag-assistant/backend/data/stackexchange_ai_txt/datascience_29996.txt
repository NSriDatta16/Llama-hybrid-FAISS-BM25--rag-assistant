[site]: datascience
[post_id]: 29996
[parent_id]: 29941
[tags]: 
The framework you describe is the Bandits framework. Bandits are algorithms that solve stateless MDPs. So the problem is not sequential in the sense that actions affect the transition to the next state. Take a look at a nice Contextual Bandits tutorial which is accompanied with Python Jupyter notebook. Please note that Contextual Bandits are a special category of Bandits but at least you will be exposed to the general Bandit idea and formalization. You can try Q learning but with the Rescorla-Wagner rule $r(a) - Q(a)$ as the reward correction $\gamma\max_a' Q(s',a')$ does not make any sense as there is no transition to a subsequent state $s'$.
