[site]: crossvalidated
[post_id]: 142382
[parent_id]: 142312
[tags]: 
I had this problem before. I think in the general case the average problem can happen when. Your final hidden layer blew up and all values are activated all the time. When all the values are 1 or 0 all the time. You basically just have the bias unit doing the lifting. And the bias unit can only predict the average at best. This can be cuased by wrong weight initialization or a step size that is too big. Is your stepsize = 50000? ` Using cross-entropy or squared error loss, when you should be using softmax
