[site]: crossvalidated
[post_id]: 99541
[parent_id]: 99527
[tags]: 
Using the vanilla implementation of Random Forest in R you would just do: library(randomForest) # load random forest package train_set = xmat[ymat==1,] # meaning you subset your xmat covariables to just # include those which are labeled rf_model = randomForest(y=ymat,x=xmat,ntree=500) # train random forest model ?randomForest # to understand the training funcion usage plot(rf_model) # plot of error against number of trees grown cor(rf_model$predicted,ymat) # usual Pearson correlation between observed training values and OOB predictions imputation_set = xmat[ymat!=1,] # unlabeled data imputation_prediction = predict(rf_model,imputation_set) # fill in values You should definitely read about Random Forest before using them, they are relatively easy to understand and will help you a lot during this model building process. Random Forest scales well on large and/or high dimensional data. If you really have a huge amount of covariables or training observations you should consider using the paralellized version which is much faster and memory efficient. Although only available for Linux.
