[site]: crossvalidated
[post_id]: 373794
[parent_id]: 373782
[tags]: 
The first approach (i.e., lm() ) postulates that there are differences in the average happy_score per team. However, it still assumes that measurements within a team are uncorrelated. If teams are truly random (i.e., you have a sample of teams), theoretically this approach violates one of the assumptions of standard asymptotics that requires that the dimension of the parameter spaces does not change with the sample size. I am not totally familiar with lm_robust() but what I think it does is that it fits the model assuming independent error terms, and corrects the standard errors using a sandwich-type estimator. Two points regarding this approach: (1) if you have teams that miss the responses of some members (i.e., you have missing data), the derived results will only be valid under the missing completely at random assumption. (2) The sandwich estimator is known to protect against misspecification (i.e., here you have correlated data but you fit a misspecified model that ignores the correlations) but at the expense of power. The last approach explicitly accounts for the correlations by including the random effect per team. Under the assumption that the postulated correlation structure is correct, this will provide you with correct inferences, and also be valid under the missing at random assumption (that is less stringent than the missing completely at random).
