[site]: datascience
[post_id]: 128460
[parent_id]: 128101
[tags]: 
1. Why are the PI outputs (gray lines) so different for certain setups like the below? As it is mentioned in the addressed referenced book by R. J Hyndman & G. Athanasopoulos in skforecast documentation, gray lines are: “blocked bootstrap” , where contiguous sections of the time series are selected at random and joined together. However, the estimated parameters will be different , so the forecasts will be different even if the selected model is the same. This is a time-consuming process as there are a large number of series. Bootstrapped time series is used to improve forecast accuracy. Note: A similar technique is used in Ensemble Learning in random forest algorithm as a : : Bootstrap - Allow Bootstrapped Sampling for each training subset of the feature : ✍️ Definition - Random sampling with replacement ✍️ it bootstraps a selection of rows for each split. This means that the trees are trained on a subset of features and a subset of rows of data. As a result, the trees are very different from each other see the details in this workaround 2. How final PI output (pink interval) is computed out of the rest of the Bootstrapped PIs? based on documentation using : Bagged forecasts If we produce forecasts from each of the additional time series, and average the resulting forecasts, we get better forecasts than if we simply forecast the original time series directly. This is called “bagging” which stands for “bootstrap aggregating” . Finally, we average these forecasts for each time period to obtain the “bagged forecasts” for the original data. Figure 12.22: Comparing bagged ETS forecasts (the average of 100 bootstrapped forecasts in orange) and ETS applied directly to the data (in blue). ref
