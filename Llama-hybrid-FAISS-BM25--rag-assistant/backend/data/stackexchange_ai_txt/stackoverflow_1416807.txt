[site]: stackoverflow
[post_id]: 1416807
[parent_id]: 1416215
[tags]: 
It really is difficult to design Unicode support for the future, in a programming language right from the beginning. Java is one one of the languages that had this designed into the language specification. However, Unicode support in v1.0 of Java is different from v5 and v6 of the Java SDK. This is primarily due to the version of Unicode that the language specification catered to, when the language was originally designed. Java attempts to track changes in the Unicode standard with every major release. Early implementations of the JLS could claim Unicode support, primarily because Unicode itself supported 65536 characters (v1.0 of Java supported Unicode 1.1, and Java v1.4 supported Unicode 3.0) which was compatible with the 16-bit storage space taken up by characters. That changed with Unicode 3.1 - its an evolving standard, usually with more characters getting added in each release. The characters added later in 3.1 were called supplementary characters . Support for supplementary characters were added in Java 5 via JSR-204 ; Java 5 and 6 support Unicode 4.0. Therefore, don't be surprised if different programming languages implement Unicode support differently. On the other hand, PHP(!!) and Ruby did not have Unicode support built into them during inception. PS: Support for v5.1 of Unicode is to be made in Java 7 .
