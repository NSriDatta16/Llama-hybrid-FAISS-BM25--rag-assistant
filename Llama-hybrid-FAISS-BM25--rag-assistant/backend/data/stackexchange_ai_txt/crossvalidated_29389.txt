[site]: crossvalidated
[post_id]: 29389
[parent_id]: 
[tags]: 
Multivariate time series model evaluation with conditional moments

Consider multivariate time series models that estimate potentially time-varying conditional means, variances, and correlations (one type of model might be a VAR(p)+Garch(1,1)+DCC Gaussian Copula model). I will simulate from one "true" distribution and compare other potential models to it. I don't particularly care about RMSE because I care just as much about the conditional covariance matrix as the conditional means. For the sake of simplicity, assume that the conditional mean and conditional covariance are sufficient to explain "true" distribution. I can calculate the conditional mean vector and conditional covariance matrix of each model and the true model at any given point in time. Alternately, I can calculate the forecasted conditional means and covariances on a rolling basis. Is there any reason to prefer the Kullback-Leibler divergence or Bhattacharyya distance as comparison methodologies or should I just do both? Alternately, is there a different method that is even more appropriate. In the constant multivariate Gaussian case, is it possible to make statistical inferences based on these comparison methodologies, such as that the divergence is not statistically bigger than zero or that the divergence of one is bigger than another? If I calculate the conditional means and variances at any given point in time, I could calculate the comparison statistic in each period. This would produce a time series of divergences/distances. Is it reasonable to make statistical inferences in this case by just assuming it is a typical time series?
