[site]: crossvalidated
[post_id]: 439528
[parent_id]: 
[tags]: 
Parameter estimation when the likelihood function does not exist

The observations $Z_1,Z_2\cdots$ are i.i.d. We have $$Z_k = \sum_{i=1}^\infty \frac{X_{ki}}{2^k}.$$ where the $X_{ki}$ 's are i.i.d. with a Bernouilli $(p)$ distribution. If $p=\frac{1}{2}$ then $Z_k$ is Uniform on $[0, 1]$ . Otherwise $Z_k$ does not have a density, see here . Yet the solution is trivial in this case: $p$ is just the proportion of binary digits of $Z_k$ that are equal to $1$ . So you can directly estimate this proportion by looking at the binary digits of your observations. But how would you do if you were to use standard statistical techniques to solve this problem? You could simulate the $Z_k$ 's using various values for $p$ and see the one that provides the best fit with your data. But are there any techniques, other than non-parametric ones, that could solve this problem in a "traditional" way? Likewise, how would you test (say) $p=0.75$ vs. $p\neq 0.75$ ? The density for the null hypothesis does not exist because the CDF is nowhere differentiable, it seems. Distribution of $Z_k$ First, note that $E(Z_k) =p$ and $\mbox{Var}(Z_k) =p(1-p)/3$ . We assume that $0 . Let us denote as $S$ the set of normal numbers in $[0, 1]$ . This set has Lebesgue measure equal to $1$ . However, the set of non-normal numbers in $[0, 1]$ is dense in $[0, 1]$ despite the fact that its Lebesgue measure is $0$ . If $p=\frac{1}{2}$ , then $Z_k$ is uniform on $S$ , and thus, does not even a density in the classical sense, since $S$ if full of holes: for instance, none of the rational numbers in $[0, 1]$ belong to $S$ because they are periodic numbers, thus their $X_{ki}$ 's are not independent in this case. If $p\neq \frac{1}{2}$ , then $Z_k$ 's support domain has Lebesgue measure $0$ yet it is dense in $[0, 1]$ . Its CDF, when $p=0.75$ , is pictured below. If it had a density, it would like this: Moments of $Z^k$ Let $F$ denote the distribution, $Z$ any of the $Z_k$ 's, and $X$ any of the $X_{ki}$ 's. The following functional equation must be satisfied: $F_Z = F_{(X+Z)/2}$ . Thus we have $E(Z^n) = 2^{-n} E((X+Z)^n)$ which leads to the following recursion formula for the moments: $$E(Z^n)=\frac{p}{2^n-1} \sum_{i=1}^n \frac{n!}{i!(n-i)!}E(Z^{n-i}).$$ This yields $$E(Z) = p \\ E(Z^2) = \frac{p}{3}(1+2p)\\ E(Z^3) = \frac{p}{7}(1+4p+2p^2)\\ E(Z^4) = \frac{p}{105}(7+46p + 44p^2+8p^3) $$ More generally, if $s\geq 0$ then $$E(Z^s) = \frac{1}{2^s} E((X+Z)^s) \Rightarrow E(Z^s) = \frac{p}{2^s-1+p}E((1+Z)^s).$$ Example Let $Z_k =\{ 2^k \pi/4\}$ be the observations, that is, the data. Here the brackets represent the fractional part function. I estimated the first few moments using the first 1,000 $Z_k$ 's. The result is $0.506$ for the mean, and $0.799$ for the variance. The theoretical values are $1/2$ and $1/12$ if $p=1/2$ . We can thus conclude that $p$ is not statistically different from $1/2$ . Note that $p$ can be estimated, using the moment method, by averaging the $Z_k$ 's. Also here the $Z_k$ 's are auto-correlated. The theoretical lag-1 autocorrelation is $1/2$ .
