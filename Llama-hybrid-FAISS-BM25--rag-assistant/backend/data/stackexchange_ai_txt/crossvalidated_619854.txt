[site]: crossvalidated
[post_id]: 619854
[parent_id]: 
[tags]: 
Implementing Logistic Regression: weights matrix becoming singular

I am implementing Logistic Regression via Iteratively Re-weighted Least Squares (in Rust for what its worth). The iterative procedure is: $$ \mathbf{w}_{k+1} = (\mathbf{X}^T \mathbf{S}_k \mathbf{X})^{-1} \mathbf{X}^T (\mathbf{S}_k \mathbf{X} \mathbf{w}_k + \mathbf{y} - \mathbf{\mu}_k) $$ I am running into the problem of the diagonal weights matrix ( $\mathbf{S}_k$ ) becoming singular (the diagonal entries are converging to zero). Are there any references that specifically discuss how to deal with this issue ? The only solution I found was to add a slight adjustment to the diagonal entries, so something like: $$ \mathbf{S}_k + \epsilon \mathbf{I} $$ However, many choices of $\epsilon$ that I have tried cause it to either diverge (overshoot the solution; start way off) or take a very long time to converge. This "solution" seems hacky to say the least.
