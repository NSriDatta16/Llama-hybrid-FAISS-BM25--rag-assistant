[site]: stackoverflow
[post_id]: 5301117
[parent_id]: 
[tags]: 
How to avoid fragmented database storage by very often updates?

When I have the following table: CREATE TABLE test ( "id" integer NOT NULL, "myval" text NOT NULL, CONSTRAINT "test-id-pkey" PRIMARY KEY ("id") ) When doing a lot of queries like the following: UPDATE "test" set "myval" = "myval" || 'foobar' where "id" = 12345 Then the row myval will get larger and larger over time. What will postgresql do? Where will it get the space from? Can I avoid that postgresql needs more than one seek to read a particular myval-column? Will postgresql do this automatically? I know that normally I should try to normalize the data much more. But I need to read the value with one seek. Myval will enlarge by about 20 bytes with each update (that adds data). Some colums will have 1-2 updates, some 1000 updates. Normally I would just use one new row instead of an update. But then selecting is getting slow. So I came to the idea of denormalizing.
