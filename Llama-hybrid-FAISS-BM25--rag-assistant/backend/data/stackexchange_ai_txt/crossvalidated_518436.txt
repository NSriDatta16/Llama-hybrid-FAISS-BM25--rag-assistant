[site]: crossvalidated
[post_id]: 518436
[parent_id]: 518283
[tags]: 
The data itself is often the same for both approaches. In practice, the Bayesian or frequentist philosophies determine different estimators to analyze that data. Conversely, some estimators can be rationalized by either philosophy. Within each approach, modeling choices are needed to take the model to data, that can sometimes be tested for out-of-sample predictive accuracy. This is particularly true of "empirical Bayes" estimators that try to fit the hyperparameters using data. For this reason, it is useful to think of the broad statistical properties of the estimators, regardless of their original rationale. I will mention two that are particularly salient: (1) Admissibility: According to Wikipedia "an admissible decision rule is a rule for making a decision such that there is no other rule that is always "better" than it (or at least sometimes better and never worse)." Admissibility is a very basic criterion that rules out estimators that are clearly bad (e.g. calculating a mean with a single observation, discarding data for no reason, scaling the data in a weird way, etc.). It is well known that Bayes estimators are admissible, and hence have minimal guarantees. What's interesting is that the set of admissible estimators can be very large . From a Bayesian point of view, different priors can induce different admissible estimators. This is analogous to the concept of "efficiency" in economics. Two allocations are efficient if they don't "waste" resources, but can use different inputs depending on the planner's preferences: there is an efficiency frontier. An agnostic frequentist might view the use of priors as a way to describe a class of admissible estimators, that impose different preferences over the weight given to new information. (2) Regularization: A prior can also be viewed as a form of regularization (reducing the complexity) in predictive models. This facilitates the estimation of complicated models with small sample sizes relative to the number of parameters. For instance this article shows that Ridge (a form of penalized linear regression) can be motivated as a bayesian estimator with a normal prior, and the tuning parameter as a hyperparameter. Hence these can be viewed as different routes to regulate the bias/variance trade-offs. Similar analogies have been found for Lasso and other recently proposed high-dimensional methods. There are other theoretical connections. For example, the Bernstein-von-Mises Theorem shows that the credible set of Bayesian parametric models can be close to frequentist confidence intervals in large samples. As an agnostic practitioner you want to either design tests of validity (even as a thought experiment) that contain tangible, replicable metrics (e.g. out-of-sample MSE), that can help you decide between alternative estimators.
