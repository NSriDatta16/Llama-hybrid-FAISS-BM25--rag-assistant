[site]: crossvalidated
[post_id]: 286259
[parent_id]: 
[tags]: 
How are the common ways to combine classification results from different classifiers?

I am building a method to classify some data. There are 4 classes (A,B,D,F). I can achieve only 48% of correct classifications if I use bagged tree. I have tried many other classifiers(e.g. SVM, ensemble KNN, neural network, etc), but bagged tree is the best. For this classification, there is a fun point. 'A' needs to be classified correctly as much as possible. B,D & F are not important. If the result is 'A', but the prediction is not 'A'. It would be 'NOT good'. The worst case (very bad) is that if it is NOT 'A' but the predicted result is A. I want to combine the results form a few different classifiers (fusion) to boost the overall result. Any suggestion of how to do that? If you have any other suggestion to do a better prediction, please advise too.
