[site]: crossvalidated
[post_id]: 89682
[parent_id]: 
[tags]: 
How to compute marginals in Sum-Product Networks?

This should be fairly easy, but for some reason i'm having hard time getting it to work and I've spent a long time trying to figure it out myself. In the last paragraph of page 4 of the original Sum-Product Networks paper the authors described how to compute the posterior marginals of sum nodes, i.e $$P(Y_k = i | e) \propto w_{k,i} \frac{\partial S}{\partial S_K}\,,$$ where $Y_k$ is a sum node and $i$ is an edge to one of its child nodes. Let's assume that I've a very simple network like this one: and I want to compute the marginal of the sum node given an evidence (which can be either: $e=\text{x}$ or $e=\text{not_x}$). The partial derivative of the sum node should be $1$ because it's the root: $$\frac{\partial S}{\partial S_{sum}} = 1$$ then the marginals should be: $$P(sum = 1 | e) \propto w_{sum,w_1} $$ $$P(sum = 2 | e) \propto w_{sum,w_2} $$ (where 1 and 2 referees to the edges) My problem is that these two equations don't depend on the evidence and they give the same results regardless of what the evidence is. I tried with different structures and I keep getting the same results. This is important because Sum nodes are seen as hidden variables in Sum-Product Networks and computing their posterior marginals is an important step in order to implement the Expectation-Maximization learning algorithm. How can I correctly compute the posterior marginal of the sum nodes?
