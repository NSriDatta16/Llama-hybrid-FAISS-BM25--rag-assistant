[site]: crossvalidated
[post_id]: 378277
[parent_id]: 189016
[tags]: 
Take throwing a dice for example, the result $X$ can be a random number in $1,2,..,6$ . When we do Bayesian parameter estimation, we can assume the probability of throwing a $1$ is $p_1$ , throwing a $2$ is $p_2$ ,..., and so on. Hence, we want to estimate $(p_1,p_2,...,p_6)$ . If we throw the dice $N$ times, we get $1$ for $c_1$ times, $2$ for $c_2$ times. We denote the result as a vector $\textbf{c}=(c_1,c_2,..,c_6)$ , where $c_1+c_2+...+c_6=N$ . Then the likelihood will be $\prod_{j=1}^6p_{j}^{c_j}$ ,which is exactly multinomial distribution. If $N=1$ , only one dimension of $\textbf{c}$ will be 1, the rest will be 0. As you can see, this feature $X$ is a multinomial distribution. Youtub videos Bayesian Naive Bayes provide detailed explanation of multinomial Naive Bayes which I found very useful.
