[site]: datascience
[post_id]: 5066
[parent_id]: 5050
[tags]: 
It sounds to me like you have a binary classification problem (classifying good vs. bad documents for some definitions of good and bad) and the words are being used as features or "signals" for what predicts good vs. bad documents. One thing you might try is to measure some type of correlation statistic between unigrams and each class you're interested in. This preserves your requirement of measuring occurrences of words given a target class over groups of documents. So, to be a bit more concrete, you could split your documents into two sets (good and bad), and then tokenize your documents to obtain individual terms. From here you could really choose whichever term weighting scheme you like (TF, TF normalized against the length of the document, TF-IDF) and measure your correlation statistic between all these unigrams and the class of interest. You could then produce a ranking based on the correlation coefficients for each term, and take the top- k terms. Some correlation statistics you might try could be Chi-squared (which would measure "lack of independence" between terms and a class). There's also a nice implementation of Chi-squared test for feature selection in Python's Scikit-Learn machine learning library that may be a place to start for this task. Hopefully, that helps!
