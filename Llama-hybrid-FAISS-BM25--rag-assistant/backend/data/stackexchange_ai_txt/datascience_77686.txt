[site]: datascience
[post_id]: 77686
[parent_id]: 77592
[tags]: 
There are a few points that I would like to mention and I believe that will serve as an answer to the question - 1. SVM work only the way we know i.e. finding the maximum margin support. So it will treat the image like a "1 x N" dimensional data just like any other data. 2. It performs well with sparse high dimension data (when data volume is small ) as compared to other Classifier. This typically happens with many image data. So if you try it on MNIST(~10K samples) data it will perform better than the Decision tree. 3. In the classical image processing approach, we first extract the key-points and then used classifiers to identify images. Data is not sparse, so I think it depends on Features Vs Data count which model can perform best. [Example] , here SVM works better than KNN. Still, SVM has other benefits e.g. sparseness of solution, Mathematically derived solution i.e. not solved for local optima. References - Researchgate Stats.SE
