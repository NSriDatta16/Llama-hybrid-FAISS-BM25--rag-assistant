[site]: crossvalidated
[post_id]: 467070
[parent_id]: 453956
[tags]: 
There are only two "principled" ways you can get out of your posited model that operate within the framework of the Bayesian paradigm. Once is to initially set a broader class of models, and give some non-zero prior probability for the alternative models in that class (i.e., have a prior probability less than one for your posited model class). The other is to observe some evidence that has zero density under all distributions in the posited model class, which then allows you to update to any belief you want ( see discussion here ). If you have assigned a prior probability of one to a class of models, and you never observe evidence that is inconsistent with those models, you can never "escape" that set of models within the Bayesian paradigm. Note that this is by design --- if you assign a prior probability of one to a set of models, you are saying that any alternative class of models has zero probability. In short, you are choosing to stick with your posited class of models no matter how strongly the evidence turns against them , so long as it is not inconsistent with those models. If you would like to have a principled "escape route" operating within the Bayesian paradigm, you will need to posit some broader class of alternative models and give it a non-zero prior probability. You could certainly give the alternative models a very low prior probability, so that they only become important a posteriori when the main model class starts to be (probabilistically) falsified by the data. Implementation in your problem: In the problem you raise, it would be usual to handle this by framing the problem as a Bayesian hypothesis test, with hypotheses: $$H_0: \mu_1 = c \mu_2 \quad \quad \quad H_A: \mu_1 \neq c \mu_2.$$ For example, under $H_0$ you could posit an overall model like this: $$\begin{aligned} X_{11}, X_{12}, ... , X_{1n} | \mu_2,\sigma_1^2,\sigma_2^2 &\sim \text{N}(c \mu_2,\sigma_1^2), \\[6pt] X_{21}, X_{22}, ... , X_{2n} | \mu_2,\sigma_1^2,\sigma_2^2 &\sim \text{N}(\mu_2,\sigma_2^2), \\[6pt] \mu_2 &\sim \text{N}(0, \eta^2), \\[6pt] \sigma_1^2 &\sim \text{Ga}(\alpha, \beta), \\[6pt] \sigma_2^2 &\sim \text{Ga}(\alpha, \beta), \\[6pt] \end{aligned}$$ and under $H_A$ you could posit an overall model like this: $$\begin{aligned} X_{11}, X_{12}, ... , X_{1n} | \mu_1,\mu_2,\sigma_1^2,\sigma_2^2 &\sim \text{N}(\mu_1,\sigma_1^2), \\[6pt] X_{21}, X_{22}, ... , X_{2n} | \mu_1,\mu_2,\sigma_1^2,\sigma_2^2 &\sim \text{N}(\mu_2,\sigma_2^2), \\[6pt] \mu_1 &\sim \text{N}(0, \eta^2), \\[6pt] \mu_2 &\sim \text{N}(0, \eta^2), \\[6pt] \sigma_1^2 &\sim \text{Ga}(\alpha, \beta), \\[6pt] \sigma_2^2 &\sim \text{Ga}(\alpha, \beta). \\[6pt] \end{aligned}$$ You can obtain the Bayes' factor for the above hypothesis test and use this to see how you update prior probabilities for the hypotheses to posterior probabilities. If the data makes $H_0$ highly implausible, this will manifest in a lower posterior probability for $H_0$ . Given some prior probability $\lambda = \mathbb{P}(H_0)$ for your posited subclass of models, you will be able to update this to a posterior probability.
