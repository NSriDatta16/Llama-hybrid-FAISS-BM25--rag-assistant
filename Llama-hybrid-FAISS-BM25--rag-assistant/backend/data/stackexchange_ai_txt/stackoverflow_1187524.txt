[site]: stackoverflow
[post_id]: 1187524
[parent_id]: 
[tags]: 
Hardware accelerated Unicode text rendering

I want to write a hardware accelerated text renderer using Free Type 2 to load the fonts, find the correct glyphs and their sizes etc. My plan to do this is to have a large texture containing glyphs (for a given font,size,etc) in video memory, and a table for each texture defining information about the contents of the texture in system memory. I can then use the table to build a vertex buffer to render the text. The problem I'm facing is the construction of the texture, it is not practical to create a texture for every glyph in Unicode, there just too many. For Ascii in the past I just built the texture in an image editor and then filled out the table as needed myself in advance, however for this I will need some kind of dynamic system that will get the glyphs needed, but also efficently cache them to avoid repeated uploads of the same glyph to vram...(some sort of least commonly used system I guess) Another problem is not all glyphs are the same size, I could split the texture up into a grid big enough for the largest glyphs (which I need some way to accurately work out) which makes fitting the glyphs onto the texture easy and replacing them with new glyphs (based on the least commonly used or something), however that leaves a lot of wasted space, but i'm not sure how to more efficiently pack them without running into problems with fragmentation as glyphs are swaped in and out... Also I assume updating the texture could stall the graphics hardware if the texture is still being used for some previous text, is this a correct assumption and how can I avoid it if its the case?
