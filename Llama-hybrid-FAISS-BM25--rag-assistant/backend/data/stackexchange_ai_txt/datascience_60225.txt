[site]: datascience
[post_id]: 60225
[parent_id]: 
[tags]: 
NLP based Data Preprocessing Method to Improve Disease Name Prediction Using CRF and Word Embedding

I built a model( using CRF along bi lstm) to Predict New Disease Name/Entities from medical text data but the problem is Disease name appears only 5,6 times in 1 text file but on average text file consists of 500-1000 words and this increase False negative (FN). when i test model on newly/real time Data set its only Predict 60% disease Names (On new dataset). In total i have 16000 words having (O-tags which represent Irrelevant words) and only 220 words having B-Disease tags. My model precision is 73 % and recall 61% f1 score is 66 %. Parameter on which i trained model params = { 'dim': 300, 'dim_chars': 100, 'dropout': 0.5, 'num_oov_buckets': 1, 'epochs': 75, 'batch_size': 7, 'buffer': 15000, 'char_lstm_size': 25, 'lstm_size': 100, 'words': str(Path(DATADIR, 'vocab.words.txt')), 'chars': str(Path(DATADIR, 'vocab.chars.txt')), 'tags': str(Path(DATADIR, 'vocab.tags.txt')), 'glove': str(Path(DATADIR, 'glove.npz')) } [file having complete code][1] Case #2 : When i trained model only on those lines which include disease Names this cause High False Positive . Q1 .Should i remove half lines from every text file so irrevlant dataset decrease. Q2. Or increase data set without removing half lines from a text file (increase train data set size rather using 80 files train data on 200 files) As i am using Neural Architectures for Named Entity Recognition and Neural Architectures Want more training data Set I am using following Code / Library , tf_ner i am using 2nd model mention in the library "chars_lstm_lstm_crf" This model include : GloVe 840B vectors Chars embeddings Chars bi-LSTM Bi-LSTM CRF Related Research Paper Neural Architectures for Named Entity Recognition by Lample et al. ==>>> Research Paper
