[site]: crossvalidated
[post_id]: 326080
[parent_id]: 326012
[tags]: 
k-NN classifier is much faster to train (because it does not really involve any training) than logistic regression, but much its predictions are much slower. The reason for this is the way k-NN works: For a new sample (in your case a 28x28 grayscale image) it needs to compute a distance to all samples in the training set. As you can see, the complexity of this depends on 1) size of the training set (60000 for MNIST), and 2) number of dimensions (784 for MNIST). You can easily check this in Python by wrapping your functions into the following code: import time as t ... t_start = t.clock() for i in xrange(50): # predict a sample using k-nn t_end = t.clock() print 'k-nn needs {}s for prediction of 1 sample'.format((t_end-t_start)/50) t_start = t.clock() for i in xrange(50): # predict a sample using logistic regression t_end = t.clock() print 'logistic regression needs {}s for prediction of 1 sample'.format((t_end-t_start)/50)
