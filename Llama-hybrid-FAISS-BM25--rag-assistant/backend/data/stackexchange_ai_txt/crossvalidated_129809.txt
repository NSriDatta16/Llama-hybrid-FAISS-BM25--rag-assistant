[site]: crossvalidated
[post_id]: 129809
[parent_id]: 129803
[tags]: 
Constant estimators/predictors have a use as benchmarks against which one judges the performance of "proper" estimators/predictors. A standard example is in the context of binary logistic regression, where we attempt to estimate conditional probabilities, exploiting the information that possibly resides in the regressors in order to predict better, in some sense, the probability related to the dependent variable, $$P(Y_i=1 \mid \mathbf x_i) = \Lambda(g(\mathbf x_i'\beta))$$ where $\Lambda()$ is the Logistic cumulative distribution function, and $g(\mathbf x_i'\beta)$ is the logit. But since we have the sample available, we can also very cheaply estimate the unconditional probability, $$\hat P(Y=1) = \frac 1n \sum_{i=1}^n y_i$$ We can then compare the predictive performance of $\hat P(Y_i=1 \mid \mathbf x_i) = \Lambda(g(\mathbf x_i'\hat \beta))$ against the "naive" (and constant) estimator $\hat P(Y=1)$. The former should do better, otherwise all the trouble we went into trying to use the information about the probability of $Y$ included in the $X$'s did not pay off. A CV thread exactly on this issue can be found here (look also at the comments).
