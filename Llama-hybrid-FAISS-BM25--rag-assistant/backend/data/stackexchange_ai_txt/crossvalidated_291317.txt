[site]: crossvalidated
[post_id]: 291317
[parent_id]: 291162
[tags]: 
In case you use U Mann-Whitney all mentioned ideas may be fair. You have to ask yourself, what is the most interesting/valuable information for you. We definietly don't have enough information about the structure of the tasks and of the collected data to make suggestions. Think what do you mean by easy/hard: In example if you take (a) first performance; or (b) mean of the 2 first performances for each person; you can check if both tasks were equally easy to understand (that may be important if usually one person will only have 1 chance to complete task, not several as in experimental conditions). Taking the best time may be your case if you are mostly interested in how fast it is possible to finish the task if one is trained. Taking avarage may be an option if you don't have such specific question, but then you should check the data. Maybe all good times differ just a bit, and if one (a)lost his focus; (b)made a mistake he had to correct; time was getting veery high. In this case mean can be deceiving. Maybe better to use median then? But then again, maybe it is important for you to evaluate, how time consuming is making mistakes and therefore how important is to be precise and fault-free (that's also a reason why task could be considered hard). Summing up - ask youself, what do you need. If distributions are symetrical and variances homogenous, there are no serious outliers, I guess you could go for mixed-design anova. This way you could see if: Considering all 6 attempts one task takes more time than the other. In whole sample (both task) there can be observed an effect of learning (further performances of each person are better). There is interaction between these (for instance considering all attempts you can't say any task takes longer, but A took less time in first 3 performances, B took much less time in the latter 3, so it is easier to master it).
