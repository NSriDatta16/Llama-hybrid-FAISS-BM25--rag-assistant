[site]: crossvalidated
[post_id]: 13149
[parent_id]: 
[tags]: 
How do you use draws from a Markov chain (Monte Carlo) for (bayesian) inference?

Say $X_0, X_1, ...$ is a Markov chain with the state space is $S=\{0,1,2,3,...,N-1\}$ and the transition probability $P(X_{n+1}=a+1 \mod N | X_n=a)$ = $P(X_{n+1}=a \mod N | X_n=a)$ = $P(X_{n+1}=a-1 \mod N | X_n=a)$ = $1/3$. (Ie, the markov chain is a random walk on $S$ with 1/3 probability of staying put, 1/3 probability moving plus or minus 1, with wrap around at the ends.) The limiting distribution is $\pi=(1/N,1/N,...,1/N)$, the uniform dist on $S$. As I understand it, the point of MCMC is to create markov chain such that the stationary distribution is the distribution you want to sample from. So the above chain could be used to sample from the uniform dist on $S$ (silly example, but bare with me). From my understanding, you starting with $x_0$ in $S$, 'burn-in' for some number of iterations, and subsequent iterations are draws from $\pi$. Several questions: First, how do you determine the length of the burn-in period? Even for the trivial example above, the time to the stationary distribution seems highly-dependent on how "mobile" the chain is (for example if $P(X_{n+1}=a \mod N | X_n=a)$ = .9, then it would take longer to spread out the distribution). After burn-in, what role does the dependency between draws play? The literature leads me to believe that I can use draws after the burn-in period as draws from $\pi$, but clearly the individual draws are still dependent on each other according to the transition rule... if you use too few draws with 'stay-still' probability of .9 as above, that's not uniform at all. This seems to mean that any calculation I do with draws (like approximating expectation) must be done of sets of draws greater than the burn-in period, but by how much?
