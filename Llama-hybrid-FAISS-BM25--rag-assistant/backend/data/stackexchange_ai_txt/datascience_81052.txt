[site]: datascience
[post_id]: 81052
[parent_id]: 81046
[tags]: 
Yes, teaching the model to expect a balanced distribution definitely will impact the results on the test set. Oversampling the minority class to balance the distribution will make the classifier more likely to predict that a given example is the minority class. Each iteration of gradient descent will push the model to a location where approximately half of the loss was contributed by examples from a minority class, which is not the situation when you're testing the model. There are a few things that I've seen that try to overcome this issue; focal loss is one example, where easily classified examples (predictions that the model has a lot of confidence in) contribute less to the loss than examples that are difficult to classify. Another approach that I've seen used is training a model on an artificially balanced training set, and then freezing all of the weights except the last layer (or last few layers), and finetuning the model on the true distribution. This usually increases the precision of the model. Accuracy is a misleading metric in this situation. As you noted, the model trained with a balanced training set performs worse when compared to a model that predicts everything as class A. Despite the fact that the accuracy of the second model is higher, the predictions don't make sense, and don't reflect the nature of the data. I would encourage you to examine the precision and recall of the two models to get an idea of where the model is doing poorly. Also, I think your validation split should have the same statistics as the test set. When the validation data doesn't reflect the test data, you're essentially optimizing your model to hit a different target than you actually want.
