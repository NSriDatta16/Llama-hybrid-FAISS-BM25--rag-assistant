[site]: crossvalidated
[post_id]: 572406
[parent_id]: 572325
[tags]: 
Machine learning does not require large amounts of data, it is just that the current bandwagon is for models that work on big data (mainly deep neural networks, which have been around since the 1990s, but before that it was SVMs and before that "shallow" neural nets), but research on other forms of machine learning has continued. My own personal research interests are in model selection for small data, which is far from a solved problem, just not in fashion. Another example would be Gaussian Processes, which are very good where a complex (non-linear) model is required, but the data are relatively scarce. It is a pity that there is so much focus on deep learning and big data as it means that a lot of new practitioners are unwaware of research that was done 20 or more years ago that is still valid today, and as a result they are falling into many of the same pitfalls that we found back in the day. Sadly ML and AI goes thorough these cycles of hype and doldrums. At the end of the day though, ML is just statistics, but a more computationally focussed branch of statistics.
