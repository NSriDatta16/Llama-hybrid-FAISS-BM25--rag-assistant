[site]: crossvalidated
[post_id]: 51500
[parent_id]: 51493
[tags]: 
NOT all the MCMC methods avoid the need for the normalising constant. However, many of them do (such as the Metropolis-Hastings algorithm), since the iteration process is based on the ratio $R(\theta_1,\theta_2)=\dfrac{\pi(\theta_1\vert x)}{\pi(\theta_2\vert x)}$, where $$\pi(\theta\vert x) = \dfrac{\pi(x\vert \theta)\pi(\theta)}{\int \pi(x\vert \theta)\pi(\theta) d\theta} = \dfrac{\pi(x\vert \theta)\pi(\theta)}{\pi(x)},$$ is the posterior distribution of $\theta$ given the sample $x$. Therefore, the normalising constant $\pi(x)$ in the denominator does not depend on $\theta$ and it cancels out when you calculate $R(\theta_1,\theta_2)$. This is $$R(\theta_1,\theta_2)= \dfrac{\pi(x\vert \theta_1)\pi(\theta_1)}{\pi(x\vert \theta_2)\pi(\theta_2)},$$ which does not involve the normalising constant, only the likelihood $\pi(x\vert \theta)$ and the prior $\pi(\theta)$.
