[site]: datascience
[post_id]: 106787
[parent_id]: 
[tags]: 
Why a CNN with decreasing filter layers sizes could perform better than a "regular one" with increasing sizes?

I did dozens (or probably hundreds) of tests and the best result with less total parameters(4 times or less) was a decreasing filter layers size architecture. This is a CNN for multiclass image classification, the dataset was more than 100.000 of images and each architecture was tested for at least 30 epochs, the structure was something like: model = tf.keras.Sequential([ layers.Conv2D(256, 3, padding='same', activation=lisht), layers.BatchNormalization(), layers.MaxPooling2D(), layers.Conv2D(128, 3, padding='same', activation=lisht), layers.BatchNormalization(), layers.MaxPooling2D(), layers.Conv2D(64, 3, padding='same', activation=lisht), layers.Flatten(), layers.Dense(512, activation=lisht), layers.BatchNormalization(), layers.Dense(3) ]) My understanding from the regular increasing structure would be that the smaller filters learn more general details, and the next ones with a bigger size will learn more complex details.So I cannot understand why the architecture mentioned above works better than its opposite (64,128,256,512). The images are CT-scans from different types of pneumonia, where 2 classes are very alike and one is very different from these. So the "work" of the NN is to understand many characteristics from each class (CTs have many layers, and some are very different even when from the same patient). The accuracy,F1 and Kappa are approximatelly 96% for all classes using a validation dataset with 20% of the data.
