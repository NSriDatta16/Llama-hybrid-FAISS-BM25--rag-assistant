[site]: crossvalidated
[post_id]: 487249
[parent_id]: 
[tags]: 
Why is learning slower for a sigmoid activation function in a neural network?

Andrew Ng in one of his deep learning course videos says that the sigmoid function acts as a slow learner in a neural network. My intuition is that the sigmoid as an activation function contributes very less to the change in the input for the tail part (after 4 in the fig). Please help me understand the intuition of the statement in detail. Thanking in anticipation.
