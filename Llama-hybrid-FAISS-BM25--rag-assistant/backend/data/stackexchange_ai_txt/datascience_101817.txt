[site]: datascience
[post_id]: 101817
[parent_id]: 54489
[tags]: 
Bias and variance are used to describe the predictions of models and they define if it is a good one or not. As a perfect model (low bias, low variance) does not exists, you often have to chose if you prefer a model with high bias/low variance or a model with low bias/high variance. This applis to the distribution of the predictions. Cross validation helps you have a more accurate value of your metrics (like accuracy), as the stochastic nature of the way models are calculated can give you different values for the metrics each time your run it: because of some randomness (random seeds) and because of the way the train/validation/test split is done... So it is good practice to do cross validation as the metrics will be averaged over several train/validation split and so the mean values will be more realistics to compare the different cases/models/parameters.
