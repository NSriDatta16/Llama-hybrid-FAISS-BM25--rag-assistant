[site]: crossvalidated
[post_id]: 445096
[parent_id]: 
[tags]: 
Understanding posterior probability (Bayesian inference)

I'm reading this online book and there is something unclear to me in this table where the posterior probability of each model computed as: $$\ P(model \ | \ data) = \frac{P(data \ | \ model) \times P(model)}{P(data) } $$ I understand $\ P(model) $ is a prior, and $\ P(data \ | model ) $ is just a binomial (probability of observing such data given the prior) distribution but what exactly is $\ P(data) $ ?
