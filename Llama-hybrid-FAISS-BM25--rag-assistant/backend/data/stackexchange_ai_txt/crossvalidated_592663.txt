[site]: crossvalidated
[post_id]: 592663
[parent_id]: 592535
[tags]: 
You've done an excellent job summarizing the key points, and you are to be lauded for readily catching the apparent discrepancy. It's simpler than that: The purpose of statistical models is to summarize and infer stochastic trends. A stochastic trend is one that's true on average. Men are on average stronger than women. Yes, there exists a woman who is stronger than a particular man. However, I can rigorously defend the notion that a randomly sampled man should be stronger than a woman. I use data to infer those choices, and if I have more data - more information specifically - I can refine my choices in scope and precision. "Big data" data science, therefore, is just a special case of statistics, I don't think it deserves special treatment. When presenting analyses to the FDA for a drug's approval, they are gravely concerned about generalizability. It's expected that the cohort that enrolls to a study is not representative of the general population, and it's known that undetected interactions and reduced compliance will negatively affect the estimated efficacy of treatment. To that end, many analyses are requested, to the tune of hundreds or even thousands of pages of tables, figures, etc. analyzing data at all levels of collection - even drug concentration in the blood, and clearance in liver and kidneys - so that there's a high degree of confidence that even if the trial results are not achieved per se, a favorable result is expected by adopting the drug in the population. Regarding the analysis of the one patient, if you make assumptions, you can in fact conduct tests or estimations of effect using specially tailored analyses.
