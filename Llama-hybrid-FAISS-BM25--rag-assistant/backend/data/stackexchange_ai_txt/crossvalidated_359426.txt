[site]: crossvalidated
[post_id]: 359426
[parent_id]: 
[tags]: 
Testing the significance of a difference between a sub-group and the total sample for a binomial distribution

Lets say I have a large group, which include a Bernoulli trial. Summing up the successes (x) and trials (n), I can get an estimate for the average event rate for the population: # This is R code: library(Misc) total_group_n = 5000 total_group_x = 500 binconf(total_group_x, total_group_n) #> PointEst Lower Upper #> 0.1 0.09198918 0.108625 And for a sub-group in the larger group: sub_group_n = 1000 sub_group_x = 200 binconf(sub_group_x, sub_group_n) #> PointEst Lower Upper #> 0.2 0.1763771 0.225919 Here is the question: What is an appropriate test to conclude that the average event rate for the sub-group is significantly different from that of the total group? Currently my strategy is to compare the PointEst of p for the subgroup to the confidence intervals for p for the total group. Is this correct? Should I be taking both the total-group, and sub-group confidence intervals into account at the same time? Is there a better way of doing this? Answers using packages in R (or base R) would be much appreciated.
