[site]: crossvalidated
[post_id]: 489178
[parent_id]: 489160
[tags]: 
The options under (d) are wrong, as a change score is associated with the baseline value. See this page , for example. Otherwise, it depends on what you mean by "taking into account the baseline measurement." You already note that option (a) doesn't do that at all. Option (b) looks only at the change from baseline as a function of Group. Based on your knowledge of the subject matter, do you think that is an adequate way to take the baseline into account? The advantage is all that you estimate is 3 parameter values. Option (c) allows for a slope in the relationship between T2 and T1, with the same slope for all Groups. (One could think of option (b) as forcing that slope to be 1 for all Groups.) But adding the slope to the model means you're now up to 4 parameter values to estimate. You could extend option (c) to include an interaction between Group and T1, allowing for different slopes among the Groups. That's a more complicated model, now with 6 parameter values to estimate by my count. So there is no clear answer about which is "best." More complicated models can capture more details about what's going on. The extra number of parameter values estimated from the data, however, can diminish the power to document truly significant relationships. A more complicated model and also lead to overfitting, building a model that fits your data set well but doesn't generalize to the underlying population. That can be a particular problem with small data sets. In many linear regression studies you typically want to have 10-20 cases per parameter estimated by the model, so if you have few cases you might need to restrict yourself to simpler models. Added in response to comments: This page and its links extensively discuss change scores, Option (b), versus regression of final values against initial values and a group indicator, Option (c). Allison provides a thorough comparison. As he says (page 106): It is unrealistic to expect either model to be the best in all situations; indeed, I shall argue that each of these models has its appropriate sphere of application. You will note, however, that Allison's arguments in favor of the change score in some circumstances are based on Option (b) without including the baseline value T1 as a predictor as Option (d) envisions. Consistent with that, Glymour et al report: ... in many plausible situations, baseline adjustment induces a spurious statistical association between education and change in cognitive score... In some cases, change-score analyses without baseline adjustment provide unbiased causal effect estimates when baseline-adjusted estimates are biased. Although Clifton & Clifton argue for including the baseline as a covariate when change scores are an outcome, they provide many cautions such as: Using change score as outcome has undesirable implications... By contrast, using post scores is always valid and never misleading. Both those arguments, for including baseline as a covariate and that "using post scores is always valid," seem to disagree with Allison's presentation in favor or change scores in some circumstances, as I understand it. Alternate approaches One might avoid some of these arguments with alternate modeling approaches. In some fields of study, errors tend to be proportional to observed values and effects are multiplicative rather than additive. If that's the case in your field of study, working with log-transformed values of T1 and T2 with a model like Option (c) provides a coefficient for T1 that expresses the fractional change in T2 per fractional change in T1, which is maybe even easier to explain than what you would get from the corresponding analysis of untransformed values. A mixed model that includes both T1 and T2 values as outcomes, with an indicator of the time of observation as a predictor, would have the advantage of putting T1 and T2 on equal footing. The fixed-effects regression approach in Option (c) implicitly assumes that T1 is known precisely and that all error is associated with T2. A mixed model with a random intercept for each individual could provide a way to "[take] into account the baseline measurement" that shares information from both T1 and T2 to get a potentially more reliable estimate of the true baseline condition rather than the particular observed baseline value . Looking over all of these different approaches, I think that this still comes down to what I said in the second paragraph: it depends on what you mean by "taking into account the baseline measurement." You have to use your knowledge of the subject matter to decide which accounting is most appropriate.
