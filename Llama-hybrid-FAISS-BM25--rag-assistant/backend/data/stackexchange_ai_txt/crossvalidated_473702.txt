[site]: crossvalidated
[post_id]: 473702
[parent_id]: 
[tags]: 
(Why) Is absolute loss not a proper scoring rule?

Brier score is a proper scoring rule and is, at least in the binary classification case, square loss. $$Brier(y,\hat{y}) = \frac{1}{N} \sum_{i=1}^N\big\vert y_i -\hat{y}_i\big\vert^2$$ Apparently this can be adjusted for when there are three or more classes. In another post on Cross Validated , it is mentioned that absolute loss is not a proper scoring rule. $$ absoluteLoss(y,\hat{y}) = \frac{1}{N} \sum_{i=1}^N\big\vert y_i -\hat{y}_i\big\vert $$ It seems similar enough to Brier score that it should be a proper scoring rule. Why is absolute loss not a proper scoring rule? Is absolute loss a proper scoring rule in the binary classification case that loses its "properness" when there are more than two output categories? Can absolute loss be wrestled with like Brier score to have a proper form when there are more that two classes? At least in the binary case, absolute loss has an easier interpretation than Brier score or the square root of Brier score in that it says the average amount by which a predicted probability differs from the observed outcome, so I would like to have a way for absolute loss to be proper.
