[site]: stackoverflow
[post_id]: 572234
[parent_id]: 571890
[tags]: 
First and foremost you must be able to quantify your options. You have also told us that the main usage pattern you're interested in is lookup , not insertion. Let N be the number of strings that you expect to be having in the table, and let C be the average number of characters in any given string present in the said table (or in the strings that are checked against the table). In the case of a hash-based approach , for each lookup you pay the following costs: O(C) - calculating the hash for the string you are about to look up between O(1 x C) and O(N x C) , where 1..N is the cost you expect from traversing the bucket based on hash key, here multiplied by C to re-check the characters in each string against the lookup key total time: between O(2 x C) and O((N + 1) x C) In the case of a std::map -based approach (which uses red-black trees), for each lookup you pay the following costs: total time: between O(1 x C) and O(log(N) x C) - where O(log(N)) is the maximal tree traversal cost, and O(C) is the time that std::map 's generic less<> implementation takes to recheck your lookup key during tree traversal In the case of large values for N and in the absence of a hash function that guarantees less than log(N) collisions, or if you just want to play it safe, you're better off using a tree-based ( std::map ) approach . If N is small, by all means, use a hash-based approach (while still making sure that hash collision is low.) Before making any decision, though, you should also check: http://meshula.net/wordpress/?p=183 http://wyw.dcweb.cn/mstring.htm
