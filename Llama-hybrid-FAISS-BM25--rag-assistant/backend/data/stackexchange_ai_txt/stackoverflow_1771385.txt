[site]: stackoverflow
[post_id]: 1771385
[parent_id]: 1771336
[tags]: 
A couple things come to mind. Do you need to keep that much data? If not, consider either creating an archive table if you want to keep it (but don't create it just to join it with the primary table every time you run a query). I would avoid using a temp table with so much data. See this article on temp table performance and how to avoid using them. http://www.sql-server-performance.com/articles/per/derived_temp_tables_p1.aspx It looks like you are missing an index on the server_id field. I would consider creating a covered index using this field and others. Here is an article on that as well. http://www.sql-server-performance.com/tips/covering_indexes_p1.aspx Edit With that many rows in the table over such a short time frame, I would also check the indexes for fragmentation which may be a cause for slowness. In SQL Server 2000 you can use the DBCC SHOWCONTIG command. See this link for info http://technet.microsoft.com/en-us/library/cc966523.aspx Also, please note that I have numbered these items as 1,2,3,4 however the editor is automatically resetting them
