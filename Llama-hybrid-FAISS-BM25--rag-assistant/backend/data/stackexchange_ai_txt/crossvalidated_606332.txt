[site]: crossvalidated
[post_id]: 606332
[parent_id]: 606102
[tags]: 
This is not a case of the learner (XGBoost here) not giving results summing up to one. What is returned by cross_val_score are the scores from our learner ( xgbc here) for each run of the cross-validation. In general, the performance attained in your test set is exceptionally high, note thought that if we use a dataset for model selection, we want another independent (or at least hold-out) dataset for evaluation. Here as we are using X in its entirety in cross_val_score we do get a somewhat optimistic view of xgbc 's performance as at least part of the X has been used to train the model as well as report is performance, at first instance, I would suggest using X_test / y_test . (Comparing different learners as a whole needs to be done via nested CV - see the CV.SE thread on: Nested cross validation for model selection as a starting point).
