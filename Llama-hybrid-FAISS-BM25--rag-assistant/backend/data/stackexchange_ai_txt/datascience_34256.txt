[site]: datascience
[post_id]: 34256
[parent_id]: 
[tags]: 
Is there any work done on reconfigurable convolutional neural networks?

Convolutional Neural networks are used in supervised learning meaning models are always "set in stone" after training (architecture and paramters) so this might not even be possible, but is there any research done on playing around with the data paths, model size (number of layers) and architecture during runtime, i.e after training is done, for instance creating a model that can be modified online to use less or more recources, skip layers or use portions of the model. There is some work done recently on creating flexible frameworks for training and designing networks, but that's always "offline". There is also an interesting paper on training two models, "big" and "little" for the same application and using an accuracy/power trade-off policy to deploy one of the two.
