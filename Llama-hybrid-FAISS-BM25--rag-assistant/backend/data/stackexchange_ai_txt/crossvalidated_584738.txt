[site]: crossvalidated
[post_id]: 584738
[parent_id]: 
[tags]: 
Q-learning function approximation issue

I am trying to get the Q value for each state-action using the Q-learning. The idea to approximate the Q is to use some ML algorithm whenever the state space is continuous. The problem that I have is that the actions are extremely correlated with the label, this makes the predictions depend only on the actions and neglect the state. How can I solve this issue? because whatever I put in the state as explanatory variable, the algorithm still neglect it. Can I approximate the Q function if my state space is continuous without adopting ML algorithm?
