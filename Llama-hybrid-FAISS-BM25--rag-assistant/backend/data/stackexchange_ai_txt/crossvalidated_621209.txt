[site]: crossvalidated
[post_id]: 621209
[parent_id]: 
[tags]: 
Cross-validation in a linear model of average time-series

I am trying to predict an average time-serie by linear combination of two average time-series using a linear-regression. To assess the quality of the fit, I'm using a 5-fold cross-validation by training the model on an average of 80% of the repetitions before testing it on the average of 20% of the left-out repetitions. However, I am not so sure 1) whether this approach is reasonable and 2) how to compute the R2 following this approach. So far, I have been averaging the true Y across repetitions and the predicted Y by averaging across folds to compute the R2. Here's some example code in Python: import numpy as np from sklearn.model_selection import KFold from sklearn.linear_model import LinearRegression from sklearn.metrics import r2_score reg = LinearRegression() n_splits=5 cv = KFold(n_splits=n_splits, shuffle=True) # generate fake data nrep = 160 # number of repetitions of the time-serie nt = 90 # number of time-steps X0 = np.random.normal(0,1,(nrep,nt)) X1 = np.random.normal(0,1,(nrep,nt)) Y = np.random.normal(0,1,(nrep,nt)) Yhat = np.zeros((n_splits,X0.shape[1])) for idx,(train, test) in enumerate(cv.split(X0)): X_train = np.vstack((X0[train].mean(0), X1[train].mean(0))).T # time x 2 Y_train = Y[train].mean(0) reg.fit(X_train, Y_train) X_test = np.vstack((X0[test].mean(0), X1[test].mean(0))).T Yhat[idx] = reg.predict(X_test) r2_score(Y.mean(0), Yhat.mean(0)) # take the r2 by averaging the predictions and the true values Is there any issue with this approach? Should I compute the R2 on each fold before averaging it?
