[site]: datascience
[post_id]: 17701
[parent_id]: 
[tags]: 
Convolutional Network for Text Classification

I am trying to train a convolutional neural network with Keras at recognizing tags for Stack Exchange questions about cooking. The i-th question element of my data-set is like this: id 2 title How should I cook bacon in an oven? content I've heard of people cooking bacon in an ov... tags oven cooking-time bacon Name: 1, dtype: object I have removed tags with BeautifulSoup and removed punctuation too. Since questions' content are very big I have decided to focus on titles. I have used sklearn CountVectorizer to vectorize words in titles. However they were more than 8000 words (excluding stop words). So I decided apply a part of speech tagging and retrieve only Nouns and Gerunds. from sklearn.feature_extraction.text import CountVectorizer vectorizer = CountVectorizer(stop_words='english') titles = dataframes['cooking']['title'] pos_titles = [] for i,title in enumerate(titles): pos = [] pt_titl = nltk.pos_tag(word_tokenize(title)) for pt in pt_titl: if pt[1]=='NN' or pt[1]=='NNS' or pt[1]=='VBG':# or pt[1]=='VBP' or pt[1]=='VBS': pos.append(pt[0]) pos_titles.append(" ".join(pos)) This represents my input vector. I have vectorized tags too and extract dense matrixes for both input and tags. tags = [" ".join(x) for x in dataframes['cooking']['tags']] Xd = X.todense() Y = vectorizer.fit_transform(tags) Yd = Y.todense() Split data into train and validation set from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(Xd, Yd, test_size=0.33, random_state=42) Now I am trying to train a Conv1D network from keras.models import Sequential from keras.layers import Dense, Activation,Flatten from keras.layers import Conv2D, MaxPooling2D,Conv1D, Embedding,GlobalMaxPooling1D,Dropout,MaxPooling1D model = Sequential() model.add(Embedding(Xd.shape[1], 128, input_length=Xd.shape[1])) model.add(Conv1D(32,5,activation='relu')) model.add(MaxPooling1D(100,stride=50)) model.add(Conv1D(32,5,activation='relu')) model.add(GlobalMaxPooling1D()) model.add(Dense(Yd.shape[1], activation ='softmax')) model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) model.fit(X_train, y_train, batch_size=32,verbose=1) But it gets stucked on a very low accuracy and it shows a barely increasing loss along the epochs Epoch 1/10 10320/10320 [==============================] - 401s - loss: 15.8098 - acc: 0.0604 Epoch 2/10 10320/10320 [==============================] - 339s - loss: 15.5671 - acc: 0.0577 Epoch 3/10 10320/10320 [==============================] - 314s - loss: 15.5509 - acc: 0.0578 Epoch 4/10 10320/10320 [==============================] - 34953s - loss: 15.5493 - acc: 0.0578 Epoch 5/10 10320/10320 [==============================] - 323s - loss: 15.5587 - acc: 0.0578 Epoch 6/10 6272/10320 [=================>............] - ETA: 133s - loss: 15.6005 - acc: 0.0550
