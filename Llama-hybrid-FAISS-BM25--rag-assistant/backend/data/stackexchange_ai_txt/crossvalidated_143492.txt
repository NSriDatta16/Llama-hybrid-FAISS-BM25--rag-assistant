[site]: crossvalidated
[post_id]: 143492
[parent_id]: 
[tags]: 
What is the mathematical underpinning of feedforward artificial neural network?

For a school project, I have implemented a 3 layer feedforward ANN with an RBF activation function that can be used to distinguish between different types of signals. I have a demonstration coming up soon and I am afraid that I will not be able to handle even trivial questions about ANNs from the other student audience such as "why does ANN work". A lot of people assumes that there exists some sort of underlying mathematical principle. For example, in SVM we have this construction of a hyperplane that separates different features. In HMM we have this markov model. But for ANN...I am truly unsure what mathematical model we are talking about here. The selection of layers, neurons, learning rate or even activation function seems a bit arbitrary. Through some search I have found that it is related to gradient descend algorithm where we are trying to find a set of weights that minimizes the potential energy function. But how can I describe this in a simple way that people can understand especially when I do not understand it too good myself?
