[site]: crossvalidated
[post_id]: 174638
[parent_id]: 
[tags]: 
Practical ways to deal with a large number of variables

Suppose you have 500,000 possible factors that could effect your response variable 'profit'. What is the best way to deal with this data set and how large should the data set be for analysis to be valid? I know there are a number of ways for dimension reduction such as PCA, but are there more 'practical methods' for dimensionality reduction? Also, if I wanted to use all 500,000 factors, how large should n be? I know you can model with P>n but is there a threshold?
