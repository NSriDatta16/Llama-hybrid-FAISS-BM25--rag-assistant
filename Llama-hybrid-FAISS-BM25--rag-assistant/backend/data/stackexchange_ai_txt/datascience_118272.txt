[site]: datascience
[post_id]: 118272
[parent_id]: 
[tags]: 
How to improve pytorch network to be more precise

I have a pytorch neural network which is being trained on data containing multiple financial values and some other non numeric values translated to numbers with self created logic (for example if company belongs to some sector, value = 10, if some not interesting sector, value = 1) I have training set from approx 1300 companies where 100 are marked with 1 as interesting, rest is -1 as not interesting I used this example as a skeleton https://visualstudiomagazine.com/Articles/2022/10/05/binary-classification-using-pytorch.aspx?Page=1 and then I tried to change number of hidden layers, set weights, use normalization but the results of prediction with new not clasified data is really bad my input data looks like this -4.8;7.3;-4.3;-9.0;-7.8;-6.3;-8.9;9.3;-6.4;-0.6;1.0;0.0;93.11;100.0;100.0;-1 42.0;11.1;33.4;22.1;23.4;20.8;-4.4;12.6;20.4;19.3;5.0;0.0;24.34;100.0;100.0;-1 94.3;22.4;39.5;76.1;0.0;66.9;-3.0;21.0;51.7;23.4;1.0;0.0;46.1;100.0;100.0;-1 1.0;0.4;0.0;-13.4;0.0;-5.1;0.5;-14.0;-5.8;-6.0;0.0;3.0;41.2;100.0;100.0;-1 -12.6;5.2;-7.0;-16.2;-17.1;-16.0;-2.1;-0.8;-15.7;-9.2;2.0;0.0;35.3;100.0;1.0;-1 -18.0;10.1;-13.3;24.6;-21.0;-26.3;4.9;8.7;-23.9;-25.5;1.0;0.0;33.2;100.0;100.0;1 18.4;-9.0;43.5;0.2;-6.0;-5.9;-10.4;5.2;-4.9;28.7;1.0;1.0;73.11;100.0;100.0;-1 0.0;3.0;-25.2;0.0;0.0;0.0;-7.6;21.7;-26.2;-20.4;0.0;0.0;2.1;10.0;100.0;-1 7.9;7.7;-1.4;3.3;5.5;6.4;-3.4;1.6;-2.7;0.1;1.0;0.0;49.41;100.0;100.0;-1 0.0;20.5;8.9;0.0;3.4;0.0;5.0;5.5;3.8;-7.6;1.0;0.0;22.22;10.0;100.0;-1 -4.7;1.9;-15.5;-12.4;0.0;-9.7;-11.8;2.3;-12.0;-9.6;2.0;0.0;27.9;100.0;1.0;-1 -4.4;0.7;4.0;-13.5;-15.6;-4.1;-7.5;-3.9;1.6;12.7;2.0;0.0;46.1;100.0;100.0;-1 and this is definition of the net class Net(torch.nn.Module): def __init__(self): super(Net, self).__init__() self.hid1 = torch.nn.Linear(15, 20) self.hid2 = torch.nn.Linear(20, 10) self.hid3 = torch.nn.Linear(10, 5) self.oupt = torch.nn.Linear(5, 1) torch.nn.init.xavier_uniform_(self.hid1.weight) torch.nn.init.zeros_(self.hid1.bias) torch.nn.init.xavier_uniform_(self.hid2.weight) torch.nn.init.zeros_(self.hid2.bias) torch.nn.init.xavier_uniform_(self.hid3.weight) torch.nn.init.zeros_(self.hid3.bias) torch.nn.init.xavier_uniform_(self.oupt.weight) torch.nn.init.zeros_(self.oupt.bias) def forward(self, x): z = torch.tanh(self.hid1(x)) z = torch.tanh(self.hid2(z)) z = torch.tanh(self.hid3(z)) z = torch.sigmoid(self.oupt(z)) return z I am new to this so any hints how to change my approach is really welcomed
