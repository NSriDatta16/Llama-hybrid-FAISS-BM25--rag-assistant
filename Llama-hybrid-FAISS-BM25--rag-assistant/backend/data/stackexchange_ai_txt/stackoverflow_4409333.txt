[site]: stackoverflow
[post_id]: 4409333
[parent_id]: 
[tags]: 
Average number of intervals from an input in 0..N

The question sprang up when examining the "Find the K missing numbers in this set supposed to cover [0..N]" question. The author of the question asked for CS answers instead of equation-based answers, and his proposal was to sort the input and then iterate over it to list the K missing numbers. While this seems fine to me, it also seems wasteful. Let's take an example: N = 200 K = 2 (we will consider K missing elements: 53, 75 The "sorted" set can be represented as: [0, 52] U [54, 74] U [76, 200] , which is way more compact than enumerating all values of the set (and allows to retrieve the missing numbers in O(K) operations, to be compared with O(N) if the set is sorted). However this is the final result, but during the construction the list of intervals might be much larger, as we feed the elements one at a time.... Let us, therefore, introduce another variable: let I be the number of elements of the set that we fed to the structure so far. Then, we may at worst have: min((N-K)/2, I) intervals (I think...) From which we deduce that the number of intervals reached during the construction is the maximum encountered for I in [0..N], the worst case being (N-K)/2 thus O(N) . I have however a gut feeling that if the input is random, instead of being specially crafted, we might get a much lower bound... and thus the always so tricky question: How much intervals... in average ?
