[site]: crossvalidated
[post_id]: 472221
[parent_id]: 472198
[tags]: 
This is going to be a fairly general purpose solution to the problem, but I'm going to name drop some ideas. Your computer model is essentially $$ \mathbf{y} = f(\mathbf{x}) $$ Where $\mathbf{x}$ has approximately a dimension of $160$ and $\mathbf{y}$ is of dimension $10,000$ (approx). Your problem is quite high dimensional, I'm assuming your code is deterministic. The first think you should do is perform PCA on the $\mathbf{y}$ space to reduce it's dimension dramatically. There is a lot of info on PCA online, once you have performed the PCA call these new reduce dimension outputs $\mathbf{z}$ where $dimension(\mathbf{z}) . I suspect you could do some kind of dimension reduction of $\mathbf{x}$ too, but $200$ dimensions might not be too difficult. Now the simulation code is reasonably expensive, you're going to need some kind of surrogate model to make the computation feasible, for a general overview of surrogates see wikipedia or this recent open source book by Bobby Gramacy , he is one of the world's leading experts on surrogates. Since your problem is quite high dimensional you're probably going to want to build something like a Neural Network, a polynomial fit or perhaps a generalised additive model (GAM). A Gaussian process surrogate might not work very well here (although they're my go-to). To build your surrogate (this might be a Gaussian process, a polynomial, neural network) by running the model at lots of different inputs (you will need to choose these carefully, e.g. by a Maximin Latin Hypercube design). We will now run the computer model lots of times and obtain data $(\mathbf{x}_i,\mathbf{y}_i)$ ; reduce the dimension of the $\mathbf{y}_i$ using the exact same algorithm as you did for $\mathbf{y}$ . Our aim is to predict $\mathbf{z}$ using some kind of surrogate, we have data $(\mathbf{x}_i, \mathbf{z}_i)$ train your surrogate on this data. Denote predictions from the surrogate to be $\hat{\mathbf{z}}(\mathbf{x})$ We then want to minimise $$\Omega(\mathbf{x}) = ||\mathbf{z}_i - \hat{\mathbf{z}}(\mathbf{x})|| $$ where $|| \cdot ||$ is some metric in the $\mathbf{z}$ space, e.g. euclidean distance. I guess we are now at the point of answering your question: how to acutally minimise this thing. In the past I've used the Nelder-Mead method with good success. There is an R implementation of Nelder-Mead and it's probably available in whatever programming language you're using. The optimisation will give you $$\hat{\bf{x}}_z =\text{argmin}_{\mathbf{x} \in \mathcal{M}} || \mathbf{z}_i - \hat{\mathbf{z}}(\mathbf{x}) || $$ This will not be the ''true'' minimum $$ \hat{\bf{x}} =\text{argmin}_{\mathbf{x} \in \mathcal{M}} || \mathbf{y}_i - \mathbf{y}(\mathbf{x}) || $$ but we frequently have to make sacrifices in these high-dim settings. As with any complex optimisation, run the optimisation a few times from different starting points to assess convergence. Finally, check that your optimal value $\hat{\mathbf{x}}_z$ is appropriate by computing $\mathbf{y}(\hat{\mathbf{x}}_z)$ against $\mathbf{y}$ ; the ''true'' values.
