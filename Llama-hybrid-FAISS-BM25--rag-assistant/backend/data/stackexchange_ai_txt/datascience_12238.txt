[site]: datascience
[post_id]: 12238
[parent_id]: 12234
[tags]: 
While there are well known techniques like down sampling for dealing with imbalanced classes (this is common in the finance industry where bankruptcies occur around only 1-3% of the time), I think in your case the model type will be much more important. If you are prioritizing explanatory power over predictive power or if you have a small data set, then logistic regression is fine. However, if you have a large dataset (which you have) and if you care more about predicting (which it sounds like you do) then you should pick a more advanced type of model. Some good examples: random forest, gradient boosting, and support vector machines. Tree based methods likes gradient boosting and random forests are able to identify variable interactions that you would have discover manually / yourself if you went with logistic regression. These models are easily accessible in R (caret), Python (scikit-learn), or Java/Scala (Spark's ML lib or Weka).
