[site]: crossvalidated
[post_id]: 343419
[parent_id]: 
[tags]: 
Variance of "an observation" and problem 5.9.8 in BDA by Gelman, et. al

I would like to understand problem 5.9.8 in Bayesian Data Analysis by Gelman, et al. . In particular the problem asks: ... create a bimodal prior density for a normal mean, that is thought to be near $1$, with a standard deviation of $0.5$, but has a small probability of being near $−1$, with the same standard deviation. If the variance of each observation $y_1,...,y_{10}$ is known to be $1$, and their observed mean is $y=−0.25$, derive your posterior distribution for the mean, making a sketch of both prior and posterior densities. What does "the variance of each observation ... is known to be $1$" mean? More specifically, the solution to this problem requires computing $P(y_1,..., y_{10})$ for each of these two normal distributions given the knowledge that $\overline{y}=-0.25$. My instinct was to do this using the $t$-distribution, interpreting the "variance" statement as "the sample variance." But that does not seem to be consistent with the solutions available on the web: http://www.stat.columbia.edu/~gelman/book/solutions2.pdf In which they state that $P(y)=F(-0.25,\; \pm 1,\; 0.5^2+1/10)$ where $F$ is the normal probability distribution with mean $\pm 1$ (in the two cases) and variance $0.5^2+1/10$.
