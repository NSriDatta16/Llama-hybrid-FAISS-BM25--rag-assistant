[site]: crossvalidated
[post_id]: 81300
[parent_id]: 81282
[tags]: 
The two approaches (meta-analysis and Bayesian updating) are not really that distinct. Meta-analytic models are in fact often framed as Bayesian models, since the idea of adding evidence to prior knowledge (possibly quite vague) about the phenomenon at hand lends itself naturally to a meta-analysis. An article that describes this connection is: Brannick, M. T. (2001). Implications of empirical Bayes meta-analysis for test validation. Journal of Applied Psychology, 86(3) , 468-480. (the author uses correlations as the outcome measure for the meta-analysis, but the principle is the same regardless of the measure). A more general article on Bayesian methods for meta-analysis would be: Sutton, A. J., & Abrams, K. R. (2001). Bayesian methods in meta-analysis and evidence synthesis. Statistical Methods in Medical Research, 10(4) , 277-303. What you seem to be after (in addition to some combined estimate) is a prediction/credibility interval that describes where in a future study the true outcome/effect is likely to fall. One can obtain such an interval from a "traditional" meta-analysis or from a Bayesian meta-analytic model. The traditional approach is described, for example, in: Riley, R. D., Higgins, J. P., & Deeks, J. J. (2011). Interpretation of random effects meta-analyses. British Medical Journal, 342 , d549. In the context of a Bayesian model (take, for example, the random-effects model described by equation 6 in the paper by Sutton & Abrams, 2001), one can easily obtain the posterior distribution of $\theta_i$, where $\theta_i$ is the true outcome/effect in the $i$th study (since these models are typically estimated using MCMC, one just needs to monitor the chain for $\theta_i$ after a suitable burn-in period). From that posterior distribution, one can then obtain the credibility interval.
