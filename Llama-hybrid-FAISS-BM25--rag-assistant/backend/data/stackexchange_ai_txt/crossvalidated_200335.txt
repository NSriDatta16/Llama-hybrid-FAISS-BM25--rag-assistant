[site]: crossvalidated
[post_id]: 200335
[parent_id]: 
[tags]: 
Speed up optimization in K-fold cross validation

Short version: What are, if any, the ways to speed up the optimization in $k$-fold cross validation $(k \ge 10)$ for generic models in which the data points are statistically independent, by exploiting the fact that the optima of each fold are likely to be close to each other? Long version: Let us consider $k$-fold cross validation for model evaluation, with $k \ge 10$. For each fold, I am performing maximum-likelihood estimation (MLE) on $\frac{k-1}{k}$-th of the data points and then computing the (log) likelihood of the test data. The models are all non-linear and fairly complex, but the data points $\textbf{x}_i$, $1 \le i \le N$, are assumed to be independent given the parameters $\theta$, that is: $$\log f(\textbf{x}|\theta) = \sum_{i = 1}^N \log f_i(\textbf{x}_i|\theta).$$ In practice, $k$-fold cross validation amounts to running a minimum of $k$ independent optimizations (one per fold) to find the MLE; possibly each optimization is repeated from several starting points if the landscape in non-convex, so as to try and avoid local optima. The point is, running $k$ independent optimizations (possibly multiple times) can be quite expensive and seems wasteful. If $k$ is large (and $N$ is large), and the folds are statistically i.i.d. (e.g., because the data approximately are, and we use stratification), the optima of the different folds will (often) be close to each other. So it seems that there should be ways to exploit this information to guide the optimizations and save function evaluations. For example, a naive approach might consist of initializing the optimization of each fold from the (vicinity of the) optimum of the previous fold, or from the optimum of the full function, or somehow exploiting information gained from optimization of other folds (various ideas come to mind for how to do so). As an example, Multi-task Bayesian Optimization (Swersky, Snoek and Adams, NIPS 2013) infers a correlation kernel between related functions to speed up simultaneous optimization. Multi-task BO is not built specifically for cross-validation (it is a possible application), and it applies to costly function evaluations, so it is not suitable for what I am currently doing. What are, if any, other known techniques in the literature [edit: not based on BO, that was just an example] that could be used to speed up the optimization for cross-validation in this case? Specific pointers to papers will be appreciated. (For the record, I am already aware of Pareto-smoothed importance sampling leave-one-out CV by Vehtari and Gelman, 2015; but that is for MCMC sampling, not MLE, and in my case it fails .)
