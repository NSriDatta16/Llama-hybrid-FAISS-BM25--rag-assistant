[site]: crossvalidated
[post_id]: 412215
[parent_id]: 412172
[tags]: 
I don't understand why in "pull" function we need to add the new random number to the true mean? The result of pulling the lever on the bandit is what the agent observes. So this is simulating the environment, which has a random reward drawn from a distribution. The agent is deliberately only allowed to call this pull method, and may not for instance query the true mean. if we know the real parameters so there is no need to solve the problem Obviously, it is trivial to find the action that maximises expected reward if you know the parameters. It is just the action with the highest mean reward. The premise of the exercise is that the agent does not know the parameters or - for most basic agents - anything about the distribution of rewards at all. For these toy problems, you know the parameters because you wrote them as part of the simulation. However, the Bandit class represents an environment which could be something that you don't know distribution of rewards for. For example it might be the outcome of a medical trial using a certain treatment, or the chance of someone clicking through on an advert and spending a certain amount of money. Most importantly, the code is constructed such that the agent does not know the parameters, and the experiment is to build agents that can find the best action through sampling. In multi armed bandit problems we also want to achieve that efficiently - with a small number of samples, or whilst gaining the most reward we can whilst still learning from the environment (this can also be framed as minimising regret - how the agent compares to a theoretical oracle that does know the parameters from the start). On a read through the code, the class design is somewhat poor/lazy as a teaching tool, in that the author has stored both the simulation and stats in the same class. It's fine as an implementation, but makes it less clear which parts of the system are the agent and which are the environment. I would personally have used a structure outside of Bandit class to store the current mean estimates that the agent uses.
