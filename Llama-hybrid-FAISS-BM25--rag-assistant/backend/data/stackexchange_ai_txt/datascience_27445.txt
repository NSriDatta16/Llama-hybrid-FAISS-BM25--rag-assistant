[site]: datascience
[post_id]: 27445
[parent_id]: 27444
[tags]: 
The class probabilities are the normalized weighted average of indicators for the k-nearest classes, weighted by the inverse distance. For example: Say we have 6 classes, and the 5 nearest examples to our test input have class labels 'F', 'B', 'D', 'A', and 'B', with distances 2, 3, 4, 5, and 6, respectively. Then the unnormalized class probabilities can by computed by: (1/2) * [0, 0, 0, 0, 0, 1] + (1/3) * [0, 1, 0, 0, 0, 0] + (1/4) * [0, 0, 0, 1, 0, 0] + (1/5) * [1, 0, 0, 0, 0, 0] + (1/6) * [0, 1, 0, 0, 0, 0] = [1/5 ,1/2, 0, 1/4, 0, 1/2] And after normalizing we get: [0.13793103, 0.34482758, 0.0, 0.17241379, 0.0, 0.34482758] If you choose weights='uniform' then it becomes a simple average, which can be computed by multiplying each indicator by (1/k) and summing, with no need for additional normalization.
