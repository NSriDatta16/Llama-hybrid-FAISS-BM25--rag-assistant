[site]: crossvalidated
[post_id]: 628181
[parent_id]: 
[tags]: 
How to do standardizing of time series data for regression tasks?

I'm using an LSTM-based model to train a regression model. I standardize the data (i.e., zero mean and unit standard deviation) (train, valid and test have different means and STDs). The model works well on standardized input. However, when scaling the predictions to their actual range, if I use the validation mean and std for that, there is a considerable difference between the predicted value and the true value. I should not use test means and STDs as it is not possible in practice to have this information. What's the best way to standardize the time series that the mean and std change over time? The only solution I can think of is to train a separate model to predict the mean and std for the test set.
