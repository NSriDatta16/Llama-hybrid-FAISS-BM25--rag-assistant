[site]: crossvalidated
[post_id]: 233283
[parent_id]: 
[tags]: 
MCMC; Can we be sure that we have a ''pure'' and ''large enough'' sample from the posterior? How can it work if we are not?

Referring to this thread: How would you explain Markov Chain Monte Carlo (MCMC) to a layperson? . I can see that it is a combination of Markov Chains and Monte Carlo: a Markov chain is created with the posterior as invariant limiting distribution and then Monte Carlo draws (dependent) are made from the limiting distribution (=our posterior). Let's say (I know that I am simplifying here) that after $L$ steps we are at the limiting distribution $\Pi$ (*). The Markov chain being a sequence of random variables, I get a sequence $X_1, X_2, \dots , X_L, \Pi, \Pi, \Pi, \dots \Pi$, where $X_i$ is a random variable and $\Pi$ is the limiting ''random variable'' from which we wish to sample. The MCMC starts from an initial value, i.e. $X_1$ is a random variable with all mass at that one value $x_1$. If I use capital letters for random variables and small letters for realizations of a random variable, then the MCMC gives me a sequence $x_1,x_2,x_3, \dots x_L, \pi_1, \pi_2, \pi_3, ....\pi_n$. So the length of the MCMC chain is L+n. [[*Note: the capital letters are random variables (i.e. a whole bunch of outcomes) and the small $x$ are outcomes, i.e. one particular value. * ]] Obviously, only the $\pi_i$ belong to my ''posterior'' and for approximating the posterior ''well'' the value of $n$ should be ''large enough''. If I summarise this then I have an MCMC chain $x_1,x_2,x_3, \dots x_L, \pi_1, \pi_2, \pi_3, ....\pi_n$ of length $N=L+n$, only $\pi_1,\pi_2,\dots, \pi_n$ are relevant for my posterior approximation, and $n$ should be large enough. If I do include some of the $x_i$ (i.e. realizations before the invariant distribution is reached) in the computation of the approximation of the posterior, then it will be ''noisy''. I know the length of the MCMC chain $N=L+n$, but without knowledge of the $L$, i.e. the step where I am sure to sample from the limiting distribution, I can not be sure that I did not include noise, nor can I be sure about $n=N-L$, the size of my sample from the limiting distribution, in particular, I can not be sure whether it is ''large enough''. So, as far as I understood, this value of $L$ is of critical importance for the quality of approximation of the posterior (exclusion of noise and a large sample from it) . Are there any ways to find a reasonable estimate for $L$ when I apply MCMC ? (*) I think that, in general, $L$ will depend on the initial value $x_1$.
