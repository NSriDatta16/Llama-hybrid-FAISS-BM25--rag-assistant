[site]: crossvalidated
[post_id]: 280097
[parent_id]: 
[tags]: 
When can likelihood be interpreted as probability function?

I'm interested in likelihood $L(\theta | x) = P( x | \theta)$ seen as the function of $\theta$ for a given $x$. I have been reading in books and other posts that $L$ is generally not a probability function (with respect to $\theta$) because it may not integrate to 1 and, moreover, there my be even no $\sigma$-field defined over the $\theta$ space. In the Bayesian approach, we define a prior probability $P(\theta)$ and so the $\sigma$-field had to be defined. What other properties we need to be able to interpret $L(\theta|x)$ as the conditional probability $P(\theta|x)$? Perhaps normalization to integrate to 1? What else? (whuber mentions some regularity conditions in this post Wikipedia entry on likelihood seems ambiguous . What would these be?) EDIT After some searching, I believe the answer is in Fisher's fiducial distribution . See Casella&Berger(2002, sec. 6.3.1), the original Fisher's papers (1933,1935) or this question: What is the fiducial argument and why has it not been accepted? EDIT2 Now that I know the key-word is fiducial , there is a fairly good explanation in the answer to this question: What does "fiducial" mean (in the context of statistics)?
