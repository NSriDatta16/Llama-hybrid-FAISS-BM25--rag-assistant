[site]: crossvalidated
[post_id]: 325622
[parent_id]: 
[tags]: 
MCMC using reduced chi-square

I have been looking at a number of references for the likelihood function in MCMC, one of the most commonly used target distribution for a fitting problem is a gaussian centered in 0 of the errors: $l(\theta|x)= \exp[ \frac{-\sum\limits_{i=1}^n (x_i-y_i(θ))^2}{ 2\sigma^2} ]=\exp[ -\chi^2 ]$ where $x_i$ is the observation i, $y_i(θ)$ is the prediction in function of the set of parameters θ, n is the number of observations, $\sigma$ is the expected errors standard deviation of the model. However, I found it odd that the likelihood would vary in function of the number of samples. Would that make sense to divide the squared sum of errors by the degree of freedom (i.e the reduced chi square) such as: $l(\theta|x)= \exp[ \frac{-\sum\limits_{i=1}^n (x_i-y_i(θ))^2}{ 2\sigma^2 \nu} ]=\exp[ -\frac{\chi^2}{\nu} ]$ where the degree of freedom $\nu$ is equal to n-m, where m is the number of parameters. I didn't find any example in the litterature so I don't know if that makes sense. Does anyone have some advice? Thank you very much for taking the time to read my question and for your potential answers!
