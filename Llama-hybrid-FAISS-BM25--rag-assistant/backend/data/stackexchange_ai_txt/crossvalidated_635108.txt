[site]: crossvalidated
[post_id]: 635108
[parent_id]: 
[tags]: 
Statistical Estimation of Machine Learning Metrics

Aloha Cross Validated, In the context of binary classifiers we have a number of metrics like accuracy, precision, recall, AUROC, F1, etc. To show robustness of a model we can gain a confidence interval via a bootstrap . Personally I have had issues with bootstrapping done with small / imbalanced datasets. Sometimes the bootstrap population contains only one class and creates issues with the bootstrap. This is more likely in class imbalanced scenario like healthcare data. I would like to know about easy / robust ways to make this process of obtaining a confidence interval for these ML metrics. This package computes analytic confidence intervals (that is, CIs in which we have a formula for the width) for a number of ML metrics. However, it does not have metrics like balanced accuracy $$\texttt{balanced-accuracy} = \frac{1}{2}\left( \frac{TP}{TP + FN} + \frac{TN}{TN + FP}\right )$$ I am not sure what arithmetic operations we can do on different CIs. That is, the first term in =balanced-accuracy= is a ratio of true positives (which we may calculate the CI for) and the sum of true positive and true negatives. Hence this term includes a sum of confidence intervals and quotients of confidence intervals. Also, have CIs been studied for notions of Algorithmic fairness ? Please help me clarify if I am unclear.
