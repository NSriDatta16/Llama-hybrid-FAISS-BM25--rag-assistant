[site]: crossvalidated
[post_id]: 106233
[parent_id]: 
[tags]: 
Combining data from different sources

I want to combine data from different sources. Let's say I want to estimate a chemical property (e.g. a partitioning coefficient ): I have some empirical data, varying due to measurement error around the mean. And, secondly, I have a model predicting an estimate from other information (the model has also some uncertainty). How can I combine those two datasets? [The combined estimate will be used in another model as predictor]. Meta-analysis and bayesian methods seem to be suitable. However, haven't found many references and ideas how to implement it (I am using R, but also familiar with python and C++). Thanks. Update Ok, here's a more real example: To estimate the toxicity of a chemical (typically expressed as $LC_{50}$ = concentration where 50% of animals die) lab-experiments are conducted. Happily the results of the experiments are gathered in a database (EPA) . Here are some values for the insecticide Lindane : ### Toxicity of Lindane in ug/L epa However, there are also some models available to predict toxicity from chemical properties ( QSAR ). One of these models predicts toxicity from the octanol/water partition coefficient ($log~K_{OW}$): $$ log~LC_{50} [mol/L] = 0.94~(\pm 0.03)~log~K_{OW}~-~1.33 (\pm~0.1)$$ The partitioning coefficient of Lindane is $log~K_{OW} = 3.8$ and the predicted toxicity is $ log~LC_{50} [mol/L] = -4.902 $. lkow = 3.8 mod1 Is there a nice way to combine these two different informations (lab experimens and model predictions)? hist(log10(epa/ (mw * 1000000))) abline(v = mod1, col = 'steelblue') The combined $LC_{50}$ will be used later on in a model as predictor. Therefore, a single (combined) value would be a simple solution. However, a distribution might be also handy - if this is possible in modelling (how?).
