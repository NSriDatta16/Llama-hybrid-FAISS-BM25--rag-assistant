[site]: datascience
[post_id]: 12778
[parent_id]: 11225
[tags]: 
Primarily, the concern with data-size arises because of the error that it can cause to the overlying model. With that concept in mind, you might want to measure the Bias and Variance of the model with your current data, understand the fitness of your model, and then take it from there. Here's an article that I wrote that may help you do the same: Machine Learning: How Big Should Your Data Be? This article talks about Bias and Underfitting Variance and Overfitting Bias-Variance Trade-Off and Optimal Complexity It concludes that: More sample data is always powerful, but is not always the right answer. As you increase your sample data, make sure to adjust your parameter space to minimize error.
