[site]: crossvalidated
[post_id]: 390298
[parent_id]: 
[tags]: 
Image feature extraction using an Autoencoder combined with PCA

Background: I have fairly large dataset of biomedical images (around 10,000 images) of 1920x1920 pixels (after cropping parts of black borders out). My task is to extract the 200 most important features from the images, to be used in a genome-wide association study. My initial idea was using a convolutional autoencoder (CAE) for dimensionality reduction but I quickly realized there was no way I could reduce the dimensions to 200 with the encoder and have the decoder reconstruct the images with acceptable accuracy from only those dimensions. I then had the idea to first train a CAE and use the encoder to create a new dataset of about 30x30x512 flattened to 460800 dimensions from 1920x1920x1 (greyscaled which I'm still debating about if it's acceptable information loss, but it's just so much more convenient to greyscale). On this new dataset I would use PCA to reduce the dimensions to 200. My questions are: Does this method make sense? I'm relatively new to machine learning (my background is in mathematical computer science). If this is a poor method for solving the problem, what would be a better one?
