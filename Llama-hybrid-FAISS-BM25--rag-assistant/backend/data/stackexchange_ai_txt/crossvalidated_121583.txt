[site]: crossvalidated
[post_id]: 121583
[parent_id]: 105264
[tags]: 
The number of different values in your categorical variables is only important relative to your sample size. If you only have 10,000 observations, 40,000 dummy variables for each zipcode in the US is probably too much, but if you have 10,000,000 observations 40,000 dummy variables is fine. You're probably going to have the best results by gathering all the data you can get your hands on and modeling it with a tool like vowpal wabbit that can handle 100's of millions of observations and all of the variables you can throw into it. As far as the unique identifier goes, if you get more than one observation per user, you probably want to use it in some fashion. A person who clicked 10 times out of 10 impressions is very likely to click again, regardless of what the other variables are. A dummy variable for every user is probably not the best approach, but a set of variables like "user's prior impressions", "user's prior clicks" and "user's prior click-through-rate" are probably really valuable. This trick can also be used to convert your other categorical variables to continuous variables, e.g. "zip code's prior impressions", "zip code's prior clicks", and "zip code's prior click-through-rate." There's a recently-completed kaggle competition for predicting ad click-through-rates , and there's some great stuff in the forums . There are also 2 very good blog posts ( here and here ) on fitting logistic regressions models to this dataset using scikit-learn and vowpal wabbit.
