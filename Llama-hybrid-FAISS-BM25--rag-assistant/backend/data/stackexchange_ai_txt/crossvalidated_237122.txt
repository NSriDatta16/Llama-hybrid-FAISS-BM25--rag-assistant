[site]: crossvalidated
[post_id]: 237122
[parent_id]: 237104
[tags]: 
This seems a case for simple logistic regression . Here is an example in R . set.seed(1) # generate some data dd You can fit the model with the glm function providing as dependent variable two columns with the number of "successes" and "failures" (people with vs without college education) # fit logistic model dd$noCollege You can assess the effect of Area on the proportion college education by means of the Wald test provided when you apply the summary function to the fitted model object: > summary(m0) Call: glm(formula = cbind(College, noCollege) ~ Area, family = binomial, data = dd) Deviance Residuals: Min 1Q Median 3Q Max -2.1467 -0.5400 0.2320 0.9513 2.0587 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) -0.5355 0.2570 -2.084 0.03720 * Area2 1.1746 0.3827 3.069 0.00215 ** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 (Dispersion parameter for binomial family taken to be 1) Null deviance: 54.786 on 39 degrees of freedom Residual deviance: 44.946 on 38 degrees of freedom AIC: 92.664 Alternatively, you can also use a likelihood ratio test , by comparing the fitted model with a null model which assume no difference between Area: > anova(update(m0, .~. -Area), m0,test="Chisq") Analysis of Deviance Table Model 1: cbind(College, noCollege) ~ 1 Model 2: cbind(College, noCollege) ~ Area Resid. Df Resid. Dev Df Deviance Pr(>Chi) 1 39 54.786 2 38 44.946 1 9.8399 0.001708 ** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Update. It might be the case that the probability of college education is different for household with different number of adults. And the expected difference related to the two areas might also vary depending on the number of adults in the household. To account for that you can use a mixed-effect logistic regression, using the number of adults as grouping factor and including a random slope for Area: > library(lme4) > mm0 summary(mm0) Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod'] Family: binomial ( logit ) Formula: cbind(College, noCollege) ~ Area + (Area | Adults) Data: dd AIC BIC logLik deviance df.resid 98.7 107.1 -44.3 88.7 35 Scaled residuals: Min 1Q Median 3Q Max -1.7109 -0.5171 0.2312 0.7983 1.8327 Random effects: Groups Name Variance Std.Dev. Corr Adults (Intercept) 0.0061963 0.07872 Area2 0.0007963 0.02822 -1.00 Number of obs: 40, groups: Adults, 6 Fixed effects: Estimate Std. Error z value Pr(>|z|) (Intercept) -0.5339 0.2629 -2.031 0.0423 * Area2 1.1748 0.3837 3.061 0.0022 ** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Correlation of Fixed Effects: (Intr) Area2 -0.658 Notice that here I simulated the data using (for each area) the same probability of college education regardless of the number of adults. In fact in this example adding the random effects does not improve the fit. You can see it by comparing the AIC values of the two models: 92.7 for the simple logistic regression, 98.7 for the mixed effect regression, that is a difference of ~6 favouring the simple model with no random effects.
