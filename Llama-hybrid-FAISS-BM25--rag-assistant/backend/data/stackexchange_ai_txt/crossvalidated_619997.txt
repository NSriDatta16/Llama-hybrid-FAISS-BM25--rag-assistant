[site]: crossvalidated
[post_id]: 619997
[parent_id]: 
[tags]: 
Bayesian Regression Evaluation Metrics

I'm pretty new to Bayesian statistics so hopefully this makes sense: I'm fitting a Bayesian ridge regression using scikit-learn whose target values lie between 0 and 1. When the point values (the mean of the predicted distribution) are compared to the observed (gold) point values, MAPE, WAPE, and r^2 look good. But when I generate predictions with the standard deviation of their distributions, the standard deviations are often large. For instance, I'll get a prediction like 0.01 -- good when compared to the expected value -- along with a standard deviation of 1.78. Obviously, such a large standard deviation indicates a large amount of uncertainty around the predicted mean, and therefore more work needs to be done on the model to increase certainty. However, I had no indication of this since MAPE, WAPE, and r^2 on the predicted mean don't provide insight into this. What other metrics should I be looking at here? Possibly related: How to evaluate uncertainty estimates in regression? Gaussian-Process (scikit-learn) Prediction Confidence Interval Oddities - Stats Question
