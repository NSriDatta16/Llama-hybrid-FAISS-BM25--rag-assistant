[site]: crossvalidated
[post_id]: 310030
[parent_id]: 309268
[tags]: 
You generally can't decompose error (residuals) into bias and variance components. The simple reason is that you generally don't know the true function. Recall that $bias(\hat f(x)) = E[\hat f(x) - f(x)],$ and that $f(x)$ is the unknown thing you wish to estimate. What about bootstrapping? It is possible to estimate the bias of an estimator by bootstrapping, but it's not about bagging models, and I don't believe there is a way to use the bootstrap to assess the bias in $\hat f(x),$ because bootstrapping is still based on some notion of the Truth and can't, in spite of the origins of its name, create something from nothing. To clarify: the bootstrap estimate of bias in the estimator $\hat \theta$ is $$\widehat{bias}_B = \hat\theta^*(\cdot) - \hat \theta,$$ with $\hat\theta^*(\cdot)$ being the average of your statistic computed on $B$ bootstrap samples . This process emulates that of sampling from some population and computing your quantity of interest. This only works if $\hat\theta$ could in principle be computed directly from the population. The bootstrap estimate of bias assesses whether the plug-in estimate—ie just making the same computation on a sample instead of in the population—is biased. If you just want to use your residuals to evaluate model fit, that is entirely possible. If you, as you say in the comments, want to compare the nested models $f_1(x) = 3x_1 + 2x_2$ and $f_2(x) = 3x_1 + 2x_2 + x_1x_2$, you can do ANOVA to check whether the larger model significantly reduces sum of squared error.
