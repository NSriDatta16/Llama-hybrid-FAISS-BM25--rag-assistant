[site]: crossvalidated
[post_id]: 316360
[parent_id]: 
[tags]: 
Zero values in the solution when using $L1$ norm

I am trying to solve the following minimization problem using alternate minimization. $\underset{a,B}{\text{minimize}} \sum_{i,t}^{I,T} \frac{||x_{i,t} - \sum_{\tau = 1}^{\Theta}[a_{i,\tau}B_{\tau}]x_{i,t-\tau} ||_{2}^{2}}{Id} + \lambda (\sum_{\tau}^{\Theta} ||B_{\tau}||_{1} + \sum_{i,\tau}^{I,\Theta} ||a_{i,\tau}||_2)$ where $B \in R^{d\times d\times \tau}$, $X \in R^{d \times I \times T}$ and $\lambda$ is a sparsity parameter. In the above model I am trying to find relation between a time and series and its past values. I have constrained $B$ which stores the relation between time series and $a$ stores the magnitude of $B$. I have put $L1$ penalty on $B$ and $L2$ on $a$. I have tried different $\lambda$ to increase sparsity in $B$. Initially when $\lambda$ is very low, solution is 0% sparse, as $\lambda$ is increased, $B$ becomes more sparse but it reaches 50% sparsity. After that if I try to increase the sparsity, the solution becomes 100% sparse i.e. all the values in $B$ become 0, I am not able to get sparsity levels between 50% and 100%. In the algorithm first I use gradient descent and then proximal operator is applied for $L1$ and $L2$ norm alternatively. Is there a way to change the proximal operatr or introduce something in the algorithm so that I can get sparsity of $B$ between 0-100%? Is there any reason for sudden jump in the sparsity of $B$?
