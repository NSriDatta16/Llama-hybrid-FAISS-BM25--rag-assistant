[site]: crossvalidated
[post_id]: 577136
[parent_id]: 
[tags]: 
how can we apply masked language modelling on the images using multimodal models?

It might not be clear from the question what I want to say, but how can we apply masked language modelling with the text and image given using multimodal models like lxmert. For example, if there is some text given (This is a MASK) and we mask some word in it, and there is an image given (maybe of a cat), how can we apply MML to predict the word as cat? Are there any techniques to solve such problems? If anyone can help, it would be great.
