[site]: crossvalidated
[post_id]: 285685
[parent_id]: 285492
[tags]: 
For each record you should create a feature vector of a fixed size. I guess there is no problem with table candidate_general_info . You simply put the values into the vector. Or trassform them somehow - one hot encoding, create ages group etc. From other tables you need to aggregate all rows into sigle features. For previous_employment_history table it could be has_been_unemployed , total_length_of_unemployment , average_salary , current_salary , nr_of_records_employment_history etc. The similar way for other tables. And if I understand correctly and you want to make prediction for each claim (row of present_claim_information ) each row of this table should be different datapoint (feature vector).
