[site]: crossvalidated
[post_id]: 366313
[parent_id]: 258094
[tags]: 
You can use genetic algorithms. Yes, it will require to rerun experiments again and again but it is also true for other hyperparameter optimization methods. You can try to use warm-starts, i.e., don't train your models from scratch but to warm-start them from some previously found solutions. The latter sometimes is used for deep neural networks when searching for networks architectures. Genetic algorithms can potentially be slow compared to other methods. However, they are relatively easy to adjust for any search space. The first GAs for hyperparameter tuning appeared about 30 years ago. For a more recent work, see "Large-Scale Evolution of Image Classifiers" by Real et al., 2017 at https://arxiv.org/abs/1703.01041
