[site]: stackoverflow
[post_id]: 1931514
[parent_id]: 1931359
[tags]: 
Average of x_1 .. x_N = (Sum(i=1,N,x_i)) / N = (Sum(i=1,M,x_i) + Sum(i=M+1,N,x_i)) / N = (Sum(i=1,M,x_i)) / N + (Sum(i=M+1,N,x_i)) / N This can be repeatedly applied, and is true regardless of whether the summations are of equal size. So: Keep adding terms until both: adding another one will overflow (or otherwise lose precision) dividing by N will not underflow Divide the sum by N Add the result to the average-so-far There's one obvious awkward case, which is that there are some very small terms at the end of the sequence, such that you run out of values before you satisfy the condition "dividing by N will not underflow". In which case just discard those values - if their contribution to the average cannot be represented in your floating type, then it is in particular smaller than the precision of your average. So it doesn't make any difference to the result whether you include those terms or not. There are also some less obvious awkward cases to do with loss of precision on individual summations. For example, what's the average of the values: 10^100, 1, -10^100 Mathematics says it's 1, but floating-point arithmetic says it depends what order you add up the terms, and in 4 of the 6 possibilities it's 0, because (10^100) + 1 = 10^100. But I think that the non-commutativity of floating-point arithmetic is a different and more general problem than this question. If sorting the input is out of the question, I think there are things you can do where you maintain lots of accumulators of different magnitudes, and add each new value to whichever one of them will give best precision. But I don't really know.
