[site]: crossvalidated
[post_id]: 108430
[parent_id]: 
[tags]: 
Is there a Bayesian approach to density estimation

I am interested to estimate the density of a continuous random variable $X$. One way of doing this that I learnt is the use of Kernel Density Estimation. But now I am interested in a Bayesian approach that along the following lines. I initially believe that $X$ follows a distribution $F$. I take $n$ readings of $X$. Is there some approach to update $F$ based on my new readings? I know I sound like I am contradicting myself: If I believe solely in $F$ as my prior distribution, then no data should convince me otherwise. However, suppose $F$ were $Unif[0,1]$ and my data points were like $(0.3, 0.5, 0.9, 1.7)$. Seeing $1.7$, I obviously cannot stick to my prior, but how should I update it? Update: Based on the suggestions in the comments, I have started looking at Dirichlet process. Let me use the following notations: $ G \sim DP(\alpha,H)\\ \theta_i | G \sim G\\ x_i | \theta_i \sim N(\theta_i,\sigma^2)$ After framing my original problem in this language, I guess I am interested in the following: $\theta_{n+1} | x_1,...,x_n$. How does one do this? In this set of notes (page 2), the author did an example of $\theta_{n+1} | \theta_1,...,\theta_n$ (Polya Urn Scheme). I am not sure if this is relevant. Update 2: I also wish to ask (after seeing the notes): how do people choose $\alpha$ for the DP? It seems like a random choice. In addition, how do people choose a prior $H$ for DP? Should I just use a prior for $\theta$ as my prior for $H$?
