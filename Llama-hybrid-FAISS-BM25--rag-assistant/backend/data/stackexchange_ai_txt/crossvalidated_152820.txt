[site]: crossvalidated
[post_id]: 152820
[parent_id]: 152815
[tags]: 
One possibility is to take a Bayesian approach using a Beta-Binomial model using Mote Carlo simulations. Specifically, we put independent $\mathrm{Beta}(\alpha_1, \beta_1)$ and $\mathrm{Beta}(\alpha_2, \beta_2)$ priors on $p_1$ and $p_2$, respectively. The posterior for $p_1$ and $p_2$ are independent Beta distributions. The posterior for $p_1$ is a $\mathrm{Beta}(\alpha_1 + x, n-x + \beta_1)$ distribution where $x$ denotes the number of sucesses and $n$ the sample size. By choosing $\alpha_1 = \alpha_2 = \beta_1 = \beta_2 = 1$, we put a uniform distribution on $p_1$ and $p_2$. Computationally we could proceed as follows: Generate $N$ samples from a $\mathrm{Beta}(\alpha_1 + x_1, n_1 - x_1 + \beta_1)$ and $\mathrm{Beta}(x_2 + \alpha_2, n_2 - x_2 +\beta_2)$ distribution (the posteriors). Calculate the difference of the posteriors. Summarize the posterior (using quantiles to calculate a credible interval, for example). One could also calculate a "Bayesian p-value" by counting the number of samples of the difference that exceed 0. Here is an R-function that does this: bayes.prop 0)/length(rd) p.below For a more sophisticated implementation, check out Rasmus Bååth's blog on this topic.
