[site]: datascience
[post_id]: 114330
[parent_id]: 114318
[tags]: 
First of all, your learning curves look really bad. Take a look at this post on How to use Learning Curves to Diagnose Machine Learning Model Performance . However, since this is an interesting topic, I think some notes are worth mentioning: One interesting and dominant argument about optimizers in papers is that SGD better generalizes than Adam. These papers argue that although Adam converges faster, SGD generalizes better than Adam and thus results in an improved final performance. One of said papers argues that minimizing training time can decrease generalization error. This is because the model will not see the same data several times and wouldn't memorize the data without losing its generalization capability. Interestingly, this can directly correlate to your problem: you are randomly oversampling your dataset. Thus, the model sees some data over and over again. So, add this to what I mentioned before; You get a model that learns nothing. In summary, ADAM isn't always better. Use regularization techniques, such as Dropout, Batch Normalization, etc. Fine-tune your model. If you don't know how, try different learning rates and compare the results. There are also numerous automatic hyperparameter tuning methods such as Hyperband, Bayesian Optimization, etc., that can basically fine-tune any hyperparameter.
