[site]: crossvalidated
[post_id]: 338441
[parent_id]: 
[tags]: 
How can reinforcement learning work for avoidance? (Paradox)

Gradient descent works by reinforcing a small amount every time the machine gets the right answer. If it gets the right answer it is more likely to pick that answer next time and so it gets reinforced again and again. But here's a paradox. What if you want to train a machine to avoid something. As soon as it starts to avoid it, it will no longer encounter that event again and so it can't reinforce its learning. Hence how can a machine learn about bad things if its very purpose is to avoid bad things? Edit: I am thinking specifically about real-time learning where there is no split between training phase and testing phase. The paradox is that if the learning rate is small, it will only shift slightly away from bad things making random exploration still likely to hit bad things. And so the equilibrium will be to be just on the edge of avoiding a bad thing but still quite likely to hit it by random chance.
