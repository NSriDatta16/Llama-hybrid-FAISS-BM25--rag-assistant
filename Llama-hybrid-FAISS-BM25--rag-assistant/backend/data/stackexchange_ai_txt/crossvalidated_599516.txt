[site]: crossvalidated
[post_id]: 599516
[parent_id]: 599289
[tags]: 
Using GAMMs might be a suitable choice. With GAMMs you can model the non-linear relationship using smooths (which are penalized splines) while accounting for the hierarchical structure of the data. One potential advantage of GAMMs over some alternative methods is that they estimate the amount of complexity that is needed from the data. You can implement them using the bam() function from R's mgcv package. Alternatively, you can use the gamm() function, but while it has a few additional modelling capabilities (which I think you do not need) it is a bit slower. That said, I suspect there are some dependencies in the data structure that you have not yet incorporated in the suggested GAMM code. Without more knowledge about the data and question(s) you want to answer, it is hard to say which random effects structure would be the most appropriate here. I suspect that with using only random intercepts for Station and CYR you have not yet captured how the (non-linear) effect of sal on the outcome might differ for each Station and each year. In mgcv you can incorporate a non-linear random effect of sal by station like this: s(center_sal, Station, bs = "fs", m = 1) Note that as such random smooths are unconstrained, meaning that they also model average differences of the outcome between levels of the random factor and therefore make random intercepts unnecessary. Fully capturing the hierarchical structure of the data in the model is advisable especially if you want to obtain appropriate inferences (in your case about the presence of an effect of sal on the outcome). Additionally, using a complete random effects structure can improve the models (out of sample) predictions. Putting these points together, the code for a potential model might look like this: library(mgcv) gamm After fitting the model you might want to check if the current model allows for sufficient complexity/wigglyness of the relationship. For this you can use the gam.check() function. It will help you decide whether you should increase the argument k of the s() function in the model (default value is 10, if too low try 20 and check again). While you are at it, you can also look at the plots that the function produces in order to check for potential heteroskedasticity (although I am not sure if the latter works for binomial models). There are some which suggest making the model more parsimonious by removing unnecessary random effects. You can do that by looking at the p-value of the random smooth term in the model summary. A low p-value (e.g. smaller than .05) suggests that the random smooth might be helpful, a higher p-value suggests that it might not be necessary. If running the model takes too long you can try the following: a) set discrete to TRUE to use a discretetized version of covariates, b) set nthreads to the number cores of your computer to run the model using multiple CPU-cores. For answering your main question, I suggest looking at the p-value of the smooth term (that of s(center_sal) ) in the model summary. For visually inspecting the relationship you could either use the built-in plot() function of mgcv or the plot_smooth() function from the itsadug package. The latter allows for using simultaneous confidence intervals which might be useful, depending on the questions you want to answer. For a general reference on GAMMs I suggest looking at the book of the author of mgcv: Wood, S. (2017) Generalized additive models: An introduction with R, 2nd. Ed. Another interesting reference that provides a (short) introduction and offers some insights into which specification of random effects might be appropriate is the following: Soskuthy, M. (2021) - Evaluating generalised additive mixed modelling strategies for dynamic speech analysis Finally I also found the articles and blog of G. Simpson to be a useful resource. To mention just one blog post: https://fromthebottomoftheheap.net/2021/02/02/random-effects-in-gams/
