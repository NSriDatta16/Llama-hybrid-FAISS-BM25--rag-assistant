[site]: crossvalidated
[post_id]: 126369
[parent_id]: 90855
[tags]: 
The reason you get 124 components even though you only had 10 original features is (probably) because you have 124 samples. In kernel PCA, the data are mapped to a space which is very high dimensional (has many more than 10 dimensions), and so the number of PCs is only limited by the number of samples. Now, your eigenvalues are actually not so uniform as you seem to think. Here is the plot of your data: One could argue that there is some sort of an "elbow" around 15 components, and that after around 20 components the spectrum becomes very monotonic. So 15-20 components seems like a reasonable number on the basis of eigenvalues only . However, if you want to use kPCA as a first step of some classification or decoding algorithms, then it is always a better idea to select the number of components to retain via cross-validation.
