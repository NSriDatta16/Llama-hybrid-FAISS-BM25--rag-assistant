[site]: datascience
[post_id]: 39321
[parent_id]: 37945
[tags]: 
In general, you can apply a variety of transformations that reduce each time series down to something more manageable. Summary stats like mean, median, standard deviation. "Bucket" the data into, e.g. monthly aggregates of any of the above Number of observed instances, if they vary. Various "bucketized" statistics like observation frequency per month, if the observations are not evenly-sampled. Compute test statistics for classic time series hypothesis tests like the ADF, PP, and KPSS tests for unit roots. Fit a model to each series and use its ARIMA coefficients as features. Apply dimension reduction. Eg. use PCA on the time series space and take the first few dimensions (e.g. look for an elbow in the eigenvalues); but this only works if the time series are both evenly-spaced and equal-length. Apply one of many time series clustering algorithms (and another reference ) and use cluster assignments or probabilities as features. You can use Dynamic Time Warping to compare time series sampled at different rates. Note that handling unevenly-sampled time series can be much harder than sampling even-spaced time series. See here for insight.
