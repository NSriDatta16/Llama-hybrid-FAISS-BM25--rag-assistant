[site]: crossvalidated
[post_id]: 384593
[parent_id]: 
[tags]: 
why too many epochs will cause overfitting?

I am reading the 《deep learning with python》. In chapter 4, about Fighting overfitting , I have two questions. why increasing epochs may cause overfitting? I know increasing will cause more gradient descent , will more gradient descent can cause overfitting? During the process of fighting overfitting, will the accuracy be reduced ?
