[site]: datascience
[post_id]: 76412
[parent_id]: 
[tags]: 
Does anybody know where this rule of thumb came from? Rule of them: embedding vector dimension should be the 4th root of the number of categories

I was taking an online ML course and the lecturer said that a rule of thumb for choosing the number of dimensions when embedding categorical data is the following embedding vector dimension should be the 4th root of the number of categories The lecturer worked for Google and when I looked on the internet for this I only found a Google blog which quickly mentioned it google blog link . I'm guessing it's something that they came up with at Google but was wondering if somebody else has maybe seen it in a research paper.
