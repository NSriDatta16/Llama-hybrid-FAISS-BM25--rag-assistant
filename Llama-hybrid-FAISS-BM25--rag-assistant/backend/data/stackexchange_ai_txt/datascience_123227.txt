[site]: datascience
[post_id]: 123227
[parent_id]: 93823
[tags]: 
From the documentation of XGBoost you can see that multi:softmax and multi:softprob are the same objective. The only difference is that multi:softprob also return output vector of ndata * nclass of the classes probabilities. multi:softmax : set XGBoost to do multiclass classification using the softmax objective, you also need to set num_class(number of classes) multi:softprob : same as softmax, but output a vector of ndata * nclass, which can be further reshaped to ndata * nclass matrix. The result contains predicted probability of each data point belonging to each class.
