[site]: crossvalidated
[post_id]: 225856
[parent_id]: 74295
[tags]: 
My guess is that Mahout uses some sort of simplified first-order method for optimisation (similar to the linear perceptron's delta rule ) whereas R's classic GLM from statistics uses ML estimation. I'm suspecting this from the fact that they're using the word "train" instead of "estimate". It would be very uncommon (not to say weird) to use the word "train" for OLS or ML estimation. I've also noticed that, when you see terms from classical statistics such as "linear regression" and "logistic regression" used in a machine learning context, the difference is always in the optimisation process, i.e. estimation vs training (again, a good example is the linear perceptron). Training algorithms in machine learning are supposed to be more robust than parameter estimation methods in parametric statistics because they favour raw computational power over mathematical accuracy, though, they both have their pros and cons . Anyway, I think it's good to pose such questions so that researchers, employers, and employees alike, can finally start understanding the differences between a machine learning expert (specialised computer scientist) and a statistician (specialised mathematician). They definitely have overlapping ground, such as the topics discussed in this question, but they're certainly not overlapping fields.
