[site]: crossvalidated
[post_id]: 78391
[parent_id]: 
[tags]: 
Theoretical performance of different classifiers

I am trying to list the differences in the ways a regularized general linear model would, in theory, be different from a neural network and linear discriminant analysis. I have a case where the number of cases is more than the number of features, and there is slight skewness in the sample cases. There is no co-linearity between the features. In most cases, the sample size of the training sample is large (> 100). Given that a neural network is a non-linear classifier, I would expect it to out-perform the LDA (at least). THe LDA is parameteric, and I assume the regularized GLM is also parametric? I am not sure what effect the lasso or elastic net fitted to the generalized linear model would have on its performance ability as a classifier. I have read Friedman et al.'s paper , but still cannot postulate how such a penalty would improve overall classification. Can anyone start me off, or direct me to literature that deals with the computational differences between these classifiers, specially the regularized GLM. Anything posted will be appreciated
