[site]: crossvalidated
[post_id]: 94346
[parent_id]: 
[tags]: 
Is it OK to increase validation checks and decrease min gradient while training neural network?

My input vector is a 130*85 matrix and my target vector is 130*26 matrix. I am using the below parameters for training the network with 60 hidden nodes. net.trainParam.max_fail = 50; net.trainParam.min_grad=1e-10; net.trainParam.show=10; net.trainParam.lr=0.01; net.trainParam.epochs=1000; net.trainParam.goal=0.001;` As you can see I have set the max_fail to 50 and min_grade to 1e-10. While the default values will be 6 and 1e-5 respectively. But with the default values, the training stops early with out reaching the performance goal. By setting these parameters,the training is stopped when the performance goal is reached. So. Is it OK to change these parameters?
