[site]: crossvalidated
[post_id]: 99658
[parent_id]: 
[tags]: 
Low classification accuracy for statistically different features

I am a little bit confused about the machine learning outcomes on my dataset. I would be grateful if anyone can enlighten me on this: When features are statistically different between two groups, shouldn't the machine learning able to predict the right class with a reasonable accuracy? The data consists of 9 features where 8 of them were significantly different between the groups (two tailed independent ttest). Total observations were 71 (30 and 41). However, the machine learning were only able to produce around 65% classification accuracy (10 fold cross validation). I have used SVM with RBF kernel, kNN, Random Forest, and Naive Bayes. My question is, is it normal? Is it possible to get higher classification accuracy when the features were not significantly different between the groups? Thanks.
