[site]: datascience
[post_id]: 87518
[parent_id]: 
[tags]: 
What does attention weights output from Transformer network do?

I'm trying to understand transformer networks. I want to know that are the attention weights, which are the outputs from forward/predict method where we get final output and attention weights as return, important after we done predicting?
