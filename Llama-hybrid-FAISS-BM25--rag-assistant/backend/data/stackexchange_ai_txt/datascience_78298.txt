[site]: datascience
[post_id]: 78298
[parent_id]: 
[tags]: 
Feature Importance without Random Forest Feature Importances

Is their an intuitive way of finding feature importances without just using the random forest feature importances method? I have a binary logistic regression problem where I have binary features (1 or 0) and a binary target (1 or 0). I want to see which features are most important towards predicting the target and somehow rank them. I did an odds ratio for each feature, which gave me some idea of importance. Are there any other methods?
