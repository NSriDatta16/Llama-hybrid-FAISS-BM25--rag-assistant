[site]: crossvalidated
[post_id]: 223400
[parent_id]: 
[tags]: 
Convergence Criteria for Stochastic Gradient Descent

I am familiar with the update rule in SGD whereby the weights ($\theta$) are updated with the gradients of the cost function ($\nabla Q$) for each sample times the learningrate ($\eta$). $$ w := w - \eta \nabla Q_{i}(w) $$ Now my question is when to evaluate the stopping criteria. In the neural network algorithms I am looking at, steps/epochs continue until the gradients get beneath a pre-defined threshold (or max number of epochs). Are the gradients evaluated within the sample loop (i.e. within SGD) or after each full pass (i.e. epoch). In the former, I can imagine a situation where the first random samples from a dataset are all the same class and therefore the SGD converges rapidly to minimize that error. This would result in a model that generalizes very poorly because it has 'learned' to classify everything as the same class. So I suspect this is not the case. If the latter, how would the gradients be evaluated for the stopping condition? Would the error averaged over the samples? I haven't been able to find anything further online besides how the update function works, nothing on implementing it within a neural network algorithm. I assume this method would be the same for 'mini-batch' gradient descent. Some pseudo-code to help explain my confusion: while(epoch
