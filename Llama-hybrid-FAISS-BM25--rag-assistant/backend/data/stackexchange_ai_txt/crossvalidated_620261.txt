[site]: crossvalidated
[post_id]: 620261
[parent_id]: 
[tags]: 
ValueError while fitting a neural networks model on Consumer Complaints data

I am trying to build a keras tensorflow neural network model. I have never built a NN model prior so facing challenges with some very basic error. I Was able to build the model using following code. I Am not adding packages for sake of brevity. %%time # prepare text data for LSTM max_features = 20_000 MAX_SEQUENCE_LENGTH = 25 tokenizer = Tokenizer(num_words=max_features, split=' ') tokenizer.fit_on_texts(df2["cleaned_text"]) X = tokenizer.texts_to_sequences(df2["cleaned_text"]) X = pad_sequences(X, maxlen = MAX_SEQUENCE_LENGTH) y = pd.get_dummies(df2['category_id']).values X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=df2["category_id"], test_size = 0.2, random_state = 43, shuffle=True) print(X_train.shape,y_train.shape) print(X_test.shape,y_test.shape) vocab_size = len(tokenizer.word_index) + 1 # build model model = Sequential() model.add(Embedding(input_dim=vocab_size, # Size of the vocabulary output_dim=50, # Length of the vector for each word input_length = MAX_SEQUENCE_LENGTH)) # Maximum length of a sequence model.add(SpatialDropout1D(0.5)) model.add(LSTM(15, dropout=0.5, recurrent_dropout=0.5)) model.add(Dense(20,input_shape=Y_train.shape, activation='softmax')) model.add(Dense(20, activation='softmax')) model.add(Dense(num_top_labels,activation='softmax')) #model.add(Dense(1)) model.compile(loss = 'categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics = ['accuracy']) print(model.summary()) After this when I fit the model usign below piece of code, I Get the ValueError: Classification metrics can't handle a mix of multiclass and multilabel-indicator targets. First time it occured at 21st Epoch, 2nd time at 25th epoch. batch_size = 64 class_weights = compute_class_weight(class_weight = "balanced", classes = np.unique(Y_train), y = Y_train) class_weights = dict(zip(range(num_top_labels), class_weights)) #print("class_weights: ", class_weights) history = model.fit(X_train, y_train, class_weight=class_weights, # fix class imbalance epochs = 25, batch_size=batch_size, validation_split=0.2, callbacks=[ EarlyStopping(monitor = "val_loss", patience = 10, restore_best_weights = True), ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, mode='min') ] ) y_pred = model.predict(X_test) print('Accuracy:', accuracy_score(Y_test, y_pred.round())) print('F1 score:', f1_score(Y_test, y_pred.round(), average='weighted')) print(classification_report(Y_test, y_pred.round())) How can I fix this?
