[site]: crossvalidated
[post_id]: 228551
[parent_id]: 125244
[tags]: 
Not really, because overfitting will likely be a major problem even with $K$ and $P$ being rather small. Take $K=P=3$. There will be $\left(^{KP}_{\text{round}(KP/2)} \right)=\left(^{3\cdot 3}_{\text{round}(3\cdot 3/2)}\right)=\left(^9_5\right)=126$ different models with 5 nonzero coefficients in each equation. For models with the same number of nonzero coefficients, AIC-based selection will be nothing more than likelihood-based selection, which is prone to selecting an overfitted model. Increase $K$ and/or $P$ just a little, and you will get exorbitant numbers in place of 126. See more about the winner's curse when selecting from a large pool of models using information criteria in Hansen "A winnerâ€™s curse for econometric models: on the joint distribution of in-sample fit and out-of-sample fit and its implications for model selection" (2010). Regularization (just as you mention), (frequentist) model averaging and/or forecast averaging could be more effective approaches to forecasting. Bayesian alternatives could be BVAR modelling and also Bayesian model averaging. The (negative) effect of overfitting due to the proposed model selection scheme may considerably dominate the loss/gain in efficiency due to the use of OLS versus FGLS.
