[site]: crossvalidated
[post_id]: 406337
[parent_id]: 404589
[tags]: 
This is a possible check but, unfortunately, ctree() does not include this information in its output as this would potentially require a lot of storage on larger data sets. But you can compute the information "by hand" using the coin package, see below for a worked example. Moreover, you could assess the stability of the tree and the estimated split points by bootstrapping. This is available out of the box in the stablelearner package and in my opinion the more comprehensive check. But first about the statistics for the split point. As a simple example consider a tree for the cars data: library("partykit") ct Thus, the first split is speed independence_test() with the coin` package for every possible split point: library("coin") sp Alternatively, you can bootstrap the learning data and re-fit the tree on every bootstrap sample. This is what stabletree() from the stablelearner package offers along with nice functions to summarize and visualize the variation in the resulting split points. Here: library("stablelearner") sb Thus, most bootstrap samples lead to splits points that are very close to the two split points from the original tree ( ct ).
