[site]: crossvalidated
[post_id]: 579012
[parent_id]: 578191
[tags]: 
IIUC, you want to add to the features (id, height, weight) as an additional feature the average of the student's performances to better predict the student's next score. The problem is that, in the training data, the average already contains, in a noisy way, the response, and even future scores. I.e. you use information that is not available when you apply the model. E.g. for students that have taken the test exactly once, the average would contain precisely the score. That might lead random forest to put more "weight" on the "average" feature than it deserves. You could remedy this by creating training data that contains the average of only the previous scores of this student. For new students, I suggest taking as imputation, instead of 0.5, the average score of all students with comparative height and weight. Another thought is the following: The average does not contain any trend. E.g. the score from last year is probably more important than that from five years ago. Let's say the maximum number of years at the school is six. Then I would suggest adding the previous five scores as additional data, such that e.g. all the most recent scores are in the same column, as are all the scores from two years ago, and so on. To handle the scores that are not available, because the student was not yet present, you could add additional five binary variables indicating "presence". I trust that random forest will figure out that the value in "score" does not contain information if the belonging field "presence" for that year is zero. This way, you add a small binary time series to each row, which contains considerably more information than just an average. Also, you don't have the trend in the height-weight ratio. I.e., if you consider this relevant, you could do the same with the two features "height" and "weight" as with the "score", except that those time series would also contain the values for the present.
