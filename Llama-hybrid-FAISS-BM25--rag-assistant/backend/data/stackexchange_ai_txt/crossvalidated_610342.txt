[site]: crossvalidated
[post_id]: 610342
[parent_id]: 
[tags]: 
Is the "Bayesian approach" about prior beliefs, viewing parameters as random variables, or both?

It seems to me like the concepts of incorporating prior beliefs about parameters VERSUS viewing parameters as latent random variables are two VERY separate concepts, and yet I've found that they're often confounded and treated as one. Can't we have prior beliefs about what the most likely value of a parameter is without actually believing that the parameters are "random variables" i.e they do have a single "true" value, but there's just uncertainty about what that value is. The fact that we have "prior knowledge" about what the value of the parameter might be and that we encode that via a prior probability distribution doesn't seem to me to exclude the possibility that that thing we're talking about (the "parameter") is a fixed, albeit latent value. I've taken a course in Bayesian statistics, and have read online about Bayesian analysis, but I actually still do not fully understand this. EDIT: Just to be a bit more concrete, suppose we conduct an analysis “as a frequentist,” and infer the value of some parameter. However, because we have some prior knowledge about the parameter, we use a prior that reflects our uncertainty about the value of the parameter. But just because we used a prior doesn’t require us to assume that the parameter we’re inferring is inherently random. The resulting probability distribution of the inferred parameter is simply arising because of uncertainty, not inherent randomness in the parameter. We still believe, as frequentists, that the parameter has a fixed, latent value. So are we being Bayesian, or frequentist, or a combination of both in this type of scenario?
