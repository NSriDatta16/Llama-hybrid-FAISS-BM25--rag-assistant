[site]: stackoverflow
[post_id]: 1984061
[parent_id]: 1983563
[tags]: 
The first difference I noticed is that Windows Vista always uses the Low Fragmentation Heap (LFH). Windows XP does not seem to. RtlFreeHeap in Windows Vista is a lot shorter as a result -- all the work is delegated to RtlpLowFragHeapFree . More information regarding LFH and its presence in various OSs. Note the red warning at the top. More information (remarks section): Windows XP, Windows Server 2003, and Windows 2000 with hotfix KB 816542: A look-aside list is a fast memory allocation mechanism that contains only fixed-sized blocks. Look-aside lists are enabled by default for heaps that support them. Starting with Windows Vista, look-aside lists are not used and the LFH is enabled by default . Another important piece of information: LFH and NO_SERIALIZE are mutually-exclusive (both cannot be active simultaneously). Combined with Starting with Windows Vista, look-aside lists are not used This implies that setting NO_SERIALIZE in Windows Vista disables LFH, but it does not (and cannot) fall back to standard look-aside lists (as a fast replacement), according to the above quote. I'm unclear as to what heap allocation strategy Windows Vista uses when NO_SERIALIZE is specified. It looks like it's using something horribly na√Øve, based on its performance. Even more information: Looking at a few stack snapshots of allocspeed.exe , it seems to always be in a Ready state (not Running or Wait), and in TryEnterCriticalSection from HeapFree, and pegging the CPU at nearly 100% load for 40 seconds. (On Windows Vista.) Sample snapshot: ntdll.dll!RtlInterlockedPushEntrySList+0xe8 ntdll.dll!RtlTryEnterCriticalSection+0x33b kernel32.dll!HeapFree+0x14 allocspeed.EXE+0x11ad allocspeed.EXE+0x1e15 kernel32.dll!BaseThreadInitThunk+0x12 ntdll.dll!LdrInitializeThunk+0x4d Which is strange, because NO_SERIALIZE precisely tells it to skip lock acquisition. Something doesn't add up. This is a question only Raymond Chen or Mark Russinovich could answer :)
