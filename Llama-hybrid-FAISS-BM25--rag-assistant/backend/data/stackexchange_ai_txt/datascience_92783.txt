[site]: datascience
[post_id]: 92783
[parent_id]: 
[tags]: 
CNN seems doing good during training and validation but not really

I'm doing a simple binary classification using this dataset import os train_dir = "/tmp/Dataset/TrainingandValidation" fire = os.path.join(train_dir, 'fire') nofire = os.path.join(train_dir, 'nofire') test_dir = "/tmp/Dataset/Testing/" tfire = os.path.join(test_dir, 'fire') tnofire = os.path.join(test_dir, 'nofire') from tensorflow.keras.preprocessing.image import ImageDataGenerator test_data = ImageDataGenerator(rescale=1.0/255.) train_data = ImageDataGenerator (rescale= 1.0/255.) train_images = train_data.flow_from_directory (train_dir, batch_size= 20, class_mode='binary', target_size=(150,150)) test_images = test_data.flow_from_directory(test_dir, batch_size=20, class_mode='binary', target_size = (150,150)) import tensorflow as tf model = tf.keras.Sequential ([ tf.keras.layers.Conv2D (16, (3,3), activation='relu', input_shape =(150,150,3)), tf.keras.layers.MaxPool2D(2,2), tf.keras.layers.Conv2D (32, (3,3), activation='relu'), tf.keras.layers.MaxPool2D(2,2), tf.keras.layers.Conv2D (64, (3,3), activation='relu'), tf.keras.layers.MaxPool2D(2,2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(512, activation='relu'), tf.keras.layers.Dense(1, activation= 'sigmoid') ]) model.summary() from tensorflow.keras.optimizers import RMSprop model.compile(optimizer= RMSprop (lr=0.001), loss = 'binary_crossentropy', metrics=['accuracy']) from tensorflow.keras.callbacks import Callback class myCallback(tf.keras.callbacks.Callback): def on_epoch_end(self, epoch, logs={}): if(logs.get('accuracy')>0.94): print("\nReached 94% val_accuracy") self.model.stop_training = True callbacks = myCallback() history = model.fit(train_images, validation_data=test_images, steps_per_epoch= 76, epochs=15, validation_steps= 19, callbacks= [callbacks]) import numpy as np # uploading images to predict from google.colab import files from keras.preprocessing import image uploaded=files.upload() for fn in uploaded.keys(): # predicting images path='/content/' + fn img=image.load_img(path, target_size=(150, 150)) x=image.img_to_array(img) x= x/255.0 x=np.expand_dims(x, axis=0) images = np.vstack([x]) classes = model.predict(images, batch_size=1) print(classes) if classes[0]>0: print(fn + " fire") else: print(fn + " no fire") The model is getting well as below : Epoch 14/15 76/76 [==============================] - 3s 40ms/step - loss: 0.0524 - accuracy: 0.9812 - val_loss: 0.2918 - val_accuracy: 0.9474 Reached 94% val_accuracy Although it might look it's overfitting or so, when I upload images to predict them the model almost always predict 1 (fire), even if I ask it to predict training images! I tried adding a dropout layer before the last layer but not much better. I feel like there's something wrong with the preprocessing of the images?
