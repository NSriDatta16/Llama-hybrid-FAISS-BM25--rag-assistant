[site]: crossvalidated
[post_id]: 385809
[parent_id]: 
[tags]: 
How is One-Hot Encoding interpreted by an Algorithm?

I'm new to machine learning, and just learned about the use of one-hot encoding as a method of passing a categorical variable as an input into a machine learning algorithm. As I understand it, one of the advantages of one-hot encoding is that it allows the algorithm to learn separate weights for each possible value of the categorical variable. My questions are the following: If the model is made to learn a separate weight for each input feature, how can it learn N weights when it comes to a one-hot encoded feature of N possible values, and then only apply the relevant one? Isn't this the same as turning the categorical variable into N individual boolean features? Thanks in advance!
