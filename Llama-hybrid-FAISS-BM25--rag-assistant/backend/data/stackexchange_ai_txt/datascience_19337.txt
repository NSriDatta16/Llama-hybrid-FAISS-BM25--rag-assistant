[site]: datascience
[post_id]: 19337
[parent_id]: 6744
[tags]: 
As far as PCA components are concerned you should use the same number of PCA for test data. The logic behind this is that same transformation should happen to test data that happened to train data. I am assuming here that your train and test data are independently drawn. In fact, it is important to normalize your data before applying PCA. There is a science behind it where it calculates the importance of a variable and if you won't normalize, it will give high weightage to values which are numerically high in value so it's important to normalize before PCA. If you want to apply SVM on top of it normalization is fine. The basic says that scale should remain same for any process thus after normalization you should use the same scale that is same max and min.
