[site]: crossvalidated
[post_id]: 355511
[parent_id]: 355489
[tags]: 
For something to be "Bayesian," in my experience, it generally has to be something that makes explicit use of Bayes' theorem. Even then, what people generally refer to as "Bayesian" are the Markov Chain Monte Carlo (MCMC) methods to sample from a posterior, often using software like Stan, BUGS, or JAGS. I don't see many people referring to themselves as "Bayesians" because they use a naive Bayes classifier to classify tweetsâ€”these people are generally those that use MCMC. Thus, just the straight-up math of what you wrote is not necessarily "Bayesian." As an aside, you note that: "since Z, a parameter is now treated as not fixed, but having a distribution, is this now a Bayesian model?" Following from my first point above, I wouldn't call anything randomly-distributed as "Bayesian." It just has a random effect. There are tons of frequentist methods (using maximum likelihood, getting 95% confidence intervals, generating p-values, etc.) that allow parameters to come from distributions. Any multilevel model is saying that some parameter (say, an intercept or a slope) comes from a distribution (usually assumed to be normal with some variance). On the other hand , you could use the first line as the likelihood and the second line as a prior. This would be like saying: "Y is Poisson-distributed with a mean of Z" (the likelihood); "Beforehand, we think Z is gamma-distributed from a gamma distribution where a = some number and b = some number ." Then you could use your favorite MCMC machine and sample from the posterior and get some results. This would be "Bayesian." Bayesian and frequentist are two schools of thought on understanding probability. But these schools of thought aren't completely disparate and wholly demarcated; neither of the schools of thought has ownership of any given model. I agree with Sycorax's comment.
