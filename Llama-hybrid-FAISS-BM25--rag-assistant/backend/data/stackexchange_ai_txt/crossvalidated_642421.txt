[site]: crossvalidated
[post_id]: 642421
[parent_id]: 642407
[tags]: 
Your question relates to a few different and loosely-related concepts, so I'll try to address each of them. (1) In short, SHAP value of a feature $x_j$ is the average absolute contribution of this feature to the difference between the actual prediction $f(\cdot)$ and the expected prediction $E[f]$ (see here ): $$\phi_j=\frac{1}{n}\sum_{i=1}^n \left|f\left(x^{(i)}_j\right)-E[f(X_j)]\right|$$ It's OK to take SHAP values as a measure of variable importance (kinda gold standard these days) but it's important to remember two things: They don't account for feature interaction They are relative - that is, changing the feature space might change the SHAP values Once you have the SHAP values set for the full feature space you can obviously take only the relevant indices using vector operations in R/python, but if I understand you correctly then you are looking for the SHAP values when the model only has those features you think are important - in which case you need to train a new model with the feature subspace and then request the SHAP values. (2) If I understand correctly, you are looking for some kind of feature selection method. You can select a feature subspace based on SHAP values (not really sure what's the literature regarding this idea) but then you need to train a new model using that subspace If you train a model on feature space $X_1,...X_p$ but use only a subspace of it and completing the remainder as weighted averages (like you described), not only you're violating the basic concepts of decision trees but to me (without doing the whole math) it looks as if you were contaminating the data with some randomly-drawn values in place of the dropped features. Which is my way of saying that it sounds totally crazy to me, but maybe I'm missing something there. (3) XGBoost is based on a large number of "meaningless" decision trees (each tree is short and not very accurate), which form a very strong ensemble when combined. That is unlike random forests, in which each of the trees is both long (/deep) and meaningful. Its importance values might differ greatly compared to other models, because in a way the meaninglessness of the trees makes the importance quite idiosyncratic. For example consider this plot of SHAP values for 5 different models in predicting Titanic survival: (4) It's true that XGBoost models provide SHAP "on the house" but it's not that difficult for other models. In R there's the fastshap package (see tutorial ) which is my personal favorite. I suppose similar packages are available for python as well.
