[site]: crossvalidated
[post_id]: 441806
[parent_id]: 441779
[tags]: 
I wouldn't read into the term "continuous depth" too much. It's just that since the ODE allows you to evaluate the neural network at any layer (for example we could compute $h(\pi)$ to obtain the value of the network at $\pi = 3.14\ldots$ , the concept of depth and number of layers is not meaningful. You could say there are an infinite number of layers, but that's not a helpful description. The authors use NFE (number of function evaluations) as a proxy for "depth" because just as we expect model expressivity and complexity to increase with depth in a typical network, we expect more powerful neural ODEs to require a larger NFE to solve. I think this is what you were getting at. While this definition of "depth" is useful for comparing model capacities and computational efficiency, it's very distinct concept from my usual conception of network depth.
