[site]: crossvalidated
[post_id]: 76711
[parent_id]: 76682
[tags]: 
Well, the short answer is that's what falls out of the math. The long answer would be to do the math$^3$. Instead I'll try to rephrase gung's explanation that these are two different (though related) things. You've collected a sample $X_1...X_n$ that is normally distributed with unknown variance$^4$ and want to know if its average is different from some specified value $\mu$. The way you do this is to compute a value that represents how "different" your observations are from the assumption that $\bar{x}=\mu$. Thus the formula for the $t$-statistic$^1$ you presented. Probably the most intuitive way of thinking about why this increases with $n$ is that you have more "confidence" that things are different when you have more samples. Moving on, this value follows a $t$-distribution$^2$ with $n-1$ degrees of freedom. The way to think about this is that the $t$-distribution is slightly different depending on your sample size. You can see plots of this distribution with 2, 3, 5, and 20 df below. You'll notice that higher df has more mass in the center and less in the tails of the distribution (I have no intuitive reasoning for why the distributions behave this way, sorry). The critical $t$-value is the x-location where the area under the curve equals a somewhat arbitrary value of your choosing (traditionally 0.05). These values are marked on the graph as points. So for the green curve (df=5), the area under the curve to the left of the left green dot = 0.025, and the area under the curve to the right of the right green dot = 0.025, for a total of 0.05. This is why the critical $t$-values decrease with increasing degrees of freedom - as df increases, the critical values must get closer to zero to keep the same area under the curve. And as gung mentioned, as df goes to $\infty$, the curve and critical values will approach that of a standard normal distribution. So now you have your critical value and your $t$-statistic, and can perform the $t$-test. If your $t$-statistic is greater than the critical value, you then can make the statement that if $\bar{x}=\mu$ really was true, then you would have observed your sample less than 5% (or whatever arbitrary percentage you chose to calculate the critical value for) of the time. $^1$ Why do we calculate this particular value out of the many arbitrary values we could calculate? Well, this is what falls out of a calculation of a likelihood ratio test $^3$. If you knew the variance of the samples beforehand, the $z$-statistic (following a normal distribution) mentioned by gung would fall out of this calculation instead, and you would perform a $z$-test $^2$ Again, this is what falls out of the math$^3$ $^3$ First good result from google: http://math.arizona.edu/~jwatkins/ttest.pdf $^4$ It turns out the t-test works even if that assumption is not met, but that's a digression
