[site]: crossvalidated
[post_id]: 387518
[parent_id]: 387482
[tags]: 
In essence, max-pooling (or any kind of pooling) is a fixed operation and replacing it with a strided convolution can also be seen as learning the pooling operation, which increases the model's expressiveness ability. The down side is that it also increases the number of trainable parameters, but this is not a real problem in our days. There is a very good article by JT Springenberg, where they replace all the max-pooling operations in a network with strided-convolutions. The paper demonstrates how doing so, improves the overall accuracy of a model with the same depth and width: "when pooling is replaced by an additional convolution layer with stride r = 2 performance stabilizes and even improves on the base model" Striving for Simplicity: The All Convolutional Net I encourage you to read the article, it isn't a hard read.
