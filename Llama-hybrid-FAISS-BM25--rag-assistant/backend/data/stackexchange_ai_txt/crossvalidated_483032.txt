[site]: crossvalidated
[post_id]: 483032
[parent_id]: 482895
[tags]: 
You have a single survey response from each individual to consider, but either 1 or 2 observations of a binary outcome for each. If you don't care about the time between taking the survey and the adherence observation, or about systematic differences with time for those having 2 observations, this could in principle be simply handled by a mixed logistic regression model, with a fixed effect for the survey response and patient having random intercepts. Say that your survey results are put together on a combined scale such that the mean response is 0. Then a logistic regression model with just 1 observation per patient would return an intercept representing the log-odds of being adherent if the survey response were 0, and the slope would be how much the log-odds changed per unit change in the survey response. The possibility of having more than 1 observation per patient, with patient adherence likely to be correlated between the observations, is handled by allowing each patient to have a different random intercept: the estimated log-odds of adherence if their survey response had been 0 . The distribution of intercepts among patients is taken to be Gaussian. Fitting the model simultaneously finds the best estimates of the overall intercept, the distribution of individual-patient intercepts around that, and the overall slope with respect to survey response. That pools information from all observations, effectively weighting patients with 2 observations more than those with a single observation. This approach might be extended to consider time post-survey as a continuous predictor, if there were adequate data and you could assume a linear change in log-odds of adherence with time or some other simple relationship. That could take advantage of the actual survey-to-observation time differences from all your cases, not just those having 2 observations. That said, your ability to evaluate predictors in a binary-outcome analysis is limited by the number of cases in the minority class, here the 29 non-adherence observations. The usual rule of thumb is you can examine about 1 predictor per 15 members of the minority class without overfitting. So don't go overboard in "looking at which variables on a survey predict a positive drug test result." The risk in examining too many predictors is that you might find a relationship that works very well in your current data set but doesn't work well on a new data set. I'd recommend using your knowledge of the subject matter to put together aspects of the survey into a small set of predictors, each of which combines related survey answers. Think about how individual Likert items are combined into a Likert scale .
