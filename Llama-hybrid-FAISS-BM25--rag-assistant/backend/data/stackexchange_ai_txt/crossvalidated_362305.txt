[site]: crossvalidated
[post_id]: 362305
[parent_id]: 362297
[tags]: 
From my understanding, you are correct in assuming you need not difference your input data before running it through your MLP. One of the most helpful recent papers I have read was this one , written by a Standard Charter Bank researcher. It goes into detail about the process of discovering "what makes a curve move." A common way to account for this autocorrelation you describe in your data is using Long Short-Term Memory (LSTM) learners. They are a derivative of Recurrent Neural Networks (RNNs) with the ability to "remember" information over a long period of time. There are many helpful resources for understanding these machines, but one I have found most enlightening was this blog post , specifically the "The Core Idea Behind LSTMs" section. In it, it describes the way LSTMs work for time series forecasting with long time horizons like yours. In fact, the keras implementation of LSTMs takes an 3D matrix with dimensions [observations, timesteps (lags), factors] as its input, indicating it is able to handle non-differenced data by understanding the lagged dataset of your input instead. If you are interested in scaling your data pre-running (highly recommended) I would look at this paper (click "View PDF" in the page), specifically the section "Constructing the Ensemble."
