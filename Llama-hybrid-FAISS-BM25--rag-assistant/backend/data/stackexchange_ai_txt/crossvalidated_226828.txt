[site]: crossvalidated
[post_id]: 226828
[parent_id]: 226825
[tags]: 
Evaluating implicit feedback based recommendations is tricky. Here are couple of approaches that I'd recommend. Approach 1 You can use modified precision and recall metrics. Overall the procedure would be as follows, Divide your data into train and test set by users . For a user in test set, given their history, get the top N recommendations using implicit feedback based model. Precision can be calculated using # of recommendations given by model which actually matched by what user had acted upon (for example read in case of articles). Recall can be calculated using # of user actions (articles read by user) that were captured by top N recommendations. You can calculate these for all users in test set and average them. Approach 2 The approach is similar to approach 1, but rather than splitting train and test data by users, you use something called as "leave one out" strategy. We use a simple accuracy metric in this case. The steps to calculate the accuracy will be as follows, For each user (or a subset of users), hide one of the articles read/browsed and move it to test set (leave one out). Using user history, get top N recommendations for each user. Calculate the number of times the left out article was captured by the top N recommendations. Note that in both cases, the N in top N recommendations will become your hyper-parameter which can be tuned further.
