[site]: crossvalidated
[post_id]: 178575
[parent_id]: 153099
[tags]: 
This question is months old now but it's still interesting. To me this sounds like a massive contingency table or sparse data, tensor problem. This doesn't make any of the MDP or reinforcement learning issues moot, it just realigns the statistical framework within which they are modeled. The decision or dependent variable is whether or not a song from a potentially very large playlist gets chosen and, once chosen, whether it gets rejected or played. Correct me if I'm wrong, but can't this be treated with effect coding or 0, 1 for yes/no -- is it played? -- and -1 if it's rejected? Based on the question, I don't see any reason to treat this as a sequential Markov chain or longitudinal time series, particularly given the random nature of the draws from the playlist, but can be convinced otherwise. Exceptions to this rule could include consideration of whether the algorithm is "learning" song preferences as a function, for instance, of genre. Sparsity would be a function of the interval for the time frame over which the choices are aggregated as well as the size of the playlist. If the interval is too short or the playlist is too large, sparsity is the inevitable outcome. The state-of-the-art for tensor modeling are probably David Dunson's papers, e.g., Bayesian Tensor Regression , but there are lots of people with plenty of papers working in this field (see DDs papers on his Duke website for reviews).
