[site]: crossvalidated
[post_id]: 545993
[parent_id]: 545873
[tags]: 
You'd concatenate the images together in different channels and the neural network would interpret it the same way it would an RGB image. This can even be done if the images were 3D, using the Conv3D and MaxPooling3D layers. Convert the DICOMs to NIFTIs using dcm2niix (a terminal program), read them in using nibabel, convert them to numpy arrays, and concatenate the individual files together using np.concatenate((im1,im2,im3),axis=-1). Some untested code for how to do this in the two-channel case. You'd probably need GPUs handy for it to be effective: import nibabel as nib import numpy as np from scipy.ndimage import zoom from tensorflow.keras.layers import * from tensorflow.keras import Model filelist_flair = ["file1_flair.nii.gz","file2_flair.nii.gz"] filelist_dwi = ["file1_dwi.nii.gz", "file2_dwi.nii.gz"] label_filename = "has_tumors.txt" imsize = (64,64,64) X = np.zeros((len(filelist_flair),imsize[0],imsize[1],imsize[2],2)) Y = np.zeros((len(filelist_flair),)) # Reads in image files, converts to numpy, resizes to standard size for i in range(len(filelist_flair)): flair_file = filelist_flair[i] dwi_file = filelist_dwi[i] flair_im = np.squeeze(nib.load(flair_file).get_fdata()) dwi_im = np.squeeze(nib.load(dwi_file).get_fdata()) assert(len(dwi_im.shape) == 3 and len(flair_im.shape) == 3) zp_flair = [imsize[i]/flair_im.shape[i] for i in range(len(imsize))] zp_dwi = [imsize[i]/dwi_im.shape[i] for i in range(len(imsize))] flair_im = zoom(flair_im,zp_flair) dwi_im = zoom(dwi_im,zp_zoom) X[i,:,:,:,0] = flair_im X[i,:,:,:,1] = dwi_im # Read in labels for Y here # Add more layers and stuff inputs = Input(shape=(imsize[0],imsize[1],imsize[2],2)) x = Conv3D(32,(2,2,2),activation="relu")(inputs) x = MaxPool3D(pool_size = 2)(x) x = BatchNormalization()(x) x = Flatten()(x) x = Dense(64,activation="relu")(x) x = BatchNormalization()(x) x = Dense(1,activation="sigmoid")(x) # or Dense(2,activation="softmax")(x) m = Model(inputs,x) m.compile(loss="binary_crossentropy",optimizer="adam") m.fit(X,Y) # Separate into training and test sets before you do this
