[site]: crossvalidated
[post_id]: 331335
[parent_id]: 331330
[tags]: 
The joint distribution $$ f(\theta, k) \propto {N \choose k} \theta^{k+\alpha_0 - 1}(1-\theta)^{N-k+\beta_0 - 1} \tag{1}. $$ That means $$ f(\theta \mid k) = \text{Beta}(k + \alpha_0, N-k+\beta_0) \tag{2}. $$ Gibbs sampling in this case would involve iterations that alternate by drawing from $f(\theta \mid k)$ and $f(k \mid \theta)$ (which is given). This would give you draws from a Markov chain with a stationary distribution equal to the joint distribution above. They would look something like: $$ (\theta_0, k_0),(\theta_0, k_1) ,(\theta_1, k_1) ,(\theta_1, k_2) ,\ldots $$ You are correct that it's strange to do Gibbs sampling in this situation because you are targeting a joint distribution, and usually in practice you target the posterior. The posterior is completely known (2), and the joint is also known ((1) is a Beta-Binomial). However, this is a common example used for for illustrative purposes.
