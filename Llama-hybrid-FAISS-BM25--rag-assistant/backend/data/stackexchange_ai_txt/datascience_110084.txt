[site]: datascience
[post_id]: 110084
[parent_id]: 110063
[tags]: 
We require some link function to map some real-valued output $u \in \mathbb{R}$ to $[0,1]$ so that we may interpret it as probabilities. Obviously there are many such functions, but the standard logistic (sometimes called sigmoid) is simple and convenient since its units of scale is log-odds which is easy to interpret. It is also symmetric. In Economics, we might view $u$ as representing latent utilities, $$ u = f(x;\beta) + \epsilon $$ where $f(x;\beta)$ is some model of observed covariates (e.g. $f(x) = \beta'x)$ . It is common to assume $\epsilon$ is the standard logistic distribution as it is more "robust" than the normal distribution since it has fatter tails. Then we just end up with the canonical sigmoid link function and logit model. If we had assumed some other distribution for $\epsilon$ , for instance normal, then we end up with the normal CDF as the link and probit model. If we think it was asymmetric and assumed $\epsilon$ is Gompertz, then we end up with the Extreme Value model. Different fields use different types of logistic regression to model the problem. For instance in epidemiology, they might use a Richards growth (generalized logistic function) so that infection rates start off small but get exponentially larger. In computer science/machine learning, for prediction problems we usually don't have an interpretation for $u$ (e.g. output of a neural network) and so we typically just use the standard logistic activation for convenience.
