[site]: crossvalidated
[post_id]: 433746
[parent_id]: 433736
[tags]: 
(1) Simple Gibbs example: Sample from bivariate normal distribution with $\mu_x = \mu_y= 0, \sigma_x = \sigma_y = 1, \rho = .8.$ This can be done as follows using a Gibbs sampler, based on $X|Y=y \sim \mathsf{Norm}(\rho y, \sqrt{1-\rho^2})$ and $Y|X=x \sim \mathsf{Norm}(\rho x, \sqrt{1-\rho^2}).$ One cycles back and forth between the two conditional distributions to get a Markov chain with the desired bivariate distribution as its limiting distribution. The burn-in period used below is at half of the iterations. set.seed(1029); m=100000 xc = yc = numeric(m) rho=.8; sgm=sqrt(1-rho^2) xc[1]=-3; yc[1]=3 # start step for(i in 2:m) { xc[i] = rnorm(1,rho*yc[i-1],sgm) yc[i] = rnorm(1,rho*xc[i],sgm) } x = xc[(m/2+1):m]; y = yc[(m/2+1):m] round(c(mean(x),mean(y), sd(x),sd(y), cor(x,y)),3) [1] 0.001 0.004 1.004 1.003 0.800 (2) Chib and Greenberg (1994), Understanding the Metropolis-Hastings Algorithm, The American Statistician, 49 327-335, generate a correlated bivariate normal distribution as a simple illustration of the M-H algorithm. Any pedagogical purposes aside, both (1) and (2) are inefficient for this simple simulation because @glen-b's method is simpler.
