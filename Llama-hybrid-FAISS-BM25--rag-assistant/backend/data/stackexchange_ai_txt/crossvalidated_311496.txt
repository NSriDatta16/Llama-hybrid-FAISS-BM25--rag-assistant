[site]: crossvalidated
[post_id]: 311496
[parent_id]: 
[tags]: 
MSE loss and information

I'm thinking if there's a way of interpreting mean square error loss frequently applied in statistics and machine learning under the information framework? Suppose we have two random variables (or vectors), $X$ and $Y$, and let's denote their observations by $\tilde{X}_i$ and $\tilde{Y}_i$, $i=1,\ldots,n$. Our job is to predict $Y$ as best as we can. In regression tasks, one is often encouraged to find a function $f$ such that $L(f) = \frac{1}{m}\sum_i (f(\tilde{X_i})-\tilde{Y_i})^2$, the squared error, is minimized. We often feel comfortable to apply $f$ on $X$ to predict $Y$. From an intuitive point of view, if we denote all possible regressors are in the set $\Omega$, and if $\min_{f\in\Omega}L(f)$ is sufficiently, we can say that $X$ contains enough "information" about $Y$. Now the function $f$ minimizing the loss globally may not be found, but once you find a $f$ such that $L(f)$ is obtained, I suppose, in principle, one can obtain a lower bound of how much information $X$ contains about $Y$. In information theory, the idea of information is formalized by the self-information w.r.t a random variable, $H(X), H(Y)$, mutual information between two variables, $I(X,Y) = H(X) - H(X|Y)$ and the K-L divergence $D(Y||X)$. My question is, can we find a lower bound for $I(Y|X)$ or $D(Y||X)$ once we are given a regressor $f$ and its MSE $L(f)$, without specifying the distribution of $Y$ or $X$? Or is it in principle possible? Another often used loss function is the cross entropy loss. Would the problem become easier if we replace MSE with cross entropy loss, since it is in form consistence with the definition of information?
