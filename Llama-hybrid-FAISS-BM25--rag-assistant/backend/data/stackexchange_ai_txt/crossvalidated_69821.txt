[site]: crossvalidated
[post_id]: 69821
[parent_id]: 69820
[tags]: 
You got logistic regression kind of backwards (see whuber's comment on your question). True, the logit of 1 is infinity. But that's ok, because at no stage do you take the logit of the observed p's. Consider standard regression, for simplicity using a single x variable: y = b0 + b1*x Logistic regression means that y is not interpreted as the response proportions (the p's), but rather as the logit of the response proportions. So let's say a p = 1. Because its logit is infinity, with finite b0 and b1, the logistic regression will never exactly predict it except asymptotically as x approaches infinity. With the observed proportion of 1, the logistic regression for that x can however predict a very high probability (but again, never as high as 1), say .99. Then, the probability of observing a proportion of 1 for a limited number of trials can easily be large. So when logistic regression corresponds to maximizing the likelihood, the probability of that data point given the model can be high. So, a proportion of 1 need not be more influential (to "drive the regression to always have infinite slope") than any other proportion. This is also true for other sigmoidal-link regression types such as probit.
