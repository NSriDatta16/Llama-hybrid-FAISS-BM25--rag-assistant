[site]: crossvalidated
[post_id]: 517318
[parent_id]: 463303
[tags]: 
Also, in XGBoost the default measure of feature importance is average gain whereas it's total gain in sklearn. See, https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn importance_type (string, default "gain") – The feature importance type for the feature_importances_ property: either “gain”, “weight”, “cover”, “total_gain” or “total_cover”. and https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. Specifying importance_type='total_gain' in XGBoost seems to produce more comparable rankings.
