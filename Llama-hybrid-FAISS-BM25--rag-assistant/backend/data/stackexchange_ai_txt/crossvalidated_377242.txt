[site]: crossvalidated
[post_id]: 377242
[parent_id]: 
[tags]: 
Bayesian inference - iterative updating with Bernoulli distribution

Suppose I pull samples from a Bernoulli distribution $\mathcal{B}(\theta)$ I don't know the value of $\theta$ , but in my case I know that $\theta$ can only have 11 discrete values, $\theta \in \{0.0, 0.1, 0.2, \ldots, 0.9, 1.0\}$ I want to figure out the distribution $P[\theta]$ using Bayesian inference. Because I know that $\theta$ can only have 11 possible values, $P[\theta]$ will be a discrete distribution over 11 values. So, I start with a non informative prior $P_{0}[\theta]=\frac{1}{11}$ for all $\theta$ I iterate for each new sample, and I set $P_{n+1}[\theta]=\frac{P[\text{data}\mid\theta]\space P_{n}[\theta]}{\sum P[\text{data}\mid\theta]\space P_{n}[\theta]}$ So far so good... but when I use the Bernoulli distribution for $P[\text{data}\mid\theta]$ , that is $P[\text{sample}\mid\theta] = \theta^\text{sample} (1-\theta)^{1-\text{sample}}$ the algorithm does not converge! Instead, the algorithm converges splendidly when I use the Binomial distribution for $P[\text{data}\mid\theta]$ . That is $P[\text{data}\mid\theta] = \theta^\text{successes}(1-\theta)^{n-\text{successes}}$ Why do I need to use the Binomial distribution, to estimate the parameter of a Bernoulli distribution?
