[site]: crossvalidated
[post_id]: 56360
[parent_id]: 
[tags]: 
Handle features of different dimensions

I have some previous knowledge about classification, however am now struggling in understanding how classification algorithms can deal with features with different dimensions. Up to now I have only used a feature vector consisting of scalars, where each scalar had one feature for itself (e.g. the variance of the data). Now, in my current problem, I want to use features that are either scalars as before or vectors (or histograms) themselves. I would hence have a feature vector looking similar to this: feature_vector = { 2, {3,4,5}, 5, {6,7,8,9}, ...} Can the standard classification algorithms deal with this? For SVMs maybe I could devise a kernel that works on sets of vectors, but e.g. for Random Forests I don't see how I can use such a feature vector. What is the general approach in this kind of situation? Maybe you would simply concatenate the vectors (i.e. remove the { )? Thanks in advance!
