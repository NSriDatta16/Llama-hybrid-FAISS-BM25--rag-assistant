[site]: crossvalidated
[post_id]: 389261
[parent_id]: 389162
[tags]: 
I assume you mean the SHAP paper and are referring to this chapter: Shapley Values . You can basically find the answer in the Supplemental Material of the Lundberg paper: http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions I'll try to summarize it here. Efficiency Efficiency is defined as: $$\sum_{i=1}^M \phi_i^* = f(x) - E_X(f(X))$$ Local Accuracy according to Lundberg is: $$f(x) = \phi_0 + \sum_{i=1}^M\phi_ix_i'$$ By defining $\phi_0^* = E_X(f(X))$ and $\phi^*_i=\phi_i x_i'$ both local accuracy and efficiency are equivalent. They both say that the prediction must be fairly attributed to the feature values. Dummy and Additivity Young [1] showed that additivity and dummy axioms can be replaced by a monotonicity axiom and still the Shapley Value is the only unique solution. What Lundberg called "Consistency" is the Monotonicity axiom. In the supplemental material he actually calls it "Monotonicity", but uses "Consistency" in the paper. Symmetry In the supplemental material, Lundberg shows that for machine learning models, Monotonicity (= Consistency) implies symmetry. That's the reason why it is not listed as additional property in Lundbergs paper. [1] H Peyton Young. “Monotonic solutions of cooperative games”. In: International Journal of Game Theory 14.2 (1985), pp. 65–72.
