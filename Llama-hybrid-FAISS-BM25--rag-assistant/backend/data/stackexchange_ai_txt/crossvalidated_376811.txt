[site]: crossvalidated
[post_id]: 376811
[parent_id]: 376808
[tags]: 
Bishop may have been talking about conditional probability tables, or "group by" aggregations of the data often used in Bayesian networks. The MLE for these probabilities overfits in that it is too particular to the training data and may not generalize. This becomes especially true once you start adding variables to that grouping and slicing your data very thin. The MLEs for these group probabilities need some kind of regularization by means of a prior distribution, pooling, or some other method.
