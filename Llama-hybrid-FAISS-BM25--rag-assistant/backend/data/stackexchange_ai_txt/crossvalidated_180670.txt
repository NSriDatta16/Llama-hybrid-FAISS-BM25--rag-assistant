[site]: crossvalidated
[post_id]: 180670
[parent_id]: 
[tags]: 
Is randomized input data less prone to the exploding gradient problem?

I'm trying to train a RNN but I'm running into NaN errors while training. I think that this is due to the gradients exploding, although I can't confirm this. As a simple test, I fed random data with the same dimensions as my prepared data to the network, and I was surprised to see the NaNs go away. Is it true that more random data are less likely to cause exploding gradients? I thought that more learnable data would be less likely to diverge, is this not the case?
