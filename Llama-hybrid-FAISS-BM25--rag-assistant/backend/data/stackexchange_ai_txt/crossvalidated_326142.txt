[site]: crossvalidated
[post_id]: 326142
[parent_id]: 
[tags]: 
Is data-likelihood-weighted regression a thing?

Consider the basic linear regression model $y = A \theta$ with $y\in R^n$ and $A \in R^{n\times k}$ measurements and $\theta \in R^k$ parameters to be estimated. In my case, $\theta$ are physically meaningful parameters that I would like to estimate for further interpretation. A situation that I encounter frequently is that $A$ and $y$ contain time series of different measurement modalities that are rather repetitive over time, with some rare "interesting" anomalies occurring from time to time. Basic linear regression will weight all measurements equally, hence leading to a model that explains the standard measurements (occurring frequently) well, but may fail during unusual events. Consequently, I thought it rather natural to perform a weighted regression, where measurements are weighted by the inverse of their likelihood of occurrence, hence weighting unusual measurements stronger than with basic (unweighted) regression and hopefully leading to a model that is more generally applicable. More precisely, I would like to assign a weight $w_i = f(p(y_i, a_i|y, A))$ to each measurement, where $p(y_i,a_i|y,A)$ denotes the likelihood of a new measurement taking values $y_i$ and $a_i$, having observed all the data in $y$ and $A$, and $f(x)$ is a positive, monotonously decreasing function for $x>0$, e.g. $f(x)=1/x$. However, I seem to be unable to find any sources doing something like this, which made me wonder: Is this ... a standard thing that people do and I'm simply unable to recognize it or find the right terms for searching for it, completely unreasonable for some reason, or reasonable but nobody has done it (seems unlikely)? Disclaimer: I'm a mathematician / engineer / computer scientist and mostly self-taught statistician, so please bear with me if this is completely obvious...
