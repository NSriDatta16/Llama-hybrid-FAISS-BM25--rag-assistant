[site]: crossvalidated
[post_id]: 428691
[parent_id]: 428666
[tags]: 
The answer to the title question is "of course it does"; you are shifting the distribution toward the minority class. You can shift your model's predictions back to match the original distribution, see e.g. Convert predicted probabilities after downsampling to actual probabilities in classification or, equivalently, adjust the prediction threshold. There's also a serious question on whether you needed to resample in the first place. See What is the root cause of the class imbalance problem? , When is unbalanced data really a problem in Machine Learning? If you do get better performance after balancing, with correct use of prediction thresholds/shifting, I'd like to know about it. I haven't been able to find a definitive answer on whether balancing helps a classifier learn. (Henry's answer to the second linked question here suggests not, but...)
