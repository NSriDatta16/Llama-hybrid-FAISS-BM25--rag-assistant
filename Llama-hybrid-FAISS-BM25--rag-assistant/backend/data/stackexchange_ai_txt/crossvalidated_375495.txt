[site]: crossvalidated
[post_id]: 375495
[parent_id]: 375401
[tags]: 
It's hard to transfer a fully connected NN to inputs of differing sizes. Convolutional neural networks are fairly flexible when it comes to input size. As long as you use some sort of global average pooling on the last conv layer, there is nothing which prevents you from feeding inputs of variable sizes. If you try to generalize to different board sizes while training only on one, I'd expect it to do poorly, but better than random. If you're able to train on all board sizes, it may do well.
