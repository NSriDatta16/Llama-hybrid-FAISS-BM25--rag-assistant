[site]: datascience
[post_id]: 47961
[parent_id]: 
[tags]: 
On the choice of LSTM input/output dimension for a spatio-temporal problem

I am using LSTM neural networks from (R)Keras for a matter of spatio-temporal interpolation. I manage to get the network to output predictions but the results are not outstanding (very little improvement on validation loss). I am wondering about the shapes of training data and labels. Say I have 50 dates of measurements of the variable of interest $y$ , accompanied by about 100 covariates $x$ (spatial coordinates, temperatures...). Each date has 24 measurements of $y$ , so nsamples=50*24=1200 . If I set the timestep hyperparameter of LSTM to e.g. 3, and use a moving window of step 1, I have therefore an input table $X$ of shape (1200, 3, 100). On the other hand, should the labels table $Y$ be of dimension (1200, 3) or (1200, 1) ? More precisely, which of the following describes the problem the best: $$ (X_{n,t-2} ; X_{n,t-1} ; X_{n,t}) \rightarrow (Y_{n,t-2} ; Y_{n,t-1} ; Y_{n,t}) $$ $$ (X_{n,t-2} ; X_{n,t-1} ; X_{n,t}) \rightarrow (Y_{n,t} ; Y_{n,t} ; Y_{n,t}) $$ $$ (X_{n,t-2} ; X_{n,t-1} ; X_{n,t}) \rightarrow Y_{n,t} $$ $$ (X_{n,t-2} ; X_{n,t-1} ; X_{n,t}) \rightarrow Y_{n,t+1} $$ Or are they all plausible ways of addressing slightly different problems? As I said, I'm trying to spatially interpolate $Y$ for the 50 dates of measurements, as well as predicting $Y$ for the year(s) to come. So I expect one is more relevant than the others but I have no clue on which one. I hope this is understandable as I clearly miss some technical vocabulary here.
