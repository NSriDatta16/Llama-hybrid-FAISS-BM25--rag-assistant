[site]: crossvalidated
[post_id]: 399597
[parent_id]: 398436
[tags]: 
Bootstrap confidence intervals would be my choice of technique for this scenario. I would like to outline an approach with some example choice numbers that you can use and the reasoning behind the approach: You have two pots/bags and each bag contains people from the control group and variant group: $U_{ctr}$ and $U_{var}$ with respective sizes $N_{ctr}$ and $N_{var}$ . I changed your notation slightly, I hope that's OK. You select a random sample of $k$ people from both groups with replacement. If both of your populations are "sufficiently large" (say at least 2000 users for example) you can choose $k\leq N_{ctr}$ and $k \leq N_{var}$ . Rule of thumb: I usually select $k = \frac{min(N_{ctr},N_{var})}{5}$ for more flexible results but in most bagging (bootstrap aggregating) algorithms, the default option is to sample from the whole population. If your populations are smaller then you can still do that but make sure you select a "sufficiently large" $k$ (say at least 400 users), again by sampling with replacement. Let's say note them $SU_{ctr}$ and $SU_{var}$ both of size $k$ You calculate your metric by getting all transactions that each person in each group made by looking at the original $T$ transactions dataset for each user in $SU_{ctr}$ and $SU_{var}$ . You will then end up with $Metric_{ctr1}$ and $Metric_{ctr2}$ . Store these values. Important notice: you should calculate these values by summing the total star items sales and dividing by the total sales. Don't take the average of each person's individual sales basket. This is very important as this is the metric you are looking at. Go back to point 2 and iterate. The optimal number of bootstrap samples, $B$ , that you can choose depends on many factors but again, a good rule of thumb would be around 1000 times. You now have a $B$ amount of $Metric_{ctr}$ and same for $Metric_{var}$ . You can now choose to compare their means using many of the usual techniques. I would personally choose to construct confidence intervals and see if they overlap or an independent sample t-test AND complete the analysis with some histograms/density plots & boxplots. Off-topic personal opinion: Always choose to viz things such as distributions whenever possible, we have the power to do that nowadays. The tests above are totally fine but there are cases where they might go wrong. For instance if you choose $B$ to be extremely high, say 1000000, then even the smallest difference between the means is more likely to be flagged as significant. The above is robust because no matter what underlying distribution is, the central limit theorem ensures that if $B$ is sufficiently large, both means of $Metric_{var}$ and $Metric_{ctr}$ across the samples will be normally distributed and the tests will be valid. You will witness that from the visuals as well. Any concerns about underlying distributions of different user spends etc will be dealt by the CLT. There are plenty of references and good reads by the users before me. Furthermore, there is a lot of research conducted on the optimal example numbers I mentioned above you can look into it to. I just wanted to give you a more empirical and easy to understand outline of approach that is robust. You can start with that and see whether things change by changing the above example numbers.
