[site]: datascience
[post_id]: 106689
[parent_id]: 90809
[tags]: 
Yes, you can train XGBoost in parallel using the Dask backend. Short Solution Training XGBoost in parallel with Dask requires 2 changes in your code: substitute dtrain = xgb.DMatrix(X_train, y_train) with dtrain = xgb.dask.DaskDMatrix(X_train, y_train) substitute xgb.train(params, dtrain, ...) with xgb.dask.train(client, params, dtrain, ...) Have a look at this tutorial for a step-by-step guide that trains XGBoost on 100GB in under 4mins. Disclaimer: I work for Coiled, a paid service that offers managed Dask clusters.
