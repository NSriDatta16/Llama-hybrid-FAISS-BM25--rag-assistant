[site]: crossvalidated
[post_id]: 618167
[parent_id]: 618121
[tags]: 
I would argue that in some ways, the premise of some of your question itself is flawed, at least from the perspective of what the typical goal of a statistical analysis is. Specifically, much of your confusion seems to stem from the fact that you are assuming that $S/\sqrt n$ is meant as an estimator of $\sigma_g$ . However, this is not really the main goal of most statistical analyses I am aware of. Typically in the sort of setting you are describing, our primary interest in performing statistical inference is to try to understand the average of $X$ in the population $f$ , given formally by $\mu=\mathbb E_f[X]$ . This objective really consists of two subgoals: Subgoal 1: We would like to have a good estimate of $\mu$ . Subgoal 2: We would like to have a way of quantifying how uncertain we are about $\mu$ , even after seeing the data. I will be taking for granted in what follows that this will be your goal in analyzing data as well. Given this objective, we draw a sample of $X$ values $X_1,X_2,\ldots,X_n$ , which in the most ideal case, we model as i.i.d. and coming from the underlying population distribution $f$ . I assume that this i.i.d. model of sampling is what you have in mind when you describe $X_1,\ldots,X_n$ as a "random sample". Given this setup, the most standard way to proceed is the following procedure: Construct sample mean $\bar X_n = \frac1n\sum_{i=1}^n X_i$ Construct sample standard deviation $\hat s_n \equiv \sqrt{\frac1{n-1}\sum_{i=1}^n (X_i-\bar X_n)^2}$ Find standard error, $se_n\equiv \hat s_n/\sqrt{n}$ . Construct (say) 95% confidence intervals, $[\bar X_n-2se_n,\bar X+2se_n]$ Why does this procedure make sense? Let us discuss each in turn. First of all, consider $\bar X_n$ . The justification for using $\bar X_n$ is that as you mentioned, given our assumptions $\bar X_n$ is an unbiased estimate of $\mu$ in that $\mathbb E[X_n]=\mu$ . Perhaps more importantly, the law of large numbers implies that $\bar X_n$ is also a consistent estimator of $\mu$ in that $\bar X_n\overset p\to \mu$ as $n\to\infty$ . Roughly, this means that provided we collect large enough of a sample, we can make sure that $\bar X_n$ is "sufficiently close" to $\mu$ with "sufficiently high probability". If we only cared about subgoal 1, then we could stop here. The fact that we care about subgoal 2 justifies why we even care about estimating $\sigma$ and pursuing this second goal is where steps 2-4 of the above procedure come in. These steps break uncertainty quantification into a series of more digestable sub-parts. The main intuition for these steps is that there are two conceptually distinct reasons why $\bar X_n$ might not, for a fixed sample size $n$ be very close to $\mu$ . First, it could be that each individual observation $X_i$ is not likely to be very close to its mean value, $\mu$ , so each individual observation does not give us much information by itself about $\mu$ . Second, it could be that $n$ is not very high, so we need to collect more data. The computation of $\hat s_n$ helps us to quantify the first reason why $\bar X_n$ may not be very close to $\mu$ . Specifically, rearranging the expression for $\hat s_n$ , we find that $$\hat s_n = \sqrt{\frac{n}{n-1}\left(\frac1n\sum_{i=1}^n X_i^2 - \bar X_n^2\right)}$$ Applying the law of large numbers and the continuous mapping theorem imply that $$\hat s_n\overset p\to \sqrt{\mathbb E_f[X^2]-\mathbb E_f[X]^2}=\mathrm{sd}_f(X)\equiv\sigma$$ where $\mathrm{sd}_f(X)$ is the population standard deviation of $X$ . Thus, $\hat s_n$ gives us a consistent estimate of how close $X_i$ is likely to be to its mean. Steps 3+4 then incorporate information about how big the sample is, and how sample size affects uncertainty about $\mu$ . First, looking at step 3, this is the step that I suspect your confusion stems from. It would seem from the logical flow of what we have been doing so far that the standard error $se_n$ is an estimator of something, and in particular, based on your question, I presume that it looks to you like it should be an estimator of $\mathrm{sd}_g(\bar X_n)$ . However, the key point I hope to convey here is that in constructing our standard errors, we are doing something related but subtly different . Specifically, to understand why constructing standard errors is important, it is actually helpful to view steps 3+4 together rather than looking at step 3 in isolation. The justification for these steps taken together comes from the following derivation: First, by the central limit theorem , $$\sqrt n\sigma^{-1}(\bar X_n-\mu)\overset d\to\mathcal N(0,1)$$ where $\overset d\to$ denotes convergence in distribution and throughout, I take the $-1$ superscript to denote taking a reciprocal. This tells us roughly that the random variable, $\sqrt n\sigma^{-1}(\bar X_n-\mu)$ formed by appropriately shifting and scaling $\bar X_n$ will behave increasingly like a standard Normal random variable when sample sizes are large. As you noted, this formula is not useful directly because $\sigma$ may not directly be known. However, because of the delta method , and because in our discussion of step 2, we noted that $\hat s_n\overset p\to\sigma$ , the following modified central limit theorem where we replace $\sigma$ with $\hat s_n$ also holds: $$\sqrt n\hat s_n^{-1}(\bar X_n-\mu)\overset d\to\mathcal N(0,1)$$ How do we use this result? One way is to ask what guesses $\tilde \mu$ of the true value of $\mu$ are "plausible" given the data. The usual statistical significance framework defines "plausible" in the following way: in light of the central limit theorem, if $\mu=\tilde\mu$ , then we would expect that the random variable $\sqrt n\hat s_n^{-1}(\bar X_n-\tilde\mu)$ follows a $\mathcal N(0,1)$ distribution. If it did follow such a distribution, then the probability that it takes on "extreme" values is $\mathrm{Pr}[|\sqrt n\hat s_n^{-1}(\bar X_n-\tilde\mu)|\geq 2]\approx 1 - \Phi(2) - \Phi(-2)\approx 0.05$ , where $\Phi$ is the CDF of a standard normal. Thus, guesses $\tilde \mu$ such that $|\sqrt n\hat s_n^{-1}(\bar X_n-\tilde\mu)|\geq 2$ are ruled to be "implausible" on the grounds that for the trule value of $\mu$ , we would only expect to see such an "extreme" value of $|\sqrt n\hat s_n^{-1}(\bar X_n-\tilde\mu)|$ 5% of the time, which is pretty unlikely. We call the 95% confidence interval the set of $\tilde \mu$ values which are plausible $|\sqrt n\hat s_n^{-1}(\bar X_n-\tilde\mu)|\leq 2$ . Rearranging this last inequality gives us that our 95% confidence interval should indeed be the form described in step 4 $$\left[\bar X_n-2\frac{\hat s_n}{\sqrt n},\bar X_n+2\frac{\hat s_n}{\sqrt n}\right] = \left[\bar X_n-2se_n,\bar X_n+2se_n\right]$$ Summarizing, the importance of the standard error is not that $\sigma_g$ is directly a parameter of interest. Rather, when we are clear about the problem we are trying to solve (quantifying uncertainty about $\mu$ given our data), we derive as a consequence of this underlying question that the quantity $se_n=\hat s_n/\sqrt n$ happens to be a part of the solution. It just happens to be the case that $se_n$ superficially looks like an estimate of $\sigma_g$ .
