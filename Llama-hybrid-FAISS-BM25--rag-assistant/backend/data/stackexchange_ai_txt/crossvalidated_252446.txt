[site]: crossvalidated
[post_id]: 252446
[parent_id]: 250269
[tags]: 
The issue has been clarified by @GeoMatt22, and I've been delighted to see @GeoffCumming coming here to participate in the discussion. I am posting this answer as a further commentary. As it turns out, this discussion goes back at least to Goodman (1992) A comment on replication, P‚Äêvalues and evidence and a later reply Senn (2002) Letter to the Editor . I can highly recommend reading these two brief articles, in particularly the Stephen Senn's one; I find myself fully agreeing with Senn. If I had read these papers before asking this question, I would most likely have never posted it. Goodman (unlike Cumming) states very clearly that he considers a Bayesian setting with a flat prior. He does not present $p$-value distributions as Cumming does, and instead reports probabilities of observing a "significant" $p His main point is that these probabilities are surprisingly low (even for $p=0.001$ it is only $0.78$). In particular, for $p=0.05$ it is only $0.5$. (This latter $1/2$ probability remains the same for any $\alpha$ and $p=\alpha$.) The point of Senn's reply is that this is a useful observation which, however, does not undermine $p$-values in any way and does not , contrary to Goodman, mean that $p$-values "overstate the evidence against the null". He writes: I also consider that his [Goodman's] demonstration is useful for two reasons. First, it serves as a warning for anybody planning a further similar study to one just completed (and which has a marginally significant result) that this may not be matched in the second study. Second, it serves as a warning that apparent inconsistency in results from individual studies may be expected to be common and that one should not overreact to this phenomenon. Senn reminds us that one-sided $p$-values can be understood as Bayesian posterior probabilities of $H_0:\mu [see Marsman & Wagenmakers 2016 for a brief discussion of this fact and some citations] . If so, then having obtained any particular $p$-value in one experiment, probability that the next experiment will yield a lower $p$-value has to be $1/2$; otherwise future replications could somehow provide additional evidence before being conducted. So it makes total sense that for $p=0.05$ Goodman obtained probability $0.5$. And indeed, all replication distributions computed by Cumming and @GeoMatt22 have medians at the respective $p_\mathrm{obs}$. We do not, however, need this replication probability to be higher than $0.5$ to believe that the efficacy of the treatment is probable. A long series of trials, $50$ per cent of which were significant at the $5$ per cent level, would be convincing evidence that the treatment was effective. Incidentally, anybody who looked at the predictive distributions of $p$-values for, say, a t-test of given size and power ( see e.g. here ) will not be surprised that requiring a median at $p=0.05$ will necessarily make this distribution pretty broad, with a fat tail going towards $1$. In this light, broad intervals reported by Cumming cease being surprising. What they rather do suggest, is that one should use larger sample sizes when trying to replicate an experiment; and indeed, this is a standard recommendation for replication studies (e.g. Uri Simonsohn suggests , as a rule of thumb, to increase sample size $2.5$-fold).
