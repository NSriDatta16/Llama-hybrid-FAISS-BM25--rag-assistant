[site]: datascience
[post_id]: 121843
[parent_id]: 121841
[tags]: 
A simple way to get started would be to simply call Word2Vec or Glove to get embeddings for the descriptors, and then refine from there. https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial is a good starting point that covers training. You can just start with pretrained vectors, something like glove_vectors = gensim.downloader.load('glove-wiki-gigaword-100') Then you'll need to split your descriptors into individual words, getting rid of underscores, "-", etc. Once you have a list of words per descriptor, you can get the average embeddings with code like words = ['upper', 'tail', 'color', 'orange'] mean_vec = glove_vectors.get_mean_vector(words) And then use the mean_vec to determine similarity (e.g. cosine distance) from other embeddings.
