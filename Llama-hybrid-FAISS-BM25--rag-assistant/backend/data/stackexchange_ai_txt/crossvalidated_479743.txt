[site]: crossvalidated
[post_id]: 479743
[parent_id]: 
[tags]: 
Poor Validation Acc and High Validation Loss for resnet50

After trying out VGG16 and having really good results, I was trying to train a ResNet50 Model from Imagenet. First I set all layers to trainable because I have a large Dataset and did the same with VGG16, but my results were quite bad. Then I tried to set the layers to not trainable and see if it gets better, but the results were still bad. My original images are of size 384x384 but I resized them to 224x224. Is that the issue? Or did I do something wrong while implementing it? from keras import Input, Model from keras.applications import ResNet50 from keras.layers import AveragePooling2D, Flatten, Dense, Dropout from keras.optimizers import Adam from keras_preprocessing.image import ImageDataGenerator class example: def __init__(self): # define the names of the classes self.CLASSES = ["nok", "ok"] # initialize the initial learning rate, batch size, and number of # epochs to train for self.INIT_LR = 1e-4 self.BS = 32 self.NUM_EPOCHS = 32 def build_model(self, train_path): train_data_path = train_path train_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.25) train_generator = train_datagen.flow_from_directory( train_data_path, target_size=(224,224), color_mode="rgb", batch_size=self.BS, class_mode='categorical', subset='training') validation_generator = train_datagen.flow_from_directory( train_data_path, target_size=(224, 224), color_mode="rgb", batch_size=self.BS, class_mode='categorical', subset='validation') # load the ResNet-50 network, ensuring the head FC layer sets are left off baseModel = ResNet50(weights="imagenet", include_top=False, input_tensor = Input(shape=(224, 224, 3))) # construct the head of the model that will be placed on top of the the base model headModel = baseModel.output headModel = AveragePooling2D(pool_size=(7, 7))(headModel) headModel = Flatten(name="flatten")(headModel) headModel = Dense(256, activation="relu")(headModel) headModel = Dropout(0.5)(headModel) headModel = Dense(len(self.CLASSES), activation="softmax")(headModel) # place the head FC model on top of the base model (this will become the actual model we will train) model = Model(inputs=baseModel.input, outputs=headModel) for layer in baseModel.layers: layer.trainable = True # compile the model opt = Adam(lr=self.INIT_LR)#, decay=self.INIT_LR / self.NUM_EPOCHS) model.compile(loss="binary_crossentropy", optimizer=opt, metrics=["accuracy"]) from keras.callbacks import ModelCheckpoint, EarlyStopping import matplotlib.pyplot as plt checkpoint = ModelCheckpoint('resnetModel.h5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1) early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=6, verbose=1, mode='auto') hist = model.fit_generator(steps_per_epoch=self.BS, generator=train_generator, validation_data=validation_generator, validation_steps=32, epochs=self.NUM_EPOCHS, callbacks=[checkpoint, early]) plt.plot(hist.history['accuracy']) plt.plot(hist.history['val_accuracy']) plt.plot(hist.history['loss']) plt.plot(hist.history['val_loss']) plt.title("model accuracy") plt.ylabel("Accuracy") plt.xlabel("Epoch") plt.legend(["Accuracy", "Validation Accuracy", "loss", "Validation Loss"]) plt.show() plt.figure(1) import tensorflow as tf if __name__ == '__main__': x = example() config = tf.compat.v1.ConfigProto() config.gpu_options.allow_growth = True sess = tf.compat.v1.Session(config=config) x.build_model("C:/Users/but/Desktop/dataScratch/Train") I have 2 Classes which contain images of integrated circuits with defect and non defect images. My Batch Size is 32, Epoches is 32, LR is 1e-4. Here are example images: This is a defect image This is an ok image
