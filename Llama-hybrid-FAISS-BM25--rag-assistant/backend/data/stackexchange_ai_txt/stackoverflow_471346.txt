[site]: stackoverflow
[post_id]: 471346
[parent_id]: 471341
[tags]: 
Assuming that the spider is kind enough to respect robots.txt, you could restrict it from accessing your site with the following: User-agent: * Disallow: / This will affect all spiders. Narrow it down by specifying the correct user-agent for the spider. If the crawler doesn't respect your robots.txt, you might want to restrict it from accessing your site by blocking its IP in your firewall. EDIT: You can read more about robots.txt here .
