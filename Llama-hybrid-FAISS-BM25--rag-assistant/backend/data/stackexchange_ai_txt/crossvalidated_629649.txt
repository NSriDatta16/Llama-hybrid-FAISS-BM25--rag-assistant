[site]: crossvalidated
[post_id]: 629649
[parent_id]: 629626
[tags]: 
(1) The distance function used should express as "correctly" as possible what distance "means" in the application in question. Any calculation based on distances, be it the clustering methods themselves or the Silhouette index (ASW for Average Silhouette Width in the following), will rely on having dissimilarity between objects correctly represented by the distance measure. If the distance measure is inappropriate, so is the resulting clustering, and also the Silhouette value. In particular, the ASW is inappropriate to compare different choices of distance. To see this, as a thought experiment split your dataset randomly into five groups. Consider a distance measure that assigns distance 1 between any two observations from different groups and distance zero between any two observations from the same group. Most if not all clustering methods will reproduce these five groups at least if you fix the number of clusters to be five. The ASW will rate this at 1, i.e., maximum quality. Yet it doesn't mean a thing, because the distance measure is meaningless (and so is every index that is based on it). (2) This means in particular that you should not pick a distance measure in order to achieve optimal clustering quality. Generally, assuming that there is a "true" distance between your observations, it may happen that this doesn't lead to a strong or convincing clustering. This would then be appropriate for the data you have - maybe there is no convincing clustering as your data are rather homogeneous. This can be valid and valuable information about your data. You wouldn't be served better by making the data look stronger clustered by applying an inappropriate distance measure. (3) It is admittedly hard to say in most applications which distance measure is "correct", and the assumption that there is one unique "true" distance is debatable (although it is less debatable that you can define obviously inappropriate distance measures, see above). So I can understand why you'd want to look at and compare several different measures. Yet the data doesn't normally hold information about which distance measure is correct (unless there is secondary information that suggests it does, which is rarely the case in unsupervised settings; actually some kind of "supervision" would be required). This means that when choosing a distance measure, you should think hard about the meaning of the data and what it means to be "similar" or "distant" in terms of the subject matter. Looking at different clusterings in the data can only help with this in the sense that regarding subject matter information some of them may look more meaningful than others (which is not measured by ASW and neither by any other index that evaluates a clustering quantitatively). (4) When discussing Euclidean vs. Manhattan two considerations are whether (a) the same change in differences on different variables should always result in the same change of the distance measure (as done by Manhattan) or whether changes between bigger differences in a variable are more important than the same changes between smaller differences in another variable (as they are for Euclidean due to the use of squares) and (b) whether data are in some way subjected to the rules of Euclidean geometry; e.g., whether it is required, for some reason, that the distance is rotation invariant, in other words, whether rotation of the coordinate system is a meaningful operation given the meaning of the variables (Euclidean is rotation invariant but not Manhattan). You also need to realise that it often makes a big difference to the distance whether you compute Euclidean or Manhattan on standardised data or not (usually this makes more of a difference than the choice of Euclidean or Manhattan itself), and there are different ways to standardise. All these are essentially different distances and the data themselves, disregarding their meaning, will not tell you what to use. Another option by the way is the Mahalanobis distance, which will assess the distance between observations relative to the variance-covariance structure in your variables (when it comes to clustering methods, this will correspond better to Gaussian mixture model-based clustering with flexible covariance matrices). (5) If you think that the ASW is a more reliable clustering quality criterion than the objective function of $k$ -means or objective functions on which other clustering methods are based, you may consider clustering the data by optimising the ASW in the first place, see F. Batool & C. Hennig (2021) Clustering with the Average Silhouette Width. Computational Statistics & Data Analysis . However, despite being co-author of that paper, I do not think that this is generally the case. As the principles of other clustering methods, also the ASW is based implicitly on its own "cluster concept" that will be appropriate in some applications and less appropriate in others, just as $k$ -means or DBSCAN (but in different situations). So the ASW doesn't necessarily have more authority to decide what the best clustering is than any other clustering method in isolated use. (6) Potentially problematic characteristics of the ASW are (a) that it can assess a clustering as bad where some clusters are very heterogeneous. Note that density-based clustering such as DBSCAN will leave rather heterogeneous point clouds together in the same cluster if there is no "density gap" separating subsets from each other. The ASW will in many situations not like this (unless such a cluster is really strongly separated from the rest of the data). Whether such clusters are desirable or not depends on how much within-cluster heterogeneity is tolerable in the specific application and more generally on what kind of clusters are required for what use. (b) The ASW can indicate to lump clusters together in order to achieve a very large between-clusters distance. For example, if you have four clusters that come as two pairs of clusters with the clusters within the pairs being fairly close together but the two pairs being strongly separated, the ASW will prefer a two cluster solution over a four cluster solution that is arguably better in most situations. (7) That said, I do like to look at the ASW to compare different clusterings as an orientation rather than as an ultimately authoritative super-index. It is a sensible heuristic tool that has some disadvantages (no clustering approach or cluster quality index is perfect). When it comes to comparing distances and you have decided that, say, Euclidean is maybe a bit better than Manhattan to express the subject-matter meaning of distance in your application, it may give interesting information if a clustering that was computed based on the Manhattan distance could have a better or as good ASW value (computed using Euclidean distance) than a clustering computed based on Euclidean distances in the first place. This is rare but I have seen it happening. Still, the decision which distance to choose should be made on subject matter grounds, not by data-driven optimisation . Also, comparing different clusterings, I would always use quantitative validity (such as ASW) and visualisation and subject matter information (can the clustering be interpreted in a way that makes sense?) and stability experiments (e.g. as done by the clusterboot function in R-package fpc based on this paper of mine (sorry for self-advertisement;-). Also the question what the clustering will be used for should be kept in mind.
