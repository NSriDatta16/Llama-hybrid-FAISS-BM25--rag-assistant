[site]: crossvalidated
[post_id]: 95134
[parent_id]: 
[tags]: 
Normalization of dummy variables

My data consists of several continuous measurements and some dummy variables representing the years the measurements have been made. Now, I want to learn a neural network with the data. Therefore, I am zScore-normalizing all variables, including the dummy variables. However, I wonder if this is a reasonable approach, because normalizing the dummy variables alters their ranges, which I guess makes them less comparable if their distributions differ. On the other hand, not normalizing the dummy variables might also be questionable, because without normalization their influence on the networks output might be suboptimal. What is the best approach to deal with dummy variables, normalizing them (zScore) or just leaving them as they are?
