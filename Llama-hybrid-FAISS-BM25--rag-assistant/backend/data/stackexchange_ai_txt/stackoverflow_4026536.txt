[site]: stackoverflow
[post_id]: 4026536
[parent_id]: 4026359
[tags]: 
If you don't plan to have a large amounts of deletes, then this isn't that hard. Deletes lead to fragmentation. You also need to commit to a fixed length key. You mentioned 80 bytes. Are your keys allowed to duplicate? If not, it's even easier. So, here is what you do. You create an array of: struct { char value[80]; char *data; } key; And you keep this array sorted. If you keys can duplicate, then you need: struct link { char *data; link *next; } struct { char value[80]; link *data; } key; (My C is rusty, but this is the gist of it) The latter has each key pointing to a linked list of values. Then a lookup is a simple binary search. The "pain" is in maintaining this array and inserting/deleting keys. It's not as painful as it sounds, but it saves a LOT of memory, especially on 64bit systems. What you want to reduce is the number of pointers. Pointers are expensive when you have lots of structures filled with pointers. On a 64bit system, a pointer is 8 bytes. So for a single pointer, there goes 8MB of your memory budget. So, the expense is in building the array, copying and compacting memory (if you "know" you will have a million rows and can commit to that, then malloc(1000000 * sizeof(key)) right away, it'll save you some copying during expansion). But don't be afraid of, once it's up and running, performance is quite good. Modern cpus are actually pretty good at copying 100M blocks of memory around. Just as an aside, I just did something much like this in Java. On a 64bit JVM, a Map with 25M entries is 2G of RAM. My solution (using similar techniques to this) has at around 600M). Java uses more pointers than C, but the premise is the same.
