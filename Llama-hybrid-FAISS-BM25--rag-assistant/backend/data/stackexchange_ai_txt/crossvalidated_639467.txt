[site]: crossvalidated
[post_id]: 639467
[parent_id]: 637758
[tags]: 
Just wanted to share what I did in the end as suggested by @COOLSerdash : First, I took @BenBolker 's hack for a custom power-logistic function which can be found here: https://rpubs.com/bbolker/logregexp This is how it looks like (straight copy from the link): library(MASS) logexp 30,.Machine$double.eps, exp(eta)/(1+exp(eta))^2) } mu.eta Note: as you can see there is a hack to allow for help with visualization, post-prediction etc. since glm() and glmer() do not evaluate the exposure variable in the context of the data argument. So this is how I adapted this solution to my problem using glm() , glmer() and ggeffects::ggpredict() . First for glm() : library(lme4) library(ggeffects) m $measurement_interval)), data = d ) # pull in the mean for the exposure variable. In my case `measurement_interval` ..exposure measurement_interval) # run model predictions (that's were `..exposure` is needed) pred_dbh The same also works for glmer() : m2 $measurement_interval)), data = d ) # pull in the mean for the exposure variable. In my case `measurement_interval` ..exposure measurement_interval) # run model predictions (that's were `..exposure` is needed) pred_dbh2 It is generally much easier to fit these types of models using a Bayesian non-linear approach for example with the brms package. The reason it didn't work for me though is because of the large size of the dataset (+1M observations) and it takes days to fit those models. Anyway, here the Bayesian approach that I tried: library(brms) m3 I hope that's useful!
