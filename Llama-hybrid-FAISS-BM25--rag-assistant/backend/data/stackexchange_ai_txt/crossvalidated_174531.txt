[site]: crossvalidated
[post_id]: 174531
[parent_id]: 174526
[tags]: 
Don't make a choice based on believes try both! Once you developed a cross validation framework it is not very hard to feed it with various models and pick the best one. Sometimes, these cross validation framework already exists ( caret in R, but there must be plenty of others!) The paper : "Do we Need Hundreds of Classifiers to Solve Real World Classification Problems?" http://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf is a very good review on existing models, their implementations and their performances on various data sets. You can find information about the performances of models according to the number of features, per example. But even if performances of a model depend a priori on the number of features, the number of observations (some models have been developed to handle specific situations), and the type of observations, it is not obvious that one model will perform better than another. IMHO, the only thing that you should consider when selecting a model is the time to train it. Some training times become prohibitive with large data sets. Per example, training a kernel SVM on 1M+ observations will never end. With 10k records and 5 features, you can train almost anything though. As for the feature engineering, you should try every idea you have as well! For categorical variables a first start is to encode them into dummy variables, in order to end up with a numeric matrix. But you could also want to remove scarce factors, consider interactions... And keep observing the influence on the predictive performance!
