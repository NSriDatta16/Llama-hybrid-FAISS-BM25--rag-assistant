[site]: datascience
[post_id]: 79846
[parent_id]: 
[tags]: 
If a single element is missing more than 50% of its feature values, should you just remove it?

I have a simple supervised machine learning problem. My training matrix is MxN, where M is the number of records and N is the number of features. I have 600,000 complete patient records and 300,000 additional records that contain some missing data. Certainly, if a record is missing 90% of all of its feature values, it's best just to remove it - mean imputation would just be adding average records for all features to the training matrix and it can overfit. If a record is only missing 2% of its feature values, then imputation would be great and you can keep it. What do you believe is the correct threshold for deciding between keeping and tossing?
