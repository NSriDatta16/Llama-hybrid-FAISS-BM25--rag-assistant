[site]: crossvalidated
[post_id]: 568274
[parent_id]: 
[tags]: 
Informative priors for standard deviation (or variance)

Suppose I want to perform Bayesian estimation of the mean $\mu$ and standard deviation $\sigma$ of a Gaussian distribution. Is there a standard way to specify an informative prior over $\sigma$ , assuming I have prior info that it lies "close" to some given $\gamma$ in log-space? In addition to having an initial guess for $\sigma$ , I want to avoid two problems with using the Jeffrey's prior (A Bayesian perspective on estimating mean, variance, and standard-deviation from data, Travis Oliphant). With the Jeffrey's prior, one does not have a well-defined MAP unless $n>3$ . And if the sum of squared deviances is 0, one's MAP estimate of $\sigma$ will also be 0.
