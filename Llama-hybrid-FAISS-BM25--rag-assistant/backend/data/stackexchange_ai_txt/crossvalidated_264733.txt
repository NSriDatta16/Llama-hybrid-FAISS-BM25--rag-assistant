[site]: crossvalidated
[post_id]: 264733
[parent_id]: 255105
[tags]: 
There are few ways to try in your situation. Firstly try to increase the batch size, which helps the mini-batch SGD less wandering wildly. Secondly tuning the learning rate, probably set it smaller. Thirdly, try different optimizer, for instance Adam or RMSProp which are able to adapt learning rates for wrt features. If possible try augmenting your data. Lastly, try Bayesian neural networks via dropout approximation, a very interesting work of Yarin Gal https://arxiv.org/abs/1506.02158
