[site]: crossvalidated
[post_id]: 558905
[parent_id]: 558900
[tags]: 
This could be for a number of reasons. I suspect it is because the logistic regression classifier is trained using Iteratively Re-weighted Least Squares (IRWLS), which requires the repeated solution of a system of linear equations that depends on the current output of the model. For details, see Minka (2003), sections 1 and 2. The ridge classifier, on the other hand only requires the solution of a single set of linear equations (of the same size). IRWLS generally takes ten or so iterations to converge, and so is about ten times slower. However, the wording of the question suggests that the ridge classifier is using the same regularisation parameter for each class, which is not something I would necessarily recommend, as it is suggesting that the matrix that is inverted in solving this system of linear equations (which depends on the ridge parameter) is the same for all classes, which would be a further saving. Having said which, I would use multi-nomial logistic regression, which is much slower as it requires the repeated solution of a much larger set of linear equations (but can give a better classifier). On the other hand, logistic regression methods can also be fitted using Bohning's method, which uses a fixed Hessian, which would mean that you could use the same inverse hessian repeatedly. This would make it nearly as fast as the RidgeClassifier, regardless of the number of classes, as the slowest part is inverting the Hessian (although in practice you would use something like the Cholesky decomposition rather than actually inverting it). See section 5 of Minka (2003). One thing to be aware of though, is that the logistic regression model gives you estimates of class membership, whereas the ridge classifier does not. This can be a big advantage in some practical applications, particularly if the misclassification costs (or equivalently the operational class frequencies) or if a reject option is needed, as a probabilistic classifier can deal with those things without needing to retrain the classifier. I like the ridge classifier, as it is fast, but don't use it where probabilities are needed by the application. Thomas P. Minka. A comparison of numerical optimizers for logistic regression, October 22, 2003 (revised Mar 26, 2007) ( pdf )
