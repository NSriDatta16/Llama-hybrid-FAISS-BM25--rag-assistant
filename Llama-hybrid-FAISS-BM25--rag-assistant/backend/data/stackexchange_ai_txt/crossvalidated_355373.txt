[site]: crossvalidated
[post_id]: 355373
[parent_id]: 321665
[tags]: 
Feature selection is not a great goal to have in an analysis. Unless all the predictors are uncorrelated with each other and your sample size is immense, the data will be unable to reliably tell you the answer. Model specification is more important than model selection. Details are in my RMS Course Notes . But shrinkage, without feature selection (e.g., ridge or $L_{2}$ penalized maximum likelihood estimation) can be a good idea. Hierarchical Bayesian models are even better because they allow for statistical inference in the shrunken model whereas we lose most of the inferential tools in the frequentist world after shrinking.
