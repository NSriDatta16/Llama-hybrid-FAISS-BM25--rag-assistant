[site]: crossvalidated
[post_id]: 488107
[parent_id]: 31066
[tags]: 
Most of the answers above are quite good, but let me clarify something for someone like me who had to spent 3 days on understanding the role Parameter C in SVM because of diffrent sources. In book ISLR( http://faculty.marshall.usc.edu/gareth-james/ISL/ ) larger C means larger misclassification are allowed which makes margin wider and smaller C means less misclassification is allowed which leads to small margin. Whereas every other resource i have read and in python documentation it is just the opposite. Actually is ISLR C is defined as the upper bound of the sum of all slack variables. But in python and other source( https://shuzhanfan.github.io/2018/05/understanding-mathematics-behind-support-vector-machines/#:~:text=In%20terms%20of%20the%20SVM,%2Bb )%E2%88%921%5D.) C is constraints on slack variables.If we set C to positive infinite, we will get the same result as the Hard Margin SVM. On the contrary, if we set C to 0, there will be no constraint anymore, and we will end up with a hyperplane not classifying anything. The rules of thumb are: small values of C will result in a wider margin, at the cost of some misclassifications; large values of C will give you the Hard Margin classifier and tolerates zero constraint violation
