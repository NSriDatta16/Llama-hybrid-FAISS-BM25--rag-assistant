[site]: crossvalidated
[post_id]: 581720
[parent_id]: 
[tags]: 
Population studies - interpreting confidence intervals, should they even be included?

I work with administrative ('routinely collected') data in situations where the data capture the entire population, e.g. hospital records, prison records, etc. When reporting statistics the question of interpreting confidence intervals has come up with colleagues and reviewers, and I'm trying to work out a coherent position. I've had a look at a related question ( Why donâ€™t we calculate the average of an entire given population instead of computing confidence interval to estimate the population mean? ) but it doesn't touch on the question of measurement error. In one sense, a confidence interval is a measure of uncertainty about our sampling process, so when the population is known, we could simply report the various statistics we use, and declare any difference as statistically significant (questions of practical significance, minimal clinical differences, etc. notwithstanding). In another sense, there is still uncertainty in the data collection process, e.g. measures being rounded to the nearest number, which the confidence interval can stand in for. I feel this is a separate issue since it's to do with uncertainty with measuring/recording rather than sampling, but reviewers/colleagues seem to be happy to accept this interpretation of the confidence interval. Pragmatically, the confidence intervals in these scenarios are usually incredibly small, so including them, or not, and interpreting them as including measurement uncertainty, or not, has little bearing on the conclusions we draw from data. Overall, I'm just confused about whether confidence intervals are appropriate when dealing with known/entire/captive populations, and whether or not the concept of measurement uncertainty applies in this case or not. I don't have a strong statistics background and would appreciate any thoughts and/or references!
