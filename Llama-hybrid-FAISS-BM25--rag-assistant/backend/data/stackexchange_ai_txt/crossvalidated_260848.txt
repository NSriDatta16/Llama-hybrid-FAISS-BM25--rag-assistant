[site]: crossvalidated
[post_id]: 260848
[parent_id]: 
[tags]: 
What is sufficient statistics in the context of generalized linear models

the three assumptions Andrew Ng makes when deriving GLM are: $y\mid x;\theta \sim \operatorname{ExponentialFamily}(\eta)$ Our goal is to predict the expected value of $T(y)$ given $x$ . Since in most of our examples $T(y) = y$ , we would like the prediction $h(x)$ to satisfy $h(x)=E[y\mid x]$ . (This assumption is satisfied for both logistic regression and linear regression) The natural parameter $\eta$ and the inputs $x$ are related linearly: $\eta = \theta^Tx$ . I get assumption 1 and 3. What bothers me is the second assumption. I get that in logistic regression $$h_\theta(x) = p(y=1\mid x;\theta) = 0 \cdot p(y=0\mid x;\theta) + 1\cdot p(y=1\mid x;\theta) = E[y\mid x;\theta]$$ Hence we want the expected value of $y\mid x;\theta$ . (This seems to be a very special case where output is $y\in[1,0]$ ). But what exactly is the sufficient statistic in this context and what does the expected value of sufficient statistic represent?
