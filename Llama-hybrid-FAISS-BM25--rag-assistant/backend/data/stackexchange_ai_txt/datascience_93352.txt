[site]: datascience
[post_id]: 93352
[parent_id]: 93350
[tags]: 
Firstly, when you have an imbalanced dataset accuracy is not a good metric to be using (see https://en.wikipedia.org/wiki/Precision_and_recall#Imbalanced_data ). You should consider what the ultimate use-case of this model is and what metric is properly capturing the performance of the model considering that use case. For example, when classifying the presence of cancer, false negatives are much more undesirable than false positives so you would want to ensure you are using a metric that captures that appropriately. In sklearn there is a class_weight parameter of the LogisticRegression model which allows you to essentially weigh misclassifications of different classes differently. Setting this to 'balanced' will automatically adjust this weight to be inversely proportional to the amount of samples of that class in your data which might be beneficial. You may want to adjust this in a custom manner also. Changing the metric you are evaluating on doesn't change the actual training of the model, so I am guessing that your custom implementation of logistic regression should not function significantly differently to the sklearn version in terms of performance (if it does their may be other issues), it seems you are just using a different metric. There are also a number of other metrics besides accuracy that you can use in sklearn ( https://scikit-learn.org/stable/modules/model_evaluation.html#model-evaluation ) perhaps consider balanced-accuracy to begin with. It is also not to hard to apply your own custom metric to the results from the sklearn logistic regression model. Tools such as the classification_report ( https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html ) and/or confusion matrix ( https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html ) can also be enlightening when dealing with imbalanced data.
