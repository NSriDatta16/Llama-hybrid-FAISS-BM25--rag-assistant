[site]: datascience
[post_id]: 116944
[parent_id]: 96250
[tags]: 
The architecture of any neural network can be thought of as a hyperparameter. It can be tricky to choose the 'right' number of layers and the 'right' number of neurons that works for you. As suggested by Shubham, you should go through the implementation of the other researchers working on a similar problem. It will give you a good starting point. Additionally, there are libraries (grid-search based of course!) to tune some of the NN architectures like KerasTuner , AutoKeras , etc which can help you. Another good starting point is to start with a simple architecture and keep adding the layers and neurons until you encounter overfitting. However, the final architecture should also make 'sense'. Note that the architecture of NN depends on the quality of features you feed the model. If your features are 'good', you may not need a complicated architecture to get a 'good' generalization. Pretrained models and transformers as feature extractors can help you reduce the complexity of the architecture.
