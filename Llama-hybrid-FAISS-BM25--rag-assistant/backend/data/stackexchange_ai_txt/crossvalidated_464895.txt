[site]: crossvalidated
[post_id]: 464895
[parent_id]: 463405
[tags]: 
The penalised spline way of smoothing is a bit of a multi-faceted thing. The Bayesian view of smoothing — that you're implicitly using when fitting with REML or ML in mgcv —, would view the smoothness parameter(s) in the model as priors on the wiggliness of the functions. From this viewpoint therefore, it is acceptable to constrain the size of the basis to meet the a priori expected wiggliness of the smooth effects you're estimating. That said, with temporal (and spatial) variables such as the one we're discussing here, you do have to be somewhat careful not to violate the theory upon which the statistical tests you might be using (p values etc). A critical assumption is conditionally independent observations; once we've accounted for the model, observations are independent. This would be violated in the case of unmodelled temporal or spatial autocorrelation. If you go with the more smooth effect of hour , you may be missing some temporal structure in the data. I would personally go with the more smooth version and then plot the deviance residuals against hour and use a variogram or the autocorrelation function to look for unmodelled temporal structure. If there, you could use the rho argument to model it (assuming equally spaced observations). A note on your model: I wouldn't combine "ts" bases with select = TRUE - that's a lot more penalties. You should be fine with the "tp" basis and select = TRUE . Also, you should be using knots = list(hour = c(0, 24)) in the model to set the end points for the "cc" cyclic smooth basis.
