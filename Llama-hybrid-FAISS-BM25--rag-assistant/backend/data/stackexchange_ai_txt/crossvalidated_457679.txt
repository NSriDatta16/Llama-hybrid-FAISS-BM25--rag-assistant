[site]: crossvalidated
[post_id]: 457679
[parent_id]: 457674
[tags]: 
I don't know of any easy formulas to compute power in quantile/median regression analyses. My first impulse would be to run a simulation. Assume a certain effect size, simulate data based on this effect size and distributional assumptions, run your analysis using your planned test for null hypotheses on the median, see whether the effect is detected at your prespecified alpha. Do this many times and count whether the effect was detected in 80% or in 20% of your sample. Adjust the effect size until you get the power you want. One big advantage of this approach is that you will be forced to think about your analysis before you collect your data, because you will actually code up your analysis beforehand. This is a Good Thing. You will figure out how you should organize your data, and while you are thinking about this, you may hit on a covariate you should actually include in your measurements. Better to figure this out before you collect your data, rather than afterwards! Yes: the dis advantage is that this power analysis will take much longer than a simple calculator. I would still argue that this time is typically well spent (and often orders of magnitude less than the time you will spend on the actual data collection, anyway). Note, incidentally, that you must specify an effect size in advance here. So-called post hoc power calculations ("is the study sufficiently powerful to detect the effect we did observe as statistically significant?") are meaningless , because there is a monotone relationship between the observed effect size and the p value. If the effect was statistically sigificant, then the study was powerful enough to detect the observed effect as significant. If not, then not. This is nothing more than a tautology dressed up in formal-sounding statistics jargon.
