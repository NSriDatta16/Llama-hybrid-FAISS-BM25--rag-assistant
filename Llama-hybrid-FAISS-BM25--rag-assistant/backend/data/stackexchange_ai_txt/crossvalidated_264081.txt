[site]: crossvalidated
[post_id]: 264081
[parent_id]: 198638
[tags]: 
No, they are not equivalent. $E(disturbance|x)$ {not residual($e$) but actual error($\epsilon$), check your question} is conditional expectation of the error term and does not need to assume the deterministic nature of matrix $X$. It is one of Gauss Markov's assumption that makes OLS estimates BLUE (Best Linear Unbiased Estimator). Co-variance of $X$ with residual($e$) is a property of OLS, which does not need any assumption. And can be easily proven by the following: Let the slope estimate be $\hat{\beta}$; After taking derivative of SSE, $e'e$, and equating it to zero we get: $$\hat{\beta} = inv[(X'X)]X'Y$$ $$(X'X)\hat{\beta} = X'Y$$ Putting $Y = (X)\hat{\beta} + (e)$ in above equation; $$(X'X)\hat{\beta} = x'[(X)\hat{\beta} + e]$$ $$(X'X)\hat{\beta} = (X'X)\hat{\beta} + X'e$$ Till here we haven't made any assumptions (except $X'X$ is invertible, which might arise due to perfect multicollenearity or trivially because number of observations is less than number of variables). Therefore from the above equation we get that $X'e = 0$ This will always be true for OLS. Now this property leads to derivation of several other properties of OLS. $E(e)$ is one of them, which is true if the regression contains a constant. Proof: If the regression contains a constant, first column of $X$ will be vector of $1$'s and $X'e = 0$, $\therefore 1*e(1) + 1*e(2)\dots 1*e(n) = 0$ Therefore, meaning $Sum(e) = 0$, dividing by non-zero $n$, we get $E(e) = 0$ Therefore these two are properties and the above one is a Gauss Markov assumption for BLUE. The no-autocorrelation and homoscedasticity comes from another Gauss Markov assumption that; $$E(\epsilon \epsilon'|X) = (\sigma^2) \text{Identity}$$ $E(\epsilon \epsilon'|X)$ gives the covariance matrix of disturbances terms conditional on $X$. This matrix is reduced to the term on right hand side by applying two assumptions, No autocorrelation hence Covariance between errors is zero, therefore making non diagonal terms zero. Variance of error term is constant (homoscedasticity), $\therefore \epsilon^2= \sigma^2$. An excellent source can be found at: https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_NYU_notes.pdf Thanks Anurag
