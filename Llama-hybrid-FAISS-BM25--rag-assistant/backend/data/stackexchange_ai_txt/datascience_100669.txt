[site]: datascience
[post_id]: 100669
[parent_id]: 
[tags]: 
Logistic Regression Model returning same output for all inputs

I made a simple linear regression model with a simple .csv dataset that had 2 categories. For reference, the dataset looks like a larger version of this Basically, it is a hobby classification dataset having two categories, 'Name' and 'Category'. Now, I made a Logistic Regression model to classify the Hobbies based on their name. Therefore, I took 'Name' as X and 'Category' as y. Here is the simple code to train the model : X = data['Name'] X.values.reshape(1, -1) y = data['Category'] y.values.reshape(1, -1) model = LogisticRegression() label_encoder = preprocessing.LabelEncoder() X_train = label_encoder.fit_transform(X_train) y_train = label_encoder.fit_transform(y_train.ravel()) X_train = np.array(X_train).reshape(256, -1) y_train = np.array(y_train).reshape(256, -1) model.fit(X_train, y_train.ravel()) Now, I made a simple list of 3 Names with diff categories for the purpose of testing. my_test = ['Sociology', 'Acting', 'Coding'] my_test = label_encoder.fit_transform(my_test) my_test = np.array(my_test).reshape(3, -1) model.predict(my_test) But, this is the output array([1, 1, 1]) Unfortunately, I'm getting the same output for all inputs I'm putting. Why is this happening ?
