[site]: crossvalidated
[post_id]: 428654
[parent_id]: 
[tags]: 
Simple Bayesian meta-analysis in R

Is there a simple way to conduct a Bayesian meta-analysis in R in order to support equivalence between the effects of two study types? E.g., Bayes factors would be perfect. So, for example I have this meta-data: met_stat = structure( list( cohens_d = c( 0.667736711989537, 0.793600760953399, 1.3124515035473, 1.30412598975747, 0.958640726783857, 0.930081791487542, 0.901946855478192, 1.02166264217578 ), variance_d = c( 0.0193529475194948, 0.0375704337470874, 0.0229130218784657, 0.052279224149358, 0.0115091851365868, 0.0219378537485526, 0.00984899858515591, 0.0209744864843904 ), version = c( "simulated", "p_vs_i", "simulated", "p_vs_i", "simulated", "p_vs_i", "simulated", "p_vs_i" ), study = c( "Verschuere, Kleinberg, & Theocharidou (2015) single", "Verschuere, Kleinberg, & Theocharidou (2015) single", "Verschuere, Kleinberg, & Theocharidou (2015) multiple", "Verschuere, Kleinberg, & Theocharidou (2015) multiple", "Kleinberg & Verschuere (2015) Study 1", "Kleinberg & Verschuere (2015) Study 1", "Kleinberg & Verschuere (2015) Study 2", "Kleinberg & Verschuere (2015) Study 2" ) ), row.names = c(NA, -8L), class = c("tbl_df", "tbl", "data.frame") ) And I want to know the effect of "version". With the frequentist approach, I could super easily get a meta-analysis done e.g. with the metafor package, in a single function: REML Then REML has all the info I need (and I can nicely print it with forest() ). Is there any kind of simple Bayesian analogue? I don't want to have to read loads of technical papers to get this done - I'll probably never even need it in the future. Now, I found this metaBMA package that at least seems to imply that I can get simple Bayes factors for a moderator in a meta-analysis. (Most other Bayesian don't seem to allow moderators.) But there is, naturally, no sensible description whatsoever on how exactly to use it and/or how to interpret the output. Below is what I managed so far. Firstly, I now calculated SEs because that's needed apparently (instead of variance), so here is how my new dataset looks like: met_bf = structure( list( cohens_d = c( 0.958640726783857, 0.930081791487542, 0.901946855478192, 1.02166264217578, 1.07356225952092, 1.44689069627541, 0.723488965731349, 0.839350257451386 ), sed = c( 0.107492799152646, 0.148930067394091, 0.0994437724487224, 0.145065264316275, 0.0805875458638765, 0.141971247410652, 0.0730295485698532, 0.158223382018453 ), study = c( "Kleinberg & Verschuere (2015) Study 1", "Kleinberg & Verschuere (2015) Study 1", "Kleinberg & Verschuere (2015) Study 2", "Kleinberg & Verschuere (2015) Study 2", "Kleinberg & Verschuere (2016) Study 1", "Kleinberg & Verschuere (2016) Study 1", "Kleinberg & Verschuere (2016) Study 2", "Kleinberg & Verschuere (2016) Study 2" ), version = c( "simulated", "p_vs_i", "simulated", "p_vs_i", "simulated", "p_vs_i", "simulated", "p_vs_i" ) ), row.names = c(NA, -8L), class = c("tbl_df", "tbl", "data.frame") ) Then I did this: bayes_model = metaBMA::meta_random( y = cohens_d~version, SE = sed, labels = study, data = met_bf ) And this indeed contains some results, but nothing that resembles Bayes factors or something that proves equivalence. There is the metaBMA::inclusion() function for inclusion Bayes factors, but I don't know how I could integrate it; it requires at least two models. I was thinking of excluding and including 'version', and then comparing the two obtained models, but I'm not sure whether it makes sense the way I do it - and even if it does, I do not understand the output. Anyway, here is how it would look: bayes_model1 = metaBMA::meta_random( y = cohens_d, SE = sed, labels = study, data = met_bf ) bayes_model2 = metaBMA::meta_random( y = cohens_d~version, SE = sed, labels = study, data = met_bf ) metaBMA::inclusion(logml = list(bayes_model1, bayes_model2)) Any ideas?
