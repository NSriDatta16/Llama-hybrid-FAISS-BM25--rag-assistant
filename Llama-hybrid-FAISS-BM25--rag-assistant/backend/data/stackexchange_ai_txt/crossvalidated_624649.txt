[site]: crossvalidated
[post_id]: 624649
[parent_id]: 
[tags]: 
How to adjust the scaling of the new data while use Incremental training of a neural network?

I am planning to use incremental training of my neural network model since I continually get new data and at present retrain the model after a period of time but the training window shifts forward. To be clear, suppose, initially, I trained on N months worth of data. But then I gather data for another 1 month and the retrain the model on the last N months (training window shifts forward by 1 month). This poses a problem: While retraining, I am not using the 1st month's data and it is effectively discarded. I don't want that as it may contain important information. However, N months data is the best I can keep without investing on additional storage. This way my training forgets important "knowledge" learned in the old data which is not desirable. To solve the problem, I was hoping to use incremental training once some some data is gathered. But I ran into the problem of how to effectively scale my training data. At present, I am scaling (Min-Max scaling) my training data before the model is trained. If I do incremental training, how do I effectively re-scale the data so that model training is consistent? Any idea ? There is another question of similar nature here but it doesn't address the scaling issue. Thanks for your help.
