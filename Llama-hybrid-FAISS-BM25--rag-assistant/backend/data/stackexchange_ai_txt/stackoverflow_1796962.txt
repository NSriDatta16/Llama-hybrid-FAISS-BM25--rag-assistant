[site]: stackoverflow
[post_id]: 1796962
[parent_id]: 1796481
[tags]: 
The short answer is, "Yes, to varying degrees." Different organizations approach software development with varying degrees of rigor, but the concept of layered design, in which each layer deals with its responsibilities in terms of a very constrained, precisely-designed interface to the services provided by the next layer down, is well-established. I would point to the growing acceptance of test-driven development, dependency injection, and design to interfaces as evidence that these ideas are slowly becoming established as standard in software development. However, software development is pursued at a wide variety of scales and for a wide variety of purposes. Just as the level of precision engineering increases in physical fabrication as scale and complexity increase (e.g. jet engine manufacturer vs. picture framer), some software developers deal with systems whose performance and scale of use are small enough that they can tolerate lack of precision, or even long-lived defects (e.g. a typical web developer vs. a developer working on avionics or embedded medical devices). My observation is that precision and strict layering have often been regarded as costs to be born only when the consequences of defects are sufficiently high. But I see that slowly changing for the better, at least in the development of mission-critical systems that work at Internet scale.
