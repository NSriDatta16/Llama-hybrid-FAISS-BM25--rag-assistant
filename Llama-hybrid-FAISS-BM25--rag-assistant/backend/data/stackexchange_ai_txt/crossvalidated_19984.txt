[site]: crossvalidated
[post_id]: 19984
[parent_id]: 19972
[tags]: 
Your problem is much like any other machine learning problem: you have some data and you use some of it as training data, to tweak your algorithms, then you use some of of the data (that wasn't used for training) to choose a "winner" algorithm, and finally you use some of the data (that wasn't used for training or testing) to give yourself an idea of how your winner will work in the Real World. In your case, the initial data is artificial. The question is: how well does the artificial data mimic the Real World where you intend to use your technique? Your technique reflects a model of the world that is simplified. The main fear would be that your data-generation method reflects the same simplifications, and thus provides data that fits your model well, as opposed to your model fitting the Real World well. (Even if your data were not artificial, the issue still arises: when you say a technique is "superior", all that you can really say is that you were able to adjust it to work better on the data on which you tested it. If you did your work well and the technique is sound, it will probably be a good choice on similar data. You have to be careful with what you mean by "superior".)
