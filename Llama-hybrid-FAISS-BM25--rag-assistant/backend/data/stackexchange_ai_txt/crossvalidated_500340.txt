[site]: crossvalidated
[post_id]: 500340
[parent_id]: 31036
[tags]: 
If we take a sample of size $n$ and calculate the difference between the estimator and the true parameter, this gives a random variable for each $n$ . If we take the sequence of these random variables as $n$ increases, consistency means the both the mean and the variance go to zero as $n$ goes to infinity. Unbiased means that this random variable for a particular $n$ has mean zero. So one difference is that bias is a property for a particular $n$ , while consistency refer to the behavior as $n$ goes to infinity. Since Another difference is that bias has to do just with the mean (an unbiased estimator can be wildly wrong, as long as the errors cancel out on average), while consistency also says something about the variance. An estimator can be unbiased for all $n$ but inconsistent if the variance doesn't go to zero, and it can be consistent but biased for all $n$ if the bias for each $n$ is nonzero, but going to zero. For instance, if the bias is $\frac 1 n$ , the bias is going to zero, but it isn't ever equal to zero; a sequence can have a limit that it doesn't ever actually equal.
