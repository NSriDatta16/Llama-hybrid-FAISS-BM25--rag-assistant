[site]: crossvalidated
[post_id]: 295373
[parent_id]: 295370
[tags]: 
Typically, you would not use bootstrapping to calculate the mean. Rather, the mean would be the empirical average from your original dataset, and the bootstrapping replicas (of which should there should be many more than 3, incidentally), would be used only to calculate the confidence interval of the mean. One exception to this would be using bootstrapped bias correction (see Introduction To The Bootstrap, Or Michael Chernik's books), but, here too, you would start off with the mean from the original dataset. In each iteration, you would calculate the difference between the original mean, and the mean of the dataset. Using the frequencies for the biases, you could decide if the original mean is biased. Using bootstrapping for bias correction is dangerous, and is done more rarely. Edit based on the question clarification Here is the application of this to the specifics of your case. Suppose you divide your dataset into 3 parts, $A$, $B$, and $C$. Using $A$ and $B$ you build a model, and predict $C'$; using $A$ and $C$ you build a model, and predict $B'$; using $B$ and $C$ you build a model, and predict $A'$. Using $A, A'$, $B, B'$, and $C, C'$, you presumably build now $A''$, $B''$, and $C''$, indicating the cross-validated accuracy. Define now $X = A'' + B'' + C''$, that is, $X$ is the concatenation of these three results. The estimated mean should be the mean of $X$. The confidence intervals should be calculated by bootstrapping $X$.
