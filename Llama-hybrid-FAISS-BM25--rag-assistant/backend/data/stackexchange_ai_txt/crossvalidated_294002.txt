[site]: crossvalidated
[post_id]: 294002
[parent_id]: 
[tags]: 
Choosing data points for multiple regression

I am building a regression model from simulation data. Specifically, I can choose which data points to sample and want to minimize my average prediction interval in the prediction space $[L,U]$. In the one-dimensional case, my I am computing my prediction interval as: $$PI(y)=MSE*\left[ 1+\frac{1}{n}+\frac{(x_{new}-\bar x)^2}{\sum_{\forall i} (x_i-\bar x)^2} \right]$$ It seems to me that, to obtain a minimal average prediction interval, I should 'observe' points as wide from the center as possible to maximize the term $\sum_{\forall i} (x_i-\bar x)^2$. Does a similar logic apply to the multivariate regression case? Should I maximize the average distance between all data points, or should I simply sample data points at the edges of the prediction space? How can I mathematically justify this procedure? Ultimately, I am looking to systematically decrease prediction intervals by intelligent data selection, as is shown in this graph (reduction by ~14%).
