[site]: crossvalidated
[post_id]: 354536
[parent_id]: 
[tags]: 
MLE for the logistic regression: Programming problem

I'm learning GLM models and found the following log-likelihood by hand and wrote the code below it as an inference exercise. However my result for the parameter is different from the glm() function's result. I'd appreciate if someone pointed out what is wrong, the calculations or my code. Thanks! \begin{align} \mathcal{L}(p_{i}, n_{i}, y) &= \prod_{i=1}^{N}{n_{i} \choose k_{i}} p_{i}^{k_{i}}(1-p_{i})^{n_{i}-k_{i}} \\ \ell(p_{i}, n_{i}, y) &= \sum_{i=1}^{N}\log {n_{i} \choose k_{i}} + k_{i} \log p_{i} + (n_{i} - k_{i})\log(1-p_{i}) \\ &= \sum_{i=1}^{N}\log {n_{i} \choose k_{i}} + k_{i}\log \frac{p_{i}}{1-p_{i}} + n_{i}\log(1-p_{i})\\ &= \sum_{i=1}^{N}\log {n_{i} \choose k_{i}} + k_{i} x'_{i}\beta - n_{i}\log(1 + \exp(x'_{i}\beta))\\ \frac{\partial\ell}{\partial \beta_{j}} &= \sum_{i=1}^{N}k_{i}x_{ij} - n_{i}x_{ij}\frac{\exp(x'_{i}\beta)}{1+ \exp(x'_{i}\beta)} \end{align} set.seed(100) dados EDIT: I found the solution by myself, me and all my disattention were optimizing the derivative, not the log-likelihood. GitHub link as said in the comments: https://github.com/sergioandrad/RegressaoLogistica-
