[site]: datascience
[post_id]: 81095
[parent_id]: 
[tags]: 
Advantages and disadvantages of using softmax/sigmoid and categorical_crossentropy/binary crossentropy for a binary classification with a CNN

I'm doing a deep learning model using tensorflow and keras. I have a question about the output architecture. I want to classify between two classes, images with defects and images without defects, I've built a CNN based on VGG16 but smaller. The problem is basically a binary classification.It's possible to use one unique neuron on the output using the sigmoid activation and the binary crossentropy function as loss. The other option is to use two neurons, using softmax and categorical crossentropy as loss (of course, using a onehot ecoder to represent the 2 labels). I've been looking for a detailed explanation of the difference between this two options but I have not found response of what I really want to know. This is a related question I've read: https://stats.stackexchange.com/a/260537/295456 Here is said that binary crossentropy is just a special case of categorical crossentropy. Is there any advantage in any of this approach? I'd like to know the advantages and disadvantages of both options. The network would converge faster/slower? There would be more parameters to train? One of this options can be considered as bad desing? This is just a schematic code to represent the two aproches: ## Opt 1. targets = [[0,1], [1,0],...] ... model.add(Dense(units = 2, activation = 'softmax')) model.compile(loss = 'categorical_crossentropy') ## Opt 2. targets = [1,0,1,...] ... model.add(Dense(units = 1, activation = 'sigmoid')) model.compile(loss = 'binary_crossentropy')
