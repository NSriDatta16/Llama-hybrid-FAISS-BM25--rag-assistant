[site]: datascience
[post_id]: 124146
[parent_id]: 
[tags]: 
Data Preprocessing in the Wild?

I am new to ML, NN, and data science as a whole so the following question might sound silly. How can we perform inference when the model is deployed in the wild? To my understanding, cleaning/preprocessing is almost always required before training a model. However, a model deployed in the wild will be ingesting raw data that might be corrupt, filled with gaps, and not normalized. How do we then guarantee the same model will be able to run properly when the data it is seeing looks very different than what it had seen during training?
