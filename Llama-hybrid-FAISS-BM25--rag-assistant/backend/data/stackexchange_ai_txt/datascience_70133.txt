[site]: datascience
[post_id]: 70133
[parent_id]: 
[tags]: 
Determining number of clusters in high dimensions

I am doing KMeans clustering for sentence embeddings and my problem is the number of clusters. In general, feature size is an order of a few hundreds (in this case 768) and my concern is the sparsity of space. I tried to use gap statistic , but it just increases monotonically and has no maximum (I ended up with max 2048 clusters). Also, embeddings lie on a n-dimensional sphere rather than fill the space uniformly. My questions is: does it really make sense to use various "clustering metrics" to determine optimal number of cluster when the feature space is large?
