[site]: crossvalidated
[post_id]: 124392
[parent_id]: 123814
[tags]: 
A very simple model: Let $s_{1,i}$ be the score of student $i$ on test 1, and $s_{2,i}$ his score on test 2. Let $A_1, \ldots, A_p$ be the partition of the students in the original cohorts. Each cohort is biased by the strength of its students and the easiness of the grader. Assuming this is an additive effect, we back out of it the following way: we'll subtract the average score of the cohort on the first test, and add the average score of the cohort on the second test. We compute an adjusted score $s'_1$ as follow $$\forall j \leq p, \forall i \in A_j, s'_{1,i} = s_{1,i} - \frac{1}{|A_j|} \sum_{i \in A_j} ( s_{1,i} - s_{2,i} )$$ Finally, form a final score $s$ with whichever weighting you find appropriate $$\forall i, s_i = \alpha s'_{1,i} + (1-\alpha) s_{2,i}$$ The downside is that an individual student might be penalized if the people in his cohort happened to get unlucky on the second test. But any statistical technique is going to carry this potentially unfair downside.
