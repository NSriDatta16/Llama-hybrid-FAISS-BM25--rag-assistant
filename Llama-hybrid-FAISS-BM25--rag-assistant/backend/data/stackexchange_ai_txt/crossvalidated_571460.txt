[site]: crossvalidated
[post_id]: 571460
[parent_id]: 
[tags]: 
How can I obtain the full posterior and the full conditionals from a joint normal and inverse gamma likelihood and prior?

As a complete beginner in the world of Bayesian statistics, I unfortunately have no idea of how to start this problem. I am given that our data is distributed in: $x_n|(\mu,\sigma^2)$ ~ $N(\mu,\sigma^2)$ . Using this, we are also given that the priors are respectively $\mu$ ~ $N(\mu_0,\sigma^2_0)$ and $\sigma^2$ ~ $Gamma^{-1}(a,b)$ . I assume that the prior for sigma squared is simply the inverse gamma function. We are also given all values for $\mu_0,\sigma^2_0,a,b$ with them being $2,1,1,$ and $1$ respectively. That means they are all fixed and known which should be very helpful in getting the full posterior and full conditionals. I have started this problem by attempting to build a DAG model in which the priors both point to the data distribution which is also normal. Is it as simple as just multiplying the two priors (pdfs) to get the posterior? In which case, the distribution for $\mu$ is simple since it is just normal and $\sigma^2$ would just be $~Gamma(a,\frac{1}{b})$ . But then, how would I obtain the conditionals since all parameters are specified and fixed?
