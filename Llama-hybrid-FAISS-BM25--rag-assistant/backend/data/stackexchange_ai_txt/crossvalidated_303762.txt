[site]: crossvalidated
[post_id]: 303762
[parent_id]: 287777
[tags]: 
Well, if you look at the way Random forests work - they work by training multiple decision trees sub-samples that are always the same as the original input sample size and a random selection of variables, repeating this process multiple times. The final result is a function of the result of each individual run such as the average or max, etc. This is how the Random Forest is able to find a near-optimal split when sometimes a single decision tree doesn't suffice.
