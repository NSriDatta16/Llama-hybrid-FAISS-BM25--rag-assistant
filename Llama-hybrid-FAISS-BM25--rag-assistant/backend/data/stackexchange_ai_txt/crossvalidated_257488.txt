[site]: crossvalidated
[post_id]: 257488
[parent_id]: 257471
[tags]: 
Yes, you can. The predictive accuracy will probably be bad, because separation usually arises from not having enough data for your predictors. Regularization (as with a ridge or lasso penalty) could help a lot. Keep in mind that logistic regression is designed more for probabilistic classification (predicting the probability of each case belonging to each class) than plain old classification. So if you don't care about predicted probabilities, you may be better served with something else, like a classification tree. That said, complete separation is an inherent feature of the data and thus is, in general, just as much of a problem for models other than logistic regression. What you want is regularization or feature selection, which are standard parts of some models.
