[site]: datascience
[post_id]: 116352
[parent_id]: 116245
[tags]: 
I don't know exactly but you could check the weight content at every epoch to see how random works: from keras.callbacks import LambdaCallback model = Sequential() model.add(Embedding(max_features, 128, dropout=0.2)) model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2)) model.add(Dense(1)) model.add(Activation('sigmoid')) print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: print(model.layers[0].get_weights())) model.compile(loss='binary_crossentropy',optimizer='adam',metrics['accuracy']) model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=5 validation_data=(X_test, y_test), callbacks = [print_weights]) Source: https://stackoverflow.com/questions/42039548/how-to-check-the-weights-after-every-epoc-in-keras-model
