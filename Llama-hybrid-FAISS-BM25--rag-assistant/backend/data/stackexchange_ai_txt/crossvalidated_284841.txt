[site]: crossvalidated
[post_id]: 284841
[parent_id]: 284769
[tags]: 
Here's a couple of (somewhat related) reasons why: For quantities that must be positive (consider that we know that at least one piano exists in at least one household) there's a tendency for errors on the high side to be further away than errors on the low side (you can be far more than 100% too big easily, but you can't be even 100% too small, because that would mean guessing $0$ , a value we just said we know is not the case); indeed - at least to a rough approximation - guessing twice too high and guessing half too high would be nearer to equally likely. (Our relative uncertainties in such guesses are usually not absolute but relative.) Or imagine that we had some kind of very noisy sense of how big it was, but there were several contributions to that uncertainty. We know that certain kinds of households are more likely to have pianos -- apartments, for example, will have trouble fitting even an upright in, while large houses might fit a grand piano, but we don't really have a good sense of a typical number of pianos per large house nor a typical proportion of large houses. Those effects tend to arise as products (proportion of dwellings big enough for a piano x pianos per larger dwelling). When you have lots of contributions of small additive errors, means work well for estimating typical values. If you take logs, the product is a sum and the geometric mean is an arithmetic mean on the log scale. I'm brought to mind of an essay in which Asimov explored the Drake equation to estimate the number of technological civilizations in the galaxy (I believe he also did a similar analysis in a book and a paper). At one point he treats one probability as "either being very small or large" (paraphrasing). He then chooses two representative values for those possibilities, and averages the final results . The outcome is very similar to just choosing a somewhat different large value (one merely half as big), so it gives almost no weight to the "small" option. When you have uncertainty in a positive quantity that spans orders of magnitude, in an ordinary arithmetic average, the large one will completely dominate the outcome, even though it had by far the larger (absolute) uncertainty. If it made sense to combine the two options at all, an arithmetic mean wasn't a suitable approach.
