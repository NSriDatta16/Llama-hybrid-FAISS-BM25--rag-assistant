[site]: crossvalidated
[post_id]: 2303
[parent_id]: 2299
[tags]: 
Great Question! In the scientific context there are various kinds of problematic reporting and problematic behaviour: Fraud : I'd define fraud as a deliberate intention on the part of the author or analyst to misrepresent the results and where the misrepresentation is of a sufficiently grave nature. The main example being complete fabrication of raw data or summary statistics. Error : Data analysts can make errors at many phases of data analysis from data entry, to data manipulation, to analyses, to reporting, to interpretation. Inappropriate behaviour : There are many forms of inappropriate behaviour. In general, it can be summarised by an orientation which seeks to confirm a particular position rather than search for the truth. Common examples of inappropriate behaviour include: Examining a series of possible dependent variables and only reporting the one that is statistically significant Not mentioning important violations of assumptions Performing data manipulations and outlier removal procedures without mentioning it, particularly where these procedures are both inappropriate and chosen purely to make the results look better Presenting a model as confirmatory which is actually exploratory Omitting important results that go against the desired argument Choosing a statistical test solely on the basis that it makes the results look better Running a series of five or ten under-powered studies where only one is statistically significant (perhaps at p = .04) and then reporting the study without mention of the other studies In general, I'd hypothesise that incompetence is related to all three forms of problematic behaviour. A researcher who does not understand how to do good science but otherwise wants to be successful will have a greater incentive to misrepresent their results, and is less likely to respect the principles of ethical data analysis. The above distinctions have implications for detection of problematic behaviour. For example, if you manage to discern that a set of reported results are wrong, it still needs to be ascertained as to whether the results arose from fraud, error or inappropriate behaviour. Also, I'd assume that various forms of inappropriate behaviour are far more common than fraud. With regards to detecting problematic behaviour, I think it is largely a skill that comes from experience working with data , working with a topic , and working with researchers . All of these experiences strengthen your expectations about what data should look like. Thus, major deviations from expectations start the process of searching for an explanation. Experience with researchers gives you a sense of the kinds of inappropriate behaviour which are more or less common. In combination this leads to the generation of hypotheses. For example, if I read a journal article and I am surprised with the results, the study is underpowered, and the nature of the writing suggests that the author is set on making a point, I generate the hypothesis that the results perhaps should not be trusted. Other Resources Robert P. Abelson Statistics as a Principled Argument has a chapter titled "On Suspecting Fishiness"
