[site]: crossvalidated
[post_id]: 9678
[parent_id]: 9664
[tags]: 
The naive bootstrap depends on the sample size being large, so that the empirical CDF for the data are a good approximation to the "true" CDF. This ensures that sampling from the empirical CDF is very much like sampling from the "true" CDF. The extreme case is when you have only sampled one data point - bootstrapping achieves nothing here. It will become more and more useless as it approaches this degenerate case. Bootstrapping naively will not necessarily fail in times series analysis (although it may be inefficient) - if you model the series using basis functions of continuous time (such a legendre polynomials) for a trend component, and sine and cosine functions of continuous time for cyclical components (plus normal noise error term). Then you just put in what-ever times you happen to have sampled into the likelihood function. No disaster for bootstrapping here. Any auto-correlation or ARIMA model has a representation in this format above - this model is just easier to use and I think to understand and interpret (easy to understand cycles in sine and cosine functions, hard to understand coefficients of an ARIMA model). For example the auto-correlation function is the inverse Fourier transform of the power spectrum of a time series.
