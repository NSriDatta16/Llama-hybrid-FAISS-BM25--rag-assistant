[site]: datascience
[post_id]: 9862
[parent_id]: 
[tags]: 
Classification using xgboost - predictions

I was trying to build a 0-1 classifier using xgboost R package. My question is how predictions are made? For example in random forests, trees "vote" against each option and the final prediction is based on majority. As regard xgboost, the regression case is simple since prediction on whole model is equal to sum of predcitions for weak learners (boosted trees), but what about classification? Does xgboost classifier works the same as in the random forest (I don't think so, since it can return predictive probabilities, not class membership).
