[site]: crossvalidated
[post_id]: 432433
[parent_id]: 432337
[tags]: 
The paper Prognostic modelling with logistic regression analysis: a comparison of selection and estimation methods in small data sets should give you some insight on variable selection and shrinkage estimation. One important remark from the paper: Note that the number of candidate predictors should be considered in this reasoning, not the number of predictors included in the final model. The LASSO selects and estimates (with shrinkage) at the same time, but I would read from the paper that you still need 10 to 20 events per predictor to do so. Furthermore, LASSO is known to behave badly when predictors are highly correlated - often LASSO will choose one of the correlated predictors by random and discard the other correlated ones. This can be alleviated to some extent by the use of Elastic Net (a combination of LASSO and ridge regression). In any case, you didn't tell how you reduced the number of rpedictors from 100 to 13 in the first place (domain/external knowledge?). If you want to report for your problem a final model for prediction, I suggest the following: report all prospective (100) predictors and give reasoning why you excluded a large part based on expert/external knowledge do an exploratory PCA on the remaining 13 predictors with biplots, and/or calculate correlations between predictors: this way you might be able to reduce the number of predictors, especially like the altitude humidity, where you could exclude highly correlated ones (note that you didn't peek at the outcome yet!) do LASSO/elastic net logistic regression with your chosen "full" predictor set and the binary outcome (preferably with cross-validation). Report the chosen set of non-zero predictors and their coefficients. Don't do another regression with the reduced set of predictors! Another possibility: If you have a group of very similar predictors and you are dead-set on choosing just one of them (like the best humidity-altitude out of several options), you could train one model for each of these predictors where you exclude the other ones from the group. You will then choose the model with the smallest AIC or some other criterion.
