[site]: datascience
[post_id]: 21926
[parent_id]: 
[tags]: 
application of Histogram of oriented gradients in colored image

I recently learned about face recognition with deep learning here . One of the approach involved is Histogram of oriented gradients which is used for face detection as follows (short summary) : convert image to gray scale look at every pixel in image and detect surrounding pixel draw and arrow in direction where surrounding pixels are getting darker repeat the whole process this results in HOG version of image ,something like this : Question Can we use similar method in colored images like how does rgb varies at pixel level or how does pixels vary in colored images to improve the accuracy of face detection and similarity. Purpose face comparison is a bit tedious in this approach in terms of accuracy. So, i want to find some sort of hash function/value (just using as layman term) to derive unique value from every image. This might improve face comparison easier. Additionally , sharing any already implemented approach in this direction will be highly appreciated.
