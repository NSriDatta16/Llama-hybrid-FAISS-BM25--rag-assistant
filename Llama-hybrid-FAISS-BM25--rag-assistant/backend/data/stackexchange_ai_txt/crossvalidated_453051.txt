[site]: crossvalidated
[post_id]: 453051
[parent_id]: 453041
[tags]: 
I agree, correlation will just throw you in another direction that's not warranted -- and besides, it's not what you're after. What you need to do (formally) for logistic regression is use Model Building Strategies (MBS). MBS is based on first running "univariate" logistic regression with each independent predictor variable singly. Thus just copy the R-code to create 27 logistic models, each of which uses one variable (with the same dependent variable with values of 0 and 1). Next, look at the p-value for each univariate model, and write down which ones have a p-value $\leq 0.25$ (each univariate model has two predictors, a "constant term" and the predictor, so don't pay attention to the p-value for the constant term in each univariate model -- only the predictor variable). Then include all the single predictors whose univariate p-values were $\leq 0.25$ into a multivariate model (multiple variables) and run this model one time. This is your final model after running MBS. You can remove any variables from the multivariate model, and re-run the final model using only significant predictor variables, since removal of the non-significant predictors probably won't change the results. One thing that is certain in "modeling," or evaluating different regression models, is that the results of any model depends on the correlations between all the predictor variables, and these essentially may be linear and non-linear. You commonly just don't know the results of any model before hand, until you run it, because the contribution to the model by different predictors can change with different combinations of predictors. The free edition of Explorer will run MBS for logistic regression your 27 variables. (see Example 3 of Chapter 7 in the User Guide).
