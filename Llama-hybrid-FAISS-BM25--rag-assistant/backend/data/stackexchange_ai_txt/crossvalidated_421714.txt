[site]: crossvalidated
[post_id]: 421714
[parent_id]: 
[tags]: 
SVM: achieving ROC curve by varying misclassification costs

Assume that we have SVM model for binary classification with objective function as follows: $$ min(\frac{1}{2}\omega\cdot\omega +C^{+}\sum_{i|y_{i}=+1}^{n}\xi_{i}\quad+C^{-}\sum_{i|y_{i}=-1}^{n}\xi_{i}) $$ After many times of running optimization with different misclassification costs( $C^{+}$ and $C^{-}$ ) for testing part of one dataset, I achieved a ROC(?) representation of the model: Then, I decided to create logarithmic trendline for this set of points achieving: After reading some questions, inter alia here, I came to a conclusion, that it is not a typical way to obtain a ROC curve for SVM. The questions are: Will I lie if I name it a (approximated) ROC curve for this model? Was this a proper way to achieve ROC curve?
