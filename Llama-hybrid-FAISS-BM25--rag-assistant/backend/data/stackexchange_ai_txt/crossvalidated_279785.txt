[site]: crossvalidated
[post_id]: 279785
[parent_id]: 
[tags]: 
Is there a way to merge two trained neural networks?

Lets say I pick some network layout (recurrent and/or deep is fine if it matters I'm interested to know why), then make two neural networks A and B using that layout that are initially identical. Now I go and train A on one dataset and someone else trains B on a different (but similar) dataset. As a concrete example, lets say we train A to classify a subset of CIFAR-10 and B to classify a different subset of CIFAR-10 . There is what is known as transfer learning, where a network trained on one dataset might do better or train faster on a different dataset, in theory because it has some ideas developed about the structure of the first problem that is in the structure of the second problem. So a trivial way to classify a new subset of CIFAR-10 is to make a dense layer as input that is then connected to both A and B, then you take say the average of their outputs. However that requires increasing the size of the network. Is there a way to "merge" A and B into a network that preserves much of the same training in both into a network C that has the same layout as A and B?
