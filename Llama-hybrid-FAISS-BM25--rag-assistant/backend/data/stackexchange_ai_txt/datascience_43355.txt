[site]: datascience
[post_id]: 43355
[parent_id]: 
[tags]: 
How to represent an image as state in a Q-table

I'm trying to do Q-learning with the Atari games using the gym python's package. I want to use the image as the state of my algorithm, but I came up with a doubt: Is the state all the possibilities for all the pixels of the image? I've seen many Q-learning implementations, and in the Q-table they always store all the possible states as rows, and the actions as columns (for example, https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/ ) Without doing maths, all the possible states for, let's say, a 200x200 grayscale image are insane. How can I handle this problem without doing neural networks? I guess there must be an approach for this scenario, but I haven't found any good example. Thank you!!
