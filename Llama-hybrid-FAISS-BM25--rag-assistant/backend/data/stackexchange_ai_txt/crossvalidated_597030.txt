[site]: crossvalidated
[post_id]: 597030
[parent_id]: 282030
[tags]: 
I know this answer comes a few years late, but it could be important. I have some recent findings on the original GAN theory, mainly Proposition 1 of the 2014 paper by Goodfellow et al GAN paper . I posted a detailed reponse on Quora and I can summarise here. The optimal discriminator result is only valid when the dimension of the data ( $n_x$ ) is less than or equal to the dimension of the latent space ( $n_z$ ). When $n_z , the generator output PDF is singular (contains delta functions) and the variational argument used to obtain Proposition 1 breaks down. This is important because Proposition 1 is used in Proposition 2 - the GAN convergence result. A further result, which is a counter-example, shows that even in simple situations, the simplest being $n_z=n_x=1$ for a 1-dimensional GAN, one can get plateaux in the cost function where the stochastic gradient descent ascent algorithm stalls nowhere near the point where the generator PDF resembles the data PDF. Your simulations are using ( $n_z=100$ , $n_x=784$ ) for MNIST and ( $n_z=100, n_x=4096$ ) for the butterly data set. Both have $n_z so the result I derived applies. Please refer to the paper for more details: Convergence & Optimality Analysis of low dimensional GANs . To your specific questions on topology, dataset size, overfitting, training synchronization ratios, etc. There is currently no theory capable of answering such detailed questions on GAN training - only empirical evidence for certain data sets. Remember that you are optimising a very complicated non-linear cost function containing thousands of parameters. Because it is unsupervised, training a GAN is fundamentally harder than training a convnet. Convnet training also has direct supervision and uses equality constraints to reduce the number of degrees of freedom that produce feature maps. So Ivanbgd's suggestion to use convolutional layers in your network seems sensible. GANs are not supervised and have no intrinsic parametric constraints, so there are a huge number of hyperparameter combinations, optimizers, batch sizes, ratios of generator / discriminator iterations to try and no guarantees of convergence. Many researches have proposed alternatives to the original GAN: they mainly focus on the form cost function. It is worth remembering that the cost function includes the expectation $E_x(D(x))$ , which is the expectation of the discriminator output with respect to the data, whose PDF is unknown. You are replacing this expectation with sample-based Monte Carlo estimates but in a very high dimensional space. I would also question the use of just a uniform generator input distribution - you could try Gaussian.
