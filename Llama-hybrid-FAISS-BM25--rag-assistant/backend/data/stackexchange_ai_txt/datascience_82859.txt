[site]: datascience
[post_id]: 82859
[parent_id]: 
[tags]: 
Different probability distributions for each number of a MultiDiscrete action space

I have made a custom gym environment, and I have a question regarding the actions. I use a MultiDiscrete action space, that is, it provides a list of integer numbers. In my case, the first number defines the type of action to take, while a second number defines other things that are related to that specific action. For example , imagine a 2D map where an agent walks up, down, left, and right. The first number defines the direction (e.g., up), and the second number defines the number of steps to walk on that direction. The problem is that I want to sample all possible types of actions (in the above example, the direction) from a uniform distribution, that is, in each step all directions have the same probability to be chosen. Then, for each specific type of action, learn a policy for choosing the best action/second number (in the above example, the number of steps). More formally, this means that in each state of the MDP, we allow the agent to choose an action only from a subset of all possible actions. This subset of actions is defined by the first number of the MultiDiscrete action space (i.e., the direction). One solution that I was thinking of is to incorporate the direction of movement into the states. So, in each step we can sample a distribution (in my case I need a uniform distribution), update the state, and then apply the given action from the (smaller) action space which is now defined only by the second number (i.e., in the above example, the number of steps to walk).
