[site]: crossvalidated
[post_id]: 482000
[parent_id]: 
[tags]: 
Why are my bootstrap confidence intervals for regression coefficients consistently wider than standard confidence intervals?

I am very new to statistics and analytics. I have some basic undergrad stats and am now studying O'Reily's Practical Statistics for Data Science. I have been doing some bootstrapping exercises on home sales data and just couldn't figure out why my bootstrap confidence intervals for regression coefficients are consistently wider than the standard coefficient confidence intervals statsmodels give me for each coefficient. I would really appreciate your help if you can help me understand why that is and, if critical concepts are missing, where to study the missing concepts. My data frame looks like this: house[cols].head() Here's my code for bootstrap regression coefficient CI: # Import resample from sklearn and statsmodels for regression from sklearn.utils import resample import statsmodels.api as sm # Define bootstrap function def bootstrap(data): """Returns the parameter coefficients of one set of bootstrapped data.""" da = resample(data) model = sm.OLS.from_formula('AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms + Bedrooms + BldgGrade', data=da).fit() return model.params # Create initial dataframe for model coefficients params = pd.DataFrame(bootstrap(house[cols])).T # Create bootstrap coefficients for i in range(1000): params.loc[i] = bootstrap(house[cols]) # Find the 95% confint with percentile method params.quantile([0.025, 0.975]).T Here's the result from the bootstrap model: And this is consistently wider than the 95% CI from a simple statsmodels OLS result: house_model = sm.OLS.from_formula('AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms + Bedrooms + BldgGrade', data=house) house_result = house_model.fit() house_result.summary() Why is it so? Thanks so much! UPDATE: Thanks all who have pointed me in the general direction. Since I was asked about any kind of dependencies within the data, I did a correlation heatmap and a residual-fittedvalue plot. See below: Not much here beyond expectation. The outliers as shown in this plot made me think I should log-transform home prices, but I'm not quite sure how I can deal with the proportional increase in variance with price. Nonetheless, my original question has been answered. Note that I'm still learning the ropes, but the heteroskedasticity and outliers in the data are quite possible culprits. Additionally, as pointed out by the top response, clustering in the data is most certainly another culprit given real estate prices do cluster in communities.
