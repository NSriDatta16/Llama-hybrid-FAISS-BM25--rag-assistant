[site]: crossvalidated
[post_id]: 532518
[parent_id]: 286522
[tags]: 
For tabular data converting categorical to integers and using an embedding layer is rather standard nowadays. Especially if you have a lot of categories, this tends to be a much better approach than one-hot-encoding (or inputting category number as a numeric value that gets treated as a continuous predictor), and that's one of the main scenarios, in which neural networks get really competitive with gradient boosted trees for tabular data. For continuous inputs standardizing makes sense to speed up convergence/make things easier, unless somehow the scales across variables are truly comparable, when maybe keeping original scales makes sense. The more interesting question is whether additional transformations make sense (e.g. log-transformation for strictly positive variables with a long right-hand-tail, rank-Gauss transformation etc.), which is probably rather problem dependent. I.e. you'd ideally want to be on a scale, where your output can be explained by a linear combination of input features, like in a traditional regression equation, in which case you don't need many layers or non-linear activations (obviously, that will only ever be an approximation). While people talk a lot about neural networks "doing their own feature engineering", they still benefit from good features and "optimally" transformed features. It's always worth looking at previous work, such as the book by the fast.ai team (link is to the github repository for the book), the code of the standard tabular model in the fastai library (plus the related paper on how to regularize such models ), TabNet , SAINT , pytorch-widedeep , this from Yandex and so on. There are currently a lot of papers appearing on neural networks for tabular data.
