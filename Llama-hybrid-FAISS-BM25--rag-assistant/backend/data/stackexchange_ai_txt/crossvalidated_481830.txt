[site]: crossvalidated
[post_id]: 481830
[parent_id]: 
[tags]: 
Finding a half-iterate approximation using neural networks

I'm trying to find good approximate half-iterates, otherwise known as functional square roots . Given a function $g$ , I want to find a function $f$ such that $g(x)=f(f(x))$ over some domain. There are a few ways to approach finding a functional square root including Newton series, matrix square roots of the Carleman matrix, and others. These are all well known, but they're kind of difficult to use and have all sorts of numerical problems. I'd like to know if neural networks could be applied to the problem. Please bear in mind I only have a surface level understanding of neural networks - I just had a vague idea how they could be relevant here. Suppose I am trying to find the $f$ such that $f(f(x))=\sin(x)$ . I know we can train a neural network to learn a good approximation to $\sin(x)$ . Is there a way to construct a neural network to learn an approximation to the half-iterate $f(x)$ ? We do not know the derivative of $f$ , but we have $f'(x)f'(f(x))=\cos(x)$ If the network had one single input node, some middle layers, and a single output node, then maybe something like this would work, starting with a randomly initialized network: for a given input $x_i$ and network state $N$ , calculate the output $y_i$ use the output $y_i$ of step 1. as an input $x_i'$ of the same network to generate another output $y_i'$ . calculate the error $(\sin(x_i) - y_i')^2$ and use this to back-propagate and update weights for $N'$ . Any ideas, implementation, or pointers to literature would be very enlightening.
