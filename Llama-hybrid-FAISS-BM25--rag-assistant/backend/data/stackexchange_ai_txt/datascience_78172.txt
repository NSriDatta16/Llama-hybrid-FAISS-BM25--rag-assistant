[site]: datascience
[post_id]: 78172
[parent_id]: 78055
[tags]: 
So, from what I understand from the question, you want to get an idea of how word2vec works so you can assess how well the resulting context vectors from this model will help discriminate between words by their meaning. Word2vec works on the premise of the distributional hypothesis which essentially states that words which appear in soimikar contexts will have similar meanings (e.g. the dog ate the food/ the cat ate the food : both dog and cat appear in the same context so they are semantically close to each other) So word2vec formulates this by a CBOW model which effectively is a feedforward neural network, which takes in the surrounding context of the target word as a series of one hot encoded vectors and aims to predict the target word (there is an assumption made of course where the contexts are treated as a bag of words and therefore assumes that a wordâ€™s meaning is not related to the word ordering of its context). After training this, the models weights are then used to dorm the word embeddings, which represents a words meaning in semantic space. (For further reference )
