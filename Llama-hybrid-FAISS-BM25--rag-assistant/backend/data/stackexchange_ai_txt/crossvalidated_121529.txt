[site]: crossvalidated
[post_id]: 121529
[parent_id]: 
[tags]: 
Motive behind preserving variance

Dimensionality reduction techniques preserve some properties of the data. I was wondering how preserving variance (as PCA does) can be helpful? Precisely speaking, PCA takes the covariance matrix and a number $k$ , which denotes the dimensionality of the mapped space. It decomposes the co-variance matrix and selects the $k$ eigenvectors as the new dimension, such that the variance is preserved, as much as possible. I wanted to know how preserving variance is useful? or in other words, what is the motive behind preserving variance?
