[site]: crossvalidated
[post_id]: 481566
[parent_id]: 479143
[tags]: 
I think what you described as the 'eigenfunction' approach is popularly known as 'Nystrom's method' in machine learning community. Basically, it is a data dependent approach to kernel approximation where we randomly sample a subset of training examples and construct an approximate low-rank kernel matrix. The feature maps for each input are obtained via eigen-decomposition of this low rank matrix matrix. This is a nice paper that provides a theoretical and empirical comparison of the two approaches i.e. random fourier features (RFF) versus Nystrom's method. Essentially, the summary of the paper is that the Nystrom's method has better generalization performance than RFFs when there is a large gap in the eigen-spectrum of the kernel matrix. Update : The eigenfunction approach is not exactly the same as Nystrom's method. Please see OP's comment on this post.
