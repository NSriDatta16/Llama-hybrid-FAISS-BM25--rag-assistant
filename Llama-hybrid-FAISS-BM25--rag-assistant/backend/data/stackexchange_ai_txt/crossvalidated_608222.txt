[site]: crossvalidated
[post_id]: 608222
[parent_id]: 545162
[tags]: 
Yes, you definitely can. Moreover, it does not have to be any linear kind of regression. In the most general case, the following method will allow you to effectively turn any parametric or even non-parametric probability density estimation into a regressor for the desired output (i.e., the 3rd variable in your case, which is salary). The following method is from the book: Deep Learning , by Goodfellow, Bengio, and Courville, 2016 (page 103 or 104, from section 5.1.3), https://www.deeplearningbook.org/contents/ml.html . Note: Despite the name of the book, the following method is completely general, and suitable beyond deep learning or any other neural network, or even other machine learning methods, for that matter. The method: Assume you've modeled the probability distribution over the input vector $\textbf{v}$ as $p(\textbf{v})$ by any parametric or non-parametric probability density estimation technique. In your example: $\textbf{v}$ = [height, weight, salary] $\in \mathbb{R}^3$ . Now, you decide to estimate one component $y$ of the vector $\textbf{v}$ from the remaining "input" components $\textbf{x}$ , i.e., estimate salary from height and weight. Let's denote: $\textbf{v} = (\textbf{x}, y)$ , where $y$ is the desired component to be estimated, and $\textbf{x}$ are the remaining "input" components. Using the definition of conditional probability, the estimation of the probability of $y$ given the other components $\textbf{x}$ is: $$p(y | \textbf{x}) = \frac{p(\textbf{x}, y)}{p(\textbf{x})} = \frac{p(\textbf{v})}{\sum_{y'}{p(\textbf{x}, y')}}$$ where: $$p(\textbf{x}) = \sum_{y'}{p(\textbf{x}, y')}$$ by the law of total probability, over quantized (discretized) values $y'$ of the component $y$ . But you can use un-quantized continuous values using a suitable 1D integration technique of your choice: $$p(\textbf{x}) = \int_{y'}{p(\textbf{x}, y')}dy'$$ by the law of total probability for continuous values $y'$ of the component $y$ . Observe that instead of a specific point-estimate of $y$ you obtain a posterior probability density estimation $p(y | \textbf{x})$ of $y$ given the $\textbf{x}$ inputs. If you only need a point-estimate, you can simply choose for example: $$\hat{y} = argmax_{y'} p(y | \textbf{x})$$ where $\hat{y}$ is the maximum aposteriori point-estimate.
