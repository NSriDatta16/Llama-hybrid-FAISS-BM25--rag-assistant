[site]: crossvalidated
[post_id]: 234743
[parent_id]: 
[tags]: 
More moderators in a meta-analysis equals greater chance of reaching statistical significance?

I have the following example data, stored in the variable TheData , Study ID Category Cohens_d Variance 1 1 A 0 0.1 1 2 B 5 0.1 1 3 C 10 0.1 2 4 A 20 0.1 2 5 B 25 0.1 which I want to run a meta-analytic model with moderators on. If I'm using the rma.mv function from the Metafor package, and run rma.mv(Cohens_d, Variance, random = ~ 1 | ID, mods = ~ factor(Category) - 1, data=TheData) I get the following result Multivariate Meta-Analysis Model (k = 5; method: REML) Variance Components: estim sqrt nlvls fixed factor sigma^2 199.9003 14.1386 5 no ID Test for Residual Heterogeneity: QE(df = 2) = 4000.0000, p-val which is what I want, namely that each category is estimated to the average of the observed values (see this question for a discussion of using different random effects structures). So far, so good. However, if I add data for a fourth category, D , like so Study ID Category Cohens_d Variance 1 1 A 0 0.1 1 2 B 5 0.1 1 3 C 10 0.1 1 4 D 0 0.1 2 5 A 20 0.1 2 6 B 25 0.1 2 7 D 10 0.1 this gives me the following result Multivariate Meta-Analysis Model (k = 7; method: REML) Variance Components: estim sqrt nlvls fixed factor sigma^2 137.4002 11.7218 7 no ID Test for Residual Heterogeneity: QE(df = 3) = 4125.0000, p-val Note that here, the standard error (and subsequently the p-values) of my original categories have changed, or more specifically shrinked. Also note the p-value for the overall test of moderators which shrinks as well when adding another category (in this case from 0.29 to 0.24 ). Is this how the model is supposed to work, or have I somehow distorted it with my strange dataset? From this result, it seems like I could, if I'm not happy with my p-values (let's say I would like cateogory B to be significantly different from zero), just chuck in a couple of extra categories and call it a day (or make sure that I include a couple extra moderators from the start if I don't want to modify my analyses after the fact). I'm not sure if I'm bumping up against some grander statistical problem/principle here, something that's not specifically related to only meta-analyses, but nevertheless, I'm still confused.
