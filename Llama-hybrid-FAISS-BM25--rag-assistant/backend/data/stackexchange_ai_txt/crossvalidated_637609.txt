[site]: crossvalidated
[post_id]: 637609
[parent_id]: 637591
[tags]: 
I disagree with @DrJerryTAO's answer for this question. Specifically, I agree that your model is wrong/problematic, but disagree about the solution. I would suggest hgt ~ time*model + (1 + time | model:member) time*model captures the different intercepts and slopes for each model. I agree with your argument for specifying model as a fixed effect, but more specifically you are probably interested in making inferences about the differences in intercepts and slopes between particular models , which requires that you treat them as a fixed effect. the problem with your random effect was using model/member as the grouping variable(s) rather than model:member . The former ( model/member ) expands to model + model:member ; the first term there ( model ) is redundant with the fixed-effect terms in your model (that is, you are including variation in intercepts and slopes among models in your model twice , once as a fixed effect and once as a random effect). If you specify sum-to-zero contrasts for model (e.g. by adding contrasts = list(model = contr.sum) to your argument list), then the intercept will represent the average intercept across models and the slope will represent the average slope. You can also achieve this post hoc using the emmeans package. Singular fits are a big can of worms, search on CrossValidated or read ?lme4::isSingular or the relevant section of the GLMM FAQ . The short version is that you aren't necessarily doing anything wrong, and it doesn't necessarily mean there's a problem â€” it may just mean that the best fit to your model is consistent with there being no variation across grouping variables in some dimension. (However, I'd fix the model specification first before thinking about it any more, in any case ...)
