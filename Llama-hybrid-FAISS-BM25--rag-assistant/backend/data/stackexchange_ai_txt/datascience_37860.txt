[site]: datascience
[post_id]: 37860
[parent_id]: 37859
[tags]: 
Machine learning is a powerful tool however it is not a silver bullet which can predict anything from nothing. For example, I cannot predict your dinner tomorrow night based on data of what you are wearing (unless you are a very particular individual). This is an exaggeration however you can see that in order to make some prediction it is vital that your data correlates with your desired targets. Predictive models have always existed. What differentiates machine learning from analytical predictive models is that it introduces algorithms which tune model parameters efficiently. As a consequence we can now train models using much more features than was previously possible. In order to be able to predict some value reliably, your data needs to have embedded information which correlates with that value. For example, if all your features contain no information which correlates with the predicted targets then no matter how powerful your model is, it will never be able to predict the target reliably. Furthermore, a target value which is very noisy will require you to have substantially more data. This is exactly the case for stocks, a stock price is not dependent on only the revenue. In fact the revenue has very little impact on the stock price. Thus, you cannot expect the target predicted value to be reliably determined using this low information feature. In order to predict stock prices you will need much more data, here are some good starting features: revenue market index stock prices of similar companies stock trade volumes stock total volumes etc... You can get really creative with features. For example, it's common for stock prediction models to use sentiment analysis from daily news articles.
