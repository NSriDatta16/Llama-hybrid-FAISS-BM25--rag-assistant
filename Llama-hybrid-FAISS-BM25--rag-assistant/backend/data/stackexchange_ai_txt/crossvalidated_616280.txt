[site]: crossvalidated
[post_id]: 616280
[parent_id]: 
[tags]: 
Which statistical tests to use for identifying trends in multiple time series?

I'm processing several time series in an effort to identify meaningful trends over time. More specifically, I'm computing several time- and frequency-domain metrics (e.g. RMS, Peak-to-Peak, Integral, Median and Peak frequencies) over sequential same-length windows/segments (no overlap) and performing a 1st order polynomial fit (using least-squares method). However, I'm struggling to understand how to objectively quantify the statistical significance of the polynomials I've obtained. For instance, a specific metric, computed for 4 separate series, over 31 intervals varies like: How to I check if these trends are statistically significant? 1 and 3 are visually increasing, but the original data (from which metrics are computed) is inherently noisy, and therefore the evaluation metrics fluctuate between subsequent repetitions, which may influence the slope of these lines. What kind of preliminary tests should I perform on either the original time series or the metric value distribution (regarding normality and autocorrelation of the time series and resulting metrics distribution)? Which statistical test(s) are indicated to evaluate the existence (or not) of significant trends in the metric values? I've looked into the Mann-Kendall test (which, in the example above, results in very low p-values for sets 1 and 3, moderate for 2, and high for 4), which tests for monotonic trends without making any assumptions on its normality, but requires the data to not have any autocorrelation. In addition, the original 4 time series are in truth rows in the coefficient matrix obtained after factorization (NNMF is used) of higher dimensional (10) sensor data, and I'm unsure as to what implications this has on the independence of each curve/trend.
