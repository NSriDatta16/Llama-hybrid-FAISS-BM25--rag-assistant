[site]: crossvalidated
[post_id]: 54542
[parent_id]: 54537
[tags]: 
It looks like you could use linear regression (without an intercept). Each dataset could be used as one "observation, and for each of those, the observed measurements are the covariates and the target mean is the outcome of interest. That way, you would fit a model like: $$ E[target] = \beta_1 obsmeas_1 + \beta_2 obsmeas2 + ... $$ An ordinary least squares fit for this would indeed minimize the error in the sense that you require, because the predictions of the model would indeed be the weighted averages, and OLS minimizes the distances between these predictions and the actual outcome (here: your target means). Caveat: this includes no way of enforcing all your weights to be positive. I'm guessing this can be done through some penalization, but I don't see it immediately.
