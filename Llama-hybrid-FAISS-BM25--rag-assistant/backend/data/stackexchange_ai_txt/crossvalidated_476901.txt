[site]: crossvalidated
[post_id]: 476901
[parent_id]: 
[tags]: 
Neural network training converges for several epochs, then diverges badly

I have a VGG-like network that I have trained from scratch on a multi-class dataset of my own. The results suggested there were probably some data errors somewhere, so I thought I would train the same network on only a sub-set of the classes to narrow down where to hunt for those alleged errors. (Admittedly, the classes are unbalanced, and that will also likely be having some impact). The results on the three (unbalanced) classes I selected were looking impressive for 25 epochs... then suddenly the loss and accuracy on the training set diverged wildly from the validation set, all metrics indicated something had gone badly wrong - e.g. the validation accuracy plumetted to far worse than chance, and got stuck there. What is this converge-then-diverge phenomenon called, and what can cause it?
