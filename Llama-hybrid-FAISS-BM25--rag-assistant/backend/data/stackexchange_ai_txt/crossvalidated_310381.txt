[site]: crossvalidated
[post_id]: 310381
[parent_id]: 310370
[tags]: 
If I understand your question correctly, you are concerned with the problem of maximizing the likelihood in the case where (without being Bayesian and having a prior) the observation will lead to an estimate on the boundary of the parameter space. In the frequentist setting I think this is a way to deal with this: Don't allow the parameter to take values on the boundary and simply conclude that you don't have enough data if the MLE lands there (probably a wise course in this case). This is related to the idea of "asymptotically well-defined" estimators, i.e., estimators where the probability of obtaining an estimate outside of the parameter space goes to zero. In other words, unless the coin is heads on both sides (P(Tails = 0)), you will eventually observe a tails and your estimate will be in the parameter space, i.e., the open interval (0,1). However, with parameter space [0,1], you can still maximize the likelihood, as was pointed out by @whuber. The MLE will then be $\hat{p} = 1$, if $p = P(X=\text{Tails})$. The question about "the formula" presumably relates to the fact that we like to solve the equation where we set the score function equal to zero ($\frac{\partial \log L(\theta ; y)}{\partial \theta} = 0$) and solve for $\theta$ to obtain a stationary point which is then $\hat \theta$. But that implicitly leans on convex optimization: (1) the log-likelihood being convex (which you demonstrate by checking the second derivative being strictly positive) and (2) the stationary point not being on the boundary of the parameter space. In this case, (2) is broken. In fact, if you consider the likelihood only as a function on the parameter space, the derivative isn't even defined there, only the derivative from the right in 0 and from the left in 1. Lastly note that while a Bayesian prior can get your posterior distribution away from the boundary, your example would still be concerning because the choice of prior will then be pretty important in how the posterior looks like. Of course, to my mind, if you don't believe in your prior you have no business using it.
