[site]: crossvalidated
[post_id]: 371026
[parent_id]: 
[tags]: 
How to test whether a prediction interval truly captures 95%?

I want to analyze the 95% prediction intervals for a model. The true values should fall within the prediction intervals 95% of the time (on average) if the interval is well calibrated. If the proportion of times that the true value falls within the prediction interval departs widely from 95%, in either direction, then the method for constructing prediction intervals likely needs to be changed. I have searched for literature on the topic of validating prediction intervals, but I have struggled to find anything. Here is my proposed method for validating prediction intervals: If I know the true values, for $n$ prediction intervals I end up with $n$ Bernoulli trials, where a "success" is defined as the true value falls within the prediction interval. I then conduct a Binomial test to analyze whether the true probability of success is 0.95 Is this a reasonable way to validate a model's prediction intervals? Is there literature on this topic that I am missing?
