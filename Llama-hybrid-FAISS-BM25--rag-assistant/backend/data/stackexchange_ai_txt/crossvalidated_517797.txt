[site]: crossvalidated
[post_id]: 517797
[parent_id]: 517795
[tags]: 
Consistency is a property of an estimator. The central limit theorem is, well, a theorem: it relates to the asymptotic property of the sample average under certain conditions, and that they tend to a normal distribution with variance equal to the inverse of the information matrix at a rate of root-n. Not all estimators are sample averages. And if they're lucky enough to have an asymptotic distributions, it may not be normal. For instance, you can estimate the upper bound of a uniform (0, $\theta$ ) distribution by $X_{(n)}$ , the sample maximum. This is a biased estimator, but it is consistent because the bias goes to 0 in large samples. The bias can be corrected by a factor of $n/(n-1)$ and this estimator has an asymptotically exponential distribution due to Huzurbazar.
