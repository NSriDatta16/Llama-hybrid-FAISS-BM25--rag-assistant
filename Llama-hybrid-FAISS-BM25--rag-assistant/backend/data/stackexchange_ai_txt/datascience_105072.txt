[site]: datascience
[post_id]: 105072
[parent_id]: 
[tags]: 
How to give feedback if it's uncertain whether or not a choice was correct?

Suppose you have a machine learning system, which aims to predict whether or not the recipient of a parcel will be at home, before delivery is attempted. For example, Alice is working from home, so the likelihood of her being at home at the time of delivery is very high. Bob, however, is working on a construction site, so he is presumed to not be at home during possible delivery windows. The system would learn by making predictions about each person, and then receive feedback whether or not that prediction was correct. If the system predicted that the recipient would be at home, then a delivery attempt would be made, and it could be recorded whether the recipient was actually at home or not. However, if the system would predict that the recipient was not at home, then it would not be possible to verify whether that prediction was correct. It could then be presumed that the system would always predict that the user was not at home. Possible Solutions I came up with two possible strategies to mitigate this issue. First, even if the system stated that the recipient was likely not at home, there would be a random chance for the delivery attempt to be made regardless. This would then be able to confirm whether or not the system was correct. This, however, would come to the downside of the added "cost" of attempting to deliver a parcel to someone who was likely not at home. The second, somewhat more elegant solution, is to ask people whether or not they were at home during the initial delivery window, when they pick up their package. This initially seems better, but could lead to negative responses from recipients. For instance, they could be upset that they were at home, but were not delivered their parcel, because a computer didn't deem them worthy. Or, it could lead to recipients lying about having been at home, as for them, being categorized as "someone, who is likely at home" is a strictly positive categorization. All the downsides of being categorized as such only affect the delivery service, but not the recipient. It is thus in the best interest to give dishonest feedback in an attempt of being categorized more favourably. Is there a better way of modelling this? Or would I just have to "bite the bullet" and accept that people will attempt to game the system?
