[site]: crossvalidated
[post_id]: 254743
[parent_id]: 254735
[tags]: 
By the law of total probability $$ P(B)=\sum_i P(B\mid A_i) \,P(A_i) $$ so both forms are equivalent. This is also noted in Wikipedia that provides multiple examples and goes into more detail. Notice also that in Bayesian statistics scenario, where $f_\Theta$ is a prior distribution of some parameters of the distribution of your data $f_{X|\Theta}$ (i.e. the likelihood ), then $f_X$ is a normalizing constant that is needed so that the posterior distribution integrates to unity (to be a valid distribution). In such case it may be more clear to write the normalizing constant in the extended form $\int\, f_{X|\Theta}(x|\theta)\,f_\Theta(\theta)\,d\theta$, so that it's role and origin is clear in the formula. $$ f_{\Theta|X}(\theta| x) = \frac{f_{X|\Theta}(x|\theta)\,f_\Theta(\theta)}{f_X(x)} = \frac{f_{X|\Theta}(x|\theta)\,f_\Theta(\theta)}{\int\, f_{X|\Theta}(x|\theta)\,f_\Theta(\theta)\,d\theta} $$
