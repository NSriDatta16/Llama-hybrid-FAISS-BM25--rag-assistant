[site]: datascience
[post_id]: 46857
[parent_id]: 46834
[tags]: 
Usually, I would test my models in both scenarios: with pre-trained word embeddings (GloVe, Word2Vec, etc.) and with my own text, giving that I have a reasonably large data set. The difference will be that the pre-trained models are more general in context. They are trained with really large data sets, thus capturing information and relationships (semantic, syntax) in a more generic way. The famous example of Mikolov's paper where linear combinations of two words such as city and Paris gives a result near to France in a high dimensional vector. In your own data set, you might capture some different relationships, as an example I could think in a situation where Paris is a character name (I am giving an extreme example for sake of clarity, hope it workds) and then it will be closer to other characters in the embeddings, etc. To conclude, I have read some papers where word embeddings from specific events (in this case was disaster management) did not work better than the general ones for topic classification. I have tried myself with the same task in a large Portuguese data set and the results were better with my own embeddings (Actually, SVM beats all Deep Learning algorithms in this case) and worked better. Maybe someone with more expertise can give a more detailed answer, but my advice is: try with both.
