[site]: stackoverflow
[post_id]: 5246736
[parent_id]: 5230601
[tags]: 
From my understanding, typically in computational photography, to evaluate the output of an algorithm like deblurring or denoising, you take a reference image, get a raw input image by adding blur (convolve with blur kernel) or add noise (Gaussian, salt-and-pepper, etc.) to degrade the image. Then, you apply the algorithm and get the recovered/enhanced image. The goal is to get the recovered as close to the reference as you can, effectively removing the degradation. Thus, I would argue that acceptable range for any measure of fidelity (such as RMSE, PSNR, etc.) is only meaningful relative to the degree of original degradation. You should likely say RMSE between enhanced and reference is 1/4 of the RMSE between raw and reference, etc. For what constitutes good performance, look up recent years of ICCV/CVPR/SIGGRAPH for the type of algorithm that you're interested in. You'll see tables to the effect of what I described in the above paragraph. Ultimately, these measures often aren't as convincing as showing the images and relying on the good old Eyeball Mk I to tell the difference.
