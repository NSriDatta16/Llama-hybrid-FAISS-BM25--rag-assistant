[site]: crossvalidated
[post_id]: 305802
[parent_id]: 305440
[tags]: 
Machine Learning algorithms learn from data and make predictions on new unseen data. As your dataset is fixed , the hardest part in supervised learning " to reduce overfitting " does not exist. No need to generalize - it's only about training a model, not testing it. Data Mining focuses more on exploratory data analysis ( unsupervised learning ), generating association rules (e.g. apriori algorithm ) and things like that. Actually I would remove that tag. Your problem definition makes it much easier than that. Given $\vec{v} = (v_1,...v_{10})$: Find rules that return the right $ID$ for a given feature vector. I would recommend Tree-based Systems (human readable and easy to train/use). The first step would be to (fully) grow a Decision Tree on your data. Each path, from root node to leaf, translates to one rule: if (v1 5 and v2 == 44 and ...): then id = 8. To take False Positives into account, use an impurity measure at each leaf node. You should only consider those rules that lead to leaves that do not have any false positives at all. E.g if you correctly classify the IDs of 200.000 instances in one leaf, you can extract that rule to optimize your workflow. About ANNs .. They are much slower (for training and classification) and useless if it is important to you what the model is doing (black box model). So unlike trees, you cannot simply analyze the ANN after it is trained and discover how (and why) it works. Btw , a decision tree algorithm is basically what you want to code yourself (mentioned in one of your comments). It searches through a hypothesis space, trying to find the simplest rules to classify instances.
