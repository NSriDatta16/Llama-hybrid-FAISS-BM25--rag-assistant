[site]: crossvalidated
[post_id]: 349683
[parent_id]: 349655
[tags]: 
Using MLPClassifier you can do exactly what you suggested, that is represent classes as integers from 0 to 27 (in the case of 28 classes). Here is an example with MLPClassifier and MNIST dataset. You can use sklearn to transform data to such format with Label Encoder . Although the above will solve your problem, I believe MLPClassifier actually transforms the numerical labels to one-hot vectors for the neural network. Using lower level neural network libraries you would have to do it yourself. This is because in multi-class classification the last layer's activation is softmax, which outputs a vector of n (number of classes) elements with continuous (0, 1) values. This makes sense as an indication of probability of observing a given class. To transform numerical labels to one-hot vectors with sklearn you can use Label Binarizer . When we expect a neural network to predict a numerical value we're really talking about a regression, not classification.
