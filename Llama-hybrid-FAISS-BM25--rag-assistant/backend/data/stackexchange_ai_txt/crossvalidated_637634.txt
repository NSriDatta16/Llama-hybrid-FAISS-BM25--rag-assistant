[site]: crossvalidated
[post_id]: 637634
[parent_id]: 
[tags]: 
Laplace approximation, MAP vs MLE and wiki's notations

I was trying to understand Laplace approximation in statistics and so I was going through the wikipedia article . I don't know much about statistics and I am already getting a bit confused by the notations. It is stated $$p(y,\theta|x)=p(y|x,\theta)p(\theta)=p(y|x)p(\theta|y,x).$$ However when using definitions, I get $$p(y,\theta|x)=\frac{p(y,\theta,x)}{p(x)}=\frac{p(y,\theta,x)}{p(x,\theta)}\cdot \frac{p(x,\theta)}{p(x)}=p(y|x,\theta)p(\theta| x)\qquad (1)$$ first I wonder why the "given $x$ " part has been omitted. Second , I saw that when we have the data $\mathcal{D}$ , bayesian inference is usually denoted $$p(\theta|\mathcal{D})=\frac{p(\mathcal{D}|\theta)}{p(\mathcal{D})}p(\theta)$$ and since the data are here $\mathcal{D}=\{(x_i,y_i)\}_{i=1}^n$ , I was wondering why instead of (1) we don't have, $$p(\theta|(x,y))=\frac{p((x,y)|\theta)}{p((x,y))}p(\theta).$$ Third , it is said Laplace's approximation provides an analytical expression for a posterior probability distribution by fitting a Gaussian distribution with a mean equal to the MAP solution and precision equal to the observed Fisher information. and in the article they proceed by computing this mean of the Gaussian by $\hat{\theta}=\underset{\theta}{argmax}\operatorname{log} p(y,\theta|x)$ . However, looking at the wikipedia for MAP , it seems to me the mean they compute is rather the MLE estimator and the MAP estimator would be $\hat{\theta}=\underset{\theta}{argmax}\operatorname{log} p(\theta|x,y)$ . I would be glad if I could get some clarifications on these matters.
