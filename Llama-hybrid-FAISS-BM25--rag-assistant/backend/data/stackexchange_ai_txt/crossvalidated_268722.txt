[site]: crossvalidated
[post_id]: 268722
[parent_id]: 
[tags]: 
Word embedding - generic corpus or specialized corpus?

When using word embedding for classifying documents from a specific corpus, is it better to use word embedding that was trained on this specific corpus, or word embedding that was trained on a wide generic corpus? Based on my intuition, and some experiments the a wide corpus appears to be better, but I'd like to know if there's relevant research, or other relevant results.
