[site]: crossvalidated
[post_id]: 8419
[parent_id]: 
[tags]: 
Bayesian classifier with multivariate normal densities

Supposing a Bayesian classifier with multivariate normal densities, how do I find the error rate of the classifier when we have two classes? I am using this: When dimension $d = 1$: $$P(x | \mu , \sigma^2) = N(x, \mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}} $$ In $d$ dimensions: $$P(x | \mu, \Sigma) = \frac{1}{(2\pi)^{d/2} |\Sigma|^{1/2}} \cdot e^{-\frac{1}{2}{(x-μ)^T\Sigma^{-1}(x-μ)}}$$ where $\mu$ is in $\mathbb{R}^d$ and $\Sigma$ is a $d \times d$ variance-covariance matrix. What would be the algebra to get the error rate, or could you give an example? I would like to do this in Matlab . Lets say I have 2 classes and 2 atributes with 20 examples: features: 1.8756 1.4236 2.0677 1.3759 0.8540 0.7782 0.5651 -0.3511 0.6103 -0.6901 -0.1945 1.6438 -0.2620 0.8022 1.5326 0.0188 0.3334 1.0578 0.8535 -1.8545 0.3066 1.9716 -1.4424 0.4216 0.3275 -0.2844 -0.0079 2.8506 0.0114 1.4001 -0.4049 -0.3981 -0.0913 2.2094 0.3376 -1.0467 0.3455 2.4960 0.3232 -0.5614 and targets 2 2 1 1 1 2 1 1 2 1 2 1 1 2 2 1 2 1 2 1 What is the process to classify them and get the error rate of this examples, so we divide the set in 15 examples for training and the other 5 for testing?
