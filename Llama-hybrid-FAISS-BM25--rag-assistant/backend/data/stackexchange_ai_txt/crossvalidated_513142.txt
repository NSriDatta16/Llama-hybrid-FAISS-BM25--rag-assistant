[site]: crossvalidated
[post_id]: 513142
[parent_id]: 
[tags]: 
Proper way to perform cross-validatation for selecting best parameters to build a calibrated model and assessing the error of the model?

I want to find the best possible: Post process to apply on my data (for example, whether or not perform PCA or scaling, to remove some features...). Some of this options have parameters to tune (like number of components). Model. Hyperparameters of the model. I want also to assess or validate how good is the model. To find those, I thought of performing a double nested Cross Validation. The problem is that I want a calibrated model, and calibration needs new unseen data to be trained on. So I am not fully sure how to implement it.
