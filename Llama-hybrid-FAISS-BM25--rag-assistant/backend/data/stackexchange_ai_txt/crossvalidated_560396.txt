[site]: crossvalidated
[post_id]: 560396
[parent_id]: 560393
[tags]: 
First to your plot: the embeddings may be being further transformed farther down the network. Further layers in the network may be transforming the values of your embedding layer in a way that is not emendable to the plotting algorithm you are using. t-SNE plots usually work pretty good, but aren't perfect. In other words, just because the plot doesn't discriminate doesn't mean the model is failing. However, you did say the classification isn't working well because of the imbalance. I want to make a slight distinction here: you actually have two problems: (a) imbalance, and (b) lack of data. Because there is a lack of data, your network doesn't have enough information to create an abstraction of the features of the class. There isn't really much to do about that; you just need more data. You can address the imbalance problem though. To do this, use cross-entropy as a loss function instead of accuracy. Cross entropy fixes the problem of imbalanced classes. You can learn more about it here . However, with your data set, you simply don't have enough data for classes 3 and 4 to reasonably train a LSTM network.
