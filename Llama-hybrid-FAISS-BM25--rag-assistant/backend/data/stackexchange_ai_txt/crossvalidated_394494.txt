[site]: crossvalidated
[post_id]: 394494
[parent_id]: 
[tags]: 
Calculating sklearn's average precision by hand

I'm trying to understand how sklearn's average_precision metric works. The reason I want to compute this by hand is to understand the details better, and to figure out why my code is telling me that the average precision of my model is the same as its roc_auc value (which doesn't make sense). The example they have is: Example >>> import numpy as np >>> from sklearn.metrics import average_precision_score >>> y_true = np.array([0, 0, 1, 1]) >>> y_scores = np.array([0.1, 0.4, 0.35, 0.8]) >>> average_precision_score(y_true, y_scores) # doctest: +ELLIPSIS 0.83... How can I compute this by hand?
