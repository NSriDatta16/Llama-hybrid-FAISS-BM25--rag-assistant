[site]: datascience
[post_id]: 11836
[parent_id]: 
[tags]: 
Find effective feature on machine learning classification task with scikit-learn

I'm tackling a binary classification task using SVM implemented in python scikit-learn. Datasize is around 10,000 and the number of feature is 34. After finding nice parameter set (using RandomizedSearchCV class), I evaluate the model by the cross validation. The result seems nice. criteria_list = ["precision", "recall", "f1", "roc_auc"] score_df = [] score_df2 = [] clf = svm.SVC(**random_search_clf.best_estimator_.get_params()) for crit in criteria_list: scores = cross_validation.cross_val_score(clf, X, y, cv=3, scoring=crit) score_df.append(["{} (±{})".format(np.round(np.mean(scores),3), np.round(np.std(scores),4)), scores]) score_df2.append(["{} (±{})".format(np.round(np.mean(scores),3), np.round(np.std(scores),4))]) pd.DataFrame(np.transpose(score_df2), columns=criteria_list, index=["SVM"]) My question is whether it is possible to find out which feature is effective to classify the test data . I thought it's relating to sensitivity analysis , but good answer cannot be shown by googling "sensitivity analysis + svm" or "sensitivity analysis + scikit learn".
