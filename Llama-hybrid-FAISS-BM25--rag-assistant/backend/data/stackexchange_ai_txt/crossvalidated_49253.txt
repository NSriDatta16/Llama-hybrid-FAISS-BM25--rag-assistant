[site]: crossvalidated
[post_id]: 49253
[parent_id]: 49246
[tags]: 
I think you might be getting a little confused about "models" and "distributions" in the context of this problem, so let's go back to basics. There are 8 possible outcomes of each trial, depending on the combination of 3 binary outcomes, so lets label them FFF, FFT, FTF, FTT, TFF, TFT, TTF, TTT, where T=1 and F=0. The most general possible model is to allow each outcome to have its own probability parameter, the only constraint here being that they have to add up to one. All possible dependencies are captured by this model. So if we choose to model this using 8 parameters $(p_{FFF}, p_{FFT}, ..., p_{TTT})$ then we need a way of estimating those parameters from your data. This is very easy to do. If you simply count up the number of each outcome you have and divide by 10,000 (the total number) then you will have a good estimate for each $p_{???}$ probability. Now, this is of course just a statistical estimate of the true probabilities. The true probalities will be different,but we can estimate how different the are likely to be. This is where the binomial (frequentist) or dirichlet (bayesian) models come in. Conditional Distributions You can apply just the same method to estimate conditional probabilities. Suppose you want $P(B,C|A=1)$ then simply select only those data points where A=1. You now have 4 possible outcomes in this distribution, and you can estimate those 4 possibilities in exactly the same manner. You should notice that the 2 sets of four condional probabilities are just the 8 probabilities from above, rescaled to add up to one across each set of 4 rather than all 8.
