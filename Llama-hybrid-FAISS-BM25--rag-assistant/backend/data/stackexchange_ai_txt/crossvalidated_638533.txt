[site]: crossvalidated
[post_id]: 638533
[parent_id]: 
[tags]: 
MLE distribution vs Bayesian posterior

Suppose that we know data is distributed according to a multivariate normal distribution $\mathbf{d} \sim \mathcal{N}(\mathbf{t}(\pmb{\theta}), \Sigma)$ , where the function $\mathbf{t} : \mathbb{R}^{N_{\textrm{param}}} \rightarrow \mathbb{R}^{N_{\textrm{data}}}$ is known, the covariance $\Sigma$ is known, but the parameters $\pmb{\theta}$ are unknown. Further suppose that we are given exactly one sample of $\mathbf{d}$ ; call it $\mathbf{d}_0$ . From this observation, suppose that we wish to place some sort of interval estimate on the value of $\pmb{\theta}$ . In a Bayesian setting, I understand that this is achieved using credible intervals . Given a prior distribution $\pi(\pmb{\theta})$ for the parameters $\pmb{\theta}$ , the posterior distribution after the observation is proportional to: \begin{equation*} \pi(\pmb{\theta})\exp\left( -\frac{1}{2} (\mathbf{d}_0 - \mathbf{t}(\pmb{\theta}))^T \Sigma^{-1} (\mathbf{d}_0 - \mathbf{t}(\pmb{\theta}))\right). \end{equation*} Sampling from this distribution (e.g. using MCMC or Nested Sampling) we can obtain credible intervals (e.g. highest density posterior intervals). In the literature of my (non-mathematical) field, however, there is a common method in use (called the 'Monte Carlo replica method') for which we observe significant disagreement from the Bayesian picture. This method proceeds as follows: Generate a sample of 'pseudodata' from the distribution $\mathbf{d}_p \sim \mathcal{N}(\mathbf{d}_0, \Sigma)$ . For each member of the 'pseudodata' sample, compute the maximum likelihood estimator: \begin{equation*} \pmb{\theta}_{\textrm{MLE}}(\mathbf{d}_p) := \textrm{argmin}_{\pmb{\theta}} \left( (\mathbf{d}_p - \mathbf{t}(\pmb{\theta}))^T \Sigma^{-1} (\mathbf{d}_p - \mathbf{t}(\pmb{\theta}))\right). \end{equation*} Treat the resulting distribution of $\pmb{\theta}_{\textrm{MLE}}(\mathbf{d}_p)$ as a 'posterior distribution', and obtain interval estimates this way. It's fairly straightforward in basic cases to show that these two procedures will not coincide, e.g. take $N_{\text{param}} = 1$ , $N_{\text{data}} = 1$ with $d \sim \mathcal{N}(t(\theta), \sigma^2)$ , and $t(\theta) = \theta^2$ . I then compute that the 'Monte Carlo posterior' obtained from the second method is: \begin{equation*} p_{\theta_{MLE}}(\theta) \propto \delta(\theta) \int\limits_{-\infty}^{0} dx\ \exp\left( -\frac{1}{2\sigma^2} (x - d_0)^2\right) + 4|\theta| \exp\left( -\frac{1}{2\sigma^2} (d_0 - t(\theta))^2\right), \end{equation*} which differs significantly from the Bayesian posterior (in particular the delta function can yield very skewed distributions!). In this case, it is also possible to show that the 'Monte Carlo replica method' disagrees with frequentist confidence intervals! Question: Is the 'Monte Carlo replica method' ever discussed in the statistics literature? Does it hold any value? It seems to me that if it disagrees with both the Bayesian and frequentist interval estimates, then it must be doing something wrong... but perhaps it can be considered an approximation to one or the other in an appropriate regime?
