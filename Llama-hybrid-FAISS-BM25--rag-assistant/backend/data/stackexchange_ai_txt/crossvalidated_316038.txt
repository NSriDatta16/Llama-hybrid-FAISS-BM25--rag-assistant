[site]: crossvalidated
[post_id]: 316038
[parent_id]: 
[tags]: 
train and test data interpretation/information

I have trained a deep learning model (with keras) which gives me this results. Accuracy I can see that regarding the training set the plot is ok except that it doesn't get steady at the last epochs.Is this a problem or not?.Is it ok to have a very small variation in the accuracy for the last epochs? I tried with larger epochs (250) but the results were awful.Smaller accuracy and a completely . How can we explain this?Why increasing epochs does not follow the previous plot and it ruins it completely? Regarding the test set, the thing that it goes up and down during all epochs, what does this mean? The same questions go for model loss. Generally, I want to know how to interpret these results.What information can I gain from these plots.I know for example, that if the training data is improving while the test data gets worse , is probably overfitting.
