[site]: crossvalidated
[post_id]: 466707
[parent_id]: 
[tags]: 
How does a probability distribution change when adding Gaussian noise?

Instance Noise is a trick for stabilising Generative Adversarial Network (GAN) training. In this paper, the authors say that (page 14, fig. 6) Instance Noise broadens the support of both distributions without biasing the optimal discriminator I understand the intuition about how noise broadens the distributions and why this is beneficial for training. What I wonder is: Is there any formal demonstration of this? What is the hypothesis behind it? What happens if we use a different type of noise (e.g., not Gaussian)? Thank you :)
