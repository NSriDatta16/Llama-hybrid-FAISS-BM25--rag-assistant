[site]: crossvalidated
[post_id]: 274404
[parent_id]: 274399
[tags]: 
It depends. Usually the point of these CNN networks is that they are robust to translations of the object-to-label, meaning that they can easily figure out if there's a bird in the top left, vs say, the bottom right. As long as the image is labelled as bird, hopefully with enough training samples with diverse backgrounds, the classifier will identify particular features that make a "bird." This is really more of a TF-IDF frequency approach: pictures with birds will tend to have things like eyes, feathers, wings, etc. These features strongly suggest bird, whereas a tree in the background provides less input. This is where the actual efficacy of the classifier is important. Here's an image taken from the following paper: Why Should I Trust You - Riberio, et. al. The point here is that for this classifier, it ended up explaining "wolf" by the fact that there is snow on the ground. This is an artifact of the training data: most likely the images labelled as "wolf" were not diverse enough in their backgrounds and had a ton of snow, whereas the non-wolf images had very little snow in the backgrounds. Going back to the TF-IDF analogy, snow becomes a very strong signal for "wolf." In general, we assume that training data has enough diversity in the background to avoid the above problems, but this can crop up still in weird ways. It's extremely expensive to figure out where in the image a "bird" is, and to zoom into it. This is partly solved by using zoomed in versions of each image, assuming that most of the time the object is near the center. It doesn't make sense to outright skip the convolution layer because then you have no actual image analysis. Also, if you train on cropped images alone, then you're not training on background noise, which will make your classifier behave poorly on uncropped images.
