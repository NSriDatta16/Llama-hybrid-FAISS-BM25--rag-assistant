[site]: crossvalidated
[post_id]: 323243
[parent_id]: 
[tags]: 
Why is the calculation of Bayes Factors for regression coefficients based on model comparison while delta-R^2 tests are discouraged?

The vast majority of the statistical inference I do is on the basis of multiple regression models (not always OLS, not always single level). Usually the focus is not on the model, but on particular predictors. For instance, my goal is not so much a perfect prediction of how much Republicans and Democrats dislike each other, but establishing whether watching cable news makes people more likely to feel that way. As I try to move towards Bayesian estimation and inference, I've run into a problem as people begin to request Bayes Factors. Just about everything I see on this topic for regression parameters is based on model comparison (Liang et al., 2008; Rouder & Morey, 2012), which in effect becomes a Bayesian version of what is sometimes called the delta-$R^2$ test or $R^2$-change test, a part of what some call hierarchical regression analysis (not to be confused with hierarchical/multilevel models). I compare a model without and with the predictor in question to calculate the Bayes Factor. I'm not digging up any references for this at the moment, but despite its wide use I have long been under the impression that comparing model $R^2$ before and after a predictor is added is bad practice in the frequentist framework. Everything becomes dependent on the order of added variables and a "control" variable may share a lot of variance with the added variable, thus leaving the model $R^2$ relatively unchanged despite the focal predictor being quite related to the DV. Why is it that this is the normal way of doing business for inference on a regression parameter using Bayes Factors but misleading/not advised in the frequentist setting? Why not calculate Bayes Factors for point null hypotheses on regression coefficients via the methods advocated for Bayesian t tests? References: Liang et al. (2008). Mixtures of g Priors for Bayesian variable selection. Journal of the American Statistical Association , 103 , 410-423. Rouder, J.N, & Morey, R.D. (2012) Default Bayes Factors for model selection in regression. Multivariate Behavioral Research , 47 .
