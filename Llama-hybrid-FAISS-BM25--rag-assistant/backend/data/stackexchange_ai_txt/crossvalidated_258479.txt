[site]: crossvalidated
[post_id]: 258479
[parent_id]: 
[tags]: 
Choice of model - GLM, GLMM, Bayesian?

I would appreciate statistical advice on this problem. I have 3 years of data taken in defined area: 200x200km. Area has been divided into 4 quadrants and each year 20 random fields in the area were sampled in each quadrant giving 80 samples total per year. The outcome is the number of diseased plants out of 30. So the response is binomial (proportion from 0 to 1, or number of plants out of 30). The important thing is that different fields were sampled every year (surveyors were not coming back to the same field). Along with the per-field incidence data I have other variables which could potentially be the predictors of disease presence - vector presence, climate, host distribution, intercrop etc. Now, I would like to analyse this data. My first approach was GLM: # Response variable (No of positives and negatives) # Create dataframe with variables from MyData that will become fixed terms: data and then GLMM with Year and Quad as crossed random terms: library(lme4) y Is any of these approaches appropriate and well scripted? What would be a better alternative? Finally - is it ok to analyse this data as it is? I might need to account for spatial correlation - can I do it in GLM or GLMM framework? Or perhaps I need to go bayesian way to account for it? How to insert some sort of X.Y term that would account for spatial correlation in my frequentist GLM and GLMM approach?
