[site]: crossvalidated
[post_id]: 582546
[parent_id]: 226281
[tags]: 
Let us assume that whoever was asking you to perform PCA on a univariate time series was really asking you "How many linearly independent subsegments does this single time series have?". We can perform PCA on this data after a simple transformation of your univariate time series. Assume your time series has length $T$ and that $T=MN$ , where $M$ is the length of each temporal subsegment of the original time series. You can perform PCA on this $M$ x $N$ matrix. For a very contrived example, say you have this time series with time on x-axis and total time length of 750: Let us now rearrange this vector of length $T$ to a 250 x 3 matrix. Notice in this very contrived case that the waveform repeats itself every 250 timesteps. We then run PCA on this 250 x 3 matrix. The plot of the variance explained vs the PCA components ranked by variance explained will be: We can plot the representation of our original data in the PC space, where we see the M-length vector corresponding to PC1 (blue) matches with the actual observed waveform that repeats, and that the plot of the M-length vector corresponding to PC2 (gold) is essentially zero as all of the variance in the original time series is explained by PC1. This is greatly simplified versus how you would do this in application. The best way to do it would be to have $M$ act as a sliding filter along the time series, where the length of $M$ and the stride are hyperparameters. You could use PCA on the eventual $MN$ matrix to reconstruct the original signal, treating the PCA scores as a basis set and comparing error between your reconstruction and the original signal. In this basic example, the stride is equal to the length of $M$
