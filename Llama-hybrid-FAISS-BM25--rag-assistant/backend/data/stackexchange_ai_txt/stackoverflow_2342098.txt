[site]: stackoverflow
[post_id]: 2342098
[parent_id]: 2341998
[tags]: 
I perceive (1) as by and large not practical because we have a hellish dependency graph within the project. Almost none of our components can be tested in isolation; we don't know all the use cases; This is your real problem. You can start by writing integration tests that essentially automate your testing process. You get value out of this right out of the gate. What you need is a safety net for refactoring that will give you a hint whenever you've broken the code. Take the widest swath of transactions you can to exercise the app, automate the process of pumping them through and comparing expected to actual. Once you have that in place, start trying to break some of that dependency graph so you can isolate pieces to test. Whenever you have a bug to fix, write a unit test for it that replicates the error. Then fix the code and re-run the test. You should see the test pass successfully. Make this your standard bug tracking and fixing procedure. That list of tests will grow like interest in a bank account. I agree with the CI recommendation. Add code coverage metrics to either Hudson or Cruise Control. It goes without saying that you're using Subversion, Git, or another source code management system, right? It's a long process, but worth it in the end.
