[site]: crossvalidated
[post_id]: 339607
[parent_id]: 
[tags]: 
K fold cross validation - final training against all data. Stopping criteria

So I have (mostly) implemented K fold cross validation, with the help of this answer: K fold cross validation; How many epochs to train for? I am at a point where I have done a grid search and calculated the average error of each hyper parameter set against k folds. Great! I know the optimal parameters for my model. I now want to train my model against the entire dataset. For the case where there is no additional holdout data, how does one know when to stop training? Is it reasonable to train for the average number of epochs that each fold was trained for (when using the optimal hyper parameters)?
