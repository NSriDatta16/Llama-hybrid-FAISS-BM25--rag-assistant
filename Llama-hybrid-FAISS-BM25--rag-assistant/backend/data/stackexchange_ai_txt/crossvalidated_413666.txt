[site]: crossvalidated
[post_id]: 413666
[parent_id]: 413648
[tags]: 
Correlation measures only linear relationships. Mutual information can measure non-linear relationships. For example, suppose $X \sim \text{Uniform}(-1, 1)$ and $Y = X^2 + \epsilon$ . The correlation between $X$ and $Y$ is zero, yet the mutual information can be high. SelectKBest ranks all features according to its score_func parameter - mutual information in your case - and, well, selects the $k$ best features. This is only useful as a preprocessing step before applying a non-linear classification algorithm such as a tree-based model or a neural network. If you are planning to use a linear model, such as logistic regression, then using SelectKBest with mutual information would be a serious error as it might include features the linear model could not use and throw away features that it could use! Even for non-linear models, considering MI for each feature in isolation is a very poor way to do variable selection. While it detects non-linear effects, it considers each variable one at at a time and does not consider interactions between features. A feature which may have little value on its own can have considerable value when intersected with another. For that reason, I don't recommend any univariate variable selection technique, including SelectKBest , except for quick-and-dirty exploratory analysis.
