[site]: crossvalidated
[post_id]: 148823
[parent_id]: 
[tags]: 
How many samples needed to determine value 4 sigma away from mean?

I have a source that generates computer files varying between 20,000 and 40,000 bytes in length. I think (strongly assume so) that they vary in length according to a Normal distribution. They average 30,000ish but haven't determined this exactly as that is contingent on this question. I want to say that only 0.001% of the files are less than X bytes long. What is X (in bytes) or how do I calculate it?
