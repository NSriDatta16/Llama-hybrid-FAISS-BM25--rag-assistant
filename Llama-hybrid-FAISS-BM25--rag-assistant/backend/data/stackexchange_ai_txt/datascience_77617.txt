[site]: datascience
[post_id]: 77617
[parent_id]: 77608
[tags]: 
This is doable, but the caveat is that a neural network might not give you a better result than a lossless compression algorithm (depending on what you want to use the compressed version for). The most sensible way to do it in my opinion is to have a function at the start that converts the coordinates into an image and a function at the end to convert the recovered image to coordinates again. The way you would train it is to gather a large number of training examples, pass them as 16*16 tensors containing 1s and 0s to your autoencoder network, then use the reconstructed image to extract the coordinates where the value is 1. There’s a good article/tutorial here to get you started. If you’re determined not to explicitly give your network a 16*16 tensor you could pass your coordinates as an ordered set of two dimensional vectors and treat the problem as a sequence transduction task . The network would need to learn an embedding for each set of coordinates and then predict each embedding based on surrounding embeddings. I expect you won’t get much joy from a transformer model as they are notoriously hard to train, but a recurrent model with attention like the ones in the article I’ve linked to might give interesting results.
