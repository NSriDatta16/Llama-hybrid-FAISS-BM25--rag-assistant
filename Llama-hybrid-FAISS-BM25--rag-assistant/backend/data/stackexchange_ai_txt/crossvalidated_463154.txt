[site]: crossvalidated
[post_id]: 463154
[parent_id]: 
[tags]: 
Issues with training on a sample of training set?

I am training an SVM on highly imbalanced data. I have rectified this issue and my ML pipeline works just fine. I have allocated 70% of my dataset for training, however this takes an infeasible amount of time to compute. I read posts about how performance doesn't necessarily grow with the amount of data and sometimes the entire dataset doesn't need to be used. So my question is, could just a sample of the training data be used to train on? And if so, what is a reasonable proportion of that data?
