[site]: datascience
[post_id]: 86550
[parent_id]: 55821
[tags]: 
I agree with Erwan. The main thing that you need to keep in mind is that training a statistical model concerns finding a set of "pseudo true parameters" (read: optimal values for relations in the model). To do this you need to define a criterion that you would like to minimize, for instance, the mean of squared errors of the model when it predicts the observations in the training sample. When using a different measure of accuracy (for instance mean absolute error), these values will be different even if the training sample grows infinitely large. We say that those are two sets of pseudo true limit parameters that minimize the limit MSE and MAE criterion respectively (there are many more options for a criterion depending on the problem). In that sense, there is no 'best model' all models fitted on a training sample are 'best' given their constraints and criterion function. Also, the train set is important. If you train a decision tree ensemble or neural network to recognize butterflies it will be useless in recognizing dogs. In the same way, if you train a time series model to predict volatility in one stock it may be useless in predicting volatility in another stock. If you have a specific task in mind though (for instance face recognition) and you don't want to spend a lot of time training a network, ashukid's suggestions seem interesting. Good luck with your future machine learning efforts!
