[site]: crossvalidated
[post_id]: 628498
[parent_id]: 628497
[tags]: 
Option 1 is better. Here's why: My favorite professor (Herman Friedman) used to say ``if you're not surprised, you haven't learned anything.'' Option 2 is a way of telling the data not to surprise you. It's the antithesis of science. But what if option 1 gives you surprising values? Then you figure out why. You learn something. Maybe it's something mundane (often, data entry errors or coding errors) and you just fix the problem. But once in a wonderful while, it isn't mundane and you discover something. The model is wrong. Or, at least, wrong in your application. Suppose you are interested in the heights of men and women. Maybe you have some theory about covariates. But you know men are taller than women, so you constrain the estimates. But what if you discovered some subgroup of people where men are not taller? That's really, really interesting. And someone else will find it, not you, and there goes your great discovery. (I don't understand your example well enough to use it, but if it is really an absolute physical constraint, then you are in the first paragraph, and finding the weird estimates lets you discover that.)
