[site]: crossvalidated
[post_id]: 419271
[parent_id]: 419269
[tags]: 
In short: there is no such thing as folded versus unfolded RNN. There is just RNN. A graphical diagram of the RNN is simply an informal description of how an RNN model works. The folded and unfolded version of the diagram are just two descriptions of the same model. The folded version is a more compact description, whereas the unfolded version makes it more clear that the hidden state takes on multiple values over time. But they are describing the same thing. However there is a very similar question which you might be asking, which is "must memory be allocated for the hidden state at each time step, or can i simply overwrite the hidden state at the last time step with the hidden state of the current time." The answer to this is: training the model via backpropagation requires access to the value of the hidden state at every time step, so all previous hidden states must be stored in memory. This is just a fact of backpropagation. On the other hand, during inference time, it's no longer necessary and the hidden state can overwrite itself, saving memory.
