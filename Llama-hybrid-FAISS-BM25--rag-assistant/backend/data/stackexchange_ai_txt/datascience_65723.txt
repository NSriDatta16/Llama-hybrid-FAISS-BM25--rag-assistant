[site]: datascience
[post_id]: 65723
[parent_id]: 65718
[tags]: 
I am just gonna copy from Oreilly's book Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition: With bagging, some instances may be sampled several times for any given predictor, while others may not be sampled at all. By default a BaggingClassifier samples m training instances with replacement (bootstrap=True), where m is the size of the training set. This means that only about 63% of the training instances are sampled on average for each predictor.6 The remaining 37% of the training instances that are not sampled are called out-of-bag (oob) instances. Note that they are not the same 37% for all predictors. Since a predictor never sees the oob instances during training, it can be evaluated on these instances, without the need for a separate validation set. You can evaluate the ensemble itself by averaging out the oob evaluations of each predictor. In Scikit-Learn, you can set oob_score=True when creating a BaggingClassifier to request an automatic oob evaluation after training. The following code demonstrates this. The resulting evaluation score is available through the oob_score_ variable: from sklearn.ensemble import BaggingClassifier from sklearn.tree import DecisionTreeClassifier >>> bag_clf = BaggingClassifier( ... DecisionTreeClassifier(), n_estimators=500, ... bootstrap=True, n_jobs=-1, oob_score=True) ... >>> bag_clf.fit(X_train, y_train) >>> bag_clf.oob_score_ 0.90133333333333332 According to this oob evaluation, this BaggingClassifier is likely to achieve about 90.1% accuracy on the test set. Letâ€™s verify this: >>> from sklearn.metrics import accuracy_score >>> y_pred = bag_clf.predict(X_test) >>> accuracy_score(y_test, y_pred) 0.91200000000000003
