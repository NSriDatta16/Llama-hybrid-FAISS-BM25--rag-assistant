[site]: crossvalidated
[post_id]: 499050
[parent_id]: 
[tags]: 
Best statistical approach for analyzing overlapping data for a particular theoretical construct?

Sorry for the vague title, but probably easiest to explain with a hypothetical data description: 20 people are given an investigational memory drug, 20 get a placebo. All are administered three tests of memory: one test of how well they can remember a list of words, one test of how well they can remember a story, one test of how well they can remember a series of pictures. Each of these three tests has scores for how well the person remembers the information immediately, after five minutes, and after 30 minutes. Data for each test is adjusted relative to population data to correct for influence of age and education level, with each test score reported as a z-score with a mean of 0.0 and a standard deviation of 1. Each participant ends up with 9 z-scores (3 scores for each of the 3 tests). No significant group differences are present on independent samples t-tests for each of the 9 scores, but there are low statistical power concerns and I want to somehow combine these scores into an overall 'memory' metric. Can I reasonably treat each score as an observation and end up with an N of 180 for each group (i.e., 9 memory scores x 20 participants in the treatment group and the non-treatment group) and do a t-test with that data (assuming the scores are highly but not perfectly correlated), or is it more appropriate to average the 9 scores for each participant? Or should I be doing something else entirely? Thanks in advance.
