[site]: crossvalidated
[post_id]: 612042
[parent_id]: 
[tags]: 
Problem from Chatfield and Xing on State-Space Model

Chapter 10, Problem 2 from The Analysis of Time Series by Chatfield and Xing: The problem says, "Consider the following special case of the linear growth model:" $$ X_t = \mu_t + n_t $$ $$ \mu_t = \mu_{t-1} + \beta_{t-1} $$ $$ \beta_t = \beta_{t-1} + w_t $$ where $n_t$ and $w_t$ are independent normal with zero means and respective variances $\sigma_n^2$ and $\sigma_w^2$ . The problem has the solver show that the initial least squares estimator of the state vector at time 2, i.e., $[\mu_2, \beta_2]^{T}$ , is $[X_2, X_2-X_1]$ , and I'm good with that. We are also to show that the covariance matrix for this vector is $$P_2 = \begin{bmatrix} \sigma_n^2 & \sigma_n^2 \\ \sigma_n^2 & 2\sigma_n^2 + \sigma_w^2 \end{bmatrix} $$ This latter is tripping me up. The answer in the book seems to suggest that the expected value of $X_2 - X_1$ is $\beta_2$ , for it computes $\mathrm{Var}[X_2-X_1]$ as $$E[(X_2 - X_1 - \beta_2)^2] = E[(n_2-n_1+\beta_2-w_2-\beta_2)^2] = 2 \sigma_n^2 + \sigma_w^2 $$ But using the given system, one could either write $X_2 - X_1 = \beta_2 - w_2 + n_2 - n_1$ or as $X_2 - X_1 = \beta_1 + n_2 - n_1$ . If I pretend that $\beta_2$ and $\beta_1$ are values that have been fixed by time 2, then the first leads to the expected value of $X_2 - X_1$ being $\beta_2$ , but the second leads to it being $\beta_1$ . Using $\beta_1$ , the same computation as above would lead to $$E[(X_2 - X_1 - \beta_2)^2] = 2\sigma_n^2 $$ It seems wrong to me to pretend the values $\beta_1$ and $\beta_2$ are fixed and non-stochastic, and getting two different values seems to confirm my impression. I guess I am confused about how any of these recursively-defined systems are started off, and the book doesn't seem to say. It only talks about estimating the initial values from the first few values of $X_t$ . I would think that the initial value of $\beta_1$ would be $w_1$ , and then I am happy with the value $$\mathrm{Var}[X_2-X_1] = \mathrm{Var}[\beta_1 + n_2 - n_1] = 2 \sigma_n^2 + \sigma_w^2 $$ given as the answer. But then I would think that $$ \mathrm{Var}[X_2] = \mathrm{Var}[\mu_1 + w_1 + n_1] $$ I don't know what to consider $\mu_1$ to be for this model, but I have trouble reconciling this thinking the the answer the book gives, that $$ \mathrm{Var}[X_2] = \sigma_n^2 $$ Any guidance here is appreciated.
