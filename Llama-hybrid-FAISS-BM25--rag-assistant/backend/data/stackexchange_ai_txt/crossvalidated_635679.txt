[site]: crossvalidated
[post_id]: 635679
[parent_id]: 635664
[tags]: 
Your independent variable appears to be a composite of three items which is supposed to represent something intangible (e.g. anxiety, socioeconomic status) and four DVs which may also represent some intangible. Specifically, the items are manifest variables because they are directly observable and the intangibles or the constructs you are trying to capture are latent variables because they are indirectly observed variables via the manifest variables. I feel the most obvious solution to your problem is some kind of structural equation model (SEM), where the IV latent variable is regressed on the DV latent variable. Here is an overly simplified simulation of your data (some of what I write here is a bit lazy but still demonstrates what I am trying to convey). I simulate the data in R and fit the model with the lavaan package, which is a common package for SEM. #### Simulated Latents #### set.seed(123) n The plot below shows the constructed model (unlabeled): The circles represent the latent variables (IV and DV) and the squares are the items that represent them, or the manifest variables. The lines drawn between the circles and squares are regression paths which estimate how much each item "loads" onto the latent variable, or essentially how close it relates to the latent variable. The semi-circle arrow paths are the variances for each. That information isn't easy to see, so I change the code here. The standardized loadings are shown below, where each number on the arrows represents how much each item "loads" onto the latent variable. You can see that the arrow between the IV and DV represents the regression path, which shows that the relationship between the two is $\beta = .51$ , which is very close to what we specified in our simulated data: #### Plot #### semPlot::semPaths( fit, "std", layout = "spring", label.cex=1, edge.label.cex = 1.5 ) The full model summary can be run with summary(fit, fit.measures = T) , which I do not go into detail here, but examining them is a necessary part of fitting these models: lavaan 0.6.16 ended normally after 29 iterations Estimator ML Optimization method NLMINB Number of model parameters 15 Number of observations 1000 Model Test User Model: Test statistic 23.797 Degrees of freedom 13 P-value (Chi-square) 0.033 Model Test Baseline Model: Test statistic 2476.670 Degrees of freedom 21 P-value 0.000 User Model versus Baseline Model: Comparative Fit Index (CFI) 0.996 Tucker-Lewis Index (TLI) 0.993 Loglikelihood and Information Criteria: Loglikelihood user model (H0) -11432.560 Loglikelihood unrestricted model (H1) -11420.661 Akaike (AIC) 22895.119 Bayesian (BIC) 22968.736 Sample-size adjusted Bayesian (SABIC) 22921.095 Root Mean Square Error of Approximation: RMSEA 0.029 90 Percent confidence interval - lower 0.008 90 Percent confidence interval - upper 0.047 P-value H_0: RMSEA = 0.080 0.000 Standardized Root Mean Square Residual: SRMR 0.020 Parameter Estimates: Standard errors Standard Information Expected Information saturated (h1) model Structured Latent Variables: Estimate Std.Err z-value P(>|z|) IV =~ IV1 1.000 IV2 1.014 0.059 17.161 0.000 IV3 1.031 0.060 17.130 0.000 DV =~ DV1 1.000 DV2 1.097 0.049 22.448 0.000 DV3 1.055 0.049 21.604 0.000 DV4 1.093 0.050 21.909 0.000 Regressions: Estimate Std.Err z-value P(>|z|) DV ~ IV 0.565 0.048 11.664 0.000 Variances: Estimate Std.Err z-value P(>|z|) .IV1 0.929 0.062 14.940 0.000 .IV2 0.961 0.064 14.978 0.000 .IV3 1.014 0.067 15.143 0.000 .DV1 1.007 0.058 17.476 0.000 .DV2 0.913 0.058 15.833 0.000 .DV3 1.051 0.061 17.143 0.000 .DV4 1.048 0.063 16.729 0.000 IV 0.972 0.087 11.115 0.000 .DV 0.886 0.075 11.787 0.000 This is just scratching the surface but gives you at least a conceptual introduction to what you can do for your case. To learn more, a good starting place is either Kline's book for conceptual knowledge or Beaujean's book for programming it in R.
