[site]: crossvalidated
[post_id]: 277348
[parent_id]: 276691
[tags]: 
A general version of your problem is indeed a classification problem. Let us suppose you stop at the 3 similarity measures, and for each entry/line you have the correct class (valid or invalid). In this case you have a standard classification problem where the 3 measures are your input and the valid/invalid class is the output. You can use any classification algorithm to learn how to classify your unlabeled data. You have to read some tutorial on how to select the best algorithm (among the tens to hundreds available) to your particular data (in short using cross validation to split your labeled data into train and test and measure in the test set the accuracy of your predictions). But you seem to require that the algorithm should be a linear classifier - you seems to want to classify the data only based on the pertinence score formula, which is a linear classifier on the attributes (the three similarity measures). There are basically three different linear classifiers - logistic regression (as @user43849 suggested), linear discriminant analysis and Linear SVM. If your data is linearly separable, that is indeed all valid cases have some high PS and all invalid cases low PS, than the three algorithms are essentially equivalent (linearly separable problems are easy and all algorithms will find one of the possible solutions to the problem) If your problem is not linearly separable then the three algorithms will result in different solutions (w1, w2, w3). Which one is the best? One solution is to use the same cross validation mentioned above and test which one is the best. I would suggest this alternative. A second alternative is to try to understand how each algorithm models the problem of separating 2 classes of data - and see which one agrees better with your requirement that "the PS should be as high as possible for the valid cases and as low as possible for the invalid cases". If this statement is a correct description of your requirements, than I think linear SVM are the closest (it will try to find the PS definition that will separate the most the valid and invalid PS). But if the statement is only your way of saying that you want the PS to be a good separator of valid and invalid cases, then I think testing the three algorithms is the way to go. Since you mentioned R, here are the links for the 3 algorithms implemented in R logistic regression https://www.r-bloggers.com/how-to-perform-a-logistic-regression-in-r/ linear discriminant analysis https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/lda.html linear SVM https://datascienceplus.com/understanding-linear-svm-with-r/
