[site]: crossvalidated
[post_id]: 287500
[parent_id]: 
[tags]: 
Framing a statistical test for an allocator

This is a real world scenario. We have some machines and these machines need some components. Someone came up with a method to select really good components for machines. The idea is that machines that use these "good" components have a lower number of failures. Now to measure the performance of this allocator, we flip a coin and only if we get heads do we use its recommendation. Otherwise, we do whatever we were doing before. So, we now have some machines in the treatment and control groups. We observe the machines in the real world and collect data on their failures for the two groups. Most of the time, the machines don't fail in both groups. Also, the allocator might be reducing not only the number of failures but also the time the machine is down per failure. Now, we want to see if the allocator makes a statistically significant difference. If we compare the average downtimes using a two sample t-test, the variances are very high. This is because most machines don't fail and have zero downtime. So, we never see a significant difference. My question is - are there alternate ways to frame the hypothesis test that might be "better" than the one proposed above?
