[site]: datascience
[post_id]: 6125
[parent_id]: 6116
[tags]: 
Gather competitive counterparts. Try and determine a state-of-the-art and see how your models compare with that. It also heavily depends on how long your team has been working on it. Science-driven models are not created statically, they develop dynamically because a good scientist will always try to find ways to improve it. Upper management personnel should know that a data scientist explores new methods, sometimes/often without knowing their quality. They should know that machine learning techniques do not produce perfect models right away. If they did, it wouldn't be challenging anyway. A data scientist ought to be evaluated by how he justifies and discusses his results and how he plans the future. A way for the management personnel to handle with their expectations is to not have unrealistically high ones. Still, if reasonable results are expected in the field of context, think about these questions: Did/will results get better over time? Are future expectations positive? How well are results compared to similar systems (from competitors)?
