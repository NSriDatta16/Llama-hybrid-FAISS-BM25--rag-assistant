[site]: crossvalidated
[post_id]: 371612
[parent_id]: 370033
[tags]: 
Your understanding is correct, the core notion of the paper is that sampling-splitting is essential for empirical work and that it allows us to have an unbiased estimate of the treatment effect. To tackle your main question: The criteria of choice are $\hat{EMSE}_\tau$ and $\hat{EMSE}_\mu$ . Both penalise variance and well as encourage heterogeneity. For starters, I will focus on the estimated expected MSE of the treatment effect $\hat{EMSE}_\tau$ . For a given tree/partition $\Pi$ when using a training sample $\mathcal{S}^{tr}$ and an estimation sample of size $N^{est}$ , the estimator for the otherwise "infeasible criterion" $-\hat{EMSE}_\tau ( \mathcal{S}^{tr},N^{est},\Pi)$ is by definition the variance of the estimated treatment effect across leaves (the term denoted as: $\frac{1}{N^{tr}} \Sigma_{i \in \mathcal{S}^{tr}} \hat{\tau}^2 (X_i; \mathcal{S}^{tr}, \Pi)$ ) minus the uncertainty about these treatments effects (the variance estimators terms $S^2_{S^{tr}_{treat}}$ and $S^2_{S^{tr}_{control}}$ that are also inversely proportional to the sample sizes $N^{tr}$ and $N^{est}$ ). Therefore the goodness of fit is not a "vanilla" MSE but rather a variance-penalised one. The stronger the heterogeneity in our estimate the better our $EMSE_\tau$ and similarly the higher the variance of our estimates the worse our $EMSE_\tau$ . Note also that the estimated average causal effect $\hat{\tau}(x; \mathcal{S}, \Pi)$ is equal to $\hat{\mu}(1,x; \mathcal{S}, \Pi ) - \hat{\mu}(0,x; \mathcal{S}, \Pi )$ i.e. we will reward the heterogeneity indirectly during the estimation of $\hat{\mu}$ too. More generally, the basic idea with sample-splitting is that we are getting our estimates for a tree by using a separate sample from the sample that was used to construct the tree (i.e. a partition of the existing sample space $\mathcal{S}$ ) and thus we can focus mostly on the variance rather than on the bias-variance trade-off. This is the gist of the section Honest Splitting where we can see that the criteria of choice will penalise small leaf size exactly because they will be associated with high variance $S^2$ of the estimated effects. In conclusion, the task of making a RF consistent is attacked from two sides: The sample is split to training and evaluation sets. The criterion for splitting is such that tree leafs are "big". As mentioned through the paper, this will induce a hit in terms of MSE of the treatment effects but that will come to the increase of the nominal coverage for their confidence interval. I think Prof. Athey's quote from her 2016 presentation on Solving Heterogeneous Estimating Equations Using Forest Based Algorithms (21:25 to 22:02) captures the essense of this work nicely : " ... people have said, if you're going to do hypothesis testing on treatment effects within leaves, shouldn't your objective function somehow anticipate you wanted to construct a confidence interval. (...) So we basically, instead of doing nearest neighbors like this " (using an adaptive $k$ -NN estimator), " we're going to have tree based neighborhoods that basically slice up the covariate space according to where we see heterogeneity in the tree building sample. And then in the estimation sample, we'll come back and estimate treatment effects in that partition. "
