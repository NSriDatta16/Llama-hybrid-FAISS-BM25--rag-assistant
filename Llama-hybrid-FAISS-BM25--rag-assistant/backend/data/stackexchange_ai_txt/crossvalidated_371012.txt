[site]: crossvalidated
[post_id]: 371012
[parent_id]: 
[tags]: 
Why the discrepancy between predict.xgb.Booster & xgboostexplainer prediction contributions?

One way to explain individual predictions of an xgb classifier is to calculate contributions of each feature. To my knowledge there are two packages in R that can do this for you automatically. In the xgboost package you can call the predict.xgb.Booster function at set predcontrib to TRUE . In the xgboostExplainer package you can call the buildExplainer and explainPredictions functions. Both methods result in a n-by-m dataframe where n = the number of observations and m = the number of features. However, in my hands the two methods give different values for the contributions of each prediction. These differences exceed floating point error, so it suggests different calculations are being performed. Interestingly, the difference in the final prediction values (sum of prediction contributions) is within floating point error. Two specific questions: Is there a preferred method within the stats community for calculating the contribution of each feature in an xgb classifier? Why the discrepancy between the feature contributions between the two methods? Reproducible example follows: library(xgboost) library(xgboostExplainer) ## binary classification: data(agaricus.train, package='xgboost') data(agaricus.test, package='xgboost') train $data, label = train$ label, max_depth = 2, eta = 0.5, nthread = 2, nrounds = 5, objective = "binary:logistic") pred $data) pred_contr data, predcontrib = TRUE) contr1 $data, label = train$ label) xgb.test.data $data, label = test$ label) explainer = buildExplainer(bst, xgb.train.data, type="binary", base_score = 0.5, trees = NULL) pred.breakdown = explainPredictions(bst, explainer, xgb.test.data) #discrepancy between prediction contributions breakdown1
