[site]: crossvalidated
[post_id]: 213675
[parent_id]: 
[tags]: 
How freqently are the information conditons for proper Akaike information criterion application actually met?

Question: what is assumed for AIC, when is this correct, and how do we know it is ever correct? How do we verify the assumptions? Akaike information criterion (AIC) is limited to goodness-of-fit for assumed distributions. That is, one can assume a maximum likelihood function but almost all of the time AIC is used for an assumed normal distribution of residuals. It is unclear to me how heteroscedastic residuals from nested models of a larger model with uncertain parameters relate to likelihood functions. It is further unclear how nested model solutions for larger problems with some uncertain parameters that can nevertheless be solved for example using Tikhonov regularization , relate to the likelihood of anything, when this is done adaptively to stabilize an ill-posed integral Tk-GV . Theil regression, Deming regression and myriad other regression techniques are superior to ordinary least squares for finding the relations between co-varying functions, and for which goodness-of-fit is largely irrelevant, counterproductive, or mutated enough to be out of context. My question then is, "What are the exact information criteria that would permit AIC to be used properly, and how reasonable is it to assume that that is physically relevant for inverse problem solutions with any appreciable frequency?" Simple example: Suppose that I own shares in a company. Does goodness of fit or a likelihood analysis tell me what those shares will be worth tomorrow? Doubtful, isn't it? Suppose I persist and try to make a prediction, do I not have to match the derivatives of the trending data as well as the data itself? In fact, I do not then care if the model is parsimonious today, I only care about parsimony for tomorrow. Does AIC apply to selecting a model for tomorrow's share price? Would not extrapolation testing be a better approach to model selection, as in "see what works"? In order to see what works, AIC would not tell us about how errors are organized in the same sense as examining a residual plot. One can test extrapolation by withholding data, and the AIC from the fit region does not contain the withheld information, thus is not useful for testing prediction. Ordinary least squares (OLS) is not useful extrapolation either as the residuals are systematically biased , making Theil median regression more useful for extrapolation than OLS, and Wilcoxon signed rank sum testing more useful to measure the accuracy of extrapolation, where no accuracy information is available from AIC.
