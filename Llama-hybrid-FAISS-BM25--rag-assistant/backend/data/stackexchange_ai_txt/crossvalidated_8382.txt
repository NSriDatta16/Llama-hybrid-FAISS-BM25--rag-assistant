[site]: crossvalidated
[post_id]: 8382
[parent_id]: 
[tags]: 
How to average quantized and truncated data?

So I have data that has been quantized by an analogue to digital converter. (continuous data has been turned into discrete data and the values range from 0 to the saturation value , which is 127 in this case). This particular instrument I used to gather the data is quite noisy, let's say there is added Gaussian noise to the real value. Luckily, when taking single measurements, I have enough time to take multiple measurements and average them to reduce the noise. Note that sampling rate is not an issue here since the thing that I'm taking measurements of is completely stable. Obviously , taking the simple mean will produce a biased result because values cannot exceed 0 or 127 (for example, if you attempt to use a plain old averaging on something with a "real" value of 126, you will get an estimated value that is less than 126. This is because the added Gaussian noise will not give you any value higher than 127 because of the truncation). So how do I take the average so the result will give me an unbiased estimator of the real value?
