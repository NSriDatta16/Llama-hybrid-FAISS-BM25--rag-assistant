[site]: crossvalidated
[post_id]: 282790
[parent_id]: 282783
[tags]: 
I think you are confusing some concepts, here's my explanation on this kind of hypothesis testing. I would guess that the claim ``average sleep for a high school student is 7 hours'' would probably involve some sampling, but also knowledge from medicine, etc. Also it seems impossible to do this for all students in the world. How would you go about on getting the (population, true) standard deviation? The standard error is a standard deviation of a statistic (like standard deviations of the mean). In the sample from a rural school they have obtained 110 sleeping times, where the average is 7.42 and the (sample) standard deviation (often noted as $s$) is 1.75. You can use this to estimate the (population) standard deviation ($\sigma$), because $s^2$ is unbiased for $\sigma^2$. In other words, if you would gather all the sleeping hours from all the high school students around the word, then the variance would be about $1.75^2$. If $X$ would be the random variable 'sleeping time of a high school student' then $Var(X) \approx 1.75^2$. The variable $X$ could have a very weird distribution (skewed or so), but that is not really of our interest. We are interested in 'how exceptional is 7.42 from the assumed population mean of 7?'. This implies that we are interested in the distribution of the sample mean $\overline X$ under $H_0$. We are not looking for an estimate of the distribution of $H_0$ . This doesn't realy make sense. It is however well know from the central limit theorem that the sample mean $\overline X$ has an asymptotic normal distribution with mean $\mu = 7$ and variance $\sigma^2/n$ (the square of the standard error ). In other words the standard error is the standard deviation of the sample mean $\overline X$. Here the $\sigma^2$ is estimated by $s^2 = 1.75^2$, but because of this extra estimation $\overline X$ has an $t$ distribution with $108$ degrees of freedom. (Which would be a nearly normal distribution because the sample size is very high). A $z$-test would be appropriate. Update: An estimator is unbiased if its expected value is the true value it is estimating. Or in symbols: $$ E(\hat \mu) = \mu $$ This is a good thing, but it can be interpreted as 'when you have many samples, then on average estimator $\hat \mu$ will have the same value as $\mu$'. The default example is that the sample average $\overline X = \hat \mu$ is an unbiased estimator of the true sample mean $\mu$. If you would have many samples, then on average the sample mean will be the true value of the population mean. The same is valid for the sample variance. It can be shown that $$ s^2 = \dfrac{1}{n-1} \sum_i (x_i - \overline x)^2 $$ is an unbiased estimator of $\sigma^2 = Var(X)$.
