[site]: crossvalidated
[post_id]: 388793
[parent_id]: 388502
[tags]: 
You have three years of daily data, which is a good amount. As you write, you may have multiple-seasonalities (intra-weekly and intra-yearly), so it is a good idea to look at models that can model such patterns, like bats or tbats . Let's start by looking at your series (I'm using R, and I created a data.frame similar to your hbf ): with(hbf,plot(TheDate,TheValue,type="o",pch=19)) No patterns are readily apparent. Let us use appropriate seasonplots to examine any seasonalities. We will start with the intra-weekly seasonality: library(forecast) seasonplot(ts(hbf$TheValue,frequency=7),pch=19) I do not see a seasonal pattern here. Let's look at an STL decomposition: plot(stl(ts(hbf$TheValue,frequency=7),s.window="periodic")) Again, there is no visible seasonality here. (Yes, there is a seasonal component in the STL plot, but note the scales given by the gray boxes. The seasonal component is completely negligible. See here for more information. ) For good measure, here are beanplots of your series by weekday: library(beanplot) with(hbf,beanplot(TheValue~TheDateFactor,what=c(0,1,0,0),col="lightgray",border=NA)) with(hbf,points(as.numeric(TheDateFactor)+runif(nrow(hbf),-.3,.3),TheValue,pch=19,cex=0.6)) Again, there is no weekly pattern. We can repeat the exercise with the yearly seasonality, though only the seasonplots and the STL plots make sense: seasonplot(ts(hbf $TheValue,frequency=365),pch=19) plot(stl(ts(hbf$ TheValue,frequency=365),s.window="periodic")) Just as for weekly seasonality, no pattern is apparent. While we are plotting, let's also look at ACF and PACF plots: acf(hbf $TheValue) pacf(hbf$ TheValue) Yes, a few of the (partial) autocorrelations exceed the significance limits. However, they do so only very slightly, and in a series of more than 1,000 observations, such small exceedances do not really indicate anything relevant. Also, note that there are no obvious periodicities of period 7 in the (P)ACF plots, which we would expect if there were any kind of weekly seasonality. Bottom line: your data are pretty much not seasonal. Why do methods like tbats() give you a flat line forecast? Time series (like any other data with a random component) consist of signal and noise . Classical signals are trend, seasonality, autoregression and moving average effects, or the effects of causal drivers (which I assume you do not have). Signal, by definition, is patterns that are forecastable. Everything else is not signal, it is noise. You can call noise "randomness". Forecasting algorithms try to separate the signal and the noise. They forecast the forecastable part, the signal. It does not make sense to forecast the unforecastable part - it will always make the forecast worse. There is no seasonal signal in your data, nor is there trend. There is some very little ARMA signal, per the (P)ACF plots. Fitting an ARIMA model picks up on this: plot(forecast(auto.arima(hbf_ts2),h=100)) Note that the forecast wiggles a tiny little bit at the beginning, but is again essentially a flat line. This is because the ARMA signal is very weak. Given the pretty much complete lack of signal in your data, I am very sure that such a forecast will be near-optimal. Flat forecasts can beat more "wiggly" ones surprisingly often. I suggest you try a holdout forecast comparison: hold out the last (say) three months of data, fit a PowerBI model, a TBATS one and an ARIMA one to the remaining data, forecast out into the holdout sample, and compare the Mean Squared Error. I'll bet you a beverage of your choice that PowerBI will not be optimal. (I'll be at a couple of forecasting conferences later this year where you can claim your prize.) Final question: why does PowerBI give you a very wiggly forecast? I'll be cynical here. I believe that PowerBI does not attempt to give you a good forecast. It wants to give you a forecast that looks sophisticated, so you will believe that PowerBI is sophisticated. Complexity for its own sake will usually make forecasts worse. I very much recommend the special issue of simple vs. complex methods in forecasting in the Journal of Business Research (vol. 68, no. 8, 2015) . I do believe that complex methods have their place, but only if there are clear drivers for your series, and there are none such here. In the end, I'd trust the people behind the forecast package for R much more than the people behind PowerBI. Rob Hyndman , who maintains the package, is probably the world's foremost expert in forecasting. He just stepped down from a decade-long tenure as the editor in chief of the International Journal of Forecasting . He knows what he is doing, and the forecast package is the state of the art, proven over many years. In contrast, after 13 years in forecasting, I have never seen PowerBI in this field. And the screenshot you show does not impress me. It truly looks like snake oil.
