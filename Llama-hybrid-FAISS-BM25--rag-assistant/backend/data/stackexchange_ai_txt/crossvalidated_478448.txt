[site]: crossvalidated
[post_id]: 478448
[parent_id]: 476214
[tags]: 
I can hazard an answer here, but I think you're right to be confused. To recap what you've said, the difference is in the criteria to evaluate predictions about the test set. PCA uses RMSE, which simply evaluates how close the reconstructed data $\hat X$ is to the original data $X$ when encoded using $L$ components. PPCA uses (negative) log-likelihood of the original data, given the reconstruction and the estimated noise ( $\sigma$ ), $-log[ P(X | \hat X, \sigma)]$ . As discussed in Section 5.3.1 of your textbook, the likelihood penalises the model both for errors in the value of $\hat X$ , and for how widely it spreads the probability mass --- that is, for high values of $\sigma$ , which can account for many values of $X$ but aren't very specific about which to actually expect. I strongly suspect the decrease in log-likelihood with $L > 100$ is due to changes in the estimate of $\sigma$ , either causing it to be underestimated (model is overconfident in the reconstructed values) or overestimated (under-confident). I can't say whether it's systematically guaranteed to be one or the other, but you could easily check on a case-by-case basis.
