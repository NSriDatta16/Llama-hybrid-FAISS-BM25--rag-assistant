[site]: crossvalidated
[post_id]: 481113
[parent_id]: 481093
[tags]: 
TL;DR: If your goal is to determine which app is more intuitive, a question asking for a direct comparison is sufficient. You can fit a Bernoulli distribution to your data via maximum likelihood for a frequentist confidence interval around the proportion of users who find an app as or more intuitive than another (a Bayesian alternative is provided below). The long version: If your goal is simply to determine which app is more intuitive, asking for a direct comparison, such as the following question, would be sufficient: Which application did you find more intuitive to use? Application A was more intuitive. Application B was more intuitive. Application A and B were equally intuitive. This question asks for a direct comparison so you can infer if users find A is more intuitive than B; however it doesn't tell you the magnitude of the difference, nor does it tell you whether or not either are intuitive in the first place (e.g., A and B can be equally intuitive in that they are both not intuitive). I am not aware of any methods to meaningfully measure the magnitude of intuitiveness (though some may exist in the psychological literature), but if you need to know if users think the apps are intuitive PERIOD you might consider prefacing the direct comparison with a pair of yes/no or Likert scale questions. For example, to ask about application A: Did you find application A intuitive to use? Yes No Or Please rate your agreement with the statement "I found application A intuitive to use" Strongly Agree Agree Neither Agree nor Disagree Disagree Strongly Disagree The second question appears like it may provide a sense of which application is more or less intuitive and by how much; however a challenge to address is whether or not you believe your survey respondents will be able to consistently measure the "intuitiveness" of the two applications. In other words, will their evaluation of the intuitiveness of application A be based on the same criteria as application B. This is true both between questions and across survey respondents (i.e. a respondent needs to be self-consistent, and all respondents should mean roughly the same thing by their stated response). If you are not confident that responses to the two questions will be commensurable, then a question asking for a direct comparison is likely safer (in the sense of producing a meaningful result). Edit: With regards to a statistical test for the direct comparison, fitting a Bernoulli distribution to your data (assuming responses are IID) via maximum likelihood can give you a confidence interval on the probability (or proportion) of respondents who will find app A (or B) equally or more intuitive. To facilitate all three responses (A is more intuitive than B, B is more intuitive A, A and B are equally intuitive) you could use a categorical distribution. The problem you have framed can easily adopt a Bayesian approach by using a beta distribution as a prior for the Bernoulli distribution where the alpha parameter is equal to the count of responses for "A is more intuitive than B" and the beta parameter is equal to sum of the count of the response for "B is more intuitive than A" and "A and B are equally intuitive". Obviously you can swap A and B depending on which app you need to determine is at least or more intuitive. You can extend the Bayesian approach to all three responses via a Dirichlet distribution.
