[site]: crossvalidated
[post_id]: 381325
[parent_id]: 
[tags]: 
Bernardo (1979) paper, section 3.2

In section 3.2 of his paper, " Reference Posterior distribution for Bayesian Inference " (on 10 Dec, 2018) he writes $$H(p^*(\theta/z))=-\int p^*(\theta/\hat{\theta})log( p^*(\theta/\hat{\theta}))d\theta,$$ $$=-log(p^*(\hat{\theta}|\hat{\theta}))+o(1),$$ $$=K(\hat{\theta})+o(1),$$ where $H(.)$ denotes the Shannon's entropy, $p^*$ denotes the asymptotic distribution, $z$ denotes the set of data. Here, he assumed that the asymptotic posterior distribution depends upon data only through maximum likelihhod estimate $\hat{\theta}$ . Further, he writes that since for large number of samples the likelihood $p(z|\theta)$ will also concentrate around its maximum $\hat{\theta}$ , we have $$\int p(z|\theta)K(\hat{\theta})dz=K(\theta)+o(1).$$ This last equation is what I do not understand. Since $K(\hat{\theta})$ is just a constant in case, I think that the right side should be equal to $K(\hat{\theta})$ instead of $K(\theta)$ . Please tell me what is wrong with my thinking in this case?
