[site]: stackoverflow
[post_id]: 3947666
[parent_id]: 3947654
[tags]: 
Here are some tries: L4 = [ n for n in L1 if (n not in L2) and (n not in L3) ] # parens for clarity tmpset = set( L2 + L3 ) L4 = [ n for n in L1 if n not in tmpset ] Now that I have had a moment to think, I realize that the L2 + L3 thing creates a temporary list that immediately gets thrown away. So an even better way is: tmpset = set(L2) tmpset.update(L3) L4 = [ n for n in L1 if n not in tmpset ] Update: I see some extravagant claims being thrown around about performance, and I want to assert that my solution was already as fast as possible. Creating intermediate results, whether they be intermediate lists or intermediate iterators that then have to be called into repeatedly, will be slower, always, than simply giving L2 and L3 for the set to iterate over directly like I have done here. $ python -m timeit \ -s 'L1=range(300);L2=range(30,70,2);L3=range(120,220,2)' \ 'ts = set(L2); ts.update(L3); L4 = [ n for n in L1 if n not in ts ]' 10000 loops, best of 3: 39.7 usec per loop All other alternatives (that I can think of) will necessarily be slower than this. Doing the loops ourselves, for example, rather than letting the set() constructor do them, adds expense: $ python -m timeit \ -s 'L1=range(300);L2=range(30,70,2);L3=range(120,220,2)' \ 'unwanted = frozenset(item for lst in (L2, L3) for item in lst); L4 = [ n for n in L1 if n not in unwanted ]' 10000 loops, best of 3: 46.4 usec per loop Using iterators, will all of the state-saving and callbacks they involve, will obviously be even more expensive: $ python -m timeit \ -s 'L1=range(300);L2=range(30,70,2);L3=range(120,220,2);from itertools import ifilterfalse, chain' \ 'L4 = list(ifilterfalse(frozenset(chain(L2, L3)).__contains__, L1))' 10000 loops, best of 3: 47.1 usec per loop So I believe that the answer I gave last night is still far and away (for values of "far and away" greater than around 5Âµsec, obviously) the best, unless the questioner will have duplicates in L1 and wants them removed once each for every time the duplicate appears in one of the other lists.
