[site]: crossvalidated
[post_id]: 529644
[parent_id]: 529632
[tags]: 
Comment: You don't explain your experiment or its goals, and the labels in your data table are cryptic. However, it looks as if you may have a $2\times 3$ contingency table TBL of counts, with $142\,124$ subjects altogether. TBL = rbind(c(1892,4009,2995),c(25383,63372,44473)); TBL [,1] [,2] [,3] [1,] 1892 4009 2995 [2,] 25383 63372 44473 sum(TBL) [1] 142124 If this accurately describes your data, then a chi-squared test rejects the null hypothesis that row and column categories are independent, with P-value near $0.$ chisq.test(TBL, cor=F) Pearson's Chi-squared test data: TBL X-squared = 32.542, df = 2, p-value = 8.583e-08 Pearson residuals in the first two cells of the first row show large absolute values, indicating that the largest discrepancies, between the observed counts in TBL and the six expected counts (computed on the assumption that the null hypothesis is true), are in these two cells of the table. The sum of squares of these six residuals is the test statistic $32.542.$ chisq.test(TBL, cor=F)$res [,1] [,2] [,3] [1,] 4.471824 -3.211960 0.4370811 [2,] -1.155538 0.829984 -0.1129436 Note: If this is not a correct interpretation, please edit your Question for clarity. [As you question stands, I see no role for a t test.] Addendum: Here is basically the same chi-squared test as above but organized to focus on three proportions (which are apparently not all the same). Inv=c(1892,4009,2995) View = c(25383,63372,44473) Tot = Inv + View 3-sample test for equality of proportions without continuity correction data: Inv out of Tot X-squared = 32.542, df = 2, p-value = 8.583e-08 alternative hypothesis: two.sided sample estimates: prop 1 prop 2 prop 3 0.06936755 0.05949748 0.06309514
