[site]: crossvalidated
[post_id]: 487086
[parent_id]: 486808
[tags]: 
I would disagree slightly with the opening statement of Sycorax's excellent and detailed answer "There's no such thing as universal statistical or machine learning assumptions" - in supervised machine learning, in general , it is assumed that your data is drawn IID from a probability distribution, and that any test/new data presented to the model after training will be sampled from the same distribution. This applies to the term "generalization" too - how well your model generalizes refers to how well it generalizes to new data sampled from the same underlying distribution as the training data . The first issue here is that, when deployed in the "real world," new data is usually not generated from the same distribution as the original training and test data (not to mention not being sampled IID). So model performance naturally deteriorates. Additionally, the higher-dimensional and more complex your data, the less likely it is you have a dataset that adequately represents the underlying distribution, partly because of the complexity of the distribution and partly because of sampling difficulties (have a look at the "tench" class in ImageNet to see pretty obvious example of severe sampling bias that will lead to poor performance as soon as you move outside the ImageNet validation set for images of real-life tenches...). I assume that this might be what the conversations you're talking about refer to - does this make sense..?
