[site]: datascience
[post_id]: 100478
[parent_id]: 
[tags]: 
Why is $2^n$ so important in deep learning?

While initializing and training a deep learning model we often use some quantities such as number of hidden neurons in dense neural networks, number of filter in CNNs, batch_size while training a neural network, number of units in LSTM cell, etc. are in the powers of 2 i.e. $2^n$ . Is there any specific reason to do the same?
