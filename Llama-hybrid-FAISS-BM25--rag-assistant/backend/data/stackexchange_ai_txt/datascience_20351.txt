[site]: datascience
[post_id]: 20351
[parent_id]: 20327
[tags]: 
1 and 2. You are in the right direction, you need to extract the features using a CNN, then instead of predicting the class you want to reshape the last layer of features and feed it directly into the RNN. A couple of things to pay attention to: With a rather shallow CNN you aren't taking advantage of the higher-level feature extraction these architectures can offer. If all your images are as simple as the example you've shown it is adequate. If you are considering a larger CNN, along with the RNN there is a substantial number of parameters to be trained. For this you need lots of data and lots of computational resources (either very strong GPUs or time). In order for you to get the best of the two, I would suggest incorporating a pre-trained CNN into your model (and just fine tune the latter layers). This pre-trained model can even be trained in generic images (i.e. ImageNet) and will substantially increase the performance of the CNN without computational cost. You then can train the latter layers of this CNN jointly with the RNN. 3. This is a good example of what you are trying to do. They basically try to recognize text from street photographs among other things with the same methodology you describe. Similar methodologies can be found in other research domains such as multi-label image classification , sequence labelling , facial expression recognition , etc
