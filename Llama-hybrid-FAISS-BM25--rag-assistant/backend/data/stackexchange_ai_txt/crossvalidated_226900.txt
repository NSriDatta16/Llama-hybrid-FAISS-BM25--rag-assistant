[site]: crossvalidated
[post_id]: 226900
[parent_id]: 226894
[tags]: 
With only having few samples in the training set it is easier for the model to find a fit/representation of the data with few error - so the resulting training error will usually be lower than with using more samples. In this state, the training samples under-represent the complexity of the real data, hence the resulting fit will usually not generalize well. In contrast, if you increase the amount of samples, finding a correct fit/representation of the training samples will usually become harder, thereby increasing the training error. But this also leads to a better generalization, as the representation becomes more realistic (thereby reducing the test error). If you try different training set sizes and compare the corresponding training and test error, you will usually end up with a curve similar to this one: In the figure, training error is purple and evaluation error (denoted CV) is pink. The same mechanism applies to CV and seems to be used for determining the $K$ in the example you mentioned in your question. In case 50% of data are enough to achieve a suitable fit, 2-fold CV would be enough. In contrast, 90% training data would require a 10-fold CV instead. You would thereby see the training error cure flattening out the same way as in the figure above. How to obtain such a plot (slow, stable): Use different $K$ and preserve both the corresponding $K$ associated training and $K$ test errors. Plot the average/median/etc. training and test error over $K$. What I assume the authors suggested (much faster, but less stable): Do a simple train/test split of your data, fit your model and preserve the training and test error. At first, do point 1 with a small portion of data in your training partition, then increase the training partition continuously. Preserve all associated training and test errors and plot them over the training partition size. As soon as the curve flattens out (will usually not be easy to determine) you know how big the portion of the data to use for training your model will be, and can therefore derive the required amount of partitions (e.g. using 80% of data in the training partition would correspond to having a 5-fold CV). (PS: I'm sure that there are better figures than the one I just used, right here on CV, so anyone knowing such: feel free to replace it!)
