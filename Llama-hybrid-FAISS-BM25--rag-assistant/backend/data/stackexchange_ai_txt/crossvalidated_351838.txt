[site]: crossvalidated
[post_id]: 351838
[parent_id]: 351760
[tags]: 
Below is my understanding of the paragraph (without having the context): Start: Cross-validation and information criteria make a correction for using the data twice (in constructing the posterior and in model assessment). Cross-validation helps to avoid the so called "double-dipping" problem - when one uses the same data to estimate the model and to check how well it does. Continues: and obtain asymptotically unbiased estimates of predictive performance for a given model. When sample size grows to infinity cross validation will generate unbiased estimates for predictive performance. With small sample sizes it will be more biased because in each cross-validation fold we will not be using all of the training data - but only a part of it (like 9/10 in 10-fold CV). Continues: However, when these methods are used to choose a model selection That is when cross-validation is used multiple times, not only once. For example when selecting between multiple models we might have an idea to run all of those models through cross validation and select the best one. Continues: the predictive performance estimate of the selected model is biased due to the selection process. Then the final predictive performance (the very thing we used in selecting our model) will be biased. This is because each model has some variability or randomness in them. When estimated on final data (with cross validation) performance estimates do not give us the exact true performance of those models on the population. Instead there is always some error associated with this performance measure. And because of this error - we will end up picking the model whose error (difference between true performance and estimated cross-validation performance) is optimistically biased. And the more models we try on cross-validation - the worse it will be. Bottom line: Cross-validation is unbiased (asymptotically) when used once. But it is not panacea for overfitting and will become biased once we start comparing different models on the same cross-validation data.
