[site]: datascience
[post_id]: 65464
[parent_id]: 
[tags]: 
How to append new numerical features to an embedding from word2vec, such that KNN on embeddings is not biased for one feature?

I am working on similarity calculation between entities of similar type. For each entity I am able to make a vector that comprises of multiple vectors itself. A = 50*1 vector B = 100*1 vector C = 50*1 vector D = [age, gender, x-feature, y-feature, z-feature] Entity = [A B C D], basically concatenating all of those. My problem is that: since they come from different spaces, each would have different orders of magnitude. If I run KNN on these vectors, I doubt that results are going to be governed by features of one space only. What should be done to get best KNN results? What "normalisation" would be best here?
