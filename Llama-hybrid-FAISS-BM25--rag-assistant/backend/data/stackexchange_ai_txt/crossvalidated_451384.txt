[site]: crossvalidated
[post_id]: 451384
[parent_id]: 8661
[tags]: 
I tried @fabians's answer. It gave different results compared to @lockedoff's and @Edward answer when using a binary predictor. Please be careful when choosing the method. For my own model, using @fabian's method, it gave Odds ratio 4.01 with confidence interval [1.183976, 25.038871] while @lockedoff's answer gave odds ratio 4.01 with confidence interval [0.94,17.05]. My model summary is as the following: Call: glm(formula = slicc_leuk ~ binf, family = binomial, data = kk) Deviance Residuals: Min 1Q Median 3Q Max -2.6823 0.3482 0.4625 0.4625 0.4625 Coefficients: Estimate Std. Error z value Pr(>|z|) (Intercept) 2.1812 0.1783 12.232 > exp(cbind(coef(fit1), confint(fit1))) Waiting for profiling to be done... 2.5 % 97.5 % (Intercept) 8.857143 6.340297 12.782462 binf1 1.806452 0.618633 7.697776 binf2 4.008065 1.183976 25.038871 > logistic.display(fit1) Logistic regression predicting slicc_leuk : 1 vs 0 OR(95%CI) P(Wald's test) P(LR-test) binf: ref.=0 0.056 1 1.81 (0.53,6.1) 0.341 2 4.01 (0.94,17.05) 0.06 Log-likelihood = -133.8248 No. of observations = 469 AIC value = 273.6496 ```
