[site]: crossvalidated
[post_id]: 17884
[parent_id]: 17878
[tags]: 
First, I would strongly advise against searching a complex hypothesis space using a genetic algorithm; it is a recipe for over-fitting unless you have a lot of data to constrain the model. Unrestricted optimisation is generally a very bad thing to do in model-fitting, every time you make a choice about your model, or optimise some parameter, you invite over-fitting, so in practice regularisation and model averaging often give better performance. I think the approach of creating random features is used in feature selection (see the work of Isabel Guyon on this topic); the random features are known as "probes" and if your modelling approach ends up with a large number of probe features in the model that suggests the model will over-fit. However it is not the case that models with irrelevant features, (including probes) will not have good generalisation performance. It is often better in terms of predictive performance not to perform any feature selection and use regularisation instead to prevent over-fitting. Randomly permuting the responses rather than the explanatory variables sounds an interesting idea as it gives a worst-case bound on the amount over-fitting we should expect as it tells us how good your algorithm is at finding patterns in "realistic" data where no genuine pattern actually exists.
