[site]: crossvalidated
[post_id]: 51923
[parent_id]: 51820
[tags]: 
For applications like this, you have to read the literature carefully, because somebody else's approximation might not reproduce the characteristic you are interested in. There are simple solutions based on precomputing values within the range where a simple approximation (like a Normal approximation) might not do a good job. In this case, you would worry most about where skewness is high: that would be where the Beta parameters are very unequal and relatively small. One solution is to create an interpolation function or lookup table based on this precomputation. To find the inverse CDF at $0.95$ , first look up its value. If the value is found in the table, use that; otherwise, use the generic approximation. Given the ease with which millions of values could be precomputed and stored, this is the way to go for intensive simulations on a PC> If RAM is really tight or, for some reason, you really want a formula, then the lookup table needs to be replaced by a formula. A good tool for fitting formulas for this purpose is Eureqa Formulize , a free download. This software identifies and fits functions to tabulated data (using a genetic algorithm). It is extremely fast, easy to learn, and fun to watch in action. Using a table of the $0.95$ quantile of Beta distributions for integer values $(a,b)$ in the range $1\ldots 10$ and minimizing worst case error, I have found--by running the software while writing this paragraph--a large number of approximations. The base case is the normal approximation itself, $z = \text{mean} + \Phi^{-1}(0.95)\times\text{SD}$ . Its worst case error is around $0.085$ (which is not terribly good). The formulas I searched for are in terms of $a$ , $b$ , $z$ , the skewness (whose formula in terms of $a$ and $b$ you can look up on Wikipedia ), and the central third moment $s_3$ (obtained by multiplying the skewness by the cube of the SD). Among the simpler formulas are $$0.0012526 + z + 8.90369 s_3 + 0.0344753 z\times \text{skewness}$$ with a worst-case error of $0.011$ --pretty good. This is recognizable as the Normal approximation $z$ plus corrections for (a) using the worst-case error as a criterion, which tends to introduce a small bias ( $0.0013$ ) and (b) the skewness (as expected). This formula would be used whenever both $a$ and $b$ are $10$ or less; otherwise, you would revert to the Normal approximation ( $z$ itself). Here is a plot comparing my tabulated values (points) against the formula, taken directly from the software: (The values jump around because this table of course is two-dimensional: it was originally organized by $a$ and $b$ , but then flattened into a traditional spreadsheet format for this analysis.) By applying this approach to a tabulated set of values you are most interested in, you will obtain different formulas. Pick one that best balances the desired accuracy against the complexity of the formula.
