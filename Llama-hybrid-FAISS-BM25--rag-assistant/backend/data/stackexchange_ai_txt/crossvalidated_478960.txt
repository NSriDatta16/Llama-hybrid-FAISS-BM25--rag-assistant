[site]: crossvalidated
[post_id]: 478960
[parent_id]: 478954
[tags]: 
Your last question - it's only test set performance that matters . So, after training has ended and model selection taken place, you can compute metrics like AUC (for the ROC-curve) based on your test set. There is precision and recall - in a medical setting you will compute predictive value positive and predictive value negative, sensitivity and specificity. However, when your classifier contains more than two classes , several other metrics can be computed than just the (conditional) correctness / error rates. For an overview of generic quality measures (beyond neural networks) see for example: M. Egmont-Petersen, J.L. Talmon, J. Brender, P. NcNair. "On the quality of neural net classifiers," Artificial Intelligence in Medicine, Vol. 6, No. 5, pp. 359-381, 1994.
