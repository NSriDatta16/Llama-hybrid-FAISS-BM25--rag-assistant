[site]: datascience
[post_id]: 25485
[parent_id]: 
[tags]: 
Are neural networks able to deal with non-normalised inputs?

All the techniques/models that I have learnt so far for deep learning start with some sort of normalization to the features, for example gaussian method, minmax scaling, robust scaling, batch normalization, instance normalization. Are there any techniques to run neural networks without normalization so that the network can see (in absolute values) the magnitude of the value and respond according to that instead of normalized values? Will there be exploding/vanishing gradient issues if I don't normalize my data? For example, if I am training a custom LSTM network for multivariate time series data, the input dimension for a feature vector $x$ is all the values from $t-n$ to $t$ , where $n$ is the number of time steps and the output vector is the value at $t+1$ . Is there any need for normalization in this case?
