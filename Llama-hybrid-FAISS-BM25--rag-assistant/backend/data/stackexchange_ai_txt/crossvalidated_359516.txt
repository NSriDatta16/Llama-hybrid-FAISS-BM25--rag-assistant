[site]: crossvalidated
[post_id]: 359516
[parent_id]: 328426
[tags]: 
Neat problem! It seems sufficient to use logistic regression with quadratic terms. If your features are $(x_1, x_2)$, then the modified features are $(x_1, x_2, x_1^2, x_2^2)$. This is because quadratics have 2 shapes: convex and concave. When using a linear model, a convex shape fits your data when the positives occur at the extremes; a concave shape fits your data when the positives occur "in the middle" (because this is when the value of the quadratic is largest). If you're certain that the positives must occur "in the middle" of the range, then you'll want to restrict the coefficients of the square terms to be negative, because these are concave quadratics. The resulting decision surface won't be a rectangle, though. Instead, it will be $$[1 ~x_1 ~ x_2 ~ x_1^2 ~ x_2^2] \beta > \text{logit}^{-1}(c)$$ where $\beta$ is your parameter vector and $c\in(0,1)$ is whatever threshold is best for your problem. I don't feel that this is any great loss, though, since the model will still reflect the core idea of what you want. [Previously, I answered this question as if it were completely deterministic but I see now that OP stated that this is not a separable problem, so that answer is irrelevant. See the edit history for more information.]
