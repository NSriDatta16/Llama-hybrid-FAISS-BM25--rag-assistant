[site]: crossvalidated
[post_id]: 595950
[parent_id]: 
[tags]: 
Hello, I am doing a machine learning assesment project in R where I have to perform multiple linear regression and write report on all my steps

So I did some data exploratory and found that the range of my features are variable, like some columns have range between 1 to 5, while other columns like 'square_feet' has range of 500 to 2000. In the pre-processing, I was planning to normalize the columns, so I have decided this approach where I only normalize the columns which have extreme range like 1000 to 10,000 and not the ones with range 0 to 10(for such columns with ordinal data, I will be creating dummy columns with 1 and 0, not sure If its needed, still in doubt). So should I normalize only specific columns or the whole data set? How should I treat the values I get after normalization, whic are continous values like -1.2341 and so on. Should I round them up or perfrom binning on them further? Please let me know the right approach, any help will be highly appreciated. Thank-you. I have normalized few columns and stuck at the decision at should I do this to the whole data set.
