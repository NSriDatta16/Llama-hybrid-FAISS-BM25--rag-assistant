[site]: crossvalidated
[post_id]: 31761
[parent_id]: 31755
[tags]: 
It is valid to compare several approaches, but not with the aim of choosing the one that favours our desires/believes. My answer to your question is: It is possible that two distributions overlap while they have different means, which seems to be your case (but we would need to see your data and context in order to provide a more precise answer). I am going illustrate this using a couple of approaches for comparing normal means . 1. $t$-test Consider two simulated samples of size $70$ from a $N(10,1)$ and $N(12,1)$, then the $t$-value is approximately $10$ as in your case (See the R code below). rm(list=ls()) # Simulated data dat1 = rnorm(70,10,1) dat2 = rnorm(70,12,1) set.seed(77) # Smoothed densities plot(density(dat1),ylim=c(0,0.5),xlim=c(6,16)) points(density(dat2),type="l",col="red") # Normality tests shapiro.test(dat1) shapiro.test(dat2) # t test t.test(dat1,dat2) However the densities show a considerable overlapping. But remember that you are testing a hypothesis about the means, which in this case are clearly different but, due to the value of $\sigma$, there is an overlap of the densities. 2. Profile likelihood of $\mu$ For a definition of the Profile likelihood and likelihood please see 1 and 2 . In this case, the profile likelihood of $\mu$ of a sample of size $n$ and sample mean $\bar{x}$ is simply $R_p(\mu)=\exp\left[-n(\bar{x}-\mu)^2\right]$. For the simulated data, these can be calculated in R as follows # Profile likelihood of mu Rp1 = function(mu){ n = length(dat1) md = mean(dat1) return( exp(-n*(md-mu)^2) ) } Rp2 = function(mu){ n = length(dat2) md = mean(dat2) return( exp(-n*(md-mu)^2) ) } vec=seq(9.5,12.5,0.001) rvec1 = lapply(vec,Rp1) rvec2 = lapply(vec,Rp2) # Plot of the profile likelihood of mu1 and mu2 plot(vec,rvec1,type="l") points(vec,rvec2,type="l",col="red") As you can see, the likelihood intervals of $\mu_1$ and $\mu_2$ do not overlap at any reasonable level. 3. Posterior of $\mu$ using Jeffreys prior Consider the Jeffreys prior of $(\mu,\sigma)$ $$\pi(\mu,\sigma)\propto \dfrac{1}{\sigma^2}$$ The posterior of $\mu$ for each data set can be calculated as follows # Posterior of mu library(mcmc) lp1 = function(par){ n=length(dat1) if(par[2]>0) return(sum(log(dnorm((dat1-par[1])/par[2])))- (n+2)*log(par[2])) else return(-Inf) } lp2 = function(par){ n=length(dat2) if(par[2]>0) return(sum(log(dnorm((dat2-par[1])/par[2])))- (n+2)*log(par[2])) else return(-Inf) } NMH = 35000 mup1 = metrop(lp1, scale = 0.25, initial = c(10,1), nbatch = NMH)$batch[,1][seq(5000,NMH,25)] mup2 = metrop(lp2, scale = 0.25, initial = c(12,1), nbatch = NMH)$batch[,1][seq(5000,NMH,25)] # Smoothed posterior densities plot(density(mup1),ylim=c(0,4),xlim=c(9,13)) points(density(mup2),type="l",col="red") Again, the credibility intervals for the means do not overlap at any reasonable level. In conclusion, you can see how all these approaches indicate a significant difference of means (which is the main interest), despite the overlapping of the distributions. $\star$ A different comparison approach Judging by your concerns about the overlapping of the densities, another quantity of interest might be ${\mathbb P}(X this answer . Note that there are no distributional assumptions here. For the simulated data, this estimator is $0.8823825$, showing some overlap in this sense, while the means are significantly different. Please, have a look to the R code shown below. # Optimal bandwidth h = function(x){ n = length(x) return((4*sqrt(var(x))^5/(3*n))^(1/5)) } # Kernel estimators of the density and the distribution kg = function(x,data){ hb = h(data) k = r = length(x) for(i in 1:k) r[i] = mean(dnorm((x[i]-data)/hb))/hb return(r ) } KG = function(x,data){ hb = h(data) k = r = length(x) for(i in 1:k) r[i] = mean(pnorm((x[i]-data)/hb)) return(r ) } # Baklizi and Eidous (2006) estimator nonpest = function(dat1B,dat2B){ return( as.numeric(integrate(function(x) KG(x,dat1B)*kg(x,dat2B),-Inf,Inf)$value)) } nonpest(dat1,dat2) I hope this helps.
