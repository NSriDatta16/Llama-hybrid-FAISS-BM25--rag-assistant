[site]: datascience
[post_id]: 58000
[parent_id]: 
[tags]: 
svm.LinearSVC: larger max_iter number doesn't always increase the accuracy/precision/recall

Background: Supervised machine learning Data shape 10+ features, target = 1 or 0 only, 100,000+ samples (so should be no issue of over-sampling) 80% training, 20% testing train_test_split(X_train, Y_train, test_size=0.2) Use svm.LinearSVC(max_iter = N ).fit( ) to train labelled data Scaling not applied yet (all feature values are around 0-100 (float64)) Other parameters (e.g., c = ) use default value Results: print("Accuracy:", metrics.accuracy_score(y_test, y_pred)) print("Precision:", metrics.precision_score(y_test, y_pred)) print("Recall:", metrics.recall_score(y_test, y_pred)) Question: I increased max_iter = from 1,000 to 10,000 and 100,000, but above 3 scores don't show a trend of increments. The score of 10,000 is worse than 1,000 and 100,000. For example, max_iter = 100,000 Accuracy: 0.9728548424200598 Precision: 0.9669730040206778 Recall: 0.9653096330275229 max_iter = 10,000 Accuracy: 0.9197914270378038 Precision: 0.9886761615689937 Recall: 0.8093463302752294 max_iter = 1,000 Accuracy: 0.9838969404186796 Precision: 0.964741810105497 Recall: 0.9962729357798165 What could be the reason? Do I need to test different max_iter values and select the best performance? For example, use GridSearchCV( )
