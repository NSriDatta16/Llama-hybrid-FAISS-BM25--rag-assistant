[site]: datascience
[post_id]: 68231
[parent_id]: 
[tags]: 
Same validation accuracy, different train accuracy for two neural networks models

I'm performing emotion classification over FER2013 dataset. I'm trying to measure different models performance, and when I checked ImageDataGenerator with a model I had already used I came up with the following situation: Model without data augmentation got: train_accuracy = 0.76 val_accuracy = 0.70 Model with data augmentation got: train_accuracy = 0.86 val_accuracy = 0.70 As you can see, validation accuracy is the same in both models, but train accuracy is significantly different. In this case: Should I go with the model which uses data augmentation, as it's train accuracy is higher? Should I expect overfitting from it, and choose the model without data augmentation as it's accuracy values are closer? Third option. Should I perform more comprobations? If so, which ones? Thanks for your time.
