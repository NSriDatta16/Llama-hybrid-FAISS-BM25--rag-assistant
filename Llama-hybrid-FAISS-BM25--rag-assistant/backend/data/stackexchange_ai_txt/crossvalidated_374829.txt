[site]: crossvalidated
[post_id]: 374829
[parent_id]: 
[tags]: 
Logistic regression with negative weights in Matlab

I want to apply a logistic regression to a set of data where observations have been assigned weights depending on their "distance" from {0,1}. Most of the observations have weights within [0,1] range, but some could be outside. (I know that this means that the binomial model is not really suitable, but let's say this is a restriction I am working under). If I write out a log-likelihood for an observation as $$w_i \ln(p(X\beta)) + (1-w_i)\ln(1-p(X\beta))$$ then this seems to work as desired: observations that have weights above 1 "pull the p" higher, and those with negative weights "pull the p" lower. However, when I try to use this weights in Matlab's glmfit, I get a warning "Weights are ill-conditioned." The documentation in Matlab on how the weights are used is "thin" (it just says "Vector of prior weights, such as the inverses of the relative variance of each observation" without any explanation on where and how they are used in the procedure), but it seems that they are used in some other way than just to multiply the log-likelihood. How are the weights applied in glmfit and how do I achieve the above log-likelihood?
