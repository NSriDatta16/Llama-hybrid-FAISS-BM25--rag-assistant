[site]: crossvalidated
[post_id]: 486438
[parent_id]: 486434
[tags]: 
It is perfect to say a logistic regression is a single perceptron. Logistic regression would be a specific case of a perceptron. In fact in Andrew Ng's deep learning specialization, an intuition for perceptron is given by beginning with logistic regression. Back-propagation helps in scaling up when you add several logistic regressions in series (several hidden layers) and parallel (a single hidden layer). Back propagation for a single perceptron will look like gradient descent for logistic regression. References DeepLearning Course Relevant stackExchange question
