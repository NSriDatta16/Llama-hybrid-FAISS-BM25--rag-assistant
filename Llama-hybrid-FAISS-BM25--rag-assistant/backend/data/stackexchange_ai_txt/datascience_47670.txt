[site]: datascience
[post_id]: 47670
[parent_id]: 47666
[tags]: 
Yes feedback loops can happen in much the same way in machine learning. It can happen when the predictions of a model affects the future labels. Let's say we are predicting crime rate in different neighborhoods. One neighborhood has biased data causing it to be predicted as higher in crime than it actually is. This causes more police presence in this neighborhood which in turn will lead to more real crime being discovered than in the areas that didn't receive extra attention caused by a biased model. This extra discovered crime will then be present for any new models to be trained even if the initial data error/bias is removed. The biased model as enforced its' own bias and produced new data to back it up.
