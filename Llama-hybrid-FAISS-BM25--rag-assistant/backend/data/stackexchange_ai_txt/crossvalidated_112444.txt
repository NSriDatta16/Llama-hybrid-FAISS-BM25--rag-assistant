[site]: crossvalidated
[post_id]: 112444
[parent_id]: 
[tags]: 
Is my interpretation of Bayesian probability and inference correct?

I have the following interpretation of the Bayesian probability and inference (without referring to Measure Theory, I am still at the very beginning of learning it): Let's say we have five random variables $x_1,x_2,x_3,x_4,p$ given as in the following graphical model: Let's say we have already observed $x_1,x_2,x_3$ and we want to make a Bayesian inference on the variable $x_4$. We assume a prior probability density function $p(p)$ for the parameter $p$ and we assume that each $x_i$ is generated from the distribution $f(x_i|p)$. Then according to our assumptions about the prior distribution $p$ and the generative distribution $f$, we assume a sample space $\Omega$ which contains all possible tuples of $(x_1,x_2,x_3,x_4,p)$ and each single outcome $\omega$ has a probability value assigned to it, which corresponds to our degree of belief about this single outcome, according to the Bayesian interpretation of probability. Then we have the event set $\mathcal{F}$ as well, according to the definition of a probability space. This space and its probability measures entail the prior distribution $p(p)$ and the distributions $f(x_i|p)$ and the independence of $x_i$s given $p$ . I assume that one of these outcomes, $\omega$ is selected and all events in $\mathcal{F}$ which contain $\omega$ are assumed as "occured". In practice, we cannot ever observe the value of the parameter $p$ in the selected outcome, $\omega$. But we are able to observe some of the $x_i$s which constitute our data, for example $D=(x_1,x_2,x_3)$. Then the broadest inference we can do about $x_4$ is to calculate the posterior distribution of $p$ given the data and then integrate over all possible single values of $p$, which might be generated the data $x_1,x_2,x_3$ and the target variable $x_4$ like in the following: $$ P(x_4|x_1,x_2,x_3) = \int_{p} f(x_4|p) P(p|x_1,x_2,x_3) dp$$ This more or less constitutes my imagination of how the Bayesian probability and inference works. Is this view correct? If not, what is wrong about it?
