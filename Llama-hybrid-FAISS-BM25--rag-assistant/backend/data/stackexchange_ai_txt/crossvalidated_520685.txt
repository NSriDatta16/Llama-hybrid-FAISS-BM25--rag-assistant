[site]: crossvalidated
[post_id]: 520685
[parent_id]: 520625
[tags]: 
You need to be clear about the quantity you want to estimate. Most causal inference applications are concerned with the average marginal effect of the treatment on the outcome. This does not correspond to the coefficient on treatment in a logistic regression model. The way to use regression to estimate causal effects is to use g-computation, which involves fitting a model for the outcome given the treatment and covariates (and their interaction), then using this model to predict the potential outcomes under treatment and under control for all units, then taking the difference in means between those predict potential outcomes. G-computation is consistent if the outcome model is consistent. Below is how you would do g-computation in R: #Fit the outcome model with an interaction between the treatment and covariates fit The coefficient on treatment in a logistic regression of the outcome on the treatment and covariates is an estimate of the conditional effect of the treatment assuming no effect heterogeneity on the odds ratio scale. This is an extremely strong and unnecessary assumption to make. The reason the effect is the conditional rather than the marginal effect is because of the noncollapsibility of the odds ratio. This is not the case for linear regression; it is possible (by correctly parameterizing the linear model) to have the coefficient on treatment be a valid estimate of the marginal treatment effect. There must be an interaction between treatment and the mean-centered covariates for this to work. I will assume that you are now using g-computation and want to know how you can incorporate weights into it. You can include the propensity score weights into an outcome model and then perform g-computation using that model. This method is doubly robust. Kang and Schafer (2007) call this method "Regression Estimation with Inverse-Propensity Weighted Coefficients" (regression estimation is another name for g-computation). Simply add weights to the glm() model exactly as you specified, and insert the code below into its appropriate place in the g-computation code above. #G-computation with a weighted outcome model fit There are many ways to produce doubly-robust estimators that are consistent if either the propensity score model or outcome model are correctly specified. The way you proposed is one, but you also have to get the conditional relationship between the outcome and propensity score correct, so simply adding it in as a covariate will not do. You need to allow it to be flexibly modeled. Using rcs() from rms is one way to do that. library(rms) #G-computation with PS as an additional covariate, modeled with a #restricted cubic spline (rcs) fit This model has a chance of being doubly robust. Estimating confidence intervals is a little challenging with g-computation; in some cases, you can use the delta method/estimating equations, but the most straightforward and recommended way is to bootstrap. You need to include the propensity score estimation in the bootstrap. I demonstrate this below using the boot package. library(boot) boot_fun $ps ps_w This is for the average treatment effect in the population. Things are a little different for the average treatment effect in the treated. If you're using matching, see the guide on estimating effects after matching with MatchIt here . I also recommend you check out the WeightIt package, which makes estimating weights very straightforward. Both packages have extensive documentation explaining how to estimate effects.
