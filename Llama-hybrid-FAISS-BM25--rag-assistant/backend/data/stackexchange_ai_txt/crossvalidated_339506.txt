[site]: crossvalidated
[post_id]: 339506
[parent_id]: 
[tags]: 
Why do we sum the cost function in a logistic regression?

I get the intuition behind the loss function for linear regression, which happens to be the MSE function. We have a set of points and we try to fit a line between them so that the line is at a minimum distance from all the points. So it makes sense to add up the distances from all the points and then try to minimize that distance. However, in logistic regression, why do we take the sum of the loss function? Can't we calculate the losses for each training example, minimize that and move on to the next? We could then average out the weights for each example over all the iterations. My question is: What is the intuitive sense behind taking the sum of the training example losses and them summing it up and minimizing that. It makes more sense to me to minimize the individual training example and then move on to the next.
