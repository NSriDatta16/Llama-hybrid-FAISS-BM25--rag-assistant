[site]: crossvalidated
[post_id]: 539676
[parent_id]: 
[tags]: 
How to handle NaN/Missing values in Machine Learning (on HiggsML competition data)

I'm currently learning Machine Learning methods and try to work on the recent HiggsML competition in which many different data scientists (etc.) could provide their algorithms etc. of solving this problem with ML. Now, the data set I have does have many missing values (or NaNs) represented as -999.0 values and I wonder how to deal with them (or to deal with them at all, see bullet point 2). Obviously, a trivial and naiv possibility is simply ignoring these data columns but this only reduces accuracy and looses a ton of data Another approach could be, as it is, setting them to a constant number (here -999., alternatively 0) but I wonder if this wouldn't change the fit of the model to predict the test data as many data points would be located around this set value Lastly, I found an approach called the MICE imputation, which assumingly uses the whole data set to simulate/approximate the missing values. Since this are detector measurements this approach could be feasible in my opinion, but I have not yet achieved experience with this method. To end with a question, until now I simply used the -999 approach, but shouldn't it be better to approximate the missing values? Are there like default approaches one typically uses?
