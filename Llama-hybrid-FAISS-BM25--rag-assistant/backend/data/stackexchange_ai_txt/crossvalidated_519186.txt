[site]: crossvalidated
[post_id]: 519186
[parent_id]: 
[tags]: 
How to calculate sample size and prove non-inferiority/equivalence between two risk prediction models

I am in need of determining the appropriate sample size to allocate to a test set in order to prove equivalence/non-inferiority of two prediction models. My model is a deep learning based model (using DeepHit ) to predict risk of sustaining at least 1 fracture utilizing the actual outcome data for a population. I want to prove it is non-inferior to an existing method (FRAX). Both my model and FRAX can produce a 10 year probability of fracture which can be compared to the gold-standard (i.e. did the event actually occur or not). I can do c-index and brier scores to compare model performance. Clinically, patients with > 20% 10 year risk of fracture are considered for treatment (which can be thought of as a binary classification). I believe I will need to compare diagnostic performance and AUC. The problem with this dichotomy is that any model will have low sensitivity since by definition patients at high risk will still only experience the event > 20% of the time. So my question is how do I determine the appropriate sample size to sufficiently power the results from my test set? I plan to stratify the test set by male/female and above/below age 65 years of age based on event prevalence.
