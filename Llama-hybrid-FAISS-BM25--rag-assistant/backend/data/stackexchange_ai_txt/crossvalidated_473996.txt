[site]: crossvalidated
[post_id]: 473996
[parent_id]: 
[tags]: 
What does a positive or a negative TD-Error mean (in DQN)?

When training a DQN, for example on board games, the sign of the TD-error varies. Sometimes, it's: always positive always negative varying during the training of the algorithm For example, on the graph below, we see this third behavior: Does this mean something? E.g can we give this an interpretation that relates to how the agent is behaving/learning? (for example interpretations about the "surprise" of the network since the td-error is the Bellman equation approximation error)
