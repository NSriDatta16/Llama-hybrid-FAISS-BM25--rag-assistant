[site]: crossvalidated
[post_id]: 574591
[parent_id]: 
[tags]: 
Evaluation for LSTM model

I have created a model for text generation using LSTM. I am having chess sequences learned, reporting only the pieces moved during the moves. So when I move a pawn on my game there will be "p", a bishop "b" and so on. Obviously this data has been mapped and taken in integer. The model used for learning is: model = Sequential() model.add(Embedding(vocab_size, 5, input_length=seq_len)) model.add(LSTM(256, return_sequences=True)) model.add(LSTM(256)) model.add(Dense(256, activation='relu')) model.add(Dense(vocab_size, activation='softmax')) My model at the end of 100 epochs has an accuracy of 0.55 and a loss of 1.05. I cannot increase these metrics. I have seen a few articles that have the same performance as mine, so I was asking if it is normal to have these values at the end of the train for models with LSTM. If they are acceptable, how can I do an evaluation for models that use LSTM? What is the best way to do the evaluation?
