[site]: crossvalidated
[post_id]: 461580
[parent_id]: 461549
[tags]: 
If you view the back-propagation purely as a graph algorithm operating on the computation graph, the inputs are qualitatively the same nodes as the parameters - some floats that one can change and the output of the network will change. The back-propagation algorithm can compute the gradient of anything in the computation graph (given all operations are differentiable) regardless if it makes sense or not. Usually, it does not make sense to change the inputs because you want a model that works well for inputs as they are. However, input gradients can be used for generating adversarial examples - small perturbations of the input that are hardly noticeable for a human but change the output of the model (more a topic in computer vision and speech recognition than NLP). I think it can make sense to view embeddings fine-tuning as back-propagation to the input, but I think NLP people usually consider the embeddings to be more of model parameters than the inputs. The "real" inputs are one-hot vectors/vocabulary indices.
