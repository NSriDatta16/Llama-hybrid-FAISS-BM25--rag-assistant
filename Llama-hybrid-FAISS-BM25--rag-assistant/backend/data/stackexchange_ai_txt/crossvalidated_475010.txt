[site]: crossvalidated
[post_id]: 475010
[parent_id]: 
[tags]: 
Intuition behind the use of multiple attention heads

Consider this introduction to attention layers with the main description below. I understand attention layers as learnable soft query retrieval operators that act on a "K-V store" of vectors. A common use case is to learn a "sequence to sequence" task where output words can query the input sequence to soft "align" on the right input sequence word or word context. What's the intuition behind multi-head attention? How are they used in practice? Do they just compute the same projection multiple times to just get a higher dimensional representation? (I doubt it). Or are the extra heads focused on shifted inputs in any way? What "extra information" or computation do they extract that can be useful for a particular task?
