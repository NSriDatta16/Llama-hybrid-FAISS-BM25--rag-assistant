[site]: crossvalidated
[post_id]: 462695
[parent_id]: 462685
[tags]: 
You are doing a one-class svm, which is essentially an unsupervised training algorithm. In this case, there is no actual label for you to assess how good / bad your model is. You cannot measure the error, and if that's the case, running tune will not work. If you are running one class svm for outlier detection, you need say a test set to define what are correct / wrong predictions, which then can give you a test error for you to choose the best parameters. If you try to run something, it gives you purely rubbish, for example: fit = tune.svm(x=x,y=rep(TRUE,nrow(x)),type='one-classification', kernel="radial",nu=c(0.05,0.1,0.2)) fit$performances nu error dispersion 1 0.05 0.4 0.1763834 2 0.10 0.4 0.1763834 3 0.20 0.4 0.1763834 My suggestion is to go back and define how you are going to assess how good the model is come up with test and train set run svm using the above to assess it
