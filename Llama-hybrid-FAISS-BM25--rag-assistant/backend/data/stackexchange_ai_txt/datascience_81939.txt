[site]: datascience
[post_id]: 81939
[parent_id]: 81451
[tags]: 
It's a good idea to remember what you're trying to predict and that is: $\mathbb{E}[Y | X=x]$ . The simplest estimate is a single tree: $$ \hat{\mu}(x) = \sum_{i \leq n} w_i(x, \theta) Y_i $$ with: $w_i(x, \theta)$ the single tree node weights (equation 4 in the paper) $Y_i$ your observations As we all know this is not a great estimate (high variance among others) so he defines a better estimator (random forest) as: $$ \hat{\mu}(x) = \sum_{i \leq n} w_i(x) Y_i $$ where the $w_i(x)$ are averages over the multiple trees (equation 5). So what does that mean? Your best estimator for $\mathbb{E}[Y | X=x]$ is $\hat{\mu}(x)$ . What do you do if you want an estimation of a function $\phi$ of $Y$ ? You just transform your observations of $Y$ and use the same formula, i.e.: $$ \hat{\mu_{\phi}}(x) = \sum_{i \leq n} w_i(x) \phi(Y_i) $$ which would then be an estimator of $\mathbb{E}[\phi(Y)|X=x]$ . If you define $\phi(Y) = \mathbb{1}_{Y \leq y}$ then you get that: $$ \hat{\mu_{y}}(x) = \sum_{i \leq n} w_i(x) \mathbb{1}_{Y_i \leq y} $$ is an estimator of $\mathbb{E}[\mathbb{1}_{Y \leq y}|X=x] = F(y|X=x)$ . I avoided a lot of low-level details here but to be clear this relates to the delta method i.e. convergence of a function of estimator. This kind of convergence is not trivial to prove (but I guess that's why they wrote a paper about it)
