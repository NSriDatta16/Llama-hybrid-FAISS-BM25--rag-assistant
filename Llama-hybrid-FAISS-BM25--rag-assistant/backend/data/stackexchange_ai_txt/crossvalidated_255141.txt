[site]: crossvalidated
[post_id]: 255141
[parent_id]: 
[tags]: 
EM for MAP variance of AR(1)

this question is about MAP inference in an AR(1) model (exercise 1.6 from West, M., Time Series: Modeling, Computation and Inference). It's not a homework assignment. Assume $n$ observations were generated from the model $y_t = \phi y_{t-1} + \epsilon_t,\ \epsilon_t\sim\mathcal{N}(0, v)$ where $y_1$ (the first observation) is known, i.e. we can use the conditional likelihood $p(y_{2:n} | y_1, \phi, v)$ in the following. The goal is to compute the mode of $p(v | y_{1:n})$ Priors and posteriors We put a Gaussian and Inverse Gamma prior on $\phi$ and v, respectively and so $\phi | v \sim \mathcal{N}(0,v)$ $v\sim IG(n_0/2, d_0/2)$ The posterior distributions are given by $\phi | y_{1:n}, v \sim \mathcal{N}(m, vC)$ $\qquad(*)$ $v| y_{1:n} \sim IG(n^*/2, d^*/2)$ where $m=\frac{\sum_{t=2}^n y_{t}y_{t-1}}{\sum_{t=2}^n y_{t-1}+1},\ C=\frac{1}{\sum_{t=2}^n y_{t-1}+1},\ n^*=n+n_0-1,\ d^*=\sum_{t=2}^n y_{t}^2-m+d_0 $ Furthermore, the joint posterior $(\phi, v | y_{1:n})$ under the full likelihood $p(y_{1:n} | \phi, v)$ is proportional to $v^{-n/2+1}(1-\phi^2)^{1/2}\exp\left(-\frac{\sum(y_t-\phi y_{t-1})}{2v}\right)$ $\qquad(**)$ EM To find the MAP for $v$ we use the EM algorithm. The $m$ -th E-step comprises of computing $E^{(m-1)}[\log(\phi,v| y_{1:n})]$ and so we need to compute the expression $\int_{\mathbb{R}}\log p(\phi, v| y_{1:n})p(\phi| v^{m-1}, y_{1:n})d\phi$ Plugging in the expressions from $(*), (**)$ I find that this integral is very hard to compute. Is this really the way to go? How can I make progress? Thanks for the help!
