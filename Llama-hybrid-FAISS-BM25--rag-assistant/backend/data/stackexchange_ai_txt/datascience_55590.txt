[site]: datascience
[post_id]: 55590
[parent_id]: 55587
[tags]: 
In my experience, it is very difficult to come up with good working custom objective functions for xgboost. Custom objectives need to be continuous and need to have a convex gradient and non zero hessian, which is often not the case for custom loss functions. One simpler method you could use is to define a custom validation metric based on your range +/-10, that can be used in conjunction with early stopping to optimize your hyperparameters of the xgboost model. So the model will not directly optimize for this, but will select hyperparamters that will minimize your custom loss. However, I would suggest to stick with the RMSE objective for this problem.
