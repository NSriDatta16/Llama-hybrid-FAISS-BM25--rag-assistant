[site]: crossvalidated
[post_id]: 438882
[parent_id]: 
[tags]: 
Regularization vs Hyper Parameter optimisation

I was hoping to get some informed opinion of the following problem. Currently we are fitting a timeseries problem by doing hyperparameter optimisation over multiple models. For instance comparing say arima, randomForest we do hyper parameter optimisation on both and then choose the best model with best hyper parameters. However, personally I feel it would be a better to fit a simple linear model (the data has some other inputs besides just time, say isWeekend ) and use regularisation, than it would be to do hyperopt over 10 models and choose the best. My personal line of thought is that there is information leakage since we are using the validation set to choose the best model. Given that often we have ~100 data points and of which 20 is the validation set, I feel that the model can just simply get 'lucky' to fit well to those 20 last points. Whereas regularising is a bit more 'statistically grounded'. Question: Is there a statistical basis to choose one of these 2 methods over the other. p.s. I'm not suggesting random forest is a good idea, just testing out everything.
