[site]: crossvalidated
[post_id]: 348255
[parent_id]: 
[tags]: 
Incorporate a lag effect into a linear mixed regression model

My data : I have 80 years of repeated measures data (forest growth rates) that unfortunately were not sampled regularly. My understanding is that this precludes me from using time series analyses (at least in any straightforward way that doesn't require more data than I have). I have GrowthRate , forest Age , and Biomass.lost as known variables (for 30 Plots ). My question : I can model the effects of Biomass.lost on GrowthRate trends across age via: GR ~ Age + BL . But what if I think Biomass.lost plays a larger role as a lagged effect? Specifically, I think that perhaps that GrowthRate increases in sampling periods after the period of recorded biomass lost . How do I incorporate this lagged effect of my predictor into a mixed model? Is it as easy as shifting my real Biomass.lost values in the dataset by a single sampling year? for example, reassigning Biomass.lost in Plot 4 in sampling year 1 to sampling year 2 This doesn't seem at all like an appropriate approach, but I'm not sure... (I'm using the lmer package in R , btw, if you wouldn't mind framing your answer in the context of that program)
