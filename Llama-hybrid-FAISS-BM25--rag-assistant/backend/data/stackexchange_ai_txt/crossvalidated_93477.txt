[site]: crossvalidated
[post_id]: 93477
[parent_id]: 
[tags]: 
What is the minimum training set size required for a given number of features for document classification?

For document classification problems, is there a rule of thumb for the number of training instances required for the number of terms in the vocabulary? I am using a logistic regression classifier with TF-IDF weighted features. After stop-word filtering, stemming, and filtering by minimum and maximum document frequencies, I have a vocabulary of ~13,000 terms for a training set with ~20,000 documents. I have attempted using LDA for dimensionality reduction by adding topic probabilities as features, but this did not significantly affect performance. The performance of a classifier trained only on LDA topic probability features was inferior to the performance of the classifiers trained on TF-IDF features and TF-IDF+LDA topic probability features.
