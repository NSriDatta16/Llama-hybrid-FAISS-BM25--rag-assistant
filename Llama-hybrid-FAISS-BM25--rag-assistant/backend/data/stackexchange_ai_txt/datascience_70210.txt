[site]: datascience
[post_id]: 70210
[parent_id]: 
[tags]: 
None of the known overfitting prevention techniques works for me, according to learning curves

I am working on HTRU2 dataset to evaluate classification models. Even though I obtain good results in terms of accuracy-MSE: I have an overfitting problem according to the learning curves below. In some of my models (Extra Tree, BaggingClassifier, AdaBoost, Random Forest, Decision Tree, k-NN), the red training curve never goes down as you can see: The ways that I have tried to prevent overfitting: I was using 30% of the whole dataset for the test set. I have decreased it to 20%, therefore I got a bigger training set but it has no effect on the curves (only slightly in the accuracies) Incremented the cv count in the GridSearchCV from 10 up to 50: The difference is only in the accuracies. I have tried to use PCA with k-NN to simplify: Again there was no difference on the curve. Tried different pre-processing techniques: I was using StandardScaler and I have changed it to MinMaxScaler, however, I could not achieve different curves (now I have slightly better accuracies though) I do not know how to solve this problem. In the beginning, I have oversampled the dataset with SMOTE method because of the imbalance. Might this cause the problem? Any help will be appreciated!
