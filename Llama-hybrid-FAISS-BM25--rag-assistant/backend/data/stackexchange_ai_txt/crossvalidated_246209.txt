[site]: crossvalidated
[post_id]: 246209
[parent_id]: 50787
[tags]: 
I see two approaches here: standard stats results (concentration bounds) bayesian approach (since you have a prior) The standard approach (concentration bounds) I would be to use concentration inequalities (e.g. Hoeffding's bound ) to derive a confidence interval for the true value of each object given the nber of trials you already have performed for it. The good thing with these bounds are that they hold for small samples, something that a normal or student interval don't really guarantee. Actually this is what works behind the scene of a bandit algorithm like UCB. The Bayesian approach Since you have a prior I would try to come back to the Thompson Sampling algorithm. Basically, you need to define a model of the value $r$ of items $E[r|\theta^*]$ with $\theta^*$ the true parameter governing the value distribution. Once you have a prior $P[\theta]$ you can use Bayes rule to update the posterior $E[\hat{\theta}|D]$ where $D$ is all the past trials and their outcome: $E[\hat{\theta}|D] \propto \prod_tE[r|\hat\theta,D]P[\theta]$, where $r$ is the outcome of the current trial. An empirical evaluation of TS and a very simple algorithm for Bernoulli rewards can be found in this paper . Both approaches are linked to the bandits field (since it was the OP formulation), but I guess you could simply derive a bayesian algorithm given that you find a good distribution to model the value.
