[site]: datascience
[post_id]: 56995
[parent_id]: 56985
[tags]: 
I find your question confusing (this might be my fault). Let's see if I understand you correctly. Feature selection is not applied before or after the filter. You choose to include a feature, or not. There are many ways to make a selection of features. If you use decision trees (or algorithms based on decision trees like XGBoost or random forest), then you can calculate the feature importance and use that to select features. Your set-up to predict ozone concentration contains feature processing (the filter) and then an algorithm (boosted trees) that makes a prediction. You use a set of features, run them through a filter, you train the trees. Now you can use the filter + the trained trees to get your prediction (ozone concentration). You can also look at the feature importance of all the features that you used, make a selection, and retrain with a reduced set of features. What makes no sense to me is to use a different set-up without the filter, to train the trees on the raw unfiltered features, and then look at the feature importance, because you have trained your trees on input data that the trees will never see in the set-up you're actually trying to use. So I think the answer to your question is "after". :-)
