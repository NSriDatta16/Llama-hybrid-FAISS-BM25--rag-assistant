[site]: crossvalidated
[post_id]: 383977
[parent_id]: 
[tags]: 
Estimation of transition probability matrix (TPM) for a discrete time, continuous state markov chain from uniformly-spaced samples

I have uniformly spaced samples from a three-component (i.e. three nodes) Markov chain: $s^{(0)}=\begin{bmatrix}0.99\\ 0.01\\ 0.00\end{bmatrix}$ , $s^{(1)}=\begin{bmatrix}0.98\\ 0.01\\ 0.01\end{bmatrix}$ , $s^{(2)}=\begin{bmatrix}0.89\\ 0.05\\ 0.06\end{bmatrix}, \cdots$ I want to estimate the $3\times 3$ transition probability matrix from these samples. This is a simple MC model and not an HMM. For discrete state spaces, I understand an MLE estimate can be obtained from transition counts. I'm looking for guidance (or a simple language reference) for how to compute it for continuous-space, discrete-time case. FYI you can assume I'm comfortable with differential equations and linear algebra, but I'd struggle with SDEs because of a lack of proper background. For context, the state vector represents fraction of user populations in the three components (e.g. [f_new_user, f_taken_action_1, f_taken_action_2] ) on each day of the year (so ~365 time step samples). There are no strong assumptions about the distribution of state vector. My first though is to discretize the state space, but even a bin size of 0.01 will lead to a million states and I dont have nearly enough data for that kind of estimation. Second thought is to treat this is as a continuous-time, continuous state-space problem and use the SDE machinery (though, as mentioned above, I dont have proper background to this -- any references appreciated). In summary, I have two questions: (1) Assuming a discrete time, continuous state-space, how do I estimate the TPM? (2) Should I instead try to force distributional assumption on the state vector and use parameter estimation for an SDE, and how do I do that?
