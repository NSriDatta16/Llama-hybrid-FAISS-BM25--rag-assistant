[site]: crossvalidated
[post_id]: 603420
[parent_id]: 603410
[tags]: 
This is a good technical question. Without being given the initial distribution of $Y_0$ , the rigorous proof of this well-known result actually requires advanced probability theory. For the sake of rigor, we need to assume $t$ ranges over $t = 0, \pm 1, \pm 2, \ldots$ . Suppose $|\rho| , Example 3.1.2 in Time Series: Theory and Methods (2nd Edition) by Peter J. Brockwell and Richard A. Davis shows that \begin{align} X_k := \sum_{j = 0}^k\rho^jv_{1 - j} \end{align} converges to $Y_1$ almost surely. Hence to determine the (marginal) distribution of $Y_1$ , it suffices to determine the limiting distribution of $X_k$ as $k \to \infty$ . Clearly, being the linear combination of independent Gaussian random variables $\{v_1, v_0, \ldots, v_{1 - k}\}$ , $X_k$ also follows Gaussian distribution with mean $0$ and variance $\sigma_k^2 := \sigma^2\sum_{j = 0}^k \rho^{2j} = \frac{(1 - \rho^{2(k + 1)})\sigma^2}{1 - \rho^2}$ , which implies that the distribution function of $X_k$ equals to $F_{X_k}(x) = \Phi(x/\sigma_k)$ , where $\Phi$ is the CDF of $N(0, 1)$ . Define $\tau^2 := \frac{\sigma^2}{1 - \rho^2} = \lim\limits_{k \to \infty}\sigma_k^2$ . It then follows by the continuity of $\Phi$ that $F_{X_k}(x) \to \Phi(x/\tau)$ as $k \to \infty$ for all $x \in \mathbb{R}$ , which by definition means $X_k$ converges in distribution to $N(0, \tau^2)$ . This proves the distribution of $Y_1$ is $N(0, \tau^2)$ .
