[site]: crossvalidated
[post_id]: 561857
[parent_id]: 
[tags]: 
Log Odds in Zero Noise Limit

I have the following problem: Define $p := 1 - \exp(-\exp(-\lambda^2/2\sigma^2))$ and consider the log odds: $$\log \frac{p}{1-p} $$ I'm interested in the limiting behavior as $\sigma^2 \rightarrow 0$ . Obviously the log odds go to $-\infty$ , but I'd like to know how quickly. My hypothesis is that the answer will be $-\frac{\lambda^2}{2\sigma^2}$ but I'm having trouble showing that. This problem arises in a modified flavor of Bayesian logistic regression.
