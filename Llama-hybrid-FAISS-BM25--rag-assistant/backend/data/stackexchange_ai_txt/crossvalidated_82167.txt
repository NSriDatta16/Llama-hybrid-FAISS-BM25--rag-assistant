[site]: crossvalidated
[post_id]: 82167
[parent_id]: 82127
[tags]: 
Classic multiple imputation methods (as developed by Rubin) generally concentrate on getting estimates of the parameters of the model. If you can follow what the combinatory process is doing (as in MIANALYZE) then this might shed light on why you get discrepant answers when comparing with hypothesis tests. My current understanding is that there are some methods/schools of thought on combining hypothesis tests from analyses on multiply imputed data: I'm not well versed in these though, but the following should be read in light of what you might be doing with your combination for the chi-squared test results (which may be sophisticated, or may be some simple mean or other average). [If I have time later I'll try and add some notes on this.] Full details of formulae for the combination of parameter estimates and calculation of confidence intervals are available on the SAS help page as follows: note that these are standard formulae, rather than being SAS-specific implementations. Weblink here Parameters When combining the parameter estimates from your ten analyses, MIANALYZE uses two sources of variance: firstly the variances from the parameter estimates in each model (which translates to an average of the variances in each analysis, i.e. the average of the standard errors squared for the parameter estimates (log(odds ratio) in this case).) This is referred to as the ”within-imputation variance” . The other source of variance is the variability between the different parameter estimates. In other words, the variance of the ten computed log(odds ratios) around the mean log(odds ratio). This is termed ”between imputation variance” These two sources of variance are then combined (see link above for formula again) to make the variance for each parameter estimate based on the imputation process, and this is then used with the average parameter estimate (again, in your case the average log(OR) across the ten imputed datasets for each parameter) to construct a Wald-like confidence interval. Hypothesis tests Here’s where I suspect your issue may arise: given that the above method uses two sources of variance, and furthermore that both sources of variance have theoretical underpinnings, any simple rolling together of the individual hypothesis tests is not going to capture the variaibility in the statistical properties of your data across the imputed datasets.
