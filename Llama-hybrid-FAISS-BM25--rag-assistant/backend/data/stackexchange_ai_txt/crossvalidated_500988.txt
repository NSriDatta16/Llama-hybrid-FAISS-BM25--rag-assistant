[site]: crossvalidated
[post_id]: 500988
[parent_id]: 
[tags]: 
Why are we checking the difference between q(z|x), and p(z|x) in variational encoders?

I'm trying to understand how VAEs work, because I didn't understand how cross entropy between $x$ (input fed into the encoder), and $p(x|z)$ (output of decoder) minus KL divergence between $p(z|x)$ , and $p(z)$ result in the latent space being so continuous. Although, I still don't understand it, the first step is to understand why are we calculating the loss as $KL(q(z|x)||p(z|x))$ , because as I read, this is the first "idea", but because of $p(x)$ is intractable, we use the fact that maximizing ELBO minimizes KL, and breaking down ELBO in an equation where we can calculate each piece. The first question in my mind was why aren't we comparing $p(x|z)$ , and $q(x|z)$ . At the end of the day we care about how well $x$ was constructed from $z$ . The encoder produces $q(z|x)$ , but where does $p(z|x)$ come from, and what do we know about it? We're calculating $p(x|z)$ with the decoder, not $p(z|x)$ . Or does it mean if we can transform $p(x|z)$ to $p(z|x)$ , and the difference between $q(z|x)$ , and $p(z|x)$ is small, then $p$ is predicting $x$ from $z$ accurately, as $p(x|z)$ ? In this understanding, we're trying to build two networks mirroring each other. But I just don't understand seeing the current equations how it is performing well. We're comparing two distributions that maybe similar to each other, but in neural network perspective, can be wrong (poor reconstruction, or wrong place in latent space). So it shouldn't be enough to build networks that are exact opposite of each other. Our only pillar is $x$ fed into the encoder, and if it would mean $q(x|z)$ , it would make sense, but as I've read so far, the input fed into the encoder is simply $x$ . On the other side, if the input fed into encoder would be $q(x|z)$ , it would prove that if the difference between $q(z|x)$ , and $p(z|x)$ is small, it doesn't mean $p$ is predicting $x$ from $z$ accurately, as $p(x|z)$ , at least early stages of the training. So the question is does comparing $q(z|x)$ with $p(z|x)$ prove how effectively the encoder, and decoder mirroring each other? In my head they could mirror each other effectively by placing the latent variables not with the continuousity as they do, so how does the loss we're calculating ensures that? Also, regardless of the tractability of the breakdown, could comparing $q(x|z)$ with $p(x|z)$ measure the loss just as effective as comparing $q(z|x)$ with $p(z|x)$ ? Are my thoughts, and imagination right, or I'm missing something important? Sorry for asking questions that may be stupid, or obvious, but I don't have too much knowledge of probabilities, just built simple neural networks, and it is very hard to imagine in a programmer perspective.
