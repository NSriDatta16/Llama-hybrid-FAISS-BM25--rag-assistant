[site]: crossvalidated
[post_id]: 560763
[parent_id]: 560748
[tags]: 
I would point out three things: (1) Generally (related to the estimation of causal effects) Usually you want to explain phenomena out there in the world with parsimonious models including variables deduced from some theory. You may just add any variable that comes to your mind to a regression model and end up with an almost perfect fit, but you did not learn anything about (or even fundamentally distorted) the relationship (aka causal/treatment effects) you actually interested in (also see the DAGs @ColorStatistics pointed to). (Literature e.g.: "Causal Inference in Statistics" by Judea Pearl). (2) Specifically (more related to the overspecified model term) You can perceive adding irrelevant variables to a regression model as estimating coefficients on irrelevant variables that are truly zero. Then if you do this the estimators of our regression coefficients are still unbiased, but also inefficient since we did not consider (true) zero restrictions on the coefficients of the irrelevant variables. Hence, inference stays valid but confidence intervals become broader. (Literature: basically any econometrics textbook, e.g. Wooldrige). (3) Additionally (related to prediction) If you are solely interested in prediction performance of a model based on your training data then adding 'irrelevant' variables to your model is less harmful ( irrelevant in the sense of being not causal and not in the sense of having true zero restrictions on the coefficients). As the overspefication of your model only becomes problematic if you want to do inference (broader confidence intervals). (Have a look in the causal machine learning literature).
