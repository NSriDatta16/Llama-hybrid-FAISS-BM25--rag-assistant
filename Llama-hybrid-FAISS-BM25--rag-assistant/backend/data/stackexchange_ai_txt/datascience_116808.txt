[site]: datascience
[post_id]: 116808
[parent_id]: 
[tags]: 
What is the math behind the Keras Tokenizer() function?

I am doing an essay on the mathematics behind a text classifier with NLP and neural networks and I would like to know how exactly the TOKENIZER function of Keras works. Whether cosine similarity is involved and how the dictionary creation is carried out taking frequency into account. If anyone knows the answer or a book/article where it is reflected, I will be eternally grateful. MAX_NB_WORDS = 50000 MAX_SEQUENCE_LENGTH = 250 tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!"#$%&()*+,-./:; ?@[\]^_`{|}~', lower=True) tokenizer.fit_on_texts(data['Consumer complaint narrative'].values)
