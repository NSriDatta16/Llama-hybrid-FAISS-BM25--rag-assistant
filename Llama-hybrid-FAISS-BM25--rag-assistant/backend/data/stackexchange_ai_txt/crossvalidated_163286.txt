[site]: crossvalidated
[post_id]: 163286
[parent_id]: 163242
[tags]: 
I'm going to be a little bit of a punk here and answer the question, "Why isn't independence checked in a one-way analysis of variance?" with the semi-sarcastic answer, "Because it's a one-way analysis of variance." But maybe this will be more helpful than it at first sounds. As a side note, if you interpreted your one-way factor as having a random effect, then the theory would give you a specific correlation structure, i.e., a departure from i.i.d. data. But let's stick with the fixed effects interpretation, where we could estimate the means and then use the residuals to search for some deviation from i.i.d. data. There is no test for arbitrary departures from the i.i.d. case , so you're going to have to impose some structure. Maybe there's a time index, or some other variable, included in the data set that you could plot your residuals against to search for patterns. Or, as @gung suggested, maybe there's a patient id that's repeated in the data set, and you could compute a Crombach's alpha or something to gauge the dependence. But you're in chapter 3 (or whatever) in your textbook, and I doubt those variables are in the data set given to you! Going deeper, even in the more empirical branches of data science such as machine learning, the assumption of i.i.d. data from some distribution underlies the theory. That is, there's some faith involved. This is used as ammunition by some critics of mainstream statistics (e.g. Nassim Nicholas Taleb) and some other practitioners I've met who feel that the i.i.d. assumption rarely holds.
