[site]: crossvalidated
[post_id]: 86810
[parent_id]: 
[tags]: 
Minimizing the sum of squares of autocorrelation function of residuals instead of sum of squares of residuals

I am trying to fit my multi-exponential model to some experimental data and I am using a simulated annealing algorithm. My objective function has so far been the sum of squares of the residuals: $\sum_{i=1}^n (y_i - \hat{y_i})^2 = \sum_{i=1}^n e_i^2 \:\:$ ...(1) However, it came to my attention that maybe I could set my objective function to be the sum of squares of the autocorrelation function of the residuals, with lag $j$: $\sum_{j=1}^m R^2_{j} = \sum_{j=1}^m \left( \sum_{i=1}^n e_i\,\overline{e}_{i-j} \right)^2 \:\:$ ...(2) Does that make sense? It seems like forcing the autocorrelation of the residual terms to be small may lead to wrong parameter estimates. I haven't rigorously proven this, but I suspect that minimizing (2) does not mean that (1) is minimized. Any ideas?
