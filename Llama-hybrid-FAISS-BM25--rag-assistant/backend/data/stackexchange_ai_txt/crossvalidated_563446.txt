[site]: crossvalidated
[post_id]: 563446
[parent_id]: 563345
[tags]: 
I really like the following figure from Daniel, Kenward, Cousens, & De Stavola (2012) that gives an intuitive view of why Missing At Random (MAR) given X is not a problem, but MAR given Y is a problem. (NOTE that this figure uses the symbol A instead of X for the predictor.) For the sake of illustration this figure shows an exaggerated situation where the missingness is either 0% or 100%, depending on the value of an observed variable. But the same principles hold in more realistic cases where missingness depends in a more fuzzy way on the observed variables. The top panel shows MAR given X. In this situation, the efficiency/precision of the slope estimate is certainly lower, but the average estimate is the same as it would be if there were no missing data. The bottom panel shows MAR given Y. Here the average slope estimate is not the same as it would be if there were no missing data -- that is, it's biased. That's because the missing large Y values lead the OLS slope estimates to be too shallow. This figure can also be used to illustrate why even certain kinds of Missing Not At Random (MNAR) are not a problem either, although I won't get into that right now. If you want to understand this better, you may be interested in this old blog post I wrote on the topic: Using causal graphs to understand missingness and how to deal with it
