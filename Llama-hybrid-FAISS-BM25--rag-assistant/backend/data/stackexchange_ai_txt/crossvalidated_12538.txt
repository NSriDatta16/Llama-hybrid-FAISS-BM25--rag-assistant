[site]: crossvalidated
[post_id]: 12538
[parent_id]: 12378
[tags]: 
I think the problem may be one of model mis-specification. If your targets are angles wrapped to +-180 degrees, then the "noise process" for your data may be sufficiently non-Guassian that the Baysian evidence is not a good way to optimise the hyper-parameters. For instance, consider what happens when "noise" causes the signal to wrap-around. In that case it may be wise to either perform model selection by minimising the cross-validation error (there is a public domain implementation of the Nelder-Mead simplex method here if you don't have the optimisation toolbox). The cross-validation estimate of performance is not so sensitive to model mis-specification as it is a direct estimate of test performance, whereas the marginal likelihood of the model is the evidence in suport of the model given that the model assumptions are correct. See the discussion starting on page 123 of Rasmussen and Williams' book. Another approach would be to re-code the outputs so that a Gaussian noise model is more appropriate. One thing you could do is some form of unsupervised dimensionality reduction, as there are non-linear relationships between your targets (as there are only a limited way in which a body can move), so there will be a lower-dimensional manifold that your targets live on, and it would be better to regress the co-ordinates of that manifold rather than the angles themselves (there may be fewer targets that way as well). Also some sort of Procrustes analysis might be a good idea to normalise the differences between subjects before training the model. You may find some of the work done by Neil Lawrence on human pose recovery of interest. I remember seeing a demo of this at a conference a few years ago and was very impressed.
