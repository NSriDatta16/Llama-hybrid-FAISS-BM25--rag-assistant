[site]: crossvalidated
[post_id]: 230439
[parent_id]: 
[tags]: 
Correct sequence of model interpretation

My question is: what is the right sequence of analyzing? And is it the right way to ggplot errorbars from that model? 1) Setup model I expect possible interactions between treatment, race, age and time, so i start with the full model: dependent variable ~ time * treatment * race * age, random=~subject time: 7 time points(1min, 2min, ... to 7min) treatment: treatment and no treatment race: race1 and race2 age: age1 (10 months old) and age2 (20 months old) subject: random factor for repeated measures within one subject So far i'm doing it the following way (with R): I'm interested in the change of dependent variable over time in dependence of age, race, and treatment (all with possible interactions) so i set up a model: library(nlme) model 2) I try to justify the model (I use either a or b. What is better / enough?) Is it justified to use a, even though i continue using the lme-function from the library(nlme)? That's why i rather tend to use version b... a) glmmMCMC(dv ~ time * treatment * race * age, random=~subject, data=mydata) pMCMC is time time * treatment time * treatment * age time * treatment * age * race (only for some dv = dependent variables) Does is justify the full model (dv ~ time * treatment * race * age) for all dependent variables, even those who are not significant for the last row of pMCMC-values? Or do i need to setup a new model? model.new for those dv, where the last line is not significant And do i need to adjust those p-values? Because i got a a lot of them (each fixed effect alone and each combination). Or is it already adjusted or doesn't need to have its p-values adjusted after this b) comparison with reduced models a.null = lme(dv ~ 1, random = ~1|subject, data=mydata, method="ML") a.1 = lme(dv ~ time, random = ~1|subject, data=mydata, method="ML") a.2 = lme(dv ~ time * treatment, random = ~1|subject, data=mydata, method="ML") a.3 = lme(dv ~ time * treatment * race, random = ~1|subject, data=mydata, method="ML") a.4 = lme(dv ~ time * treatment * race * age, random = ~1|subject, data=mydata, method="ML") anova(a.null, a.1, a.2, a.3, a.4) All models excepct a.1 are significant (each compared to the previous model) --> enough justification of the model? Do i need to adjust the p-values from the anova results? 3) I check for assumptions to use the LMM instead of the GLMM: hist(scale(residuals(model))) ---> check for normal distribution qqnorm(scale(residuals(model))) ---> check for normal distribution plot(fitted(model),residuals(model)) --> check for homoscedasticity the breadboard does not indicate to collinearity between time, treatment, race, age According to the graphs, there are no obvious violations of the assumptions needed for the linear mixed effect model. (If there are in some cases, i add a weights factor, in order to continue using the linear mixed model instead to switch to the GLMM, because there are some packages i want to use that i can only use with the LMM) 4) Visualisation library(ggplot2) ggplot(mydata, aes(time, dv, color = treatment)) + stat_summary(fun.y = mean, geom = "line") + stat_summary(fun.data = mean_se, geom="pointrange") + facet_grid(race ~ age) Is this the right use of error-bars? I think not, because the ggplot does not account for repeated measures, and thus the error_bars are way too small... So what would be the correct way of plotting error_bars into this ggplot? edit: I have 4 dependent variables dv1, dv2, dv3 and dv4. The statement in 2)a) "time * treatment * age * race (only for some dv = dependent variables)" could be read as followed: For some dependent variables i got significant pMCMC-values for time * treatment * age * race, for others not. Am i still allowed to use the full model in those cases?
