[site]: crossvalidated
[post_id]: 402175
[parent_id]: 266359
[tags]: 
This is still a matter of debate and it also depends strongly on the algorithms you're using. For example, if you're using Lasso for feature selection, all of the features should be on the same scale and standardization of binary features is recommended (see The Elements of Statistical Learning by Tibshirani et al.: http://web.stanford.edu/~hastie/ElemStatLearn/ ). Logistic regression doesn't profit as much from normalization of binary variables: Should you ever standardise binary variables? . Interestingly enough, Andrew Gelman suggested standardizing all numeric variables by dividing with two times the standard deviation and leave binary variables as they are, such that you can interpret and compare the influence of the regression coefficients more easily: http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf .
