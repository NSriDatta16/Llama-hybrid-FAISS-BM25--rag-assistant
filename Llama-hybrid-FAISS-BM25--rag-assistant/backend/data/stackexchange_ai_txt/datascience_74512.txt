[site]: datascience
[post_id]: 74512
[parent_id]: 
[tags]: 
Tensorflow hub module taking long time for embedding single sentence

I am using universal sentence encoder from tensorflow hub to encode sentence into embedding. import tensorflow_hub as hub import tensorflow as tf module_url = "https://tfhub.dev/google/universal-sentence-encoder/1?tf-hub-format=compressed" def get_emb(text): embed = hub.Module(module_url) similarity_input_placeholder = tf.placeholder(tf.string, shape=(None)) similarity_message_encodings = embed(similarity_input_placeholder) with tf.Session() as session: session.run(tf.global_variables_initializer()) session.run(tf.tables_initializer()) message_embeddings_ = session.run(similarity_message_encodings, feed_dict={similarity_input_placeholder: text}) tf.reset_default_graph() return message_embeddings_ Now the problem is each time I call the function the time is taking is about 10 seconds which is very high. Is there a way to save the model or something and do it instantly. This will be used in restful service where the response should be near instant
