[site]: crossvalidated
[post_id]: 418228
[parent_id]: 
[tags]: 
Sampling from joint distribution by writing its density as a product of conditional densities

In Gelman et al. "Bayesian Data Analysis Ed3" the authors often do the following (e.g. on pg. 65): Given two parameters $\mu$ and $\sigma^2$ and data y joint posterior density $p(\mu,\sigma^2)$ is derived and then factored as $p(\mu,\sigma^2)=p(\mu|\sigma^2,y)⋅p(\sigma^2|y)$ . In this case the distributions described by $p(\mu|\sigma^2,y)$ and $p(\sigma^2|y)$ are known, e.g. they are normal or any other common distribution; the point is that we can draw samples from them. Now, the authors claim that we can first draw a sample from $p(\sigma^2|y)$ and then use it to draw a sample from $p(\mu|\sigma^2,y)$ to obtain a sample from the joint posterior. Intuitively, that makes sense. However, I am having difficulties to translate the intuition to a rigid mathematical reasoning. Why is a sample drawn as described above a sample from the distribution with density $p(\mu|\sigma^2,y)⋅p(\sigma^2|y)$ ?
