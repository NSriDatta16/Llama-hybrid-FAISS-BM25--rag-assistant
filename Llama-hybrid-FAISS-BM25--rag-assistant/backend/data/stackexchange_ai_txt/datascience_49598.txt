[site]: datascience
[post_id]: 49598
[parent_id]: 49587
[tags]: 
Usually, we report mean and variance for k-fold crossvalidation and similar techniques. We run the model multiple times in different data, but that can be applied to the second case too as, for example, a Neural Network can be initialized with random weights multiple times for test in the model. If the paper does not explicitly say that they re-splited the dataset, then is more likely that this variance comes from random initialization. You should read the experimental procedures used and try to determine all sources of variance for papers results. So it might be either or a combination of both dataset random splits and model random initialization
