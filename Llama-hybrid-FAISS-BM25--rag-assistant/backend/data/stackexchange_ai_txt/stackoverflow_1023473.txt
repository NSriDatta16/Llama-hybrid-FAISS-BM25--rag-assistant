[site]: stackoverflow
[post_id]: 1023473
[parent_id]: 1020847
[tags]: 
I'm somewhat exaggerating when I say they're evil. For very large data sets, even when they fit within a single database, joining is an expensive operation (lots of non-sequential IO). With a typical web-app load (90/10 read/write), your reads need to be as cheap as possible, while you can spend more time on writes (and lazily replicate writes in many cases). In a typical high-performance web-app, you're going to want to perform all database IO within a couple of hundred milliseconds, so that's your first limit. Secondly, you want to be able to do plenty of concurrent requests. This tends to point to being able to collect records straight from index for large tables. Someone already mentioned that you don't need to send a ton of data to the browser, so performing the join across the whole dataset isn't needed, but consider ordering: if you can't get the records in the correct order straight from index, you're going to need to perform the entire join before ordering the results. For multi-machine partitioned data, the same problems apply but on a larger scale. The usual solution is materialized views (data flattening) to enable join-like queries by performing multiple writes at insert/update/delete time (or lazily afterward) and using very simple indexed selects. It's obviously the case that joins are useful and are perfectly good most of the time. But for large datasets in a database that doesn't natively support materialized views, this falls down at high concurrency on large datasets. And the specific complaint about Django is that because of the inflexibility in changing models on existing data, people are encouraged to create 1-to-1 mapped tables which are only ever joined against, rather than adding columns to existing tables.
