[site]: crossvalidated
[post_id]: 363098
[parent_id]: 
[tags]: 
What does that mean if neural network never overfits on a dataset?

I'm trying to predict a parameter with use of neural networks. The parameter is highly linearly correlated with some of its predictors (Pearson's r~0.9)(However, the influence of time may not be linear/trivial). I use a network with one hidden layer and it never overfits. Very often I get two smooth parallel lines of training and test errors that go close to each other. I expect that may mean that the train and test sets are very similar. They contain over 2500 units of every parameter. However, in what way are these sets similar? Also, does that mean that the influence of time on the prediction is linear as well? ( I cannot beat MLR with the ANN - although I get close to it)
