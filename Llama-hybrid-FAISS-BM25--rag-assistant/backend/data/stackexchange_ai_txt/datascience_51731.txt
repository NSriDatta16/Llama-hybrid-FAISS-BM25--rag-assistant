[site]: datascience
[post_id]: 51731
[parent_id]: 
[tags]: 
why does performance of machine learning models plateau after certain amount of training data

I'm referring to the below image which I came across. The explanation seemed intuitive at first but I don't think I understand how it works. The image says that the performance of traditional machine learning algorithms plateau after a certain amount of data while that of deep learning algorithms gets better with more data. Does it have to with the feature learning where deep learning methods automatically learn the important features as opposed to the manual feature selection for machine learning models? If so, can you please elaborate on that.
