[site]: crossvalidated
[post_id]: 70258
[parent_id]: 
[tags]: 
Deep Belief Network (number of layers)

So we have "several RBMs" Deep Belief Network A deep belief network is obtained by stacking several RBMs on top of each other. The hidden layer of the RBM at layer `i` becomes the input of the RBM at layer `i+1`. The first layer RBM gets as input the input of the network, and the hidden layer of the last RBM represents the output. When used for classification, the DBN is treated as a MLP, by adding a logistic regression layer on top. but why more RBM's don't means better? How to determine best number of layers? Seems related: Deep belief network performs worse than a simple MLP
