[site]: crossvalidated
[post_id]: 417133
[parent_id]: 
[tags]: 
empirical standard deviation and model standard errors in simulation studies

I'm running a simulation in meta-analysis to compare two methods that estimate the same problem parameters. One of them is a likelihood-based approach. In this kind of problems, one has to fix in advance a number of parameters, such as nn number of data sets we need to apply the method on, the true value of the parameters, etc. In the end, I stored a matrix with the estimates of parameters in my case 5 (the matrix is called estimas, dimension nn*5) and matrix of standard errors (the matrix is called st_err). Then I eventually compute for each estimate the mean of model based s.e. and the empirical standard deviation. st_error In practice these two should be very close, being this a signal that the simulation exercise is correct. My results are not that encouraging. For instance for one of the parameters I get, Empirical standard error Model-based standard error: 1.3660 4.7237 0.9370 1.1601 0.6553 0.5365 In one case they are way too different. Can anyone provide insight into why this is happening? Sorry for the long message. This is the code for the likelihood function: lik.to.optim As you can see se and st. dev get further as I increase the sample size. I don't get why.
