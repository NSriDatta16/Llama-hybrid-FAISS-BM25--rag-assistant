[site]: datascience
[post_id]: 80807
[parent_id]: 
[tags]: 
How to utilize measurement accuracy metadata in classifier

Given that one wants to ascribe a class to groups of measurements using a classifier model, in what way can one include information about measurement accuracy? More specifically, is there a feature engineering strategy for including information with the intent to allow the model to weight a subset of the sample more than other subsets? As an example, say I have have coordinate and accuracy information (lat, lon, measurement_accuracy) in a time-series. I want to make a classifier which takes a group of 2 coordinate pairs, and output a class from this group. Each sample therefore consists of 2 coordinate pairs. The measurement accuracy could be used to indicate to the model which of these measurements should be trusted most, but does not by itself give any hint towards the class the sample belongs to. given the 3 samples [ # learn to trust the first coordinate set more in making a prediction {'lat': 11, 'lon': 40, 'acc': 5}, {'lat': 9, 'lon': 40, 'acc': 2} ], [ # learn to trust the second coordinate set more in making a prediction {'lat': 74, 'lon': 131, 'acc': 1}, {'lat': 78, 'lon': 140, 'acc': 4} ], [ # learn to treat these coordinates approx. equally {'lat': 74, 'lon': 131, 'acc': 1}, {'lat': 78, 'lon': 140, 'acc': 1} ] and assuming acc is an indication of the coordinate pair measurement accuracy I would like the model to trust the first coordinate pair more in the first sample, trust the second one more in the second sample, and in the third sample trust both coordinate pairs equally. What kind of a representation of the data could enforce this logic, given that the data will be fed into the model in a tabular way?
