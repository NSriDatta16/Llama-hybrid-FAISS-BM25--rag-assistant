[site]: datascience
[post_id]: 62832
[parent_id]: 62820
[tags]: 
R2 and encoding before split are both can be misleading. At first, target encoding, I wouldn't recommend to do it before the split - this is basically target leak. There're at least two major downsides of doing target encoding before split: 1) Overfitting - putting knowledge about your target into features during training always tend to overfit. 2) Impossible to do the same in production. Handling unseen categories is the thing which should be supported in production as well. Running well-done N-fold cross-validation can help you check how are you handling unseen categories "in average". There's a good example of target encoding I always share if anyone asks me about this technique. Also for highly skewed data, I can suggest using log(y) when you encoding your feature, that may help as well. Also, I would recommend reading about R2 (from my experience it's very bad metrics for non-linear problems): - Why R Squared is Useless? - another post about R2 I would rather use MAPE/MAE or some metric which fits your task. Looking at your distribution, I guess it shouldn't be sensible to outliers.
