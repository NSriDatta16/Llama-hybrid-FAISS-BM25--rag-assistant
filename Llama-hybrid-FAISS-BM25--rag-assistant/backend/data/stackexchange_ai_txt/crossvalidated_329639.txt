[site]: crossvalidated
[post_id]: 329639
[parent_id]: 
[tags]: 
Why does changing factor level order of a categorical predictor affect significance of continuous predictors in a linear model with interactions?

Although I am asking this question using R , I imagine it is potentially applicable more broadly in linear modelling, so I think general explanations are also really helpful. I have a dataset with a binomial response, two continuous predictors, a categorical predictor, and a random effect of block. I have a model structure like this: response~cont1 + cont2 + cat + cont1:cont2 + cont1:cat + cont2:cat + (1|block) After running this model once, I decided that I wanted to reorganize the levels of the categorical predictor so that a different one was alphabetically first. R and lme4 pick the alphabetically-first level of a categorical predictor to incorporate in the intercept, and for the second model, I needed the last one of my levels (alphabetically) to be first. In looking at the results of both of these models, I noticed that the significance of the main effects of my continuous predictors (as well as their slopes) changed when I altered the order of levels of my categorical factor. My question is: Why does that happen? I would expect that the intercept would change, as well as the pairwise comparisons between the levels of the categorical predictor, but I didn't expect anything to change with my continuous predictors. After doing some troubleshooting, I have discovered that removing the interaction terms erases any differences in the significance of the predictors between the two factor-level ordering schemes. This makes me think it is something about how the model is parsing the variation in the continuous predictors, but I really have no idea. I also tried the model with a simple lm style linear model, and get the same pattern of results, so I don't think it is specific to GLMMs. Any thoughts would be very much appreciated. Thanks! Also, a reproducible example is below. This is using a publicly-available dataset, and please ignore that the models may not be relevant to the data themselves, as I just wrote it quickly to replicate the issue that I am seeing in my data, and didn't pay attention to what the different columns of data actually are. #Data for example can be downloaded here: #https://github.com/lme4/lme4/blob/master/inst/testdata/gopherdat2.RData load("gopherdat2.RData") #Needed libraries library(lme4) library(car) #I need a categorical predictor, so for the purposes of this model, I will use year as categorical Gdat$yFac
