[site]: crossvalidated
[post_id]: 387767
[parent_id]: 
[tags]: 
Average time series forecast errors from cross-validation with rolling origin

I'm calculating the MAPE and RMSE over a rolling origin cross-validation with fixed forecast interval for several models. For example, for a daily series with 3 years, I'm training my model with 2 years and generating 10 rolling forecasts with 30 days each, cutting off by month. I'm trying to decide which model is the best using the cross-validation, but instead of having only one out of sample error value for each model, as it would be the case for a fixed out of sample error, I have N. How can I combine the rolling origin forecast errors into a single metric to decide which is the best model?
