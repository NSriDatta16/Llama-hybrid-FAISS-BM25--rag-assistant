[site]: crossvalidated
[post_id]: 116700
[parent_id]: 
[tags]: 
Is this problem Bayesian? And can I use variational approximation?

Suppose there are $N$ samples of observations $\mathbf X(n)$ ($n=1,\cdots,N$), which are given by probability distribution $p(\mathbf X(n)|\mathbf Z(n))$ with their conditions are given by hidden random variables $\mathbf Z(n)$. Also suppose the hidden variables $\mathbf Z(n)$ are i.i.d and generated from distribution $p(\mathbf Z(n)|\Theta)$ given by a parameter set $\Theta$, which is deterministic. I want to estimate the parameter set $\Theta$ to maximize the mariginal likelihood $\prod_{n=1}^N p(\mathbf X(n)|\Theta)$. My questions are: Point optimization of hyperparameters in Bayesian framework is referred to empirical Bayes . Still, is it appropriate to regard this problem as an empirical Bayesian problem? In many Bayesian problems I've seen, the hidden variables $\mathbf Z(n)$, behaving as parameters of the observation $\mathbf X(n)$, are usually constrained, for example, by Markov chain; \begin{equation} p(\mathbf Z(1:n)|\Theta)=p(\mathbf Z(1)|\Theta)\prod^{N}_{n=2} p(\mathbf Z(n)|\mathbf Z(n-1),\Theta), \end{equation} or constrained to be common through all the samples; \begin{equation} \mathbf Z(n)=\mathbf Z. \end{equation} So this problem looks slightly different because the hidden variables $\mathbf Z(n)$ are i.i.d. Because the integral to obtain the marginal distribution $p(\mathbf X(n)|\Theta)$ does not have an analytical form, I'm thinking of the use of variational approximation regarding \begin{align} p(\mathbf Z(n)|\mathbf X(n),\Theta) &\approx \prod_i q(\mathbf Z_i(n)|\mathbf X(n),\Theta), \\ q(\mathbf Z_i(n)|\mathbf X(n),\Theta) &\propto \exp\left\langle\log p(\mathbf Z(n),\mathbf X(n)|\Theta)\right\rangle_{\prod_{j\neq i}q(\mathbf Z_j(n)|\mathbf X(n),\Theta)}, \end{align} where $\mathbf Z_i(n)$ is the subset of $\mathbf Z(n)$, and the use of an EM algorithm with an auxiliary function $Q(\Theta,\bar\Theta)$ is given by \begin{equation} Q(\Theta,\bar\Theta) = \sum_{n=1}^N \int \left(\prod_i q(\mathbf Z_i(n)|\mathbf X(n),\bar\Theta)\right)\log p(\mathbf X(n), \mathbf Z(n)|\Theta) d\mathbf Z(n). \end{equation} Is this strategy appropriate? My concern is that the variational independence assumption in the i.i.d. case might be much stronger than that in the case where Z(n) is constrained to be common through all the samples; \begin{align} \mathbf Z(n) &= \mathbf Z, \\ p(\mathbf Z|\mathbf X(1:n),\Theta) &\approx \prod_i q(\mathbf Z_i|\mathbf X(1:n),\Theta), \end{align} or constrained by Markovian chains. I'm wondering if the parameter estimation works properly in the i.i.d. case with more freedom in the optimization of $q(\mathbf Z_i(n)|\mathbf X(n),\Theta)$. Leading to related articles is also appreciated.
