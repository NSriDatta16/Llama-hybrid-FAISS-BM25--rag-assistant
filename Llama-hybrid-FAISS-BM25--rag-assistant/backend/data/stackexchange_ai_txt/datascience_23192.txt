[site]: datascience
[post_id]: 23192
[parent_id]: 5893
[tags]: 
An approach I have used to build a stopword list is to build and train a logistic regression model (due to its interpretability) on your text data. Take the absolute value of the coefficients for each token. Then, sort descending the absolute value of the coefficients of the tokens. Then, create a list of all the tokens with high coefficient absolute value that might lead to overfitting or that might meet some other criteria to be a stopword. That list is your stopwords list. You can then apply that stopword list to another set of documents of this type (kind of like a test set), to see if removing them increases the accuracy, precision, or recall of the test set model. This strategy is effective because it takes into account the impact of tokens when building a stopword list.
