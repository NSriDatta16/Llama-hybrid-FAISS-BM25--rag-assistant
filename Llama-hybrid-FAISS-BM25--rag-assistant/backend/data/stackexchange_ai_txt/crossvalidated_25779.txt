[site]: crossvalidated
[post_id]: 25779
[parent_id]: 
[tags]: 
Lag Selection Modelling 'Pseudo' Panel Data

I have what I would call a pseudo panel, where my dependent variable varies over time and space (regional death counts), but my x variable of interest does not (national wage time series). Basically, I want to look at the effect of real wage variation on mortality, so $\log (D_{it})=f(\log (W_{t}))$. However, I have run into some problems. Here are the steps I have taken, and the problems (as I see) with them. I am looking for suggestions as to what is the best way to model 'long panel' data in this form. I cannot find any references on the topic of modelling a panel variable which does not vary in the cross-section. Pooled OLS using first differences. There are a few problems here. Firstly, there is no good way to choose the lag length. In a time-series setting, I would just use the AIC or BIC. In this application, the model can always be 'improved' by adding lags. Similarly, since the errors are autocorrelated, I have added a lagged dependent variables. Again, I am able to add a huge number of these variables while once again 'improving' the model fit but failing to tackle the autocorreltation! What makes this worse is that all the coefficients are meaningful, with elasticities in excess of 0.2 (and also very high t-ratios!). There does not seem to be a good way of deciding model specification in this model. The second approach I have taken is to model each mortality series separately as a Dynamic Linear Regression using the R-package DLM. In this analysis, I leave the mortality variable in raw levels form since the intercept is a Markov-Chain. The effect of the real wages is also time-varying so, in effect, I am calculating the effect in each district for each time-period. So the results would be a distribution of effects. This procedure works well (to an extent) as there is no autocorrelation in the residuals. However, I am unsure running over 400 separate regressions is a good modelling strategy, since it is highly inefficient. I tried a seemingly unrelated time series regression, using Bayesian inference (Gibbs with d-inverse gamma priors), but this procedure took a long time to run, and yielded some strange answers.
