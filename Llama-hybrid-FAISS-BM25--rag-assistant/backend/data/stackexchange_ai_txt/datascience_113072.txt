[site]: datascience
[post_id]: 113072
[parent_id]: 
[tags]: 
Is gradient descent useful to get the least mean squared error in linear regression?

I am new to machine learning. I have read about the linear regression where-in the ideal model is a line which has the least mean squared error. In multi-variable linear regression we would have a plane instead of the line. However the goal is the same - least mean squared error. This is calculated as the sum of squared distance between the value and the line, divided by the number of samples. I then read about gradient descent which is a technique to reduce the loss. So the example showed a loss function with y-axis as loss and x-axis as model params. I'm trying to understand the relation between gradient descent and linear regression's least mean squared error.
