[site]: crossvalidated
[post_id]: 471631
[parent_id]: 
[tags]: 
How is the law of total probability used here?

Consider a Markov chain $\{X_n, n = 0, 1, \dots\}$ . The probability of going from one state $i$ to state $j$ in two steps is $p_{ij}^2 = P(X_2 = j | X_0 = i)$ . Then by the law of total probability we have: $p_{ij}^2 = P(X_2 = j | X_0 = i) = \sum _{k \in S}P(X_2 = j | X_1 = k, X_0 = i) P (X_1 = k | X_0 = i)$ . How is $P(X_2 = j | X_0 = i) = \sum _{k \in S}P(X_2 = j | X_1 = k, X_0 = i) P (X_1 = k | X_0 = i)$ by the law of total probability? The law of total probability says that if $\{B_i\}$ is a partition of the sample space $S$ , then for any event $A$ we have $P(A) = \sum P(A \cap B_i) = \sum P(A | B_i)P(B_i)$ . I'm having trouble seeing how this is used here. Does anyone have an explanation?
