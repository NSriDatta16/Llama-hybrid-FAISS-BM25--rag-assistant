[site]: crossvalidated
[post_id]: 47212
[parent_id]: 47209
[tags]: 
It might be a data issue and not a classifier issue (Neural Networks, Logistic Regression ..etc) problem, because when data has a shape ( say it could be divided into two classes ) 800 points should be fine as training set. It might be that the decision boundary is a funny one (Not linear for example), have you tried to play with the Neural Network classifier parameters such as the number of hidden layer ..etc? The problem with Neural networks is that the objective function is not always a convex function which translates into a bad parametrization of the classification problem. Have you tried kernel methods ( this is supposed to do a transformation on your data, in some cases this allows you to have an infinite number of feature if you use a suitable kernel ), you can use SVM for example, this is how it works: ###################################### # svm ###################################### Svm = svm(Species ~ ., data = train,type = "C-classification",kernel = "polynomial",degree = 1, gamma = 2, cost = 0.5, coef0 = 2) SvmPr = predict(Svm,test) table(as.vector(SvmPr),iris[-tr,5]) And, once again, you should know what the classifier parameter are meant to do and have a play around with them. HTH D
