[site]: crossvalidated
[post_id]: 363317
[parent_id]: 361378
[tags]: 
I've found a solution that works reasonably well. Rather than testing with Chi Square, to see if two variables are similar, I instead take a sample of the data, split it into "train" and "test" subsets, and then fit a Support Vector Machine or a Naive Bayes classifier, using one variable as an outcome and one as a regressor. I then use the classifier to predict on the "test" dataset and see how well the predicted values match the actuals. If the match is sufficiently high, I consider these two variables to be potentially redundant. I've put this test into an algorithm, using a while loop that grabs a reference variable (dependent) from the full list of categoricals, and a for loop that fits these test models on the remaining variables, testing for redundancy. At each step of the while loop, I remove any variables which were predicted strongly from consideration in the next step, and save the flagged redundant variables. SVM performs a little better with my data, Naive Bayes however takes only 10% as long to run.
