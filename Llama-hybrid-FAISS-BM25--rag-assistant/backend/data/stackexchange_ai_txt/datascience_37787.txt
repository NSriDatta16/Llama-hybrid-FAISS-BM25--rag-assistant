[site]: datascience
[post_id]: 37787
[parent_id]: 
[tags]: 
What is layout of weights

I'm working on neural networks. I have one very important question. For instance, there are two layers with 2 neurons in each. They are all fully connected. Which neurons do the weights belong to? Do they belong to neurons in next layer or the layer preceding it? Moreover, when weights are saved in Keras, are they saved for each neuron completely or they are saved as linknumber(first weight of every neuron)? I hope I'm able to clarify my question
