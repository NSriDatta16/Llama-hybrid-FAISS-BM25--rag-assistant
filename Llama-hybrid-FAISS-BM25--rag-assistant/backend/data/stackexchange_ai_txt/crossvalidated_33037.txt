[site]: crossvalidated
[post_id]: 33037
[parent_id]: 32958
[tags]: 
Rather than one-versus-all, you may want to try methods that deal with multi-class outcomes directly: multinomial regression (glmnet package in R), the pamr package (shrunken centroids), random forests (randomForest) to name a few. I don't know of any packages that implement one-versus-all for you, but it is simple enough to code. For example, with leave-one-out cross validation, we would: hold out one observation fit all possible binary models (class 5 versus 1,2,3,4) the model must output a score (such as a predicted probability) obtain all scores for the models applied to the held out sample choose the class with highest score as the predicted class I find this procedure awkward, but it seems to be used often, and it is also mentioned briefly in Hastie (Element of Statistical Learning) with respect to support vector machines.
