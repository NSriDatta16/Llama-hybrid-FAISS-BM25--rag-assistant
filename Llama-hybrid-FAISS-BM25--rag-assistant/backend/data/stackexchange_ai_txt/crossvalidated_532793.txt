[site]: crossvalidated
[post_id]: 532793
[parent_id]: 
[tags]: 
What exactly does transformer encoder + linear layer return?

I was following a Pytorch tutorial on transformers in language modelling ( https://pytorch.org/tutorials/beginner/transformer_tutorial.html ) and I came across a bunch of questions. My goal is to make a sequence classifier. But first, let's agree on used symbols: Input: [ B x N ] Output: [ B x N x P ] N - number of words in input sequence (words dim) B - batch dim P - logits What exactly does the particular model return? When I feed it with a sequence of N length (in one batch), it returns always a B x N x P array. But why N dim is not just size 1 but size of the input sequence? The aim is to achieve class prediction. If the last layer is Linear, shouldn't I get just one vector of logits instead of N vectors? (I mean, an array of B x 1 x P)? I thought I need a whole transformer decoder block to produce N outputs and a Linear layer would just return logits (classes) (P) and batches (B). So why it returns N outputs and which one should I treat as "class"? def __init__(self, ntoken, ninp, nhead, nhid, nlayers, classes, dropout=0.5): super(TransformerModel, self).__init__() self.model_type = 'Transformer' self.emb = nn.Embedding(ntoken, ninp) self.ninp = ninp self.pos_encoder = PositionalEncoding(ninp, dropout) encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout, batch_first=True) self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers) self.decoder = nn.Linear(ninp, class_count) # two classes def forward(self, src, src_mask=None): src = self.emb(src) * math.sqrt(self.ninp) src = self.pos_encoder(src) output = self.transformer_encoder(src, src_mask) output = self.decoder(output) model = TransformerModel(ntoken=1000, ninp=200, nhead=8, nhid=40, nlayers=2, class_count=2, dropout=0.1).to(device) When fed with: model(to_tensors([[22, 45, 55, 23, 30]])) returns tensor([[[ 2.0076, -1.0457], [-0.7449, 0.9649], [ 0.3181, 0.1880], [ 0.3181, 0.1880], [ 0.3181, 0.1880]]]) instead of e.g. tensor([[[ 2.0076, -1.0457]]]) Thanks in advance for answers.
