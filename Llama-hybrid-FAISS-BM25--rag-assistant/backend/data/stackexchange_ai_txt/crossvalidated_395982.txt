[site]: crossvalidated
[post_id]: 395982
[parent_id]: 333239
[tags]: 
The OP states, "I am interested in whether my empirical data (yellow) "clusters" around the midpoint of the plot more than the simulated data (blue)." This is not a question about kurtosis: kurtosis does not measure "clustering" around the midpoint. Rather, it measures tails of the distribution. (Rare, extreme potentially observable data). Here is a visual image to help understand the above comment. Compute the z-values for each sample. Plot the $z^4$ values for the observed data sample using a dot plot. Now, compute the average of the $z^4$ values for the simulated data; this is the kurtosis of the simulated data. Now, locate the kurtosis of the simulated data as a "fulcrum" on the horizontal axis of your dot plot of your observed data $z^4$ values. If the dot plot "falls to the right," then your observed data have higher kurtosis than the simulated data, and conversely. Now, what causes the "falling to the right"? Is it greater "clustering around the midpoint" of your actual data? Obviously, not, because it falls to the right, not to the left. So, higher kurtosis implies greater tail weight (rare, extreme value(s)), not greater "clustering around a midpoint." If you want to compare "clustering around the midpoint," you might instead consider comparing the difference between 10th and 90th percentiles (or other similar). You could use a bootstrap-type (perhaps smoothed) method to estimate standard error of the difference.
