[site]: crossvalidated
[post_id]: 451094
[parent_id]: 451084
[tags]: 
Of course you can look back in time--but you cannot look forward. That distinguishes the past from the future. The following brief, elementary account uncovers the basic underlying concepts and reveals how "time's arrow" is modeled in statistical applications. The backshift operator isn't limited to stochastic processes: it applies to arbitrary sequences of numbers. Formally, the set of all sequences $(x_t),$ $t\in\mathbb{N},$ is a vector space $\mathbb V$ because sequences can be added and multiplied by constants according to the familiar rules for vectors. An operator $B$ on a vector space is a linear map $$B:\mathbb{V}\to\mathbb{V}.$$ This means $B$ preserves the vector space structure; that is, for all vectors $v,w\in\mathbb{V}$ and numbers $\alpha,\beta,$ $$B(\alpha v + \beta w) = \alpha B(v) + \beta B(w).$$ (Often, square matrices are used to represent operators when a basis is given for $\mathbb V.$ It is rare to do that in time series analysis, though, because such matrices would be infinite.) Consider the particular map $B$ defined by $$B((x_t)) = (x_{t-1}),$$ the "backward shift." (To complete the definition, set $x_{-1}=0.$ ) It is straightforward to check that $B$ is an operator. A discrete-time stochastic process $X$ is a random variable with values in $\mathbb V.$ Formally, this means there is some abstract probability space $\Omega$ and for each outcome $\omega\in\Omega,$ $X(\omega)$ is a sequence. (Recall that a probability space is a set of abstract "outcomes" together with a special collection of outcome sets called "events;" probabilities can be assigned only to events.) Many things we can do to sequences extend to operations on these stochastic processes. In particular, we may compose $X$ with $B$ to obtain a new function $$BX: \Omega \to \mathbb{V};\quad BX(\omega) = B(X(\omega)) = (X_{t-1}).$$ For every $t,$ this replaces the value of $X$ at time $t$ by its value at the immediately preceding time $t-1:$ it "looks back" to construct a forward shift of the sequence. After all, if the original value of $X$ on some $\omega\in \Omega$ were written $$X(\omega) = X(\omega)_0, X(\omega)_1, X(\omega)_2, \ldots, X(\omega)_t, \ldots,$$ then the shifted sequence would be written $$BX(\omega) = 0, X(\omega)_0, X(\omega)_1, \ldots, X(\omega)_{t-1}, \ldots$$ with each term displaced forward (to the right). In the extreme generality posited here, there is no assurance that $BX$ is itself a random variable. We have to add a condition on the space $\Omega$ to assure this. Evidently any such condition would be tantamount to requiring that any event determined by $X$ is also an event for $BX.$ Random variables $Z$ determine events in the sense that they must have distribution functions via the formula $$F_{Z}(x) = \Pr(Z \le x)$$ for all numbers $x.$ In order for that to happen, the set described by " $Z \le x$ " has to be an event. Consequently, the condition needed to conclude $BX$ is a random variable if $X$ is a random variable would be At all times $t,$ the events determined by $X_t$ must be events for $X_{t-1}.$ So that we may freely apply $B$ (and thereby look back into the immediate past to analyze a time series), this condition is usually taken to be part of the definition of a stochastic process (but is usually not mentioned in elementary accounts of the theory). Advanced accounts state this condition in terms of "filtrations of sigma algebras." This avoids having to discuss all possible random variables at once. All possible events at time $t$ for all possible random variables form the sigma algebra $\mathfrak{F}_t.$ The foregoing condition will therefore be satisfied for any process $(X_t)$ provided $$\mathfrak{F}_{t-1}\subset \mathfrak{F}_t$$ for all $t\in\mathbb N.$ That guarantees $B$ can be applied to any time series process to produce another time series process.
