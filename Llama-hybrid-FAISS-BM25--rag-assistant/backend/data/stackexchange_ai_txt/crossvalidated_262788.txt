[site]: crossvalidated
[post_id]: 262788
[parent_id]: 
[tags]: 
Do I have to start logistic regression with weights = 0?

I'm confused about logistic regression cost function. What if in some test data is bad prediction? Then one of the terms in sum is equal to infinity and sum of anything with one infinity member is equal to infinity. It means, that the cost function is also equal to infinity. Here is the cost function: I have an idea and I can't find any proof. The idea is to start with weights equal to zero, then all logarithms have parameters equal to 0.5, then log(0.5) is not infinity and you can run gradient descent or whatever to minimize the cost. Am I right?
