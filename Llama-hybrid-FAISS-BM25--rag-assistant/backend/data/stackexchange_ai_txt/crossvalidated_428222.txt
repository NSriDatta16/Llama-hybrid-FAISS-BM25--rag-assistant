[site]: crossvalidated
[post_id]: 428222
[parent_id]: 
[tags]: 
Neural network vs regression in a small sample

I have a small numeric dataset with 20 observations and 30 variables. I want to approximate Y as a function of the rest 29 Xs(x1,x2,x3...x29). I've tested: neural network (NN) with 1 hidden layer and 7 nodes NN with 0 hidden layers (equivalent to regression without interactions) The reason for testing NN is because it's highly likely interaction to exist among the 29 variables which the NN will capture automatically. When cross validated, the 1st option showed lower MAPE and MPE error % vs the 2nd. Hence I concluded it's a better fit. Is it safe to use NN with so little data? Edit: I am planning to create new data points by using the approximation from the fitted model. I can control and change all Xs. The new data points will be fed back into the observations iteratively (21st observation->refit model->22nd observation-> refit model...->100th observation...). I am facing a cold start problem which I have to somehow overcome.
