[site]: datascience
[post_id]: 108815
[parent_id]: 
[tags]: 
How to serve deep learning model using tensorflow lite

I am trying to serve an image caption model based on flickr8k dataset using TensorFlow lite in the android app. I am new to Android App development and stuck at the below code where I need to provide input to Feature0 and Feature1 to my model. Can someone please guide me how to do so? try { Model3 model = Model3.newInstance(MainActivity.this); // Creates inputs for reference. TensorBuffer inputFeature0 = TensorBuffer.createFixedSize(new int[]{1, 37}, DataType.FLOAT32); inputFeature0.loadBuffer(byteBuffer); TensorBuffer inputFeature1 = TensorBuffer.createFixedSize(new int[]{1, 4096}, DataType.FLOAT32); inputFeature1.loadBuffer(byteBuffer); // Runs model inference and gets result. Model3.Outputs outputs = model.process(inputFeature0, inputFeature1); TensorBuffer outputFeature0 = outputs.getOutputFeature0AsTensorBuffer(); // Releases model resources if no longer used. model.close(); } catch (IOException e) { // TODO Handle the exception }
