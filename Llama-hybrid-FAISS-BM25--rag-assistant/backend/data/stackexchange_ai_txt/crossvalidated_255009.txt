[site]: crossvalidated
[post_id]: 255009
[parent_id]: 253105
[tags]: 
The answer is no. The Q-network's parameters can be updated at once using all examples in a minibatch. Denote the members of the minibatch by $(s_1,a_1,r_1,s'_1),(s_2,a_2,r_2,s'_2),...,(s_M,a_M,r_M,s'_M)$ Then the loss is estimated relative to the current Q-network's parameters: $$\hat{L}(\theta)=\frac{1}{M}\sum_{i=1}^M(Q(s_i,a_i;\theta)-(r_i+\gamma\max_{a'}{Q(s'_i,a';\theta)}))^2$$ This is an estimation of the true loss, which is an expectation over all $(s,a,r)$. In this way, the updating of the parameters of Q is like in SGD. Notes: The estimation is biassed since it does not contain a term representing the variance due to $s'$, but this does not change the direction of the gradient. Sometimes, the second set of parameters $\theta$ in the squared expression is not the current one but a past one (double Q-learning).
