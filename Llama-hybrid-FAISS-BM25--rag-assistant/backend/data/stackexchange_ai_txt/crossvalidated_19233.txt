[site]: crossvalidated
[post_id]: 19233
[parent_id]: 19226
[tags]: 
I would suggest that you define some features, and then pick a machine learning algorithm to apply to those features. Features: Basically, each feature should be something that can be computed from a particular sequence, and that you think may be relevant to whether the sequence has the property or not. Based upon your description, you might consider features such as the following: "Bag of numbers". You might count how many times each possible number appears in the sequence. For instance, suppose each sequence is made out of the numbers 1-30 only. Then you can generate 30 features; the $i$th feature counts how many times the number $i$ appears in the sequence. For instance, the sequence (7 5 21 3 3) generates the feature vector (0,0,2,0,1,0,1,0,...,0,1,0,...,0). "Bag of digrams." A digram is a pair of consecutive numbers. Given a sequence, you can extract all of its digrams. Then you could count how many times each possible digram appears. For instance, the sequence (7 5 21 3 3) has the following as its digrams: 7 5 , 5 21 , 21 3 , and 3 3 . Assuming the sequence is made out of the numbers 1-30, there are $30^2$ possible digrams, so you obtain $30^2$ features. Given a sequence, you can generate this feature vector. "Bag of trigrams." You could also consider trigrams, which is a subsequence of three consecutive numbers from the original sequence. You can do the same as above. If you use the above features, you can then extract $d=30+30^2+30^3$ features from each sequence. In other words, to each sequence, you associate a $d$-dimensional feature vector, which is the collection of features. Once you have this, you can throw away the original sequences. For instance, your training set becomes a bunch of input/output-pairs, where the input is the feature vector (corresponding to some sequence from your training set) and the output is a boolean (indicating whether that sequence had the property or not). Another variation on the above idea is to use "set of X" instead of "bag of X". For instance, instead of counting how many times each number $i$ appears, you could simply generate a boolean that indicates whether the number $i$ has appeared at least once or not. This may or may not give better results. In general, you can experiment with the set of features you use, to figure out which ones give the best results (for instance, maybe you drop the "bag of trigrams"; or maybe you can come up with some other ideas to try). Machine learning algorithm: I'm not qualified to give you advice about how to select a machine learning algorithm; there are many possibilities. But in general you are going to apply the learning algorithm to your training set (the input/output pairs of features/booleans), and try to use it to predict which of the values in the test set have the property. Your selection of machine learning algorithm may depend upon several factors, including how the size of the training set compares relative to $d$ (the number of features). Your best bet may be to try several machine learning algorithms and see which works the best. You might want to include Support Vector Machines (SVMs) as one of the algorithms you try.
