[site]: crossvalidated
[post_id]: 314441
[parent_id]: 314413
[tags]: 
In bayesian inference, when you have some data $x$, you first specify a ${likelihood}$, $p(x|z)$, also called a sampling distribution, which will depend on some unknown parameters $z$ (also called latent variables, going with your notation). We then have to specify a $prior$ on these latent variables, $p(z)$, to completely specify the $data\ generating\ process$. This is called the data generating process as we can imagine first sampling some latent variables from the prior $z^*\sim p(z)$, and then sampling a data point from the likelihood at this sample $z^*$, $x^*\sim p(x|z^*)$. The reason the likelihood is tractable is ${because\ we\ say\ it\ is}$. This isn't specific to bayesian inference either. In frequentist inference you also specify a likelihood (you just don't specify a prior). At some point you need to assume some model for your data so you can actually infer something! In the case of bayesian inference this model is the combination of likelihood and prior.
