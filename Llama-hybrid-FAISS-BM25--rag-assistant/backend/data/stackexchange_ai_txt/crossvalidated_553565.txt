[site]: crossvalidated
[post_id]: 553565
[parent_id]: 
[tags]: 
Machine Learning with Aggregated Frequency Data as Training

I am trying to build a Deep Learning model in which I have the following structure user feature binary_label 1 100 0 2 200 1 3 140 0 ... ... ... 6000000 188 1 But the problem is that when I try to use all data I am running out of memory. Since some users have the same features and labels I rewrote my SQL to select count(user) users, feature, binary_label from table group by 2,3 which returns users feature binary_label 1132 100 0 2 200 1 3435 140 0 ... ... ... 3251 188 1 Since my users are aggregated I cannot parse that as an input as my prediction users would always be one (prediction per user). I think I'd lose value if I only use the feature since I believe the number of users falling in a particular segment adds weight to the prediction model. What would be the best approach to be able to use this column in python? The current model that only uses the feature is X_train, X_test, y_train, y_test = train_test_split( df.feature.values, df.binary_label.values, test_size=.2, shuffle=True) model = Sequential() model.add(Dense(4, input_shape=(1,), activation='tanh')) model.add(Dense(1, activation='sigmoid')) model.compile(optimizer='sgd', loss='binary_crossentropy') model.fit(X_train, y_train, epochs=100) model.evaluate(X_test, y_test) Which when evaluated returns .7
