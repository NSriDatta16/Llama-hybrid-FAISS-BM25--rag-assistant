[site]: crossvalidated
[post_id]: 333639
[parent_id]: 
[tags]: 
In paper “Neighbourhood Components Analysis”, how to determine the optimal number of neighbours (K)?

Recently, I am reading the paper "Neighbourhood Components Analysis" (Goldberger, Jacob, et al. "Neighbourhood components analysis." Advances in neural information processing systems. 2005.). At the last paragraph on the second page of the paper: "Notice that by learning the overall scale of A as well as the relative directions of its rows we are also effectively learning a real-valued estimate of the optimal number of neighbours (K). This estimate appears as the effective perplexity of the distributions $p_{ij}$" 1.Is effective perplexity the perplexity ? 2.I really can't see the reason. How may I get the formulation of K in your paper and connect it to effective perplexity please? 3.The equation of KL-divergence on the Eq.(6) is: "A natural alternative distance is the KL-divergence which induces the following objective function $g(A)=\sum_ilog(\sum_{j\in{C_i}} p_{ij})$" seems different as in other books. How should I understand it? Thank you in advance for your help.
