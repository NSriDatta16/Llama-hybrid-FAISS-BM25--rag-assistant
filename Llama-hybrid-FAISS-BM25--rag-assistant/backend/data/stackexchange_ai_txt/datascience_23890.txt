[site]: datascience
[post_id]: 23890
[parent_id]: 
[tags]: 
Training XGBoost sequentially

I'm currently tring to train a model with XGBoost. My dataset has ~7 million records and 61 columns. The problem I'm currently having is that I get a MemoryError on python when I try to train the model. Investigating on the XGboost documentation I can see that I can train a pre trained model, so I thought I could implement a sequential training dividing my data into smaller pieces. Have anyone already done this? If so, could you please share or recommend the way to do it? I'm currently using the SkLearn XGBClassifier model. Thank!
