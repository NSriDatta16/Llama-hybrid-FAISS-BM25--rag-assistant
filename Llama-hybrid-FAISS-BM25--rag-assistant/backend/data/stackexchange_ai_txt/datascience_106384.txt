[site]: datascience
[post_id]: 106384
[parent_id]: 106381
[tags]: 
I am in a similar boat (although not developing algorithms/libraries, just running DL models on some datasets). My laptop does not have a GPU and DL requires a GPU. So what I do is use free GPU's like Google Colab , Kaggle notebooks , Paperspace to run my models. Most of my time is spent in EDA and feature engineering which does not require a GPU. So while I am performing these tasks I turn off the GPU on the platform I am using. When I actually want to train my model or tune HP, I simply turn on the GPU . This facility is provided by the platform you are using. So basically I am running DL models for free. Although the GPU's provided by these platforms are not that fast but they are enough for most of the people provided you are not working with big data. If you really need something faster, you could buy a subscription of Google Colab (10$ per month). I don't know what kind of GPU you would get for that but it would be much faster than the free version. Another viable option is to rent a VM in Azure . The part where you do not require a GPU you could do that in your local machine and for the part where you require one, only that part you could execute in the VM. For example the EDA, feature engineering, feature selection etc all those steps could be done on your local machine and the actual training and HP tuning could be done on the VM. Hope it helps! Cheers!
