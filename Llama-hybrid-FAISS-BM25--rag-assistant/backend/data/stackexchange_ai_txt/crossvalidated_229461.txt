[site]: crossvalidated
[post_id]: 229461
[parent_id]: 
[tags]: 
Linear regression question on Idempotent matrix and leverage points

I am considering a linear regression model $Y_i = X_i^T \beta + \epsilon_i, i = 1,2,\dots,n$. where $X_i \in \mathbb{R}^p$. $\epsilon_i$'s are independent copies of random error $\epsilon \in \mathbb{R}^1$ with mean 0 and variance $\sigma^2$. We have the hat matrix given by $$ H = X^T (X^TX)^{-1} X$$ I am trying to show $h_{ij}^2 \leq h_{ii} h_{kk}$. I know that $$h_{ij} = X_i^T (X^T X)^{-1} X_j$$ and that $H^2 = H$ because it is idempotent. This gives me $\sum_{k=1}^n h_{ik}^2 = h_{ii}$ but I don't know how to prove $h_{ij}^2 \leq h_{ii} h_{jj}$.
