[site]: crossvalidated
[post_id]: 69639
[parent_id]: 
[tags]: 
Doubts regarding neural network training using k-fold cross validation?

Facing the following problem: Using k-fold cross validation to select network parameters. Early stopping on the held-out fold to obtain the 'best' weights in terms of classification error. Repeat for k-folds. Use lowest average error (from these k runs) to select best network. Now I have selected the best network but how do I train it on the whole training set for deployment? In the k runs, best 'weights' were obtained at different iterations. Do I use a separate test set as stopping criteria ? If so would this indicate fairly the generalization performance?
