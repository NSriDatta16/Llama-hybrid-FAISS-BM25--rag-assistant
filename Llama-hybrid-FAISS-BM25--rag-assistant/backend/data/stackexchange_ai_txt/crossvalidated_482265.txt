[site]: crossvalidated
[post_id]: 482265
[parent_id]: 
[tags]: 
Permutation sensitive Graph Neural Network

For my research, I'm representing first order logic statements as Directed Acyclic Graphs (DAGs). Each node in such a DAG has a symbol associated with it (which is modelled as a one-hot node feature vector.) Something like "f(a,b)" would be represented as a node with symbol "f" having two directed edges to nodes with symbols "a" and "b". Graph Neural Networks seem like the right model for processing data like this, but I have one problem: I care about the order of children. For instance f(a,b) is not the same as f(b,a). Strictly speaking as DAGs, they are the same, but I want to have an ordered adjacency list implementation and use a permutation-sensitive (as opposed to permutation-invariant) aggregation function so that I can tell the difference between f(a,b) and f(b,a). I've never seen this done. Is there a reason why this hasn't been considered? Is it a bad idea?
