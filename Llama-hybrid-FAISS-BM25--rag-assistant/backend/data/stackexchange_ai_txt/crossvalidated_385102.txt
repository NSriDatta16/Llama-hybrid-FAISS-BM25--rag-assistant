[site]: crossvalidated
[post_id]: 385102
[parent_id]: 
[tags]: 
Does using random minibatchs give more resilance against local minima, vs full batch gradient descent

It was my believe that one of the advantages of using minibatches, when training a neural network via gradient descent (be it "vanilla" or the latest flavour of AdaGrad), was an increased resiliance against local minima. I thought I read it somewhere, but when challanged I find that I can not produce a reference for it. I expected to find it in Y. A. LeCun and L. Bottou, “Efficient backprop,” in Neural networks: Tricks of the trade, Springer, 2012, pp. 9–48. but it was not there. It logically makes sense to me that this would be the case. Minibatchs add noise to the training process, so local minima for one minibatch would be bounced out of for a different one. And since you generate a new set of random minibatches every epoch, that will mean not seeing the same local minima ever again. But that isn't very strong, since those local minima for minibatchs could in the scheme of things all be associated with the same full batch local minima. Anyway, I would like a reference for or against my belief.
