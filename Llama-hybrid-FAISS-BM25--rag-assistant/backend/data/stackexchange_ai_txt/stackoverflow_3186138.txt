[site]: stackoverflow
[post_id]: 3186138
[parent_id]: 3175774
[tags]: 
The process for comparing a set of sounds for similarities is called Content Based Audio Indexing , Retrieval , and Fingerprinting in computer science research. One method of doing this is to: Run several bits of signal processing on each audio file to extract features, such as pitch over time, frequency spectrum, autocorrelation, dynamic range, transients, etc. Put all the features for each audio file into a multi-dimensional array and dump each multi-dimensional array into a database Use optimization techniques (such as gradient descent ) to find the best match for a given audio file in your database of multi-dimensional data. The trick to making this work well is which features to pick. Doing this automatically and getting good results can be tricky. The guys at Pandora do this really well, and in my opinion they have the best similarity matching around. They encode their vectors by hand though, by having people listen to music and rate them in many different ways. See their Music Genome Project and List of Music Genome Project attributes for more info. For automatic distance measurements, there are several projects that do stuff like this, including marsysas , MusicBrainz , and EchoNest . Echonest has one of the simplest APIs I've seen in this space. Very easy to get started.
