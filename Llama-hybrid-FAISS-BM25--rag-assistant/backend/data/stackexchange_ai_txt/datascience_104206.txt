[site]: datascience
[post_id]: 104206
[parent_id]: 
[tags]: 
What could be good Perfomance Evaluation Metrics for a Data Scientist?

Background I'm a Data Scientist and am being asked to come up with a set of metrics/KPIs to assess my annual performance, and things like bonuses (and in the worst case being fired) depend on that. And of course I want them to align to my personal Data Scientist growth goals as well. My position entails: working on machine learning projects from the start to end (getting data access, exploration, modelling, results, presentation, helping in productionising etc) Analysing certain topics to give suggestions to the management A part of which could be to educate stakeholders on using new tools to analyze on their own What I've observed is that the job of a Data Scientist is rather complicated when it comes to measuring success, and things like performance appraisals metrics are then harder to design. My Intuition: On one hand, things like number of machine learning models deployed seem like a direct measurable metric, but on the other hand all models are not equal. Some may need a lot of time while others might be ready relatively quicker. The same goes for number of topics analysed/explored, as in exploration the required effort could vary a lot more than in modelling. The only thing I can clearly put is the cumulative business value of the machine learning models developed, or of the business decision made from an exploration/analysis. This, however, puts the responsibility on the stakeholders a lot, putting an overhead work (to devise this value) needed to approach our team, and the stakeholders might hesitate approaching us. On the other hand, I believe that the stakeholders should be clear about the value of every topic they're working on, and the ones they requested other teams to work on. Apart from business value, I also think about including something to assess the quality of every modelling project or analysis, something like a quality score, so as to drive me to improve the quality of my approach, to present better etc. But I'm not sure if quantifying the overall quality of such things could be practical and indicative consistently of what it was meant to be. Question: What could (generally) be good performance evaluation metrics for such a Data Scientist? OR What should the technical approach be to devise such metrics?
