[site]: crossvalidated
[post_id]: 343350
[parent_id]: 343157
[tags]: 
The best approach for selecting from such a large set of feature variables is to perform sequential forward search . I recommend building a classifier from each individual feature using a fast construction algorithm. Use for example the J48 decision tree algorithm [1], which has been implemented also in Weka . You need to program a wrapping search algorithm around the classifier evaluation, to perform this 'over night'. After having built each of the $20,000$ one-feature classifiers and having evaluated each one by say $5$-fold cross validation, you make a ranking of the most promising $50$ features. Then you start again by building decision trees, for each of the possible $50\cdot(50-1)$ two-feature classifiers from the $50$ subset. You make a selection of the best $100$ classifiers, and add a third feature from the most promising feature set. Gradually, you get to a situation where you have say $10-20$ features that perform nicely on your training set. You can now train and test your support vector machine with this $10-20$ subset of features. This approach does not in any way ensure optimality. There is no guarantee that the features left out early in your feature selection procedure will not have an important contribution to the test-set performance of your SVM. Nonetheless, this is a pragmatic way-of-working which can yield a well-performing classifier for the classification task at hand. The small number of training cases, $200$, is really the limiting factor. [1] Ross Quinlan (1993). C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers, San Mateo, CA.
