[site]: crossvalidated
[post_id]: 443615
[parent_id]: 443606
[tags]: 
You are likely to get into serious trouble with this approach, on several accounts. First, a high LASSO (L1-penalized) regression coefficient (which you seem to be calling "effect size"*) doesn't necessarily mean anything unless you take variable scaling into account. If you measure a distance in miles instead of in millimeters, the regression coefficient will be much larger. Second, even if that's taken into account, you should not be so willing to ignore standard errors. Do you really want to pin your hopes on a large numeric coefficient value that is so intrinsically variable that it has a proportionately large standard error? There's an important reason for paying attention to what you call "effect size normalized by standard error," a basis of statistical hypothesis testing: it helps prevent you from making unwise choices of potentially unreliable predictors. Third, your limited re-sampling (only 10 fold; not clear whether this represents standard cross-validation or some variant) is insufficient to do what you want. To have anything remotely resembling a reasonable representation of what might be going on in the underlying population without having to worry about the vagaries of your re-samples, you would be better off doing something on the order of 100 random rounds of 10-fold cross validation. Fourth, you don't specify what you are using to test the performance of your models. Accuracy per se is a poor choice despite how often it is used; among other things it often makes an arbitrary (and hidden) decision that p = 0.5 is the classification cutoff. You need to separate out the probability modeling provided by the logistic regression from the tradeoffs between false-positive and false-negative costs needed to choose a decision threshold. Fifth, once you have a good measure of performance, if your features are at all correlated then the sets of features selected by LASSO from your different re-samples are likely to differ. One or the other of 2 or more correlated features might be chosen in any one re-sample. That's not necessarily a problem in using such models for prediction, but how are you handling that in your estimates of regression coefficient magnitude or standard errors? Sixth, it's not clear how you would be evaluating "statistical significance" in your approach. The ways to do reliable inference of this type in LASSO are still not completely worked out. Standard significance testing assumes that you haven't used the data to pick the predictors used in the model. Once you have used the data to pick the predictors then the independence and other assumptions needed to determine "statistical significance" in standard ways no longer hold. There has been some success in this respect for standard linear regression but I'm not sure that there is a good way to do this for logistic regression. Your best bet is to focus on cross-validated or bootstrapped model performance itself and use the features and coefficients that LASSO returns on that basis rather than searching for effect sizes. *"Effect size" has so many potential definitions that use of the term often leads to confusion. Many of those definitions, and often the most useful ones, are more related to what you call "effect size normalized by standard error."
