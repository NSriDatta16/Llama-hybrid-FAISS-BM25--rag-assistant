[site]: crossvalidated
[post_id]: 274850
[parent_id]: 274815
[tags]: 
assume that the real model of the data $p_{true}(X)$ differs from $p(X|\theta)$ for all values of $\theta$ Bayesian interpretation of this assumption is that there is an additional random variable $\phi$ and a value $\phi_0$ in its range $\phi_0$ such that $\int p(X|\theta,\phi=\phi_0) \mathrm{d}\theta =0$. Your prior knowledge says $p(\phi=\phi_0)\propto 1$ and $p(\phi\neq\phi_0)=0$. Then $p(\theta|X,\phi=\phi_0)=0$ which is not proper probability distribution. This case corresponds to a similar inference rule in logic where $A, \neg A \vdash \emptyset$, i.e. you can't infer anything from a contradiction. The result $p(\theta|X,\phi=\phi_0)=0$ is a way in which bayesian probability theory tells you that your prior knowledge is not consistent with your data. If someone failed to get this result in their derivation of the posterior, it means that the formulation failed to encode all relevant prior knowledge. As for the appraisal of this situation I hand over to Jaynes (2003, p.41): ... it is a powerful analytical tool which can search out a set of propositions and detect a contradiction in them if one exists. The principle is that probabilities conditional on contradictory premises do not exist (the hypothesis space is reduced to the empty set). Therefore, put our robot to work; i.e. write a computer program to calculate probabilities $p(B|E)$ conditional on a set of propositions $E= (E_1,E_2,\dots,E_n)$ Even though no contradiction is apparent from inspection, if there is a contradiction hidden in $E$, the computer program will crash. We discovered this ,,empirically,'' and after some thought realized that it is not a reason for dismay, but rather a valuable diagnostic tool that warns us of unforeseen special cases in which our formulation of a problem can break down. In other words, if your problem formulation is inaccurate - if your model is wrong, bayesian statistics can help you find out that this is the case and can help you to find what aspect of the model is the source of the problem. In practice, it may not be entirely clear what knowledge is relevant and whether it should be included in derivation. Various model checking techniques (Chapters 6 & 7 in Gelman et al., 2013, provide an overview) are then used to find out and to identify an inaccurate problem formulation. Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian data analysis, Third edition. Chapman & Hall/CRC. Jaynes, E. T. (2003). Probability theory: The logic of science. Cambridge university press.
