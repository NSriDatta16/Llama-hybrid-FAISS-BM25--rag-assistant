[site]: crossvalidated
[post_id]: 88422
[parent_id]: 88421
[tags]: 
If you're just using a metropolis algorithm, you need a symmetric proposal distribution, where "symmetric" in this context means $p(a|b) = p(b|a)$ (i.e. the probability of moving from $a$ to $b$ is the same as the probability of moving from $b$ to $a$). If you want to use an asymmetric proposal, you need to use a metropolis- hastings algorithm, which is basically the exact same thing except that the acceptance ratio is multiplied by a factor that corrects for the asymmetry of the proposal distribution. Theoretically, yes, you can use really any value for the starting position of your search. Practically, you want to start in the high probability region of your distribution. Basically, the distance from your initial value to the high probability region is going to determine your burn-in time, so if you know what a "likely" value is, this can reduce your burn-in by essentially starting you in the stationary distribution. The other tuning parameters are, well, going to need to be tuned to your problem. It's more art than science. Aim for an acceptance rate of around 20%-30%, and then start playing with your proposal variance from there. The wider your proposal variance, the lower your acceptance rate will be. If you shrink your proposal variance too much, you'll have a high acceptance rate. This might sound good, but it corresponds to a lower "effective sample size," which is the approximate number of samples you would have if you were able to use monte carlo sampling instead of MCMC. So you're algorithm will accept more values, but you'll need to draw more samples. If you don't like the idea of playing with the tuning parameters, you can use an "adaptive" algorithm that checks on the acceptance rate over a (reasonably large) window of the most recent samples and modifies the proposal variance appropriately. This way your algorithm--hopefully--converges on a good proposal distribution, allowing you to more quickly converge on a good sample.
