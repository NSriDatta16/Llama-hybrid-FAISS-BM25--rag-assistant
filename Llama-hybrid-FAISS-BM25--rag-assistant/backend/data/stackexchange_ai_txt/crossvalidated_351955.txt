[site]: crossvalidated
[post_id]: 351955
[parent_id]: 
[tags]: 
How to avoid extremely small values when normalizing uint64 data

I am currently trying to normalize a data set for training a neural network. It has some specific properties which make it hard to normalize by any method I know of. I am looking for a normalization technique which can deal with it. I have around 90 features that originally were uint64 numbers. So I have only positive values in the range of [0; 2^64] . Some of the features are kinda small (between 0 and 1k) while others are around 64k. To avoid that smaller values get ignored, I want to map them to the [0; 1] range. Naturally, I would divide any counter value by the upper boundary 2^64. Overall this leads to very small values. I don't think that training the network with data like this leads to reasonable results. If I tried to make the normalization constant smaller or set it to the biggest number around, I would risk to get normalized values that are out of the desired range as I cannot guarantee that all values will be smaller than this bound. Is there a technique to deal with data like this? Or is my normalization proposal entirely wrong and I have to map the values to another range? I would be very grateful for any kind of help! Thanks
