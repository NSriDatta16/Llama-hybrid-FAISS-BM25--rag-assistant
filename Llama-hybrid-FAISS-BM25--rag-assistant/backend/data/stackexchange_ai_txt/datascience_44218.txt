[site]: datascience
[post_id]: 44218
[parent_id]: 44141
[tags]: 
Pre-processing is 50% of the entire pipeline. With better data you build better machine learning/deep learning models. But unfortunately, cleaning data is something that needs time and experience. You need to visualise it and make your hands dirty. The aim is to remove noise, garbage and outliers, in short. There are some really good data visualisation libraries in Python such as : MatplotLib Seaborn GGPlot Bokeh PyGal Plotly and more . Since, you are comfortable with Scikit learn, as you mentioned in the question, I would suggest you to look up the preprocessing modules in scikit learn, it contains several APIs such as feature extraction, normalization, feature scaling, mean removal, variance scaling, standardization, etc. But, it is always better to understand the data, visualise it like a story and clean it manually, slowly, instead of passing it through predefined frameworks or pipelines. These videos : Why You Need Data-Preprocessing Data-preprocessing tasks can be helpful. There are many more available easily. Good luck ! Also, do upvote my answer, if it has helped you. It encourages the community to help each other.
