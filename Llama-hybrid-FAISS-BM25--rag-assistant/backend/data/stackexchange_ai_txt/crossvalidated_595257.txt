[site]: crossvalidated
[post_id]: 595257
[parent_id]: 
[tags]: 
Question on the interpretation of the predicted results

I would like to understand something that is bothering me. Suppose you have a dataset and a probabilistic model that depends on few parameters $\alpha, \beta $ etc, and suppose that you find an estimate of these parameters through an MCMC sampler. Such sampler will find the values of the parameters with the highest probability together with an estimate of the uncertainty. In other words, from what I understood, MCMC methods find the configuration that maximize the posterior distributions of the parameters. Now suppose you use a neural network trained through the maximum likelihood method to extend the number of points of your dataset to build up an augmented dataset that extend in an area where the original dataset did not cover. If you apply again the MCMC method with the same model as before, will you get an estimate close or at least compatible with the original dataset or the neural network has the ability to learn a hidden pattern that may cause the likelihood to change and thus, once we apply again the MCMC method over the extended dataset, leading to a different set of values of the original parameters?
