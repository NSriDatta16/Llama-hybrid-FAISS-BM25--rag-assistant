[site]: datascience
[post_id]: 65864
[parent_id]: 
[tags]: 
NLP : variations of a text without modifying it's meaning

I am currently working on the automation of recurring reports (weekly 30-50 pages reports for around 100 districts). Those reports have a mostly fixed form : maps, graphs, data tables and small zone of text. Apart for some discussion around colors and legends, it isn't difficult to automate the production of maps / graphs / tables. (I work with Rmarkdown if you want to know) However, for the text, a simple approach like writing 'r value' in markdown to produce a variable value inside of the text feel 'too automated'. The reports end up having ten sentences like 'During the last quarter (QX 201X) total result was XXX (a +X% growth compared to the same quarter the previous year).' I'd like to get automatic variations of that phrase without modyfiying it's meaning. I've ended up writing half a dozen variations myself. But (1) it still feels repetitive and unnatural, and (2) doing it for every phrase of the report may take a lot of time. We have seen a lot of extraordinary things in transfering things for visual representation (see : https://en.wikipedia.org/wiki/Neural_Style_Transfer ). So I was wondering if we have similar things for NLP, that would allow a text to be rewritten using a different 'style' (a neutral style -or an absence of style- in my case), keeping it's main content. The main paper I found on the subject is titled ' What is wrong with style transfer for texts? ' and shows why style transfer doesn't really work for texts. Given (1) the constraint (keeping the same meaning) and (2) it's formalism (I know which number should be shown), I feel like the problem may be simpler than the whole style transfert. Any idea where to start to automatically write variations of a text while keeping it's meaning constant ?
