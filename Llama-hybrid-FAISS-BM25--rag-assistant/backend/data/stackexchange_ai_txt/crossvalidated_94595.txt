[site]: crossvalidated
[post_id]: 94595
[parent_id]: 93569
[tags]: 
It we have two classes, $C_{0}$ and $C_{1}$, then we can express the conditional probability as, $$ P(C_{0}|x) = \frac{P(x|C_{0})P(C_{0})}{P(x)} $$ applying the Bayes' theorem, $$ P(C_{0}|x) = \frac{P(x|C_{0})P(C_{0})}{P(x|C_{0})P(C_{0})+P(x|C_{1})P(C_{1})} = \frac{1}{1+ \exp\left(-\log\frac{P(x|C_{0})}{P(x|C_{1})}-\log \frac{P(C_{0})}{P(C_{1})}\right)} $$ the denominator is expressed as $1+e^{\omega x}$. Under which conditions reduces the first expression to a linear term?. If you consider the exponential family (a canonical form for the exponential distributions like Gau√ü or Poisson), $$ P(x|C_{i}) = \exp \left(\frac{\theta_{i} x -b(\theta_{i})}{a(\phi)}+c(x,\phi)\right) $$ then you end up having a linear form, $$ \log\frac{P(x|C_{0})}{P(x|C_{1})} = \left[ (\theta_{0}-\theta_{1})x - b(\theta_{0})+b(\theta_{1}) \right]/a(\phi) $$ Notice that we assume that both distributions belong to the same family and have the same dispersion parameters. But, under that assumption, the logistic regression can model the probabilities for the whole family of exponential distributions.
