[site]: crossvalidated
[post_id]: 493197
[parent_id]: 493106
[tags]: 
To understand why we use the relative and subjective notions of under- and overfitting, we must remember that, as George Box said, " all models are wrong " ( see here for an explanation of this aphorism ), but some of them are useful. When confronted to data whose generative model is unknown, we can define a set of plausible and competing models to explain these data. None of these models will be perfect, in the sense that none of them will perfectly correspond to the ground truth (as Norbert Wiener said, " the best material model of a cat is another, or preferably the same, cat "); but you can compare them in terms of their ability to explain the data and their relative simplicity (i.e. their ability to generalize). Model selection and comparison are subjective (since you have to define a family of plausible models) and relative (since models are not compared to a ground truth, but to the other competing models) by nature. You probably won't be able to fine the true model, but you can find the best model among the family of models you have at hands. For large data sets, you can compare your competing models based on their training and test errors (as shown in the graph in your question). For smaller data sets, you can use model selection criteria such as the Bayesian Information Criterion or the Akaike Information Criterion .
