[site]: crossvalidated
[post_id]: 470982
[parent_id]: 470967
[tags]: 
What is the relationship between this and Gibbs sampling / Blotzmann sampling? Mathematically, the two functions are very similar. Gibbs sampling adds a scaling "temperature" factor which is applied to scores before using them in the softmax. The scenarios in which they are used are different: Softmax probabilities are used when the function's sole purpose is to generate probabilities, and you are free to adjust the input preferences (or logits) in order to converge on a target distribution. This is the case for policy functions in policy gradient methods. Gibbs sampling can be used when the inputs already represent some other relevant score function (e.g. an action value in reinforcement learning). The temperature parameter gives you some control over the impact in differences of that score between options, but not full control because the scores are measuring something else. This can still be useful for generating policies - both on-policy and a behaviour in off-policy - and has some nice properties for online learning in real systems (it quickly learns to avoid very bad action choices for example), although adding a new important hyperparameter in the form of the temperature value is not great.
