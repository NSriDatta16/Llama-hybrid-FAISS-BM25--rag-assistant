[site]: crossvalidated
[post_id]: 494787
[parent_id]: 488667
[tags]: 
How can we evaluate a model trained in a Reinforcement learning manner ? Evaluation of the performance of an RL model varies very widely depending on the task. For example, you could use the average reward as an evaluation metric, or if there's a reasonable "success condition", you could use that as the metric. In other situations you might use already established metrics of performance, (such as chess ELO). can we quantify the RL generalization ? If you're generalizing from some environment E to a different environment E', then you could simply measure the performance on E', or the performance drop from E to E'.
