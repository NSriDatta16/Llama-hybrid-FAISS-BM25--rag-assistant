[site]: datascience
[post_id]: 115634
[parent_id]: 
[tags]: 
Optimization on a convex function used in a loss function

I am currently creating a deep learning model which deals with classification and regression problem together such that each class has continuous value within an interval of real numbers in common across the classes. In other word, the machine learning model classifies input first as a classification problem and perform to find a number for each classified input as a regression problem. Let's say loss function L1 is for classification loss and L2 is for regression loss. I combined the two loss functions by a convex function; Loss = theta*L1 + (1-theta)*L2 This loss function performs better than other loss functions. My main question is that I would like to find a optimized theta during the training phase, since currently the theta is manually adjusted. If there is any knowledge on this, it is really appreciated. Thank you so much for your help in advance!
