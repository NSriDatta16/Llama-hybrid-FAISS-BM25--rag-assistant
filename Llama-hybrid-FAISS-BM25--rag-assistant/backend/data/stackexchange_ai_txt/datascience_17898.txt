[site]: datascience
[post_id]: 17898
[parent_id]: 2368
[tags]: 
Ben is talking about the static features , and make use of the timestamp features. As an extension, i will introduce the lag features , I am not talking the raw time series, but the aggregates on it. The most mystical part is that the future value is unseen for us, how can we use that aggregate features in the training data? A little example: There is yearly electric consumption data from 1991 to 2015, I want predict the electric consumption in the future 5 years, 2016 to 2020. I will calculate the last 5 years moving average of electric consumption as the 2020's feature values, but the 2016 to 2020 is unknown for us, so we leading (opposite the lagging) the time series 5 years, lets do the moving average on 2010 to 2015, then use this value as 2020's feature values. So, we can construct the future 5 years' feature data. The next step is just using the moving function (count\mean\median\min\max.etc) and try different windows, then you will construct lots of features!
