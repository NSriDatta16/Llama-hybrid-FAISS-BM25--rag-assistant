[site]: datascience
[post_id]: 68549
[parent_id]: 68542
[tags]: 
How you do this will depend a lot on the tools you are already using and the way your model trains. If you are iterating e.g. over a grid of parameters to search, it can be trivial to parallelize. Other setups can be quite difficult. There are some generic ways to do it using Python: check out the relevant documentation . One thing to be aware of is that you really must use multiple processes to get real parallelism in Python. Using a thread in python does not speed things up for the actual computation. Threads are typically only useful in scenarios where you think you will be waiting for responses e.g. in networking/web programming (similar to asynchronous programming in Python). In your case, doing bioinformatics, I would first check there aren't frameworks that will already do the parallel processing for you. Maybe you could use: A typical Deep Learning framework like Tensorflow or PyTorch , which do many things in parallel on the CPU and also offer GPU support, which can be even faster. You can see from all these examples using Tensorflow , that you can create many models, not just neural networks. There are also other generic frameworks, such as Ray , which try to abstract the difficult parts away for you. Here is an introduction tutorial for that tool . Sci-Kit Learn's tools, some of which have an options to add more workers or can be used together with joblib .
