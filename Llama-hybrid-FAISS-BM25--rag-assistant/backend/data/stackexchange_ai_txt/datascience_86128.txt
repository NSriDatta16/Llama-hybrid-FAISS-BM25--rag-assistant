[site]: datascience
[post_id]: 86128
[parent_id]: 
[tags]: 
Reduce overfitting in a CNN model

We are Data science students and we are building a CNN model to pneumonia classification (dataset: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia ). We have applied a data augmentation for improve our number of images to balance the classes (5500 images for classes). Data augmentation process is the same for both the classes. Data augmentation import os import glob from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img datagen = ImageDataGenerator(rotation_range =45, vertical_flip = True, width_shift_range = 0.2, height_shift_range = 0.2, rescale=1./255, shear_range=0.2, zoom_range=0.2, zca_whitening= True, horizontal_flip = True, fill_mode = 'nearest', data_format='channels_last', brightness_range=[0.5, 1.5]) %%time import cv2 img_dir = 'NORMAL' data_path = os.path.join(img_dir,'*g') files = glob.glob(data_path) data = [] for f1 in files: img = cv2.imread(f1) data.append(img) x = img_to_array(img) x = x.reshape((1,) + x.shape) %%time i = 0 path, dirs, files = next(os.walk("NORMAL")) file_count = len(files)*8 for batch in datagen.flow (x, batch_size=1, save_to_dir ='augmentation',save_prefix="N",save_format='jpg'): i+=1 if i==file_count: break %%time #rename NORMAL images path = '/train/NORMAL' i = 0 for filename in os.listdir(path): os.rename(os.path.join(path,filename), os.path.join(path,'NORMAL'+str(i)+'.jpeg')) i = i +1 Model %%time normal = [] pneumonia = [] img_size = 150 normal_path = ('/content/train/NORMAL') pneumonia_path = ('/content/train/PNEUMONIA') DIRS = [(0, normal_path), (1, pneumonia_path)] %%time train_images = [] labels = [] for num, _dir in DIRS: _dir = _dir + '/' count = 0 for file in os.listdir(_dir): if count >= 5500: break img = image.load_img(_dir + str(file), target_size=(img_size, img_size)) img = image.img_to_array(img) img = img/255 train_images.append(img) labels.append(num) count += 1 %%time X = np.array(train_images) X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.1, random_state=101) y_train_labels = to_categorical(y_train) %%time def build(width, height, depth, classes): #initialize the model along with the input shape initializer = tf.keras.initializers.GlorotUniform(seed=1234) model = Sequential() inputShape = (height, width, depth) chanDim = -1 if K.image_data_format() == 'channels_first': inputShape = (depth, height, width) chanDim = 1 model.add(Convolution2D(64, (3,3), padding='same', kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.1), input_shape=inputShape)) model.add(Activation('relu')) model.add(BatchNormalization(axis=chanDim)) model.add(MaxPooling2D(pool_size=(2,2))) model.add(Dropout(0.10)) model.add(Convolution2D(32, (3,3), padding='same', kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.1))) model.add(Activation('relu')) model.add(BatchNormalization(axis=chanDim)) model.add(MaxPooling2D(pool_size=(2,2))) model.add(Dropout(0.10)) model.add(Convolution2D(16, (3,3), padding='same', kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.1))) model.add(Activation('relu')) model.add(BatchNormalization(axis=chanDim)) model.add(MaxPooling2D(pool_size=(2,2))) model.add(Dropout(0.10)) model.add(Convolution2D(32, (3,3), padding='same', kernel_initializer=initializer, kernel_regularizer=regularizers.l1_l2(0.1), )) model.add(Activation('relu')) model.add(BatchNormalization(axis=chanDim)) model.add(MaxPooling2D(pool_size=(2,2))) model.add(Dropout(0.10)) model.add(Flatten()) model.add(Dense(classes)) model.add(Activation('sigmoid')) return model model = build(img_size, img_size, 3, 2) model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), metrics=['accuracy']) model.summary() Model: "sequential" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 150, 150, 64) 1792 _________________________________________________________________ activation (Activation) (None, 150, 150, 64) 0 _________________________________________________________________ batch_normalization (BatchNo (None, 150, 150, 64) 256 _________________________________________________________________ max_pooling2d (MaxPooling2D) (None, 75, 75, 64) 0 _________________________________________________________________ dropout (Dropout) (None, 75, 75, 64) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 75, 75, 32) 18464 _________________________________________________________________ activation_1 (Activation) (None, 75, 75, 32) 0 _________________________________________________________________ batch_normalization_1 (Batch (None, 75, 75, 32) 128 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 37, 37, 32) 0 _________________________________________________________________ dropout_1 (Dropout) (None, 37, 37, 32) 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 37, 37, 16) 4624 _________________________________________________________________ activation_2 (Activation) (None, 37, 37, 16) 0 _________________________________________________________________ batch_normalization_2 (Batch (None, 37, 37, 16) 64 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 18, 18, 16) 0 _________________________________________________________________ dropout_2 (Dropout) (None, 18, 18, 16) 0 _________________________________________________________________ conv2d_3 (Conv2D) (None, 18, 18, 32) 4640 _________________________________________________________________ activation_3 (Activation) (None, 18, 18, 32) 0 _________________________________________________________________ batch_normalization_3 (Batch (None, 18, 18, 32) 128 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 9, 9, 32) 0 _________________________________________________________________ dropout_3 (Dropout) (None, 9, 9, 32) 0 _________________________________________________________________ flatten (Flatten) (None, 2592) 0 _________________________________________________________________ dense (Dense) (None, 2) 5186 _________________________________________________________________ activation_4 (Activation) (None, 2) 0 ================================================================= Total params: 35,282 Trainable params: 34,994 Non-trainable params: 288 %%time history = model.fit(X_train, y_train_labels, epochs=100, batch_size=32, validation_split=0.30) Epoch 1/100 217/217 [==============================] - 10s 48ms/step - loss: 13.8373 - accuracy: 0.9567 - val_loss: 2.9341 - val_accuracy: 0.4953 Epoch 2/100 217/217 [==============================] - 9s 40ms/step - loss: 0.9611 - accuracy: 0.9750 - val_loss: 1.4211 - val_accuracy: 0.4953 Epoch 3/100 217/217 [==============================] - 9s 41ms/step - loss: 0.4153 - accuracy: 0.9785 - val_loss: 0.7272 - val_accuracy: 0.7215 Epoch 4/100 217/217 [==============================] - 9s 40ms/step - loss: 0.2925 - accuracy: 0.9799 - val_loss: 0.9268 - val_accuracy: 0.7037 Epoch 5/100 217/217 [==============================] - 9s 41ms/step - loss: 0.2749 - accuracy: 0.9818 - val_loss: 0.3339 - val_accuracy: 0.9576 Epoch 6/100 217/217 [==============================] - 9s 40ms/step - loss: 0.2414 - accuracy: 0.9814 - val_loss: 0.2825 - val_accuracy: 0.9384 Epoch 7/100 217/217 [==============================] - 9s 41ms/step - loss: 0.2163 - accuracy: 0.9831 - val_loss: 0.9659 - val_accuracy: 0.8202 Epoch 8/100 217/217 [==============================] - 9s 41ms/step - loss: 0.2122 - accuracy: 0.9834 - val_loss: 0.2410 - val_accuracy: 0.9727 Epoch 9/100 217/217 [==============================] - 9s 41ms/step - loss: 0.2188 - accuracy: 0.9830 - val_loss: 0.3082 - val_accuracy: 0.9815 Epoch 10/100 217/217 [==============================] - 9s 41ms/step - loss: 0.2107 - accuracy: 0.9844 - val_loss: 0.2320 - val_accuracy: 0.9684 Epoch 11/100 217/217 [==============================] - 9s 41ms/step - loss: 0.2385 - accuracy: 0.9814 - val_loss: 0.2697 - val_accuracy: 0.9677 Epoch 12/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1806 - accuracy: 0.9835 - val_loss: 0.4971 - val_accuracy: 0.9027 Epoch 13/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1647 - accuracy: 0.9841 - val_loss: 2.6447 - val_accuracy: 0.6088 Epoch 14/100 217/217 [==============================] - 9s 40ms/step - loss: 0.1710 - accuracy: 0.9851 - val_loss: 0.2097 - val_accuracy: 0.9660 Epoch 15/100 217/217 [==============================] - 9s 40ms/step - loss: 0.1781 - accuracy: 0.9841 - val_loss: 0.3810 - val_accuracy: 0.9189 Epoch 16/100 217/217 [==============================] - 9s 40ms/step - loss: 0.1466 - accuracy: 0.9877 - val_loss: 0.2020 - val_accuracy: 0.9785 Epoch 17/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1622 - accuracy: 0.9843 - val_loss: 0.1882 - val_accuracy: 0.9731 Epoch 18/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1468 - accuracy: 0.9850 - val_loss: 0.3029 - val_accuracy: 0.9556 Epoch 19/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1536 - accuracy: 0.9846 - val_loss: 0.2355 - val_accuracy: 0.9458 Epoch 20/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1456 - accuracy: 0.9853 - val_loss: 0.1792 - val_accuracy: 0.9798 Epoch 21/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1371 - accuracy: 0.9863 - val_loss: 0.1802 - val_accuracy: 0.9832 Epoch 22/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1378 - accuracy: 0.9847 - val_loss: 0.7035 - val_accuracy: 0.9135 Epoch 23/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1446 - accuracy: 0.9835 - val_loss: 0.3637 - val_accuracy: 0.8973 Epoch 24/100 217/217 [==============================] - 9s 40ms/step - loss: 0.1193 - accuracy: 0.9861 - val_loss: 0.1854 - val_accuracy: 0.9609 Epoch 25/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1284 - accuracy: 0.9859 - val_loss: 0.1862 - val_accuracy: 0.9717 Epoch 26/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1377 - accuracy: 0.9814 - val_loss: 0.5382 - val_accuracy: 0.8960 Epoch 27/100 217/217 [==============================] - 9s 40ms/step - loss: 0.1266 - accuracy: 0.9834 - val_loss: 0.1324 - val_accuracy: 0.9835 Epoch 28/100 217/217 [==============================] - 9s 40ms/step - loss: 0.1200 - accuracy: 0.9869 - val_loss: 0.1707 - val_accuracy: 0.9774 Epoch 29/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1178 - accuracy: 0.9846 - val_loss: 0.1559 - val_accuracy: 0.9707 Epoch 30/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1112 - accuracy: 0.9872 - val_loss: 0.1294 - val_accuracy: 0.9825 Epoch 31/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1152 - accuracy: 0.9848 - val_loss: 0.1786 - val_accuracy: 0.9586 Epoch 32/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1050 - accuracy: 0.9877 - val_loss: 0.1276 - val_accuracy: 0.9835 Epoch 33/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1010 - accuracy: 0.9883 - val_loss: 0.1495 - val_accuracy: 0.9630 Epoch 34/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1024 - accuracy: 0.9880 - val_loss: 1.3460 - val_accuracy: 0.6687 Epoch 35/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1046 - accuracy: 0.9876 - val_loss: 0.3186 - val_accuracy: 0.9431 Epoch 36/100 217/217 [==============================] - 9s 40ms/step - loss: 0.1058 - accuracy: 0.9872 - val_loss: 0.1845 - val_accuracy: 0.9576 Epoch 37/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1041 - accuracy: 0.9869 - val_loss: 0.1200 - val_accuracy: 0.9845 Epoch 38/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1053 - accuracy: 0.9869 - val_loss: 0.7715 - val_accuracy: 0.7919 Epoch 39/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1013 - accuracy: 0.9877 - val_loss: 0.1210 - val_accuracy: 0.9832 Epoch 40/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0997 - accuracy: 0.9872 - val_loss: 0.2194 - val_accuracy: 0.9478 Epoch 41/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1045 - accuracy: 0.9869 - val_loss: 0.1183 - val_accuracy: 0.9828 Epoch 42/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0991 - accuracy: 0.9869 - val_loss: 0.1148 - val_accuracy: 0.9852 Epoch 43/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0876 - accuracy: 0.9899 - val_loss: 0.1446 - val_accuracy: 0.9657 Epoch 44/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0881 - accuracy: 0.9879 - val_loss: 0.2258 - val_accuracy: 0.9434 Epoch 45/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0900 - accuracy: 0.9870 - val_loss: 0.2228 - val_accuracy: 0.9377 Epoch 46/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0905 - accuracy: 0.9872 - val_loss: 0.1515 - val_accuracy: 0.9801 Epoch 47/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1060 - accuracy: 0.9853 - val_loss: 0.1051 - val_accuracy: 0.9838 Epoch 48/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0887 - accuracy: 0.9880 - val_loss: 0.1118 - val_accuracy: 0.9761 Epoch 49/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0879 - accuracy: 0.9872 - val_loss: 0.1649 - val_accuracy: 0.9566 Epoch 50/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0941 - accuracy: 0.9848 - val_loss: 0.1305 - val_accuracy: 0.9747 Epoch 51/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0868 - accuracy: 0.9893 - val_loss: 0.1722 - val_accuracy: 0.9667 Epoch 52/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0856 - accuracy: 0.9877 - val_loss: 0.2049 - val_accuracy: 0.9418 Epoch 53/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0930 - accuracy: 0.9867 - val_loss: 0.1377 - val_accuracy: 0.9771 Epoch 54/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0893 - accuracy: 0.9879 - val_loss: 0.1309 - val_accuracy: 0.9788 Epoch 55/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0945 - accuracy: 0.9880 - val_loss: 0.1205 - val_accuracy: 0.9828 Epoch 56/100 217/217 [==============================] - 9s 40ms/step - loss: 0.0881 - accuracy: 0.9898 - val_loss: 0.1288 - val_accuracy: 0.9825 Epoch 57/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0944 - accuracy: 0.9869 - val_loss: 0.5726 - val_accuracy: 0.8613 Epoch 58/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1009 - accuracy: 0.9846 - val_loss: 0.1765 - val_accuracy: 0.9572 Epoch 59/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0916 - accuracy: 0.9886 - val_loss: 0.1366 - val_accuracy: 0.9737 Epoch 60/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0858 - accuracy: 0.9890 - val_loss: 0.1202 - val_accuracy: 0.9764 Epoch 61/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0853 - accuracy: 0.9898 - val_loss: 0.1848 - val_accuracy: 0.9515 Epoch 62/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0997 - accuracy: 0.9861 - val_loss: 0.3633 - val_accuracy: 0.9165 Epoch 63/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1011 - accuracy: 0.9882 - val_loss: 0.1214 - val_accuracy: 0.9751 Epoch 64/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0848 - accuracy: 0.9892 - val_loss: 0.2118 - val_accuracy: 0.9471 Epoch 65/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0907 - accuracy: 0.9883 - val_loss: 0.1917 - val_accuracy: 0.9579 Epoch 66/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0883 - accuracy: 0.9893 - val_loss: 0.1620 - val_accuracy: 0.9741 Epoch 67/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0906 - accuracy: 0.9879 - val_loss: 0.1543 - val_accuracy: 0.9727 Epoch 68/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0873 - accuracy: 0.9905 - val_loss: 0.3044 - val_accuracy: 0.9246 Epoch 69/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0902 - accuracy: 0.9879 - val_loss: 0.1103 - val_accuracy: 0.9811 Epoch 70/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0888 - accuracy: 0.9892 - val_loss: 0.1271 - val_accuracy: 0.9808 Epoch 71/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0954 - accuracy: 0.9874 - val_loss: 0.1114 - val_accuracy: 0.9862 Epoch 72/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0890 - accuracy: 0.9880 - val_loss: 0.4402 - val_accuracy: 0.8902 Epoch 73/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0858 - accuracy: 0.9887 - val_loss: 0.2590 - val_accuracy: 0.9401 Epoch 74/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0833 - accuracy: 0.9903 - val_loss: 0.1798 - val_accuracy: 0.9529 Epoch 75/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0890 - accuracy: 0.9882 - val_loss: 0.2340 - val_accuracy: 0.9529 Epoch 76/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0861 - accuracy: 0.9902 - val_loss: 0.1544 - val_accuracy: 0.9663 Epoch 77/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0857 - accuracy: 0.9879 - val_loss: 0.1358 - val_accuracy: 0.9747 Epoch 78/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0846 - accuracy: 0.9896 - val_loss: 0.1611 - val_accuracy: 0.9613 Epoch 79/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0838 - accuracy: 0.9909 - val_loss: 0.1216 - val_accuracy: 0.9744 Epoch 80/100 217/217 [==============================] - 9s 41ms/step - loss: 0.1234 - accuracy: 0.9834 - val_loss: 0.1747 - val_accuracy: 0.9640 Epoch 81/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0929 - accuracy: 0.9876 - val_loss: 0.1156 - val_accuracy: 0.9811 Epoch 82/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0813 - accuracy: 0.9903 - val_loss: 0.1233 - val_accuracy: 0.9815 Epoch 83/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0801 - accuracy: 0.9912 - val_loss: 0.1104 - val_accuracy: 0.9791 Epoch 84/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0790 - accuracy: 0.9909 - val_loss: 0.1446 - val_accuracy: 0.9677 Epoch 85/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0863 - accuracy: 0.9887 - val_loss: 0.1100 - val_accuracy: 0.9842 Epoch 86/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0815 - accuracy: 0.9898 - val_loss: 0.1410 - val_accuracy: 0.9818 Epoch 87/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0848 - accuracy: 0.9880 - val_loss: 0.1438 - val_accuracy: 0.9704 Epoch 88/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0941 - accuracy: 0.9873 - val_loss: 0.1201 - val_accuracy: 0.9774 Epoch 89/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0863 - accuracy: 0.9879 - val_loss: 0.1199 - val_accuracy: 0.9835 Epoch 90/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0794 - accuracy: 0.9909 - val_loss: 0.1292 - val_accuracy: 0.9785 Epoch 91/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0789 - accuracy: 0.9906 - val_loss: 0.2260 - val_accuracy: 0.9492 Epoch 92/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0904 - accuracy: 0.9886 - val_loss: 0.1604 - val_accuracy: 0.9640 Epoch 93/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0773 - accuracy: 0.9925 - val_loss: 0.1194 - val_accuracy: 0.9822 Epoch 94/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0799 - accuracy: 0.9911 - val_loss: 0.2213 - val_accuracy: 0.9465 Epoch 95/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0835 - accuracy: 0.9911 - val_loss: 0.1067 - val_accuracy: 0.9828 Epoch 96/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0999 - accuracy: 0.9866 - val_loss: 0.1114 - val_accuracy: 0.9845 Epoch 97/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0880 - accuracy: 0.9898 - val_loss: 0.1255 - val_accuracy: 0.9741 Epoch 98/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0848 - accuracy: 0.9908 - val_loss: 0.1314 - val_accuracy: 0.9818 Epoch 99/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0776 - accuracy: 0.9924 - val_loss: 0.1916 - val_accuracy: 0.9532 Epoch 100/100 217/217 [==============================] - 9s 41ms/step - loss: 0.0870 - accuracy: 0.9896 - val_loss: 0.1198 - val_accuracy: 0.9852 %%time plt.figure(figsize=(8,8)) plt.subplot(1, 2, 2) plt.plot(history.history['accuracy']) plt.plot(history.history['val_accuracy']) plt.title('model accuracy LR=0.0005') plt.ylabel('accuracy') plt.xlabel('epoch') plt.legend(['train', 'val'], loc='upper left') plt.show() plt.figure(figsize=(8,8)) plt.subplot(1, 2, 2) plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.title('model loss LR=0.0005') plt.ylabel('loss') plt.xlabel('epoch') plt.legend(['train', 'val'], loc='upper left') plt.show() precision recall f1-score support 0 0.98 0.99 0.98 567 1 0.99 0.98 0.98 533 accuracy 0.98 1100 macro avg 0.98 0.98 0.98 1100 weighted avg 0.98 0.98 0.98 1100 However, when testing the model on a never-before-seen dataset, the accuracy of the model turns out to be much lower than that predicted by the model (real 70-75%, instead of 98%). How can we improve the fit accuracy of the model? As can be seen from the loss graph, the fit on the loss is very good, but the accuracy graph shows overfit. We tried to limit overfit using regularizer (L1 and L2), Dropout, Batchnormalization, Learning rate and testing a lot of optimizer and model architecture. But all tries failed to improve the accuracy on test set
