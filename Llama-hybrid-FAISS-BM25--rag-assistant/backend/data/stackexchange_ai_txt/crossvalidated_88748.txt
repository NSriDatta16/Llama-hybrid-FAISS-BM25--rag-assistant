[site]: crossvalidated
[post_id]: 88748
[parent_id]: 88722
[tags]: 
Just to be certain, the residual plot does not demonstrate autocorrelation. If you did want to visually describe the extent of autocorrelation in these data, I think a variogram would be a much better descriptive tool. Nonetheless, autocorrelation is present in these data based on your understanding of the time series and your belief that the predictors in your model do not adequately handle the extent of residual variance due to autocorrelation that they could. An example of when that might not be the case is in clinical trials with adaptive dosing where the dosage is based on severity of disease, so you make the time series of subsequent maladies conditionally independent by adjusting for the dosage. Nonetheless, at any point if there is unmeasured correlation in the data, the interpretation of the coefficients remains exactly the same. The least squares regression slope is still a measure of expected difference in outcomes comparing a unit difference in exposures/regressors. What you lose by ignoring correlation is efficiency/validity of inference. Your standard errors can be inflated or shrunk, so it's the confidence intervals that are messed up. Of course, if you accurately identify the correlation structure, you can iteratively estimate correlation and parameters, and obtain the BLUE which gives valid inference. This is all detailed in Seber & Lee. What's not in Seber & Lee is that if you use robust standard errors, these will give you correct inference even if the correlation structure is misspecified. The data could be AR-1, you can specify independence, and you still get valid inference... you just lose a little efficiency relative to estimating robust standard errors with the correct correlation structure.
