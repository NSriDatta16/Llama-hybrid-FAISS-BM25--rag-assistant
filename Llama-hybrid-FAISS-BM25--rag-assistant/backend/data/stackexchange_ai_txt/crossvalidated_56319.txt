[site]: crossvalidated
[post_id]: 56319
[parent_id]: 
[tags]: 
How to derive Bayes prior given large amounts of sample data from different population members

In Poker, it is important to judge the likelihood of an opponents action, but for unknown opponents, we have few samples available. One method proposed in http://www.husng.com/content/interpreting-small-sample-sizes-bayesian-estimators was to use bayesian estimators, but the author used a simple heuristic for constructing the prior. Assume we have a database with a large number of opponents and their frequencies of the actions (however, the number of samples per opponent might be very different, e.g. there might be opponents where we have just 5 hands and others we have 10000 hands). In my understanding, each opponent can be described by a binomial distribution and our prior could be determined by "combining" those into a Beta distribution. The questions I have are: Is the thought process so far correct? Especially, does it make sense to split the observations into several opponents or can we see all different ones as a single "default" opponent and it leads to the same prior? Is it a problem that we have a different sample size for each opponent? I'm thinking especially on cases where we have a tiny sample size for an opponent. How can calculate the parameters of our prior beta distribution with parameters $(\alpha, \beta)$ based on the data?
