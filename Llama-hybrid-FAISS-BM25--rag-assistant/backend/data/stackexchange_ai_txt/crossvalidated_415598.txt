[site]: crossvalidated
[post_id]: 415598
[parent_id]: 415571
[tags]: 
The King & Nielsen (2016) paper is misleading. It has not been peer-reviewed, and it makes a claim about the results of a testable assumption that you can assess in your own data set (i.e., whether propensity score matching produces balance). In addition, there has been some work to debunk the paper, and several instances in which coarsened exact matching does not perform well. The paper has since been peer-reviewed and accepted. The claims it makes are still empirically verifiable, though, so there is no reason to categorically avoid using propensity score matching. The paper makes testable predictions, and you can assess whether those predictions are realized in your data. The prediction is that propensity score matching will not yield balance; you can simply assess balance in your data after matching. Update (1/1/20) : A paper examining the validity of King & Nielsen (2019) in pharmacoepidemiology is Ripollone et al. (2018). They find that the propensity score paradox does occur, but far beyond recommended and common practices for propensity score matching. In applications, propensity score matching is effective at achieving bias and lowering bias. The same group (Ripollone et al. 2019), who maybe have a bone to pick with King, also evaluate the performance of CEM and find that it yields extremely high error in the effect estimates compared to propensity score matching. The question of how to deal with high-dimensional covariates in causal inference is really hot right now, and there are several modern techniques that have been developed that you should consider before propensity score matching and regression. Matching and regression are some of the earliest causal inference techniques and there has been so much advancement upon these methods that really no one should be using their basic forms. Here are some recommendations for causal inference tools for high-dimensional data: Targeted Minimum Loss-Based Estimation (TMLE) - TMLE is a doubly-robust effect estimator that relies on machine learning and regression to remove confounding without making functional form assumptions about the treatment or outcome model. There is a version called "Collaborative" TMLE (CTMLE), which specifically addresses the problem of high-dimensional covariates. TMLE has been shown to do very well in simulations and in a recent causal inference competition (Dorie et a., 2019). It's very easy to implement and there is an easy-to-use R package ( TMLE ) to do it. It is becoming the gold standard in causal inference. See Schuler & Rose (2017) for an introduction. Bayesian Additive Regression Trees (BART) - BART is a machine learning method that uses Bayesian components both to yield good performance and inference. It works like a flexible outcome regression model, but you can include the propensity score (potentially also estimated using BART) to increase its robustness and performance. Because it only prioritizes covariates that are predictive of the outcome, it automatically selects the relevant variables from a potentially long list, and therefore is effective in high dimensions. It has also been shown to have great performance and to have done will in the causal inference competition, and there is also an easy-to-use R package ( bartCause ) to implement it. See Hill (2011) for an introduction. Group Lasso with Doubly Robust Estimation (GLIDER) - GLIDER is a double-robust propensity score weighting + regression estimator that is especially useful in high dimensions. It uses lasso to select the right covariates that predict both the outcome and the propensity score. It uses an adaptive lasso, which means the coefficients are asymptotically unbiased. It is straightforward to include many transformations of variables to account for potential nonlinearities; if they aren't useful in the model, they are lasso'ed out. See Koch, Vock, & Wolfson (2018) for an introduction. Hopefully that should get you started. Matching and regression do not appear appropriate to me in this case, and there are several better-performing methods that would suit your goals. You should consult with a biostatistician rather than attempt to implement out-of-date methods. Dorie, V., Hill, J., Shalit, U., Scott, M., & Cervone, D. (2019). Automated versus Do-It-Yourself Methods for Causal Inference: Lessons Learned from a Data Analysis Competition. Statistical Science, 34(1), 43–68. https://doi.org/10.1214/18-STS667 Hill, J. L. (2011). Bayesian Nonparametric Modeling for Causal Inference. Journal of Computational and Graphical Statistics, 20(1), 217–240. https://doi.org/10.1198/jcgs.2010.08162 King, G., & Nielsen, R. (2016). Why propensity scores should not be used for matching. Retrieved from http://www.polmeth.wustl.edu/files/polmeth/psnot4.pdf King, G., & Nielsen, R. (2019). Why Propensity Scores Should Not Be Used for Matching. Political Analysis, 1–20. https://doi.org/10.1017/pan.2019.11 Koch, B., Vock, D. M., & Wolfson, J. (2018). Covariate selection with group lasso and doubly robust estimation of causal effects. Biometrics, 74(1), 8–17. https://doi.org/10.1111/biom.12736 Ripollone, J. E., Huybrechts, K. F., Rothman, K. J., Ferguson, R. E., & Franklin, J. M. (2018). Implications of the Propensity Score Matching Paradox in Pharmacoepidemiology. American Journal of Epidemiology, 187(9), 1951–1961. https://doi.org/10.1093/aje/kwy078 Ripollone, J. E., Huybrechts, K. F., Rothman, K. J., Ferguson, R. E., & Franklin, J. M. (2019). Evaluating the Utility of Coarsened Exact Matching for Pharmacoepidemiology using Real and Simulated Claims Data. American Journal of Epidemiology, kwz268. https://doi.org/10.1093/aje/kwz268 Schuler, M. S., & Rose, S. (2017). Targeted Maximum Likelihood Estimation for Causal Inference in Observational Studies. American Journal of Epidemiology, 185(1), 65–73. https://doi.org/10.1093/aje/kww165
