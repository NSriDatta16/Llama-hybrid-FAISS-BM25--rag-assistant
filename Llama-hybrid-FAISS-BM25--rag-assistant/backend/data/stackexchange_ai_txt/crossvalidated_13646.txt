[site]: crossvalidated
[post_id]: 13646
[parent_id]: 13643
[tags]: 
Bias is the difference between the expected value of an estimator and the true value being estimated. For example the sample mean for a simple random sample (SRS) is an unbiased estimator of the population mean because if you take all the possible SRS's find their means, and take the mean of those means then you will get the population mean (for finite populations this is just algebra to show this). But if we use a sampling mechanism that is somehow related to the value then the mean can become biased, think of a random digit dialing sample asking a question about income. If there is positive correlation between number of phone numbers someone has and their income (poor people only have a few phone numbers that they can be reached at while richer people have more) then the sample will be more likely to include more people with higher incomes and therefore the mean income in the sample will tend to be higher than the population income. The are also some estimators that are naturally biased. The trimmed mean will be biased for a skewed population/distribution. The standard variance is unbiased for SRS's if either the population mean is used with denominator $n$ or the sample mean is used with denominator $n-1$. Here is a simple example using R, we generate a bunch of samples from a normal with mean 0 and standard deviation 1, then compute the average mean, variance, and standard deviation from the samples. Notice how close the mean and variance averages are to the true values (sampling error means they won't be exact), now compare the mean sd, it is a biased estimator (though not hugely biased). > tmp.data mean( apply(tmp.data, 1, mean) ) [1] 0.0001561002 > mean( apply(tmp.data, 1, var) ) [1] 1.000109 > mean( apply(tmp.data, 1, sd) ) [1] 0.9727121 In regression we can get biased estimators of slopes by doing stepwise regression. A variable is more likely to be kept in a stepwise regression if the estimated slope is further from 0 and more likely to be dropped if it is closer to 0, so this is biased sampling and the slopes in the final model will tend to be further from 0 than the true slope. Techniques like the lasso and ridge regression bias slopes towards 0 to counter the selection bias away from 0.
