[site]: datascience
[post_id]: 68785
[parent_id]: 
[tags]: 
Interpretable xgboost - Calculate cover feature importance

When trying to interpret the results of a gradient boosting (or any decision tree) one can plot the feature importance. There are same parameters in the xgb api such as: weight, gain, cover, total_gain and total_cover. I am not quite getting cover. ”cover” is the average coverage of splits which use the feature where coverage is defined as the number of samples affected by the split I am looking for a better definition of cover and perhaps some pseudocode to understand it better.
