[site]: crossvalidated
[post_id]: 571326
[parent_id]: 571322
[tags]: 
Maximum likelihood estimation exists for a reason. The gold standard objective function--the one that results in the best coefficients--is the log likelihood plus the penalty function. The penalty can be a variety of functions. The best penalty is the log prior, resulting in Bayesian estimates. No penalty means you get ordinary maximum likelihood estimates, which are fine if your effective sample size (roughly the minimum of the number of outcome events or the number of non-events) is large in comparison with the number of predictor parameters. Note that split-sample validation is not a good idea unless n>20,000 give-or-take. Details about all this are in RMS .
