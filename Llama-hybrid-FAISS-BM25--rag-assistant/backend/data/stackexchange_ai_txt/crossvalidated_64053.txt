[site]: crossvalidated
[post_id]: 64053
[parent_id]: 
[tags]: 
SVM has relatively low classification rate for high-dimensional data even though 2-D projections show they are separable

I have another problem with 14000 features and 500 training samples. It is a binary classification problem and approximately in the form of an ellipse. My classification accuracy using the 2nd degree polynomial Kernel and via CV is ~ 80%. However, I've randomly tried projecting the data onto 2-D, that is I just pick out two features and project them, and find that there are several combinations that give me 100% separation. I've also used the RB kernel and the classification accuracy is ~70% for that. Does anyone have a reason why this is happening? This is the code I'm using for libsvm... % train SVM model model = svmtrain2(Y(train_vec,1),X(train_vec,:),['-t 1 ' '-d 2 ' '-g ' num2str(grid_data(i,1)) ' ' '-r ' num2str(grid_data(i,2)) ' ' '-c ' num2str(C)]); % test model on test set [predict_label, accuracy, dec_values] = svmpredict(Y(test_vec,1),X(test_vec,:),model);
