[site]: crossvalidated
[post_id]: 345595
[parent_id]: 345469
[tags]: 
Terminology A "forward pass" just means you put inputs in and propagate through the network, which in most implementations is a bunch of matrix multiplications and point-wise function applications. At the end, you get a set of outputs. During training, the outputs are compared to what the answer should be, and the differences between the two--as measured by a loss function--are used to update model parameters, so now that input will cause the output to look a little bit more like the should-be answer. Once the model is trained there is no backpropagation, no model-parameter-updating step, so there is no need to use the loss function. Actually, if you pass in some new input for which you don't know the answer, then there is nothing to compare the output against, so you don't even have all the information necessary to find a loss. Keras I interpret the methods you describe to be the same, at least by architecture: In both cases you use a convolutional network to get some simplified features out of the raw data and then pass those to a classifier that tells you something useful. But there might be a difference in how they're trained. The word "frozen" implies that you train the CNN first and then stop updating its parameters while you train the classifier as a separate step. You can train the classifier via supervised learning because you presumably know what the classifications should be. But how do you train the CNN? One possibility is with an autoencoder architecture: A network tries to compress the input down to some smaller representation, and then a mirror network re-expands from that representation to the original space. (Imagine an input image compressed down to some key features and then propagated through a reverse network to yield a blurry or distorted version of the image.) The program can then use the difference between the true and re-constituted versions to decide how to update the network so that it can more accurately re-represent the input next time. Then take the first half (the compression part) of this autoencoder to be the CNN for your other problem. Voila. But you say this is more expensive than the alternative: In principle it should be possible to backpropagate through all layers of both networks, so you could train both at once. This is likely what is happening in the method you say doesn't take as long.
