[site]: crossvalidated
[post_id]: 216126
[parent_id]: 215970
[tags]: 
The comments are quite accurate, to summarize (and calling $p$ the number of simulateneous workers you have) the complexities should be (depending on the implementations) : Random Forest : $O(n_{trees}*n* \log (n) / p)$ Neural Network : $O(n_{neurons}*size_{neurons}*n/p)$ The speed will also depend on the implementation, the $O$ just gives information about the scalability of the prediction part. The constant term omitted with the $O$ notations can be critical. Indeed, you should expect random forests to be slower than neural networks. To speed things up, you can try : using other libraries (I have never used Matlab's random forest though) reducing the depth of the trees (which will replace the $\log(n)$ by a constant term and allow you to use more workers - but this may harm the accuracy of the classifier) check for duplicate features / constant columns in your data set and remove them (they do not improve accuracy and are responsible for a greater memory usage) [Edit] is your data sparse ? I observed huge speed-ups using the "sparse" representations of the data (as long as the learning algorithms support it)
