[site]: crossvalidated
[post_id]: 295509
[parent_id]: 
[tags]: 
Logistic Regression Results seem Inconsistent

I have a dataset with 53k samples and 12 predictors, divided in this way: 15k - Group 1 10k - Group 2 8k - Group 3 7k - Group 4 4k - Group 5 4k - Group 6 2k - Group 7 2k - Group 8 1k - Group 9 1k - Group 10 The dependent variable is binary (0/1) and the groups are in decreasing order of likelihood of Y=1, basically. So the distribution of Y is skewed towards 0s in the lower groups and 1s in the higher groups (for example: G1 has 12k 1s and 3k 0s). After running a Logistic Regression on each group separately and the entire dataset, these are the coefficients and p-values for predictor P: Coefficient p-value Group 1 0.4392 0.0905 Group 2 0.1923 0.1333 Group 3 0.1222 0.6540 Group 4 0.101 0.5599 Group 5 -0.353 0.7000 Group 6 -0.005 0.6889 Group 7 -0.0208 0.9343 Group 8 0.184 0.9268 Group 9 0.2722 0.4466 Group 10 0.1009 0.3230 Overall 0.8842 4*e^-16 Now, I've never had to run a Logistic Regression on subsets of a dataset and the entire dataset, but is it possible that the coefficient is so strong and significant for the whole dataset while being insignificant in all the other groups? My intuition is yes, because there's more data, but anyone have any ideas? The code for the Logistic Regression is very basic: glm.fit.1 Repeated for each group + entire dataset
