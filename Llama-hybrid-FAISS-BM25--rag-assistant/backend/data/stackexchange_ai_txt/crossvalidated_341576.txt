[site]: crossvalidated
[post_id]: 341576
[parent_id]: 341432
[tags]: 
I think the use-case described: "empirical reasons to expect that each time series can be well described by a function with a small number of parameters, but the parameters can vary across time series " fits naturally within the context of functional principal component analysis (FPCA). Through FPCA we are able to define principal modes of variations that are defined as functions over a continuum (eg. time) rather than a multi-dimensional discretised space (like it is typically done in standard PCA). Given that we will zero-centred our data by subtracting their mean, we can then estimate their covariance and through that get their principal modes of variations in the form of the eigenfunctions of that covariances. To draw a direct analogy with the phraseology in the post: The FPC scores (ie. the projections of the original sample over the axis system defined by the eigenfunctions) can be use the " small number of parameters " to describe each functions and the eigenfunctions themselves are " extract(ed) and visualize an appropriate "shape" or "type" of function directly from the data ". Notice that FPCA is a non-parametric technique so we do not need to worry about an exact parametric form for the functions of the sample or the derived "features"/eigenfunctions of the sample. CRAN has a whole task view on the analysis of functional data .
