[site]: crossvalidated
[post_id]: 619658
[parent_id]: 616082
[tags]: 
The uncomfortable truth is that any "validity index" for clustering is mostly pointless if it does not relate to anything that is really actionable. Based on our understanding of the data we need to pragmatically validate our clustering results. Do they tell us anything new or even half-reasonable? CV.SE has some great threads on the matter: eg. see How to select a clustering method? How to validate a cluster solution (to warrant the method choice)? and Can any dataset be clustered or does there need to be some sort of pattern in the data? for starters. In general, clustering is used first and foremost about structure discovery, about uncovering hidden patterns. Particular to the use case described now, if we cluster a 2D embedding from some dimensionality reduction algorithm (UMAP, t-SNE, LLE, whatever) but we have no way to understand if the clustering translates to anything meaningful in the original data domain, irrespective of what our favourite metric of "clustering validity" suggest, that clustering is pretty useless for EDA purposes. (It might still be good for predictive purposes but that's not our main point here.) In that sense, DBCV just says that we have clear clusters in terms of their density and shape properties. Whether or not those clusters though reflect anything non-trivial or just noise, that is for the analyst to decide. The above being said and focusing again to the use case described, yes, UMAP does to some extent " artificially eliminate noise ". As it tries to retain as much structure as possible, as we lower the number of embedding dimensions, only the strongest signal is retained as it is more easily captured. That means that weaker signal/structure is not retained, whether that reflect real information or just background noise is unclear. Notice that almost every dimensionality reduction algorithm has to do this though! So in that sense, the fact we observe lower dimensions having better DBCV is expected. So all in all, there is no better metric for clustering usefulness. Most these metrics are helpful to say if " a clustering is there " not whether " a reasonable clustering is there ". Combining therefore a clustering procedure (e.g. HDBSCAN) with a dimensionality reduction technique (e.g. UMAP) that really tries to pack points together, can give us interesting results but we need some thinking regarding the results' usefulness as no domain-agnostic metric (DBCV, Silhouette Width, etc.) will ever provide that.
