[site]: crossvalidated
[post_id]: 176740
[parent_id]: 
[tags]: 
Finding ideal hypothetical data according to a regression model

Analogy We have 10 athletes. Each athlete is represented as a binary feature vector. We make these athletes compete in a 100 metre race. We get real value numbers corresponding to the time they took in the race. We train a model from athlete features to time. Now, say we want to imagine a hypothetical athlete that runs the 100 metre race as quickly as possible, what feature vector (or vectors) would our model need to predict the fastest time? As human beings it seems that we do this all the time. "Imagine how fast Usain Bolt would run if he had bionic legs." In fact, one could view any kind of training as the process of attempting to adjust our features towards those that we believe will make us perform better. How do we decide what those hypothetical features are? Technical Inverse regression as I understand it is the problem of learning the expectation of data given labels according to a model. It answers the question, if a model predicts a label, what observation was it that resulted in this prediction? Say that we've learnt a Bayesian linear regression model from data that is a binary feature vector (e.g. $ $ indicating if a feature is active or not) and a response value $r \in \mathbb{R}$, how would I use inverse regression to tell me what hypothetical data would be required to give me a particular value of $r$. Or if not a particular value, the maximum/minimum value of $r$ that my model might predict given hypothetical data. I could of course just try all $2^n$ feature combinations where $n$ is the number of features. However, there must be a more efficient way of doing this?
