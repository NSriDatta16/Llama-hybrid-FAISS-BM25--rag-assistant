[site]: crossvalidated
[post_id]: 634984
[parent_id]: 
[tags]: 
Instance segmentation using a discriminative loss?

I have been reading this paper and I was wondering if their discriminitive loss definition is correct for instance segmentation ? From what I understand they map the image pixels into a higher dimension and try to cluster them according to the instance they belong to. There is a loss term that "pulls" pixel embeddings that belong to the same class towards their mean (L_var) while the other term "pushes" away means of different instances (L_dist). But the problem is this is a setup for classification where we have a finite number of classes. But in instance segmentation each instance should have their own separate cluster which easily runs into the curse of dimensionality problem. In addition how can the function map an unseen instance to its own separate cluster during inference ? I think the loss function is actually classifying the instances based on their appearance plus the location of the pixels in the image. So instances that look the similar and overlap will always be a source of error for this model. I would appreciate it if someone could shed some light on this.
