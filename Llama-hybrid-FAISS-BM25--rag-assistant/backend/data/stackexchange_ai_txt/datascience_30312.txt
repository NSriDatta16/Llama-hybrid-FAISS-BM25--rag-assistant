[site]: datascience
[post_id]: 30312
[parent_id]: 
[tags]: 
Regression coefficients vs feature_importances_ vs none

On looking at various machine learning methods at the scikit-learn , it appears that some modules such as LinearRegression provide coefficients ( coef_ ), others such as AdaBoostRegressor provide feature_importances_ while some e.g. BaggingRegressor and BernoulliNB do not provide either of these. Why this difference? Are coef_ similar to feature_importances_ to assess the contribution of a variable in prediction? How to assess the feature importance for modules where neither of these is available?
