[site]: datascience
[post_id]: 67898
[parent_id]: 
[tags]: 
EfficientNet: Compound scaling method intuition

I was reading the paper EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks and couldn't get my head around this sentence: Intuitively, the compound scaling method makes sense because if the input image is bigger, then the network needs more layers to increase the receptive field and more channels to capture more fine-grained patterns on the bigger image . In the case of a big image, why the network needs more layers to increase the receptive field ? What does increasing the receptive field mean? Increasing its width/height ? If so, we can do it directly without increasing the number of layer in the network no ? is "fine-grained patterns" referring to noisy shape we can see after visualizing convolution output ? I feel like I am missing / misunderstanding something evident.
