[site]: datascience
[post_id]: 78318
[parent_id]: 78296
[tags]: 
The effect will be increasing the intercept. I don't recommend doing oversampling unless any other solution doesn't work. Besides, 10% is not such a big imbalance. I've been in kaggle competitions with way more imbalance where no imbalance solutions were adopted, logistic regression and random forest work quite well without the need of these. Edit After @Ben Reininger input, here's a theoretical justification on how does the intercept change. Also, a quick experiment showcasing that over-sampling doesn't help improve a metric like AUC, and that it indeed increases the intercept of the logistic regression model.
