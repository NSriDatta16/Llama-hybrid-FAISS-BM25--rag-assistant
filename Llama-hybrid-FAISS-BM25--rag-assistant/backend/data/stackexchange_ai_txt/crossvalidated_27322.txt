[site]: crossvalidated
[post_id]: 27322
[parent_id]: 
[tags]: 
Are logistic regression coefficient estimates biased when the predictor has large variance?

I'm simulating data from a logistic regression model: log(p/1-p)= 0 + X where $X \sim N(0,\sigma^2)$. After I simulate the data, I fit a logistic regression model to the data and compare the fitted regression coefficients to the actual regression coefficients. I've noticed that as I increase $\sigma$ (i.e. the variance of the original $X$ data) the fitted regression coefficient for $X$ (i.e. $\beta_1$) is consistently greater than 1 (however, the sd of the estimate also increased so 1 is still contained in the confidence interval for beta1) I was wondering why when you increase the variance, the fitted $\beta_1$'s tend to be greater than the actual $\beta_1$ (i.e. $\beta_1 = 1$), not less than? Is there a statistical explanation for this? Thanks! beta0 = 0 beta1 = 1 sigma = 1 number_samples = 10000 genLogit = function(pos_prop,sd){ generated_data = c() xtest = rnorm(10000,0,sd) linpred = beta0 + (xtest * beta1) prob = exp(linpred)/ (1+exp(linpred)) runis = runif(10000,0,1) ytest = ifelse(runis If you run genLogit(.5,1000) this is generating balanced (50/50) data with X distributed normal(0,1000). Running it multiple times, I get a beta0 estimate much greater than 0.
