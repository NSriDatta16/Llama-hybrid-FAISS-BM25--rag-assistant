[site]: crossvalidated
[post_id]: 406254
[parent_id]: 148357
[tags]: 
It has been awhile, but this is still getting upvotes. So ... In the event, I did use a Random Forest, and it worked really well. A boosted tree did a bit better that that even. Also since then I know of several other similar projects that took the same route with success and very little fuss. While ARIMA is surely a powerful method with a distinguished history, it seems in today's world the ensemble methods will usually get you where you want to go much quicker, but maybe with the disadvantage of not shed as much light as to what is really going on under the covers. One thing to watch out for is don't just split your training/test set randomly and test on it, you have to chunk it out so that the test points are not right up against to the training points (on the time axis). This is necessary for any time series which has slowly changing data, otherwise the forest always gets to see training points almost identical to the test points and will thus fit it almost exactly, giving you highly misleading performance that will not reflect real life performance on unseen data.I made that mistake in the first round and was euphoric about my model explaining 90% plus of the variation - for about a day until I realized what was going on. 60% to 80% was what it really did.
