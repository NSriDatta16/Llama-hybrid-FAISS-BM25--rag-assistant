[site]: crossvalidated
[post_id]: 507354
[parent_id]: 507164
[tags]: 
Many of your questions cannot be answered definitively and require you to make some ad hoc decisions prior to estimating your model. I will address each question and comment, in turn. I am in the process of setting up a difference-in-differences analysis (DiD) to evaluate a particular policy. It was launched on the year 2000, and it basically is relevant in ten-year periods. One important thing to notice is that different units (communities) started treatment in different years. This is not a problem. However, you must use the generalized difference-in-differences (DiD) estimator. This will account for the different subsets of communities with different policy adoption periods. I have full treatment information (2000 to 2020) and I have access to my outcome variable for the years 2000 to 2012 (it's GIS forest cover data). So that means, for the first 10 years of the policy, and two periods after it. It appears the time variation in your outcome does not span the full policy period. I would assume the late adopter communities have a longer treatment phase than the early adopters, but it isn't clear from your question. It isn't fatal to subject treated communities to a scanty number of post-treatment years. However, it will be difficult to nail down your treatment effect if it takes more than two years before the policy reaches its full effect. Or, suppose theory suggests effects accumulate over time. You cannot possibly address any long-run effects with a transient exposure epoch. Does this mean I should mostly focus on the communities that were treated in 2000, 2001, and 2002 (given my outcome variable)? Maybe. If you only observe outcomes during the interval from 2000–2012, then I assume the early adopter communities (i.e., pre-2000) do not have any pre-treatment data prior to the year 2000. Thus, it might be worthwhile in your setting to restrict attention to the communities with policy adoption periods within the three-year window you referenced. Your comments do suggest a subset of treated and/or untreated communities do not have any pre-policy data. But which ones? And how many? I just hope you don't lose too many clusters by dropping too many early adopter communities. My first question is, would 2 time periods suffice? I believe I need 3 at least to test pre-trends (there is a good chance I do get 3 time periods, but want to know for sure). Serial observations before policy adoption is not necessary—but is very much preferred . At least three pre-policy periods is recommended. It is rare today to find a DiD evaluation with less than three pre-treatment time periods. My second question is, does the pre-policy time periods used for the pre-trend analysis have to be continuous (e.g., 1986 to 1991), or do they have to be adjacent to the date the policy was launched (e.g., 1995 until 1999)? Your first parenthetical time interval suggests an 8-year gap before the intervention, assuming the year 2000 is the initial adoption year. Think of all the possible pseudo-paths your outcome could have taken pre-shock. For instance, suppose outcomes in treated communities trend upward before policy implementation, while untreated communities remain unchanged. Effects will be overstated in the post-period should outcomes in treated communities mean revert to pre-policy levels. How would you statistically model the pre-period spike with missing pre-policy data? You can't. In fact, you would have to make some strong theoretical assumptions about how your outcome was trending before the policy went into effect. Maybe the individuals nested within your communities anticipated the impending policy, which is often the case in settings where a sufficient time gap exists between the announcement of the policy and its ultimate effective date. Assessing anticipatory behavior may be worth exploring in periods approaching program exposure. But you have little hope of investigating any anticipatory effects if the years close to your initial treatment are entirely absent. In general, the years relative to treatment should be evenly spaced, and temporally adjacent to the policy adoption period. Your second parenthetical time interval is preferred , which again is assuming the initial treatment is implemented in the year 2000. Each unit is observed over five evenly spaced yearly time periods pre-shock. Your years should move in regular intervals until treatment begins. Any gap in your time series invites deception into your plot(s) of the group trends, especially if you assume equidistant spacing over a multi-year gap. As a graphical recommendation: do not arbitrarily impose uniform intervals over an irregular time series. You do not want to be accused of visually manufacturing outcome variation over time. To borrow a line from Edward R. Tufte's book The Visual Display of Quantitative Information : "A steady canvas makes for a clearer picture" (p. 61). In sum, eschew any deception by arbitrary design variation. Instead, be transparent about what's missing. If your time series is highly irregular in the pre-policy epoch, then you may want to consider using some interpolation methods to help transform the series into evenly spaced time units. However, this introduces bias if the missing time series information is long. A larger and larger void between the last pre-treatment period and the immediate (first) treatment year exacerbates the interpolation bias. Interpolate with caution. And third, does the pre-policy data HAVE to be of the same quality of the policy data (in GIS terms it's somewhat hard to find data for those years for the area I am looking into). It should . This question suggests non-random measurement error in your outcome variable. Why is the resolution of lesser quality in the pre-period? Is it a software issue? If it's due to the absence of sufficient data pre-policy, then this is unfortunate. My only recommendation is to get more data. Should you select more distant pre-policy years further from the initial treatment, then I suppose this is better than no data at all. Just be prepared to defend your decisions!
