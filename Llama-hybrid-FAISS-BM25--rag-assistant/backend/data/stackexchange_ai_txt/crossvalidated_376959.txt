[site]: crossvalidated
[post_id]: 376959
[parent_id]: 
[tags]: 
Random Forest % Var explained OOB output differs from test dataset results

I am learning how to use Random Forest in R for regression based on the Boston dataset. I am unsure on which values I should concentrate to evaluate the obtained model, the OOB % Var explained and MSE of the model output, or the results I obtain applying the random forest model to a validation set. In a first step I split the Boston dataset in a Training and a Validation set require(randomForest) require(MASS) attach(Boston) set.seed(100) train Then perform random forest based on the TrainSet set.seed(100) Boston.rf In a next step I use the obtained model to predict the variable in the independent validation set and use the results to obtain r-square and the MSE and RMSE of the validation set. predvalidSet |t|) (Intercept) -1.87664 0.69482 -2.701 0.00771 ** predvalidSet 1.06294 0.02916 36.448 The r-square value is higher and MSE and RMSE are lower in the validation set than the output of the random forest model directly (the OOB % Var explained and MSE). In general, what values should I choose to evaluate the model and its predictive ability? I tend towards using the values obtained based on the validation set. Thanks in advance!
