[site]: datascience
[post_id]: 75770
[parent_id]: 66802
[tags]: 
My answer would be to perform LDA in each fold of your cross-validation. The reason is the following. Cross-validation is used as a way to get an estimate of the performance of the model. This estimate essentially attempts to answer the following question: How will my model perform when trained on an arbitrary set of data If you don't use cross-validation, you always run a small risk that the model is specifically good for that particular training set. And perhaps, if your training data changes, your model won't learn as well. This is why you want to run LDA on each fold. If you don't, you risk the fact that the impact of LDA on your SVM may become negative once your training data changes. Of course, once you've run cross-validation and found the best hyperparameter setup, you should train your model once on all of your data.
