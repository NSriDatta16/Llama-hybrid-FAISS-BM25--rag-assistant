[site]: crossvalidated
[post_id]: 626912
[parent_id]: 626862
[tags]: 
My suggestion is to think hard about what you really want to know. Explained variance gets funky once you move from the relatively straightforward situations of OLS linear regression. If a customer is demanding this, press them on what they want to know, or go with your judgment of what they want to know or should want to know. The usual measure of the proportion of variance explained in a regression is the $R^2$ value: $R^2 = 1-\dfrac{\sum_i(y_i - \hat{y_i})^2}{\sum_i(y_i - \bar{y})^2}$ . Here , I derive how this value corresponds to the proportion of variance explained in OLS linear regression. The key point there is that, once you leave the world of least squares linear regression, there is more to the total sum of squares than the regression and residual sum of squares. It is not at all obvious to me what to do with that third component of the total sum of squares, which is why I am comfortable using $R^2$ as a transformation of square loss that might make more sense than just the sum or mean of the squared residuals, but I stop short of saying that the above equation corresponds with the proportion of variance explained. You're looking at individual features, so some kind of partial $R^2$ , but a similar idea exists. With the differences your model has from linear regression, the usual $R^2$ does not necessarily correspond to the proportion of variance explained. I see three reasonable approaches. Just do the usual calculation for a partial $R^2$ . Nothing stops you from using square loss to evaluate a logistic regression. This is the Brier score, and the pseudo $R^2$ based on Brier score is Efron's pseudo $R^2$ , as is discussed on this UCLA page . Drag along that cross term in the linked derivation (or the analogous derivation for partial $R^2$ ). This, arguably, relates more to the proportion of variance explained than just assuming that term to be zero like it is in OLS linear regression. Calculate partial pseudo $R^2$ based on the binomial likelihood, as discussed in another answer . This relates to the McFadden pseudo $R^2$ . I think I would go with the third option while noting that this is more accurately described as assessing the proportion of deviance explained instead of variance explained . However, binomial deviance is somewhat more natural to use than square loss (Gaussian deviance) for a binomial outcome, so I think such an assessment is really getting at the key aspects of the inquiry into which features have the most influence over the outcome.
