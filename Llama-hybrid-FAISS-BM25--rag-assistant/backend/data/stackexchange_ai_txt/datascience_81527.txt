[site]: datascience
[post_id]: 81527
[parent_id]: 81526
[tags]: 
As you quoted The padding argument effectively adds dilation * (kernel_size - 1) - padding , so you see the padding value is subtracted, the resulting shape becomes lower. It's a reverse (in some sense) operation to Conv2d, which means the arguments work the opposite way here. And I think this behavior is introduced to make it easier to design neural nets with symmetric architecture (like autoencoders) -- you just copy the parameters of kernel size, stride and padding from the corresponding Conv2d layer and get an operation which preserves the input shape of an image.
