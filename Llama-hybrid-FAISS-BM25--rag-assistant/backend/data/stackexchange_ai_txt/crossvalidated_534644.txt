[site]: crossvalidated
[post_id]: 534644
[parent_id]: 
[tags]: 
Feature importance and selection on an unbalanced dataset

I have a dataset which I intend to use for Binary Classification. However my dataset is very unbalanced due to the very nature of the data itself(the positives are quite rare). The negatives are 99.8% and the positives are 0.02% . I have approximately 60 variables in my dataset. I would like to do a feature importance test to eliminate less useful features. However I cannot directly run methods to do that, due to the unbalanced nature of the dataset. How do I approach this problem? P.s I plan to use Gradient Boosting and/or Neural Networks to work on this dataset.
