[site]: crossvalidated
[post_id]: 313487
[parent_id]: 313405
[tags]: 
Yes. Providing fine-grained labels can help, and probably doesn't hurt, although it's hard to say exactly how much it would help. To provide a concrete example, suppose most vehicles tend to have wheels, except boats, which have propellers instead. Also, most non-vehicles have neither wheels nor propellers. Then if you train the network to classify an object as car, boat, or non-vehicle, the network will probably learn a wheel-detector and a propeller-detector (features which correspond to wheel/propeller), which happens to be very useful for classifying an object as vehicle or non-vehicle. It's possible for the network to learn such a wheel/propeller detector without the extra labels. However, labeling each vehicle as car or boat would make it more likely, as the network is directly encouraged to learn "part features" such as wheel/propeller, in order to discriminate between the two classes. This is similar to the idea of multi-task learning, where training a network to do many things often results in better performance than just training it to do one thing, because those "many things" cause the network to learn better features. Note that to do this properly, you may have to adjust the capacity of your network. Otherwise, if the network has enough capacity to perform well at binary but not multi-class classification, the performance may be poor. Also since the ultimate goal is to minimize the binary cross-entropy, not the multiclass cross-entropy, you might want to adjust the losses appropriately, so that being confused between two vehicles incurs less loss than being confused between a vehicle and a non-vehicle.
