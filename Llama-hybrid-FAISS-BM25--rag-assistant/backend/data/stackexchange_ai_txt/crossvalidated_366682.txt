[site]: crossvalidated
[post_id]: 366682
[parent_id]: 366623
[tags]: 
You are right, lazy learning is feasible for competitions like kaggle. However their issue comes from the fact that they are based on distances which actually incorporate some part of knowledge. Simple distance functions require complex data transformation, complex distance functions require less data transformation. As such to have in the end proper distances you have to put your learning bias either in distance function complexity either in feature transformation. Either way it is a knowledge introduced by designer not learned automatically. This is the hard part. Because most of the observations are not measured in a way aligned with true structure of the data to answer the learning question. Imagine for example that your true model is $E=mc^2$. You have measured m, c and E. You want to regress E on the other features. If you use a regression technique which can find interaction terms automatically you have a chance to fit a model which approximates well, otherwise you would have to introduce it yourself. In the case of knn either in distance either in feature engineering.
