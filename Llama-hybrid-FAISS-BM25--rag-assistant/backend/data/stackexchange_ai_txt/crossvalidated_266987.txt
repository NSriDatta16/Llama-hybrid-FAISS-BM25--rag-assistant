[site]: crossvalidated
[post_id]: 266987
[parent_id]: 89863
[tags]: 
Backpropagation is basically a clever way of expressing and calculating the gradient of a cost function, which depends on known target labels and its corresponding inputs. That is the original formulation of CNNs. They are step beyond traditional MLPs, where features are not designed, but automatically learned from data, so that the recognition rate is maximized (with respect to known labels). If I understood you question properly, I would reformulate it like: is it possible to train a discriminative model without labels (just data, or partially labelled data?). What I networks does is defined by the loss (or energy) function it minimizes. What sort of gradient based optimization technique you apply, depends on that energy function. This topic is analyzed in detail in the following references: Loss Functions for Discriminative Training of Energy-Based Models A Tutorial on Energy-Based Learning
