[site]: stackoverflow
[post_id]: 1931359
[parent_id]: 
[tags]: 
How to reduce calculation of average to sub-sets in a general way?

Edit: Since it appears nobody is reading the original question this links to, let me bring in a synopsis of it here. The original problem, as asked by someone else, was that, given a large number of values, where the sum would exceed what a data type of Double would hold, how can one calculate the average of those values. There was several answers that said to calculate in sets, like taking 50 and 50 numbers, and calculating the average inside those sets, and then finally take the average of all those sets and combine those to get the final average value. My position was that unless you can guarantee that all those values can be split into a number of equally sized sets , you cannot use this approach. Someone dared me to ask the question here, in order to provide the answer, so here it is. Basically, given an arbitrary number of values, where: I know the number of values beforehand (but again, how would your answer change if you didn't?`) I cannot gather up all the numbers, nor can I sum them (the sum will be too big for a normal data type in your programming language) how can I calculate the average? The rest of the question here outlines how, and the problems with, the approach to split into equally sized sets, but I'd really just like to know how you can do it. Note that I know perfectly well enough math to know that in math theory terms, calculating the sum of A[1..N]/N will give me the average, let's assume that there are reasons that it isn't just as simple, and I need to split up the workload, and that the number of values isn't necessarily going to be divisable by 3, 7, 50, 1000 or whatever. In other words, the solution I'm after will have to be general. From this question: What is a good solution for calculating an average where the sum of all values exceeds a doubleâ€™s limits? my position was that splitting the workload up into sets is no good, unless you can ensure that the size of those sets are equal. Edit : The original question was about the upper limit that a particular data type could hold, and since he was summing up a lot of numbers (count that was given as example was 10^9), the data type could not hold the sum. Since this was a problem in the original solution, I'm assuming (and this is a prerequisite for my question, sorry for missing that) that the numbers are too big to give any meaningful answers. So, dividing by the total number of values directly is out. The original reason for why a normal SUM/COUNT solution was out was that SUM would overflow, but let's assume, for this question that SET-SET/SET-SIZE will underflow, or whatever. The important part is that I cannot simply sum, I cannot simply divide by the number of total values. If I cannot do that, will my approach work, or not, and what can I do to fix it? Let me outline the problem. Let's assume you're going to calculate the average of the numbers 1 through 6, but you cannot (for whatever reason) do so by summing the numbers, counting the numbers, and then dividing the sum by the count. In other words, you cannot simply do (1+2+3+4+5+6)/6. In other words, SUM(1..6)/COUNT(1..6) is out. We're not considering NULL's (as in database NULL's) here. Several of the answers to that question alluded to being able to split the numbers being averaged into sets, say 3 or 50 or 1000 numbers, then calculating some number for that, and then finally combining those values to get the final average. My position is that this is not possible in the general case, since this will make some numbers, the ones appearing in the final set, more or less valuable than all the ones in the previous sets, unless you can split all the numbers into equally sized sets. For instance, to calculate the average of 1-6, you can split it up into sets of 3 numbers like this: / 1 2 3 \ / 4 5 6 \ | - + - + - | + | - + - + - | \ 3 3 3 / \ 3 3 3 / Which gives you this: 2 5 - + - = 3.5 2 2 (note: (1+2+3+4+5+6)/6 = 3.5, so this is correct here) However, my point is that once the number of values cannot be split into a number of equally sized sets, this method falls apart. For instance, what about the sequence 1-7, which contains a prime number of values. Can a similar approach, that won't sum all the values, and count all the values, in one go, work? So, is there such an approach? How do I calculate the average of an arbitrary number of values in which the following holds true: I cannot do a normal sum/count approach, for whatever reason I know the number of values beforehand (what if I don't, will that change the answer?)
