[site]: crossvalidated
[post_id]: 584730
[parent_id]: 415943
[tags]: 
How can we figure out whether or not an algorithm or approach will be negatively affected by class imbalance? First, data. See if the instances in the minority class have sufficient signal for the model to learn. If not, it becomes a few-shot learning problem, and the model may assume the rare classes just don't exist. Second, output evaluation. See if the metric you use is appropriate. If you simply use accuracy, your model probably tends to just learn the very straightforward heuristic: always output the majority class. Otherwise its performance becomes worse even though it is trying to learn the underlaying data patterns. Third, outcome evaluation. Your approach will be negatively affected by class imbalance if the cost of a wrong prediction on a sample of the rare class is much higher than that of the majority class. From the algorithmic perspective, this may help: Some tasks are more sensitive to class imbalance than others. Japkowicz showed that sensitivity to imbalance increases with the complexity of the problem, and that noncomplex, linearly separable problems are unaffected by all levels of class imbalance. Class imbalance in binary classification problems is a much easier problem than class imbalance in multiclass classification problems. Ding et al. showed that very deep neural networks—with “very deep” meaning over 10 layers back in 2017—performed much better on imbalanced data than shallower neural networks. References: Designing Machine Learning Systems
