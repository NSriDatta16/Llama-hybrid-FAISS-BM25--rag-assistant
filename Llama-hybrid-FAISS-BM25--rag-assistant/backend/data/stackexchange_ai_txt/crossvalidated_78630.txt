[site]: crossvalidated
[post_id]: 78630
[parent_id]: 78621
[tags]: 
Yes, ridge regression can be used as a classifier, just code the response labels as -1 and +1 and fit the regression model as normal. Allen's PRESS statistic (i.e. the leave-one-out estimate of the squared error) works fine as a model selection criterion (e.g. for selecting the ridge parameter). In my experience it works about as well as a linear support vector machine on most problems (the main reason the SVM is a good classifier is that it is regularised - the difference in the loss function is secondary). Note this is also equivalent to a linear Least-Squares Support Vector Machine, which is a quite well regarded classifier. Standard ridge regression will not give you sparsity though, for that you want an L1 (LASSO) type penalty function, in which case I would recommend LARS, or perhaps L1 regularised logistic regression.
