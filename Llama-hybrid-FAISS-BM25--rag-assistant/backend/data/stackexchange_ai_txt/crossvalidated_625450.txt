[site]: crossvalidated
[post_id]: 625450
[parent_id]: 625445
[tags]: 
My interpretation would be that this describes the number of distinct layers with learnable parameters to get a sense of overall network depth. Each of the described "fire modules" consists of [1x1 conv] - ReLU - [1x1conv, 3x3conv] - ReLU , i.e., we have two distinct layers with learnable parameters per module (depth = 2). The two layers conv1 and conv10 are simple convolution layers with a single activation, leading to a depth of 1. Max/average pooling does not have learnable parameters and therefore has depth 0
