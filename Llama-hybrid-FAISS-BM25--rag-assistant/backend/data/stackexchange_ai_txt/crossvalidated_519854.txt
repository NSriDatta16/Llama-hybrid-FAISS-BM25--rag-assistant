[site]: crossvalidated
[post_id]: 519854
[parent_id]: 
[tags]: 
Likelihood from DAG

I am reading a paper, where the authors state a different likelihood function, than the one I keep deriving. Therefore, I was wondering where I am making a wrong turn. The model is a hierarchical Bayesian model, which is described by a Bayesian network / directed acyclic graph / DAG: We have observed variables: $$ O = \{X,Y\}$$ Hidden variables: $$ H = \{ Z, \beta, \pi, \theta\} $$ and priors: $$ \Pi = \{ \beta^0, \pi^0, \theta^0 \}$$ and I want to derive $$P(O,H|\Pi)$$ . First, we split up the equation according to the DAG: \begin{equation} \begin{aligned} p(O,H|\Pi) & = p(\{X,Y\}, \{ Z, \beta, \pi, \theta\} | \Pi) \\ & = p(\{X,Y\} | \{ Z, \beta, \pi, \theta\} \Pi) p( \{ Z, \beta, \pi, \theta\} | \Pi) \\ & = p(\{X\} | \{ Z, \pi\}, \Pi) p(\{Y\} | \{ Z, \beta\}, \Pi) p( \{ Z, \beta, \pi, \theta\} | \Pi) \\ & = p(\{X\} | \{ Z, \pi\}, \Pi) p(\{Y\} | \{ Z, \beta\}, \Pi) p( \{ Z \} | \{ \theta\}, \Pi) p( \{ \theta\} | \Pi) p( \{ \beta \} | \Pi) p( \{ \pi\} | \Pi) \\ \end{aligned} \end{equation} where I use set notation for multiple r.v., e.g. $\{X\}=\{x_{ij}\}_{i=1,j=1}^{L_j,J}$ . So far so good. Let $i \in \{1,...,L_j\}$ , $j \in \{1,...,J\}$ and $k \in \{1,...,K\}$ . When I want to write out the likelihood explicitly using the replications ( $K$ , $J$ and $L_j$ ), how does that reflect in products? My understanding is that I always need to take the product over all replicators present in an equation, e.g. $$p(\{Y\}|\{Z,\beta \}) = \prod_j^J \prod_k^K \prod_i^{L_j} p(y_{ij}|z_{ij}, \beta_{jk})$$ So here my derivation of the full likelihood (with slight abuse of set notation): \begin{equation} \begin{aligned} p(O,H|\Pi) & = p(\{x_{ij}\} | \{ z_{ij}, \pi_k \}, \Pi) p(\{y_{ij}\} | \{ z_{ij}, \beta_{jk}\}, \Pi) p( \{ z_{ij} \} | \{ \theta_j \}, \Pi) p( \{ \theta_j \} | \Pi) p( \{ \beta_{jk} \} | \Pi) p( \{ \pi_k\} | \Pi) \\ & = \prod_j^J \Big\{ p(\{x_{ij}\} | \{ z_{ij}, \pi_k \}, \Pi) p(\{y_{ij}\} | \{ z_{ij}, \beta_{jk}\}, \Pi) p( \{ z_{ij} \} | \theta_j, \Pi) p( \theta_j | \Pi) p( \{ \beta_{jk} \} | \Pi) \Big\} \prod_k^K p( \pi_k | \Pi) \\ & = \prod_j^J \left\{ \prod_k^K \Big[ p(\{x_{ij}\} | \{ z_{ij} \}, \pi_k, \Pi) p(\{z_{ij}\} | \{ z_{ij}\}, \beta_{jk}, \Pi) p( \beta_{jk} | \Pi) \Big] p( \{ z_{ij} \} | \theta_j, \Pi) p( \theta_j | \Pi) \right\} \prod_k^K p( \pi_k | \Pi) \\ & = \prod_j^J \left\{ \prod_k^K \left[ \prod_i^{L_j} \Big\{ p(x_{ij} | z_{ij}, \pi_k, \Pi) p(y_{ij} | z_{ij}, \beta_{jk}, \Pi) \Big\} p( \beta_{jk} | \Pi) \right] \prod_i^{L_j} \Big\{ p( z_{ij} | \theta_j, \Pi) \Big\} p( \theta_j | \Pi) \right\} \prod_k^K p( \pi_k | \Pi) \\ \end{aligned} \end{equation} which is different from the likelihood stated (but not derived) in the paper: \begin{equation} p(O,H|\Pi)=\prod_j^J \prod_k^K \left[ p(\beta_{jk}|\Pi) p(\theta_j|\Pi) \left( \prod_i^{L_j} p(x_{ij} | z_{ij}, \theta_j) p(z_{ij}|\theta_j) \right) \right] p(\pi_k|\Pi) \end{equation} Question Who is correct? Me or the paper? (I assume the paper) Is my understanding of how to factorise the likelihood given a DAG correct?
