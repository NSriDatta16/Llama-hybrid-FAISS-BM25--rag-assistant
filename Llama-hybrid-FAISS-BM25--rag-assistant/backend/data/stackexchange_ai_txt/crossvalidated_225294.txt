[site]: crossvalidated
[post_id]: 225294
[parent_id]: 
[tags]: 
How to compare data that fluctuates?

I want to build a chart to compare accessibility of N given front pages of different web sites. For getting the initial data I use AChecker tool which returns me a number of accessibility issues were found on each front page included into my research array. Since the page design of the sites is the same from day to day, the correlation between the amount of issues seems to stay within acceptable error. But the data itself fluctuates a bit, because each page updates daily. Which means it would be wrong to represent the correlation in raw data for a chart to say “site01 has 42 issues, and site02 has 112 issues”, because the next day it can be “48” and “110” respectively. I thought to collect data about the amount of “reported problems” for each page at same day, then find an average, and build a chart around this average. Would it be a valid way to represent a correlation? If no, what should I do to find and show a valid correlation in such case? If the question doesn't belong here, I apologize, and will be grateful if someone will guide me to appropriate sub.
