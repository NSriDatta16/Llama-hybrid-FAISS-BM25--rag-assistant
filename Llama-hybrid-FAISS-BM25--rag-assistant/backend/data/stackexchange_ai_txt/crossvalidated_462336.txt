[site]: crossvalidated
[post_id]: 462336
[parent_id]: 461920
[tags]: 
From a Bayesian point of view: $$ P(\theta|X_{new}) = \frac{P(X_{new}|\theta)P(\theta)}{P(X)} $$ Or in words: the probability the parameters, $\theta$ , are what we think they are, given the data we've just observed, $X_{new}$ , is given by the probability of getting the data we've just observed given the parameters times our confidence in the parameters. If there have been hundreds, or thousands, of samples supporting $ X \sim N(100,20) $ , and the process is believed stable, then $P(\theta=[100, 20])$ will be close to 1. When new data, $X_{new}\sim N(120,5)$ , comes in, the original parameters, $\theta = [100,20] $ still look like a reasonable fit and $P(\theta =[100, 20] | X_{new})$ remains high. It's not until a large number of samples from $X_{new}\sim N(120,5)$ are observed that our confidence in $\theta=[100, 20]$ decreases and we can say we detect a change. On the other hand, if our confidence in $\theta=[100, 20]$ is low to begin with, $P(\theta=[100, 20])$ will be small and $P(\theta=[100, 20] | X_{new})$ gets smaller much quicker and we can say we detect a change much earlier. This raises the question: are we willing to sacrifice being wrong about a change in distributions in order to claim to detect such a change sooner?
