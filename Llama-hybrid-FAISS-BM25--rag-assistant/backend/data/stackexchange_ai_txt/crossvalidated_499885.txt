[site]: crossvalidated
[post_id]: 499885
[parent_id]: 
[tags]: 
How to combine several machine learning models trained with the same target but different sets of predictors

The book Hands-On Machine Learning with R gives an overview of model stacking, but goes on to say that the same training set shall be used for the models. The vignette of caretEnsemble also stresses the use of the same training data. I am curious if there is any well-established methodology, preferably implemented in R, that combines several classification models trained with the same target but different, exclusive sets of predictors to form a stronger model. Or is "the same target, different sets of predictors" still tantamount to the same training data? Thanks for any clarification and pointer.
