[site]: crossvalidated
[post_id]: 291937
[parent_id]: 
[tags]: 
Does it ever make sense to talk about the confidence (faith) in a probability value?

Let us suppose that we want to know what weather will be tomorrow. We ask two meteorologists and both give us an identical probabilistic answer: It will rain with probability of 30% It will snow with probability of 60% It will be sunny with probability of 10% Now, there are many different approaches to aggregation of probabilistic opinions. One of the simplest ones, as well as the only one satisfying some nice properties ( Marginalization property, zero unanimity + irrelevance of alternatives ) is the linear opinion pool . That is, combine the opinions by a weighted average . That means that our best guess will also be rain 30%, snow 60%, and sun 10%. Now imagine that instead of two meteorologists, I would ask a thousand meteorologists, and all of them would give me the identical answer. In this case, I would have the same probability distribution, but I would have much more confidence in this probability distribution. We can have a crooked coin that lands on heads with an unknown probability and then we can use an uniform prior and Bayesian updating to get the posterior probability and to construct confidence intervals on this probability. However, this probability seems to be a fixed property of the crooked coin and not a real probability. I feel that we cannot treat real probability as a parameter that can be measured and that has any objective existence outside our minds. Therefore the weather example makes me feel uneasy. Would it make sense to extend the notion of probability in some way? Are there such theories? I know that some prominent mathematicians have already thought about it , but it is hard to find details.
