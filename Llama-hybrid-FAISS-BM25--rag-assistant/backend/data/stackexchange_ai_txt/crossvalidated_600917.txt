[site]: crossvalidated
[post_id]: 600917
[parent_id]: 
[tags]: 
Monte Carlo Dropout as surrogate model for Bayesian Optimization

I am interested in using Monte Carlo Dropout as a surrogate model for Bayesian optimization. I noticed that the paper states: The use of dropout (and its variants) in NNs can be interpreted as a Bayesian approximation of a well known probabilistic model: the Gaussian process (GP) Does this mean that I can use any common acquisition function designed for GP in my case without any changes? For example, probability of improvement that uses the mean, standard deviation and cumulative distribution function (Ð¤) in analytical form for GP. P.S. While I am aware of some criticisms of this approach, I would like to assume that the Gal's statements are correct for the purposes of this question.
