[site]: crossvalidated
[post_id]: 617986
[parent_id]: 186039
[tags]: 
Let's start from the correlations. Pearson's correlation is a linear measure and the hypothesis test for it ( cor.test in R, for example) assumes (approximate) Normal distributions of the input data. This makes the corresponding hypothesis test ("is my correlation coefficient 'significantly' different from 0?") a parametric test. Spearman's rank correlation coefficient uses the ranks only, it has no distributional assumptions, the corresponding hypothesis test will thus be a non-parametric test. When you say that "a Spearman PCA does this with the Spearman correlation matrix, and therefore the dimensions are not only linearly uncorrelated, but monotonically uncorrelated. At least to me, that seems much stronger." you probably refer to the fact that a non-parametric hypothesis testing procedure is more robust than the corresponding parametric variant in the sense that the former has no distributional assumptions. The price that you pay, however, is reduced power (because "you know less", in this case by "throwing away" the actual data and keeping only their relative order). I suspect one of the reasons why the Pearson PCA is "more popular" is that the Pearson's correlation coefficient is "more popular", perhaps because of the higher power of the corresponding hypothesis test if the Normality assumption is approximately correct . Note, however, that the "popularity" of a scientific method depends on psychological and societal factors to a not inconsiderable extent. What is taught at universities in 1950 will influence what is written in textbooks in 1960 which will largely determine what will be taught in 1970, .... :-) So maybe there's no good reason to it other than "this is what we got accustomed to."
