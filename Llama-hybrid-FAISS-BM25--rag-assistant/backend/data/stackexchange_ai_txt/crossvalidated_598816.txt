[site]: crossvalidated
[post_id]: 598816
[parent_id]: 
[tags]: 
Should I always pick the parameters with the best CV accuracy for GridSearch?

I’m currently training an SVM for multi classification, and to choose the C and gamma parameters, I'm using Grid search combined with k-fold CV. I get a cross validation accuracy of 99.8%. I am not quite sure of what training score means, but I suppose it’s just the accuracy you get by trying to predict the training set labels using the trained model. If this is the case, I get an accuracy of around the same percentage as the CV accuracy, but when I try to predict for my test set, I get a significantly lower accuracy (50%). I know that this means that the model is suffering from overfitting. However, when I use a combination of parameters with which I got a little bit lower CV accuracy (around 99.2%), I get a very high training score as well as a very high test score. Which parameters should I use in this case? Some more questions: Does the training score need to be higher than the validation score? Does the training score should be higher than the test score? Does the validation score should be higher than the test score? I’m a noob in machine learning, so please try not to use complex terms when answering. Thank you in advance!
