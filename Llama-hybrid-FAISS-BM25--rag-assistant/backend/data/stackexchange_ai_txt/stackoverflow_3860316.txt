[site]: stackoverflow
[post_id]: 3860316
[parent_id]: 
[tags]: 
How to parallelize reading lines from an input file when lines get independently processed?

I just started off with OpenMP using C++. My serial code in C++ looks something like this: #include #include #include #include #include #include int main(int argc, char* argv[]) { string line; std::ifstream inputfile(argv[1]); if(inputfile.is_open()) { while(getline(inputfile, line)) { // Line gets processed and written into an output file } } } Because each line is pretty much independently processed, I was attempting to use OpenMP to parallelize this because the input file is in the order of gigabytes. So I'm guessing that first I need to get the number of lines in the input file and then parallelize the code this way. Can someone please help me out here? #include #include #include #include #include #include #ifdef _OPENMP #include #endif int main(int argc, char* argv[]) { string line; std::ifstream inputfile(argv[1]); if(inputfile.is_open()) { //Calculate number of lines in file? //Set an output filename and open an ofstream #pragma omp parallel num_threads(8) { #pragma omp for schedule(dynamic, 1000) for(int i = 0; i EDIT: Important Things Each line is independently processed Order of the results don't matter
