[site]: datascience
[post_id]: 13480
[parent_id]: 12693
[tags]: 
I'm surprised nobody mention fully convolutional neural networks (FCNs) for semantic segmentation . They are inspired by the original AlexNet style convnets that ended with one or two densely connected layers and softmax classifier. But FCNs dispense with the dense layers and stay fully convolutional all the way to the end. Here's the basic principle. Take AlexNet, or VGG or something like that. But instead of using the parameters in the classifier to compute a scalar for each category, use them to compute a whole array (i.e. image) using a 1x1xNUM_CATEGORIES convolution. The output will be NUM_CATEGORIES feature maps, each representing a coarse-grained "heat map" for that category. A map of dogness, a map of catness. It can be sharpened by including information from earlier layers with "skip connections". EDIT: Just one further bit of good news: the authors of that paper provide implementations of their nets in Caffe's Model Zoo . Tweak away!
