[site]: datascience
[post_id]: 49446
[parent_id]: 
[tags]: 
Something is disastrously wrong with my neural network and what it's produced

I just got a neural network to run and although it doesn't raise any exceptions, I'm left with a horrible mess after 80 to 100 epochs: After 100 epochs with the adapted code: After 100 epochs with the original code: I am trying to generate a grid of synthetic images of cats from my own database of cat photos that I compiled using a crawler. I am using an adapted code originally intended for the MNSIT handwritten digits database (hence the shape of the grid). The network doesn't appear to be training, generating or discriminating properly because the epochs aren't taking long at all and what is being produced is very poor. To be clear, I've tried to adapt another author's code that I found online and I've added other snippets of code to try to get it to work. It's evident that my 'FrankenNet' has fallen to bits and my 'bolt it together and see what happens' approach has its limitations. Maybe I haven't loaded in the data correctly or perhaps there are a few other issues such as converting the data to a numpy array? I'd love some advice because I really want to generate something and I've spent a long time trying to work it out through trial and error with no results. I'd especially appreciate some specific suggestions about what lines I need to change, add or remove to get this beast up to scratch. Firstly, I have removed keras.datasets because I am not working with their database. Original code: from keras.layers.advanced_activations import LeakyReLU from keras.datasets import mnist Adapted GAN: from keras.layers.advanced_activations import LeakyReLU from keras.optimizers import Adam This is how the data is loaded from MNIST in the original GAN: def load_minst_data(): (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = (x_train.astype(np.float32) - 127.5)/127.5 x_train = x_train.reshape(60000, 784) return (x_train, y_train, x_test, y_test) And this is what I have replaced it with to try to load and train my own JPGs: from os import listdir from PIL import Image as PImage def loadImages(path): # return array of images imagesList = listdir(path) loadedImages = [] for image in imagesList: img = PImage.open(path + image) loadedImages.append(img) return loadedImages DATASET_NAME = 'catscats' ROOT_DIR = '/Users/Darren/desktop' DATASET_DIR = f'{ROOT_DIR}/{DATASET_NAME}' input_files = [os.path.join(dp, f) for dp, dn, fn in os.walk(os.path.expanduser(f'{DATASET_DIR}/processed')) for f in fn if f != '.DS_Store'] imgs = np.ndarray(shape=(len(input_files), 100, 100, 3), dtype=np.int) for i, input_file in enumerate(input_files): # print('processing file: {}'.format(input_file)) image = imread(input_file) imgs[i] = image # your images in an array imgs = loadImages(path) def loadImages(): (x_train, y_train), (x_test, y_test) = input_file x_train = (x_train.astype(np.float32) - 127.5) / 127.5 x_train = x_train.reshape(60000, 784) return (x_train, y_train, x_test, y_test)
