[site]: crossvalidated
[post_id]: 632803
[parent_id]: 
[tags]: 
If I set a Gaussian prior in the parameter space, can I use the variance as diagonal of the Hessian?

Say I have a neural network, where I put a Gaussian prior over the parameters $\theta_i \sim N(\mu_i, \sigma_i^2)$ and that I learn both $\mu$ and $\sigma$ via the reparameterization trick $f = \mu + \epsilon \cdot \sigma$ After training, I'll have for each weight its corresponding $\mu, \sigma$ My question is, can I consider $\sigma$ as a "proxy" for the diagonal of the Hessian? In my mind it works because $\sigma >>0$ means that that parameter is pretty invariant to big changes, thus should have a second derivative pretty large, right?
