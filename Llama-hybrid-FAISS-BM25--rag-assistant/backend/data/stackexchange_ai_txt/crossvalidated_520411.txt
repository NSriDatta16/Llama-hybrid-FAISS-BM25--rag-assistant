[site]: crossvalidated
[post_id]: 520411
[parent_id]: 520392
[tags]: 
xgboost works perfectly fine with skewed input data, even large amount of outliers. One of the reason is because it is a tree based model and tree is relatively robust to skewed data and outlier. In fact, many xgboost users even do not check the distribution of the input. And the xgboost can have thousands of columns as inputs. In most cases, if you are focusing on accuracy, do not bin the continuous data. Some related posts can be found here. When should we discretize/bin continuous independent variables/features and when should not? Why should binning be avoided at all costs?
