[site]: crossvalidated
[post_id]: 20471
[parent_id]: 15148
[tags]: 
I would use a relational database that has OLAP features, arranging the data in a star schema like so: Fact: UUID Dimensions: Region, Street, Building number, Entrance number, Floor (stock) number, Religion, Appearance of toilete Then I would make a view over it with a large number of features, average religion per region, per building, appearance of toilet per floor/building ... etc. Vector: UUID, Dimensions: Region, Street ..., Features: average per X, max per Y ... etc Now I have a big vector space to witch I can easily apply common anomaly detection algorithms. For example let's say that training data size (m) and we are on a reasonable powered computer to apply multivariate Gaussian probability density estimation. For our training vectors \begin{align*} {x^{(i)}} \in \mathbb{R}^n, i \in 1..m \end{align*} Our probability function is: \begin{align*} p(x, \mu, \Sigma)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{n/2}}exp\bigg(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\bigg) \end{align*} So we need to fit the parameters: \begin{align*} \mu=\frac{1}{m}\sum_{i=1}^mx^{(i)} \space , \space \Sigma=\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T \end{align*} Now, that we can compute $p(x, \mu, \Sigma)$ we can flag a fact as anomalous if: \begin{align*} p(x, \mu, \Sigma) By varying $\epsilon$ we will enlarge/restrict our anomalous facts class, and for really small values of $\epsilon$ we will find the most far away outliers (assuming there are any). All there is to do now is vary $\epsilon$ and analyze different results.
