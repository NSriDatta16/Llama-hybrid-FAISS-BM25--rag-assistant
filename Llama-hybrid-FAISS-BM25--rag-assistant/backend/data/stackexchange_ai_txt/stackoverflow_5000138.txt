[site]: stackoverflow
[post_id]: 5000138
[parent_id]: 
[tags]: 
Need help with python exception handling

Here is the code I'm currently working with: url = locations[state]['url'] headers = {'User-Agent':'Firefox/3.6.13'} req = urllib.request.Request(url, headers=headers) try: resp = urllib.request.urlopen(req) except: print('Caught error, trying again...') print('This should be handled better, I\'m sorry') time.sleep(2) resp = urllib.request.urlopen(req) The problem I'm getting, and thus the exception I actually care about is this will occasionally happen when making a request: URLError: That's not the exact error, I think that may be for python 2.x's urllib/urllib2 and I'm on python3, which I think is urllib.error.URLError iirc. Anyway though, I know I can do except URLError and it should work (though I wonder if I need to do urllib.error.URLError instead since that's what it reports on mine), but how do I test to make sure it's because of a 104. I would like it to keep retrying to request until it gets it, or at least try it a specified number of times, how would I do that most elegantly? From what I can find the error 104 is because my local router can't handle the request and freaks out, I'm guessing because it can't handle the requests so quickly? If anyone has any further insight as to what causes that, that too would be helpful, but I'm not too concerned.
