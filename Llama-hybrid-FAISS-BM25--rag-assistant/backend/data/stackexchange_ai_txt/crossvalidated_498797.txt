[site]: crossvalidated
[post_id]: 498797
[parent_id]: 
[tags]: 
Logistic Regression ignore "One in Ten Rule", if regularization is implemented?

In Logistic Regression there is the "One in Ten Rule" ( https://en.wikipedia.org/wiki/One_in_ten_rule ). For example, there is a sample of 2000 customers, and 50 of them belong to the positive class (1950 of them are negative). Then the maximum number of features we can have in the Logistic Regression model is 50 / 10 = 5, although there may be 150 features available. My question is, in the example above, can I use all 150 features in the Logistic Regression model at the same time, and hoping with the right amount of L1 or L2 Regularization via cross validation , I will end up having nearly the best Logistic Regression model I can build with this dataset ( just in terms of AUC or accuracy )? This is related to the idea that having a complicated model + regularization is better than having a simple model.
