[site]: crossvalidated
[post_id]: 329555
[parent_id]: 325379
[tags]: 
Question 1: Why not use Stacking in Random Forests instead of averaging? Decision trees have high variance and averaging them together reduces the variance, improving the performance. Since decision trees are weak individual models, stacking does not work that well on them. Stacking is best suited for a diverse set of strong models, which themselves can be ensembles (e.g. Random Forests, GBMs, etc). Question 2: Can you stack clustered (aka "pooled repeated measures") data? Sure, you can stack clustered data. However, when you use cross-validation to create the "level-one" data (the data to train the metalearner), you should ensure that the rows belonging to a single cluster all stay within a single fold. In your example above, that the rows corresponding to a whole classroom must be contained in a single fold and not be spread out across different folds. Question 3: What do you do with negative regression coefficients in the stacking regression? There's nothing inherently wrong with allowing negative weights, however, I've consistently seen better results if you restrict the weights to be non-negative. That's why we choose a GLM with non-negative weights as the default metalearner in the H2O Stacked Ensemble implementation. It's also the default in the SuperLearner R package. Having a lot of zero weights is not a problem, it probably just means that many of your base learners are not adding value to the ensemble.
