[site]: crossvalidated
[post_id]: 460069
[parent_id]: 
[tags]: 
Paired t-test on large sample that *should* be normal, but isn't (or Wilcoxon Signed Rank Test)?

A dataset contains the number of fast food restaurants per thousand people for each county in the USA, for two different years (five years apart). 3,143 rows. None of the following are normally distributed: the 2009 data, the 2014 data, the difference between the two years, or the percentage difference between the two years. Here is a ggqqplot (in R) of one of the years, and of the difference: I removed around 30 outliers from the data (the graphs), which I restored for the Wilcoxon Signed Rank Test. I am finding conflicting information as to whether I can use the paired t-test to see if there is a significant change in the rates/1000 people between the two years. One reference says if it's a very large set of data that should be normal, use the paired t-test even if it isn't. Another says to use the Wilcoxon Signed Rank Test. Which is correct for this data? In case you are curious, the average of the rates went up around 1.5%, and both the paired t-test and the Wilcoxon Signed Rank Test show very high significance (> E10). Another question is do I need to weight the samples somehow? The populations of the counties are available. The test is asking about changes in the geographic areas (counties). I think this is okay, as I've seen peer-reviewed studies of animal traits in different areas (paired t-tests over years), and they are treated the same in spite of the size of the area or it's population. UPDATE There is also data for the number of fast food restaurants. The graphs are worse than the ones above, on the data, and on the differences. Do I use a paired t-test, as the data "should" be normal? I know paired t-tests can be used on data like this, such as changes in the numbers of crabs on a number of different beaches between two years.
