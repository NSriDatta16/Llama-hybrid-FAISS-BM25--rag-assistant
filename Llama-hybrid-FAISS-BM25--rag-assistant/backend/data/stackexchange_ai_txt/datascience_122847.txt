[site]: datascience
[post_id]: 122847
[parent_id]: 
[tags]: 
What dimensional reduction and similarity score work for sentence embeddings created using sentence transformers

I am clustering sentence embeddings for log files, and find anomalies. So, when I create sentence embeddings for logs using sentence transformers. It will create vector of fixed length, which somehow place similar sentences together (is my understanding right?) and how do they become similar, like is it when I use certain function, the similar sentences will have higher scores? I cant find good resource on this in internet. Also, any idea on which dimensional reduction preserves these embeddings? Like are there any good websites to find research articles on this.
