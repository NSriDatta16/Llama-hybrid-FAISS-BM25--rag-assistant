[site]: crossvalidated
[post_id]: 383990
[parent_id]: 
[tags]: 
Is some degree of overfitting always going to occur in tree based models?

So, I am somewhat new to machine learning, and I am trying my hand at a bunch of different Kaggle datasets. In a lot of the datasets that I ended up a tree-based model on, I noticed one that all of them had. After graphing the learning curve, I noticed that they all had a level of variance. While the variance wasn't very high, and the bias was low, I was wondering if this variance is possible to get rid of, or is it just part of tree-based models, and is there always going to be some level of overfitting?
