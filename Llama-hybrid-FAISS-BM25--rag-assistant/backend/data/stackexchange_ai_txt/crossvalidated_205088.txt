[site]: crossvalidated
[post_id]: 205088
[parent_id]: 205075
[tags]: 
I removed classification from your title and text because classification has absolutely nothing to do with this problem. You are interested in prediction/modeling of probabilities. Once you stack the dataset tall and thin as suggested by @DJohnson, you have many options. An extremely flexible approach is called pooled logistic regression or repeated measures logistic regression. The method is so flexible that you can have $Y$ mean an event at an ultimate follow-up time (e.g., at 2 years from subject entry into a study) or $Y$ can be from a moving window of time that is always $t$ days later than the current row's observation. Parameter estimation using maximum likelihood proceeds in the usual way for binary or polytomous (multinomial) logistic regression, using a GEE working independence model, which means you just stack all the data and ignore any intra-cluster correlations. The standard errors will all be wrong because the ordinary calculation treats all rows as independent of each other. You can get valid standard errors by using the cluster sandwich covariance estimator or the cluster bootstrap. The R rms package can do all this for binary and ordinal $Y$ using functions lrm , orm , robcov , bootcov . You can reshape the data using the built-in R function reshape plus others.
