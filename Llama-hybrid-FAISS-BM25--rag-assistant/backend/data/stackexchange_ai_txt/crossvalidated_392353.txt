[site]: crossvalidated
[post_id]: 392353
[parent_id]: 
[tags]: 
How can I compare models without fitting?

Regression and machine learning are used in the natural sciences to test hypotheses, estimate parameters, and make predictions by fitting models to data. However, when I have an a priori model, I don't want to do any fitting---for example, a model of a deterministic physical system calculated from first principles. I simply want to know how well my model matches the data, and then understand which parts of the model contribute significantly to the match. Could someone point me towards a statistically rigorous way of doing this? In more specific terms, suppose I have a physical system for which I measured a dependent variable $y_i$ ( $i$ ranges from 1 to $n$ , the sample size) under varying conditions described by three independent variables $x_{1,i}$ , $x_{2,i}$ , and $x_{3,i}$ . Although the real system that generated the data is complicated, I made some simplifying assumptions to derive a theoretical model $f$ for the system, such that $y_i = f(x_{1,i}, x_{2,i}, x_{3,i}) + \epsilon_i$ , where $f$ is a non-linear (and not linearizable) function of the independent variables and $\epsilon_i$ is the difference between the model-predicted and measured values. $f$ is completely pre-specified; no fitting is done and no parameters are estimated. My first goal is to determine if $f$ is a reasonable model for the process that produced the measured values $y_i$ . I also developed simplified models $g(x_{1,i}, x_{2,i})$ and $h(x_{1,i})$ , which are nested in $f$ (if that matters in this case). My second goal is to determine if $f$ matches the data significantly better than $g$ or $h$ , suggesting that the features that differentiate model $f$ from models $g$ and $h$ play an important role in the process that generates $y_i$ . Ideas so far Perhaps if there were some way to determine the number of parameters or number of degrees of freedom for my mathematical model, it would be possible to use existing procedures like a likelihood ratio test or AIC comparison. However, given the nonlinear form of $f$ and the absence of any obvious parameters, I'm not sure if it's reasonable to assign parameters or to assume what constitutes a degree of freedom. I've read that measures of goodness-of-fit, such as the coefficient of determination ( $R^2$ ), can be used to compare model performance. However, it's not clear to me what the threshold for a meaningful difference between $R^2$ values might be. Further, because I don't fit the model to the data, the mean of the residuals is not zero and may be different for each model. Thus, a well-matching model that tends to underpredict the data might yield as poor a value of $R^2$ as a model that was unbiased but poorly matched to the data. I've also read a bit about goodness-of-fit tests (e.g., Anderson-Darling), but as statistics is not my field, I'm not sure how well this type of test suits my purpose. Any guidance would be appreciated.
