[site]: datascience
[post_id]: 39937
[parent_id]: 
[tags]: 
practical improvements worth trying over plain LSTM in text classification?

I have a dataset of about 1 million tweets corresponding to about 30,000 user accounts, labelled with binary data (classifying the tweet as written by a bot). With that amount of data, I could use a LSTM-based NLP approach to take advantage of the sequence data in the text. I would like to get the best accuracy possible, but don't know what models are available that could be combined with or build on LSTM-based approaches. I also wonder, as one part of the data is sequential and the other stationary (account metadata), whether some kind of hybrid classifier could do better than using just an LSTM. Are there any hybrid models or any other proven models that would be worth investigation further, to implement for my project?
