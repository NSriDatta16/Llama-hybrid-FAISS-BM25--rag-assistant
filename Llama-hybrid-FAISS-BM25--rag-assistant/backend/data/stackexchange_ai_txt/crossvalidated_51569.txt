[site]: crossvalidated
[post_id]: 51569
[parent_id]: 
[tags]: 
Neural networks for simplistic image classification

I want to train a neural network to classify a few simple, cartoony images like the ones below (for the moment I only have the classes house , tree , and sword ). The images I am (currently) using are downsized to 32x32 pixels, and the feed-forward network architecture I use is 1024-512-256-3. This means that I end up with a total number of weights (excluding biases) of 1024*512 + 512*256 + 256*3 = 656128 That is a huge number and some function optimization algorithms end up depleting the available memory because of it. Obviously I'm doing something wrong. Should I use a different architecture or a different type of neural network (not MPL)? Should I reduce the image sizes further? When people train neural nets for complex object recognition tasks, how to they avoid using up all the memory?
