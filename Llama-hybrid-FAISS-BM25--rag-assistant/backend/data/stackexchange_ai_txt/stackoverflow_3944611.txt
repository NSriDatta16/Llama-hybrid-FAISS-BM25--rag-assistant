[site]: stackoverflow
[post_id]: 3944611
[parent_id]: 3944452
[tags]: 
Given that you're working on a game, the first thing that comes to mind is an ancient program for playing checkers, developed by Arthur Samuel in the 1950s and mentioned by Russell and Norvig in their chapter on game playing (among others; it's still a classic in unsupervised/semi-supervised machine learning). This program assumed that the value of a checkers board was a linear function of the board position. I don't know the details, but I assume each of the player's pieces was worth +1, the opponent's pieces -1, and empty fields 0. Each square had a weight associated with it, which was learned by letting the program play against itself some (large) number of times, evaluating play after every match. This strategy is called self-training and was also applied in the classic backgammon software TD-Gammon , which is based on neural networks (multi-layer/non-linear ones). The Wikipedia page about that program has some potentially interesting references. This answer is turning into an essay about something at which I'm not an expert. Please see the relevant literature.
