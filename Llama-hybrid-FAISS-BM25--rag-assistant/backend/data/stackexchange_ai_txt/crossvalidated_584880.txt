[site]: crossvalidated
[post_id]: 584880
[parent_id]: 584561
[tags]: 
For regression you could try 'permutation feature importance'. Feature importance shows, which variable were more or less important for a model to predict a value. The corresponding model summary should also provide metrics for each explanatory variable - among others e.g. their statistical significance as indicated by its p-value. However, all those methods proposed are not that straight-forward as you would like them to be, according to your question. Maybe also take a look into: Why does Random Forest variable importance not sum to 100%? and https://machinelearningmastery.com/feature-selection-for-regression-data/ In case you have many different features you could also take a look into 'factor analysis' and the amount of variance that is described by each factor and the actual features that are 'covered' by respective factors (see 'bi-plot'). Hope this helps.
