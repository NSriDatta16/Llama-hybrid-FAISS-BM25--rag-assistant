[site]: datascience
[post_id]: 89891
[parent_id]: 89890
[tags]: 
Consider a game being played between two people, for simplicity, we'll assume this game is distinguishing a true picture of a panda vs. a fake picture of a panda. The first player will take the painting and show it to the second player, if the second player guesses whether it is a fake correctly, they receive a reward, if not they do not. Both players are playing the game with the goal of maximizing their reward. To go a little deeper but make it slightly more relevant to the context of Adversarial ML. We can further assume that both players start from 0 knowledge of pandas. You might imagine that player 1 just throws random colors at a canvas and tries to convince player 2, and player 2 just randomly guesses, slowly building their intuition for what a Panda is. After several hours/days/years, we might find that both players are extremely skilled and drawing pandas and identifying fake pandas respectively. This is really what adversarial ML is about in a nutshell. The goal is to have two agents with competing rewards, where their optimal solution is at some form of a mixed strategy Nash equilibrium.
