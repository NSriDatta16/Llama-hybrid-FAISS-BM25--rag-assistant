[site]: datascience
[post_id]: 117926
[parent_id]: 117920
[tags]: 
You can generate custom embeddings for your corpus/dataset and then calculate the cosine similarity. When you generate your own word embeddings for your dataset, words with similar meaning will be close to each other in vector space. So even if two words don't have any letter in common but are in same context would have some value of cosine similarity. Below is the link of a tensorflow tutorial of generating custom embeddings - https://www.tensorflow.org/text/guide/word_embeddings
