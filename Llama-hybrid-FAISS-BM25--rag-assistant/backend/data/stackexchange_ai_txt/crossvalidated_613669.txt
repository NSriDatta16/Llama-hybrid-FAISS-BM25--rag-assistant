[site]: crossvalidated
[post_id]: 613669
[parent_id]: 
[tags]: 
Gibbs sampler: Conditional distribution with nested latent variable distributions

I have the following model (simplified here for the description). The obsvered variable is $y_i$ which is a linear function of some random variable $\eta_i$ and a random error term $\epsilon_i$ : $y_{i} = \eta_i + \epsilon_i$ Now, $\eta_i$ is also a linear function of some random variable plus another random error term: $\eta_{i} = b \cdot \tau_i + \delta_i$ and finally $\tau_i$ is something like $\tau_i = c \tau_i + \xi_i$ $\tau_i = c' \cdot \xi_i$ The goal is to estimate the coefficients $b$ and $c$ , and the variances of $\epsilon_i$ , $\delta_i$ , and $\tau_i$ with a Bayesian approach. Say $\theta = (b,c,\sigma^2_{\epsilon},\sigma^2_{\tau}, \sigma^2_{\xi}$ ). The posterior is proportional to $f(\theta, \eta_i, \tau_i | y_i ) \propto f(y|\eta_i,\theta)f(\eta_i|\tau_i,\theta)f(\tau_i|\theta)f(\theta)$ I am not an expert in Bayesian estimation, but my understanding is for the Gibbs sampler I would need the conditional distributions $f(\eta_i| \cdot)$ and $f(\tau_i| \cdot)$ , that is I need to sample $\eta_i$ and $\tau_i$ . I was wondering whether I really need this or whether there is a way - given the construction of the model - to circumvent the sampling of one of the two variables. For instance, I can easily derive the marginal distribution of $f(\eta_i|\theta)$ where $\tau_i$ is integrated out. Any hints - pointers to papers/books - are appreciated (and sorry when this is a silly problem/question). Thanks Stefan
