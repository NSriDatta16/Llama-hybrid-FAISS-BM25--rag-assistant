[site]: datascience
[post_id]: 18278
[parent_id]: 
[tags]: 
Checkers playing Neural Network evolved with Genetic Algorithm becomes too sensitive to input data changes

I recently embarked on a very ambitious project and I have to say it has turned out a lot better than I expected, I succeeded in coding from scratch a neural network that plays checkers at a very acceptable level. I have one problem though which prevents me from having a stronger AI, I guess some people would call it overfitting, I'm not sure if the term is correct in this situation. The main issue is that after a certain amout of generations the weights become so great that the smallest change in the state of the board changes the evaluation of it drastically, effectively limiting any kind of nuanced analysis. A bit more information: Neural Network Structure: Input layer is a series of indipendent layers which take as input a section of the board (1, 0.5, -0.5 and -1 are the inputs taken from the board). I am using 2 hidden layers of approximately 30 and 10 nodes each, the output node is an evaluation of the board. Genetic Algorithm 30 Neural Networks are generated randomly with weights from -0.2 to 0.2, they play 20 games against random opponents and they are rated accordingly (-2 points for a loss, -1 for a draw [120 moves with no winner] and 1 point for a win). The 15 best are kept and copy/pasted on top of the 15 worst ones, then each weight of the new networks are mutated using the following equation: $m' = m * e^{r*0.9} $ $w' = w * m' * r$ Where $m$ is the mutation parameter of that specific weight which starts off at 0.05, $r$ is a random standard Gaussian number and $w$ is the weight. I hope someone here can help me figure out how to prevent the weights from going haywire after the 40th or so generation.
