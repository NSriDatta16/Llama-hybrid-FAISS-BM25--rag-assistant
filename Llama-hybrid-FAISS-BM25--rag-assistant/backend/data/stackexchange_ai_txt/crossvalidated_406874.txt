[site]: crossvalidated
[post_id]: 406874
[parent_id]: 406863
[tags]: 
I suggest a simple "voting" mechanism: remove top and bottom n readings from each observation. This is often used in scoring of sporting events, such as diving where out of 10 judges top and bottom 2 scores are removed from calculations. This is not the most optimal approach, of course, especially if it's rare that the sensor is faulty. However, it's very simple and robust. Even if you decide to employ more sophisticated approach, I'd still keep this one as a benchmark. Another approach, if to constantly impute the measurement of each sensor based on the readings of other sensors. When the imputed value is different enough from an actual measurement, it indicates the problem. Of course, you'd have to take into account, that when the faulty sensor is used to impute values of other sensors, they'll have a larger than normal discrepancies too. However, since this sensor is just one of them in the imputation, the discrepancies will be relatively small. For instance, you could peek a very simple imputation by average: $$\hat x_k=\frac 1 {n-1} \sum_{i=1\\i\ne k}^n x_i$$ Suppose that sensor $j$ is faulty, then the discrepancy $$\hat x_j - x_j=\frac 1 {n-1} \sum_{i=1\\i\ne j}^n x_i$$ should much larger than usually, and also much larger than of a working sensor k: $\hat x_k-x_k$ , becauase the faulty sensor comes with weight $1/n$ into calculation of imputed value $\hat x_k$
