[site]: crossvalidated
[post_id]: 291063
[parent_id]: 290860
[tags]: 
A few suggestions are below. Say we've run our GLM in R and called it fit , i.e. we've done fit . predict(fit,newdata,type = "response") will get you the predicted probabilities for a new $X$ matrix, i.e. for a new workforce with attributes given by the rows of $X$. Now we just need to decide how we're going to construct our newdata matrix. The first 50 rows are easy -- they're just the rows corresponding to the friendly staff in our original matrix/data frame. For the remaining 50, we need to make some (hopefully sensible) decisions. We know that we want the friendliness column to be all 1 s, but we're also going to need to provide the other attributes for these new employees. One way would be to assign the mean of each attribute from the original data frame to each new employee. This essentially means we're saying that all new employees are completely average, apart from the fact they're all friendly; i.e. we're looking at the marginal effect of making everybody friendly. We could also use the average among friendly staff if you expect some correlations between friendliness and other attributes. Another option would be to try some sort of sampling procedure, whereby we get lots of possible outcomes corresponding to different attribute assignments, and we can look at the distribution of expected sales under the assumptions we embed in our sampling procedure. The simplest way to do this would be bootstrapping -- sample attributes with replacement from the original matrix and use these samples to create 50 plausible new (friendly) employees. Predict the outcome using this new matrix and store the result. Rinse and repeat 500-1000 times, plot the histogram of your expected sales figures to get a sense of the possible variability/uncertainty associated with your decision to replace all unfriendly staff with friendly staff.
