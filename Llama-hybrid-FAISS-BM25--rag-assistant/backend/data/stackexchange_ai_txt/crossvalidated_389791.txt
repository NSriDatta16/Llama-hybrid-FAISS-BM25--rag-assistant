[site]: crossvalidated
[post_id]: 389791
[parent_id]: 
[tags]: 
strategy for using stationarity tests

I have a long (~20,000 points) time series that I tested for stationarity. I am following this strategy: I started by plotting the series and determining visually whether a drift / trend exists or not, so as to chose the right alternative hypothesis in next step. Next I performed Augmented Dickey-Fuller test with no drift/trend, with 1-50 lags. Now I examined the BIC for each model corresponding to lags 1-50 and chose the one with minimum BIC. This corresponded to large lag, >25. Note: it was suggested in another thread ( here ) that one should chose lag by examining the residuals, choosing minimum lag that do not have serial correlation in residual. If I do that I find that there is no serial correlation (as confirmed by Durbinâ€“Watson test) for all tested lags and thus I am tempted to choose lag 1. I found that the ADF rejected the null hypothesis for lower lags, but failed to reject at the BIC-chosen lag (at 1% confidence level). To make sure I am not sensitive to the lag value I did a Phillip-Parron test as a confirmation. I found that the null hypothesis is indeed rejected, at same confidence level, but for all lags. Examining the coefficient value for the ADF test, I found that it is larger than 0.99 for these large lags. I know that the ADF test has low power at such values close to 1. Thus I resorted to a variance ratio test as a final judgement. Random walk should have a ratio of 1, but at the BIC-lag I got a value of less than 0.1 (and even at lag 1, the ratio is I thus concluded that the series is stationary, although probably (very) close to a random walk. Is this line of reasoning sound?
