[site]: crossvalidated
[post_id]: 495354
[parent_id]: 
[tags]: 
Principal Component analysis - SVD U matrix projection

I have a bit mathematical question I am interested in. Principal component analysis (PCA) has mathematically multiple solutions. One way is to use SVD. I have prepared an example bellow. I am curious when I plot U matrix observations relative positions are exactly the same relatively to each other. However when we use prcom function that thas PCA analysis and we use X matrix. We can see that observation positions on PC1 and PC2 low-dimmensional space are (relatively) the same as with U matrix in SVD. Only different thing is scalling. I now that to obtain the same values as in the X matrix from prcom function we need to get matrix product of (Centered) observation and VT matrix from SVD. My question is if this step product of C and VT is really necessary taking into account that observations relative position is the same. library(tidyverse) library(datasets) library(matrixStats) # Loading The Data X % broom::tidy(matrix = 'v') %>% pivot_wider(names_from = PC, values_from = value, names_prefix = 'PC') %>% mutate(column = colnames(X)[column]) U % broom::tidy(matrix = 'u') %>% pivot_wider(names_from = PC, values_from = value, names_prefix = 'PC') %>% mutate(row = rownames(X)[row]) U %>% ggplot(aes(PC1, PC2, label = row)) + geom_point() + geom_text() # NOW USE PCA build-in function PCA_FUN % as.data.frame() %>% ggplot(aes(PC1, PC2, label = rownames(.))) + geom_point() + geom_text() ```
