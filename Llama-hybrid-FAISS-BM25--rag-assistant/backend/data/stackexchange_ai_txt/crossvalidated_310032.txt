[site]: crossvalidated
[post_id]: 310032
[parent_id]: 
[tags]: 
Models for binary outcomes: creating a balanced Recall?

I am running an experiment where the target variable is a binary category. I have tried various algorithms, from XGBoost through to multi-layer networks in Keras. In the case of my neural network, I use a variety on the adam learner, with binary_crossentropy as my loss. Due to the nature of the problem, it is challenging to have similar Precision when compared to Recall. Accordingly, I am careful not to over fit and optimize using k-folds validation techniques. However, I notice that my model is very prone to performing very well for one category at the expense of the other. The average of the recall could remain constant at 0.6, but the recall for binary category 0 is significantly higher than binary category 1 (e.g. 0.8 vs. 0.4). It would be much more preferable for performance in both categories to be 0.6 for this use-case. While I firm up the model, I have ensured that the number of examples presented both during training and testing are balanced, so the model does not see more of any one category than the other. Is there a better approach to forcing my model to find a balance across both categories, by perhaps using a different loss function for my neural network, or a different modelling approach altogether.
