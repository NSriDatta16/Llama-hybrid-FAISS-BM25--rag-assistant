[site]: crossvalidated
[post_id]: 248152
[parent_id]: 248146
[tags]: 
The expectation operator $E[f(X,Y,\ldots)]$ takes the expected value of the thing inside the square brackets over the (joint) distribution of that thing. If that thing is discrete, the expectation comes down to taking a sum over all possible values $f(X,Y,\ldots)$ can have, of that value times the probability of that value. So, $$ \text{E}[f(X,Y)] = E_{X,Y}[f(X,Y)] = \sum_{i}\sum_{j} f(x_i,y_i)\text{Prob}[X=x_i,Y=y_j] $$ The "default" expansion is to average out over the joint distribution of all random variable mentioned inside the square brackets. However, sometimes it is useful to use another distribution if additional information about $X$ and $Y$ is available. For example, suppose you know that $Y=y$, then you may be interested in the expected value of $f(X,Y)$ conditional on $Y=y$. Several notations exist: \begin{align*} \text{E}_{X|Y=y}[f(X,Y)] & = \text{E}[f(X,Y)|Y=y]\\ & = \sum_{i} f(x_i,y)\text{Prob}[X=x_i|Y=y]\\ & \neq \sum_{i} f(x_i,y)\text{Prob}[X=x_i] = \text{E}[f(X,y)]\\ \end{align*} In these situations where an expectation is taken over a distribution other than the default one (i.e. the joint distribution of all involved random variables), my advice is to always revert back to the probability notation by doing the expansion. Especially if you are in doubt what the $E[\ldots]$ really means. In your specific case, the fourth line contains the expectation of a loglikelihood where the expectation is taken over the distribution of $\mathbf{Z}$ conditional on $\mathbf{X=\mathbf{x}_i}$ and on the parameter $\theta$ being $\theta^{(t)}$. The latter is not a random variable of course, but it is als something that "modifies" the probability distribution used in the expansion. Incidently, on the fourth line, it would have been better to write $\text{E}_{Z_i|\mathbf{X};\theta^{(t)}}[\ldots]$ instead of $\text{E}_{\mathbf{Z}|\mathbf{X};\theta^{(t)}}[\ldots]$.
