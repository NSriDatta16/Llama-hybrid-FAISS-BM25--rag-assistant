[site]: datascience
[post_id]: 123798
[parent_id]: 
[tags]: 
Simple classification problem between real and fake data always gives zero loss

Hey I have just started with machine learning and was trying to classify between real ( label 1 ) and fake data ( label 0 ). Here is the code that I have written. The real_loss and fake_loss is always zero. Intuitively, I would assume it would go to zero over time, but not from the first epoch. Can someone please correct me, where I am going wrong. import torch import torch.nn as nn import torch.optim as optim #generate n samples with class labels #1 --> real data class name def gen_real_samples(n): #generate samples from the function x = np.random.rand(n) - 0.5 #domain of input to f(x) is [-0.5, 0.5) y = func(x) #reshape x = x.reshape(n, 1) y = y.reshape(n, 1) data = np.hstack((x, y)) #data labels = np.ones((n, 1)) #lables return data, labels #generate n samples with class labels #0 --> fake data class name #both x and y are in between [-1, 1) def gen_fake_samples(n): #generate samples from the function x = 2 * np.random.rand(n) - 1 y = 2 * np.random.rand(n) - 1 #reshape x = x.reshape(n, 1) y = y.reshape(n, 1) data = np.hstack((x, y)) #data labels = np.zeros((n, 1)) #lables return data, labels class Discriminator(nn.Module): #initialize the NN layers in this module def __init__(self, n_inputs=2): super().__init__() self.model = nn.Sequential( nn.Linear(in_features=n_inputs, out_features=25), nn.ReLU(inplace=True), #has no tunable params, can define in forward() nn.Linear(in_features=25, out_features=1), nn.Sigmoid() #has no tunable params, can define in forward() ) #operations on the input data def forward(self, x): model = self.model(x) return model def train_Discriminator(model, n_epochs=1000, n_batch=100): #define the loss and the optimizer d_criterion = nn.CrossEntropyLoss() d_optimizer = optim.Adam(model.parameters(), lr=0.01) half_batch = int(n_batch / 2) for k in range(n_epochs): #generate real samples and update model real_data, real_labels = gen_real_samples(half_batch) #real out = model(torch.Tensor(real_data)) #forward pass loss = d_criterion(out, torch.Tensor(real_labels)) #compute the total loss loss.backward() #backward pass (compute parameter update) d_optimizer.step() #make the updates for each parameter d_optimizer.zero_grad() #a clean up for pytorch print(f'real_loss: {loss}') #generate fake samples and update model fake_data, fake_labels = gen_fake_samples(half_batch) #fake out = model(torch.Tensor(fake_data)) #forward pass loss = d_criterion(out, torch.Tensor(fake_labels)) #compute the total loss loss.backward() #backward pass (compute parameter update) d_optimizer.step() #make the updates for each parameter d_optimizer.zero_grad() #a clean up for pytorch print(f'fake_loss: {loss}') def main(): model = Discriminator() train_Discriminator(model) ```
