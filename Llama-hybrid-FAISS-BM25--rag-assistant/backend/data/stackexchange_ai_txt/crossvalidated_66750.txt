[site]: crossvalidated
[post_id]: 66750
[parent_id]: 63631
[tags]: 
Many models can actually provide you with the uncertainty measure, first of all: Naive Bayes directly models the P(y|x) probability, which is exactly what you are asking for Support Vector Machine defines a hyperplane, a distance to this hyperplane is a certainty measure (closer the point, less certain is the model). In libraries like python sklearn you can access it by looking for the difference between decision_function(x) value and the intercept parameter Multilayer Neural Network if you train a network for the M-classes classification task with the M-output neurons network (and the expected output for the element of first class is 1 0 0 ... , for the second 0 1 0 ... and so on), the output neurons' values can be used as a certainty measure ( 0 0.7 0 ... can be interpreted as "quite a member of second class), but of course some more interesting measures can be used here (like e.g. Kullbackâ€“Leibler divergence)
