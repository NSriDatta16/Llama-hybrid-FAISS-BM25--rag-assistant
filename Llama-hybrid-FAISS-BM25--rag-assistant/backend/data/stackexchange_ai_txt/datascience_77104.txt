[site]: datascience
[post_id]: 77104
[parent_id]: 77046
[tags]: 
Are there certain techniques I can use to reduce the probability to below 0.5 in the stacked model so that it isn't classified the way it currently is? It's generally not a good idea to try to bias the classifier in order to deal better with some specific instances, because it's likely to make it weaker in with some (possibly many) other instances. The way to do that would be oversample in the training set the instances which will help predict the target instance correctly, but that's a terrible idea, don't do it! :) In general it's perfectly normal to have some errors, the data can contain noise or even sometimes annotation errors. My other question is if there is even value in making a hybrid model if the accuracy is the same as SVM's? If the data is really easy to classify, it's totally possible that stacking learners doesn't improve performance: if the performance of a single model reaches the maximum obtainable on this data, clearly there's nothing to improve. However it's also possible that the benefit of stacking is not visible in this particular test: in this hypothesis the meta-model is indeed better in general that a single learner, but the test set just doesn't contain any instance on which this can be seen. A way to check this is to reduce the size of the training set: by making things harder for the classifiers, it's possible that the weaknesses of the individual learners will show up.
