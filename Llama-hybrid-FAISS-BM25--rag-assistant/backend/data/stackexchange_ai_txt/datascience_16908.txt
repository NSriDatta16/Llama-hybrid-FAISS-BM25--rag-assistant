[site]: datascience
[post_id]: 16908
[parent_id]: 16904
[tags]: 
Quote from the author of xgboost : Both xgboost and gbm follows the principle of gradient boosting. There are however, the difference in modeling details. Specifically, xgboost used a more regularized model formalization to control over-fitting, which gives it better performance. We have updated a comprehensive tutorial on introduction to the model, which you might want to take a look at. Introduction to Boosted Trees The name xgboost, though, actually refers to the engineering goal to push the limit of computations resources for boosted tree algorithms. Which is the reason why many people use xgboost. For model, it might be more suitable to be called as regularized gradient boosting. Edit: There's a detailed guide of xgboost which shows more differences. References https://www.quora.com/What-is-the-difference-between-the-R-gbm-gradient-boosting-machine-and-xgboost-extreme-gradient-boosting https://xgboost.readthedocs.io/en/latest/tutorials/model.html
