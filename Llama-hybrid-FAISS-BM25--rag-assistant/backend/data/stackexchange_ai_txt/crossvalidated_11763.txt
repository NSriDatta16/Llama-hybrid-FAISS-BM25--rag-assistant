[site]: crossvalidated
[post_id]: 11763
[parent_id]: 643
[tags]: 
Often when mathematicians talk about probability they start with a known probability distribution then talk about the probability of events. The true value of the central limit theorem is that it allows us to use the normal distribution as an approximation in cases where we do not know the true distribution. You could ask your father a standard statistics question (but phrased as math) about what is the probability that the mean of a sample will be greater than a given value if the data comes from a distribution with mean mu and sd sigma, then see if he assumes a distribution (which you then say we don't know) or says that he needs to know the distribution. Then you can show that we can approximate the answer using the CLT in many cases. For comparing math to stats, I like to use the mean value theorem of integration (which says that for an integral from a to b there exists a rectangle from a to b with the same area and the height of the rectangle is the average of the curve). The mathematician looks at this theorem and says "cool, I can use an integration to compute an average", while the statistician looks at the same theorem and says "cool, I can use an average to compute an integral". I actually have cross stitched wall hangings in my office of the mean value theorem and the CLT (along with Bayes theorem).
