[site]: crossvalidated
[post_id]: 630111
[parent_id]: 563588
[tags]: 
From xgboost documentation : get_fscore method returns (by deafult) the weight importance of each feature that has importance greater than 0. That is, features never used to split the data are disconsidered. feature_importances_ attribute is the average (over all targets) feature importance based on the importance_type parameter that is passed when initializing the model. My guess is that the default value of importance_type is different than "weight" , making the two representing different things. You can try initialize the model with importance_type="weigth" and see if the two converges to same values, still considering that feature_importances_ includes zero importance features.
