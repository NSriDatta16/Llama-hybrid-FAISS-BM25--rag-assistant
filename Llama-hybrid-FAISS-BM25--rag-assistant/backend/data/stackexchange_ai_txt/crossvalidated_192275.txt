[site]: crossvalidated
[post_id]: 192275
[parent_id]: 
[tags]: 
Magic of neural networks?

I've read a bit on neural networks and wonder why they are actually so popular at the moment. For example, a feed-forward network is a quite simple mathematical object: An input vector $\mathbf{x}\in \mathbb{R}^n$ is mapped to some output vector $\mathbf{y}\in\mathbb{R}^k$ via linear and non-linear mappings, e.g., for a two-layer NN: $$\mathbf{y}=f(\mathbf{W}_1,\mathbf{W}_2)=h(\mathbf{W}_2g(\mathbf{W}_1\mathbf{x})).$$ Learning amounts to estimating the matrices $\mathbf{W}_1,\mathbf{W}_2$. So, asking a bit heretically: Most mathematicians would find this a very simple problem, for which well-known techniques exist. So, what's the issue about neural networks and why are they so powerful and why is there so much mystery surrounding them?
