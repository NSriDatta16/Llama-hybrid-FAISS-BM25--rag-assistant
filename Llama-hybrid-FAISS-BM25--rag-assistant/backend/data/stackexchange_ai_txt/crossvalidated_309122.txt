[site]: crossvalidated
[post_id]: 309122
[parent_id]: 
[tags]: 
Help understanding training stacked autoencoders

I've been learning about stacked autoencoders, but wasn't entirely sure how to train them. From what I understand, given layers $h_1,h_2,...,h_n$, we greedily train as follows For every h in hidden_layers: let prev_hs be all the previously trained hidden layers let transformed = prev_hs(input_x) train h'(h(transformed)) ~ transformed delete h' add h to list of previously trained hidden layers Then for fine tuning, we do Initialize new hidden layers h1', h2',...,hn' with size hn, h(n-1),..., h2, h1 Train hn'(...(h2'(h1'(hn(...(h2(h1(input_x)))))))) ~ input_x Is this correct, and if not, what does the training procedure look like?
