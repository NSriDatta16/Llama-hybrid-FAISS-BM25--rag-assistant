[site]: datascience
[post_id]: 85454
[parent_id]: 
[tags]: 
Calibration using predict_proba vs class_weight

I am making a Random Forest Classifier to determine whether a sentence is "positive" (1), "negative"(-1) or "neutral"(0). However, I prefer having false negative than false positive, that is, I prefer saying that a sentence is neutral even if it's not than to say that a sentence is positive when it's neutral, a fortiori if it's negative. So I use predict_proba , with something like: def my_pred(rfc, X, weight=0.5): res = rfc.predict_proba(X) if res[0]>weight: return -1 elif res[2]>weight: return 1 return 0 But I wonder if I can make such things (give more importance to the neutral class) using class_weight ? Would it be better?
