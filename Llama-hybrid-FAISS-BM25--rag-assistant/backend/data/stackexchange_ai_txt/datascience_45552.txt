[site]: datascience
[post_id]: 45552
[parent_id]: 
[tags]: 
Why am I getting very different results between SVC, LinearSVC and Naive Bayes?

I am doing classification by using bag-of-words model. The goal is to locate users based on their tweets. Splitted the data as 80% training and 20% test. I did experiments with sklearn's SVC and Naives Bayes. The results 35% and 42% accuracy respectively. However, when I try the sklearn's LinearSVC algorithm, it gives me 80% which is shocking. This is the part of the code: text_clf = Pipeline([ ('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), ('clf', LinearSVC()), ]) text_clf.fit(train_data, train_target) What might be the reason for that? Why LinearSVC performs really good?
