[site]: datascience
[post_id]: 80732
[parent_id]: 78032
[tags]: 
Oh, I think I've finally got it. It's just an averaging problem: for each fold in your k-fold cross-validation, you get perfect auROC, but at the default threshold of 0.5 your hard classifiers (for each fold) sometimes have $FPR=0$ and $TPR , but some other times $FPR>0$ and $TPR=1$ . Then averaging you are able to get both $\operatorname{mean}(FPR)>0$ and $\operatorname{mean}(TPR) . To check, have a look at the cv_results_ table, particularly at each test fold scores ( split _test_ ), rather than just the mean_test_ scores.
