[site]: crossvalidated
[post_id]: 306196
[parent_id]: 
[tags]: 
Which test to take when compare two continuous distribution(LIWC score)

I am now working on a project that try to extend the LIWC dictionary to fit our local language (mixed English, Indonesian, Malay and Chinese). We use a word embedding model to find similar words to words in LIWC dictionary, then calculate score based on the new dictionary. The original output from LIWC dictionary looks like this: [53.2, 11.2,..., 85.01] which represent the proportion of words belonging to each category, and the categories include: ['Function', 'Pronoun', 'Ppron', 'I', 'We', 'You', ... ,'Netspeak', 'Assent', 'Nonflu', 'Filler'] After extending the LIWC dictionary, I want to test whether we have the similar output as that from the original LIWC. However after extending the words in the dictionary, the proportion of each category will surely increase. Therefore instead of directly compare the two score, I think it will make more sense if we compare the relation between variables. More precisely, say I have the original output dist1, [d1v1, d1v2, ..., d1vp] and the output from our extended dictioary dict2, [d2v1, d2v2, ..., d2vp] where p represent the number of categories. Does there exist a test that can help me prove whether the relation between variables in dist1 is similar to that in dist2? I was thinking that in each dist divide the score by the highest score to get a normalized score dist, then use paired t-test to test whether there is a significant difference between two dists. However I'm not sure whether this makes any sense. A gentleman from stackoverflow told me that corss entropy and K-L Divergence might work. Is there any other suggestion? Thank you in advance for any advice :)
