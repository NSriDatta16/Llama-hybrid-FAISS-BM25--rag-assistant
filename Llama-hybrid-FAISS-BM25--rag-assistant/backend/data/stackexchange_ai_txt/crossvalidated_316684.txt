[site]: crossvalidated
[post_id]: 316684
[parent_id]: 152621
[tags]: 
Multiple imputation is similar to maximum likelihood in that they both provide unbiased and efficient parameter estimates even with missing at random (MAR: or missingness with likelihood depending on observed factors) data. The reason for this is that imputation models and reduced likelihoods both plausibly account for what a reasonable range of missing values would have been had they been observed. I would argue that neither really "substitutes data". However, with multiple imputation, you can inspect the multiply imputed datasets and explain to non-analysts what values were actually imputed. Just the same, you can use your maximum likelihood estimates to create a parametric bootstrap for the missing values after performing EM and "sample from the posterior" in that fashion. MI has been described as an approximate Bayesian bootstrap for that reason.
