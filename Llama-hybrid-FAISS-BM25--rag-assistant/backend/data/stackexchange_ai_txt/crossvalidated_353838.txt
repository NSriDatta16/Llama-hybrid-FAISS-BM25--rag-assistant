[site]: crossvalidated
[post_id]: 353838
[parent_id]: 353823
[tags]: 
Based on the STL decomposition chart I would say the time series exhibits only very mild heteroskedasticity (maybe a little less variance 2004-2008) and this is not associated with periods with a higher or lower mean value. There also don't seem to be any outliers caused by an additive model such as a negative prediction for a strictly non-negative count data. In fact, the mean seems to vary only from 600 to 900 ( Just to be clear about the heuristics I'm using to make this recommendation, let's consider a counter example. Let's say the mean had changed from 500 to 20,000 over a few years, and that during the period when the mean was close to 500, the standard error was about 100, while the standard error during the period when the mean was 20,000 was about 4,000. This would show on the residual component of the STL chart as very strong heteroskedasticity. Another kind of pathology to look for is interaction of seasonal and trend predictions. Consider these two statements about a website that got 1 million page views a day on average over a period of several years On Christmas, the number of page views is 1/5 of normal. On Christmas, the number of page views is 800,000 Both fit the historic data. But what if site traffic starts to grow, and we have 2 million in 2017, and 3 million in 2018? Would we still use an adjustment of -800e6 for that day, or would the 1/5 make more sense? What if the site traffic crashes to only half a million a day? Would you then predict negative -300e6 page views? A multiplicative model would instead take trend * seasonal and predict 500e6 * (1/5) = 100e6 for the same day. So if we use the wrong model, we'll see a huge residual spike of with a magnitude of 400e6 for that day. Look for a weak seasonal component outliers in the residuals to indicate we've made a bad choice of multiplicative vs. additive.
