[site]: crossvalidated
[post_id]: 18671
[parent_id]: 16930
[tags]: 
It turns out that, as always, there are multiple, competing ways of figuring this out. The most common involves estimating the finding the change in $R^2$ when the independent variable is added to the model, as in a stepwise regression. In order to eliminate ordering effects, all possible orderings are tried and the resulting change in $R^2$ is averaged. This seems to have been invested multiple times - the best explanation I have come across is Kruskal (1987), " Relative Importance by Averaging Over Orderings ", The American Statistician 41(1):6-10. This method is elaborated on as hierarchical partitioning in Chevan and Sutherland (1991), The American Statistician 45(2):90-96. The R packages hier.part implement this algorithm (and the relaimpo package includes many more). Indeed, I'd recommend anyone interested in this to check out the relaimpo package which can also estimate confidence intervals using bootstrapping, either assuming simple random sampling or using the survey package. Using the example given above with the hier.part package gives the following: > require(hier.part) > p p$I.perc I x1 10.96334 x2 18.18595 x3 12.67995 x4 58.17075 > I should probably add that this method isn't appropriate for time-series data given the for all the usual reasons that regression of time-series data should be undertaken with caution.
