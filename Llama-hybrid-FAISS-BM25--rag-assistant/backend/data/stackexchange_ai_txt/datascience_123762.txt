[site]: datascience
[post_id]: 123762
[parent_id]: 
[tags]: 
How to simulate from bivariate time series using VAR in R?

Background I've run into a problem while trying to simulate from an existing time series using a VAR. My aim is to simulate future "trajectories" which I'd like to integrate in an existing MCS, so my question is about simulating, not forecasting. My time series looks like this - sorry for the mess, I was not able to recreate my problem with simulated data: dat Current Approach My current approach is as follows: I fit a VAR using the tsDyn 's lineVar -function, and then I simulate a "trajectory" using VAR.sim from the same package. However, when I plot the original time series, extended by my simulation, the results look suspicious: library(tsDyn) library(tidyverse) # Fit the VAR: fit % rename(A = "V1", B = "V2") # Plot the original time series and the simulated trajectory: ggplot(dat %>% add_case(., sim) %>% mutate(time = 1:nrow(.)) %>% pivot_longer(cols = A:B)) + geom_path(aes(y = value, x = time, color = name)) + geom_vline(xintercept = 41, linetype = "dashed") + theme_classic() Problem It is easy to see that the simulated trajectory has far less variance than the original time series, both variables are oscillating around the last known data points. I'm aware that a VAR has assumptions about stationarity etc. that may not be met by the original time series, but even in case those assumtions are not fullfilled: Shouldn't the variation of the original time series be carried over to the simulation? I'm confused whether this outcome is a result of my model choice not being adequate, or of some mistake in my code. Questions What is the reason for the low variance in the simulations? How to simulate plausible trajectories instead?
