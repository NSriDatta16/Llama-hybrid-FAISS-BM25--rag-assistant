[site]: crossvalidated
[post_id]: 395635
[parent_id]: 
[tags]: 
Incremental solution for matrix inverse using Shermann-Morrison in $O(n^2)$

I have been reading a presentation on Value Function Approximation by David Silver (Introduction to Reinforcement Learning Course). On page 43 he finds a solution for linear least squares for an unknown parameter vector $w$ . He claims that, for $N$ features, inverting a matrix is $O(N^3)$ , but an incremental solution using Sherman-Morrison algorithm with complexity of $O(N^2)$ is possible ( see image ). Since Shermanâ€“Morrison formula allows for computing an inverse of the sum of an invertible matrix $A$ and the outer product, $uv^T$ , of vectors $u$ and $v$ , I don't really see how this applies to this case as well.
