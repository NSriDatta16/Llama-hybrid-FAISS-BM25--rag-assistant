[site]: crossvalidated
[post_id]: 296044
[parent_id]: 
[tags]: 
When is logistic regression Bayes-optimal?

In logistic regression, we model the posterior probability $P(y=1 | x)$ with the help of a sigmoidal function: $$P(y=1 | x) = \frac{1}{1+\exp(-x)} = h(x)$$ If we classify a datapoint to the class y = 1 if $h(x) > 0.5$, is then our classification Bayes-optimal, since it chooses to classify according to the higher posterior class probability? Is this connected to the fact that the minimizer of log loss is $\ln\frac{h(x)}{1-h(x)}?$
