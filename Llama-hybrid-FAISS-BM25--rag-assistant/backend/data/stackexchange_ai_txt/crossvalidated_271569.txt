[site]: crossvalidated
[post_id]: 271569
[parent_id]: 270043
[tags]: 
From the plot, it seems you choose 2, 6 and 10 random selected features with cross validation. Good result for you, it's not the more features, the better prediction result for random forest. For random forest, the optimal number of features is the sqrt of features numbers, but you can tuning it with cross validation. The best feature numbers seems is 6 for you (maybe 5 or 7, you can try again). The more features, the more redundancy features being selected as split nodes, so it's true for the decrease of predictions.
