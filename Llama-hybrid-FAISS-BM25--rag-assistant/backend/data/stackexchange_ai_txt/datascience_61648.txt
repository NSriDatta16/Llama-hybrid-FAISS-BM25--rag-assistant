[site]: datascience
[post_id]: 61648
[parent_id]: 61567
[tags]: 
It can be a good idea, but if you want to use PCA, you will have to use it carefully. First of all, PCA will reduce dimension depending on the data observed in your dataset . Consequently, if it is biaised somehow, the projection will not work with different datasets. For instance, if you have a strong correlation between two features and a third one is independent, the principal component will not be the same vector as if features 2 & 3 were highly correlated. Secondly, as PCA relies on variance, and your data is likely to be extensive, you will probably need to scale each feature (so that it is given the same importance a priori ). But here's the trick: you will have to be clever in your scaling, depending on whether you want to process only this dataset (in this case, scale from min to max could be a good idea), or other datasets (in this case, scale from bounding values that you could encounter). Then there are a few other things to care about: Of course, you need to split your data for each type of player Once your data is scaled, PCA will give the same importance to each feature, which may not be exactly what you are looking for The projection on one single feature will not be interpretable anymore. It will basically allow you to describe a player by a single scalar value, but it does not mean that a "good" player will have a low or high score , it may be an intermediate value (but if the data describes the problem well and the projection is good, all good players should have approximately the same value) Standard PCA does not work if "good" and "bad" players cannot be separated linearly in the feature space. In that case, it is possible to turn to kernel PCA or other more complex techniques. The projection will retain part of the total variance, keep an eye on how much, because it describes how good your approach is. If it is not sufficient, why not keep more dimensions to describe your player?
