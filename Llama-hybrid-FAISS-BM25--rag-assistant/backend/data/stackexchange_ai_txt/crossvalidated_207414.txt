[site]: crossvalidated
[post_id]: 207414
[parent_id]: 206975
[tags]: 
All particle filters are for state state space models, but not all state space models need a particle filter. Below is a quick explanation. You need a few probability distributions to define a state space model for your observable time series $y_{1:T}$ . Let $x_{1:T}$ denote the sequence of unobserved, or latent, random variables. You need $p(x_1)$ to start off the sequence, and then a bunch of transition distributions, $p(x_t|x_{t-1})$ for $t=2, \ldots, T$ . And then you need the observation distributions, $p(y_t|x_t)$ for $t=1, \ldots, T$ . Most of the time you're interested in using some sort of Bayes' rule because you want to infer about the hidden states. For example, filtering gets you $p(x_t|y_{1:t})$ for all times $t$ , and smoothing gets you $p(x_{1:t}|y_{1:t})$ . Here's when you DON'T need a particle filter. If the initial time state distribution, state transition distributions, and the observational distributions are all Gaussian, then your filtering and smoothing distributions are Gaussian. You get to use closed form Kalman filtering and smoothing here. If your hidden state chain evolves on a finite state space, you get to use hidden markov models, so you can compute all your stuff in closed form too. Particle filters are basically importance sampling for your hidden states. You draw samples at each time point from some distribution, and then weight them according to how good they are. You do this because the state space model you assume is true doesn't fit into one of the above two categories. Any posterior distribution has a weird normalizing constant, so you try to draw samples instead. Those are all state estimation problems. When you say, "say for example, I want to estimate the variance of a time series sequentially using such a filter; what is the difference between a state estimation problem and estimating the variance of my series?" that totally depends on how you write down your model. A general rule of thumb is that if you're assuming it moves over time, that's a state estimation problem and is comparatively easy to the other problem. If you're estimating static parameters, that's generally harder. I would recommend that you figure out how the filtering algorithms work for known parameters first. Take for instance an example in the second link in one of the comments above (page 3 of the tutorial paper). They model the return of an asset at time $t$ , call it $y_t$ , with a normal distribution that has mean zero, but changing variance over time. The state $x_t$ represents (something proportional to) the log of the variance of your return sequence, . $$ y_t = \beta \exp\left[\frac{x_t}{2} \right] w_t\\ x_t = \alpha x_{t-1} + \sigma v_t $$ Since $p(y_t|x_t)$ is gaussian, but nonlinear in $x_t$ , you could use a particle filter here. The filtering distribution $p(x_t|y_{1:t})$ gives you the most up-to-date information about what volatility of your asset is. Notice how we have said nothing about how to estimate $\alpha$ , $\beta$ , or $\sigma$ , even though these numbers have something to do with how volatility or how it changes over time. Edit: particle filters can also be use for non-time series models. In the case of data-annealing, the sequence of target distributions will correspond to posterior distributions with more and more data. See this paper: A sequential particle filter method for static models . There is also "temperature annealing" where the sequence of target distributions will correspond to your prior multiples by different powers of your likelihood. In this situation, as the iterations progress, you will eventually be targeting your parameter posterior. For that you can look at this paper: Annealed Importance Sampling .
