[site]: crossvalidated
[post_id]: 163074
[parent_id]: 
[tags]: 
Assigning Weights to An Averaged Forecast

So I've been learning how to forecast over this summer and I've been using Rob Hyndman's book Forecasting: principles and practice. I've been using R, but my questions aren't about code. For the data I've been using, I've found that an average forecast of multiple models has produced higher accuracy levels that any sole model by itself. Recently I read an blog that talked about averaging forecasting methods and assigning weights to them. So in my case, lets say I assign 11 different models to my set of data (Arima, ETS, Holt Winters, naive, snaive, and so forth) and I want to average a few of these to get a forecast. Has anyone had any experience with this or can point me to an article that might give some insight on the best way of going about this? As of right now, I'm using cross validation and Mean Absolute Error to figure out which models perform best and which perform worst. I can even use this to identify the top k # of models. I guess my questions are 1) How many models would you suggest selecting? (2,3,4,5,6, etc) 2) Any ideas on weights? (50% to the best, 25% to the second best, 15% third best, 10% to the 4th best, etc) 3) Are any of these forecasting models redundant and shouldn't be included? (Arima, snaive, naive, HW's "additive", ETS, HoltWinters exponential smoothing, HoltWinters smoothing w/ trend, HoltWinters w/ trend/seasonality, multiple regression)
