[site]: crossvalidated
[post_id]: 524133
[parent_id]: 
[tags]: 
How does one initialize an LSTM/GRU to produce the identity function?

I know this sounds silly, but I would like to initialize an LSTM/GRU in such a way that the output hidden state for an arbitrary sequence length is precisely the first $k$ dimensions of the input embedding. In other words, if my word embedding is $\mathbf{x} = (x_1,x_2,\ldots,x_{n})$ , I would like to find an appropriate initialization for all weights and biases (and also the initial hidden/cell states) so that $\mathsf{RNN}(\mathbf{x}, \mathbf{h}) = \mathsf{Id}(\mathbf{x})_{1:k}$ , assuming $k . There are many possibilities, but I'm not quite sure which weights should be initialized to zero. I'm afraid killing too many gates might also break training (similar to when one initializes an MLP with zero weights). I am working with a special sequence type where only using the first token provides a decent embedding for my downstream task which consumes the last hidden states of the RNN. Intuitively, I would think that forcing the RNN to output this embedding at the start would provide a reliable satefy net to default to. The RNN could then refine/adapt its inner working during training, either from the start or by unfreezing its parameters later on. Is this a good idea, or even possible given the nonlinearities? If so, how do I derive the correct initialization scheme? Any insights would be appreciated.
