[site]: datascience
[post_id]: 81224
[parent_id]: 81124
[tags]: 
The point is that parameters sharing is not the same as reusing some learnt weights in a task for another task (a.k.a transfer learning ); it is, transfer learning can be used with convolutional neural networks, but parameters sharing does not mean transferring knowledge from one task to another. For a detailed definition of parameters sharing, look at this documentation from Stanford university , section Parameter Sharing As explained in that page, you can think of it as a tool for reducing the number of weights while learning in a specific task (so forget about traqnsferring these weights to another task, which could be the case, but not the meaning of this concept). An intuitive way of reasoning the concept could be: parameter sharing assumption is relatively reasonable: If detecting a horizontal edge is important at some location in the image, it should intuitively be useful at some other location as well due to the translationally-invariant structure of images
