[site]: crossvalidated
[post_id]: 99800
[parent_id]: 
[tags]: 
PCA realization in python

Input matrix M x N, M rows (number of samples), N cols (dimesionality of data). But I don't understand why we must transpose matrix when put it in np.cov? def pca(): #M x N xs= np.loadtxt("data_3d.txt",delimiter=" ", skiprows=1, usecols=(0,1,2)) print xs.shape # print xs #get mean mean= np.mean(xs,axis=0) # print mean.shape # print mean #N x M data= (xs-mean).T # why need transpose? print data.shape # print data #N x N covData=np.cov(data)#calculate covariance matrix print covData.shape eigenvalues, eigenvectors = np.linalg.eig(covData) print eigenvalues.shape # N long print eigenvectors.shape # N x N print eigenvalues print eigenvectors And how then project and reconstruct data? By projection we need to obtain matrix M x k where k #sort and get k largest eigenvalues k=2 idx = eigenvalues.argsort()[-k:][::-1] print idx eigenvalues = eigenvalues[idx] # k long eigenvectors = eigenvectors[:,idx] # N x k print eigenvalues.shape print eigenvectors.shape print eigenvalues print eigenvectors #projection and reconstruction pr= np.dot(data.T,eigenvectors) # (M N) * (N k) => (M k) rec= np.dot(eigenvectors, pr.T) #(N k) * (k M) => (N M) print (data-rec) # test reconstruction error
