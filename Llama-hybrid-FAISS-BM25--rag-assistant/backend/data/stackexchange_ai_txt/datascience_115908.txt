[site]: datascience
[post_id]: 115908
[parent_id]: 115541
[tags]: 
A model-free RL algorithm means that the algorithm does not know how the environment works. In your case, your agent receives states and rewards from your simulation model and uses this data to update the policy by trial-and-error. Therefore, it is still model-free (but in a simulated environmnet). This is not different than standard RL benchmark environments, like the torque simulators such as MuJoCo. A model-based RL algorithm would know how the environment works (or at least learn it) and would be able to plan actions by using the knowledge of the environment. If you want that the agent uses the differential equations of the simulator to get a better performance, you can try other approaches such as model predictive control.
