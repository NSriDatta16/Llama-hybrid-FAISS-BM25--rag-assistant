[site]: crossvalidated
[post_id]: 474826
[parent_id]: 
[tags]: 
Predicting multilinear regresssion coefficients using an RNN

If you had a multlinear regression problem (y = $a_{1}x_1$ + $a_{2}x_{2}$ + $a_{3}x_{3}$ + ... + $a_{n}x_{n}$ + b, want to predict the coefficients, $a_{1}$ , $a_{2}$ , ..., $a_{n}$ , and b), could you use an RNN to solve for the coefficients? I've been using no hidden layers to solve a linear problem ( $y = mx+b$ ) for the coefficients ( $m$ and $b$ ) using a regular neural net, and they show up as the neural net's weights. However, when you extrapolate this to having multiple inputs and coefficients, the neural nets weights turn into the averages of the $a$ 's because there are a lot of equations that yield similar outputs to the input line. To fix this, I was thinking you could use an RNN or LSTM, feed different x sets, and accurately estimate the coefficients.
