[site]: datascience
[post_id]: 60893
[parent_id]: 60861
[tags]: 
The answer in the linked question says to use approach 2. Specifically: Run cross-validation on the train set separately for each choice of hyper-parameter values. On each run, average the score across the k folds to produce a final cross-validation score. Choose the hyper-parameters that give us the best cross-validation score. Retrain a model with those hyper-parameters on the entire training set. Test this model on the test set, which has not been used at all until now.
