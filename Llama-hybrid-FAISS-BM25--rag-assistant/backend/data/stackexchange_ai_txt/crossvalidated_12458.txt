[site]: crossvalidated
[post_id]: 12458
[parent_id]: 12420
[tags]: 
Let's think of a rating of test item $k$ as a function of a three latent variables: the intrinsic difficulty of the question, $u_k$, an item specific ability of test subject $i$, $u_{ik}$, a question specific rating 'leniency', $u_{jk}$. Assuming a rating is a linear function of these factors we can say: $$ \text{Rating}_{ijk} = u_k + u_{ik} + u_{jk} + \varepsilon_{ijk} $$ If $u_k$ is drawn at random conditional on $k$, we can get a valid estimate of item position specific ability learning and leniency from this model: $$ \text{Rating}_{ijk} = \beta_0 + u_{ik} + u_{jk} + \varepsilon_{ijk} $$ Where $\beta_0$ is the average difficulty of the questions and variance of difficulties is aborbed into the error term. This model is estimable but it has a lot of parameters. If you are interested in detecting linear trends then you can simplify the model as follows. $$ \begin{align} u_{ik} = p_{0i} + p_{1i}\text{Item Position}_k \\ u_{jk} =r_{0j} + r_{1j}\text{Item Position}_k \end{align} $$ And in the combined model: $$ \text{Rating}_{ijk} = \beta_0 + p_{0i} + p_{1i}\text{Item Position}_k + r_{0j} + r_{1j}\text{Item Position}_k + \varepsilon_{ijk} $$ This is similar to your proposed model except it does not include a predictor for specific item difficulty, which makes sense because if item difficulties are random, your $\beta_1$ term should equal 0. You might consider adding higher order polynomials of item position to allow for more flexibility in learning and leniency rates.
