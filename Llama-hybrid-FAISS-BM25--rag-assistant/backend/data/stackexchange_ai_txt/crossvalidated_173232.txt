[site]: crossvalidated
[post_id]: 173232
[parent_id]: 
[tags]: 
Introduction to Markov Process (Part 2): Dynamical system and Markov relationship

In my previous post asked here Introduction to Markov process: How to prove that a process is Markov? Part 1 , -- a process is Markovian if it follows the memoryless property. Consider, a dynamical system $x_n = f(x_{n-1})$ and a (stationary) Markov chain ${(X_n)}_{n \in \mathbb{Z}}$ in discrete time with each $X_n$ taking its values in a finite set $E$. The canonical space of the Markov chain is the product set $E^{\mathbb{Z}}$. The trajectory $X=(\ldots, X_{-1}, X_{0}, X_1, \ldots)$ of the Markov chain is a random variable taking its values in $E^{\mathbb{Z}}$. Let $\mu$ be its invariant distribution. Question1: How does one show that a Markov Process generates (iid) random variables or is it only random variables which may not be iid? Question2: In https://en.wikipedia.org/wiki/Subshift_of_finite_type it says that through the shift operator $T$, a shift dynamical system is a Markov Process. So, it means that the shift dynamical system can generate iid random variables. How? A simplified version of explanation as to how a Markov Chain is a dynamical system and vice-versa (how the dynamical system can be a Markov Chain) will be helpful to clear the concept. Links to Theorum and proof will be additionally very helpful
