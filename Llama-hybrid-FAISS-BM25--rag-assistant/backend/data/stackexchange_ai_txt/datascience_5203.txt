[site]: datascience
[post_id]: 5203
[parent_id]: 5196
[tags]: 
If you're working with R language, I would suggest first to try use R ecosystem 's abilities to parallelize the processing, if possible. For example, take a look at packages, mentioned in this CRAN Task View . Alternatively , if you're not comfortable or satisfied with the approaches, implemented by the above-referred packages, you can try some other approaches, such as Hadoop or something else. I think that a Hadoop solution would be an overkill for such problem, considering the learning curve , associated with it, as well as the fact that, as far as I understand, Hadoop or other MapReduce frameworks/architectures target long-running processes (an average task is ~ 2 hours, I read somewhere recently). Hope this helps.
