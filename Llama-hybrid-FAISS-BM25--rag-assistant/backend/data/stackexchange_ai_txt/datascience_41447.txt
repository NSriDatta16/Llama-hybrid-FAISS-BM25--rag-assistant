[site]: datascience
[post_id]: 41447
[parent_id]: 
[tags]: 
Mixing Textual Data and Numerical Data (Neural Network)

I have 2 "nature" of data (more actually if I count images data) : Textual (that I treat with special tokenization and a TfIdfVectorizer) ~ 5000 features Non textual (like length of sentences, # of characters in my sentence, etc.) : only numerical features Image data (presence of special label in the image in a document) : very rare so no need here With all this kind of data I should be able to distinguish spam from non spam (different languages here). For now I do have a good performance on my model but I was thinking of a way to mix more "properly" this kind of data in order to improve the performance. For now I simply deal with all those features at the same level (with a RandomForest Classifier) but I was wondering if it could be a good idea to work with Neural Network and specifically neural network with multi input & multi output : my idea here is to deal with each nature of data first then merge all to see interactions between the different kind of features. I am using the MultiInput MultiOutput architecture present in Keras : In fact for the Main_Input part (for me it is for textual features) I am just using a simple NN with only one hidden layer (only 64 nodes) and then an output layer with a $sigmoid$ activation function. My Aux_Input are my "numerical" features and after merging all of these I just add one Dense Layer with again 64 nodes and then a output layer with a $sigmoid$ activation function. The implementation in Keras is pretty good by the performance are worst than when I simply deal with all the features at the same time and throw it in an output layer (so just a Logistic Regression) ... and It is a little bit confusing to me: to me this kind of architecture is more suitable for my phenomena (I have two kind of data and I deal first separately then merge to get interaction). Is it because I am loosing information between my initial textual features (TFIDF) and the "numerical" features by passing through a hidden layer only for the textual features ? How to deal with "high dimensional" data (here the TFIDF features) and maybe perform a reduction dimension without losing performance ? When I deal only with textual features I get better performance and when I deal with only numerical features, again, I get better performance but for both little bit worst than doing a Logistic Regression with all features together ... any clue here ? Do you have suggestions or remarks for my architecture ? In fact, just by writing down this question I realize that maybe I can do multiple classifier (one for each kind) and then "average them with a new one" ... but I don't know how ^^ (I am thinking of something like the output of a ML model would be an input of my final model). I am pretty sure that separately I can improve performance (for example try different embedding for the textual part). What do you think ? Thank you in advance for any comments, clues or whatever that can clear my mind or that can refer to a good article/book/tutorial/example :)
