[site]: datascience
[post_id]: 83942
[parent_id]: 83940
[tags]: 
First, note that Random Forests can handle categorical variables (moreover, if you have too much categories, reducing this number is a good practice). If you want to apply a filter to your data, I'd suggest you using sklearn transformers (like OneHot Encoder, Label Encoding, ... pick the one you need according to what you want to do). In this case, you have to fit the encoder in your train dataset, and then apply it in your test. If you want to apply this in a real case, you have to save your trained encoders alongside your trained model, so you can apply the encoder directly to the new data before predicting on it, so it has the same pattern. Here is an example with Label Encoder from sklearn import preprocessing train, test = ... # SEPARATE YOUR DATA AS YOU WANT le = preprocessing.LabelEncoder() trained_le = le.fit(train) train = trained_le.transform(train) test = trained_le.transform(test)
