[site]: crossvalidated
[post_id]: 342123
[parent_id]: 121975
[tags]: 
This paper trains a GAN on point clouds: https://arxiv.org/pdf/1707.02392.pdf In that process they created an auto-encoder framework. So they were able to get those distinct feature vectors, and they show an example of traversing the latent space. I figure that new challenges arise in working in 3D. One of them is that it is not clear the best way to order 3d data, in this paper they don't order the data, so evaluation functions need to be symmetric (permutation agnostic). So they used 1-D convolution layers. They use the same activation functions as 2D representation (ReLU), since it is symmetric. Seems that there is a lot of untraversed territory at the intersection of 3d representations and ML. Edit- adding citation: Panos Achlioptas and Olga Diamanti and Ioannis Mitliagkas and Leonidas J. Guibas, Representation Learning and Adversarial Generation of 3D Point Clouds, CoRR, Sun, 06 Aug 2017
