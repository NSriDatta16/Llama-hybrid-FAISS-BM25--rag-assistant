[site]: crossvalidated
[post_id]: 619130
[parent_id]: 618966
[tags]: 
This question gets to the core of the complex relationship between Machine Learning, Statistical Inference, and Causal Inference 1. Machine Learning In conventional supervised machine learning, a model is simply a flexible curve-fitting device. There is typically no intention to make statistical or causal assumptions about the underlying real-world process which is reflected in the flexibility of the models used (e.g. random forests, neural networks, etc.). Due to their flexibility, such models may overfit the training data, which is why it's important to split data into train/test. 2. Statistical Inference Statistical inference tries to make statements about properties of the distribution of an entire population given finite samples. The uncertainty arises from the fact that relationships in small sample may arise by chance and may not hold true on the population level (that is, asymptotically for infinite samples). Statistical inference typically specifies target parameters ("estimands") by proposing a parametric model of the population probability distribution. One can then estimate the parameters on finite samples and quantify the uncertainty of the estimates. In this procedure, any data not used to estimate the target parameter would be a waste - it could only increase the uncertainty of the estimate. However, there is still an analogous practice to train/test splits. As some statisticians (famously John Tukey) have noticed, the decision about what models may plausibly describe the data also tend to be made on the basis of inspecting the very same data in a process Tukey named "Exploratory Data Analysis". If one comes up with a hypothesis about the data by inspecting it, only to confirm it on that same data, of course the parameter estimates it would most likely be significant. It may therefore be useful to split data into two parts, on for "exploration" (the training set), and one for "confirmation" (the test set), to avoid confirmation bias (akin to data leakage in ML). 3. Causal Inference Causal inference is much more ambitious than purely statistical inference. The goal is not only to find population-level parameters, but these parameters should correspond to stable relationships that can predict what would happen when one intervenes on variables. In this context, a model is not merely a model of the distribution of the variables (is in statistical inference), but a model of the data-generating process itself. In real-world applications the model is often based on domain knowledge, although there are many attempts to discover causal structure from data. As with statistical inference, there is a danger of confirmation bias or data leakage (on the side of the domain expert or the causal discovery algorithm). However, causal inference typically relies on other, arguably much stronger, assumptions such as "no unobserved confounders". This is probably why considerations about train/test splits take a back seat compared to other considerations.
