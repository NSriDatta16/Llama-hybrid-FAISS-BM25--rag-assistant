[site]: datascience
[post_id]: 116837
[parent_id]: 116791
[tags]: 
To evaluate a model based on K-means clustering and TF-IDF, you can use a variety of metrics. About TF-IDF, you can use metrics from sklearn: from sklearn import metrics actual = predictionDF.select('label').toPandas() predicted = predictionDF.select('prediction').toPandas() print('accuracy score: {}%'.format(round(metrics.accuracy_score(actual, predicted),3)*100)) One common metric is the silhouette coefficient, which measures how well each sample has been assigned to its cluster. This coefficient ranges from -1 to 1, with a high value indicating that the sample is well-matched to its cluster and a low value indicating that it is poorly matched. https://stackoverflow.com/questions/40994347/sklearn-clustering-calculate-silhouette-coefficient-on-tf-idf-weigthed-data You can also use other metrics such as the Calinski-Harabasz index or the Davies-Bouldin index, which measure the compactness and separation of the clusters. It's important to choose the right evaluation metric for your particular task and data. For another unsupervised clustering, you can apply UMAP and TF-IDF. UMAP is a non-linear algorithm for dimensional reduction that works better than linear ones: https://umap-learn.readthedocs.io/en/latest/document_embedding.html In all cases, you need some target information, at least for a random sample (test data). Otherwise, by which basis could you evaluate if the results are correct or not? See also: https://subscription.packtpub.com/book/big-data-and-business-intelligence/9781788474221/7/ch07lvl1sec65/evaluating-tf-idf-model-performance https://pyshark.com/calinski-harabasz-index-for-k-means-clustering-evaluation-using-python/
