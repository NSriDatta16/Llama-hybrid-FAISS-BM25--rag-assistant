[site]: crossvalidated
[post_id]: 343685
[parent_id]: 174279
[tags]: 
If by Bayes classifier you mean a maximum a posteriori probability (MAP or MAPP) decision rule, then for discrete random variables, an intuitive explanation can be found here . More generally, the fact that the minimum probability of error decision rule is the one that decides that $H_i$ is the true hypothesis if $$\pi_if_i(x) > \pi_{1-i}f_{1-i}(x),$$ is easily derived (see, e.g. here for details). The rule above can also be expressed as $$L(x) = \frac{f_1(x)}{f_0(x)} ~~\begin{array}{c}H_1\\ \gtrless\\H_0\end{array}~~\frac{\pi_0}{\pi_1}$$ which can be recognized as a likelihood ratio test with the Bayesian threshold.
