[site]: datascience
[post_id]: 90705
[parent_id]: 
[tags]: 
Deep Q-learning in non-episodic tasks

I want to use Deep Q-learning (specifically DDQL by Hasselt et al. 2015, but it is the same principle) in a non-episodic task (continuing). I know that it is possible to use Q-learning in continuing tasks; however, I'm not sure if I should modify my model. Until now, I've found little information, and the closest article that I have read is this website , where the use of mean reward is explained based on Sutton's book. The explanation makes sense to me, but I'm not completely sure, and I'm relatively new on the field. I've grateful if anyone could give me some insights on using DQL in non-episodic tasks or a reference where I can look it. I especially care about the computation of the update. Thanks in advance, Tom√°s
