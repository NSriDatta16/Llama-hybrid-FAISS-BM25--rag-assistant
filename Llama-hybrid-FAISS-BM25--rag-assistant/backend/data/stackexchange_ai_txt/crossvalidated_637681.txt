[site]: crossvalidated
[post_id]: 637681
[parent_id]: 597167
[tags]: 
We begin by highlighting key facts and details about diffusion models: The forward diffusion process is a step-wise deformation of the data distribution caused by the injection of additive noise at each time step. The forward process assumes the latent dimension is exactly equal to the data dimension $x_{t+1} \equiv x_{t}$ The structure of the latent space of each time step is fixed as a linear Gaussian model (not learned) centered on the output of the previous time-step. The transition probability kernel for a single time-step is $q(x_{t} \vert x_{t-1}) \: = \mathcal{N} \big( \: \sqrt{\smash[b]{\alpha_t}} \cdot x_{t-1} , \: (1 \: - \: \alpha_t) \cdot \mathcal{I} \: \big)$ where moments depend on the parameter $\alpha_{t}$ with mean $\mu=\sqrt{\smash[b]{\alpha_t}}$ centered on the previous timepoint and covariance $\Sigma=(1 \: - \: \alpha_t)$ To sample from the diffusion kernel distribution $x_{t} \sim q(x_{t} \vert x_{t-1})$ , we could use the re-parameterization trick, mathematically expressed as $x_{t} \: = \: \mu_{t} \cdot x_{t-1} \: + \: \sigma_{t} \cdot \epsilon_{t}$ These modeling constraints on the diffusion process labor the point that all that the encoding process $q(x_{t} \vert x_{t-1})$ requires is learning the $\mu_{t}$ and $\sigma_{t}^2$ of each latent Gaussian distribution. Because each of these independent and sequential time-steps are analytically tractable (Gaussian), in consequence, so is the full chain as well. It can then be shown that the KL-divergence requiring optimization of the posterior is $\underbrace{ \mathbb{E}_{ q(x_{1} \vert x_{0}) } \: \Big\lbrack \: \log p_{\theta}(x_{0} \vert x_{1}) \: \Big\rbrack }_{\text{reconstruction term}} \: + \: \underbrace{ D_{KL} \: \big( \: q(x_{T} \vert x_{0}) \: \Vert \: p(x_{T}) \: \big) }_{\text{prior matching term}} \: - \: \sum_{t=2}^T \underbrace{ \mathbb{E}_{ q(x_{t} \vert x_{0}) } \: \Big\lbrack \: D_{KL} \: \big( q(x_{t-1} \vert x_{t}, x_{0}) \: \Vert \: p_{\theta}(x_{t-1} \vert x_{t}) \big) \: \Big\rbrack }_{\text{denoising matching term}}$ With some math, the main computational challenge comes from the third KL-divergence term which is shown to be equal to $D_{KL} \big( \: q( x_{t-1} \vert x_{t}, x_{0}) \: \big\Vert \: p_{\theta}(x_{t-1} \vert x_{t} ) \: \big) \: = \frac {1} {2 \sigma_{q}^2 (t)} \Big\lbrack \: \big\Vert \: \mu_{\theta} \: - \: \mu_{q} \: \big\Vert_{2}^2 \: \Big\rbrack$ where $\mu_{q}$ and $\mu_{\theta}$ are shorthand for $\mu_{q}(x_{t}, x_{0})$ and $\mu_{\theta}(x_{t}, t)$ respectively. Examination of this result explains why diffusion models train a parameterized neural network model to learn to predict the original training image $x_{0}$ from noisy image $x_{t}$ and sampled time index $t$ . By extension, a simple application of the re-parameterization trick permits modeling the noise instead $\epsilon_{\theta}(x_{t}, t)$ . In summary, with a few modeling constraints, the forward diffusion (encoding) process serves as a way to calculate the parameters of the true posterior for the reverse (decoding) process for each time-step $p_{\theta}(x_{t-1} \vert x_{t})$ . The following excerpts are taken from my book on variational inference. Learn more on the topic by visiting https://www.thevariationalbook.com/
