[site]: crossvalidated
[post_id]: 175776
[parent_id]: 
[tags]: 
Combining different classifiers yields lower accuracy than a Random Forest alone

I used the following classifiers (with accuracies): Random Forest - 85 % SVM - 78 % Adaboost - 82% Logistic regression - 80% When I used voting from the above classifiers for final classification, I got lower accuracy than when I used Random Forest alone. How is this possible? All classifiers are giving more or less the same accuracy when used individually, then how does Random Forest outperform their combined result?
