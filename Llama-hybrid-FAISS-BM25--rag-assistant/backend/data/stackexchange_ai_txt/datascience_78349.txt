[site]: datascience
[post_id]: 78349
[parent_id]: 
[tags]: 
Logic behind the Statement on Non-Parametric models

I am currently reading 'Mastering Machine Learning with scikit-learn', 2E, by Packt. In Lazy Learning and Non-Parametric models topic in Chapter 3- Classification and Regression with k-Nearest Neighbors, there is a paragraph stating- Non-parametric models can be useful when training data is abundant and you have little prior knowledge about the relationship between the response and the explanatory variables. kNN makes only one assumption: instances that are near each other are likely to have similar values of the response variable. The flexibility provided by the non-parametric models is not always desirable; a model that makes assumptions about the relationship can be useful if training data is scarce or if you already know about the relationship. My doubt is that I am able to reason out the logic behind the statement- "a model that makes assumptions about the relationship can be useful if training data is scarce or if you already know about the relationship." But, I am not able to see any logic for the first statement- "Non-parametric models can be useful when training data is abundant and you have little prior knowledge about the relationship between the response and the explanatory variables." Please help me to find out the logic behind it other than for computation. Thanks for your time and consideration.
