[site]: crossvalidated
[post_id]: 612792
[parent_id]: 612785
[tags]: 
Yes, we can consider using binary:hinge as our objective such that we get 0/1 predictions. Using a custom evaluation metric is straightforward in XGBoost (a custom objective function is a bit thornier as it requires a Hessian), there is a nice worked example in the Custom Objective and Evaluation Metric section so defining Partial AUC-ROC should be easy. Note that sklearn.metrics.roc_auc_score has an argument for partial AUC calculations already so that might save you even more coding. Just note that we need to set disable_default_eval_metric to True so we use primarily our own metric. Using rankers for fraud detection definitely can be done. Nevertheless, I have not seen it in Kaggle Fraud detection competitions yet so I am not sure how easy is to implement and if it's worth the effort. We would have to reshape our data quite a bit. That said, there are some publications on this for example Viola et al. (2022) MetaAP: a meta-tree-based ranking algorithm optimizing the average precision from imbalanced data specifically uses XGBRanker as its baseline. Almendra (2013) Finding the needle: A risk-based ranking of product listings at online auction sites for non-delivery fraud prediction covers a similar area too.
