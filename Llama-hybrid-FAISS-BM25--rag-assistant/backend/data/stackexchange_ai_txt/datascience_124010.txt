[site]: datascience
[post_id]: 124010
[parent_id]: 115182
[tags]: 
You can think of attention, as used in Transformers or Perceiver as a soft differentiable database. The keys, values and queries are continuously valued vectors and instead of computing a perfect result, i.e. a single query match, you will get weightings of the values depending on the vector similarity of the queries to the keys. Now for your question, suppose you have some feature vectors from a vision encoder that serve as keys and values. In a sense, the table of our the database is already filled with data, we just have to figure out how to query it. If we want to solve the problem of image classification for instance, and the label of an image is 'dog', there might be some visual tokens that represent this, say, in the form of a texture feature. The latent vectors in this case act as queries which extract information from the input data and need to be aligned in such a way, that they extract the necessary information to perform the prediction task. Since the whole model is differentiable, we can backpropagate the loss and shift the latent vectors in a direction that extracts more meaningful information from the inputs. In Jaegle et al. they refer to the latent vectors as clusters because each of them might in fact something like a specific latent feature which can be seen as an implicit clustering of the data within the internal representations. The latent vectors are, however, not pre-computed from any features but initialized randomly at the beginning and then learned via gradient descent as described above.
