[site]: stackoverflow
[post_id]: 2932878
[parent_id]: 2932355
[tags]: 
Byte Endianness On different machines this code may give different results: union endian_example { unsigned long u; unsigned char a[sizeof(unsigned long)]; } x; x.u = 0x0a0b0c0d; int i; for (i = 0; i This is because different machines are free to store values in any byte order they wish. This is fairly arbitrary. There is no backwards or forwards in the grand scheme of things. Bit Endianness Usually you don't have to ever worry about bit endianness. The most common way to access individual bits is with shifts ( >> , ) but those are really tied to values, not bytes or bits. They preform an arithmatic operation on a value. That value is stored in bits (which are in bytes). Where you may run into a problem in C with bit endianness is if you ever use a bit field. This is a rarely used (for this reason and a few others) "feature" of C that allows you to tell the compiler how many bits a member of a struct will use. struct thing { unsigned y:1; // y will be one bit and can have the values 0 and 1 signed z:1; // z can only have the values 0 and -1 unsigned a:2; // a can be 0, 1, 2, or 3 unsigned b:4; // b is just here to take up the rest of the a byte }; In this the bit endianness is compiler dependant. Should y be the most or least significant bit in a thing ? Who knows? If you care about the bit ordering (describing things like the layout of a IPv4 packet header, control registers of device, or just a storage formate in a file) then you probably don't want to worry about some different compiler doing this the wrong way. Also, compilers aren't always as smart about how they work with bit fields as one would hope.
