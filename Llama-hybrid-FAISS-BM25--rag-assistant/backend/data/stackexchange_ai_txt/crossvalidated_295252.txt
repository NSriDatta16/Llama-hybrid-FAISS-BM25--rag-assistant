[site]: crossvalidated
[post_id]: 295252
[parent_id]: 241954
[tags]: 
As mentioned by Franck, there are tradeoffs for sure. In some cases where the categorical variable has a very large number of categories, one hot encoding can blow out the dataset, which also isn't great for some classifiers/datasets. So in those cases, pragmatically, trading off some encoding quality for a smaller dataset can make some sense. If you want to experiment with it, you can use the BaseN encoder in https://github.com/scikit-learn-contrib/categorical-encoding . It lets you specify a base (base-1 is taken to be equivalent to one-hot, base-2 is the binary case, etc.), and then you can do a grid search or something like that to find a base that works out. But, if you can get away with it, one-hot is going to represent the categories more correctly always.
