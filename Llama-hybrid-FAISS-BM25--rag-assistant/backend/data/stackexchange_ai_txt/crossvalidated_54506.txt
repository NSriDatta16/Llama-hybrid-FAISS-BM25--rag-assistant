[site]: crossvalidated
[post_id]: 54506
[parent_id]: 
[tags]: 
Difficulties with a Bayesian formulation of a model for human timing data

The Wing-Kristofferson model is a simple model of the behavior of a human trying to drum out a steady beat (that is, trying to mimic a metronome). Let $y_i$ be the $i$th interval between two drum beats then the model is: $$y_i \sim \text{Normal}(\mu + m_i - m_{i-1}, \sigma_y) $$ $$m_i \sim \text{Normal}(0, \sigma_m) $$ where $\mu$ is the mean interval of a time keeper and $m_i$ is the error of the $i$th drum stroke. What one wants is to estimate the parameters $\sigma_y$ and $\sigma_m$ ( while $\mu$ is considered more of a nuisance parameter). I've been trying to implement this model in a Bayesian framework by treating the $m_i$ as missing data. I've got two problems that I can't get my head around and that I would really appreciate some input on: 1. What would be appropriate "vague/objective" priors for the SD parameters $\sigma_y$ and $\sigma_m$? I've been trying to to find "objective" priors for $\sigma_y$ and $\sigma_m$ that let the data dominate and that are relatively unbiased. Using simulated data I've tried a number of priors, non which have worked well so far. Flat priors on $\sigma_y$ and $\sigma_m$ tend to overestimate $\sigma_m$ but flat priors on $\log(\sigma_y)$ and $\log(\sigma_m)$ tend to pull $\sigma_m$ close to zero. 2. Is there a way to reduce the correlation between the parameters? As $m_i$ are treated as missing data, and thus are parameters of the model, the number of parameters increase with the number of datapoints $y_i$. This wouldn't be too bad if it wasn't for the fact that both the parameters $m_i$ are heavily correlated both with each other and with $\sigma_m$. Another issue is that that $\sigma_m$ and $\sigma_y$ are heavily correlated. All these correlations makes the models hard to fit using MCMC frameworks such as JAGS or STAN. I've been tinkering around with different reparametizations of the model, but so far I haven't found anything that works. Still when the number of data points are low ($n
