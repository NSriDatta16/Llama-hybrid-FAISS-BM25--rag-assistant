[site]: crossvalidated
[post_id]: 484159
[parent_id]: 484153
[tags]: 
The equation described here looks familiar to many machine learning approaches. It appears to fit the paradigm of a regression equation where you have designed/engineered "features" by applying a function, $F$ , to your raw data, $x_i$ . The $w_i$ 's would be the weights that can be learned by least squares or other methods. If you re-use the function $F$ , this problem could be structured as a single hidden-layer neural network. In this case $F$ would typically be a function of the group called activation functions. It would be ideal to explore the addition of an intercept/bias term to the equation for A.
