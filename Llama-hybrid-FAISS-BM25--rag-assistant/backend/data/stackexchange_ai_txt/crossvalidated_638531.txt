[site]: crossvalidated
[post_id]: 638531
[parent_id]: 
[tags]: 
How many lags to insert into a GARCH(m,p) model?

My question might be trivial, but the doubt arises due to different ways of dealing with modeling that I have found in different research papers. In particular, I was able to observe that (in time series environment) after having decided with the information criteria (e.g. AIC or BIC) what the optimal lag of the model is, at this point some authors insert "all" the lags into the model of the variable up to the last lag suggested by the information criterion, while on the contrary, other authors insert "only" and solely the optimal delay defined by the information criterion. What kind of rationale justifies the first or second approach?
