[site]: datascience
[post_id]: 77587
[parent_id]: 77579
[tags]: 
In transfer learning there are two parameters which influence the basic setup to go for: Size of new dataset Similarity of new dataset to dataset of pre-trained model When your dataset is small the problem is that high capacity pre-trained models can easily overfit if you re-train too many layers. And since you re-trained multiple layers this could be an issue here. Instead, try the following two options: Re-train only the last fully connected layer . This is the general approach if your data is similar to the data which the pre-trained model was trained on. Remove the conv. layers towards the end of the pre-trained model and re-train only the new fully connected layer . For ResNet18 you could try tossing conv4 and 5, for example. This is the general approach in transfer learning for small datasets if your data is not very similar to the original data and you only want to use layers for lower level features since the datasets do not have similar higher level features. If you are interested in a theoretical reading on the topic, the paper "How transferable are features in deep neural networks?" could be of interest.
