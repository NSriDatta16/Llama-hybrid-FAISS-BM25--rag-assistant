[site]: crossvalidated
[post_id]: 241888
[parent_id]: 
[tags]: 
What are neurons in neural networks / how do they work?

From what I found out until now: A layer in a neural network consists of a parameterizable number of neurons. A neural network consists of multiple layers. A neuron consists of a function f(x1, x2, ..., xn), a sigmoid function which uses f as input and gives a binary output and a weight factor which is multiplied with with the sigmoid function and determines how much this neuron is considered for the output of the layer. Is this correct and what is the function f/how does it combine the inputs to the output? (I tried to read the literature and some course material myself but they all either ignore this part/call it a black box or assume you have a PhD in Theoretical Math but my university only focused on Applied Informatics. So if you have literature understandable for someone like me I would also appreciate it)
