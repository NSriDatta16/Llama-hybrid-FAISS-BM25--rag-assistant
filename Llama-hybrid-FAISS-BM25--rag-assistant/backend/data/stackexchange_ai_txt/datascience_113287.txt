[site]: datascience
[post_id]: 113287
[parent_id]: 
[tags]: 
Demand Forecasting/Regression task for new products

I'm currently at the end of my master's degree and have to solve a data science problem. I am currently kind of stuck and need some kind of advice to get better results. I want to share the task I have to solve, and how I approached it. Maybe you stumbled upon some similar problem and could give me advice. The task is some kind of forecasting quantities for new products in a given interval. I got historical data which includes only one categorical flag of the product group, a description text, and the time series. So it's not a typical demand forecasting where I want to continue an existing time series. It's more like a classification/regression problem. The input is really small for such a task and in addition to that, the text is in a really bad spot. Counting of around 6-7 words on average, mainly holding the brand names and occasional some product-specific information like size, or flavor. The trained FastText/Word2Vec embeddings seem kind of alright. Currently, I'm using 3 approaches: Nearest Neighbor: Here I simply take the time series of the nearest neighbor depending on the input features as a forecast for my new product. DemandForest: As first presented here . I cluster the time series for each product and assign the clustered shape to each of them. After that, I train some kind of classifier that predicts the cluster shape based on the input features. In parallel but separately I train a Quantile Regression Forest that predicts the cumulative total demand over the interval. In the end, I multiply the predicted demand with the predicted shape and take the result as a forecast for the new product. The same approach as in 2., but I exchange the separated models with one LSTM-Keras model with two outputs: regression and classification of the shape. I created a custom MAPE loss function that combines the regression and classification of the time series shape and calculates the loss, based on the actual forecast and the true time series. I promised myself that this might lead to an optimization towards better forecasts. The Nearest Neighbor approach is by far the best of all with a mean average percentage error (MAPE) of 47%. The DemandForest by 51% and the custom Keras model by 60%. I thought the last approach should be the best because I'm optimizing towards the goal of a better forecast MAPE, but in the end, taking the nearest neighbor seems by far the best and simplest solution. Approach 3 struggles the most with its three loss functions. Sparse Categorical Crossentropy for the classification, RMSE, and the custom MAPE loss. Since the cluster shape occurrences are super imbalanced the model learns to put all products in one shape category. The results of only optimizing towards the custom MAPE loss are even worse. I am kind of struggling at the moment with how to improve my approaches and how I can get better results. I got some ideas in mind, but I am not quite sure if they make any sense. Is it possible to take the nearest neighbor output as an input for approach 2/3? Like the total demand of the nearest product in historical data. Training a model that learns to shift the time series of the nearest neighbor in the right direction to better fit the actual truth time series? Should I improve the 3rd approach or do you guys think this won't work in any way? Are there any better approaches? Did I miss something during my research? I would appreciate some thoughts, help, and ideas on how you would tackle this project. I'm kind of stuck at the moment on how to proceed. Thanks for your help!
