[site]: crossvalidated
[post_id]: 257581
[parent_id]: 
[tags]: 
Recursive backpropagation vs backpropagation

I recently read a paper that tried to find out what happened in a RNN by linearization around slow and fixed points. I can't figure out why we have to use linearization around these points. After I read another paper about FIXED POINT ANALYSIS FOR RECURRENT NETWORKS, I found out that recursive backpropagation should converge to a stable fixed point in order to backpropagate the error signals. My questions are: What's the main difference between recursive backpropagation and standard backpropagation? Why must RBG converge to a fixed point?
