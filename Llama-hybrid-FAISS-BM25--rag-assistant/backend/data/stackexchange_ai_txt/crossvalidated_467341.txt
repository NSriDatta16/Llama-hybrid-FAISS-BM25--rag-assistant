[site]: crossvalidated
[post_id]: 467341
[parent_id]: 467315
[tags]: 
In the first place, cross validation is a technique to estimate certain aspects of predictive performance of a model. These performance estimates can then be used either as estimate of generalization error xor to select among several "candidate" models (typically corresponding to different hyperparameter sets). Cross validation works by training a number of surrogate models which are assumed to be approximately equal to the model (I'll refer to this as the model ) whose performance we actually want to know. These surrogate models are trained on training data sets that are again approximately equal to the model 's training data: they differ by leaving out a few cases (which are then used as test cases for this surrogate model). For almost all cross validation procedures* the training sets for the surrogate models have substantial overlap in cases (this is desired: they are all assumed to approximate the same model , so they should be similar among themselves). Cross validation can have iterations (aka repetitions), too: in that case, the whole procedure from the splitting on is repeated. Again, we have substantial overlap between training subsets for the surrogate models. In contrast, AFAIK iterations during a training epoch of a neural network use batches of disjoint training cases. * the exception is 2-fold where we get two models trained and tested on mutually independent subsets.
