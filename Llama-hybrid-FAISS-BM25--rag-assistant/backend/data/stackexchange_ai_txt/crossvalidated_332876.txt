[site]: crossvalidated
[post_id]: 332876
[parent_id]: 332839
[tags]: 
Yes, your understanding is correct. In the case of batch or mini-batch back-propagation we really use the "average .... We should use the average gradient. However, you can choose the learning rate and account for averaging. If you use sum, the division term can be subsumed in the learning rate however, learning rate will now be dependent on batch size. This is another practical reason to use the average.
