[site]: datascience
[post_id]: 123790
[parent_id]: 123778
[tags]: 
First of all, there will always be a trade-off between precision_score and recall_score . So you must choose a satisfying recall_score that you can live with. There are few techniques that you might try: Use F-beta Score : F-beta score allows you to give more importance to either precision_score or recall_score depends on beta value. Basic rule for that: If beta is less than 1, this gives more importance to precision (fewer false positives) over recall. If beta is greater than 1, this gives more importance to recall (fewer false negatives) over precision. When beta equals 1, it's equivalent to the F1 score - giving equal weight to both precision and recall. You can choose whichever value of beta that you want based on your results. Ensemble Methods : Another approach is using ensemble methods designed for imbalance problems such as Balanced Random Forests and Easy Ensemble classifier which balance classes internally. To create Balanced Random Forest , you need to install imbalanced-learn . from imblearn.ensemble import BalancedRandomForestClassifier brf = BalancedRandomForestClassifier(n_estimators=100) brf.fit(X_train, y_train) predictions = brf.predict(X_test)
