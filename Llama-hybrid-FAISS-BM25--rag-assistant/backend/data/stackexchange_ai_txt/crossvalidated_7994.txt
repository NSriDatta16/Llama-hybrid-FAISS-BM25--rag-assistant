[site]: crossvalidated
[post_id]: 7994
[parent_id]: 
[tags]: 
Linear discriminant analysis and the "kernel trick"?

This is problem 12.10 in "The Elements of Statistical Learning" : Suppose you wish to carry out a linear discriminant analysis (two classes) using a vector of transformations of the input variables $h(x)$. Since $h(x)$ is high-dimensional, you will use a regularized within-class covariance matrix $W_h + \gamma I$. Show that the model can be estimated using only the inner products $K(x_i, x_{i'}) = \left $. How can I go about showing that regularized linear discriminant analysis can be estimated using only inner products, as in the "kernel trick" that is often used with SVM's?
