[site]: crossvalidated
[post_id]: 219335
[parent_id]: 219332
[tags]: 
To answer your questions directly: Q1: But when I use the scale=T option I'm getting different SD. From the Help, I know that scale=T is used, so that variables should be scaled to have unit variance before the analysis takes place. But does this actually means??? The scale=T argument tells prcomp to perform z-scaling (that is, dividing each value by the standard deviation of all the values). You would get the same result if you performed scaling before calling prcomp. scaledUSArrests Q2: By the way, if I want to calculate SD in usual way, I'm getting different result. The standard deviation that you see there is not the standard deviation from running sd(USArrests$Assault) , etc. Q3. Are these Eigenvalues or some percentage? What should I conclude from this result? Any help or link for further reading will be appreciated. PCA works by projecting your original data set onto new axes called principal components. Because your original data has 4 features (Murder, Assault, UrbanPop, and Rape), there will be 4 new principal components. Think of them as a new coordinate system defined by 4 new axes. In the output, you can seem them labelled as PC1, PC2, PC3, and PC4. In the figure below, you can see how the blue dots are projected onto a new axis by connecting them with the red lines. Once the blue dots are on the new axis, you can compute the variance over them, as seen by the green segment. That variance is, of course, the square of the standard deviation shown in the output above. For example, your first axis is defined by the PC1 vector above, which has the coordinates (-0.535, -0.583, -0.278, -0.543). When your data is projected onto this axis, you can compute a standard deviation of 1.5748783. You can get more information form using the summary() function, as shown below. summary(prcomp(USArrests, scale=T)) # Importance of components: # PC1 PC2 PC3 PC4 # Standard deviation 1.5749 0.9949 0.59713 0.41645 # Proportion of Variance 0.6201 0.2474 0.08914 0.04336 # Cumulative Proportion 0.6201 0.8675 0.95664 1.00000 What this shows is that the first three axes explain 0.95664 (the bottom row) of the variance. That is, if your data is projected onto the first three axes defined by the PC1, PC2, and PC3 vectors, then the variance would be 0.95664 of all the variance. The missing variance is explained by data projected onto the axis of PC4. I know this probably seems really difficult to understand. Here are some great tutorials: http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf http://www.sthda.com/english/wiki/principal-component-analysis-the-basics-you-should-read-r-software-and-data-mining
