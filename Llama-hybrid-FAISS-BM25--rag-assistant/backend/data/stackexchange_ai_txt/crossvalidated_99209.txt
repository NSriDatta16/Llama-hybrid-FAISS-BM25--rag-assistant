[site]: crossvalidated
[post_id]: 99209
[parent_id]: 99206
[tags]: 
Perhaps the best way would be to examine the distribution of the residuals. You get them from lm (it's one of lm's list components). The root mean square error (as Glen_b mentioned) gives you a sense of how far your line is off on average. You could also plot the residuals in a histogram to get a more complete sense of how badly the line fits. Perhaps the most interesting look would be to plot the residuals by the predictor(s) which has(ve) fixed slope to see if there is some trend there. However, your assumption that $R^2$ is useless is incorrect.. See the definition here . $R^2$ is really just a way to understand how much better/worse your line is compared to the worst possible 'best guess' line: the mean of the observations. It's possible for your line to have an $R^2$ that is not in $[0,1]$, since your fixed slope line is not guaranteed to be better than the mean of the observations like a typical regression line would be (e.g., the observations are all on a horizontal line but your fixed slope is nonzero).
