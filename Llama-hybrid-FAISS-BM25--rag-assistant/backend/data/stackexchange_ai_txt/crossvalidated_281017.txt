[site]: crossvalidated
[post_id]: 281017
[parent_id]: 280991
[tags]: 
I think the complaints brought up by the Vanderbilt site are valid ones, but they can't be applied universally without knowledge of the question . They mention specific graphical tests which can be used to assess assumptions about a magnitude of effect. For instance, in HIV rebound patients, administration of antiretroviral therapy (ART) has a demonstrable geometric mean effect. That's because when the virus is more prolific, the PK dynamics are such that the virus interacts at a higher rate with the ART. Issues with interpretation behoove us to think more carefully about our interpretation than to seek in vain an omnibus that permits us to be loose with interpretation. You bring up two separate points: ANCOVA vs paired differences and percent change as the scale of effect. Modeling change as a percentage involves performing a log transform of the outcome, re-exponentiating the coefficients obtained from the linear model, and interpreting them as a percentage change. A paired t-test is a special case of a linear model without log-transform where you actually model an offset: \begin{equation} E[Y_1 | Y_0, X] = \beta_0 + Y_0 + \beta_1 X \end{equation} $\beta_1$ is the intervention effect as a mean difference obtained from a paired t-test, or a univariate t-test based on pairwise differences in $Y_1, Y_0$. Note the term $Y_0$ does not have a coefficient. The ANCOVA is seen as a better model because it is a more flexible parametric model which incorporates a coefficient for the referent/baseline term. \begin{equation} E[Y_1 | Y_0, X] = \beta_0 + \gamma Y_0 + \beta_1 X \end{equation} $\beta_1$ still has the same interpretation: the expected difference in outcome comparing individuals who receive the intervention to those who don't conditional upon baseline/referent value. To model percent change in an ANCOVA design, you apply log transform of the outcome. \begin{equation} E[\log Y_1 | Y_0, X] = \beta_0 + \gamma Y_0 + \beta_1 X \end{equation} And $\exp(\beta_1)$ is interpreted as a percent difference in outcome comparing those who receive intervention to those who don't conditional on their baseline/referent value. The issue of homogeneity which is addressed in the Vanderbilt site is also worth mention. Suppose you are interested in modeling percent change as with our final log transformed ANCOVA model. Suppose further, there is a truncation of treatment effect for a range of values, like with our HIV patients receiving ARTs. If the viral load drops below a threshold the devices cannot detect its presence. In many data analyses, analysts impute the minimum (a pragmatic and inefficient solution). This would, by assumption, violate the predicted trend. However, we can view the model as summarizing those data in spite of those differences, or any other subgroup differences, when we interpret the $\beta_1$ or $\exp \beta_1$ as the Average Causal Effect (or ACE). This is an issue of interpretation that considers the whole population rather than what individual outcomes are, which is often a follow-up question requiring much more extensive design and investigation. The mixed model is a bit confusing since you haven't defined terms. Nonetheless, a mixed approach is the way to go if there are more than one post measurement. Why would you assess more than one post measurement? Measurement error: blood pressure? different every day, viral load? different every day, weight? you get the picture. By design if an outcome can be measured cheaply but has low reliability, an efficient design might specify multiple measurements as a way of reducing intraindividual variability. However, in doing this, we now have correlated measures. Introducing a random intercept further reduces intraindividual variability, and hence the overall variability of the effect estimate, by inducing an exchangeable correlation structure where each repeated measure within an individual has a fixed, constant, positive correlation. This design feature updates ANCOVA to be a "repeated measures ANCOVA". As a note your R notation is wrong. Note in my describing the above design: we incorporate a baseline measure as a covariate in the ANCOVA design or an offset in the paired design. In your reshape dataset, the pre and post measures are taken as exogenous measures which are predicted by G which I presume is the intervention design. Baseline measures are NOT predicted by this value, so that model is wrong. "Repeated measures" in a pre-post design means you have more than one measure of the outcome.
