[site]: crossvalidated
[post_id]: 588027
[parent_id]: 
[tags]: 
Why probit regression is less interpretable than logistic regression?

What I've seen very often, is that people are saying, that logistic and probit regression are giving very similar results, however, logistic regression is more interpretabe. And in this question, I want to understand why. In the logistic regression, interpretability lies on the log of the odds: $$\log\left(\frac{p}{1 - p}\right) = \beta_0 + \sum_{i = 1}^n \beta_iX_i,$$ because if we take the derivative with respect to $j-$ th variable, we exactly obtain the $j-$ th coefficient: $$\frac{\partial\log\left(\frac{p}{1 - p}\right)}{\partial X_j} = \beta_j.$$ Because this happens, people are saying, that increase $X_j$ of one unit, increase the odds (i.e. $\frac{p}{1-p}$ ) of $\exp(\beta_j)$ units. In the probit regression we can come up with the exactly same thing. We have the following relationship: $$p = \Phi\left(\beta_0 + \sum_{i = 1}^n \beta_i X_i\right),$$ where $\Phi$ is the PDF of standard normal distribution. From this equation we have that: $$Q(p) = \beta_0 + \sum_{i = 1}^n \beta_i X_i,$$ where $Q$ is a quantile function of standard normal distribution. Now if we take the derivative : $$\frac{\partial Q(p)}{\partial X_j} = \beta_j$$ So can we say the same? What I would like to say, is that increase $X_j$ by one unit, increases quantile function by one unit, and therefore, increase $X_j$ by one unit, increases $p$ by $\Phi(\beta_j)$ units. If that's true, why people are saying, that probit regression is less interpretable?
