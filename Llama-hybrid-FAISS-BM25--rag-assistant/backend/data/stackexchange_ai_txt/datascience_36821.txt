[site]: datascience
[post_id]: 36821
[parent_id]: 
[tags]: 
How to tinker with CNN architectures?

I was thinking of creating a CNN. Now it is known CNN takes long times to train so it is advisable to stick to known architectures and hyper-parameters. My question is: I want to tinker with the CNN architecture (since it is a specialised task). One approach would be to create a CNN and check on small data-sets, but then I would have no way of knowing whether the Fully Connected layer at the end is over-fitting the data while the convolutional layers do nothing (since large FC layers can easily over-fit data). Cross Validation is a good way to check it, but it might not be satisfactory (since my opinion is that a CNN can be replaced with a Fully Connected NN if the data-set is small enough and there is little variation in the future data-sets). So what are some ways to actually tinker with CNN and get a good estimate for future datasets in a reasonable training time? Am I wrong in my previous assumptions? A detailed answer would be nice!
