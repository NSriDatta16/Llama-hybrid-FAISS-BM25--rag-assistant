[site]: crossvalidated
[post_id]: 323390
[parent_id]: 323269
[tags]: 
An area of research where I believe the Bayesian methods are absolutely necessary is that of optimal design. In the logistic regression setting, a researcher is trying to estimate a coefficient and is actively collecting data, sometimes one data point at a time. The researcher has the ability to choose the input values of $x$. The goal is to maximize the information learned for a given sample size (alternatively, minimize the sample size required to reach some level of certainty). One can show that for a given $\beta$ there is a set of $x$ values that optimize this problem. The catch-22 here is that to choose the optimal $x$'s, you need to know $\beta$. Clearly, you don't know $\beta$ or you wouldn't need to collect data to learn about $\beta$. You could just use the MLE's to select $x$, but This doesn't give you a starting point; for $n = 0$, $\hat \beta$ is undefined Even after taking several samples, the Hauck-Donner effect means that $\hat \beta$ has a positive probability of being undefined (and this is very common for even samples of, say 10, in this problem) Even after the MLE is finite, its likely to be incredibly unstable, thus wasting many samples (i.e if $\beta = 1$ but $\hat \beta = 5$, you will pick values of $x$ that would have been optimal if $\beta = 5$, but it's not, resulting in very suboptimal $x$'s). This doesn't take into account the uncertainty of $\beta$ The (admittedly older) Frequentist literature deals with a lot of these issues in a very ad-hoc manner and offers sub-optimal solutions: "pick regions of $x$ that you think should lead to both 0's and 1's, take samples until the MLE is defined, and then use the MLE to choose $x$". The Bayesian analysis is to start with a prior, find the $x$ that is most informative about $\beta$ given the current knowledge, repeat until the convergence. Given that this is a problem that starts with no data and requires information about $\beta$ to choose $x$, I think it's undeniable that the Bayesian method is necessary; even the Frequentist methods instruct one to use prior information. The Bayesian method just does so in a much more efficient and logically justified manner. Also, it's totally reasonable to analyze the data that comes in a Frequentist method (or ignoring the prior), but it's very hard to argue against using a Bayesian method to choose the next $x$.
