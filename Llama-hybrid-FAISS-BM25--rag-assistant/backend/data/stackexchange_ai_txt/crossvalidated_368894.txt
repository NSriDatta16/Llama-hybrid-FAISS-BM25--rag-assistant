[site]: crossvalidated
[post_id]: 368894
[parent_id]: 
[tags]: 
Is it normal to have higher cross validation score IN EACH ITERATION than testing score

I'm using 10 fold stratified cross validation, training:testing is 0.75:0.25. Balanced data. I'm using cross validation when doing feature selection with the 0.75 training data. The score I'm using is sklearn "average_precision_score", and got values between 0.78 and 0.9 in each iteration . Finally with selected features, I'm using the 0.25 testing data to predict, got average_precision_score around 0.76. I'm wondering is this overfitting or normal. I think each iteration of cross validation has smaller data sample while my testing data has larger size than each CV iteration, therefore this should be normal. But what do you think? NOTE: At this moment, I haven't added param tuning methods. I will do that later. I think param tuning is not relevant yo my question here.
