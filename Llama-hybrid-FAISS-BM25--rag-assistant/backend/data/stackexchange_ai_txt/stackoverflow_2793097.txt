[site]: stackoverflow
[post_id]: 2793097
[parent_id]: 2793069
[tags]: 
A lot of the tree structure can be reused. I don't know the algorithmic complexity offhand, I would guess on average there's only like amortized logN 'waste'... Why not try to write a program to measure? (We'll see if I can get motivated tonight to try it myself.) EDIT Ok, here is something I hacked. I haven't decided if there's any useful data here or not. open System let rng = new Random() let shuffle (array : _[]) = let n = array.Length for x in 1..n do let i = n-x let j = rng.Next(i+1) let tmp = array.[i] array.[i] When I run this in FSI on my box, I get --> Timing now on > 16 Real: 00:00:08.079, CPU: 00:00:08.062, GC gen0: 677, gen1: 30, gen2: 1 > 17 Real: 00:00:17.144, CPU: 00:00:17.218, GC gen0: 1482, gen1: 47, gen2: 4 > 18 Real: 00:00:37.790, CPU: 00:00:38.421, GC gen0: 3400, gen1: 1059, gen2: 17 which suggests the memory may be scaling super-linearly but not too badly. I am presuming that the gen0 collections are roughly a good proxy for the 'waste' of rebalancing the tree. But it is late so I am not sure if I have thought this through well enough. :)
