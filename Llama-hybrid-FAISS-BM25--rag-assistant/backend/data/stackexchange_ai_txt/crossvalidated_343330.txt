[site]: crossvalidated
[post_id]: 343330
[parent_id]: 343328
[tags]: 
David's answer brought up a valid point - you should try using CNNs to exploit the spatial correlations in the images. Further suggestions: High training accuracy and significantly lower test accuracy is a sign of overfitting, so you should try to finetune your model with a validation dataset first. For example, you can split your training examples with a 70-30 split, with 30% validation data. Once you get reasonably good results with the above, then test the model's generalization ability with the test dataset. Since your number of training examples is quite small (and the image size as well), you can try some k-fold stratified or random cross validation. Evenly shuffle and split the training examples into some k number of folds, with each fold having approximately the same distribution of classes. This will let you see your validation accuracy more realistically. Perform early stopping - 1500 epochs seem a bit too excessive for a small dataset. Try a smaller number of epochs and see if your results improve. Try a better initializer than just a uniform one. e.g. try "He initialization" ( https://keras.io/initializers/ ).
