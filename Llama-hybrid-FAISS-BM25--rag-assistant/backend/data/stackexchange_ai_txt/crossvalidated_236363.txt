[site]: crossvalidated
[post_id]: 236363
[parent_id]: 236361
[tags]: 
Gaussian Mixture Models allow assigning a probability to each datapoint of beeing created by one of k gaussian distributions. These are normalized to sum up to one, allowing interpretation as "Which cluster is most probably responsible for this datapoint?" If you do not normalize, you have absolute probabilities which estimate how probable a point is - given a specific gaussian mixture model. Then you can simply define an outlier such as: If p Yet be warned, the expectation maximization algorithm for gaussian mixture models - which you will need to get best parameters for your gaussian mixture model - is not very robust and tends to find suboptimal solution. For reading more - especially unterstanding more - I recommend Bishop: Pattern Recognition and Machine Learning
