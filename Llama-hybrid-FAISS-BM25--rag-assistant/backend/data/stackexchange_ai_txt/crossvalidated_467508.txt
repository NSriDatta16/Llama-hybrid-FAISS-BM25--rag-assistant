[site]: crossvalidated
[post_id]: 467508
[parent_id]: 
[tags]: 
Angle between PCA vector spaces?

I have two datasets of the same shape, one for condition A, the other for condition B. I would like to test if the major axes of variance of condition A are different than those of B. Here is my idea. For each dataset, take as many PCA's as necessary to have a total explained variance of, for example, 90%. Then I will have two vector spaces: $\{\vec{a}_i\}$ and $\{\vec{b}_j\}$ , where each vector is the eigenvector of PCA. Now, the goal would be to calculate the "angle" between the two vector spaces, where small angle would mean that the axes of variance are almost aligned, and large angle would mean that the axes of variance are almost orthogonal. I have tried formulating this as an optimization problem. Find an arbitrary vector in each vector space. $\vec{p}_A(\vec{\alpha}) = \sum_i \alpha_i\vec{a}_i$ , $\vec{p}_B(\vec{\beta}) = \sum_i \beta_i \vec{b}_i$ Impose the constraint that the prefactors are normalized $\sum_i \alpha_i^2 = 1$ , $\sum_i \beta_i^2 = 1$ Define the cosine between the two vectors as their dot product $$\cos_{AB} = \vec{p}_A \cdot \vec{p}_B = \sum_{ij} M_{ij} \alpha_i \beta_j$$ Where $M_{ij} = \vec{a}_i \cdot \vec{b}_j$ Use Lagrange multipliers to search for extrema of $\cos_{AB}$ subject to the normalization constraints. I have found that the solutions to this equation are the eigenvalues of the following matrix $$\cos^2_{AB} = \mathrm{eval}(MM^T)$$ This is as far as I got so far. Questions : Has somebody tried finding angle between PCA vector spaces? If they have done it my way, how to interpret the eigenvalues I have found? Can I convert the eigenvalues to a single number that would tell me how different are the vector spaces? If there already is a canonical method to solve this question, what is it called?
