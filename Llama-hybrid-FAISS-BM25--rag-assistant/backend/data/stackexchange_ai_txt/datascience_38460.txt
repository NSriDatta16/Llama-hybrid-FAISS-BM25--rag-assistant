[site]: datascience
[post_id]: 38460
[parent_id]: 
[tags]: 
Quantifying feature importances using Auto-encoders

I have a set of features(mixture of numerical and categorical), each of size n. I am embedding them into a dense lower dimensionality space using an auto-encoder. I want to know if it is possible to get the feature importances. One vague idea that I can think of this : Assume the Weight matrix for the 1st layer(the layer immediately next to the input layer, of size p) is W(shape : n x p). This is the weight matrix used in the affine transformation dot(W.T, x) + b, x being the input. We can sum over the rows of W and then normalize it to get the feature importances of different features. But again, this is quite ad-hoc. Can someone refer me to some paper where the authors have explored this, or maybe better some implementation of this. Thanks in advance.
