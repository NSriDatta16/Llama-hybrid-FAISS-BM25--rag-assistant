[site]: crossvalidated
[post_id]: 181980
[parent_id]: 
[tags]: 
PLS using a kernel matrix

I would like to use a kernel matrix generated with a custom kernel function to fit a PLS-DA model (I am thinking of caret's PLS-DA at the moment), with only one binary response variable in the Y block. Before beginning, I am centering the kernel matrix on feature space with A few remarks: I see that caret's plsda function relies on the pls package functions mvr and plsr . When fitting a PLS-DA model, the method used to fit the model defaults to kernelpls , which is the version described on algorithm 1 on Dayal, B. S. and MacGregor, J. F. (1997) Improved PLS algorithms. Journal of Chemometrics, 11, 73-85. In this paper, they propose to compute a kernel matrix directly as as part of the algorithm, and they rely directly on X as well during other steps. Therefore, it seems to me that using this method would mean to calculate a kernel matrix again over my kernel matrix. I've seen three different methods in the literature that involve kernels and PLS. The first one is Dayal and MacGregor's kernel algorithm, the second one is K-PLS ( Rosipal, Roman, and Leonard J. Trejo."Kernel partial least squares regression in reproducing kernel hilbert space." The Journal of Machine Learning Research 2 (2002): 97-123. ) and the third one is DK-PLS (direct kernel PLS). My understanding is that K-PLS is just a modification of the NIPALS algorithm (oscorespls fitting method in the pls package) to use a kernel matrix, and therefore I suspect that this might be the one I should be using. DK-PLS seems to use a kernel matrix as input as well. In short, I guess my question can be summarized as: Which method should I use to fit a PLS-DA model for a binary response, with a custom kernel matrix as input data? Any insights would be appreciated!
