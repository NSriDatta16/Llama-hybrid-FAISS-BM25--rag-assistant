[site]: crossvalidated
[post_id]: 420909
[parent_id]: 420219
[tags]: 
In a sequential experimental design, the credible interval can be misleading. (Disclaimer: I am not arguing it is not reasonable - it is perfectly reasonable in Bayesian reasoning and is not misleading in the perspective of Bayesian point of view.) For a simple example, let say we have a machine giving us a random sample $X$ from $N(\theta,1)$ with unknown $\theta$ . Instead of drawing $n$ i.i.d. samples, we draw samples until $\sqrt{n} \bar{X}_n > k$ for a fixed $k$ . That is, the number of samples is a stopping time $N$ defined by $$ N = \inf\left\{n \geq 1 : \sqrt{n}\bar{X}_n > k \right\}. $$ From the law of iterated logarithm, we know $P_{\theta}(N for any $\theta \in \mathbb{R}$ . This type of stopping rule is commonly used in sequential testing/estimations to reduce the number of samples to do inference. Likelihood principle shows that posterior of $\theta$ is not affected by stopping rule and thus for any reasonable smooth prior $\pi(\theta)$ (e.g., $\theta \sim N(0, 10))$ , if we set a large enough $k$ , the posterior of $\theta$ is approximately $N(\bar{X}_N, 1/N)$ and thus the credible interval is approximately given as $$ CI_{bayes} :=\left[\bar{X}_N - \frac{1.96}{\sqrt{N}}, \bar{X}_N + \frac{1.96}{\sqrt{N}}\right]. $$ However, from the definition of $N$ , we know that this credible interval does not contain $0$ if $k$ is large since $$ 0 for $k \gg 0$ . Therefore, the frequentist coverage of $CI_{bayes}$ is zero since $$ \inf_{\theta} P_\theta( \theta \in CI_{bayes} ) = 0, $$ and $0$ is attained when $\theta$ is $0$ . In contrast, the Bayesian coverage is always approximately equal to $0.95$ since $$ \mathbb{P}( \theta \in CI_{bayes} | X_1, \dots, X_N) \approx 0.95. $$ Take home message: If you are interested in having a frequentist guarantee, you should be careful about using Bayesian inference tools which is always valid for Bayesian guarantees but not always for frequentist ones. (I learned this example from Larry's awesome lecture. This note contains many interesting discussion about the subtle difference between frequentist and Bayesian frameworks. http://www.stat.cmu.edu/~larry/=stat705/Lecture14.pdf ) EDIT In Livid's ABC, the tolerance value is too large, so even for the standard setting where we sample a fixed number of observations, it does not gives a correct CR. I am not familiar with ABC but if I only changed the tol value to 0.05, we can have a very skewed CR as following > X = like(theta = 0) > m = mean(X) > print(m) [1] 0.02779672 > as.numeric(hdi(chain[, 1], credMass = 0.95)) [1] -0.01711265 0.14253673 Of course, the chain is not well-stabilized but even if we increase the chain length, we can get similar CR - skewed to positive part. In fact, I think the rejection rule based on mean difference is not well-suited in this setting since with high probability $\sqrt{N}\bar{X}_N$ is close to $k$ if $0 and close to $-k$ if $-k \ll \theta .
