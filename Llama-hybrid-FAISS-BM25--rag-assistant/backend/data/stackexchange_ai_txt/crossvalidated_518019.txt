[site]: crossvalidated
[post_id]: 518019
[parent_id]: 
[tags]: 
Non linear regression on 2D features space using SVR failed

I try to estimate the execution time of some application based on the mCPUs (fraction of physical CPU) used for the run and the overall size of input data that the application is processing. The data set (from executing the application on different CPU resources with different input data) looks like this: mCPUs overall_size [bytes] execution_time [s] 0.5 12 154 123 121.4 2.5 41 420 813 91.8 ... ... ... I am using the SVR algorithm with RBF kernel. Theoretically the algorithm allows to model any function that is a sum of unknown degree polynomials. Practiacally it fails even with 2D features space described above. As I can see in the image below (the grey hyperplane is the best result using SVR with RBF kernel for this data, I have searched a wide range of hyperparameters, it looks linear, but the data is definitely not linear) execution_time is ~ ( mCPUs )^ x and execution_time is ~ ( mCPUs )^ y , where x != y . Is it SVR able to fit a hyperplane that have a different polynomial fit on each feature? I am almost certain that some algorithm based on decision trees like XGBoost can do it better but the task is really simple and i am looking for a simple solution (algorithm). I am looking for any help and suggestions. Cheers! EDIT: Take a look at the full data set: https://github.com/K4liber/statistic_under_AI/blob/main/execution_results/results.csv and the script for model training and validation: https://github.com/K4liber/statistic_under_AI/blob/main/project/models/main.py
