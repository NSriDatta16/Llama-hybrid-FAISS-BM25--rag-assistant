[site]: crossvalidated
[post_id]: 274173
[parent_id]: 
[tags]: 
What level granularity should be used for time series prediction?

Say I have 1,000,000 records of customer sales over the last year, recorded at the millisecond level as mm/dd/yyyy HH:MM:SS.SSS My goal is to predict customer sales for the next 3 months. Is there a best practice for what level of aggregation I should use for the prediction? Should I aggregate my last year to 12 months, or leave it at the millisecond level?
