[site]: datascience
[post_id]: 70347
[parent_id]: 70346
[tags]: 
You are trying to input 60000 training images with size 28 by 28 into a dense neural network. This will work since a dense neural network can only work with one dimensional data, with each input neuron of the network representing a pixel in the image. You therefore have to reshape your data first from (n_samples, height, width) to (n_samples, n_pixels) using numpy.reshape . The following code reshapes both your training and test input features, it keeps the number of samples the same and infers the second dimension from the data. import numpy as np import matplotlib.pyplot as plt from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense from tensorflow.keras.datasets import mnist (X_train, Y_train), (X_test, Y_test) = mnist.load_data() X_train.shape plt.imshow(X_train[0].reshape([28,28]), cmap="gray") plt.axis("off") X_train = X_train / 255 X_test = X_test / 255 # Add these two lines to reshape the data X_train = np.reshape(X_train, (X_train.shape[0], -1)) X_test = np.reshape(X_test, (X_test.shape[0], -1)) from tensorflow.keras.utils import to_categorical num_classes = 10 Y_train_dummy = to_categorical(Y_train, num_classes) Y_test_dummy = to_categorical(Y_test, num_classes) model = Sequential() model.add(Dense(512, activation="relu", input_dim=X_train.shape[1])) model.add(Dense(256, activation="relu")) model.add(Dense(128, activation="relu")) model.add(Dense(num_classes, activation="softmax")) model.compile(loss="categorical_crossentropy", optimizer="sgd", metrics=["accuracy"]) model.fit(X_train, Y_train_dummy, epochs=20) Adding these two lines to your code (before training the model) allows me to train the network and achieve just over 98% accuracy after 10 epochs. For more info on how numpy.reshape works you can take a look at the documentation .
