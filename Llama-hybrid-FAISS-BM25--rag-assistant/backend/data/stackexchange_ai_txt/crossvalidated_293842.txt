[site]: crossvalidated
[post_id]: 293842
[parent_id]: 
[tags]: 
How is empirical Bayes valid?

So I just finished reading a great book Introduction to Empirical Bayes . I thought that the book was great, but building priors from the data felt wrong. I was trained that you come up with an analysis plan then you collect data then you test the hypothesis you previously determined in your analysis plan. When you do an analysis on data that has already collected this puts you into post-selective inference where you have to be much more stringent on what you call "significant", see here . I think that machine learning has something analogous which is called "cherry picking" which means picking predictors before setting up test and training sets ( Introduction to Statistical Learning ). Given what I have previously learned it seems to me that empirical Bayes is based on a weak foundation. Do people use it just in settings where data was generated passively? If so, this may be justifiable, but it does not seem correct to use it when doing rigorous experimental design, yet I know that Brad Efron does use empirical Bayes specifically for Biostatistics, generally a very NHST field. My questions are: How is empirical Bayes valid? In what situations is it used? In what situations should you avoid using the empirical Bayes approach and why? Are people using it in fields other than Biostatistics and if so, in what situations are they using it?
