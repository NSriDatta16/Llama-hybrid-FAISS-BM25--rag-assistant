[site]: crossvalidated
[post_id]: 420517
[parent_id]: 
[tags]: 
Can feature importance be measured in machine learning models by selectively removing predictor variables?

In addition to techniques like measuring permutation importance, could feature importance be estimated by sequentially removing predictor variables from the training data, rerunning the model, and then comparing the prediction error on the validation data to the full model?
