[site]: crossvalidated
[post_id]: 535418
[parent_id]: 535402
[tags]: 
You should search for the best params using pmdarima or you can just grid search with statsmodels and minimize AIC or whatever cost you deem appropriate. Assuming you did that already and that's how you got those orders or just in general it is entirely possible that your validation data is just different. Perhaps there is a level change which causes the issue and there is NO way a model would be able to perceive this. Or there may be an exogenous factor that you can account for. Either way, if you just adjust your current parameters to something that is a less 'likely' given your training data but doesn't underforecast then you are just overfitting the validation set by using future knowledge. You could mitigate this by using time series cross validation with a rolling train/validation set but in my 'experience' your best bet is to use AIC/AICc for params in ARIMA models since I have seen arima models go crazy from overfitting on a simple holdout set. Another possible issue is that you wanted to produce n number of one-step-ahead forecasts but you accidentally produced a n-step forecast. That would put it on the right level overall. Statsmodels api is confusing.
