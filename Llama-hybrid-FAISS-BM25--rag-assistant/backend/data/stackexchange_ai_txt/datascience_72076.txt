[site]: datascience
[post_id]: 72076
[parent_id]: 
[tags]: 
Ngram based Langauge Models learned using an Encoder-Decoder Model

I have been going through a Ngram based Langauge Model learned using an Encoder-Decoder Model for Email smart compose. The program output only 1 prediction for given input. I want to know how to get multiple predictions out of the same. Here is the link to the notebook: https://nbviewer.jupyter.org/github/PrithivirajDamodaran/NLP-Experiments/blob/master/Gmail_style_smart_compose_with_char_ngram_based_language_model.ipynb Here, for input sequence : "hi there" the predicted sequence is: ", how are you today?" But it maybe possible that I have multiple sentences starting with "hi there" in my training dataset. So how do I get all of those?
