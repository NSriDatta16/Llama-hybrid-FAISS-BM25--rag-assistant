[site]: stackoverflow
[post_id]: 1336123
[parent_id]: 1334813
[tags]: 
This is pretty standard data-warehousing stuff. Lots of "facts", organized by a number of dimensions, one of which is time. Lots of aggregation. In many cases, simple flat files that you process with simple aggregation algorithms based on defaultdict will work wonders -- fast and simple. Look at Efficiently storing 7.300.000.000 rows Database choice for large data volume?
