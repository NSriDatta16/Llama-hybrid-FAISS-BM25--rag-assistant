[site]: crossvalidated
[post_id]: 77975
[parent_id]: 7935
[tags]: 
LASSO encourages shrinking of coefficients to 0, i.e. dropping those variates from your model. On contrast, other regularization techniques like a ridge tend to keep all variates. So I'd recommend to think about whether this dropping makes sense for your data. E.g. consider setting up a clinical diagnostic test either on gene microarray data or on vibrational spectroscopic data. You'd expect some genes to carry relevant information, but lots of other genes are just noise wrt. your application. Dropping those variates is a perfectly sensible idea. By contrast, vibrational spectroscopic data sets (while usually having similar dimensions compared to microarray data) tend to have the relevant information "smeared" over large parts of the spectrum (correlation). In this situation, asking the regularization to drop variates is not a particularly sensible approach. The more so, as other regularization techniques like PLS are more adapted to this type of data. The Elements of Statistical Learning gives a good discussion of the LASSO, and contrasts it to other regularization techniques.
