[site]: crossvalidated
[post_id]: 503430
[parent_id]: 502349
[tags]: 
For matching problems, there are mainly two approaches: Single network to embed object A and object B: In natural language processing, the input would be "[CLS] SentenceA [SEP] SentenceB [SEP]". Then the neural network would measure the difference between the two sentences. In computer vision, you would need to concatenate the two images (as you do not have a sequence). Siamese network: It is still a single network, but you would first run "object A" through the network and then "object B" through the same network. The result is two vectors of size batch_size x n. The second approach is a bit more complicated because you have to turn the outputs "object A" and "object B" into a single number. However, this approach is also more common in computer vision. As you have two vectors of size n, you can compute the scalar product between both objects to obtain a single value. The scalar product can be interpreted as cosine similarity. Normalizing the two vectors is maybe not necessary in deep learning. The next step is to define a loss function $L(a^Tb, y)$ between objects $a^Tb$ and the ground truth $y$ . Note that a batch should not only consist of positive examples. So you have to sample negative examples for each positive example (noise contrastive estimation). See this question . I described the general approach, but what works best depends on the dataset. For example, instead of using the scalar product, you could also try the mean squared error. Besides the papers, I mentioned in the comments, you can also look at contrastive losses .
