[site]: crossvalidated
[post_id]: 225228
[parent_id]: 224904
[tags]: 
Is there a best practice that I am not aware of? There is at least a standard practice that you seem not be aware of: $k$-fold cross validation results (if used for validation as opposed for training purposes, see below) are used as an approximation to measuring the generalization error of the one model fit using the whole data as training set. So that one model is the one you use for predicting new cases. You may want to read up on the fundamentals of model validation, and how cross validation fits into that framework. I believe I am not allowed to assume that the distributions of the classifier output variable on, for example, signal, is the same among the k test samples of the k folds. In the case of a model fully trained to output the labels you'd be wrong. However, you seem to be talking here about some intermediate scores, on which further calculations (thresholding) are done. For such intermediate scores, it depends on the particular algorithm you use to produce them whether they will/should already be calibrated to some numerical (?) range with interpretable meaning or not. It may help to think whether there are (and which) changes to these internals of the model to which prediction is invariant (such as the flipping/mirror invariance of PCA) I then apply a cut on the classifier output variable in my labelled data. Because the data is labelled, I can measure the background and signal efficiency of that cut. I am applying the same cut on all data points, no matter which classifier was used to determine the classifier output. This of course is not optimal unless the output distributions of the k classifiers are similar. This means that you are using your cross validation as part of the model training process: to determine the optimal cut point. In that case, a) you need to do an independent validation of the model you get by this optimization process (e.g. by nested cross validation), and b) I'd put it the other way round: in order for your approach of for finding the threshold to work, you need to use a classifier that produces calibrated intermediate output.
