[site]: crossvalidated
[post_id]: 459341
[parent_id]: 290716
[tags]: 
as far as I see, the train and test set remain independent You're right that information from the test set wouldn't be leaking into the training set, but it could be leaking into the model at test time. In case of a standard scaler, it would probably hardly matter for the performance of the resulting model. Transformers that are fit to a dataset contain information about that dataset. So if you fit a transformer (such as StandardScaler ) to the test set, then information from the test data (mean and standard deviation in this case) has leaked into that transformer. This information leakage may cause your model to overfit the test set.
