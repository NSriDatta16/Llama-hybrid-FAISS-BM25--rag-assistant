[site]: crossvalidated
[post_id]: 559911
[parent_id]: 559907
[tags]: 
A binomial distribution with probability of success $p$ and number of trials $n$ has expectation $\mu = np$ and variance $\sigma^2 = np(1-p)$ . One can derive these facts easily , or look them up in a standard reference. Given the mean $\mu$ and the variance ${\sigma}^2$ , we can write $$\begin{align} p &= 1 - \sigma^2 / \mu \\ &= 1 - \frac{np(1-p)}{np} \\ &= 1 - (1 -p)\\ &= p \end{align}$$ The code uses the estimate $\hat{p}$ and the estimated expectation to estimate $\hat{n}=\mu / \hat{p}$ (rounding to the nearest integer). The code uses a method-of-moments estimator for $p,n$ , because it assumes that the sample moments (mean, expectation) equal the moments of the true distribution. The MME isn't the only one available; see also: Homework: Bayesian Data Analysis: Priors on both binomial parameters Estimating parameters for a binomial in particular the discussion to this answer which describes the deficiencies of the technique used in your code.
