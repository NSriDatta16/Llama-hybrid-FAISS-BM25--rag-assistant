[site]: crossvalidated
[post_id]: 379428
[parent_id]: 379423
[tags]: 
Case 1: the null hypothesis is true. The type II error is 0. The type I error is less than the nominal size of the test unless the test is biased. It can be as high as 1 if the test decision is "reject the null every time". Case 2: the null hypothesis is false. The type I error is 0. the type II error can be as high as 1 if the test decision is "do not reject the null any time". To conflate Bayesian and frequentist terminology : you can't speak of the Pr(Type 1 error) without "conditioning" or knowing H_0 is true. A nice bit of frequentist notation is this: $P_{H_0}(\text{Event})$ to refer to probabilities of events or outcomes under the probability model where the null is true, or $P_{\theta = \theta_0}(\text{Event})$ equivalently. If you want to be crazy and sum together probabilities that don't make sense, you can conceive of two values of $\theta \ne \theta_0$ and $\theta=\theta_0$ for which the Type 1 and Type 2 errors add to more than 1. For instance: P(decomposing corpse | dead) + P(looking alright | alive) > 1 Is this surprising or interesting? No. IRL one of those error probabilities will always be 0 and the other is less than or equal to 1 depending on how good or stupid the test is.
