[site]: crossvalidated
[post_id]: 371859
[parent_id]: 371836
[tags]: 
In one sense, the answer is tautologically "no". This is because the point of supervised methods is to have optimal predictions, so they are all an attempt to minimize a predictive loss function. However, not all methods are using optimization routines (i.e., L-BFGS, gradient descent, etc.) to achieve this. The most striking example is Bayesian methods, in which integration, rather than optimization, is used to make inference. Other examples are anything in which the solution is in closed form; linear regression and random forests are two such examples.
