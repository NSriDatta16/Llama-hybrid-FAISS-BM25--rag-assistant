[site]: crossvalidated
[post_id]: 115378
[parent_id]: 115375
[tags]: 
Decision trees are notoriously unstable : small perturbations in the training data can produce dramatically different trees, even though these trees can, and often do, perform about the same on held-out data. Decision trees are particularly prone to this because they make a series of sequential decisions and the decisions are discrete. If you just want to classify your data, this isn't really an issue. Cross-validation is telling you that your approach (training a decision tree) works with your data. Assuming the performance is acceptably high, I'd fit a final tree with all of the data and deploy it. It is worth noting that this instability can actually be turned to your advantage. Model-averaging or ensemble methods fit a collection of decision trees, using subsets of the data/features each time. The results of these trees are then combined and used to make predictions. This is the idea behind bagging and random forests. On the other hand, if you need to examine the structure of your decision tree, there have been a couple of attempts at creating more stable decision trees, like this and this paper
