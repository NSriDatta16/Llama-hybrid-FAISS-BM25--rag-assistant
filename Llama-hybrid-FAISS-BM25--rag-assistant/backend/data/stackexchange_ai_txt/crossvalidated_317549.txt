[site]: crossvalidated
[post_id]: 317549
[parent_id]: 32400
[tags]: 
Just some extension to Dikran Marsupial's comment (cross-validation). The main idea is to split your data into training and validation sets in some way, try different number of components and select the best based on the corresponding training and validation likelihood values. The likelihood for GMM is just $p(x|\pi,\mu,\Sigma)=\sum_K\pi_kN(x|\mu_k,\Sigma_k)$ by definition, where $K$ is the number of components (clusters) and $\pi$,$\mu$,$\Sigma$ are model parameters. By changing the value of $K$ you can plot the GMM likelihood for training and validation sets like the following. In this example it should be obvious that the optimal number of components is around 20. There's nice video about this on Coursera, and it's where I got the above picture from. Another commonly used the method is the Bayesian information criterion (BIC) : $$BIC = -2\log(L)+K\log(n)$$ where $L$ is the likelihood, K the number of parameters and $n$ the number of data points. It can be understood as adding a penalty for the number of parameters to the log likelihood.
