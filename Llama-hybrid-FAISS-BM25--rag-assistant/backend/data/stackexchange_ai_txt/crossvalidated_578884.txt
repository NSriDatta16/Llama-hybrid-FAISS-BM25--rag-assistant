[site]: crossvalidated
[post_id]: 578884
[parent_id]: 
[tags]: 
Outlier/Anomaly Detection Algorithm Options

I am trying to determine the best algorithm/approach to monitor an application at my company. The simple overview is that when our customers call in to report an issue, we run automated diagnostics to help isolate the issue. The automation returns a number of different codes back to represent the results. IE, a 1 may be a "No Issue Detected", a 2 may be "Server has high CPU", and so on. There are 50 or so different ones, but only 5-10 that have much volume. What I am trying to do is use anomaly detection to monitor this automation. Sometimes the automation continues to work, but some of the sub-components of the tests start to fail and is not noticed in a timely manor. The volume of total tests are dependent on the number of troubles reported by the customer. It is generally fairly predictable, but events like major weather events etc cause spikes. There is also a seasonal component. I have about 500 days of data, though due to improvements in the automation, etc, all of it is probably not very useful. I create a time series by day of each results total volume. So, Day 1 - 50, Day 2- 40, Day 3-37, etc etc and train the model. I have tried using Isolation Forest and Prophet, but both have issues. One primary issue is that for low volume results, the range of of values allows for negatives. Even when I use the floor/cap in prophet. And even that has other problems, as I know the floor(zero), but the cap is not as easily determined. In my scenario the lowest possible value is obviously zero. So, if one of the result codes ends up being zero on one day, that could trigger as an anomaly, but since it generally has between 10-20, that ends up within the y_hat_lower range(in prophet). And usually that value even dips into negative ranges. I tried converting each result code to a percentage of the total volume, and I still get this issue. Basically, negative values should not be allowed in this scenario. Because they are not possible. You would think a model that is trained on 400 days of data with the lowest value being zero and the majority being above zero would pick up on that. I'm trying to determine if a different model(SVM/LOF/ARIMA) would suit my dataset better. I get why and how these ranges are generated on forecasted type data. It makes sense, if there is a downward trend on something that has low volume it would generally assume the value would go negative, but at the same type, there has to be models that understands that zero is an absolute low as well. Any suggested reading, etc. would be greatly appreciated.
