[site]: datascience
[post_id]: 23029
[parent_id]: 
[tags]: 
Why are RNN/LSTM preferred in time series analysis and not other NN?

I had recently a great discussion about the advantages of RNN/LSTM in time series analysis in comparison to other Neural Networks like MLP or CNN. The other side said, that: The NN just have to be deep enough to model the time connections RNNs are just used, because they are faster With RNN the older (e.g. t-20) timepoints are not that relevant in comparison to the newer timepoints (e.g. t-1), because the data from older timepoints have to go through all neurons until the weight is updated in this neuron. It is easier to understand the weight matrix of normal NN in comparison to RNN to understand partly the behavior of the NN My answer to that was: Everyone suggests using the LSTMs for times series analysis It can consider the time better in comparison to a sliding window approach especially if the length of the sequence is quite long To 3. That happens just if you use vanilla RNN instead of LSTM, because of the gradient explosion So I know that I did not answer him completely (and maybe not correctly) and I am now really interested in the real reasons why LSTMS are suggested the most of the times. Maybe he is right? What do you think? Can a normal NN model the time connections the same way like a RNN/LSTM does when it is just deep enough? Does an RNN need more or less data in comparison to a NN to get the same/ better results? Are there time series where normal NN or RNN/LSTM perform better? Is it time data depended which Model will perform the best or are there some guidelines? Can the NN behavior be understood better than the RNN behavior?
