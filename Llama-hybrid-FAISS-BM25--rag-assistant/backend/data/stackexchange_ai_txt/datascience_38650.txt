[site]: datascience
[post_id]: 38650
[parent_id]: 20474
[tags]: 
The answer is Data Fusion or Feature Fusion. I am implementing one using neural networks to classify Human Activity using multiple kinds of sensors: accelerometer, binary sensors, ecc.. We train a neural network with multiple input layers: one for each data source. The forward pass keeps these separate until deeper in the network, at which point we concatenate the feature representations and then proceed with a single, merged processing pipeline in the network which ends at a single classification layer. We can think of it as each independent pipeline learn a feature representation of its data source that can then be usefully combined with the other representations to perform classification. This maintains independence of each network branch (e.g. you could have an LSTM processing sequential data, whose latent state vector then is concatenated with a FC feature from a CNN processing pressure plate measurements as images, and so on).
