[site]: crossvalidated
[post_id]: 138370
[parent_id]: 33083
[tags]: 
One way to handle this situation is to rescale the inputs so that their variances are on roughly the same scale. This advice is generally given for regression modeling, but it really applies to all modeling situations that involve variables measured on different scales. This is because the variance of a binary variable is often quite different from the variance of a continuous variable. Gelman and Hill (2006) recommend rescaling continuous inputs by two standard deviations to obtain parity with (un-scaled) binary inputs. This recommendation is also reflected in a paper and blog post . A more specific recommendation for neural networks is to use "effect coding" for binary inputs (that is, -1 and 1) instead of "dummy coding" (0 and 1), and to take the additional step of centering continuous variables. These recommendations come from an extensive FAQ by Warren Sarle, in particular the sections "Why not code binary inputs as 0 and 1?" and "Should I standardize the input variables?" The gist, though, is the same: The contribution of an input will depend heavily on its variability relative to other inputs. As for unordered categorical variables -- you must break them out into binary indicators. They simply are not meaningful otherwise.
