[site]: crossvalidated
[post_id]: 18118
[parent_id]: 18116
[tags]: 
My view is that the models used in economics and the other social sciences are useful only insofar as they have predictive power in the real world - a model which doesn't predict the real world is just some clever math. A favorite saying of mine to colleagues is that "data is king". It seems to me that your question raises two critiques of a predictive approach. First, you point out that the models produced by machine learning techniques may not be interpretable . Second, you suggest that the methods used by those in the social sciences are more useful for uncovering causal relationships than machine learning. To address the first point, I'd offer the following counter argument. The present fad in machine learning favours methods (like SVMs and NN) which are not at all easy for a layperson to understand. This does not mean that all machine learning techniques have this property. For example, the venerable C4.5 decision tree is still widely used 20 years after reaching the final stage of its development, and produces as output a number of classification rules. I would argue that such rules lend themselves better to interpretation than do concepts like the log odds ratio, but that's a subjective claim. In any case, such models are interpretable. In addressing the second point, I will concede that if you train a machine learning model in one environment, and test it in another, it will likely fail, however, there is no reason to suppose a priori that this is not also true of a more conventional model: if you build your model under one set of assumptions, and then evaluate it under another, you'll get bad results. To co-opt a phrase from computer programming: "garbage in, garbage out" applies equally well to both machine learning and designed models.
