[site]: crossvalidated
[post_id]: 135957
[parent_id]: 58050
[tags]: 
Take a look at paper of Brennan (1992) on Generalizability Theory or his book, also titled "Generalizability Theory" (2010, Springer). Brennan writes about GT using ANOVA, but mixed models could be used the same way - and many would consider them as a more recent method. You could think of a mixed model for cross-classified data (e.g. Raudenbush, 1993 ). Say you have $N$ patients measured by $R$ researchers, and your measurement is denoted as $X_{ij}$ for $i = 1,...,N$ and $j = 1,...,R$. In this case, the measurement has both effects of patients and researchers, with patients "nested" in researchers (multiple measures for a single patient) and researchers "nested" in patients (multiple measurements for each patient), so $$ X_{ij} = \beta_0 + b_i + b_j + \varepsilon_{ij} $$ where $\beta_0$ is an fixed intercept (if the data is not centered), $b_i$ is patient random effect (random intercept) and $b_j$ is a researcher random effect, while $\varepsilon_{ij}$ is an error term. In lme4 this would be x ~ (1|patient) + (1|researcher) you could extend this approach to using $X$ as an independent variable or define a hierarchical Bayesian model where you include both sources of variability.
