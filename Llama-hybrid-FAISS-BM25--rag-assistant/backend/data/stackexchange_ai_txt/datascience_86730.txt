[site]: datascience
[post_id]: 86730
[parent_id]: 86727
[tags]: 
Rather than oscillations, it looks like white noise, like a random walk. In other words, as you said, your model is not learning anything. Unfortunately it's impossible to say what's wrong, since we can't see any code. We need more information about dataset, how you processed it, model implementation, all the hyperparams you chose, what other versions you tried before that one, ... the list is countless. But most importantly it's really hard to help you without code. If the dataset is a good one the problem must be some error you made along the way. EDIT: Here's what I think: You don't need Conv layers followed by RNN layers. This doesn't really make sense. Let the LSTM receive raw input. Don't use Dropout with RNNs, they don't go along very well together. Dropout makes sense with Dense and Conv data, but in RNNs, where sequence is everythin, they can actually make things worse. Somebody uses recurrent dropout as an alternative but it's not necessary. Don't use return_sequences=True between an LSTM and a Dense layer. That must be used between LSTM's only. That Lambda layer at the end is probably causing most of the error. If you multiply all your predictions by 1000, what you get is by definition a prediction that on a completely different scale than your target value. The Network overall is too deep and has too many parameters. I assume you are working with the famous Beijing air quality dataset. In this case, It is enought to work with one LSTM layer, followed by a Dense node to make the prediction. Everything else is overkill and not necessary for a simple dataset like that. Something much more simple, like: model = tf.keras.models.Sequential([ tf.keras.layers.LSTM(24, input_shape=(seq_len, n_vars)), tf.keras.layers.Dense(1), ]) has higher chance to work. (Please specify the input shape correctly). Try playing with its hyperparameters, after you made sure all variables are properly scaled between train and test data. Good luck!
