[site]: crossvalidated
[post_id]: 342985
[parent_id]: 
[tags]: 
Corrupted inputs, better accuracy?

I am training a neural network for audio classification using the UrbanSound8K dataset. I want to study how different intrusions in the inputs affect the network predictability. One such intrusion is to add noise to the input audio files. I was surprised to see that, for certain classes, the accuracy prediction heavily increased when adding noise to the test set. By taking a look at the confusion matrices when evaluating the test data, we can get a better picture of the problem. I was expecting a decrease in accuracy for all classes. However, two cases are a clear case of improved classification accuracy: Air conditioner and Jackhammer. My main questions are: Could this result make sense under any circumstance? Are corruptions of the inputs always supossed to decrease test accuracy? I could maybe figure out an explanation for this, but I am afraid that my vision is biased by my wishes of getting reasonable results. Looking at the first class that I mentioned (Air conditioner) for instance. I would say that, In the 7800-dimensional space of my inputs (they are images of size = 60x130 , single channel), the hyperplane separating the classes air conditioner and engine idling has troubles to differenciate between them because they are pretty close to each other. However, it happens that, when adding noise, this intrusion pushes the air conditioner samples closer to the subspace (forgive my most likely innacurate mathematical terminology) of air conditioner samples, which are characterized by having a noisy nature (engine sounds are also kind of noisy, but it could be that this particular noise is more simmilar to the air conditioner sound)
