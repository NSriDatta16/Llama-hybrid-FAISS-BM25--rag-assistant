[site]: crossvalidated
[post_id]: 616083
[parent_id]: 
[tags]: 
Attention is All You Need: How to calculate params number of the models?

I want to re-calculate the last column of Table 3 of Attention is All You Need , i.e. number of params in the models. But numbers from my calculation do not match. Model Params from Table 3 ( $\times 10^6$ ) My Calculation base 65 63014912 B (1) 58 55937024 B (2) 60 58296320 big 213 214110208 My calculations are as following: Number of parameters in each multi-head attention layer: $$ N_{att} = N(W^O) + (N(W_i^Q) + N(W_i^K) + N(W_i^V)) \times h $$ $$ = h \times d_v \times d_{model} + (d_{model} \times d_k + d_{model} \times d_k + d_{model} \times d_v) \times h $$ where $N(.)$ is the size (number of elements) of a matrix. Number of parameters in each Feed Forward Network: $$ N_{FFN} = 2 \times d_{model} \times d_{ff} + d_{model} + d_{ff} $$ Therefore, the total number of parameters is: $$ 2 N \times N_{FFN} + (N + 2 N) N_{att} + N_{voc} \times n_{model} $$ where $N_{voc}$ (the size of the vocabulary) is $37000$ according to section 5.1. Substituting all numbers in Table 3 into the above formula, we get $63014912$ for base model. If let $N_{voc}$ be $40000$ , then the numbers for base , (A) ~ (E) models seem to be matched with those in the table, but $217182208$ is got for big model, while $213M$ is given in the table.
