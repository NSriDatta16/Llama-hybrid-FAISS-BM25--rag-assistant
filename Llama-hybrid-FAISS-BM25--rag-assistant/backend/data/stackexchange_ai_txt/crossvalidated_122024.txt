[site]: crossvalidated
[post_id]: 122024
[parent_id]: 118473
[tags]: 
Merging in most cases is not a good option. Multilevel model is better idea. Of course, not a classical generalized linear mixed model, because you have not enough observations for "random" effect, but Bayesian hierarchical model would be probably fine - at least based on what I understand from your description. You probably choose to have two independent raters for a reason, so there's no point to "drop" one rater by merging the data. It would be different if they gave 100% similar answers, than it probably wouldn't make sense, but I can imagine it is not the case. If not, then the information on when your raters vary on opinion could also be interesting and it would be good to include it in the model. Think of it - as you did - as multilevel model: group level average (or mode, or some other value) tells you about how do raters as a group rate your patients, so it does not tell you about individual raters ratings. Even if in most cases the ratings are the same: isn't interesting when they are not the same? Also choosing the criteria for "merging" raters would be subjective: why at least one "yes" and not at least one "no"?
