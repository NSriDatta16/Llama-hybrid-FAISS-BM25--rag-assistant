[site]: datascience
[post_id]: 61024
[parent_id]: 
[tags]: 
What is auxiliary loss in Character-level Transformer model?

I am reading Character-Level Language Modeling with Deeper Self-Attention from Rami Al-Rfou. In the second page, they had mentioned about Auxiliary Losses which can speed-up the model convergence and as an additional regularizer. They said they had 3 kinds of auxiliary losses: Auxiliary losses at intermediate sequence positions Auxiliary losses from intermediate hidden representations Auxiliary losses at target positions multiple steps. However, I cannot find any information or reference explaining auxiliary losses. I would like to know: What is auxiliary losses? Is it an unsupervised prediction model using part of the data ? How can I calculate the auxiliary losses?
