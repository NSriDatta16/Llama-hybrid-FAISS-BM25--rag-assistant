[site]: datascience
[post_id]: 64027
[parent_id]: 
[tags]: 
Logistic regression, where is my mistake

I am doing assigment on Logistic Regression on Andrew Ng DL course, and can't understand where is my mistake, # FORWARD PROPAGATION (FROM X TO COST) ### START CODE HERE ### (≈ 2 lines of code) A = sigmoid(np.dot(w.T,X) + b) # compute activation cost = -1/m * np.sum(np.dot(np.log(A), Y.T) + np.dot(np.log(1-A), (1-Y.T))) # compute cost ### END CODE HERE ### # BACKWARD PROPAGATION (TO FIND GRAD) ### START CODE HERE ### (≈ 2 lines of code) dw = 1 / m *(np.dot(X,(A - Y).T)) db = 1 / m *(np.sum(A - Y)) ### END CODE HERE ### assert(dw.shape == w.shape) assert(db.dtype == float) cost = np.squeeze(cost) assert(cost.shape == ()) grads = {"dw": dw, "db": db} return grads, cost w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]]) grads, cost = propagate(w, b, X, Y) print ("dw = " + str(grads["dw"])) print ("db = " + str(grads["db"])) print ("cost = " + str(cost)) Giving this error ValueError: shapes (2,) and (3,1) not aligned: 2 (dim 0) != 3 (dim 0) Please help Thanks a lot
