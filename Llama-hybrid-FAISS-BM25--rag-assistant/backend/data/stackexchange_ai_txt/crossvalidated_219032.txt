[site]: crossvalidated
[post_id]: 219032
[parent_id]: 215179
[tags]: 
From my understanding of that probability, it is asking that given that you are in state $j$ at time $n$ ($X_n = j$), what is the probability that you will be in state $j$ at time $n+i$ ($X_{n+i} = j$) given that you do not go through state $j$ at any time in between. If we were to have the probability: $P(X_{n+i} = j | X_{n+i-1} = x_{n+i-1}, ... , X_n = x_n $), then due to the Markov Property we would have the above equation equalizing to $P(X_{n+i} = j | X_{n+i-1} = x_{n+i-1})$. But because of the fact that we are focusing on an initial start point at time $n$ and other conditions in between, you are certainly right in the sense that we have to multiply the probabilities. But the equation you have mentioned is also correct and that is because there may be many different ways to from state $j$ at time $n$ to state $j$ at time $n+i$ while not going through state $j$ while you are in time $n+1$ to time $n+i-1$. The best way to describe what I mean is through the Markov Chain below. Say you want to calculate the probability $P(X_2 = G | X_0 = A)$, then from the diagram you see that there several ways 4 different transitions that match that probability: ATG AGG ACG AAG (where ATG means $P(X_2 = G | X_1 = T, X_0 = A)$, which can also be calculated by multiplying the transition probabilities $0.2*0.05 = 0.01$). Adding all 4 probabilities gives you the answer to $P(X_2 = G | X_0 = A)$, and if you apply the same logic to your original question you will come to the same answer. Hope that helped!
