[site]: crossvalidated
[post_id]: 440995
[parent_id]: 440993
[tags]: 
We know that $$ P(A,B)=P(A|B)P(B) $$ and this remains true when conditional on $C$ : $$ P(A,B|C)=P(A|B,C)P(B|C). $$ You'll notice that the $C$ conditioning seems to be "along for the ride." In Bayesian analysis, one typically replaces $C$ with $I$ , indicating prior information. So, $$ P(A,B|I)=P(A|B,I)P(B|I). $$ which can get cumbersome, but it underscores the central point that every interpretation of probability is conditional on what we -- most often tacitly, but occasionally explicitly -- affirm to be true. If you want to "remove a conditional," you may use the definition of conditional probability to restate the problem as a joint probability and a marginal: $P(A|C)=P(A,C)/P(C).$ Where from there depends on what you are trying to do.
