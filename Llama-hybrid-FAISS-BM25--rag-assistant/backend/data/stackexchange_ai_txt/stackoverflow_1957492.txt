[site]: stackoverflow
[post_id]: 1957492
[parent_id]: 1957390
[tags]: 
5 million records it's about 81MB - acceptable to work with array in memory. As you described problem - it's more unique keys than hash values. Try to use hash table for accessing values (look at this link ). If there is my misunderstand and this is real hash - try to build second hash level above this. Hash table can be successfuly organized on disk too (e.g. as separate file). Addition Solution with good search performance and little overhead is: Define hash function, which produces integer values from keys. Sort records in file according to values, produced by this function Store file offsets where each hash value starts To locate value: 4.1. compute it's hash with function 4.2. lookup for offset in file 4.3. read records from file starting from this position until key found or offset of next key not reached or End-Of-File. There are some additional things which must be pointed out: Hash function must be fast to be effective Hash function must produce linear distributed values or near that Table of hash value offsets can be placed in separated file Table of hash value offsets can be produced dynamically with sequential read of whole sorted file at start of application and stored in memory at step 4.3. records must be readed by blocks, not one-by-one, to be effective. Ideally reads all values with computed hash to memory at once. You can find some examples of hash functions here .
