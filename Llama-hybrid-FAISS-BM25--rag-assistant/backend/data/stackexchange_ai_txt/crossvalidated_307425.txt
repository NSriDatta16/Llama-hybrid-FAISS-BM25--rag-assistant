[site]: crossvalidated
[post_id]: 307425
[parent_id]: 
[tags]: 
Adding features to xgboost worsening results

I was using xgboost for binary classification task and notices that adding new features to model worsening results. As I understand xgboost itself can do implicit 'feature selection' because it tend to use more usefull features (can be seen by feature importance after model trained) and can handle feature correlation (does it really?). So my questions is why performance is degrades when I add more features to model and what are common tips & tricks to prevent such behaviour?
