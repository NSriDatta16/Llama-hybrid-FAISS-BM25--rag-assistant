[site]: crossvalidated
[post_id]: 159670
[parent_id]: 
[tags]: 
Poisson vs. Gaussian in Geomagnetic Data

I've been studying geomagnetic signals using a threshold approach to detect pulse events in the data. The question here is what is the significance of the crossover of stddev and mean as the threshold is loosened? Samples are taken at a low rate (30-50 S/sec), and since we are counting events, the mean rate of events is never negative. Here is a typical result: The mean, median, and stddev are computed using Matlab's routines, mean(), median(), and std(), respectively. The Y-axis shows the pulse rate in a 24 hour period, while the X-axis shows the amount by which the threshold is increased. In particular, I am counting the number of times the time series amplitude increases beyond a threshold for more that 1/8 of a second. And to be clear, the time-series is zero-centered, so I am counting BOTH the negative and positive excursions. (Some are symmetric and some are not, which is a whole 'nuther topic). So here is the question. Why does the stddev start out less than the mean, but then exceed it as the threshold increases? My thought would be that with tighter thresholds we are closer to measuring simply noise, ie. Gaussian, but as we loosen the threshold (signal has high a dynamic range) we become more of a Poisson process. Is this shown by having a stddev > mean for these types of counting problems?
