[site]: datascience
[post_id]: 96494
[parent_id]: 96452
[tags]: 
A baseline model is a na誰ve way of predicting. People who do this kind of work sometimes have a company pay them to do so. Justify your salary to the company by achieving better performance than they could get without much work. EXAMPLE : If you want to predict the expected stock price tomorrow, na誰vely guess today's price. You don't need a fancy data science team to do that. If the data science team cannot do better than that baseline model, their models are worse than the na誰ve, easy model that requires almost no work. Would you pay thousands or millions of dollars to a team that cannot even achieve the performance you can get out of the stock app on your phone? When you calculate $R^2$ for a linear regression, you are comparing your model to a baseline model that always guesses the mean of the observed $y$ values. The $SSRes$ is the numerator measures how much error (variance) your model has, and the $SSTot$ in the denominator measures how much error (variance) the na誰ve model that always achieves the pooled mean of your data has. $$ R^2 = 1- \dfrac{SSRes}{SSTot} = \dfrac{\dfrac{\sum(y_i - \hat{y_i})^2}{n-1}}{\dfrac{\sum(y_i - \bar{y})^2}{n-1}} $$ (The $n-1$ denominators, of course, cancel out to give the more familiar equation, but this representation, I think, ties it back to variance.) The $\frac{\sum(y_i - \bar{y})^2}{n-1} $ is the same as $\frac{\sum(y_i - \hat{y_i})^2}{n-1}$ if every $\hat{y_i} = \bar{y}$ , in other words, always guessing the average value of $y$ .
