[site]: datascience
[post_id]: 124111
[parent_id]: 
[tags]: 
Value Error: One of the dimensions in the output is <= 0 due to downsampling in conv1d_9

i am trying to implement classification model on my dataset, which has 3 columns and 651 rows Displacement Time Labels 0.000245879 0.01 Undamage 0.001954869 0.02 Damage 0.006545664 0.03 Undamage 0.015357094 0.04 Undamage 0.029615621 0.05 Damage In output it produce accuracy of 99% and during confusion matrix it only classify 125 lables as damaged and un damaged can you guide me what is wrong with this code import numpy as np import pandas as pd from sklearn.model_selection import train_test_split from sklearn.metrics import confusion_matrix, classification_report import matplotlib.pyplot as plt import seaborn as sns from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten from sklearn.preprocessing import LabelEncoder Load your dataset data = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/LabeledSignal.xls') Extract features and labels features = data[['Displacement', 'Time']].values labels = data['Labels'].values Encode labels to numerical values label_encoder = LabelEncoder() labels = label_encoder.fit_transform(labels) Define constants sequence_length = 1 # Each data point is treated as a separate sequence num_features = 2 # Number of features (Displacement and Time) Reshape the features for input to CNN-LSTM X = features.reshape(features.shape[0], sequence_length, num_features) Split the data into training and testing sets X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42) Define and compile the model model = Sequential() model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=(sequence_length, num_features), padding='same')) model.add(MaxPooling1D(pool_size=1)) model.add(LSTM(units=64, return_sequences=True)) model.add(Flatten()) model.add(Dense(units=128, activation='relu')) model.add(Dense(units=2, activation='softmax')) # Output layer for binary classification model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) Train the model history = model.fit(X_train, y_train, epochs=100, batch_size=35, validation_split=0.1) Evaluate the model on the test set and obtain class predictions y_prob = model.predict(X_test) y_pred = np.argmax(y_prob, axis=1) Calculate the confusion matrix confusion = confusion_matrix(y_test, y_pred) Display the confusion matrix print("Confusion Matrix:") print(confusion) Plot the confusion matrix plt.figure(figsize=(8, 6)) sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues', xticklabels=['Damaged', 'Undamaged'], yticklabels=['Damaged', 'Undamaged']) plt.xlabel('Predicted') plt.ylabel('Actual') plt.show() Generate classification report report = classification_report(y_test, y_pred, target_names=['Damaged', 'Undamaged']) print("Classification Report:") print(report) Evaluate the model on the test set loss, accuracy = model.evaluate(X_test, y_test) print(f"Test Loss: {loss:.4f}, Test Accuracy: {accuracy*100:.2f}%") and when i try to pass pool size morte then 1 then it generate this error ValueError: One of the dimensions in the output is
