[site]: crossvalidated
[post_id]: 108911
[parent_id]: 
[tags]: 
Why does frequentist hypothesis testing become biased towards rejecting the null hypothesis with sufficiently large samples?

I was just reading this article on the Bayes factor for a completely unrelated problem when I stumbled upon this passage Hypothesis testing with Bayes factors is more robust than frequentist hypothesis testing, since the Bayesian form avoids model selection bias, evaluates evidence in favor the null hypothesis, includes model uncertainty, and allows non-nested models to be compared (though of course the model must have the same dependent variable). Also, frequentist significance tests become biased in favor of rejecting the null hypothesis with sufficiently large sample size. [emphasis added] I've seen this claim before in Karl Friston's 2012 paper in NeuroImage , where he calls it the fallacy of classical inference . I've had a bit of trouble finding a truly pedagogical account of why this should be true. Specifically, I'm wondering: why this occurs how to guard against it failing that, how to detect it
