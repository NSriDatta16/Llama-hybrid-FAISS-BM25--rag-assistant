[site]: crossvalidated
[post_id]: 9911
[parent_id]: 
[tags]: 
Sampling dataset, choosing among N dimensions

I'm trying to reduce a dimension of my dataset. Maybe reduce is not a good word. I need to sample some of my dimensions. Setup For example: I have $M$ events (let's say $M \tilde{} 60$ ). They are ALL labeled. I have $K$ trials/repetitions (let's say $K \tilde{} 10$ or more). $K$ different sets of $M$ events. Therefore, I have a matrix $K\times M$ Now I need to choose $N$ events among $M$ of them as my representatives. I don't need to reduce the dataset, I just need to pick $N$ columns (events) from the matrix $K\times M$ . These $N$ events should reflect the behavior of particular trial. I'm interesting in corresponding labels of $N$ chosen events. I know that events are quite different, and probably if there is some correlation it's safe to assume that is a nonlinear and in the best case maybe linear. Further, I want the best representation. Meaning $N$ is not an input (of course $N ). Discussion I considered PCA, kernel PCA and sampling. After some reading, I found the following: PCA will reduce my dataset, but I just need to pinpoint the events. Even if I brake down the algorithm, just choose the appropriate eigenvalues, and reverse back to the original dataset, PCA still remains as linear projection. kernel PCA is basically nonlinear, but still it will reduce my dataset instead of choosing particular event. sampling , I went through different types (random, systematic, stratified, cluster ...) but I could not find the particular type. I need something to capture nonlinear connection between the events. Any pointer or explanation of the problem would be much appreciated.
