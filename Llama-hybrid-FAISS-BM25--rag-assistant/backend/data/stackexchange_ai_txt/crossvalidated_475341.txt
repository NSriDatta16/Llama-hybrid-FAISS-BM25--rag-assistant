[site]: crossvalidated
[post_id]: 475341
[parent_id]: 474210
[tags]: 
One approach that comes to mind is to segment the image into "road" and "not-road" (a nice introduction is given e.g. in lecture 7 of the fastai Deep Learning for coders course - a lot can also be found in relevant Kaggle competitions ). Note that the fastai library or its version 2 fastaiv2 (associated with the aforementioned fastai course) are great to get started quickly, and very nicely cover vanilla image segmentation out-of-the-box. If you like their style of coding, you can dive into it and learn how to adapt it as needed. Of course, you can instead use other DL libraries such as keras , for which you find nice example notebooks in relevant Kaggle competitions (search for kaggle competition satellite image segmentation for more relevant material). The training data would be a pixel-by-pixel annotation of a reasonable number of training images (you obviously would not annotate on a pixel-by-pixel basis, but rather by drawing lines/outlines and specifying that what's between two lines is a road and what's outside is not). The annotation is obviously rather tedious, unless you find segmented satellite pixture somewhere (great if someone else has already done the work! In particular, it can be hugely helpful if the existing dataset is much bigger than anything you'd need. E.g. perhaps some dataset from Kaggle or some other source - depending on whether works okay for desert images, as well as whether it is under a suitable license etc.). Then you train some suitable machine learning model (e.g. a U-Net starting from a pre-trained ResNet) to predict this for new images. Either the library you use already does image augementation for you or you need to do it yourself (e.g. in a satellite picture the road could be going in any direction, so rotating the image is a plausible augmentation, or slightly different colors etc.). You can probably more or less follow the basic recipe for image segmentation without much modification. Once you have a trained model for segmenting new unseen images and have done the prediction for the new images, you just need to figure out how wide the road is. If there's just one road in an image, you might just be able to put some kind of LOESS or similar curve through the pixels labelles as road and then count pixels to both sides perpendicular to the local LOESS curve (afterwards, you average the width in pixels along the road - or for a certain length of road segment if the widht can vary along the road - and convert that to e.g. meters based on what you know of the resolution of your image). Alternatively (and this should work even if there's multiple roads), you could for each pixel labelled as road calculate the shortest distance in pixels (going in both directions at once) until you reach non-road pixels on both sides. Afterwards, you perhaps smooth that across surrounding pixels (e.g. using some sensible smoothing kernel, e.g. bivariate-normal, bivariate-Epanechnikov, etc. - bandwidth should probably be wider than the road is wide, possible several multiples). That way you can get for each bit of road how wide the road is around there. This last step could probably just be done with the matrices/tensors that come out as model predictions and in basic ( numpy or similar libraries). Perhaps there is some package that specializes in this, but I do not happen to be aware of it.
