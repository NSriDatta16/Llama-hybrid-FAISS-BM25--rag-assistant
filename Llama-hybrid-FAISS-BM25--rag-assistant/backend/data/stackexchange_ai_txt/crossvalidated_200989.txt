[site]: crossvalidated
[post_id]: 200989
[parent_id]: 
[tags]: 
Converting Dirichlet distribution to distribution on the log-linear parameters

Dirichlet prior/posterior provides a probability density on distributions over a multinomial variable. It has the form : $P(P) \varpropto \prod_i{P_i^{\alpha_i-1}}$ I can also describe the probability over my variable using log-linear parameters $\theta_i$ so that $P_i=\frac{e^{\theta_i}}{\Sigma e^{\theta_i}}$ As adding the same value to all the $\theta_i$ leads to the same $P_i$, there is an infinity of $\theta$ parameters associated with a probability distribution. What I would like to find is a distribution over the $\theta$ that is equivalent to a Dirichlet distribution over the P shown above. My final aim is to calculate the average Kullbach-Leibler divergence between a distribution P that I know not exactly but through sampling (posterior of P is a Dirichlet distribution) and Q that I know precisely. I find it difficult to integrate on a Dirichlet distribution due to the constraint $\Sigma P_i=1$. So integrating through a log-linear distribution should be easier. I have found an interesting paper "Estimating Functions of Probability Distribution From A Finite Set of Sample" by David H. Wolpert and David R.Wolf that obtain the average Entropie in the same context but using complex mathematical machinery.
