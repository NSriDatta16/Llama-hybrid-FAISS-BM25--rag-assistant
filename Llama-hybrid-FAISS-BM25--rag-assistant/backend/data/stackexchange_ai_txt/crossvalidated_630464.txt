[site]: crossvalidated
[post_id]: 630464
[parent_id]: 628497
[tags]: 
Is one of these options preferable? If so, which one and why? Is one of these options so problematic that it should not be used? If so, which one and why? Depends on your goal. If you trust your priors, model specification and error distribution, you would like to include as much of those prior beliefs in the model as you can. If you want to perform an analysis on a large number of samples, on the other hand, you might want to perform a different analysis altogether. Of course, if you need to find out whether there is some systematic bias in your measurements, you need to use an estimator that has minimal bias -- but then could choose to model the bias directly. So in general, I would dismiss your pro towards the method (1): can yield unrealistic estimates, but when applied to a large number of datasets might provide better average estimates on the whole , and only worry about the bias if it is the quantity you want to model . Frequentist vs. Bayesian interpretation There was a paper I found comparing frequentist constraints and bayesian priors, the difference of which comes down to interpretation as well as practical usage. Since the frequentist approach treats the parameter $\theta$ as unknown, but fixed, element of $\Theta$ , it does not make much sense to me to allow values that are physically impossible -- i.e. there is no sensible interpretation for those. In practice, then, this means that the estimation must be restricted to a set of parameters that satisfy the constraints, if you wish to set them. Alternatively, you simply accept that your model doesn't actually model the phenomena. In the Bayesian framework, the parameter itself is a random variable, for which we know at least that $\theta \in \Theta$ . Of course, there are infinitely many distributions that can be used to assign total probability of 1 to that space. The interpretation of prior distributions to restrict parameter values is straightforward, and you get the (posterior) probability distribution of the parameter values, which, again, has quite simple interpretation. It could include physically impossible values, but in that case it is clear that they were, also, included in your prior beliefs. I would say, then, that in the Bayesian case it is quite OK to not restrict the parameter to a certain range, and this has a simple explanation: We chose to allow the parameter to take those values, even if we knew that they were impossible. Conversely if you choose to restrict the parameter space by using a prior, the meaning of that is clear and reflects the analyst's prior beliefs: There is zero probability that the parameter could take these values. If you are concerned about systematic biases introduced by the prior, one option would be to use cross-validation to check the distribution of the errors. Bayesian approach in practice Most common (and trivial) case where you restrict the parameter space by a prior functions is when setting a prior for variance of normal distribution: Inverse gamma distribution is often used. For most parameters there is often enough data that accurate prior distributions matter little, and noninformative, computationally easy (e.g. conjugate) priors are often chosen. More relevant to your question, perhaps, is this is done with physical models in practice. One paper that might be of interest is A Bayesian Search for the Higgs Particle , where one distribution of the prior is based on the theoretical, expected mass of the Higgs Boson -- and another on what we might see if it does not exist. The same author also had another paper that is more general and thus maybe more relevant to your question.
