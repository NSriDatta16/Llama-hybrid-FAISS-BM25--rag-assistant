[site]: stackoverflow
[post_id]: 749337
[parent_id]: 
[tags]: 
Best practices for a single large SVN project

I have inherited a single project in svn: 30Gb in over 300 000 files. There are tons of binary files in there mostly in an images folder. Operations like updating the entire project can be dramatically slow. The team has evolved a process to only run update/switch on the specific folders they are working on and end up checking in broken code because "it works on my computer". Any one person's working copy can include out-of-date code, switched code, and forgotten-never-committed code. Also, minimal branching takes place. My personal solution is a small bash checkout/build script at 5am every morning, however not everyone has the command line courage to even copy my solution and would rather the comfort of tortoise svn and the broken process. Has anyone tried to tune such a large repository and can give advice? Are there any best practices I can implement for working with large repositories that I can ease everyone into? P.S. externals don't seem to be a good idea and SVN optimizations to keep large repositories responsive doesn't apply here because I am dealing with a single project P.P.S. This is currently being looked into also: http://www.ibm.com/developerworks/java/library/j-svnbins.html
