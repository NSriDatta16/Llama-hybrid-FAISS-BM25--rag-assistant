[site]: crossvalidated
[post_id]: 522224
[parent_id]: 522025
[tags]: 
The log likelihood of a model with more covariates will always be larger than a that of a model with fewer covariates. The reason is simple, if $\alpha \subset \beta$ , then $$\max_{\alpha}L(\alpha) \leq \max_{\beta} L(\beta).$$ However, the question is: how much gain is there in adding the covariates that are in $\beta$ but not in $\alpha$ ? The answer is not straightforward, but you can use: Akaike or Bayesian information criteria. These penalize the number of parameters. LASSO, which is implemented in the R package glmnet . Likelihood ratio test. As an informal reference, you can also fit the model using glm in R, and take a look at the p-values of the additional variables.
