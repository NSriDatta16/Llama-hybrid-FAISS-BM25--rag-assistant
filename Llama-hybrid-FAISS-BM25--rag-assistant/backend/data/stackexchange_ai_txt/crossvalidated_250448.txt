[site]: crossvalidated
[post_id]: 250448
[parent_id]: 250339
[tags]: 
To begin with your data is discrete ( fixed # of values that can arise e.g. hour in the day ) while the ADF test requires a large number of assumptions one of which is the data is continuous ( large # of values that can arise like time ). Your software utilization (who should have warned you about this deficiency/limitation ?) is invalid and all results are meaningless. A periodic sequence of consecutive zeroes incorrectly suggests high correlation between successive values thus ADF incorrectly suggests first differencing. To give you an idea of your unfortunate suggested model your ma(1) coefficient is -.98 (nearly -1.0) effectively cancelling your mis-specified differencing operator. I took your 105 values into AUTOBOX , a piece of time series software that I have helped to develop, and (using a slightly different estimation algorithm) and assumed your model . I obtained a coefficient of -.953 and an R-Square of 0.0 reflecting the redundancy. Curiously your software reported an R-Square of .457 which motivated some research on my part. If one unnecessarilly differences a series then one is injecting structure and the new series will have greater variance Variance of difference of $x_{i,t}$ and $x_{i,t+1}$ . If one then models this inflated series with an MA(1) then one can then get an R Squared of .457 .This reporting of the R Squared of the differenced series as compared to the R squared of the observed series is very bad statistics in my opinion and represents an inability to deal holistically with the observed series and the ARMA struture. Software is just as good as the last time it was checked . This is poor practice and defintely non-standard. There is nonsense and there is nonsense but the most nonsensical of them all is statistical nonsense. Now continuing with possible analyses .... your data reflects the impact of two random variables viz. 1) the time between shocks (eathquakes) and 2) the magnitude of the shock (earthquake). I have used two different approaches for data like this. APPROACH 1: Computing and interpreting ACF's and PACF'S for discrete data is problematic. Note that the classic airline series (# of passenger miles) from Box and Jenkins is discrete data BUT a large number of values can arise thus all is well and it passes as approximately continuous. ARIMA modeling with Intervention Detection providing reasonably robust solutions. For this data AUTOBOX found the data to be stationary (without memory) AND number of anomalies i.e. one-time pulses. This is the equation and visually showing Actual/Fit and Forecast . Note that the level of the series appears to be stable with periodic shocks ( 1 time pulses) . The Confidence Limits are computed by resampling the (decidedly non-normal error process ) and allowing for re-occurrence of the empirically identified pulses. Since negative earthquake numbers can not exist simply replace the lowerlimit (red) valiues with 0.0 . Not much more to be said about this as we are pushing the aboundaries of where ARIMA might apply . Certainly if we had n discrete possible values and a large enough history of all possible values a markov switching model might apply GIVEN that anomalies had been silenced (treated). APPROACH 2: The time series literature includes something referred to as Intermittent Demand or AKA Sparse Data Anlysis . In this section I will outline and demonstrate that method to solve this complex problem (aren't they all !) . Copute the time between non-zero evbent. For each of those intervals compute the Rate (observation divided by # of intervals between events) . Construct a Transfer Function between Rate and Interval Size identifying level shifTs and pulses as needed to predict Rate . Use the Interval data to predict the next interval and use that predicted interval to compute the size of the earthquake. This is a superset/modification of Crostonâ€™s method. This procedure has served us well by actually developing a forecast for both the interval and the demand (in this case magnitude of the earthquake) APPROACH 3: Certainly if we had n discrete possible values and a large enough history of all possible values a markov switching model might apply GIVEN that anomalies had been silenced (treated). I will leave it others to possibly flesh this out but I would like to subsequentally know the critical assumptions that being made.
