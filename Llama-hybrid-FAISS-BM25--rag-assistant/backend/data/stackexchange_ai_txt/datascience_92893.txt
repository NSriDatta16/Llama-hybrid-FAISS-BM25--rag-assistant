[site]: datascience
[post_id]: 92893
[parent_id]: 
[tags]: 
Random forest: Should OOB accuracy equals Test Set accuracy?

In random forests, we bootstrap a sample from the training set, and train a decision tree on the bootstrapped sample. Some observations are not drawn from the training set, and not used to train the decision tree: these are out-of-bag (OOB) observations that we can use to compute the performances of the model. For random forests, I thought that the out-of-bag performance should be the same (or at least very similar) to the performance calculated on a separated test set. But this does not seem to be the case. In the following R code, the accuracy computed on the out-of-bag sample is 77.81%, while the one computed on a separated test set is 81%. What I am doing wrong? library(randomForest) library(ISLR) Carseats $High Sales $High High) train = sample(1:nrow(Carseats), 200) rf = randomForest(High~.-Sales, data=Carseats, subset=train, mtry=6, importance=T) acc $confusion[1,1] + rf$ confusion[2,2]) / sum(rf$confusion) print(paste0("Accuracy OOB: ", round(acc*100,2), "%")) yhat
