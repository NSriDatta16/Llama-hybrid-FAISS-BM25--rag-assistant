[site]: crossvalidated
[post_id]: 295438
[parent_id]: 295432
[tags]: 
I have read that we should think of entropy as expected bits of required to store the information provided about a variable. Perhaps you might modify that a bit (pun intended!). Intuitively, entropy is the expected average per-bit number of bits required to store the information, for a long enough sequence of known length. That is, if you have a long enough sequence of length $n$ with entropy $H$, then you will be able to encode it in about $nH$ bits (and not significantly less), so each bit requires, on average , about $H$ bits. If outcome of a variable is A: 0.9 and B: 0.1? In this case, a combinatorical argument shows that a long enough sequence of length $n$ generated with these probabilities (or a long enough sequence having these empirical probabilities) is one of about $2^{n H(0.9)}$ such sequences, and so about $n H(0.9)$ bits, per bit , is a necessary and sufficient encoding length.
