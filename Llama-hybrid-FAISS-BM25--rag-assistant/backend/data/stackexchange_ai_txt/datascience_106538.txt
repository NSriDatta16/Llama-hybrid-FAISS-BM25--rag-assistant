[site]: datascience
[post_id]: 106538
[parent_id]: 106537
[tags]: 
From the info you provide, I think you can do: average the test scores you get from your splits instead of printing per split, or use the cross_validation_score option given by sklearn, and then average such scores: cross_val_score(clf, X, y, cv=5).mean(), or use the sklearn GridSearchCV class, with which you can access the details of your cross validation strategy v√≠a the cv_results_ parameter: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html You can see a related question and answer on: KFold cross validation ambiguity
