[site]: datascience
[post_id]: 20005
[parent_id]: 20001
[tags]: 
The method to use depends on the problem at hand. Is your data linearly separable? In the case of a single feature, this corresponds to all instances of a class being within a lower and an upper bound. If this is the case, then a simple model like logistic regression should do the trick. If your data is not linearly separable, then a decision tree could be enough. The optimization would take care of finding the optimal cuts in the values of the feature to split the data into the different classes. Another option for non-linearly separable data is to use an SVM with some kernel that makes your data linearly separable. More complex methods are designed to capture patterns in the data when multiple features are available, and as such shouldn't be expected to perform well under these conditions.
