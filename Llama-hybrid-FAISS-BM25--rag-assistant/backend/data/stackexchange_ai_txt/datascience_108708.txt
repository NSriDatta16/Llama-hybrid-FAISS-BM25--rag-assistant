[site]: datascience
[post_id]: 108708
[parent_id]: 
[tags]: 
Latent space vs Embedding space | Are they same?

I am going through variational autoencoders and it is mentioned that: continuity (two close points in the latent space should not give two completely different contents once decoded) and completeness (for a chosen distribution, a point sampled from the latent space should give “meaningful” content once decoded). so is latent space merely an embedding space where two similar entities are mapped nearby in the vector?
