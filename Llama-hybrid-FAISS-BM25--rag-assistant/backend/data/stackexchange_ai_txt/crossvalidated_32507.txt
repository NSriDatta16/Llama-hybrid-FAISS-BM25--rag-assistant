[site]: crossvalidated
[post_id]: 32507
[parent_id]: 32496
[tags]: 
I am not sure variance is the right thing to be looking for. A complex procedure like regression using a variable selection method or generating a random forest will change with slight changes in the data. So what I think is good in those situations is to bootstrap the entire procedure. That means getting bootstrap samples and for each bootstrap sample go through the entire procedure. This can be very computer-intensive but also very enlightening. Often you see surprising differences in the algorithms choice from one bootstrap sample to the next. But for example in variable selection you may see certain important variables being selected consistently more often than the others. So the bootstrap provides the variability or sensitvity of the procedure to small changes in the data. But important patterns that you wouldn't see otherwise may emerge. It is another way to do sensitivity analysis. In the case of bagging procedures in random forests it may be interesting to look at what treeare used in the ensemble each time. You can also compute classification error rates each time and see how that varies from one bootstrap sample to the next. I think you can even estimate a variance for the classification error due to the perturbations in the data. The idea in stepwise logistic regression of bootstrapping the selection procedure was first given by Gail Gong in her dissertation at Stanford in the early 1980s. I discuss some of this in my bootstrap books.
