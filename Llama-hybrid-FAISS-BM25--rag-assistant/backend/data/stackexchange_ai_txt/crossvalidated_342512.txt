[site]: crossvalidated
[post_id]: 342512
[parent_id]: 
[tags]: 
Could adding more history (expanding the training sample) reduce forecast accuracy?

Following up on a discussion in a previous thread : Are there any situations where adding too much data to a forecasting model is counterproductive, in the sense that it reduces the forecasting accuracy of the model? Specifically, if I have a univariate time series model, is there such thing as using too much history? Are there situations where I have 20 years of monthly data, but I would be better off using only the most recent 5 years of data, since older data would reduce the accuracy of the model. For example if there was a structural break in the time series, does feeding data from before the break to the time series somehow throw the model off? Or does the ML truism that "more data = better accuracy" hold for time series as well?
