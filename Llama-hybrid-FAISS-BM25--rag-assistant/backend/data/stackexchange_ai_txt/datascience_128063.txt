[site]: datascience
[post_id]: 128063
[parent_id]: 128043
[tags]: 
You could use OpenAI's API, GPT3.5 and use those to build a retrieval augmented generation model (RAG) to search a vector store of contexts of your choosing. You can do this using a couple of different python packages such as LLamaIndex or Langchain . Of course, this only makes sense if you intend to have it search information that you have in text documents. This course from DeepLearning.ai , should also get you started with RAG and LLMs. You could also choose to use Llama2 if you prefer to not use OpenAI models or if your data is proprietary.
