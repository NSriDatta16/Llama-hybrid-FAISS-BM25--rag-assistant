[site]: crossvalidated
[post_id]: 360269
[parent_id]: 350695
[tags]: 
Machine learning algorithms are, by definition, methods for minimizing the loss function. A model is therefore locally optimized for minimizing the loss function. It follows that, generally speaking, if model M1 is trained on loss function L1, and model M2 is trained on loss function L2, M2 will have a worse L1 score than M1 does, and M1 will have a worse L2 score than M2 does. Your loss function does not weight misclassified inputs higher, so models trained with those inputs weighted higher will do more poorly on your loss function. If you were instead to measure your Strategy1 models on your weighted loss function, then Strategy1 would do better than the baseline. It's like if you bred quarter-horses (horses optimized for running quarter-mile races), then ran one of them in a 10-mile race. Of course it's not going to do as well as a horse breed that's been optimized for 10-mile races. Now, something that can improve accuracy is, given an ensemble of classifier, give more weight to the classifiers that do better at the inputs misclassified by the other classifiers. This is the concept behind gradient boosting. Something to look at is what the nature of the feedback is. For each input, can you tell from the feedback whether it was correctly classified? If not, then are there any patterns as to what inputs you get feedback on? If you are more likely to get feedback on misclassified inputs, then you might actually get a better model by weighting correctly classified inputs higher, because for every correctly classified input you see, there are several more that you didn't see.
