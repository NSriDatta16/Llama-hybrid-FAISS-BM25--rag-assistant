[site]: datascience
[post_id]: 63034
[parent_id]: 16843
[tags]: 
Some of the answers on this page are misleading. In the perceptron algorithm, the weight vector is a linear combination of the examples on which an error was made, and if you have a constant learning rate, the magnitude of the learning rate simply scales the length of the weight vector. The decision boundary depends on the direction of the weight vector, not the magnitude, so assuming you feed examples into the algorithm in the same order (and you have a positive learning rate) you will obtain the same exact decision boundary regardless of the learning rate. The talk of "overshooting the minima" does not apply here, because there are an infinite number of weight vectors with different magnitudes which are all equivalent, and therefore an infinite number of minima. The whole beauty of the perceptron algorithm is its simplicity, which makes it less sensitive to hyperparameters like learning rate than, for instance, neural networks. The answer above citing an infinite learning rate is more of an edge case than an informative example - any machine learning algorithm will break if you start setting things to infinity. That being said, it was recently pointed out to me that more complex implementations of learning rates, such as AdaGrad (which maintains a separate learning rate for each feature) can indeed speed up convergence. Long story short, unless you are using something significantly more complex than a single constant learning rate for your perceptron, trying to tune the learning rate will not be useful.
