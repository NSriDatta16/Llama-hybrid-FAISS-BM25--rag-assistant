[site]: crossvalidated
[post_id]: 414930
[parent_id]: 
[tags]: 
Streaming audio to neural network

I am trying to create a neural network that performs speaker recognition. I would like to be able to serve it such that it takes streaming audio - i.e. I want to perform partial recognition on 100ms frames and then calculate an average at the end. I would like to know which of the following two forseeable options is the best. Training the network on audio clips of 100ms Using audio clips of arbitrary lengths and feeding subsequent 100ms segments into some sort of recurrent network. I was thinking that similar to text analysis, maintaining some state information could be useful in real time speaker identification. Does anyone have some guidance in this regard? Thanks.
