[site]: crossvalidated
[post_id]: 399129
[parent_id]: 
[tags]: 
Dirichlet Multinomial Posterior Predictive Distribution for Language Model

I have been trying to teach myself about Bayesian analysis, and whilst I have been through the theory several times, I am struggling to actually apply it. I have found some questions online to practice with and am currently trying to do question 3 in the following: https://www.cs.ubc.ca/~murphyk/Teaching/Stat406-Spring10/hw8.pdf I figure that to obtain a histogram for part a, I should calculate a posterior probability for each possibility. To this end, I currently have $p(X=j) = \int p(X=j| \theta) p(\theta) d \theta = \int_{\theta_j} \int_{\theta_{\neg j}} p(X=j|\theta) p(\theta) d \theta_{\neg j} d \theta_j$ Using that $p(X=j|\theta) = \theta_j$ , we can pull this outside the interior integral to get $=\int_{\theta_j} \theta_j \left( \int_{\theta_{\neg j}} p(\theta) d \theta_{\neg_j} \right) d \theta_j = \int_{\theta_j} \theta_j p(\theta_j) d \theta_j = E[\theta_j]$ where I have used that $p(\theta) = p(\theta_j, \theta_{\neg j})$ and marginalised in the second to last equality. Now we need to evaluate the expectation of the marginal $\theta_j$ . According to Wikipedia page on Dirichlet distribution, if $\theta \sim$ Dirichlet, then the marginal is $\theta_j \sim$ Beta. However, I do not know : (a) Why this is true? (b) What the parameters of the Beta distribution should be? (c) How to carry out the integral in the expectation? And finally, given that we are using a Dirichlet prior with parameters $\alpha_1 = \dots = \alpha_{10}=1$ (flat prior), how is the MAP estimate in (b) going to differ from the MLE? Won't the histogram just boil down to the relative word frequencies in the original poem? Thanks
