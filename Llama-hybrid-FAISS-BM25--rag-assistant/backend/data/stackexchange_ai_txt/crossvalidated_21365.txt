[site]: crossvalidated
[post_id]: 21365
[parent_id]: 
[tags]: 
Does the p-value in the incremental F-test determine how many trials I expect to get correct?

I've implemented an incremental F-test program that evaluates the fit of an unrestricted model $M_{UR}$ against the restricted model $M_R$ using the F statistic $\frac{SSE_{R} - SSE_{UR}}{SSE_{UR}}\frac{n-p-1}{j}$. In this instance, I'm interested in comparing a polynomial with order $p$, against another (the restricted model) with order $p-1$. It is worth noting that this necessarily makes $j = 1 $. In order to validate this program, I create data using randomly generated polynomials, add gaussian noise to it, and see if the incremental F-test identifies the correct polynomial order (i.e. if the data is created from a $3^{rd}$ order polynomial, I would expect to get order $3$). In detail, the framework is as follows: For i = 1 : $n_trials$: 1. Randomly choose a polynomial order between 2 and 10 2. Populate the coefficients of this polynomial with values between -5 and 5 3. Evaluate this polynomial at abscissa values X = [0,0.01,0.02,...3.00] 4. Add gaussian noise ~N(0,0.01) to each output of P(X) 5. For p = 3:10 : a. Fit the tuples (X,P(X)) using polynomials of order p-1 and p b. Compare the results using the FTest, if it fails, exit. If it passes try increasing p = p+1 6. Return the last polynomial order p-1 that passed the F-Test (at p-value 0.05) Having done this for $n_{trials} = 3000$, I'm finding that the algorithm incorrectly identifies the order on average $200$ to $300$ times. However, if I've chosen a p-value of $0.05$, shouldn't I only expect to see errors $5\%$ of the time, that is $0.05\cdot3000 = 150$? I also noticed that, if I change the range of X from $[0, 0.01, ... ,3.00]$ to $[0, 0.1, ... , 30.0]$, the F-test fails much more frequently, even though the number of data points is the same between the two experiments! Is this an artifact of the multicollinearity problem with polynomials?
