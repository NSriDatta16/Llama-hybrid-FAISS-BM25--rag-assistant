[site]: crossvalidated
[post_id]: 416684
[parent_id]: 
[tags]: 
Comparing student test results

Students complete a test at the end of a course. The test conditions are always the same as are the content of the test. Students are given six hours to write a paper on a given topic, the source material is provided for the students to produce their paper. A statistically significant reduction in average test scores has been observed in the last three courses. This reduction has coincided with a change in the person marking the tests. There is a marking guide, however as it is a written test there is a degree of subjectivity in whether the students paper meets the criteria. A working hypothesis is that students attending the last three courses have a lower starting state (inferior knowledge) compared with students from previous courses. The number of students attending each course is between 13 and 24. The average score for the all previous five courses is 76% with a Std Dev of 4.97, 7.6, 5.36, 5.42 respectively. The last three courses had an average score of 65%, 66%, and 59%. With a std dev of 9.18, 8.71, and 12.51 respectively. Is there a way to test the working hypotheses, perhaps assuming a lower starting state of say 0.5 compared with previous students? Is there any way to test the possibility of inconsistent marking given the students are always selected randomly and the test conditions have remained the same?
