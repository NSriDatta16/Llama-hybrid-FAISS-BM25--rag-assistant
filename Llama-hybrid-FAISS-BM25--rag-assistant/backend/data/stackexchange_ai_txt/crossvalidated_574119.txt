[site]: crossvalidated
[post_id]: 574119
[parent_id]: 573951
[tags]: 
Another way of looking at the issue of approximating $$\mathfrak I = \sum_{x\in\mathfrak X} p(x)O(x)$$ by stochastic techniques is to aim at adding primarily large values of $p(x)O(x)$ . Assuming no information is available about the [location or values of the] largest probabilities over $\mathfrak X$ , one could consider a self-avoiding Markov chain by never returning to entries in $\mathfrak X$ already visited and move from $X_t$ to $X_{t+1}$ by choosing among neighbouring entries with probabilities proportional to $p(x)O(x)$ or $\exp\{\alpha p(x)O(x)\}$ . With the added perk that since $p(x)O(x)$ is computed for these neighbours, they can all be added to the approximation of $\mathfrak I$ and excluded from future steps. The algorithm could stop when the probability of the visited values is close enough to one. Here is a toy illustration where $\mathfrak X$ is an $N\times N$ grid, $O(\cdot)$ is a discretised Normal density (represented by the level set on the above picture) and $\mathfrak X$ is explored by a random exploration until the accumulated probability mass is $0.999$ . The white dots in the above picture correspond to the points $x$ that have not been explored. Here is the attached R code: #preliminaries N=5e2;N2=N*N Y=matrix(0,N,N)#visited points P=exp(matrix(rnorm(N2),N)) P=P/sum(P)#probability mass function O=matrix(dnorm((1:N2)%%N,mean=N/2,sd=N/3)+ dnorm((1:N2)%/%N,mean=N/2,sd=N/3),N)#function O(x) #stochastic exploration m=sample(1:N2,1)#current point t=P[m]*O[m]#targeted expectation p=P[m]#visited mass Y[m]=1 while(p
