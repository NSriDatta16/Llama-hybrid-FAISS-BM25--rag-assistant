[site]: crossvalidated
[post_id]: 162835
[parent_id]: 
[tags]: 
Gibbs sampling version for estimating Hierarchical Double Dirichlet Process Mixture of Gaussian Processes

I'm trying to implement Gibbs sampling to estimate the parameters of the following non-parametric model: $$\begin{align*} \beta|\gamma & \sim \text{GEM}(\gamma)\\ k_t|\beta & \sim \beta\\ \pi|\alpha & \sim \text{GEM}(\alpha)\\ t_i|\pi & \sim \pi \\ \Sigma_t & \sim \mathcal{W}^{-1}(S_0,\nu_0)\\ \mu_t |\Sigma_t & \sim \mathcal{N}(\mu_0,\kappa^{-1}\Sigma_t)\\ X^t|\mu_t,\Sigma_t & \sim \mathcal{N}(\mu_t,\Sigma_t)\\ \Theta_k | \Lambda & \sim \text{H}(\Lambda)\\ Y_k | X_k,\Theta_k & \sim \mathcal{N}(m(X_k),K(X_k,X_k')|\Theta_k) \end{align*} $$ Here $\text{GEM}(\cdot)$ is the notation used for the stick-breaking construction of the Dirichlet Process. $t_i$ are latent cluster indicator variables. $k_t$ are latent indicator variables denoting the assignments of GP experts. $X^t = \{x_i : t_i = t\}$. $X_k = \{x_i : k_{t_i} = k\}$ and $Y_k = \{y_i : k_{t_i} = t\}$. $\Lambda$ is the set of hyper-hyper parameters of the GP hyperparameters $\Theta_k$. Here, I was assuming a squared exponential covariance function. The associated Bayesian network is depicted in the following figure: Actually, I know that I have to derive the conditional posteriors of each parameter, given the data and all the remaining parameters. This is not so straightforward for me that I'm not an expert in these models. In order to start writing the posteriors, of course I was studying the most famous works about non-parametric models, e.g., Rasmussen, Teh, Hughes, Sudderth, Jacobs and Meeds. However, the description algorithm is not so clear. Many hidden parts.
