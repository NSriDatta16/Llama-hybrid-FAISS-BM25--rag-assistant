[site]: crossvalidated
[post_id]: 20569
[parent_id]: 20563
[tags]: 
I think you can devise a big number of tests, and the good choice depends on the alternate hypothesis you have in mind... I just have a few remarks. I place this post under community wiki as I feel it can be improved a lot. The first think I would think to: divide your sample in n subsamples of size k; if the experiments are independents, in sample number $i$ the number $X_i$ of successes is a $\mathcal Bin(k,p)$, so you have $n$ independent values $X_1, \dots, X_n$ of a binomial variable. This can be tested by a $\chi^2$ test. (The choice of $n,k$ will depend on the total sample size...) Considering your remark about the process sticking for a number of trials, it seems that you think of positive correlation between successive experiments. I think the above test can be powerful in this case. However you can consider the length of runs in your sequence of trials: denoting $L_1$ (resp. $L_0$) the length of a 1 run (resp. of a 0 run), you have $$\mathbb P(L_1 = k) = p^{k-1} (1-p),$$ $$\mathbb P(L_0 = k) =(1-p)^{k-1} p.$$ These are geometric distributions, beware: in some softwares like R, $k$ is shifted by $1$. You can again test for goodness of fit of the observed values. I don’t know how the preceding suggestion performs as compared to Wald–Wolfowitz runs test . Special attention has been given to the case where $p={1\over 2}$, as this is the case of a sequence of random bits generated by a Random Number Generator. A number of tests has been devised by George Marsaglia, under the name Diehard test battery . You can surely generalize (most of) these tests to the case $p \ne {1\over 2}$. (But is it worth it?)
