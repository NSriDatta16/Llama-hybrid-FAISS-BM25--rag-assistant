[site]: crossvalidated
[post_id]: 105366
[parent_id]: 
[tags]: 
Timeseries: Find points deviating from the mean

I haven't done much time-series modelling at all and now I have a dataset which screams "time series" at me and now I am hunting for a model. The data: Imagine a video watched by ~400 people, 100 seconds long. Each person had a slider from 0 (bad) to 10 (good) to indicate if they liked a particular scene. The value of the slider is recorded each second, resulting in 100 variables from the first to the last second. The problem: Now I would like to determine points of interest in this short film: e.g. seconds where the mean answer deviates from the overall mean of the film, indicating a good or bad scene. Is there some form of time-series model which can do this? Thank you.
