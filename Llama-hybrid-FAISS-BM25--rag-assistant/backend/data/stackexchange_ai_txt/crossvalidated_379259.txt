[site]: crossvalidated
[post_id]: 379259
[parent_id]: 
[tags]: 
Is RJMCMC robust to overfitting?

I have noticed that RJMCMC is often described as robust to overfitting. I am struggeling a bit with the intuition for this. Why doesn't the Reversible jump Markov Chain Monte Carlo (RJMCMC) always get stuck at more complex models? Won't transdimensional jumps to models that have a higher dimensionality (more parameters) tend to be accepted more often, because they have a higher likelihood? Is the number of parameters penalized in some sense, is the procedure related to the Bayes factor? The procedure is commonly used for model selection by using the number of iterations spent in each model as an estimate of the model evidence. Thanks in advance!
