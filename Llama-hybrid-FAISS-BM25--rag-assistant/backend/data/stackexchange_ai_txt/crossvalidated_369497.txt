[site]: crossvalidated
[post_id]: 369497
[parent_id]: 
[tags]: 
Mobilenet Original Paper Architecture vs Keras Implementation

1. Question: Why do original paper mobilenet architecture and keras implementation differ? Keras implementation of mobilenet's last 5 layers after AVG Pool layer: Layer (type) Output Shape Param # ================================================================= global_average_pooling2d_1 ( (None, 1024) 0 _________________________________________________________________ reshape_1 (Reshape) (None, 1, 1, 1024) 0 _________________________________________________________________ dropout (Dropout) (None, 1, 1, 1024) 0 _________________________________________________________________ conv_preds (Conv2D) (None, 1, 1, 1000) 1025000 _________________________________________________________________ act_softmax (Activation) (None, 1, 1, 1000) 0 _________________________________________________________________ reshape_2 (Reshape) (None, 1000) 0 In the original Mobilenet paper, last 2 layers after AVG Pool layer look like this: Type / Stride | Filter Shape | Input Size Avg Pool / s1 | Pool 7 × 7 | 7 × 7 × 1024 FC / s1 | 1024 × 1000 | 1 × 1 × 1024 Softmax / s1 | Classifier | 1 × 1 × 1000 2. Question: In the original paper, for the fully-connected layer, is there just 1 Input and 1 Output layer (with softmax) or is there also a hidden layer. I wasn't sure because they have mentioned Softmax as a separate layer.
