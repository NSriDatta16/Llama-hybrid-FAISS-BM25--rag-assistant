[site]: crossvalidated
[post_id]: 219687
[parent_id]: 
[tags]: 
Analogy between Neural network and naive bayes

I am trying to understand the analogy between a single layer neural network and naive Bayes classifier. Particularly, I want to know if, in a neural network, the variables are independent given the class and if the bias term represents the prior probability. (As far as I understand, if I take the log of the naive bayes expression, it seems to give a term similar to the weighted sum +bias in neural network as worked out here wiki ) Moreover, if single layer neural network have exactly same representative power as naive Bayes (i.e. the features are independent given the class), I want to understand, how multilayer neural network captures the dependence among features.
