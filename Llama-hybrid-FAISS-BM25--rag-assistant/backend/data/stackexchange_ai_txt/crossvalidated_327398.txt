[site]: crossvalidated
[post_id]: 327398
[parent_id]: 
[tags]: 
Why center the data during feature scaling for neural network

Basically, feature scaling is done to transform the data to same scale so that the gradients don't have bias towards larger values. Now, we do this by centering the data and dividing by standard deviation - x = np.array([-20,-10,20,50]) y = (x - x.mean())/x.std() print(y) I get the scaled values as - [-1.09544512 -0.73029674 0.36514837 1.46059349] But, if we only want to scale the values, why subtract by the mean, we can only divide by standard deviation i.e x = np.array([-20,-10,20,50]) y = (x)/x.std() print(y) And I get the scaled values as - [-0.73029674 -0.36514837 0.73029674 1.82574186] What purpose does this centering the data serve?
