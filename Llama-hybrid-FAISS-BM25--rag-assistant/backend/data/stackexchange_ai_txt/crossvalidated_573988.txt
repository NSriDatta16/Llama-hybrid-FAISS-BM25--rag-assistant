[site]: crossvalidated
[post_id]: 573988
[parent_id]: 
[tags]: 
Change in Correlation after Imputation of Missing Outcome Data for Machine Learning Prediction Task

I am attempting to generate a predictive model for a continuous outcome using machine learning models. However, some observations in the original dataset have missing outcome data (and missing predictor values). I had been using mice to impute the missing outcome data, first generating the imputation scheme on the training data and re-using it on the test data. After the models performed worse than expected, I noticed that after imputing the data, the correlation between some of the most important predictors has decreased as compared to what was observed in the original data. In short, there is one main predictor that has a correlation of ~0.92 with the outcome in the complete cases analysis in the full dataset (train + test), but this correlation drops to the range of 0.4 to 0.6 in the imputed test data. In the training data, the decrease in correlation is more modest, with the correlation generally remaining around 0.8. My models were not generalizing well to the test data, and I suspect this may have been due to the decrease in correlation between the variables. Is this an expected result, or does it suggest that something is incorrect with the imputation model being used, such as assumptions being violated? I'm happy to provide more information if necessary - just a bit confused as to why the correlation has changed so dramatically! EDIT: One comment about the data that may be important - many of the features are highly correlated with one another, so not sure if this will also cause problems with mice.
