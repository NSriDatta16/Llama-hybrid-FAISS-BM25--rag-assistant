[site]: crossvalidated
[post_id]: 600144
[parent_id]: 600000
[tags]: 
I have this controversial view that the answer to this question is actually very simple and people over-complicate it by using academic responses. I also have asked the question, "why use frequentist methods when you can just get the same answer using Bayesian methods?", and I get academic responses which are not very convincing, e.g., "because the answer depends on the prior", ect. When I ran my own simulations and use absolutely horrendous priors the MCMC sampling still converged to the correct answer, which was almost the same as using non-informative priors, and which was almost the same as using frequentist methods. So the common response that, "since your answer depends on the prior", is not a what is seen in practice. So it is really a non-answer. The only time when the prior actually does matter is when you have small amounts of data, but then, statistical analysis derived from that data is highly suspicious anyway. There are only three practical answers that make sense to me. Frequentist methods, if applicable, are much faster than MCMC. For example, you can run least-squares regression calculators on gigantic datasets and get an answer extremely quickly. However, running Stan would be too slow. Also, related to this problem, sometimes setting up an MCMC simulation might cause some sort of bugs, and then you need to figure out what those are and why it is not running. With frequentist methods it is more reliable, but again, provided that the problem can be delt with in a frequentist manner. Necessity is the mother of all invention. In the 1920s it was not possible to do Bayesian computation beyond the simplest problems. Therefore, the frequentist method was the default since it was the only way calculations could actually have been done. People are lazy. Once they learn how to do something one way, why would they then learn how to do it another way? For example, R is superior to SPSS, Stata, SAS, ect, so why do people not use R? Because they already can do it in using other software, so why put in the effort to learn something which is harder (even if better)? Pedagogical reasons. Imagine incoming freshmen in Psychology are taking their first statistics course. You cannot talk about calculus, or MCMC algorithms, or MLE with gradient descent, ect. That will confuse everyone. Instead if you teach the students some commonly used sampling distributions, and how to look up their values, then they can actually learn how to do some statistical analysis. It is similar to asking the question, for an easy intro physics class, "why do they just not teach calculus and differential equations?". Because everyone would be confused, so they teach more elementary methods so the students can still get something out the class.
