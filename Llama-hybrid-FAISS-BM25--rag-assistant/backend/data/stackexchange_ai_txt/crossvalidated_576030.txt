[site]: crossvalidated
[post_id]: 576030
[parent_id]: 576024
[tags]: 
This is not a complete answer, and it's not exactly "objective", but a useful tool is what is known as posterior predictive checks in a Bayesian context (but probably by other names elsewhere). In this, you simulate data from the distribution implied by your model, and compare it to your actual data, usually by plotting them side-by-side in whatever fashion makes sense for your problem. Mismatches then suggest assumptions that don't hold - e.g. your simulated data is symmetrical where the real data is skewed, or the real data has fatter tails.
