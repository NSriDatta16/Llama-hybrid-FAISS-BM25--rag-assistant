[site]: crossvalidated
[post_id]: 506365
[parent_id]: 
[tags]: 
Does increasing the value of C in svm.LinearSVC leads to overfitting?

I have made an svm.LinearSVC model to classify images. Firstly, the features of the images are extracted by SIFT and then based on them the LinearSVC is trained. I have the following Python snippet: from sklearn import svm model = svm.LinearSVC(C=2, max_iter=10000) model(x_train, y_train.ravel()) y_pred = model(x_test) print(metrics.accuracy_score(y_test, y_pred)) x_train shape is (3700, 256) and x_test shape is (1300, 256) I have received the following accuracy results with the different values of C : C = 2.0 => accuracy = 72.3% C = 10.0 => accuracy = 82.9% C = 100.0 => accuracy = 90.2% C = 1000.0 => accuracy = 91.1% C = 1500.0 => accuracy = 91.2% Based on "Kent Munthe Caspersen" answer on this page , in an SVM model, we look for a hyperplane with the largest minimum margin, and a hyperplane that correctly separates as many instances as possible. Also I think C, as the regularisation parameter, prevents overfitting. So does the model explained above, suffers from overfitting and if so, then how do I find the appropriate value of C? Thanks
