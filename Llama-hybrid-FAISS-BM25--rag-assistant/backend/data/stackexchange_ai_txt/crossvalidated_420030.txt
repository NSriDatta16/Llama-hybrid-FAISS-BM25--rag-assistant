[site]: crossvalidated
[post_id]: 420030
[parent_id]: 
[tags]: 
Using Bayesian formula to apply uncertainty to topic probability given length of document

After computing topics ( $z$ ) over a word network, I'm assigning topic probability to documents, following: $$p(z|d) = \sum_{w_i}p(z|w_i)p(w_i|d)$$ with $d$ being a document composed by $w_{i...n}$ words. With this setting, I have that very short documents get a high probability of belonging to a certain topic $z$ , because $p(w_i|d)$ is very high. Eg. if a document (after removing stop words, adverbs etc) has only 4 words, all belonging with high probability to topic $z$ , also $p(z|d)$ will be very high. Furthermore, in truth, my $p(w_i|d)$ are scaled using word scores (TfIdf and more), so it's very easy that one word get very high relative document probability. I would like instead to add some uncertainty given by the fact that with shorter documents is harder to define a topic. I could do it with various weighting schema, but I prefer to use something theoretically sound, using a weakly informative prior. I'm no Bayesian expert, how should I behave? I guess my likelihood probability is a Beta distribution, how do I encode document length? Which is a conjugate prior (I would like to avoid mcmc, given the processing time). should I parametrize the prior around the topic mean probability or around zero?
