[site]: crossvalidated
[post_id]: 161466
[parent_id]: 161450
[tags]: 
You're looking at so many comparisons there once you adjust for multiplicity, your cut off for significance is going to be tiny. In my very humble opinion, it also weakens the study to have so many categories, even though I can understand clinically why they would be of interest. I would suggest you just do a z test for proportions to compare the percent of each team that actually achieved the >16 sessions (don't forget to adjust for multiplicity) (and you can only do z test if npq>5, otherwise do chi square). It also begs the question- is there a reason you're interested in comparing your teams to each other? Might it not be more meaningful to categorize the outcome as either met guideline recommendations or didn't and do logistic regression? If you have data collected on each team, you might want to run a logistic regression model to determine predictors of meeting the NICE guideline recommendations for CBT. Eg practice volume, years in practice of MRP, patient SES etc, as this will inform what modifiable factors exist in teams that either increase or decrease guideline uptake. Unless you implemented educational interventions to improve uptake of CBT and are trying to compare groups? Then you could do logistic regression but include group as a categorical predictor to see if team/group was associated with the outcome of interest. I too am more clinician than statistician so take this with a grain of salt. Just my two cents! I'm sure many more qualified people here will have more to offer.
