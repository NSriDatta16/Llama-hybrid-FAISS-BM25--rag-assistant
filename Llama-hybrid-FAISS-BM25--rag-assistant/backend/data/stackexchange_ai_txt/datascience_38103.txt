[site]: datascience
[post_id]: 38103
[parent_id]: 9507
[tags]: 
So a couple of ways that can be conceived: @Miguel Gonzalez-Fierro's answer of 0-padding. probably the easiest to implement and makes sense. If padding is not sensible for your problem, if your output is a time series, you could learn a neural translation model of sorts and have a STOP/END token in your output. Have a generator based model (like an alteration on a VAE) and then generate a whole bunch of possible inputs, and you can take any # of draws that suffice some criterion (like a mode with little shift having some calculated conditional information). There are probably others, but I can't think of them right now.
