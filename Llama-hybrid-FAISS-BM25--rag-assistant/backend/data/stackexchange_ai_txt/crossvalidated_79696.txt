[site]: crossvalidated
[post_id]: 79696
[parent_id]: 79687
[tags]: 
I'll try. First you calculate a p-value based on the average data and how variable the data is. The more variable, the less likely to get a small p-value. On the other hand, if, for example, you are comparing two groups, the greater the difference between the averages of them, the smaller the p-value. Also, the variability of the data can be somewhat canceled out by having more data. Imaging two sets of data with the same difference between two averages and same amount of variability. In this case, the set with larger sample size will have smaller p-value. The test part is just seeing if the p-value is lower than some number. Usually people use .05, but this is arbitrary social custom. A lot of people think it makes no sense to use an arbitrary number, yet it is very common for historical reasons. Also keep in mind that just because your significance test says there is a difference between two groups does not mean you know why there is that difference. On the other hand, if the test says there is no significant difference, this could just be because your variability was too large and you didn't have enough data to get a low p value, it does not mean there is no actual difference. Edit: To summarize, lower p value means more evidence against the prediction: Difference from predicted result -> Down p-value More data -> Down p-value More variability -> Up p-value Down p-value means more evidence saying the prediction is false. Every prediction in history has been shown false to some decimal place.
