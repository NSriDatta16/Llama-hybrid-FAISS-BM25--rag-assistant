[site]: crossvalidated
[post_id]: 582262
[parent_id]: 497050
[tags]: 
If you are training neural network models, you will quickly find that validation performance is worse than training performance. This is OK as long as the validation error does not increase while the training error is decreasing. Personally, I call "overfitting" to "training error decreases and validation error increases". The difference between them is largely irrelevant as long as you don't have bugs.
