[site]: crossvalidated
[post_id]: 265873
[parent_id]: 265856
[tags]: 
There is a simple nonparametric prediction limit. Recall that a prediction limit is a procedure consisting of two independent samples $\mathcal{X}=x_1,\ldots, x_n$ and $\mathcal{Y}=y_1, \ldots, y_m$ , two statistics $t$ and $s$ , and a size $1-\alpha$ . When the chance that $s(\mathcal{Y})$ is less than $t(\mathcal{X})$ is $\alpha$ or smaller, we say that $t$ is a one-sided lower prediction limit for $s$ of size $1-\alpha$ . The PL in question uses the smallest of the $x_i$ for $t(\mathcal{X})$ . It is intended that all the $y_j$ should equal or exceed the PL with high probability. Equivalently, $s(\mathcal{Y})$ is the smallest of all the $y_j$ . This PL works when the $n$ observations are independent and identically distributed and the $m$ additional observations are also iid and independent of the first $n$ observations. These assumptions imply all $n+m$ observations are exchangeable, which in turn (easily) implies the smallest observation of them all is found among the first $n$ with probability at least $n/(n+m)$ . The size is the chance that one (at least) of all the observations tied for smallest lies within the $n$ values of $\mathcal{X}$ . This chance is no smaller than $n/(n+m)$ . When the common underlying distribution is continuous, it is exactly $n/(n+m)$ . For example, the smallest of $n=95$ values is a $95\%$ lower prediction limit for $m=5$ additional values. The smallest of $n=10^6$ values is only a $50\%$ lower prediction limit for $m=10^6$ additional values. Similar considerations (requiring more combinatorial sophistication) are used to compute the coverage of any order statistic qua prediction limit. See section 5.4 of Hahn & Meeker for a synopsis ("Distribution-free prediction intervals to contain at least $k$ of $m$ future observations.") Reference Gerald J. Hahn and William Q. Meeker, Statistical Intervals, A Guide For Practitioners. J. Wiley & Sons, 1991.
