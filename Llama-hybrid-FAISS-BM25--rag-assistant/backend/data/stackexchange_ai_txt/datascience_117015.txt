[site]: datascience
[post_id]: 117015
[parent_id]: 
[tags]: 
Adding punctuation for a long text

I want to add punctuation to a long text (youtube transcript) before using a Transformer pipeline for summarization. I have found this answer here: original answer thus I have tried: from transformers import T5Tokenizer, TFT5ForConditionalGeneration tokenizer = T5Tokenizer.from_pretrained('SJ-Ray/Re-Punctuate') model = TFT5ForConditionalGeneration.from_pretrained('SJ-Ray/Re-Punctuate') input_text = 'the story of this brave brilliant athlete whose very being was questioned so publicly is one that still captures the imagination' inputs = tokenizer.encode("punctuate: " + input_text, return_tensors="tf") result = model.generate(inputs) decoded_output = tokenizer.decode(result[0], skip_special_tokens=True) print(decoded_output) While this is working fine with short sentences the token limit is 512 and I have text with lengths up to 13000 tokens. This is not a problem for summarization I use longformer model that has limits of 16000, but I would like to know the best strategy to add punctuation for a long text. How do you suggest splitting the text? other kinds of strategies? do you have a snippet of code? Thank you very much for your help
