[site]: crossvalidated
[post_id]: 540110
[parent_id]: 
[tags]: 
Using a different (but related) hypothesis for the prior in MAP

Say we have a general set of data $\mathcal{D} = \{\mathbf{x}_i, \mathbf{y}_i \}_{i \in N}$ of covariates $\mathbf{x}$ and observations $\mathbf{y}$ . Our problem is in fitting a known model $\mathbf{y}_i = f_\mathbf{p}()$ with parameters $\mathbf{p}$ . We can find a $\mathbf{p}^*$ that results in the lowest squared error of predictions for all individuals in our dataset, but that would in general not be that accurate. We could do standard linear regression to solve $\mathbf{p}_i = \mathbf{x}_i^T\beta + \epsilon_i$ , but we might be aware of some non-linear relationships (but not their exact form). So instead, we might opt for a black box model $\hat{\mathbf{p}}_i = \phi(\mathbf{x}_i; \theta)$ with parameters $\theta$ . In order to regularize this black box model I want to apply additional prior knowledge. Following from the Bayes rule we get: $$p(\theta \mid \mathbf{y}) \propto p(\mathbf{y} \mid \theta)p(\theta)$$ Since placing a prior over my black box parameters is difficult I was thinking about setting a prior over the parameters of $f$ instead since $\hat{\mathbf{p}}$ , and thus $\mathbf{y}$ , depend on $\theta$ (which would be quite easy in my case): $$\arg\max_{\theta} p(\mathbf{y} \mid \theta)p(\mathbf{p})$$ If my prior is set correctly, and $\phi(\mathbf{x}_i)$ can actually produce samples from this prior, then there is a set of parameters $\theta^*$ that I am implicitly using in this prior so that $p(\mathbf{p})$ approximates $p(\theta)$ . Technically using $p(\mathbf{p})$ to regularize my likelihood function should not be much of a problem, and I understand I'm not actually getting the exact posterior $p(\theta \mid \mathbf{y})$ . But what posterior am I getting in this case? I was thinking, if my black box model is a sufficiently good function approximator, and my data is rich in information, am I then not at least approximating the posterior? Any ideas? I have never seen anybody use a different prior than the parameters in the likelihood function. EDIT: Here's a dummy example: Let's focus on our black box model $\phi(\cdot)$ being a regular feedforward Neural Network of ~2-3 hidden layers with weights $w$ and biases $b$ so that $\theta = \{w, b\}$ . We could make this a Bayesian Neural Network by including variance terms, but instead we could perform a MAP estimation to only get point estimates of $\hat{\theta}$ , allowing us to use regular gradient descent methods to train our model. The prior $p(\theta)$ would still be a multivariate normal distribution. Let's solve some biological system, for example one simulated by Lotka-Volterra equations: $$\frac{dy_1}{dt} = \alpha y_1 - \beta y_1 y_2$$ $$\frac{dy_2}{dt} = \delta y_1 y_2 - \gamma y_2$$ We might have measured the number of rabbits ( $y_1$ ) and foxes ( $y_2$ ) so that $\mathbf{y}(t) = [y_1(t), y_2(t)]$ indexed by timepoints $t$ and want to learn $\mathbf{p} = [\alpha, \beta, \delta, \gamma]$ . $i \in N$ could represent different areas where we have measured the number of animals. At each area we have also measured $\mathbf{x}_i$ with information of whatever factors also relevant for rabbit and fox survival (other than foxes eating rabbits). In a different country, a similar study was done describing how they found $\mathbf{p}$ was distributed. Now we wish to use this prior information when creating our model, however translating the $p(\mathbf{p})$ into $p(\theta)$ is difficult. I see three options for this: Use some method in the literature for initializing neural network $\theta$ as to constrain its output $\mathbf{p}$ . There is however not really a good consensus in the literature on how to do this well. First train a Bayesian Neural Network on a simulated dataset of $\mathbf{x}$ (containing the full expected range of values) and minimize the KL divergence of the resulting distribution with respect to $p(\mathbf{p})$ . This way we get a $p(\theta)$ satifying $p(\mathbf{p})$ , and we can use that as a prior in our real problem. Use $p(\mathbf{p})$ directly as the prior. In this case I am not sure why we could not just do option 3? Especially when performing a MAP doesn't that just mean we simply put higher density at model output similar to the prior and in a way propagating this density to some set $\theta^*$ (which could have been $p(\theta)$ )?
