[site]: crossvalidated
[post_id]: 570378
[parent_id]: 570104
[tags]: 
I think the source of confusion comes from the word observation and it's meaning in various contexts. I have to confess that this book was not my first statistical book read and perhaps this helped me to handle that easier. The paragraph from Page 207 I understand it as: Under the random sampling model each $X_i$ is an observable distinct random draw produced by the same phenomenon (statistical population described by an assumed variable) and each $X_i$ has a marginal distribution given by $f(x)$ . In different wording we can say that the random sampling model is the assumption that all random variables $X_i$ which are distinct have the same distribution because they are occurrences of the same phenomenon. Because they are produced by the same process they are observations of the same population. They still are distinct because they have independent error components. This interpretation of word observation is consistent with surrounding paragraphs. For example: The random sampling model describes a type of experimental situation in which the variable of interest has a probability distribution described by $f(x)$ . If only one observation $X$ is made on this variable, then probabilities regarding $X$ can be calculated using $f(x)$ . and continues In most experiments there are $n \gt 1$ ... repeated observations made on the variable, the first observation is $X_1$ ... And immediately after your cited paragraph we have: Furthermore the observations are taken in such a way that the value of one observation has no effect on or relationship with any other observations The last paragraph is illuminating since it operates the distinction of the two components of an observation: it's value / outcome / data point and it's random variable. The paragraph states the value of one observation does not influence how other values are produced. It also states that the random variables which models each observation does not have any conditional leak of any sort. In all those paragraphs other than the last one, they don't talk about values or outcomes. It talks only about how one can choose to model some random variables if we assume they are produced by the same phenomena. One cannot talk about any statistical property of a value. The value of an observation is dead from a probabilistic point of view. The associated random variable which produced that value can be used for that. To me, a natural way to understand the word observation is as an unique occurrence, measurement or snapshot of some source which has an value where random noise is incorporated (observation result) which can be seen (if observable) or not (if hidden) and has an associated random variable (implicitly a probability distribution, sample space and so on) which describes the process. Sometimes I shortcut the terms and use observation to point to the random variables (like here in the random sample definition) and sometimes to point out the pieces of data (for example when we have a sample of that data). Somehow, it is still clear in my mind and well separated. Later edit (I forgot to comment on your interpretation): Under the random sampling model each $x_i$ is an observation on the same variable and each $X_i$ has a marginal distribution given by $f(x)$ . This looks wrong to me since if each $x_i$ is the outcome of the same variable ( $X$ perhaps, certainly not any of $X_i$ since there are more than one variables there), than on which basis $X_i$ have the same marginal?
