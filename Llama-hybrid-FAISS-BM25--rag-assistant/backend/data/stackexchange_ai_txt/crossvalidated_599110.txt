[site]: crossvalidated
[post_id]: 599110
[parent_id]: 515824
[tags]: 
The "best" solution is going to be domain dependent. Most proposed solutions to deal with mixed frequencies or different timestamps fall into some flavor of the two categories below. Binning and aggregations (what you've already suggested) --> Information loss Oversampling/imputation --> Increased bias and memory requirements Oversampling would do something like grab the timestamps of the highest frequency time series and use them for synchronization or make a new clock that has a higher sampling rate than all series you are summing. To synchronize all timeseries before performing a mathematical operation you would set timestamps for all series to be equal based on the clock from above and perform some imputation for timestamps where you do not have data. Literature exists for more advanced imputation methods, but imputation may be as simple as using the last observed value or a linear interpolation between the last and next observed value. At this point all your series should have the same timestamps and performing any operations on them should be straight forward. I'm aware of the following R library and function that implements a method that falls into the binning category where the bins are essentially variable and aggregation chooses the most recent observation in a bin: https://rdrr.io/rforge/highfrequency/man/refreshTime.html
