[site]: crossvalidated
[post_id]: 276211
[parent_id]: 275677
[tags]: 
Consider the small dataset (illustrated below) with mean $\bar x \approx 0$ , say that you conducted a two-tailed $t$ -test with $H_0: \bar x = \mu$ , where $\mu = -0.5$ . The test appears to be insignificant with $p > 0.05$ . Does that signify that your $H_0$ is true? What if you tested against $\mu = 0.5$ ? Since the $t$ distribution is symmetric, the test would return a similar $p$ -value. So you have approximately the same amount of evidence that $\mu = -0.5$ and that $\mu = 0.5$ . The above example shows that small $p$ -values lead us away from believing in $H_0$ and that high $p$ -values suggest that our data is somehow more consistent with $H_0$ , as compared to $H_1$ . If you conducted many such tests, then you could find such $\mu$ that is most likely given our data and in fact you would be using semi- maximum likelihood estimation . The idea of MLE is that you seek for such value of $\mu$ that maximizes the probability of observing your data given $\mu$ , what leads to likelihood function $$ L(\mu | X) = f(X | \mu) $$ MLE is a valid way of finding the point estimate for $\hat\mu$ , but it tells you nothing about probability of observing $\hat\mu$ given your data. What you did is you picked a single value for $\hat\mu$ and asked about probability of observing your data given it. As already noticed by others, $f(\mu|X) \ne f(X|\mu)$ . To find $f(\mu|X)$ we would need to account for the fact that we tested against different candidate values for $\hat\mu$ . This leads to Bayes theorem $$ f(\mu|X) = \frac{ f(X|\mu) \, f(\mu) }{ \int \, f(X|\mu) \, f(\mu) \, d\mu } $$ that first, considers how likely are different $\mu$ 's a priori (this can be uniform, what leads to results consistent with MLE) and second, normalizes for the fact that you considered different candidates for $\hat\mu$ . Moreover, if you ask about $\mu$ in probabilistic terms, you need to consider it as a random variable, so this is another reason for adopting Bayesian approach. Concluding, hypothesis test tells you if $H_1$ is more likely then $H_0$ , but since the procedure needed you to assume that $H_0$ is true and to pick a specific value for it. To give an analogy, imagine that your test is an oracle. If you ask her, "the ground is wet, is it possible that it was raining?" , she'll answer: "yes, it is possible, in 83% of cases when it was raining, the ground become wet" . If you ask her again, "is it possible that someone just spilled the water on the ground?" , she'll answer "sure, it is also possible, in 100% of cases when someone spilled water on the ground, it become wet" , etc. If you ask her for for some numbers, she will give them to you, but the numbers would not be comparable . The problem is that the hypothesis test/oracle operates in a framework, where she can give conclusive answers only for the questions asking if the data is consistent with some hypothesis , not the other way around, since you are not considering other hypotheses.
