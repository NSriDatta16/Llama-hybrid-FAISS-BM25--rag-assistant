[site]: datascience
[post_id]: 118523
[parent_id]: 118499
[tags]: 
You can absolutely do this. Whether it's optimal depends on the missingness mechanism. If the missing values in this column are independent of other columns, then this is probably the best possible handling. If not, then it's hard to say: maybe a missing value here doesn't actually contribute new signal for higher default rate, because these rows also have other feature values that already account for that increase. I'm not sure there's a great way to tease this out beside cross-validating different imputation strategies. You do need to be careful when looking at the target in preprocessing, but it's not necessarily leakage. You need to be doing this just on the training set/folds: if you perform this analysis on the entire dataset (including your test sets/folds), then you have leakage and cannot trust your scores as unbiased. But if you do this analysis only on training, then it's fine. Your model gets perhaps access to more information, but the model eventually stares at the training targets anyway. You might want to more strongly regularize your final model to reduce overfitting, but the test scores will be unbiased in any case. Notice that there's a reasonably common strategy that reveals even more information directly to the model: "target encoding" replaces the categories with their average target value.
