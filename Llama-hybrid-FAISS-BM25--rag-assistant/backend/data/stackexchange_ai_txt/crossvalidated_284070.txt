[site]: crossvalidated
[post_id]: 284070
[parent_id]: 252015
[tags]: 
We know from intuition of the necessity of the Bessel correction that $$\arg\min_x \sum_{j=1}^n (x_j - x)^2 = \bar{x},$$ the sample mean. It similarly turns out that $$\arg\min_x \sum_{j=1}^n |x_j - x| = \mathrm{med}(x_1, \dots, x_j),$$ the sample median. Commonly in regression, we minimize the squared error, giving us estimates for the mean, but, if we were to instead minimize the absolute error, we'd get estimates for the median. Of course, when the the regression model is $y \sim \mathcal{N}(X \beta^*, \sigma^2I)$, the median is the mean so the differences between these two methods aren't too pronounced. Indeed, I've commonly seen quantile regression motivated as being useful in the presence of outliers. An interesting history of the use of absolute error in regression is included here (in section 2): Portnoy, S., & Koenker, R. (1997). The Gaussian Hare and the Laplacian Tortoise: Computability of Squared-Error versus Absolute-Error Estimators. Statistical Science, 12(4), 279â€“300. It's discussed that the idea to use this loss was had long ago, but, due to computational intractability, it didn't gain widespread attention. More generally, we could this is an example of quantile regression , which just installs weights into the absolute error that works for the median.
