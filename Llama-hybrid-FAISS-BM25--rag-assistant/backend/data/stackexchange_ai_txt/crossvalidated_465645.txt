[site]: crossvalidated
[post_id]: 465645
[parent_id]: 465639
[tags]: 
First you should understand that why we moved to Random forest or AdaBoost. We always want our model to have low bias and low variance. Suppose you train a pure decision tree which has low-bias and high-variance, so now if we use Random Forest then we will get a low-variance in the model with the almost same bias(because of Bootstrap technique in random forest).So here in this case Random Forest is a good option to use instead of pure decision tree to achieve low variance in the model. Now let suppose you train a very shallow decision tree which results in high-bias and low variance model. Now using the AdaBoost you can get a low-bias and low-variance model(because off additive weight technique in AdaBoost). So in this case AdaBoost is a good option instead of pure decision tree to achieve low bias in the model. So it depends on the bias and variance of the model you are training. If your pure decision tree is already giving you a low-bias and low-variance model then there may not be much significant improvement over using either Random Forest and AdaBoost. Random Forest and AdaBoost are techniques to reduce the variance and bias in the model respectively.
