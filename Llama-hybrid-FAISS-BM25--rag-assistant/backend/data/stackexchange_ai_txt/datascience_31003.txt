[site]: datascience
[post_id]: 31003
[parent_id]: 30999
[tags]: 
Your approach seems fair enough. Create a low dimensional vector of text features or if your corpus of text is small (like in comments) then make a bag of words representation or tf-idf based word scoring (after cleaning) and use them as normal features by flattening them with other features. The thing is if you go with word embeddings and when you want to un-blackbox the model you had created based on text, it can be hard as each individual dimension in word2vec does not hold any meaning. So start with bad of words and move to embeddings and see the metrics.
