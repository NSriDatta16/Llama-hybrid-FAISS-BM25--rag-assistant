[site]: crossvalidated
[post_id]: 388977
[parent_id]: 
[tags]: 
Regarding drop in test accuracy of one fold in 5 fold cross validation

I am training and testing a convolution neural network for binomial classification with 5 fold cross-validation. The data set has 4684 3 dimensional arrays of shape (2000,102,1). This is a sparse data set with values between 0 and 1 in only one column of a row. The network consists of one cnn layer, maxplooling, drop out, fully connected and finally output layer. I also set aside 0.1 percent of training data for validation. Sorry, I am unable to provide code as this is for research purpose. I am looking to understand why suddenly one fold test accuracy of my 5 fold cross validation falls to 0. I see that the 4 folds are giving 95 percent test accuracy but one fold is giving 0 test accuracy. Thanks
