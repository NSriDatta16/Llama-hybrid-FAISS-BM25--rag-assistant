[site]: crossvalidated
[post_id]: 209546
[parent_id]: 897
[tags]: 
The term "online" is overloaded, and therefore causes confusion in the domain of machine learning. The opposite of "online" is batch learning. In batch learning, the learning algorithm updates its parameters after consuming the whole batch, whereas in online learning, the algorithm updates its parameters after learning from 1 training instance. Mini batch learning is the halfway point between batch learning on one end and online learning on the other extreme. Also, "when" the data comes in, or whether it is capable of being stored or not, is orthogonal to online or batch learning. Online learning is deemed to be slower to converge to a minima , when compared to batch learning. However, in cases where the entire dataset doesn't fit in memory, using online learning is an acceptable tradeoff.
