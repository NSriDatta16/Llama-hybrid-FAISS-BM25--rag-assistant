[site]: crossvalidated
[post_id]: 515122
[parent_id]: 514944
[tags]: 
From what I understand, your query concerns whether it is "correct" to compare the Bayes estimators, belonging to a "Bayesian paradigm", with other frequentist estimators such as maximum likelihood or method of moments estimators, which belong to a "frequentist paradigm". And that this is essentially a question of whether these estimators, generated under different paradigms, are commensurable according to the metric of mean squared error. To the best of my understanding, one can compute Bayes estimators without necessarily adopting Bayesian semantics nor the epistemology - in this case, the frequentist would view Bayes estimators purely as an algorithmic procedure for generating a point estimator. That is, after setting up the Bayesian machinery of a posterior, and computing the posterior mean, you then retain the subsequent estimator $\hat{\theta}(x) = \mathbb{E}[\theta | X = x]$ , and bin the semantics and interpretation - $\hat{\theta}$ is now just one of many possible point estimators. On this basis, I see no reason why two competing point estimators cannot be compared on the basis of mean squared error. However, if you want to retain the Bayesian semantics and epistemology of the Bayes estimator, that is, to treat the parameter $\theta$ not as fixed unknown number, but a random variable whose uncertainty is captured by a distribution, and say compare it to a maximum likelihood estimator $\tilde{\theta}$ by comparing the MSE of $\hat{\theta}$ and $\tilde{\theta}$ , then I think there might be good reasons to question the use of MSE. In that it is a frequentist metric whereby the "quality" of an estimator is measured by its proximity to a fixed, "true", unknown parameter $\theta$ . However, on this latter point I am unsure, and would be keen to hear from a seasoned statistician about this. As a side-note, in the contexts in which I've encountered theoretical statistics, that is, in statistical machine learning, metrics such as mean-squared error are only a preliminary stepping stone for evaluating the quality of estimators. I cannot speak for theoretical statistics, but I know that in statistical machine learning, there is much more of a focus on using the more formal framework of minimax theory to evaluate the quality of estimators.
