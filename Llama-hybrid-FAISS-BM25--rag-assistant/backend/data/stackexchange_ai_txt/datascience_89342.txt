[site]: datascience
[post_id]: 89342
[parent_id]: 89326
[tags]: 
The Bayesian optimization algorithm selects points to test based on a balance between exploring uncertain regions and exploiting high-performing regions. But before you've tested very many points, there's not much information to go on. So, in this implementation you can specify a number of completely-at-random points to evaluate to start, and after that the actual Bayesian exploration begins. Setting a high number of random points gives you guaranteed "exploration" points; indeed, in the documentation for the package bayesian-optimization , we find: init_points : How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space. (The default is 5 in that package, and 3 times the dimension in keras-tuner .) That said, you can also make the algorithm focus more or less on exploration/exploitation directly, using the beta parameter ( kappa in bayesian-optimization , see this example notebook ).
