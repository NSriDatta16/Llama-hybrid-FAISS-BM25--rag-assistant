[site]: crossvalidated
[post_id]: 458425
[parent_id]: 
[tags]: 
tensorflow high validation acuraccy but bad predictions

I asked this over at stackoverflow but this seems to be the specific place to ask machine learning questions so hopefully I can get more answers. Anyways I am trying to make a multiclassed multilabel neural network. My training result after 20 epoch is loss: 0.1121 - accuracy: 0.9591 while my validation results are loss: 0.2006 - accuracy: 0.9405 . I then used model.predict to test things out but the results were quite bad. I even tested on the images I used for training and I got: [0.1367569 0.2681733 0.0271427 0.3046791 0.01867249 0.05539117 0.00498121 0.00070545 0.03091554 0.00495859 0.00811522 0.01736604 0.02292746 0.00100211] But I should of have got: [0 1 0 0 0 0 0 0 0 0 1 0 0 0] I saw this thread and changed my momentum but 0.01 but that still doesn't seem to change things much. It said something about using the wrong batch mean so I'm assuming its related to that and somehow training and evaluating is different from predicting? Anyways here is my code: if silence_debug: import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' import tensorflow as tf from tensorflow.keras.models import load_model from tensorflow.keras import layers, models, backend from tensorflow.keras.preprocessing.image import ImageDataGenerator import pandas as pd #load images df=pd.read_csv("/content/drive/My Drive/trainlist.csv") columns = [ "Atelectasis", "Cardiomegaly", "Effusion", "Infiltration", "Mass", "Nodule", "Pneumonia", "Pneumothorax", "Consolidation", "Edema", "Emphysema", "Fibrosis", "Pleural Thickening", "Hernia", ] datagen = ImageDataGenerator( rescale=1./255., rotation_range=7, horizontal_flip=True, ) traindata = datagen.flow_from_dataframe( dataframe=df[:76800], directory="/content/traindata/traindata", x_col="filename", y_col=columns, color_mode='grayscale', batch_size=8, class_mode="raw", target_size=(448,448), shuffle=False, ) #load model if load: #load saved model print("Loading model") model = load_model('/content/drive/My Drive/net_1.h5') else: #create model def identity_block(input_tensor, filters): f1, f2, f3 = filters axis = 3 if backend.image_data_format() == 'channels_last' else 1 #conv1 res = layers.Conv2D(f1, (1,1), 1)(input_tensor) res = layers.BatchNormalization(axis=axis, momentum=0.01)(res) res = layers.Activation('relu')(res) #conv2 res = layers.Conv2D(f2, (3,3), 1, padding='same')(res) res = layers.BatchNormalization(axis=axis, momentum=0.01)(res) res = layers.Activation('relu')(res) #conv3 res = layers.Conv2D(f3, (1,1), 1)(res) res = layers.BatchNormalization(axis=axis, momentum=0.01)(res) res += input_tensor res = layers.Activation('relu')(res) return res def conv_block(input_tensor, filters, stride=2): f1, f2, f3 = filters axis = 3 if backend.image_data_format() == 'channels_last' else 1 #conv1 res = layers.Conv2D(f1, (1,1), 1)(input_tensor) res = layers.BatchNormalization(axis=axis, momentum=0.01)(res) res = layers.Activation('relu')(res) #conv2 res = layers.Conv2D(f2, (3,3), stride, padding='same')(res) res = layers.BatchNormalization(axis=axis, momentum=0.01)(res) res = layers.Activation('relu')(res) #conv3 res = layers.Conv2D(f3, (1,1), 1)(res) res = layers.BatchNormalization(axis=axis, momentum=0.01)(res) #shortcut, resizes input so it can be added with res shortcut = layers.Conv2D(f3, (1,1), stride)(input_tensor) shortcut = layers.BatchNormalization(axis=axis, momentum=0.01)(shortcut) res += shortcut res = layers.Activation('relu')(res) return res #model layerinput = layers.Input(shape=(448, 448, 1)) layerlist = layers.Conv2D(64, (7,7), 2, activation='relu', padding='same')(layerinput) layerlist = layers.MaxPooling2D((3,3), 2, padding='same')(layerlist) #resblock 3x layerlist = conv_block(layerlist, (64, 64, 256), 1) layerlist = identity_block(layerlist, (64, 64, 256)) layerlist = identity_block(layerlist, (64, 64, 256)) layerlist = identity_block(layerlist, (64, 64, 256)) #maxpool layerlist = layers.MaxPooling2D((3,3), 2, padding='same')(layerlist) #resblock 3x layerlist = conv_block(layerlist, (128, 128, 512)) layerlist = identity_block(layerlist, (128, 128, 512)) layerlist = identity_block(layerlist, (128, 128, 512)) layerlist = identity_block(layerlist, (128, 128, 512)) #resblock 5x layerlist = conv_block(layerlist, (256, 256, 1024)) layerlist = identity_block(layerlist, (256, 256, 1024)) layerlist = identity_block(layerlist, (256, 256, 1024)) layerlist = identity_block(layerlist, (256, 256, 1024)) layerlist = identity_block(layerlist, (256, 256, 1024)) layerlist = identity_block(layerlist, (256, 256, 1024)) #resblock 5x layerlist = conv_block(layerlist, (512, 512, 2048)) layerlist = identity_block(layerlist, (512, 512, 2048)) layerlist = identity_block(layerlist, (512, 512, 2048)) layerlist = identity_block(layerlist, (512, 512, 2048)) layerlist = identity_block(layerlist, (512, 512, 2048)) layerlist = identity_block(layerlist, (512, 512, 2048)) #fully connected layer layerlist = layers.AveragePooling2D((7,7), padding='same')(layerlist) layerlist = layers.Flatten()(layerlist) layerlist = layers.Dense(2048, activation='relu')(layerlist) layerlist = layers.Dense(14, activation='sigmoid')(layerlist) model = models.Model(inputs=layerinput, outputs=layerlist) #print (model.summary()) model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"]) #train model try: model.fit( x=traindata, epochs=1, verbose=1, ) print("\nsaving model") model.save('/content/drive/My Drive/net_1.h5') except Exception as e: print('\n', e)
