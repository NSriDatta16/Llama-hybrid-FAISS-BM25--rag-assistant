[site]: crossvalidated
[post_id]: 571935
[parent_id]: 
[tags]: 
How is an embedding space optimized with respect to the loss function?

I understand that the point of the embedding layer is to reduce the dimensionality of the input space while also projecting it onto a space that represents the similarity between the medium in question (eg. an image, a word, n-gram, etc). What I can't understand is how the embedding vector for each point in the training space is updated. I understand that the embedding vector would start as a random vector. But how does optimization (eg. gradient descent, ADAM) update these vectors? Is the gradient applied pointwise like we do when updating neural network weights? So like this: $$W = W + dW$$ , or is there some other method?
