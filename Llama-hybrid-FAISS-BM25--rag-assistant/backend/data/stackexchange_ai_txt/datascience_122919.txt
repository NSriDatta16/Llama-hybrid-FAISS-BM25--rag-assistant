[site]: datascience
[post_id]: 122919
[parent_id]: 31259
[tags]: 
"Test" is often misleadingly used instead of "validation". Even academic literature sometimes use them interchangeably, while they are not. It is correct, as you say, to discard the validity of "test" data if we use it during training to decide when to stop the training. In such case, the correct word is "validation" data. Validation data is by definition the data you use to verify your model can still generalize well. A model overfitting to its training data will have its validation loss increase. However, to hold more reliable assumptions about generalization, we may use a held-out, so called, "test" set on which we test the model, once we decided to freeze the model's parameters for good. But after doing so, you may wonder: why choosing one train/validation/test configuration rather than another random one from your dataset? To answer this problem and get even stronger assumptions on the generalization capabilities of our model, we can use cross-validation which is considered a fairly robust evaluation method in machine learning. Eventually, all assumptions we make about the loss of our model on some set of data is subject to statistics, in which generally we cannot draw clear conclusions.
