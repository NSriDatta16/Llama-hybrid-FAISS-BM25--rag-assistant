[site]: crossvalidated
[post_id]: 603191
[parent_id]: 
[tags]: 
In the Bernoulli distribution $P(x^{(i)} ; \theta)=\theta^\color{red}{x^{(i)}}(1-\theta)^{(1-\color{red}{x^{(i)}})}$ what does $x^{(i)}$ stand for?

I am trying to understand the Bernoulli example for the biais given in Deep Learning by Bengo et. al. in 5.4.2: Consider a set of samples $\{\color{red}{x^{(1)}, . . . , x^{(m)}}\}$ that are independently and identically distributed according to a Bernoulli distribution with mean $\theta$ : $$ P\left(\color{red}{x^{(i)}} ; \theta\right)=\theta^\color{red}{x^{(i)}}(1-\theta)^{\left(1-\color{red}{x^{(i)}}\right)} . $$ I don't get what $x^{(i)}$ are. Indeed I used to remember a Bernoulli distribution probability equation like this one: $$ P\left(x ; \theta\right)=\theta^{x}(1-\theta)^{\left(1-x\right)}$$ Where we only have two outcomes. Therefore I don't get the demonstration: A common estimator for the $\theta$ parameter of this distribution is the mean of the training samples: $$ \hat{\theta}_m=\frac{1}{m}\sum_{i=1}^m x^{(i)} $$ To determine whether this estimator is biased, we can substitute equation 5.22 into equation 5.20: $$ \begin{aligned} \operatorname{bias}\left(\hat{\theta}_m\right) & =\mathbb{E}\left[\hat{\theta}_m\right]-\theta \\ & =\mathbb{E}\left[\frac{1}{m} \sum_{i=1}^m x^{(i)}\right]-\theta \\ & =\frac{1}{m} \sum_{i=1}^m \mathbb{E}\left[x^{(i)}\right]-\theta \\ & =\frac{1}{m} \sum_{i=1}^m \sum_{\color{red}{x^{(i)}=0}}^{\color{red}1}\left(x^{(i)} \theta^{x^{(i)}}(1-\theta)^{\left(1-x^{(i)}\right)}\right)-\theta \end{aligned} $$ Why do we go from ${x^{(i)}=0}$ to 1? Do we get from the outcome i with 0 probability of outcome to the very sure outcome?
