[site]: crossvalidated
[post_id]: 562442
[parent_id]: 
[tags]: 
How to perform data augmentation with traditional machine learning algorithms?

I am currently working on a multi-class image classification project, in which I have to use traditional machine learning and feature extraction methods (no convolutional neural networks). I know data augmentation is basic step for CNNs, allowing the network to generalize as, at each batch, images are loaded with different transformations (as flipping, rotation, zooming, etc.). However, I am having troubles to imaging it applied to traditional ML algorithms such as SVM or KNN, as they receive all the training examples at once, so these data are in a certain way "static". Let's say I have 1000 training images. At this point, I have doubled my training dataset, training my model on both original and flipped images (for a total of 2000 images). What should I do if I also want to use more augmentation techniques, e.g. rotations? Should I further duplicate training images with random rotation (reaching size 3000 or higher), or instead rotate the ones I already have (keeping size 2000), always avoiding overfitting? Thanks in advance.
