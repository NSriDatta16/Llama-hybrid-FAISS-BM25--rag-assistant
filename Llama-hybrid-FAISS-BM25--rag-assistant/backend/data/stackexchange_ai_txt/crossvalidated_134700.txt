[site]: crossvalidated
[post_id]: 134700
[parent_id]: 134650
[tags]: 
I think you need to be clear what distribution you need to represent. This differers according to what the cross validation is meant for. In the case that the cross validation is meant to measure (approximate) the performance of the model obtained from this particular training set, the corresponding distribution would be the distribution of cases in the training set at hand. From that perspective, you draw almost the entire population, though without replacement. In contrast, if you are asking about the distribution of $n$ cases drawn from the population the training set was drawn from, then the cross validation resampled surrogate training sets are correlated. See e.g. Bengio, Y. and Grandvalet, Y.: No Unbiased Estimator of the Variance of K-Fold Cross-Validation Journal of Machine Learning Research, 2004, 5, 1089-1105 . This is important for comparisons which algorithm performs better for a particular type of data.
