[site]: datascience
[post_id]: 66288
[parent_id]: 66015
[tags]: 
First, I don't think this problem can be addressed as a binary classification problem. Indeed, your current label (customer has or has not defaulted with others) is not reliable, as some customers who have not defaulted in the past might do so in the future, with you or others. Consequently, what comes to me as the first thing to try is one-class SVM (see the scikit-learn implementation ), because you can only rely on a single class (the 30% of your dataset which correspond to the default class). OCSVM is useful when you have only one class in your dataset, and also popular in problems where the classes are so imbalanced that some are likely to have too simple patterns. Theoretically, training an OCSVM over your default class and applying it to the other 70% will let you see which currently reliable customers are likely to default in the future. The distance to the separating hyperplane will even enable you to sort customers regarding their potential to default. However, in practice, it won't be an easy task : you will especially find it hard to choose a kernel and its hyperparameters without a proper validation dataset, including a certain number of customers who will not default. To prepare this validation dataset, I trust that you can collect some past data of both customers who defaulted and not. As soon as you can do this, find the best kernel / hyper-parameters with a classical validation approach, trying to lower the false negatives rate (use the recall score as your main guide). Please note that your problem is such that you will thus build a model to predict the risk of default for other customers. You might want to include data about customers who defaulted with your own company, and see if it changes the results.
