[site]: crossvalidated
[post_id]: 456081
[parent_id]: 
[tags]: 
test set R2 is higher than cross-validated R2. why?

I am running a random forest regression and have encountered a situation where my test-set performance is markedly better than my training/validation performance (as measured by R2), I'm unsure how/why this should be the case. For clarity, I initially started with a dataset of over 1000 features and 400 observations. Using K-fold CV with K=5, I have applied removed highly correlated features, and run recursive feature elimination to bring the feature-set down to about 90. I have then used gridsearch to fine-tune hyperparameters and have achieved a cross-validated R2 of 0.2, which is slightly above average for my particular problem. My thinking then was to obtain some more data to run as a test set, expecting this to score less than my CV performance but hopefully not too much lower. So, having found 65 more observations, I used the optimized random forest to predict target values in this new test set. Surprisingly, I am getting R2 on this test set of 0.26. I am at a loss to explain why the test set performance should be so much higher than the k-fold performance, given that all the tuning/feature selection was done on this dataset. I am assuming that I must have screwed up somewhere. I've tried googling the answer but cannot seem to make sense of similar queries.
