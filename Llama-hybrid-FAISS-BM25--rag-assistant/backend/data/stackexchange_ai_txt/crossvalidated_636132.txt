[site]: crossvalidated
[post_id]: 636132
[parent_id]: 
[tags]: 
How do I use GMM or LDV to handle a big problem with autocorrelation in a data frame spanning 1945-2018?

For an exam (results for this exam do not need to be entirely accurate and explain the all variations in our variable) I am doing an analysis of (all countries in the world) of whether parliaments with a higher percentage composition of women, tend to engage in less wars as aggressor. The data model I've created spans (a bit unrealistic for an analysis - I've had to recognize) 1945-2018. Not to my surprise I have now run into the problem of autocorrelation, after conducting a two-way fixed effects model. After reading through some material on how to deal with autocorrelation two methods are suggested as solutions as far as I can see; Lagged dependent variable (LDV) and GMM (Generalized Method of Moments). It has come to my attention that GMM might be a bit out of my reach in terms of complexity. However, which method do you suggest me using? And if so / what tips can you give me for writing the codes for these two methods. EDIT: I have now tried the following code to lag my dependent variable. However this still returns a significant p-value in the Breusch-Godfrey/Wooldridge test for serial correlation: # Create lagged dependent variable finaldatamerged $Dependent_Variable_Lag1 `Wars started`, 1) # Estimate a fixed effects model with the lagged dependent variable laggedfemodel $Dependent_Variable_Lag1 ~ Percent_women_in_parliament + finaldatamerged$ `Rate of liberal democracy`, data = finaldatamerged, model = "within", effect = "twoways") pbgtest(laggedfemodel)
