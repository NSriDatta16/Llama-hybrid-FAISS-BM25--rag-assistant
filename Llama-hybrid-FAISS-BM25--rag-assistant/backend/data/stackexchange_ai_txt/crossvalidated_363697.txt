[site]: crossvalidated
[post_id]: 363697
[parent_id]: 313163
[tags]: 
Theoretically what you said is right, that a GAN converges only when the discriminator cannot distinguish generated image from sampled image, but you can just think about how impossible it is. Images lie in $\mathbb{R}^n$, where $n$ is at least 784 (for MNIST). Just think about it, how can you capture a distribution in $\mathbb{R}^{784}$? In fact it has been proven that $p_{G}$ have no intersection with $p_{data}$ almost everywhere in a 2017 paper. Empirically, GAN convergence is hard to capture because GAN loss are always vibrating. What I use is to see how the generated samples look like and that may give some sense (after a sufficiently long time, say 20 epochs). Of course it is not an ideal method, but that is currently the only way.
