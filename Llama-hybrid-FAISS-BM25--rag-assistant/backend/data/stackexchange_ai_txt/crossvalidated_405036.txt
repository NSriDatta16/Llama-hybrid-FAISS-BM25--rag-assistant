[site]: crossvalidated
[post_id]: 405036
[parent_id]: 405034
[tags]: 
It's no different from using ReLU in any other context. In a feedforward network, a standard usage is $\text{ReLU}(Ax+b)$ . In a CNN, a standard usage is $\text{ReLU}(\text{convolution}(y))$ : all you do is apply the convolution operation and then the ReLU operation. It's not clear what you mean by "feature maps." The learned parameters of a convolution layer are sometimes called "feature maps" or "kernels". However, these are not the same thing as the output of a convolution operation applied to an image. The output of a convolution layer is just an image with a filter passed over it; this is what the ReLU operation is applied to.
