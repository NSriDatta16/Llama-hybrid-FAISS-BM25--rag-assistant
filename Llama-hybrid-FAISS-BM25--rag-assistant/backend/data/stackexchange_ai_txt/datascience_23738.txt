[site]: datascience
[post_id]: 23738
[parent_id]: 20403
[tags]: 
It seems that you are training on a very small dataset. A dataset of size 10000 samples will bring out less than 5k words after preprocessing, which I think isn't enough for your model to learn the relations. Try increasing your dataset and then train. Also, you can tune your parameters while training. Try changing window size (default is 5), embedding size and min count. Generally, 100 is a good embedding size, but you can tweak it and see what gives you better results. You can try using already trained word2vec model released by Google. It's 1.5GB and includes word vectors for a vocabulary of 3 million words and phrases that they trained on roughly 100 billion words from a Google News dataset.
