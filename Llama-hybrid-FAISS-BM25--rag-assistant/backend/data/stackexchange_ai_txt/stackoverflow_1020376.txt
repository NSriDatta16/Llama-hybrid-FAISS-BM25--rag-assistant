[site]: stackoverflow
[post_id]: 1020376
[parent_id]: 1019907
[tags]: 
You can first scan all present series for the distinct values (for example, aggregating them in a HashSet), then simply dump them into an array of dates (storing a match between date and index position in a dictionary). var distinctDates = allSeries .SelectMany(s => s.Values.Select(v => v.Date)) .Distinct() .OrderBy(d => d) .ToArray(); var datePositions = distinctDates .Select((d,index) => new { Date = d, Index = index }). .ToDictionary(x => x.Date, x => x.Index); Then, create a jagged array that has width of "NumberOfSeries" and length of "NumberOfDates". After that, do a second scan of all the data and dump them to their positions. var values = new float[allSeries.Length][]; for (var i=0;i I wrote this code without touching VisualStudio, so I may have a few typos. Or there may be used a few LINQ methods that are not present in the .NET (just look in Lokad.Shared.dll ). But you should be able to get the idea. Some more notes, while I'm at the topic: Go for the jagged array, if you have to keep everything in the memory at once. It is way more efficient than a dictionary and has a lot less memory problems than a rectangular array. Keep Value objects as small as possible (i.e.: float instead of double). If number of time serie values is expected to go large in the future, then never store values in database in a "one row per value". It is recommended to either go for something like HDF (which has a .NET interface) or use persist time serie fragments in binary form in DB (as in time serie databases ) Sticking to these should allow you to scale up to hundreds of millions of time values without a lot of problems (done that).
