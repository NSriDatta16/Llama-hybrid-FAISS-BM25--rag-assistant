[site]: datascience
[post_id]: 108730
[parent_id]: 49712
[tags]: 
It really depends on your use case. Whenever we talk about projects where speed and complexity do not play a role lemmatization is usually the better solution. It is also the better solution since it outputs actual words and not just word stems which do not have to be real words. Stemming is just preferred when you have to process a lot of words and are restricted in processing power. However, nowadays transformer models detect the meaning and context the words are used in pretty well. Then you don't need to preprocess the data with stemming or lemmatization.
