[site]: crossvalidated
[post_id]: 390283
[parent_id]: 
[tags]: 
Statistical conclusions based on conditional trees

I have a complex dataset, number of features is much bigger than number of samples. The question is - which features are important for classification into 2 groups. I think that (after some engeneering of features taking into account possible interactions) ctree is a good instrument for doing this. However I need to present results in a paper. Do I need to cross-validate ctree in order to be able to present some "significance", e.g. "feature X appears 10 times out of 12 as a root split - may be it is important"? I would go with random forest feature importance (and shuffle the labels to find p-values), but as far as I know RF is parametric and ctree is non-parametric which is preferable...
