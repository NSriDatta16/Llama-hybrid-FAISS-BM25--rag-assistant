[site]: crossvalidated
[post_id]: 485905
[parent_id]: 485888
[tags]: 
Pretty sure the statistical properties of bootstrap hold only for when n of your bootstrap sample equals the N of your actual sample so duplicates are necessary. This is pretty easy to see with some simulation of the sampling process in general, sampling without replacement and some arbitrary percentage of your N gives you, on average, more biased results. Bagging when it comes to predictors don't require N = n but as an approach it is very useful for increasing the bias and decreasing the variance when it comes to things such as trees. Bagging linear models will just converge to a normal linear model but you can use those estimates to do analysis on rather than standard formulas which is a fun thing to do. You are putting more weight on the duplicates for that specific draw but you are drawing hundreds or thousands of times.
