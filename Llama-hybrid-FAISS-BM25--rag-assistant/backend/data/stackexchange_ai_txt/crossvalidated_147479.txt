[site]: crossvalidated
[post_id]: 147479
[parent_id]: 
[tags]: 
How to make use of less data of a particular class for better modeling?

I have a dataset, say 9000 rows, with some features. Around 8000 belong to class 1 and 1000 to class 0. So, if I am creating a model with any method say SVM, LR, Random forest the model has a tendency to give more prediction to class 1. So I have two things in mind: a) I want to separate 8000 rows belonging to class 1 into 4 groups and use each group with those 1000 rows belonging to class 0 and create a model. After that I thought of averaging over the models. My first question is, averaging over the models as in theory means really what. Does it mean that we have to sum over the coefficients of each model and take the average? I am stuck with that part of averaging. And is my approach a good one? b) Another approach I am thinking of is to replicate the 1000 rows belongs to class 0 8 times to get 8000 rows of 0. So, total data will be 16000. Will the duplication result in new information? Will it tend to overfit? Is there any approach to deal with these unbalanced data?
