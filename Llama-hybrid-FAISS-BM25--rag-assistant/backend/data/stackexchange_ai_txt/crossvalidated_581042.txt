[site]: crossvalidated
[post_id]: 581042
[parent_id]: 575049
[tags]: 
In the attention model, the mask required is of the shape (batch, queries, keys) so in order to train the entire horizon (queries) on the last value (last key): def timeseries_sliding_window(length): """Returns a mask of shape (length, length) where only the last entry of the 2nd dimension is of relevance to all elements of the 1st """ return tf.concat([tf.zeros((length - 1, length)), tf.ones((1, length))], 0)
