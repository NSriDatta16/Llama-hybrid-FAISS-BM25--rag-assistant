[site]: crossvalidated
[post_id]: 59630
[parent_id]: 
[tags]: 
Test accuracy higher than training. How to interpret?

I've a dataset containing at most 150 examples (split into training & test), with many features (higher than 1000). I need to compare classifiers and feature selection methods which perform well on data. So, I'm using three classification methods (J48, NB, SVM) and 2 feature selection methods (CFS, WrapperSubset) with different search methods (Greedy, BestFirst). While comparing, I'm looking at training accuracy (5-fold cross-folding) and test accuracy. Here is one of the results of J48 and CFS-BestFirst: { "accuracyTraining" : 95.83, "accuracyTest" : 98.21 } Many results are like this, and on the SVM there are many results that indicate that test accuracy is much higher than training (training: 60%, test: 98%) How can I meaningfully interpret these kind of results? If it was lower, I would say it's overfitting. Is there something to be said about bias and variance in this case by looking all the results? What can I do to make this classification meaningful, such as re-selecting training and test sets or just using cross-validation on all data? I have 73 training & 58 test instances. Some answers didn't have this info when they were posted.
