[site]: crossvalidated
[post_id]: 624024
[parent_id]: 
[tags]: 
How do we obtain the posterior of a beta binomial mixture of continuous and a discrete density?

In section 3.6 of Jim Albert's 2009 book "Bayesian Computation with R" he describes a test of whether a coin is fair using a mixture of priors. The coin tossing follows a binomial distribution so the likelihood is $\binom{n}{y}p^y(1-p)^{n-y}$ . The prior is given as mixture: $$g(p) = 0.5\ I(p=0.5) + 0.5\ I(p \ne 0.5) \texttt{beta}(p, a, a)$$ The second term is a beta distribution and a previous section has covered mixtures with two such. But this mixture has on the left a function which is .5 when p=.5 and zero everywhere else. To apply Bayes rule to get the posterior $g(p|y)$ I multiply the likelihood by the prior for the numerator: $$ \binom{n}{y}p^y(1-p)^{n-y} \times \bigl( 0.5\ I(p=0.5) + 0.5\ I(p \ne 0.5) \ \texttt{beta}(p, a, a)\bigr) \tag{1} $$ For the denominator I must "integrate out" the parameter $p$ from (1) then the posterior is just numerator/denominator. My difficulty is that I cannot do this - I don't understand how to handle the indicator functions to obtain the posterior density. I attach an image of how Albert continues the discussion (note that there is no explanation of $f(y|p)$ which is perhaps the $p(y|p)$ , the binomial probability of $y$ given $p$ ?).
