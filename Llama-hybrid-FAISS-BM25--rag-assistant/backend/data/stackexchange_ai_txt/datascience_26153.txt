[site]: datascience
[post_id]: 26153
[parent_id]: 
[tags]: 
How regression algorithm works on categorical features

I have a dataset with features that most of them are nominal categorical features, I have converted my model to indicator values, Original F1,F2,L 1 ,1 ,50 2 ,3 ,30 After indicator values F1-1,F1-2,F2-1,F2-3,L 1 ,0 ,1 ,0 ,50 0 ,1 ,0 ,1 ,30 I used different regression algorithm (Poisson, Bayesian, Decision Tree reg, Decision Forest reg, Boosted decision tree reg, linear regression, neural network), but all of then have low performance (r2 ~ 20-30) Then I was thinking how regression can find values, then I found something interesting : relation of data with label They are like below picture But in most of the books and examples and samples suitable data for regression are like below And this is the point I got confused! So my question is how regression (or which algorithms) are suitable for predicting values in high categorical data
