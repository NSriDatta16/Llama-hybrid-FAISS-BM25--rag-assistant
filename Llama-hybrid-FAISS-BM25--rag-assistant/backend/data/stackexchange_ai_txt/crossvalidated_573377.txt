[site]: crossvalidated
[post_id]: 573377
[parent_id]: 573336
[tags]: 
In uncertain scenarios, where Bayesian optimization is employed, we are facing the exploration-exploitation tradeoff . The acquisition function is a solution for it. As you noticed, Bayesian optimization only approximates the target function. The approximation is imperfect, so we don't want to optimize it directly. Models like the Gaussian process are designed to do well at learning the uncertainties (covariances). Now recall how acquisition functions work, for example, the upper confidence bound (UCB) looks at values that are high in terms of mean $\mu$ and uncertainty $\sigma$ , $\mu + \beta\sigma$ , so you explore the areas where you are the most uncertain until the uncertainty is reduced enough that it doesn't play important role in the result. The same applies to other acquisition functions like expected improvement or probability of improvement. Thompson sampling overcomes this problem by sampling from the posterior distribution, so by randomizing the process according to the posterior probabilities. So acquisition function forces you to explore more rather than focusing on pure exploitation.
