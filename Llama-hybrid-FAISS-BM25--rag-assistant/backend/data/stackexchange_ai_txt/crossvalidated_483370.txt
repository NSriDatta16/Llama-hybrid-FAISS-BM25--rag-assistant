[site]: crossvalidated
[post_id]: 483370
[parent_id]: 483369
[tags]: 
It's a bit unclear from your question, but the correct sequence is: Split your data into training data (80%) and test data (20%). Split the training data into K "folds", typically 3 or 5. Use cross validation to find the best hyperparameters. This means that you train your model on 4 of the folds, then compute error/loss on the remaining fold. Do this for each fold, so if you have 5 folds you repeat this process 5 times. Train the model with the best hyperparameters on the entire training set, then compute error/loss on the test set. So to answer your questions: Yes, if I understand you correctly. The former. Compute the error of the model on each iteration, using the held-out data from the K-fold CV procedure. Use the average across all K iterations. Do not use the test set during cross validation.
