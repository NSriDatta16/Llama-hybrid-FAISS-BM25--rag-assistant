[site]: crossvalidated
[post_id]: 64436
[parent_id]: 64147
[tags]: 
A key reference explaining this is: @ARTICLE{pic90, author = {Picard, R. R. and Berk, K. N.}, year = 1990, title = {Data splitting}, journal = The American Statistician, volume = 44, pages = {140-147} } See also: @Article{mic05pre, author = {Michiels, Stefan and Koscielny, Serge and Hill, Catherine}, title = {Prediction of cancer outcome with microarrays: a multiple random validation strategy}, journal = {Lancet}, year = 2005, volume = 365, pages = {488-492}, annote = {comment on p. 454; validation;microarray;bioinformatics;machine learning;nearest centroid;severe problems with data splitting;high variability of list of genes;problems with published studies;nice results for effect of training sample size on misclassification error;nice use of confidence intervals on accuracy estimates;unstable molecular signatures;high instability due to dependence on selection of training sample} } In my own work I've found that data splitting requires training and test sample sizes approaching 10,000 to work satisfactorily.
