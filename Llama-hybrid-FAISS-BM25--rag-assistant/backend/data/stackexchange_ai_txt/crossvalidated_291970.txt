[site]: crossvalidated
[post_id]: 291970
[parent_id]: 
[tags]: 
SKLearn: SelectKBest Ignores Seemingly Relevant Features

I'm trying to predict engagement time for an article from the text of the article itself. I'm extracting a bunch of features such as number of words in article, number of characters in article, number of paragraphs in article, etc. Then I do TFIDF to get a ton more features. Finally, I do this: selector = SelectKBest(k=1000) X = pd.DataFrame(selector.fit_transform(X, y)) Effectively, I want to get the top 1,000 most relevant features. However, when I inspect it with: X.head() It looks like all TFIDF features; that is, it's implying that length of article in words or characters isn't a top 1,000 feature. This seems very wrong. Could someone tell me what I'm doing incorrectly? Thanks!
