[site]: crossvalidated
[post_id]: 531912
[parent_id]: 
[tags]: 
Relationship Between Binomial and Poisson Regressions to Get Treatment Effects

Let's say I'm at an e-commerce company running an experiment with a binary treatment and want to understand the % lift the treatment gives to products on average. A typical way to handle this might be a Poisson specification with 1 row in the data set per treatment-product pair. orders ~ b0 + b1*treatment + offset(log(exposure)) Then exp(b1)-1 would be the % lift. It's also possible to use binomial regression here with 1 row per product (though it's unusual): portion_of_orders_treated ~ b0 . Then (control_exposure/treated_exposure)*exp(b0)-1 would be the % lift. The idea here is Nt = exposure to treatment Nc = exposure to control CVR = control conversion rate (1+lift)*CVR = treatment conversion rate Ot = (1+lift)*CVR*Nt = expected orders in treatment Oc = CVR*Nc = expected orders in control p = portion of orders treated = Ot/(Ot+Oc) p/(1-p) = (Ot/(Ot+Oc))/(1-Ot/(Ot+Oc)) = Ot/Oc = (1+lift)*Nt/Nc in binomial reg log(p/(1-p)) = b0 => lift = exp(b0)*Nc/Nt - 1 I wanted to evaluate the differences between these approaches so I started to run some simulations and found something unusual: the models return the same lift estimates and the same standard errors for b1 (Poisson) and b0 (binomial) regressions. Going in I expected at least the standard errors to be different because my simulation did not use data coming from a Poisson distribution. Can anyone explain why the results are the same? I was told that this binomial approach had fewer assumptions than the Poisson approach, but I haven't been able to see that in the data. Interestingly, I think for the binomial model this would mean that the confidence intervals for the lift are different because the coefficient has the same standard error, but this error, after exponentiated, gets scaled by Nc/Nt as well. When I ran the simulation 10000 times the Poisson confidence interval contained the true effect 97.15% of the time, which is really close to the 97.5% I was aiming for, the binomial confidence interval contained the true effect 100% of the time (which seems too conservative given I was using 1.96 as the z score). More details on my simulation: Code to make a data set with a very skewed order distribution and 2x as much exposure (impressions) in control vs treatment. make_test_data % inner_join(tibble(x = 1, treated = c(1, 0)), by = 'x') %>% select(-x) %>% mutate( impressions = ifelse(treated == 0, impressions_control, impressions_treatment), conversion_true = case_when( treated == 0 & .05 * .5 ^ (product_id - 1) > .5 / impressions_control ~ .05 * .5 ^ (product_id - 1), treated == 0 ~ .5 / impressions_control / log10(product_id), treated == 1 & .05 * .5 ^ (product_id - 1) > .5 / impressions_control ~ (1 + treatment_effect) * .05 * .5 ^ (product_id - 1), treated == 1 ~ (1 + treatment_effect) * .5 / impressions_control / log10(product_id) ), conversion_true = conversion_true * 10, orders = rbinom(n = num_products * 2, size = impressions, prob = conversion_true) ) # widen the data for use in the binomial model products_wide % pivot_wider( id_cols = "product_id", names_from = "treated", values_from = c("impressions", "orders", "conversion_true") ) %>% mutate( orders_total = orders_0 + orders_1, p_orders_treatment = orders_1 / orders_total, impressions_total = impressions_0 + impressions_1, p_impressions_treatment = impressions_1 / impressions_total ) # return the two data sets return(list("binomial" = products_wide, "poisson" = products_long)) } For example, data might look like this for the binomial model and this for the possion model Then, the code to make the models make_models % filter(orders_total > 0), maxit = 100 ) return(list("binomial"=m_bionmial, "poisson"=m_poisson)) } Here's an example of the lift estimates and standard errors being equal:
