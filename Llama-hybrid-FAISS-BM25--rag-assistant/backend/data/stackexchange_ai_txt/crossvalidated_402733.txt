[site]: crossvalidated
[post_id]: 402733
[parent_id]: 
[tags]: 
What is the best way to represent uncertainty from linear interpolation?

A little background to this question: Part of my job is to conduct flood risk appraisals to help determine the viability of flood defence construction. There is a standardised way to do this, which uses flood depth data from a computer model and depth-damage data gathered from large scale flood events. It is understood that there is significant uncertainty in the raw data, but it still allows us to estimate the relative value of different defences. I have linearly interpolated between points on a flood damage-probability graph and integrated with respect to probability to find an average annual damage. As a way of quantifying the uncertainty in the interpolation, I have calculated an upper (blue dashed line in figure) and lower (red) bound of the interpolation as a way of quantifying the uncertainty in the interpolation. Although this gives quite extreme values, it allows comparison of the relative uncertainty between different data sets. EDIT: The value of a defence is its benefit, which is the cost avoided. e.g. A defence with 1% standard of protection will have a benefit equal to the area under the curve between 1% and 33% (x-axis limit). This means that the total area under the curve is never calculated, as defences normally have a standard of protection between 0.1% and 20%, and so outlying values do not contribute to the uncertainty in the benefit. My questions are: Is this an acceptable way of calculating the uncertainty of the method used? Given that there is also significant random error in the data points as well, is there a better way to represent the total uncertainty? e.g. Standard deviation assuming a normal distribution.
