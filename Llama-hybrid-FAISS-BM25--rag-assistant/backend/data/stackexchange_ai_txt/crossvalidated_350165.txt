[site]: crossvalidated
[post_id]: 350165
[parent_id]: 
[tags]: 
When predicting (not training) using neural networks, why would we have to specify a number of epochs?

I'm looking at code from a Google course on how to use Tensorflow. When explaining how to specify the function for generating predictions from an already trained model, the function they define takes a data frame and a number of epochs: def make_prediction_input_fn(df, num_epochs): return tf.estimator.inputs.pandas_input_fn( x = df, y = None, batch_size = 128, num_epochs = num_epochs, shuffle = True, queue_capacity = 1000, num_threads = 1 ) This doesn't make sense to me: isn't the number of epochs something specific to the training phase of a neural network? When you are predicting data, you just run the data set once through a network that has been already trained. Why would you need to specify a number of epochs?
