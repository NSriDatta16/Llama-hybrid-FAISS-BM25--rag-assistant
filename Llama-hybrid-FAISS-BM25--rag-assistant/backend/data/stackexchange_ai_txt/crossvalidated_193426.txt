[site]: crossvalidated
[post_id]: 193426
[parent_id]: 144378
[tags]: 
The cross entropy of an exponential family is always convex. So, for a multilayer neural network having inputs $x$, weights $w$, and output $y$, and loss function $L$ $$\nabla^2_y L$$ is convex. However, $$\nabla^2_w L$$ is not going to be convex for the parameters of the middle layer for the reasons described by iamonaboat.
