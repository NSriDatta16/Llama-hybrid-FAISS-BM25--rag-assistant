[site]: crossvalidated
[post_id]: 316657
[parent_id]: 
[tags]: 
How to evaluate actual vs. expected performance when expected performance is estimated with uncertainty?

Suppose person A is given 25 tasks to complete. For each task, the overall success rate across all people is $p$. Now we don't know $p$ so we estimate it somehow. Let's say we estimate $\hat{p}$ = 0.6 so we would expect an "average" skilled person to complete 60% of the tasks. Person A attempts the 25 tasks and completes 56% of them. The questions is, is person A "below average"? There seems to be at least 2 reasons why the answer would be no: It was due to randomness in the small sample size (n = 25). The 60% estimate of average performance is wrong. Perhaps the true value of $p$ is actually 0.55. The 2nd point is what my question is. How am I supposed to evaluate if someone is below average when there is uncertainty in what average is? I suspect this could be put into some sort of Bayesian framework, but like most people who only took a couple of prob/stats classes, none of them covered Bayesian methods so I'm not sure. Finally, my real life scenario has a few additional complications: The number of tasks will vary from person to person. The probability of success for each task is not a constant. Each task has a unique probability of success, $p_i$. I believe this results in a Poisson binomial distribution. I have a model (logistic regression) that gives an estimate of $p$ for task $i$. I found several examples that show the beta binomial conjugate prior, but none about what to do when $p$ varies. The above means each person would have a unique expected performance based on the (estimated) difficulty of tasks they happened to receive. In the end, if I were able to make a statement such as "I think there is an x% chance the true performance is below average", that would be very useful.
