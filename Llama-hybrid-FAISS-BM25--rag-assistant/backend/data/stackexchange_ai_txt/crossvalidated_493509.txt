[site]: crossvalidated
[post_id]: 493509
[parent_id]: 
[tags]: 
Frequency of mutants in a very large number of observations

During cellular division (generation of two cells from one) bacteria experience mutations, where a newly produced cell harbors altered genetic code. To measure the rate of this happening Max Delbr√ºck and Salvador Luria have designed an experiment from which it is possible to measure such mutation rate. Now, since mutation is a random event and it can arise any time during the growth of bacterial population the frequency of mutants can vary greatly between different populations when the population reaches its peak, because for example it exhausts the resources. Estimating the mutation rate solely on the frequency is thus not a sufficiently accurate measure. Now my question is the following: let's suppose we start with a single cell that has zero mutations, and at each time step each cell divides in two. After each division, one of the daughter cells can gain a mutation with probability $\mu$ , after gaining it, it doesn't lose it and as well each offspring has it. There is no death in such a population and each cell divides at the same rate (up until the exhaustion of resources, when it drops to zero). If we had the possibility to look at the frequency of mutants in a very large number of different bacterial populations (approaching infinity), would the average frequency be dependent on $\mu$ and what would it be? If not, what would it be in that case? A bit of background for better clarity: https://en.wikipedia.org/wiki/Luria%E2%80%93Delbr%C3%BCck_experiment
