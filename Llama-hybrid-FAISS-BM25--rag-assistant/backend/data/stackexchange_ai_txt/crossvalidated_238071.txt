[site]: crossvalidated
[post_id]: 238071
[parent_id]: 237966
[tags]: 
With solid statistical foundations, he argues the models should predict well out-of-sample. Assuming that by "the underlying statistical assumptions are rock-solid" and "solid statistical foundations" he means "accurate assumptions", this is wrong. Models with more accurate assumptions may make worse out-of-sample predictions. Domingos and Pazzani (1997) has an example of this: even with simulated data generated from a known, complex model, a simpler model can perform better than the true model. Domingos, P., & Pazzani, M. (1997). On the optimality of the simple Bayesian classifier under zero-one loss. Machine Learning, 29 , 103â€“130. doi:10.1023/A:1007413511361
