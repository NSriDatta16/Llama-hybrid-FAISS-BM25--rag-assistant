[site]: crossvalidated
[post_id]: 553302
[parent_id]: 
[tags]: 
How are the self-attention layer weigths updated?

I am trying to figure out how the updating of the weights in the self attention layer works. I think I have some basic understanding of how the self-attention mechanism works, however it is really unclear to me how loss on the language modeling task (I'm considering CLM as an example, but I am interested in an explanation for any LM task) is used to update the weights in the attention layers. From what I understand the state of the self attention mechanism should be considered "good" if the attention weights are "high" for tokens that are semantically correlated with the current token. The back-propagation step, however, only has information on the predicted token probabilities, and whether it was the correct token or not. So how does this information get used to update the attention weights so that they ouptut large score for semantically related tokens? Thanks!
