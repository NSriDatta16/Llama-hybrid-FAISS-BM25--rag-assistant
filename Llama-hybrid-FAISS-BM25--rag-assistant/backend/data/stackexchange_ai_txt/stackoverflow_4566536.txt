[site]: stackoverflow
[post_id]: 4566536
[parent_id]: 4534539
[tags]: 
There are a lot of different ways to implement neural networks that range from simple/easy-to-understand to highly-optimized. The Wikipedia article on backpropagation that you linked to has links to implementations in C++ , C# , Java , etc. which could serve as good references, if you're interested in seeing how other people have done it. One simple architecture would model both nodes and connections as separate entities; nodes would have possible incoming and outgoing connections to other nodes as well as activation levels and error values, whereas connections would have weight values. Alternatively, there are more efficient ways to represent those nodes and connections -- as arrays of floating point values organized by layer, for example. This makes things a bit trickier to code, but avoids creating so many objects and pointers to objects. One note : often people will include a bias node -- in addition to the normal input nodes -- that provides a constant value to every hidden and output node.
