[site]: crossvalidated
[post_id]: 561304
[parent_id]: 
[tags]: 
Logistic regression - are interaction terms redundant vs original features if using L1 penalization for feature selection?

I am running lasso/elastic regression for feature selection in a logistic classifier. I have two continuous features, and was wondering if it would be redundant to include an interaction term or other feature created from the two (like a product x*y or ratio x/y)? I am assuming that the ratio would run into multicollinearity against the two original features, but from what I know logistic regression is linear and additive.
