[site]: crossvalidated
[post_id]: 478656
[parent_id]: 
[tags]: 
Calculating the variance of dice rolls?

I am having trouble understanding how to find the variance for the proportion of times we see a 6 when we roll a dice. The question is below: Suppose we are interested in the proportion of times we see a 6 when rolling n=100 dice. This is a random variable which we can simulate with x=sample(1:6, n, replace=TRUE) and the proportion we are interested in can be expressed as an average: mean(x==6) Because the die rolls are independent, the CLT applies. We want to roll n dice 10,000 times and keep these proportions. This random variable (proportion of 6s) has mean p=1/6 and variance p*(1-p)/n . So according to the CLT, z = (mean(x==6) - p) / sqrt(p*(1-p)/n) should be normal with mean 0 and SD 1. So according to the problem, the mean proportion you should get is 1/6. I can get how the proportion of 6's you get should average out to 1/6. The mean proportion is p = 1/6. But the variance confuses me. The question says variance is p*(1-p)/n . But the formula for variance for a sample is the sum of the difference between a value and the mean divided by the sample size minus one. Why do they do differently here?
