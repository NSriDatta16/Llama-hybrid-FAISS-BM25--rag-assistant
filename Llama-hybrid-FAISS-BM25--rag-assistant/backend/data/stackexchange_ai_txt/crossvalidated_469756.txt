[site]: crossvalidated
[post_id]: 469756
[parent_id]: 469742
[tags]: 
You should optimize the hyperparameters of each class of model first and then compare the different classes of model to each other. Otherwise, the performance of the different model types will be heavily influenced by the arbitrary selection of hyperparameters. For example, with the initial parameters, it may be the case that a random forest performs better than SVM. However, once both have the best hyperparameters, it may be the reverse case. If you had chosen the random forest and then optimized, you'd end up with a worse than optimal model because you never even tested the optimal SVM model. Using loops where you can and reusing old code will speed things up. Also, depending on your program, there are functions which implement CV and hyperparameter selection, so you don't need to code that by hand. In Python you can use GridSearchCV.
