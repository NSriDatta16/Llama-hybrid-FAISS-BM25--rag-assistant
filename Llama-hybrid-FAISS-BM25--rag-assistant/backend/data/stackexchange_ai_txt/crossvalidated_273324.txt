[site]: crossvalidated
[post_id]: 273324
[parent_id]: 
[tags]: 
Multiple observations per subject in logistic regressions

In my study, 210 subjects had to choose three out of nine options. I want to find out what several predictors (X1, X2, X3, X4) had on the selection of these options (Y), where: X1 and X2 are objective attributes of the options (i.e., independent from the subjects) X3 is a subjective attribute of the options (i.e., specified for each option by each participant) X4 is an attribute of the subject that in theory should influence the subjective importance of X1 and X2 for the selection decisions and Y shows for each option and each participant whether it was selected (1) or not (0). My data thus looks like the following, with 210*9=1890 observations in total: ID Y X1 X2 X3 X4 1 1 1 1 10 5.5 1 0 2 1 56 5.5 1 1 3 1 25 5.5 1 1 1 2 11 5.5 1 0 2 2 14 5.5 1 0 3 2 23 5.5 1 0 1 3 25 5.5 1 0 2 3 45 5.5 1 0 3 3 47 5.5 2 0 1 1 22 4.9 2 1 2 1 25 4.9 2 0 3 1 27 4.9 ... My first idea was to calculate a logistic regression model where X1, X2, and X3 are used as predictors and X4 may interact with X1 and X2: glm(Y ~ X1 + X2 + X3 + X1:X4 + X2:X4, data = dat, family = binomial) However, this neglects the multiple observations per participant. Does modelling the same model as a generalized estimating equation with ID as a clustering variable solve this problem?
