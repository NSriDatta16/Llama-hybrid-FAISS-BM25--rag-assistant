[site]: crossvalidated
[post_id]: 353882
[parent_id]: 67565
[tags]: 
Reproducing comments: Shea Parkes: nnet() by default optimizes squared error instead of binomial loss. Try using entropy=TRUE to have it optimize the same loss function as logistic regression. Also, to reproduce a logistic regression, you need the input to output activations to be linear, but the readout layer to predict probabilities. This is because the logistic regression is estimating a linear function of the inputs. The readout layer piece is accomplished by Shea’s comment, but you’ll also need to adjust the internal activations.
