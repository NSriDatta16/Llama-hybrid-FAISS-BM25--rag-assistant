[site]: crossvalidated
[post_id]: 52331
[parent_id]: 52319
[tags]: 
This is a simple case of a multi-armed bandit problem. As you note, you want to balance the information you collect by trying the unknown coin when you think is suboptimal in the short run against exploiting the knowledge you have. In the classical multi-armed bandit problem, you would not be certain of the probability for either coin. However, here you are given that you know the value of coin A, so when you flip A, you get no information. In fact, you might as well ignore the stochastic nature of A, and assume you get a flat $1/2$ per choice of A. This means if it is ever right to flip coin A, then you should keep flipping A. So, you just want to find the optimal stopping rule for when you should give up on B. This depends on the prior distribution for the parameter for B and the number of trials. With a greater number of trials, exploring has more value, so you would test B more. In general, I think you can't get away from a dynamic programming problem, although there might be special cases where the optimal strategy can be found and checked more simply. With a uniform prior, here is where you should stop: $(0 ~ \text{heads}, 3 ~\text{tails}), (1 ~\text{head}, 5 ~\text{tails}), (2 ~\text{heads}, 6 ~\text{tails}), (3,7), (4,8),...(31,35), (32,35), (33,36), (34,37), ... (41,44), (42,44), ... (46,48), (47,48), (48,49), (49,50)$. Under this strategy, you expect to collect $61.3299$ heads. I used the following Mathematica code to compute the equities: Clear[Equity]; Equity[n_, heads_, tails_] := Equity[n, heads, tails] = If[n == 0, heads, Max[1/2 + Equity[n - 1, heads, tails], (heads + 1)/(heads + tails + 2) Equity[n - 1, heads + 1, tails] + (tails + 1)/(heads + tails + 2) Equity[n - 1, heads, tails + 1] ] ] For comparison, the Thompson sampling heuristic (which Cam Davidson Pilon claimed is optimal) gives an average of 60.2907 heads, lower by 1.03915. Thompson sampling has the problem that it sometimes samples B when you have enough information to know that it is not a good bet, and it often wastes chances to sample B early, when information is worth the most. In this type of problem, you are almost never indifferent between your options, and there is a pure optimal strategy. tp[heads_, tails_] := tp[heads, tails] = Integrate[x^heads (1 - x)^tails / Beta[heads + 1, tails + 1], {x, 0, 1/2}] Clear[Thompson]; Thompson[flipsLeft_, heads_, tails_] := Thompson[flipsLeft, heads, tails] = If[flipsLeft == 0, heads, Module[{p = tp[heads, tails]}, p (1/2 + Thompson[flipsLeft-1,heads,tails]) + (1-p)((heads+1)/(heads+tails+2)Thompson[flipsLeft-1,heads+1,tails] + ((tails+1)/(heads+tails+2)) Thompson[flipsLeft-1,heads,tails+1])]]
