[site]: crossvalidated
[post_id]: 5741
[parent_id]: 5727
[tags]: 
The parameter $\sigma^2$ is the (unknown) common variance of the vector components, each of which we assume are normally distributed. For the baseball data we have $45 \cdot Y_i \sim \mathsf{binom}(45,p_i)$, so the normal approximation to the binomial distribution gives (taking $ \hat{p_{i}} = Y_{i}$) $$ \hat{p}_{i}\approx \mathsf{norm}(\mathtt{mean}=p_{i},\mathtt{var} = p_{i}(1-p_{i})/45). $$ Obviously in this case the variances are not equal, yet if they had been equal to a common value then we could estimate it with the pooled estimator $$ \hat{\sigma}^2 = \frac{\hat{p}(1 - \hat{p})}{45}, $$ where $\hat{p}$ is the grand mean $$ \hat{p} = \frac{1}{18\cdot 45}\sum_{i = 1}^{18}45\cdot{Y_{i}}=\overline{Y}. $$ It looks as though this is what Efron and Morris have done (in the 1977 paper). You can check this with the following R code. Here are the data: y and here is the estimate for $\sigma^2$: s2 which is $\hat{\sigma}^2 \approx 0.004332392$. The shrinkage factor in the paper is then 1 - 15*s2/(17*var(y)) which gives $c \approx 0.2123905$. Note that in the second paper they made a transformation to sidestep the variance problem (as @Wolfgang said). Also note in the 1975 paper they used $k - 2$ while in the 1977 paper they used $k - 3$.
