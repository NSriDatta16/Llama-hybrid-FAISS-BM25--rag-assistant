[site]: datascience
[post_id]: 33772
[parent_id]: 
[tags]: 
what is the reason behind the bad outputs gained by RNN, LSTM when using GloVe pretrained model in text classification?

the problem is with the results gained for accuracy and f1 afer training our model via pretrained models such as GloVe. when I apply CNN as a classifier, the result are good as follows: acc: 0.9345 - val_loss: 0.1513 but when I apply RNN and LSTM as a classifier the results will be as follows: 24931/24931 [==============================] - 188s 8ms/step - loss: 7.9559 - acc: 6.0166e-04 - val_loss: 7.9904 - val_acc: 0.0000e+00 Epoch 2/4 24931/24931 [==============================] - 189s 8ms/step - loss: 7.9645 - acc: 0.0000e+00 - val_loss: 7.9904 - val_acc: 0.0000e+00 the above result is reached both via RNN and LSTM. the problem is that I use the same data set and the same structure and the same GloVe but I reach acc: 0.9345 for CNN and gain acc: 0.0000e+00 for both LSTM and RNN. It is worth noting that I have changed optimizer but still get the same result. the applied dataset contains 41,399 items, totaling 60.3 MB and also is binary. any guidance will be appreciated as I am a beginner in working with GloVe. I apply keras with tensorflow backend with python 3.5 in ubuntu.
