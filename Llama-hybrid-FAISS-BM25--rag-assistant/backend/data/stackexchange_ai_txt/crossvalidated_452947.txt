[site]: crossvalidated
[post_id]: 452947
[parent_id]: 
[tags]: 
Is LASSO and Automatic Relevance Determination the same in a Bayesian setting

I am currently trying to understand different variable selection / regularization techniques in more detail. I found some indication that Automatic Relevance Determination can be implemented by adding an inverse exponential hyperprior on the variance component of a normally distributed variable (or equivalently an exponential on the precision $\tau$ ). So something like this: $\beta_i \sim Normal(0,\sigma^2_i)$ $1/\sigma^2_i \sim exponential(\lambda)$ So the exponential distribution drives the variables towards zero. I also found the same approach under the term LASSO (L1 regularization), although it seems more common to find the term LASSO in models where the normal is replaced by a Laplace distribution (without hyperprior). As far as I understood, LASSO in ML is equivalent to a Laplace prior in Bayesian estimation. So is this just that some authors are not taking care to use the correct terms in all cases? Or is there a larger similarity between these two approaches, that is not obvious at first sight (besides both attempting to reduce the number of included variables).
