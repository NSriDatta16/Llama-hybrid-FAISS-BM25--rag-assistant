[site]: datascience
[post_id]: 5512
[parent_id]: 5493
[tags]: 
Here's a solution using the caret package for R. A Random Forest is first trained on the data. All observations for which the probability (from the voting) is less than 99% are then passed to model 2, linear discriminant analysis. Only the probabilities from unseen resampling observations are used, since the Random Forest will otherwise fit the training data perfectly. That is what caret is needed for. The accuracy is a little higher for the uncertain cases, but this is probably overfitting since I have tried several different models and the data set is small. I'd like to know if this really improves the performance in your application for the out of sample test data. Are there any papers that recommend this approach? This approach seems to resemble boosting. I tried it on some of my data but could not improve the out of sample performance I got from model 1 (a Random Forest). data(iris) library(caret) myTrainControl
