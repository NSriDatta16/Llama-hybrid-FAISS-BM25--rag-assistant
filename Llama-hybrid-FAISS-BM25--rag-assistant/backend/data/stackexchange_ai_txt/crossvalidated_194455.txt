[site]: crossvalidated
[post_id]: 194455
[parent_id]: 194035
[tags]: 
The actual execution of a Bayesian method is more technical than that of a Frequentist. By "more technical" I mean things like: 1) choosing priors, 2) programming your model in a BUGS/JAGS/STAN, and 3) thinking about sampling and convergence. Obviously, #1 is pretty much not optional, by definition of Bayesian. Though with some problems and procedures, there can be reasonable defaults, somewhat hiding the issue from the user. (Though this can also cause problems!) Whether #2 is an issue depends on the software you use. Bayesian statistics has a bent towards more general solutions than frequentist statistical methods, and tools like BUGS, JAGS, and STAN are a natural expression of this. However, there are Bayesian functions in various software packages that appear to work like the typical frequentist procedure, so this is not always an issue. (And recent solutions like the R packages rstanarm and brms are bridging this gap.) Still, using these tools is very similar to programming in a new language. Item #3 is usually applicable, since the majority of real-world Bayesian applications are going to use MCMC sampling. (On the other hand, frequentist MLE-based procedures use optimization which may converge to a local minima or not converge at all, and I wonder how many users should be checking this and don't?) As I said in a comment, I'm not sure that freedom from priors is actually a scientific benefit. It's certainly convenient in several ways and at several points in the publication process, but I'm not sure it actually makes for better science. (And in the big picture, we all have to be aware of our priors as scientists, or we'll suffer from all kinds of biases in our investigations, regardless of what statistical methods we use.)
