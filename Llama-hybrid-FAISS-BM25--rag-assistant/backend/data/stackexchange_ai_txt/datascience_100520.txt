[site]: datascience
[post_id]: 100520
[parent_id]: 
[tags]: 
How to Inference With Keras Sequential Models (Text Classification)

I have the following LSTM model and I can't make inference with it: print("Define LSTM model") rnnmodel=Sequential() rnnmodel.add(embedding_layer) rnnmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2)) rnnmodel.add(Dense(2, activation="sigmoid")) rnnmodel.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"]) rnnmodel.fit(X_train, y_train, batch_size=256, epochs=1, validation_data=(x_val, y_val)) score, acc=rnnmodel.evaluate(test_data, test_labels, batch_size=128) print(f"Test accuracy with RNN: {acc}") (epoch is 1 to test) I want to make an inference with the text, let's say text=["the product was horrible"] I check the documentation of tf.keras.Sequential and it states I should use the predict function and the input should be "A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs)." So what I did is: text=["the product was horrible"] inference_sequence=tokenizer.texts_to_sequences(text) inference_data=pad_sequences(inference_sequence, maxlen=MAX_SEQUENCE_LENGTH) predictions=rnnmodel.predict(inference_data) print(predictions) and it gives me the result [[0.63219154 0.33410403]] However I've given only one sentence. Why it gives me two results? I checked the sigmoid documentation from here and for an confirmed it should return only one result. So what's the problem here? I also tried other approaches to make inference like mentioned https://stackoverflow.com/questions/61443543/how-to-make-prediction-on-keras-text-classification So I did: text=["the product was horrible"] rnnmodel.predict(text) and it gives me the warning: WARNING:tensorflow:Model was constructed with shape (None, 1000) for input Tensor("embedding_input:0", shape=(None, 1000), dtype=float32), but it was called on an input with incompatible shape (None, 1). and stuck forever. What should I do I just can't make an inference.
