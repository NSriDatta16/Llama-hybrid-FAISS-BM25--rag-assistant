[site]: crossvalidated
[post_id]: 183890
[parent_id]: 
[tags]: 
Why are we using ICA?

I am new to Independent Component Analysis (ICA) and have a rudimentary understanding of the method. I understand that PCA finds vectors on which the projected data has maximum variance. ICA, on the other hand, finds vectors on which the projected data is statistically independent however, what those ICA is actually producing as a benefit when applied to a dataset ? Let say that I want to apply FastICA to the iris dataset of scikit-learn. (maybe not the best example as it only have 4 features however I use it for illustration) from sklearn import datasets from sklearn.preprocessing import Imputer imp = Imputer(missing_values='NaN', strategy='mean', axis=0) imp.fit(X) X = datasets.load_iris().data ica = FastICA(n_components=2) X_trans = ica.fit_transform(X) print ica.components_ plt.scatter(X_trans[:, 0], X_trans[:, 1]) In this example I selected 2 components for ICA for visualization purpose however there should be a way to select the optimal number of components ? What does the plot is supposed to show me in this example ? What objet or property the vectors correspond to ? How can this be used in practice? I also find this post and went through it however my question is a bit more specific. What ICA has to offer if applied on a dataset. In the example I gave, I use ICA. Why one would use ICA? What are the property of the vectors produced by ICA and in the example ?
