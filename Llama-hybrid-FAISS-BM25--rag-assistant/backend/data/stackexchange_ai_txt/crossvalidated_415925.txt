[site]: crossvalidated
[post_id]: 415925
[parent_id]: 415914
[tags]: 
The signal processing approach to such problems may be easier to understand. Among other things, the signal to noise ratio (SNR) for stocks may be so high as to render signal detection difficult, there are none-the-less many off-the-shelf algorithms for improving SNR, and that is perhaps of more interest to you. Such algorithms may sacrifice some signal (lossy algorithms) to accomplish noise reduction. The simplest algorithm to understand is perhaps addition. For example, if the trends are low frequency (long term) then reduction of the higher frequency noise by averaging (read as addition of ) adjacent temporal signals or averaging over a short time 'window' will tend to reduce high frequency noise more so than low frequency signal thereby improving SNR. In the frequency domain this is called a low pass filter. With respect to the question, addition and subtraction reduce information in the sense that when an average or difference is created, one loses the information as to what the numbers were before combining them. For example, given a $5$ as a result that could have come from $6-1$ , $10-5$ or an uncountably infinite number of other number pairs. Regarding information content such things are context dependent. If we assume that the noise contains no information, and that only the signal has information content, the goal of signal processing would then be to isolate the signal with the least possible signal loss while reducing the memoryless noise to zero. On the other hand, if the context is that both signal and noise contain information, then obviously noise reduction would seriously reduce information content. With respect to prediction, if the noise contains no information then one could establish bounds or an 'envelope' in which the noise is contained. That is not exactly a prediction in the same sense as $y=f(t)$ , but when coupled with the low pass signal may none-the-less offer a prediction range. In the real world (assuming money is real) the high frequency data contains less information (but still some) and the low frequency data relatively more information. Still, signal processing may be useful. For example, examining the data in the frequency domain may reveal repetitive occurrences that are not obvious in the data itself, and such a process (Fourier transform) is lossless.
