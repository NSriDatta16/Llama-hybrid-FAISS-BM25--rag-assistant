[site]: crossvalidated
[post_id]: 591053
[parent_id]: 591005
[tags]: 
Multiplying the one-hot vector with the weight matrix actually means selecting one column from the weight matrix. This is the reason why the words are one-to-one associated with the columns of the weight matrix. In practice, there are no one-hot vectors and the embedding lookup is implemented directly as retrieving the corresponding vector from the matrix. The vector from the weight matrix is trained in such a way that you predict what words typically appear around the particular word which says how to word is used which is a proxy for its meaning (or in some theories, such as in Wittgenstein's Philosophical Investigations, the use is actually the meaning). The context actually predetermines what word can be there: both its grammatical features and its possible meaning.
