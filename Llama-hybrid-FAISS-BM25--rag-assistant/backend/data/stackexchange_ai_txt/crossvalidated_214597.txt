[site]: crossvalidated
[post_id]: 214597
[parent_id]: 213325
[tags]: 
I think you are trying too hard on the model that does not have too much interpretability. Neural network (NN) is one of the black box models that will give you better performance, but it is hard to understand what was going on inside. Plus, it is very possible to have thousands even millions of weights inside of NN. NN is a very big non-linear non-convex function that can have large amount of local minima. If you train it multiple times, with different start point, the weights will be different. You can come up with some ways to visualize the internal weights, but it also does not give you too much insights. Here is one example on NN visualization for MNIST data . The upper right figure (reproduced below) shows the transformed features after applying the weights.
