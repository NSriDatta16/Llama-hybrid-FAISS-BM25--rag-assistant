[site]: crossvalidated
[post_id]: 424170
[parent_id]: 
[tags]: 
error, cost, loss, risk, are those 4 terms the same in the context of machine learning?

People uses these 4 terms when talking about deep learning, machine learning, data science. error (such as training error, test error), cost (such as training cost, test cost), loss (such as empirical loss), risk (such as empirical risk) Are those 4 terms the same in the context of machine learning? Answers with authoritative reference would be better, such as published paper, text book, user guide or documentation.
