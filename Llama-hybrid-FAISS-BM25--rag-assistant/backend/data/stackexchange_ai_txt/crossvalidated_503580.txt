[site]: crossvalidated
[post_id]: 503580
[parent_id]: 
[tags]: 
NLP: vectorizer/metric to upweight absence of frequent terms

I'm doing hierarchical clustering of documents in a corpus; there are words that occur in almost all the documents. To define document similarity, I've used sklearn.feature_extraction.text.TfidfVectorizer and scipy.spatial.distance.cosine . The results look reasonable; but it occurs to me that the absence in a particular document of a word that occurs in almost all documents ought to be very significant, whereas in my approach I gather that idf makes the presence or absence of that word relatively insignificant. Before I reinvent the wheel (and possibly poorly): Is there an established vectorization/metric that would give a large increment in similarity to two documents in each of which a very common word was absent â€” and a large decrement in similarity to two documents only one of which included the very common word?
