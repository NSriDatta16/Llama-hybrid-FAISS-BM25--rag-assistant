[site]: datascience
[post_id]: 38266
[parent_id]: 36957
[tags]: 
Assuming no relationships between facilities, the most straightforward way to do outlier detection on your dataframe would be to treat each facility as a separate dataset and look at each one in isolation. So, train one model per facility. In brief, in the unsupervised case you want to fit a model to a dataset that returns a score or measure of distance. You can then use that to judge which points are outliers. For one class SVM, you could adapt the code and examples on the scikit-learn novelty and outlier detection page or the isolation forest example but bearing in mind that you only need to look at one facility at a time. If you don't mind not doing unsupervised learning, and willing to consider a simpler approach, plot the distribution of each facility in a histogram and as a timeseries to work out what sorts of numbers of outliers to expect, and at what scale (unless the number of facilities makes this prohibitive). With an idea of the outliers in the data, points that outside the normal distribution can be identified by transforming each facility's data by z-score and look at the highest and lowest scores; these points are the furthest from the centre of the distribution. For each facility pick a threshold and mark everything outside that threshold as an outlier. This assumes a normal distribution, so it's worth looking at the histograms and line plots to see if that holds in your case.
