[site]: crossvalidated
[post_id]: 431059
[parent_id]: 
[tags]: 
Semi-supervised objective function VAE

In Kingma's paper on Semi-supervised learning https://arxiv.org/pdf/1406.5298.pdf , we are shown equations for the ELBO for the semisupervised case, however I am having a hard trying to derive the math from the vanilla VAE objective. Specifically, Eq.6 in the paper refers to the situation where we have labels (supervised) and Eq.7 refers to no labels (unsupervised) and 'y' is treated as a latent variable. Can someone provide a derivation for these two objectives or provide some pointers on how to derive these? Eq.6 for labelled data is: $log p_{θ}(x,y) \ge E_{q_{\phi} (z|x,y}) [ log p_\theta(x|y,z) + log p_{θ}(y) + log p(z) - log q_\phi(z|x,y)] $ Eq.7 for unlabeled data is : $log p_{θ}(x) \ge E_{q_{\phi} (y,z|x}) [ log p_\theta(x|y,z) + log p_{θ}(y) + log p(z) - log q_\phi(y,z|x)] $ = $ \sum_y q_\phi (y|x) (-L(x,y)) + H(q_\phi(y|x)) $ Thanks!
