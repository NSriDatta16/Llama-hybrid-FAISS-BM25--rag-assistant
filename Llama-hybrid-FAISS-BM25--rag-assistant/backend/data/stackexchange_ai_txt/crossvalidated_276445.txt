[site]: crossvalidated
[post_id]: 276445
[parent_id]: 276208
[tags]: 
The update policy is: $$ w = w - \alpha \nabla C(t, \sigma, w) $$ where $C(t, \sigma, w)$ where $t$ is the vector of target values, $w$ represents the weights on the edges coming in and $\sigma$ is the activation function. Let's assume, for the sake of simplicity, that we deal with a simple neural network with one hidden layer and one single output unit. Let's also assume that the cost function is: $$C(x, w) = \frac{1}{\sqrt 2} \sum_{i=1}^{m} (\sqrt{\sigma(w; x_i)} - \sqrt{t_i})^2$$ In the calculation of the gradient for the $i$th element in the sample, the gradient in the $j$ weight would be: $$\frac{\partial C(x,w)}{\partial w_j} = 2 (\sqrt{\sigma(w; x_i)} - \sqrt{t_i}) \sigma(w; x_i)^{-1/2} \frac{\partial \sigma (x,w)}{w_j}$$ The next step would be to define an activation function and carry on with the calculations. In light of all of this: If 3 and 4 is true for every cost function, how these steps use cost function application result? We follow the steps above. The cost function plays a direct role in the calculation of the gradient. Then how is it possible that 3 and 4 is true for every cost function? There is a sleight of hand which I have not made use of because I felt it was the source of the confusion. It is easier to consider your output node output $o$ the entire $\sqrt{\sigma(w; x_i)}$. From the point of view of the notation, this is very convenient because you abstract away from a specific cost function. If you exploit this "notation" and plug the partial derivative in the update policy, you get to see your general statement for the update function. This generalization is also very convenient for the SW implementation level - it constitutes a higher level abstraction.
