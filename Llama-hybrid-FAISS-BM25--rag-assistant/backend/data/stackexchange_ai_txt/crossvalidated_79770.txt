[site]: crossvalidated
[post_id]: 79770
[parent_id]: 79745
[tags]: 
Ans 1: You can check to see how well your models fit your data. Some will fit well and some will not. It does not mean that you disprove a model, this is meaningless. Some models will outperform the others. Ans 2: In general, it is not enough. You need to double check other assumptions of the model. Also see the Ans 3 below. Ans 3,4: There are different ways to compare these models. One of them would be based on their mean square errors (MSE). This means that you are looking at "in sample performance" of the models. In addition to MSE, you can check the "out of sample performance" of these models. It means that you remove some observations from your given data, and re-fit all these models to this new smaller data set. Then by using the obtained models, you try to predict the weights for the knows values of the characteristics for each model. Since you know the observed value of the weights, you can figure out how these models will actually perform. In addition, I can see that these models have different number of parameters. In general, the model with more parameters, is expected to fit better than the model with less number of parameter. But there should be a balance between the number of parameters and the goodness of fit. So one way is to use some criteria like, Akaike information criterion (AIC) or Bayesian information criterion (BIC). In these criteria, there is a penalty for each new parameter that is added to the model. In general, the models with less AIC or BIC would be the preferred model.
