[site]: stackoverflow
[post_id]: 3565186
[parent_id]: 3557820
[tags]: 
By the way, it looks like you have a well-known problem (at least among socket gurus) that most socket servers get in .Net. Paul has already touched on what it means. To elaborate more, what is going wrong is that during a Read/Write on the socket the buffer gets pinned - which means the GC isn't allowed to move it around (as such your heap fragments). Coversant (who pioneered the solution) were seeing an OutOfMemoryException when their actual memory usage was only about 500MB (due to such heavy fragmentation). Fixing it is another story entirely. What you want to do is at application start up allocate a very large amount of buffers (I am currently doing 50MB). You will find the new ArraySegment (v2.0) and ConcurrentQueue (v4.0) classes particularly useful when writing this. There are a few lock-free queues floating around on the tubes if you are not using v4.0 yet. // Pseudo-code. ArraySegment CheckOut() { ArraySegment result; while(!_queue.TryDequeue(out result)) GrowBufferQueue(); //Enqueue a bunch more buffers. return result; } void CheckOut(ArraySegment buffer) { _queue.Enqueue(buffer); } void GrowBufferQueue() { // Verify this, I did throw it together in 30s. // Allocates nearly 2MB. You might want to tweak that. for(var j = 0; j (buffer, i, 4096)); } } Following this you will need to subclass NetworkStream and swap out the incoming buffer with one from your buffer pool. Buffer::BlockCopy will help performance ( don't use Array::Copy ). This is complicated and hairy; especially if you make it async-capable. If you are not layering streams (e.g. SSLStream DeflateStream XmlWriter etc.) you should use the new socket async pattern in .Net 4.0 ; which has more efficiency around the IAsyncResult s that get passed around. Because you are not layering streams you have full control over the buffers that get used - so you don't need to go the NetworkStream subclass route.
