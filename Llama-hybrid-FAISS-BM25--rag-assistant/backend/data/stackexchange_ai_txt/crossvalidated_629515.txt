[site]: crossvalidated
[post_id]: 629515
[parent_id]: 455124
[tags]: 
This can absolutely be done and is incredibly widely used. See e.g. https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation , https://en.wikipedia.org/wiki/Hidden_Markov_model , https://en.wikipedia.org/wiki/Kalman_filter https://en.wikipedia.org/wiki/Mixture_model . for a few ubiquitous examples. "Unmeasured confounding" and "latent mediators" are other topics in this area; there are many more. Essentially, any latent-variable problem can be formulated in terms of inference in a Bayesian network. Kevin Murphy's Probabilistic Machine Learning: Advanced Topics has some sections on this; probably Koller's & Friedman's Probabilistic Graphical Models does as well, but I currently don't have access to that and cannot verify. Generally speaking, models with latent variables are, of course, significantly more challenging to identify compared to models in which all nodes are observed.
