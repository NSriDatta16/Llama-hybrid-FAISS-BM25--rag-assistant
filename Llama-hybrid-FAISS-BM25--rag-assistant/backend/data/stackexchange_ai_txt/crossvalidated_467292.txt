[site]: crossvalidated
[post_id]: 467292
[parent_id]: 465692
[tags]: 
Generally speaking, multivariate time-series should be stationary because it reduces variance in the model. But this is usually looked at a case-by-case basis. The normalisation of such time-series could also prove to be important. You can transform them into stationary time-series. Two main methods are using differencing or Box-Cox transformations. See this section and this answer for more details. Absolutely! Highly correlated time-series make the estimation of the regression coefficients computationally difficult. To understand the correlation in time-series you'll need to first understand ACF and PACF. These links help with that. This link talks about causality and multi-collinearity at length. It is important to understand that correlations are useful for forecasting, even when there is no causal relationship between the two variables, or when the correlation runs in the opposite direction to the model. However, often a better model is possible if a causal mechanism can be determined. This link should help you differentiate the RNN vs Supervised learning approach for time-series. Generally, if you have a time-series X = [1,2,3,4,5,6,7,8,9,10] then that could be transformed into a supervised learning problem like - # assuming we only consider lag = 1 | X(t) | X(t-1) | y | | ---- | ------ | ---- | | 1 | 2 | 3 | | 2 | 3 | 4 | | 3 | 4 | 5 | | 4 | 5 | 6 | | 5 | 6 | 7 | You can extend this for multivariate time-series like so - # assuming we only consider lag = 1 | X1(t) | X1(t-1) | X2(t) | X2(t-1) | y | | ----- | ------- | ----- | ------- | ---- | | 1 | 2 | 50 | 60 | 3 | | 2 | 3 | 60 | 70 | 4 | | 3 | 4 | 70 | 80 | 5 | | 4 | 5 | 80 | 90 | 6 | | 5 | 6 | 90 | 100 | 7 | ```
