[site]: crossvalidated
[post_id]: 284907
[parent_id]: 
[tags]: 
Posterior Predictive Density of Linear Regression

I'm trying to derive the Posterior Predictive Density of a Linear Regression Model with a diffuse, uninformative prior such that we have: $y_{i} = x_{i}'\beta + \varepsilon_{i}$ with $\varepsilon_{i} \sim N(0,\sigma^{2})$ Equation (1) We have the density of $y_{N+1}$ given $x_{N+1}, \beta,\sigma^{2}$ as $p(y_{N+1}|x_{N+1},\beta,\sigma^{2}) = (\frac{1}{\sigma (2\pi)^{1/2}})\exp(\frac{-(y_{N+1}-x'_{N+1}\beta)^2}{2\sigma^{2}})$ Equation (2) Following some notes on Bayesian Econometrics the definition of posterior predictive density is: $p(y_{N+1}|x_{N+1},y) = \int\limits_{-\infty}^{\infty}\int\limits_{0}^{\infty}p(y_{N+1}|x_{N+1},\beta,\sigma^{2})p(\beta,\sigma^{2}|y)d\sigma^{2}d\beta$. Equation (3) Then under a prior specification $p(\beta,\sigma^{2}) \propto \sigma^{-2}$, the posterior predictive density is given by: $p(y_{N+1}|x_{N+1},y) \propto \Big((N-k) + \frac{(y_{N+1}-x'_{N+1}\hat{\beta})'M(y_{N+1}-x'_{N+1}\hat{\beta})}{(y-X\hat{\beta})'(y-X\hat{\beta})/(N-k)}\Big)^{-\frac{(N-k+1)}{2}}$ Equation (4) with $M = (1 + x'_{N+1}(X'X)^{-1}x_{N+1})^{-1}$ I would really appreciate some intuition of how I can arrive to Equation 4. I am able to derive marginal, conditional and predictive distributions in almost any kind of shape but I really got stuck in this normal gaussian approach.
