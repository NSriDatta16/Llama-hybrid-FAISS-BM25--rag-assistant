[site]: crossvalidated
[post_id]: 294998
[parent_id]: 294982
[tags]: 
Here's another way of approaching this problem. Suppose $X_i \sim Exp(\beta)$. For simplicity, define $T_k = \sum_{i=1}^k X_i$. Finally, we define $$N = \min(n \ \ s.t. \ \ T_{n-1} Then it follows that $N-1$ is a Poisson random variable with mean $\frac{1}{\beta}$. We notice that $T_{n-1} \sim Gamma(n-1, \beta)$ and that $T_{n-1}$ and $X_n$ are independent and thus the joint pdf is easily attainable. In order to leverage this fact, we write: $$\begin{align*} P(N=n) &= P(T_{n-1} We can obtain this probability by integrating the joint pdf $f(x, t)$ over the appropriate domain. $$\begin{align*} P(N=n) &= \int_0^1\int_{1-t}^\infty f(x,t)\ dx\ dt \\ &= \int_0^1\int_{1-t}^\infty \frac{e^{-t/\beta}t^{n-2}}{(n-2)!\beta^{n-1}}\cdot\frac{e^{-x/\beta}}{\beta} \ dx \ dt \\ &= \frac{e^{-1/\beta}}{(n-2)!\beta^{n-1}}\int_0^1 t^{n-2} \ dt \\ &= \frac{e^{-1/\beta}(1/\beta)^{n-1}}{(n-1)!} \end{align*}$$ If we make the simple transformation $Y = N-1$, and define $\lambda = 1/\beta$ we obtain: $$P(Y=y) = P(N=y+1) = \frac{e^{-\lambda}\lambda^y}{y!}$$ Hence $Y = N-1$ is Poisson as desired.
