[site]: crossvalidated
[post_id]: 175307
[parent_id]: 175302
[tags]: 
This is pretty heuristic explanation :( Autoencoders with sparsity enforcement seek to arrive at a more efficient representation of the data. Because we effectively restricting the number of how many neurons we allow to "fire" at a given layer, we are actually imposing sort-of bound on dimensionality of data which makes it to the next layer. This forces the algorithm to compress information. This compression is achieved, as usual, by similar treatment of simliar cases. For example, if we were to train an autoencoder with n-dimensional input and output, one hidden layer with strict sparsity parameter with linear activation functions of all neurons and we would succeed in training it "near-perfectly", we would arrive at a result very similiar to PCA. That is, the hidden layer would try to capture information which explains most variance. In this sense, grouping observations which have similar output from the hidden layer allow us to get dimensionality-reduction effect while preserving a lot of information. This grouping or dimensionality reduction is essence of unsupervised learning.
