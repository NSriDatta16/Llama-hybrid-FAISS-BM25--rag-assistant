[site]: crossvalidated
[post_id]: 173356
[parent_id]: 
[tags]: 
Updating a Bayes factor

A Bayes factor is defined in Bayesian testing of hypothesis and Bayesian model selection by the ratio of two marginal likelihoods: given an iid sample $(x_1,\ldots,x_n)$ and respective sampling densities $f_1(x|\theta)$ and $f_2(x|\eta)$ , with corresponding priors $\pi_1$ and $\pi_2$ , the Bayes factor for comparing the two models is $$\mathfrak{B}_{12}(x_1,\ldots,x_n)\stackrel{\text{def}}{=}\frac{m_1(x_1,\ldots,x_n)}{m_2(x_1,\ldots,x_n)}\stackrel{\text{def}}{=}\frac{\int \prod_{i=1}^n f_1(x_i|\theta)\pi_1(\text{d}\theta)}{\int \prod_{i=1}^n f_2(x_i|\eta)\pi_2(\text{d}\eta)}$$ A book I am currently reviewing has the strange statement that the above Bayes factor $\mathfrak{B}_{12}(x_1,\ldots,x_n)$ is "formed by multiplying the individual ones [Bayes factors] together" (p.118). This is formally correct if one uses the decomposition \begin{align*}\mathfrak{B}_{12}(x_1,\ldots,x_n)&=\frac{m_1(x_1,\ldots,x_n)}{m_2(x_1,\ldots,x_n)}\\&=\frac{m_1(x_n|x_1,\ldots,x_{n-1})}{m_2(x_n|x_1,\ldots,x_{n-1})}\times \frac{m_1(x_{n-1}|x_{n-2},\ldots,x_1)}{m_2(x_{n-1}|x_{n-2},\ldots,x_1)}\times\cdots\\&\qquad\cdots\times\frac{m_1(x_1)}{m_2(x_1)}\end{align*} but I see not computational advantage in this decomposition as the update by $$\frac{m_1(x_n|x_1,\ldots,x_{n-1})}{m_2(x_n|x_1,\ldots,x_{n-1})}$$ requires the same computational effort as the original computation of $$\frac{m_1(x_1,\ldots,x_n)}{m_2(x_1,\ldots,x_n)}$$ outside artificial toy examples. Question: Is there a generic and computationally efficient way of updating the Bayes factor from $\mathfrak{B}_{12}(x_1,\ldots,x_n)$ to $\mathfrak{B}_{12}(x_1,\ldots,x_{n+1})$ that does not require recomputing the entire marginals $m_1(x_1,\ldots,x_n)$ and $m_2(x_1,\ldots,x_n)$ ? My intuition is that, besides particle filters, which indeed proceed along estimating the Bayes factors $\mathfrak{B}_{12}(x_1,\ldots,x_n)$ one new observation at a time, there is no natural way of answering this question.
