[site]: datascience
[post_id]: 5628
[parent_id]: 5609
[tags]: 
Not a typical problem formulation indeed. I suggest two approaches: Use a simple bayesian model where the states or nodes are each of your features. Connect the nodes directly when they haven a direct time dependency (for example vote1 -> vote2 -> vote3, but not vote3 -> vote1) and calculate the probability of a final (output) node to be something (for example user type 1, user type 2, etc). You could also use a hidden markov model that naturally models transitions between states. In your case it would output just 1 state (the prediction). I am not very fan of this model for your problem, but it could be nice to try. You will need a lot of data though. You could use Fuzzy Inductive Reasoning (FIR). It is definitely not a simple algorithm, but works quite well for classification having time series or time-related features. In FIR you want to find an optimal mask of a given depth. If you have, say, 5 features per sample, and for instance you want to know which features to select you will learn an optimal mask for your data that address this (and creates fuzzy rules, etc...). Also if you want to relate two or more examples you will define a depth higher than 1 for the mask. This will allow you to find a mask that for instance uses features 1,2 and 4 of sample t, features 2,3 ,4 and 5 of sample t+1 and features 1 and 4 of sample t+2. Moving t from 1 to N number of samples. So, interesting combinations of features from samples that have a time-relation (or some sort of sequence) are created.
