[site]: crossvalidated
[post_id]: 579880
[parent_id]: 
[tags]: 
"Biasing" a generalized trained object detector towards specific examples during inference

I have trained an object detection deep learning model on many different types of cars (shape, color, car model variations etc.). I'm just using a single class "Car" for all the different types of cars. I am deploying this model on mobile phones. The accuracy of my model that I have achieved so far is quite good enough for my case. What I now want to achieve is that when I open the car detector app on the phone to try to detect a certain car, let's say a Blue Sedan, the detector should temporarily get biased towards this specific car i.e. the Blue Sedan only (and not any other types of cars) (until the app is started again where it should be able to detect all types of cars again). Is such a thing possible to do currently i.e. "biasing" a generalized trained OD model towards specific examples during inference? I'm not even sure what keywords I should be using to look for such methods. Can you please suggest the solution to the problem or the keywords to look for the solution?
