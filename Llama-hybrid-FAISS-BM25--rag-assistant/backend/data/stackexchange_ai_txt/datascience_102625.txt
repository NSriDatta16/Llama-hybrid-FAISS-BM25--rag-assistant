[site]: datascience
[post_id]: 102625
[parent_id]: 
[tags]: 
Is standardization/normalization a good way of reducing the impact of outliers when I'm training a machine learning model?

Recently, I have read some papers in which the authors state that they have performed standardization/normalization of the variables for reducing the impact of outliers in the machine learning models trained with the data. Does it make sense? Why? I think that the difference between outliers and the other values is still in the data, after standardization.
