[site]: datascience
[post_id]: 61910
[parent_id]: 61864
[tags]: 
As a practice data is divided into 2 parts first, train and test. Now test is kept completely separate and from train further 80 20 split is done as train and validation data. Now when you fit model, for example say neural network model. For each epoch model will be trained using only and only train data. Test and validation are untouched. But at each epoch you want to know if the model trained is a better than previous or not (based on loss or any other metric you define), for that we evaluate performance on validation data (for this purpose only we give validation data in .fit) Now as we are using validation data for checking best model, validation data is kind of used in training the model and hence to report final accuracy number of your model you use .predict on test data. Here also you can use .evaluate which returns predicted probability as well as loss contrary to .predict which just returns predicted probability. Sometimes checking loss is also helpful as it gives sort of idea on how confident the model is in making predictions.
