[site]: datascience
[post_id]: 40079
[parent_id]: 40012
[tags]: 
I would recommend applying GloVe info available here: Stanford Uni Glove to your word structures before modelling. This way you can extract meaningful probability densities. If you then PCA to reduce dimensions at least you have interrelated context that explains interaction. Effectively you will have better results as the dense vectors are more representative in terms of correlation and their relationship with each other words is determined. This is due to the dense vector being a represented form of interaction. This process will allow you to reduce dimensions with a pca in a meaningful way ;)
