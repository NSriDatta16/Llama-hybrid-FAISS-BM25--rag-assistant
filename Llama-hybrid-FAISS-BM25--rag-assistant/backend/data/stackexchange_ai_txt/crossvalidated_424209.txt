[site]: crossvalidated
[post_id]: 424209
[parent_id]: 
[tags]: 
Why is my neural network giving unequal probabilities when predicting an image that isn't one of the given classes?

Let's say I had 5 different types of images I wanted to classify in my neural network and I trained it on 10,000 images. When it is done training, I give it an image that it has never seen before and isn't part of one of the 5 classes. Shouldn't it give a semi-equal probability distribution of what class it is. Something like [0.20, 0.20, 0.20. 0.20, 0.20]. Instead my model in Keras predicts that it is certain it is one of the 5 even though it isn't one of the classes. Ex. [.99, 0, 0, 0, .01]. Is this a result of over training or something similar?
