[site]: crossvalidated
[post_id]: 570661
[parent_id]: 
[tags]: 
imbalanced data creates biased results in multinomial logistic regression, balancing it spreads probabilities almost equally - what can i do?

I am working in Python. I am using this method to generate the transition probability matrix of a Markov-Chain-Model. Each row of the Matrix is one multinomial regression that gives me the probabilities of going from the state of the number of the row to one of the states in the columns. My matrix has 10 states. So I have 100 transitions. If I transfer from state 1 to 2 the transition code is 2. If I transfer from state 2 to state 2 the transition code is 12. If I transfer from state 3 to state 5 the transition code is 25 etc. (just for some context) This is the input dataframe: logit_pre_input_all_seasons Out[201]: hour weekday month transition_code 0 0 1 1 1.0 1 1 1 1 1.0 2 2 1 1 1.0 3 3 1 1 1.0 4 4 1 1 1.0 ... ... ... ... 150475 19 6 12 1.0 150476 20 6 12 1.0 150477 21 6 12 1.0 150478 22 6 12 1.0 150479 23 6 12 1.0 [150480 rows x 4 columns] the column transition_code has therefore values from 1 to 100. 70361 of the 150480 observed transitions are simply from state 1 to state 1. The rest is better distributed with high states being rarer in general and big jumps (e.g. from 2 to 10) are also rare. So on the backdrop of the transition probability matrix, I have one multinomial logistic regression model for each row. The problem starts already in the first row, which i coded like this: first_row_transitions = [1,2,3,4,5,6,7,8,9,10] first_row_data = logit_pre_input_all_seasons[logit_pre_input_all_seasons["transition_code"].isin(first_row_transitions )] Now the typical train,test split: X_train, X_test, y_train, y_test = train_test_split(first_row_data.drop(["transition_code"], axis=1), first_row_data["transition_code"], test_size = 0.1) I am using the one-vs-rest classifier from scikit. I thought it would make sense to balance the data, as almost half of the transitions are 1, though there are 100 possible transitions (or rather 10 for the first row). I also created a polynomial feature vector through PolynomialFeatures(degree = 3, interaction_only=True, include_bias=True) X_poly = poly.fit_transform(X_train.values) since I assumed that with this data I can't really use straight decision boundaries. Setting class_weight = "balanced" gives me a result like this, if I wanted to get the probability for 5 am on a monday: ovr.predict_proba(poly.fit_transform([[5,0,4]])) Out[206]: array([[0.0352168 , 0.09572709, 0.10967989, 0.12287931, 0.12065948, 0.12357549, 0.12156339, 0.11488389, 0.12242008, 0.03339457]]) Not balancing gives me this result: ovr.predict_proba(poly.fit_transform([[5,0,4]])) Out[230]: array([[8.14109256e-01, 9.80132328e-02, 3.39940624e-02, 2.88906196e-02, 1.31220018e-02, 5.87523171e-03, 3.55703613e-03, 1.68042884e-03, 7.48728647e-04, 9.40195113e-06]]) For this specific example point, there are 4442 transitions in total, of which only 463 are type 1 but for example there are 133 type 2 transitions, 134 type 3 and 222 type 4 transitions. Due to the high amount of classes balancing just flattens out the probabilities but not balancing leaves the bias. Is there any thing I can do with this data? I must use logistic regression because I am trying to recreate a specific method someone else used. Thanks!
