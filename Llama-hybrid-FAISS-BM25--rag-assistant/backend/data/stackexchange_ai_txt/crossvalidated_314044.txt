[site]: crossvalidated
[post_id]: 314044
[parent_id]: 
[tags]: 
Using machine learning models in an explanatory way

I'm hoping to learn some caveats to consider when training a machine learning model not for prediction but to point out features and feature values that significantly influence a target variable. I have a data set with a large set of categorical attributes and one continuous target variable. I want to ask the question: Which attribute, and specifically, which attribute value is associated with a high value in the target variable? Experimentally, I tried the following approach: applied dummy coding/one-hot encoding to all categorical features trained a regression model ( sklearn.RandomForestRegressor ) on the entire data set looked at the result of sklearn.RandomForestRegressor.feature_importances_ : They have a very skewed distribution in which some feature-value combinations pop out as very important compared to the rest Now, is it methodically sound to infer that these are important factors influencing the target variable? What needs to be considered to make this conclusion valid? e.g. is this a sound approach in general? is one-hot-encoding the right preprocessing step? are the same validation/optimization/parameter tuning methods to improve a predictive model relevant to such an "explanatory model" the target variable has a very skewed distribution where 80% of items have a value of less than 3 and some a value of >100 - is that relevant? ...
