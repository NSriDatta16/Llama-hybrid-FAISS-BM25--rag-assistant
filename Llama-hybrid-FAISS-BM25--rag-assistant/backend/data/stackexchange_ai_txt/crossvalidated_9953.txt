[site]: crossvalidated
[post_id]: 9953
[parent_id]: 9852
[tags]: 
As whuber stated this actually is a case of nested models, and hence one can apply a likelihood-ratio test . Because it is still not exactly clear what models you are specifying I will just rewrite them in this example; So model 1 can be: $Y = a_1 + B_{11}(X) + B_{12}(W) + B_{13}(Z) + e_1$ And model 2 can be (I ignore the division by 2, but this action has no consequence for your question): $Y = a_2 + B_{21}(X) + B_{22}(W+Z) + e_2$ Which can be rewritten as: $Y = a_2 + B_{21}(X) + B_{22}(W) + B_{22}(Z)+ e_2$ And hence model 2 is a specific case of model 1 in which $B_{12}$ and $B_{13}$ are equal. One can use the likelihood-ratio test between these two models to assign a p-value to the fit of model 1 compared to model 2. There are good reasons in practice to do this, especially if the correlation between W and Z are quite large ( multicollinearity ). As I stated previously, whether you divide by two does not matter for testing the fit of the models, although if it is easier to interpret $\frac{W+Z}{2}$ then $W+Z$ by all means use the average of the two variables. Model fit statistics (such as Mallow's CP already mentioned by bill_080, and other examples are AIC and BIC ), are frequently used to assess non-nested models. Those statistics do not follow known distributions (like the log-likelihood does, Chi-square ) and hence the differences in those statistics between models can not be given a p-value.
