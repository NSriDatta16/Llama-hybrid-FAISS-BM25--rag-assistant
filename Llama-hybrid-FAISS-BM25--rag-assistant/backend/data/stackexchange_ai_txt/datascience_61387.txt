[site]: datascience
[post_id]: 61387
[parent_id]: 
[tags]: 
Suggestions on non-linear dimensionality reduction for small, one-hot encoded dataset

I wish to apply non-linear dimensionality reduction on a very small dataset (less than 100 observations). The dataset is very sparse , of approx 20 columns, each containing either 0 or 1. It's the result of a set of non-exclusive on-hot encoding of features. Observations are of this kind: --------------------------------- | a | b | c | d | e | f | g | h | --------------------------------- | 0 1 1 1 0 0 0 0 | | 1 1 0 1 0 1 1 0 | | 0 1 1 1 1 0 0 1 | ... I tried with t-SNE , but its stochastic nature leads to very different results each time I run my code. Any suggestions for what shall I use? I also need a technique that is strictly non-hierarchical (such as PCA, for example, in which each factors explains just the "leftovers" of the variance of the previous factor; I don't want that).
