[site]: crossvalidated
[post_id]: 435680
[parent_id]: 435618
[tags]: 
Both approaches lead to unbiased estimators, hence comparing their variances amounts to comparing their second moments. Without loss of generality, since the distributions of $X$ and $Y$ are arbitrary, we can take both $\varphi_1$ and $\varphi_2$ to be the identity transform. Then $$\mathbb E[(\bar X\bar Y)^2]=\mathbb E[\bar X^2]\mathbb E[\bar Y^2]=\frac{n\mathbb E[X]+\sigma^2_X}{n}\frac{n\mathbb E[Y]+\sigma^2_Y}{n}$$ while $$\mathbb E[\overline {XY}^2]=\frac{n\mathbb E[X]\mathbb E[X]+\sigma^2_{XY}}{n}$$ Therefore if both $\mathbb E[X]$ and $\mathbb E[Y]$ are close to zero $$\mathbb E[(\bar X\bar Y)^2]=\text O(n^{-2})\quad\text{and}\quad\mathbb E[\overline {XY}^2]=\text O(n^{-1})$$ while otherwise mileage may vary $$\mathbb E[(\bar X\bar Y)^2]=\text O(n^{-1})\quad\text{and}\quad\mathbb E[\overline {XY}^2]=\text O(n^{-1})$$ Using the same example as in the earlier answer shows that the variability is slightly lower for the product of the averages (left) than for the average of the products (right), obtained over 10³ replications of 10⁴ simulations (the 10³ curves are the cumulated means): If we compare directly the variances estimated from the 10⁷ simulations in this example $$\text{var}(\bar X\bar Y)=\text{var}(\bar X)\mathbb E[\bar Y^2]+ \text{var}(\bar Y)\mathbb E[\bar X]^2\qquad\qquad\qquad\\=\frac{\text{var}(X)}{n}\frac{\mathbb E[Y^2]+(n-1)\mathbb E[Y]^2}{n}+\frac{\text{var}(Y)\mathbb E[X]^2}{n}$$ is estimated by [1] 8.990575e-07 while the variance of $\overline{XY}$ is estimated by [1] 1.097814e-06 If anything, I would favor the $\bar X\times\bar Y$ solution as it also writes as $$\frac{1}{n^2} \sum_{i=1}^n\sum_{j=1}^n X_iY_j$$ giving the impression it exploits the independence between both samples in a more systematic manner.
