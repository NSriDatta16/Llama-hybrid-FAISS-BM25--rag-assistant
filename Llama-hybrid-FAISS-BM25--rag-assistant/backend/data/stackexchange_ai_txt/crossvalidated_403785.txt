[site]: crossvalidated
[post_id]: 403785
[parent_id]: 403749
[tags]: 
With $20$ iterations you are exploring $\tfrac{20}{1 \times 4 \times 4 \times 2 \times 2 \times 7 \times 4} \approx 1\%$ of the parameter grid, so you would be exploring only a small fraction of the search space. You would need many more iterations then this. For finding the optimal parameters algorithms smarter then random search (e.g. based on Gaussian processes, or tree-based ), should be faster in many cases. Still, you would need many more iterations for reasonable results and since random search has no overhead, then your model is a bottleneck, so this will take some time. The ultimate solution is to buy, or rent cloud-based) a better computer, with more CPUs, more RAM, and with GPUs (XGBoost and LightGBM have support for GPUs). If this is not an option, you could try training the model on smaller subsets of the data.
