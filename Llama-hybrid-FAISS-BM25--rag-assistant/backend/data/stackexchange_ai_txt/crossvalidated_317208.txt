[site]: crossvalidated
[post_id]: 317208
[parent_id]: 
[tags]: 
Credible intervals from bayesian NN misbehave

I am using Edward , to create a Bayesian neural network for non-linear regression. My training set consists of time series that all end at 0 but after doing inference the predictions (and thus the credible intervals) do not seem to pick up on that i.e the network is not getting more confident as it approaches zero. The way I am generating my predictions and credible intervals is the following n_of_preds = 200 xp = tf.placeholder(tf.float32, [Np, D]) y_post = tf.placeholder(tf.float32,[Np,D]) A1 = neural_network_with_2_layers(xp,q_W_0, q_W_1,q_b_0, q_b_1) A2 = tf.reshape(A1,[Np,1]) y_post = Normal(loc=A2,scale=q_sigma) # Generating some outputs and averaging them outputs = np.vstack([sess.run(y_post,{xp:X_test_norm}) for _ in range(n_of_preds)]) outputs = outputs.reshape([n_of_preds,X_test_norm.size]) p = np.average(outputs,0) # De-normalization of the outputs using the train tests dists = np.zeros(first_values_train.size,dtype=object) for i in range(first_values_train.size): dists[i] = np.linalg.norm(first_values_train[i]-first_values_test) dists.astype("float32") min_dist_index = np.where(dists == np.min(dists)) Y_denorm = Y_train_max[min_dist_index] p_denorm = ((p+1)/2)*Y_denorm def Credible_intervals_from_predictions(predictions,credible_mass): ecdf = ECDF(predictions) z = ecdf.x w = ecdf.y w.astype("float32") w = np.around(w,decimals=3) # Find the index of w where w = 0.95/0.05 to know which values of z to keep u1 = np.where(w==credible_mass) a2 = 1 - credible_mass u2 = np.where(w==(np.around(a2,decimals=3))) # Upper and lower bounds of the interval UB = z[u1] LB = z[u2] return (LB,UB) # Upper and lower bound for p (with q_sigma) UB = np.zeros(outputs[0].size) LB = np.zeros(outputs[0].size) for i in range(outputs[0].size): LB[i],UB[i] = Credible_intervals_from_predictions(outputs[0:,i],0.95) # De-norm them UB = ((UB+1)/2)*Y_denorm LB = ((LB+1)/2)*Y_denorm What am I doing wrong? EDIT: Added a figure
