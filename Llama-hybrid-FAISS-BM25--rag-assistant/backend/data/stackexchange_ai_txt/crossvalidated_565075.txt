[site]: crossvalidated
[post_id]: 565075
[parent_id]: 563696
[tags]: 
Scott Aaronson has a nice survey paper " Quantifying the Rise and Fall of Complexity in Closed Systems " on several related approaches to formally defining complexity in a way which matches intuition - as opposed to Kolmogorov complexity $^1$ (the minimum description length of some data), which is maximized when the data is random bits. Kolmogorov sophistication measures this by factoring out from the data $x$ a "non-random part" $S$ . In particular, we say $S$ is a set of similar looking instances of which $x$ is one member. There has to be a constraint that $K(S) + \log_2 |S| \leq K(x) + c$ , which prevents us from picking a trivial $S$ for low-complexity strings. Then, the sophistication of $x$ is the smallest $K(S)$ which satisfies our constraint. To make a long story short, Scott Aaronson describes an extremely crude way to compute sophistication for images: define $S$ to be the set of images which look the same as $x$ when downsampled in resolution by some factor, and estimate it's Kolmogorov complexity -- so basically, downsample $x$ and (losslessly) compress it, and measure the resulting size. Practically, this assigns nearly 0 sophistication to a totally blank image, or to random noise (which, when downsampled, averages out to grey everywhere). What maximizes sophistication is random noise, but on the same scale as downsampling -- e.g. if you downsample by a factor of 5 to estimate sophistication, having each 5x5 block of pixels being a random color maximizes this measurement. $^1$ A quick description of Kolmogorov complexity $K(x)$ is that it's the length of the shortest computer program which can generate/print out an exact copy of your data $x$ . A simple way to compute an upper bound on $K(x)$ is 1. pick your favorite compression algorithm, compress $x$ . 2. take the size of the compressed content, add it to the size of the algorithm used to compress it (although often, the length of the algorithm may be omitted..) - and this is your upper bound. A totally different approach might be to just compute the power spectrum of a bunch of natural images. I'd guess that the general shape of the power spectrum of natural images would be pretty distinct from many types of "artificial images".
