[site]: crossvalidated
[post_id]: 231958
[parent_id]: 231954
[tags]: 
There seems to be a fairly deep misunderstanding of what you're trying to do, so while this may solve your immediate problem, I urge you to read one or several tutorials on out of sample prediction. This question is not about xgboost, and it is not about labels -- it is about a basic statistical procedure, that it is imperative to understand before doing analysis. In your example, you are using the same function twice -- in the second case, trying to FIT a NEW model to your testing data (without labels). However, labels or NOT, this is not what testing data is FOR. When you are doing out of sample prediction: First, you fit a model based on your training data, and get parameter estimate $\hat{\theta}$ (your fitted model). $$ Y_{train} \sim f(X_{train}; \theta) $$ Then, using your fitted model, and your testing data, you PREDICT new labels -- in other words, what SHOULD the labels on your test data be, based on what your model says? $$ \hat{Y}_{test} \leftarrow f(X_{test}; \hat{\theta}_{train}) $$ Last, you compare the actual testing labels with the predicted ones, to get your out of sample error. $$ \mathbb{E}[(\hat{Y}_{test} - Y_{train})^2] $$ A very quick search of the xgboost documentation returns the predict function: ## S4 method for signature 'xgb.Booster' predict(object, newdata, missing = NULL, outputmargin = FALSE, ntreelimit = NULL, predleaf = FALSE) Meaning, the call you really want is: y.test.hat I hope that sets you on the right track, but I also hope that the next time you spend hours stuck on something, you consider that it may not be a software problem.
