[site]: crossvalidated
[post_id]: 231238
[parent_id]: 
[tags]: 
Confused by a simple setting in Bayesian inference

I want to use Bayesian approach to test whether a single data point $x$ came from model $M_1$ or model $M_2$. I am having difficult time to get my head around this very basic setting. I make a few steps a long the way and then I get stuck \ confused. So the two models are: $$ M_1: X \sim N(0, 1)\,, $$ $$ M_2: X \sim N(\mu, 1)~~~ \text{ with }~~ \mu \sim U[1, 2]\,. $$ Where $N(\mu, \sigma^2)$ stands for Normal distribution with mean $\mu$ and variance $\sigma^2$, and $U[a, b]$ is uniform distribution. My attempt to find the posterior odds. By Bayesian formula $$ \frac{P(M_1|x)}{P(M_2|x)} = \frac{P(x|M_1)}{P(x|M_2)}\frac{P(M_1)}{P(M_2)}\,. $$ At this point I need to introduce priors for $M_1$ and $M_2$ let those be $\pi_1$ and $\pi_2 = (1- \pi_1)$, this leads to $$ \frac{P(M_1|x)}{P(M_2|x)} = \frac{P(x|M_1)}{P(x|M_2)}\frac{\pi_1}{ (1- \pi_1)}\,. $$ Here I already get confused - formally probability of $P(X = x|M_1) = 0$ , any way, I do continue $$ P(X = x|M_2) = \int f_{(X|\mu)}(x)f_\mu(\mu)d\mu \,, $$ where $f_{(X|\mu)}(\cdot)$ is conditional probability density of $X$ given $\mu$ and $f_\mu(\cdot)$ is probability density of $\mu$. $f_\mu(\cdot)$ is uniform on $[1,2]$. Thus, $$ P(X = x|M_2) = \int f_{(X|\mu)}(x)f_\mu(\mu)d\mu = \int_1^2 \frac{1}{\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2}}d\mu = C \neq 0\,. $$ Overall $$ \frac{P(M_1|x)}{P(M_2|x)} = \frac{P(x|M_1)}{P(x|M_2)}\frac{\pi_1}{ (1- \pi_1)} = \frac{0}{C}\frac{\pi_1}{ (1- \pi_1)} \equiv 0\,. \quad(\textbf{?}) $$ So, regardless of $x$ the odds in favor of $M_0$ are zero. Am I having not enough coffee? did I get the Bayesian development above all wrong, should I have used likelihood function instead of probability (that is to look at densities not probabilities)? I would appreciate any help, thanks!
