[site]: crossvalidated
[post_id]: 564818
[parent_id]: 564782
[tags]: 
Interactions technically are products between predictor variables. So what you have simulated (and seem to have interpreted correctly) is an effect of a single predictor variable ( sideSame ) on your binary outcome , which is "whether or not they go for a rewarding option." That's not an interaction. If you think that there is a systematic difference between left- versus right-side presentations in some respects you could include leftSide as an extra predictor in your model in addition to sideSame , and maybe even an interaction between leftSide and sideSame , depending on your knowledge of the subject matter. In response to comment: Two things can be hard to grasp. First, as you add more predictors, the interpretation of the intercept changes. For dummy/treatment coding, it's the estimated outcome when all categorical predictors are at reference levels and continuous predictors are at 0. So as you add more predictors the intercept is expected to change. Second, when you include interactions, the interpretation of lower-level regression coefficients changes. A lower-level coefficient for a predictor then is for a case when the predictors with which it interacts are at reference or 0 levels. It can help to write out everything explicitly in terms of the predictors and interactions. Then you plug in various predictor values to see specifically what you are modeling. Let's call the sideSame predictor S (=1 if training and test side are the same), call age A (=1 for adult, 0 for juvenile), and call the actual side presented in the test case L (=1 if left, 0 if right). Then a model without interactions would be: choice ~ 1 + S + A + L Plugging in 0 for the 3 predictors, you see that the intercept would be for different training from test side, juvenile age, test side right. Each coefficient is then the change from that intercept when the predictor takes the other value. An interaction between sideSame and age would be: choice ~ 1 + S + A + L + S:A where the S:A interaction is just the product of the individual 0/1 values for S and A . The intercept is interpreted the same as above, but the S coefficient is the value for the A = 0 case (juvenile), and the A coefficient is the value for the S = 0 case (different train/test sides). The coefficient for S:A is the extra difference when both S = 1 and A = 1 . Writing out the explicit form of the linear predictor, recognizing that interaction terms are just products of the individual predictors that are involved, is the safest way to avoid arguing yourself into confusion. Remember that each predictor and interaction term that you add to the model requires a correspondingly larger study. With logistic regression in this type of biological study, you typically need to have about 10-20 cases in the minority outcome class per predictor (including interactions) to avoid overfitting. So to fit the last model with the interaction term you would need on the order of 2 * 60 = 120 observations if the choice outcome was evenly divided between rewarding/not.
