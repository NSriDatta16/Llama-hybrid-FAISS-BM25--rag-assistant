[site]: crossvalidated
[post_id]: 346046
[parent_id]: 346042
[tags]: 
Regression models do not assume independence of the explanatory variables, so it is perfectly legitimate to use a logistic regression with one explanatory variable that is dependent on another. The issue of statistical dependence between explanatory variables is called multicollinearity , and it affects the results of your model, but does not invalidate it. Multicollinearity between explanatory variables in your model means that there is some redundancy in the information provided by those explanatory variables. Bear in mind that if you are ultimately looking for the joint distribution of $Y,Z \bot \boldsymbol{X}$ then you will have to be careful getting this. It is not easy to put separate regression models together to estimate joint behaviour, and so you may be better off using a single model that treats $(Y, Z)$ as your response. Since you are working with two binary response variables, your problem could be handled by using a multinomial logistic regression with four outcome possibilities; this analysis can be conducted in R using the multinom function in the nnet package.
