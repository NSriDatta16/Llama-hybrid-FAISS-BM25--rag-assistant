[site]: crossvalidated
[post_id]: 606868
[parent_id]: 
[tags]: 
Visualize difference between time series lines, with similar changes over time and missing data

I have a large set of objects that each generate a multivariate time series at a daily to hourly resolution. As an example, let's say that they are weather stations generating variables for temperature, humidity, etc. Generally speaking, for each variable, the data from each object changes similarly over time. Here's an example of two variables, each from the same three sources (identifying info replaced with weather station example): I want to qualitatively evaluate how "good" each object is, and compare around 2 to 10 at a time. For each variable, higher is better and lower is worse or vice versa. In the plots above, it's pretty clear that orange > green > blue, but it's not always this obvious and there are usually a lot more things to look at, so I want to visually condense the information. How can I do this in a way that condenses the information as much as possible while still giving the reader as much qualitative information as possible? My current approach is that for each variable, I normalize by subtracting the median value from each timestep to remove the day-to-day variation that I don't care about, and then divide all timesteps by the average value to get a sort of normal distribution. Since all variables now follow this distribution, I can superimpose them on one another, and then get a strip plot like one of these (I also change the dot intensity based on recency, since I care a bit more about the most up-to-date information): Both of these can, at a glance, give me a good intuition for how significant the differences are and what anomalies might exist. I don't care about the actual value of the difference here, only the relative rankings and overall "shape" of the data. The issue is missing data. These strip plots were generated from examples where there was no missing data, but the data coverage is highly variable. Scattered missing data is common like in the first line plot, and there can also be objects that just stop generating data entirely, so they only exist for e.g. the first 25% of the time range. This can result in plots that look like this: With more objects, less consistent data, and more variance, it can be difficult to get as much out of these plots as I want to. Thinking about the problem in a very simple sense, I basically want to take the line plot for one variable, then shift each timestep as a whole up or down so that each color is as grouped as possible and as distinct as possible from the other colors. This seems to point to an optimization problem where we try to minimize the squared distance between each dot and the other dots of the same color. However, that seems difficult to solve easily, since it's not unusual to have 3 variables, 10 objects, and 100 timesteps. Is there a good way to normalize the data consistently, given that many of the data points I would want to include in naive normalization are missing?
