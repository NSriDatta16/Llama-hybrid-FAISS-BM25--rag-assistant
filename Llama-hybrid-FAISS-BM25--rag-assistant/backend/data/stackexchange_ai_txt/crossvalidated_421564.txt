[site]: crossvalidated
[post_id]: 421564
[parent_id]: 421546
[tags]: 
Well, in Bayesian world, you could do something like this (bugs/JAGS notation): intcept ~ dnorm(0, 0.01) sigma ~ dunif(0, 10) X_SE ~ dunif(0, 10) Y_SE The X[i] and Y[i] are your measurements; X_real and Y_real are the real values, which you don't know. X_SE and Y_SE are your measurement errors of X and Y. This is actually beautiful in bayesian models, that you can model this very easily. And the regression itself is done on those latent (unknown) values of X_real and Y_real. It is advised to standardize X. Not sure how to do this in non-bayesian setting. Gaussian processes should be also able to handle uncertain input data, but I have no experience with that. EDIT: I realized that this model would have an issue to identify the parameters X_SE and Y_SE. It can only be applied if you have some estimate how big these errors are since the model has no information how to tell how big these errors actually are.
