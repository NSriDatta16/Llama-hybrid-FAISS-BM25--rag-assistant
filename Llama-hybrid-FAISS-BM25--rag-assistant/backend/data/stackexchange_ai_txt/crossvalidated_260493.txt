[site]: crossvalidated
[post_id]: 260493
[parent_id]: 259908
[tags]: 
So here is how I initially made the data: ## libraries and purpose library(NbClust) library(pracma) ## main set.seed(1) #how many trials per sample-size N_tests = 1/N_samp[i]) zval This gave me a csv file, which I imported into JMP, stacked the DZ columns, looked for non-zero values, and then averaged them to get a table of separation that has 50/50 likelihood of not containing a mis-classification, and then fit it in the bivariate platform as shown here: I think the log-log domain, third order polynomial fit is the best one. I don't believe it is much more than a transformed version of a taylor series approximation to the truth, but it is what I have. $ dx \left( N,P \right) |_{P = 50 \%} = e^{1.3989 - 0.1221 \cdot ln \left(N\right) + 0.07444 \cdot ln \left(N\right)^{2} - 0.007329 \cdot ln \left(N\right)^{3}}$ And yes, I used the level of local oscillations in the spline to determine a decent fit parameter. Someday I will apply a Fourier method to it to find the best parameter, or I will find someone else who has done it, but until then I will use it as an "eyeball norm" to augment fit parameters. The sampling delta for x was about 0.04 units. I would expect error in the mean to be on that scale. I would also expect the trendline error to be less than that.
