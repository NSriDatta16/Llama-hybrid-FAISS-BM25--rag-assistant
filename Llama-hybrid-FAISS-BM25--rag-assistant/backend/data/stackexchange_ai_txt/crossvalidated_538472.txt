[site]: crossvalidated
[post_id]: 538472
[parent_id]: 538460
[tags]: 
Your assumptions are very straightforward, and there are no problems with what you envision. While correlation can be used to understand the informativeness of each property feature in terms of linear association (covariance) with class, regression is better since it can actually determine what property features are the most optimal predictors of class. Obviously, you're supposed to have, in terms of sampling, a lot of values for property1, e.g. $n=30$ for fish in class 1, $n=30$ for cats in class 2, and $n=30$ for horses, plus a lot of values for the other two classes of mammals. In other words, you need sampling variation based on measurements of all the property features from many different animals in the same class. Then, you can easily determine correlation between class and each property, since class is already ordinal, since it's in the Likert scale with a gradient-based definition --> lower is low weight, higher is high weight. Linear regression and polytomous (polychotomous) logistic regression are easy classifiers to use as well. Correlation is not really used for class prediction, at least not nearly as much as various regression models are used. Once you can apply logistic regression or linear (it would have to be multivariate normal regression), you can then branch out to classification analysis using by K-nearest neighbor (KNN), naive Bayes classifier (NBC), discriminant analysis (LDA), quadratic discriminant analysis (QDA), Fisher discriminant analysis (FDA), decision tree classification (DTC), supervised random forests (SRF), learning vector quantization (LVQ), gradient ascent support vector machines (SVMGA), least squares support vector machines (SVMLS), supervised artificial neural networks (SANN), kernel regression (KREG), particle swarm optimization, supervised neural gas (SNG), and mixture of experts (MOE).
