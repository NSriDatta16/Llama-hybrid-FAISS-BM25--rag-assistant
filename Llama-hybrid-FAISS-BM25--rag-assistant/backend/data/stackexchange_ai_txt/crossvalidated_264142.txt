[site]: crossvalidated
[post_id]: 264142
[parent_id]: 263879
[tags]: 
It depends on the sampling distribution and on the loss function as well as the dimension of the parameter. For instance, the MLE of a multivariate Gaussian mean is admissible when the dimension is $p=1,2$ under quadratic loss. Since its risk is constant, it is the sole admissible minimax estimator. This does not hold for $p\ge 3$, a phenomenon called the Stein effect . ( Brown (1966) shows the wide generality of this phenomenon.) In Strawderman (1972) , the author shows the existence of proper Bayes [hence admissible] minimax estimators of the multivariate Normal mean for dimensions $p\ge 5$. One example of such estimators is associated with the priors$$\theta\sim\text{N}_p(0,\lambda^{-1}\lambda\mathbf{I}_p)\qquad \lambda\sim\lambda^{-a}/(1-a)\quad 0\le a\le 1$$ In Berger and Robert (1990) , we extended this result and obtained a family of priors leading to admissible minimax estimators of the multivariate Normal mean. This was further extended by Berger and Strawderman (1996) . In Ghosh and Amin (1981) , the authors exhibit a family of proper Bayes [hence admissible] minimax estimators of the p-variate Poisson mean, under the sum of weighted squared error losses, when $p\ge 3$, weights being reciprocals of variances. For instance, for a prior$$\pi(\lambda)\propto\lambda^{m-1}\{1+\lambda\}^{-(n+m)}\qquad 0 0,$$the associated posterior mean $$\mathbb{E}[\lambda|\mathbf{x}]=\dfrac{z+m+p}{z+m+n+p-1}\mathbf{x}\qquad z=\sum_{i=1}^p x_i$$is proper Bayes minimax admissible.
