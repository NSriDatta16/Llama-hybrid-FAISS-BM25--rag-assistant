[site]: datascience
[post_id]: 41895
[parent_id]: 41894
[tags]: 
You seem to experience a class imbalance situation where some classes dominate the others by the number of samples they have, so that your algorithm finds it wise to predict less of the rare classes or non-predict them to decrease the loss at the end. You can manually set the class weights for the Random Forest Classifier, making loss function treat unevenly to different classes, but even in total. For details you can refer to: https://stackoverflow.com/questions/20082674/unbalanced-classification-using-randomforestclassifier-in-sklearn Note: Random Forest is not robust to class imbalance, this is a known situation. You can refer to: https://stats.stackexchange.com/questions/242833/is-random-forest-a-good-option-for-unbalanced-data-classification Hope if I could help. If not, I will be around for further discussion.
