[site]: datascience
[post_id]: 124245
[parent_id]: 124230
[tags]: 
For classification, we generally want the output to be between 0 and 1, to be able to interpret it as a probability. As show in your graph a linear regression can go to +/- infinity, well outside of the (0,1) range. For example how would you interpret a -1 outputted by the model here ? It is not that bad if you are interested in relative ranking. As is, a linear model would give you a good AUC for exemple. But the model would not be calibrated in probabilities. The other problem that is visible on your graph is that the linear regression would be more sensitive to outliers. The line change significantly with (blue) and without (pink) the last outlier, while a logistic regression would mostly be determined by the interface between points with (y=0 and y=1).
