[site]: crossvalidated
[post_id]: 263405
[parent_id]: 
[tags]: 
Random Forest regression for time series prediction

I'm attempting to utilise RF regression to make predictions on the performance of a paper mill. I have minute by minute data for the inputs (rate and amount of wood pulp going in etc...) as well as for the performance of the machine (paper produced, power drawn by the machine) and am looking to make predictions 10 minutes ahead on the performance variables. I've got 12 months of data, so have separated it into 11 months for the training set, and the final month for testing. So far I have created 10 new features which are lagged values by 1-10 minutes for each of the performance variables, and used these as well as the inputs to make predictions. The performance on the test set has been quite good ( the system is quite predictable), but I'm worried that I'm missing something in my approach. For example, in this paper , the authors state their approach in testing the predictive ability of their random forest model: The simulation proceeds by iteratively adding a new week of data, training a new model based on the updated data, and predicting the number of outbreaks for the following week How is this different from utilizing 'later' data in the time series as testing? Should I be validating my RF regression model with this approach as well as on the testing data set? Furthermore, is this sort of 'autoregressive' approach to random forest regression valid for time series, and do I even need to create this many lagged variables if I'm interested in a prediction 10 minutes in the future?
