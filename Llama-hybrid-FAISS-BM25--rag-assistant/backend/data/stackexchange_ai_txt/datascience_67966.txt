[site]: datascience
[post_id]: 67966
[parent_id]: 67950
[tags]: 
CNNs like U-Net extract lower level features like edges on lower layers (i.e. the first convolutional layers) and higher level features on higher layers (i.e. convolutional layers closer to the final linear layers). This principle is losely inspired by how visual perception is implemented in the Visual Cortex among humans (and other animals). In a CNN the feature maps could for example look like this: As you can see the lower level feature maps detect simple structures like edges while higher level feature maps recognize more complex structures like eyes or faces. Colors, however, are processed differently by CNNs than spatial features since color images are usually fed to CNNs using three input channels (one for each color in RGB format ). So colors are not detected in the same way as spatial features but instead the first convolutional layer receives a 3-dimensional input image with one dimension for each color-component (one for red, one for green, one for blue). The article What exactly does CNN see? and the paper Visualizing and Understanding Convolutional Networks (which are also the sources of above images) provide a more detailed explanation.
