[site]: crossvalidated
[post_id]: 213159
[parent_id]: 
[tags]: 
How to improve a bad long-term forecasting of time series in common case

I have two time series $d_t(t)$, $d_c(t)$, where I'm modelling charge as a function of time. Lengths of time series, $N$ are equal to $101$ data points. For the $d_t(t)$ (test sample, short-term) the time interval between observations is $t_1 = 0.1$ sec, and for the $d_c(t)$ (control sample, long-term) the time interval is $t_2 = 1$ sec. Thus, the right boundary of time for $d_t(t)$ is equal to $0.1\times 100 = 10$ sec, and the right boundary of time for $d_c(t)$ is equal to $1 \times 100 = 100$ sec. Both $d_t(t)$, $d_c(t)$ are correspond to the one experiment. The accuracy of measurements is $tol=0.001$. Here's some sample data and visualization, dtest As we can see from figure above the data from start region is increasing exponentially $f(x)=(1+exp(-x/t))$, later they are increasing (stationary) with linear rule, like $f(x)=kx+b$. I'd like to forecast a value of $d_t(t)$ at time point $t=100$ sec, i.e. I have 10 seconds of history and want to forecast out 90 seconds. Then verify the forecasting $d_t^p(t=100)$ with corresponding value from the $d_c(t=100)$. The forecasting is satisfactory, if $$0.95 \times d_c(t) \leq d_t^p(t)\leq 1.05 \times d_c(t).$$ On physical grounds, the experimental data can be described with an exponential function $f(x) = a \times (1+exp(-(x/\tau)))$, where $a$, $\tau$ are parameters. I have been doing curve-fitting $d(t)$ in R using nlminb . The initial values of the parameters for optimization are chosen based on the physical characteristics of the process: parConv . The result is below: $a= -1.03084$, $\tau= 0.50464$. Unfortunatly, the forecasting $f(t=100)=-1.030845$ does not satisfy to the range: $$f(t=100) = -1.030845 \bar{\in} [0.95 \cdot (-0.952), 1.05 \cdot (-0.952)]=[-0.9044, -0.9996].$$ I have tried to split the original time series $d_t(t)$ into two parts: $d_{t_1}(t=1..10)$ and $d_{t_2}(t=11..101)$, then I have approximated the $d_{t_2}(t=11..101)$ using a linear function $f_1(x)=kx+b$ and a polynomial $f_2(x)=ax^2+bx+c$. Result are better but not satisfy to the range: $f_1(x)=-1.05851+x \cdot 5.61364\cdot 10^{-4}$, and $f_2(x)=-1.0718+x\cdot 0.0012+x^2 \cdot (-5.86943\cdot 10^{-6})$, Adj. R-Square = 0,9815 . Then I have obtained the forecasts: $f_1(t=100)=-1.002374$ and $f_2(t=100)= -1.010494$. My question is : How to improve a bad long-term forecasting of time series in common case? Another possible solutions are: Apply function ln() to the original data $d_t(t)$ and repeat fitting. To use an exponential function and to assign greater weight to the $k$ last points (like here ). To use some alternative models, for example, Autoregressive moving-average model , _https://en.wikipedia.org/wiki/Backcasting. Example code: library(minpack.lm) library(ggplot2) library(optimx) d
