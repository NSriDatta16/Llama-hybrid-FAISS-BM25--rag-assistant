[site]: crossvalidated
[post_id]: 406680
[parent_id]: 406666
[tags]: 
Your understanding is correct, extraTrees does implement Geurts et al. (2006) Extremely randomized trees . The implementation of extraTrees has been discussed in detail in Github's thread on that issue so I would strongly urge you read it further here . Regarding the particular questions raised: Yes, but read on! By default the same number of candidates mtry is used, this being calculated as the (rounded down) square root of the number variables. It makes sense for ranger to use a particular number for mtry because that way it can be effectively regularised. Theoretically, we should indeed restrict the choice to a random subset to begin within each tree. Nevertheless as the choice of the attribute to split as well as the split itself are random this difference is mostly a formality. Yes, you can. By far the main novelty in Geurts et al. is the way that nodes are split by choosing cut-points fully at random; that is something that ranger definitely does. You could/should specify in the paper that the implementation used is the one from ranger to alleviate any uncertainties. You are correct; the default values hurt us here. That said if during training, we sample without replacement (i.e. we set replace = FALSE ) as well as set the fractions of observation to sample to 1 (i.e. we set sample.fraction = 1 ) we will not get a OOB error and the forest is trained on the whole sample. You might want to create a new issue about this in ranger 's github repo. It will mostly be a case of re-adjusting the defaults when splitrule='extraTrees' but we can do it manually too. To recap: If we use rf we can safely say that we use Geurts et al. implementation. All the core differences between extremely randomized trees and "standard" random forests are respected. Minor point on regarding reporting OOB or not: While indeed OOB estimates can substitute the presence of a separate test set, I find it much more clear if there is a distinct test set and/or we use repeated CV or bootstrapping. It makes the comparison with other approaches (e.g. a simple linear model or an SVM) more comparable and coherent.
