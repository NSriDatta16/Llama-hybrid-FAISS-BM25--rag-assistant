[site]: crossvalidated
[post_id]: 140485
[parent_id]: 140435
[tags]: 
You can... the question remains whether you should . And if it were me, I wouldn't . Here's one way to combine the models: in each model (separately), compute the joint probability table at each node; then combine the joint probability tables by weighting them by the likelihood of the entire network given the data you're trying to model (which I assume you have). So if you have JPTs $T^i_1$ and $T_2^i$, with model likelihoods $L_1$ and $L_2$, you can have a "mixed" JPT $T^i_{mixed} = \frac{L_1T_1^i + L_2T_2^i}{L_1 + L_2}$ If you get very lucky, $L_1$ and $L_2$ will be on the same order of magnitude, and you'll get some meaningful mixture of the first and second networks. However, that's very, very unlikely, and this mixture is just going to give you back either $T_1$ or $T_2$, with some astronomically small changes, while at the same time ruining the causal structure. Just because the nodes of two Bayesian Networks are the same does not mean that there is any meaningful relationship between them; and the reason I wouldn't try averaging these two models is because reversing the causal structure tells the opposite story; if you believe in a certain chain of causation and its opposite, what a priori reason is there to then reject any set of causal relationships? In a graph of $N$ nodes, there are $2^{\omega(N)}$ different DAGs that can represent, so picking two that are reverses of each other is like picking two grains of sand out of all the beaches in the world and trying to infer all the properties of sand from just those two.
