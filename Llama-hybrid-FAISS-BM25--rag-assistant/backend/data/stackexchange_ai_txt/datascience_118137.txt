[site]: datascience
[post_id]: 118137
[parent_id]: 
[tags]: 
why some authors said that BERT cannot be used for text prediction?

I was trying to get a grasp about BERT and found this post in DS StackExchange: Can BERT do the next-word-predict task? In broad terms, it says that Bert cannot be used for next-word prediction. I suppose that next-word prediction it could be used, for example, in some sort of autocorrect tools. However, I saw in this blog: https://medium.com/mlearning-ai/an-illustration-of-next-word-prediction-with-state-of-the-art-network-architectures-like-bert-gpt-c0af02921f17 That BERT could be used for text prediction; so, why it is said that it cannot be used for next-word prediction? If somebody could explain the caveats of it and an example to clarify this, it would be really helpful. Thanks.
