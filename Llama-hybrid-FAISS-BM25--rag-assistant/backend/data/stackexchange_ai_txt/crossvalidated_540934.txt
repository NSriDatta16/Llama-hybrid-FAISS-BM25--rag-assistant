[site]: crossvalidated
[post_id]: 540934
[parent_id]: 540906
[tags]: 
The criteria for 'significant'/'not significant' in a Neymanâ€“Pearsonian hypothesis test are based on the error rate characteristics of the test, determined in advance of seeing the data. (See this for an explanation of hypothesis tests and p-values: https://link.springer.com/chapter/10.1007/164_2019_286 ) The dichotomy is not as universal or as useful as many beginner statisticians think. With a Bayesian posterior you usually do not have access to the error rate considerations and so the 'significant'/'not significant' dichotomy is usually not applicable. You might choose to set up criteria for inclusion into a set of classes for your devices on the basis of probability ratios for a specified hypothesis (i.e. a parameter in the statistical model that makes up the x-axis of your likelihood functions) compared to the maximally probable hypothesis but you must not call it 'significant'/'not significant'! However, the characteristics of the test that you invent would be generally unknown and so the utility and desirability of such a procedure would need to be explored. Perhaps you should be asking a different question. Explain your data and inferential objectives and ask for suggestions as to how you might proceed. It might be that a Bayesian posterior is appropriate, but that is not clear to me. (You failed to say anything about the prior used to convert the likelihoods into posterior probabilities. That is bad practice.)
