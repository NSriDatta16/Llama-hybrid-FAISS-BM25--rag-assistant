[site]: datascience
[post_id]: 15961
[parent_id]: 15960
[tags]: 
One method would be to take many subsets of your dataset, i.e. bootstrapping , build your models, perform cross-validation and calculate the average performance. This is a good explanation of how the amount of data affects the model outcomes: https://stackoverflow.com/questions/25665017/does-the-dataset-size-influence-a-machine-learning-algorithm Play around with the size of your subsets until you start getting stable results.
