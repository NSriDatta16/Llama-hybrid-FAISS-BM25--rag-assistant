[site]: crossvalidated
[post_id]: 532061
[parent_id]: 531978
[tags]: 
There are plenty of machine learning models that are all about possibly correlated data. Examples include LSTM and transformer neural networks, Gaussian processes, AR/MA/ARMA/ARIMA/etc. models, various forms of mixed models such as hierarchical models, spatial models, GAMMs and so on. Ignoring an existing correlation is often a very bad idea and using a model that can reflect a correlation is usually a good idea. There's also various techniques to try to reduce the time series nature of data (e.g. building a lot of features based on the past history etc.) that might make ML models that assume i.i.d. observations fit better. One way to evaluate whether using a model that ignores correlations is an option is to use some suitable form of (cross-)validation such as past-vs.-future splits for time series or sampling clusters (rather than individual records) in cross-validation in case of clustered data. If with a good validation strategy a model that ignores the correlations works great, then maybe it's an option.
