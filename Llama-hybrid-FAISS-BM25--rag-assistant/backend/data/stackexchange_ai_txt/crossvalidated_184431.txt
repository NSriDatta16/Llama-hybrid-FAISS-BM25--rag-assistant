[site]: crossvalidated
[post_id]: 184431
[parent_id]: 182734
[tags]: 
I've also been confused a bit in the beginning by the difference between neural networks (NN) and deep neural networks (DNN), however the 'depth' refers only to the number of parameters & layers, unfortunately. You can take it as some sort of re-branding under the so-called 'Canadian Mafia'. Several years ago, I also had Neural Networks as a part of a class and we did digit recognition, wave approximation and similar applications by using NN, which had multiple hidden layers and outputs and all that jazz that DNN's have. However, what we didn't have then was computing power. The reason that made the move to DNN possible and desirable are the advances in hardware development. Simply put, now we can compute more, faster and more parallelized (DNN on GPU's), while before, time was the bottleneck for NN's. As referenced on the Wikipedia's page for Deep Learning , the 'deep' part refers mostly to having features interact in a non-linear fashion on multiple layers, therefore performing feature extraction and transformation. This was also done in standard NN's, however at a smaller scale. On the same page, here you have the definition 'A deep neural network (DNN) is an artificial neural network (ANN) with multiple hidden layers of units between the input and output layers.'
