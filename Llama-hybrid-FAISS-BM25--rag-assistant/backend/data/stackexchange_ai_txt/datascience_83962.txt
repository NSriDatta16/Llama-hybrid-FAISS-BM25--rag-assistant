[site]: datascience
[post_id]: 83962
[parent_id]: 83961
[tags]: 
Which value should I take into account for saying that my model has an accuracy of ...? None. Accuracy is practically meaningless in such class imbalanced settings; the metrics of interest here are precision, recall, and f1 score. Now, it's true that the values of these metrics also fluctuate between runs, much similar to the reported accuracy. But this is to be expected due to the small-sample effects - your sample is so small that even a difference in the classification of a couple of samples in your (even smaller) validation set is enough to give the observed discrepancies. Does it make sense to run a model where there are so few values = 1 for the dependent variable? Indeed it does; there are plenty of applications where the positive values are a very small percentage of the whole dataset (thing of sick people versus the general population of healthy ones, or engine faults versus long-running times where no fault is present). That's why this is a (large enough) sub-topic of machine learning called class imbalance or imbalanced classification , with its own specific approaches. I suggest you start googling ruthlessly.
