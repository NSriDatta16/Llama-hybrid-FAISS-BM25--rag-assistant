[site]: crossvalidated
[post_id]: 443214
[parent_id]: 443137
[tags]: 
A bit late to the party but I wanted to clarify that the intercepts in your models have different interpretations, as follows. model1 The intercept for model1 represents the total points predicted by the model for a randomly selected athlete from your target population of athletes for whom m400 = 0, m1500 = 0, m100 = 0 and m110hurdles = 0. model2 The intercept for model2 represents the total points predicted by the model for a randomly selected athlete from your target population of athletes for whom Polevault = 0, Highjump = 0 and Longjump = 0. model3 The intercept for model3 represents the total points predicted by the model for a randomly selected athlete from your target population of athletes for whom Shotput = 0, Discus = 0 and Javelin = 0. These interpretations may not be meaningful in real life if the value 0 falls outside the range of observed values for each (or at least some) of your predictor variables. You can make them meaningful by centering your predictor variables around their mean or median values observed in your sample (whichever makes most sense). For example: samp1 $ShotputCen Shotput - mean(samp1$Shotput, na.rm = TRUE) samp1 $DiscusCen Discus - mean(samp1$Discus, na.rm = TRUE) samp1 $JavelinCen Javelin - mean(samp1$Javelin, na.rm = TRUE) model3Cen The intercept for model3Cen represents the total points predicted by the model for a randomly selected athlete from your target population of athletes for whom ShotputCen = 0, DiscusCen = 0 and JavelinCen = 0. In other words, it represents the total points predicted by the model for an athlete with typical (i.e., average) values for Shotput, Discus and Javelin.
