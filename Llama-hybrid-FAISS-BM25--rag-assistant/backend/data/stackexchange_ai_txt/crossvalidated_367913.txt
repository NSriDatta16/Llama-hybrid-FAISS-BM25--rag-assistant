[site]: crossvalidated
[post_id]: 367913
[parent_id]: 
[tags]: 
Maximizing cross entropy reinforcement learning

I have read that in reinforcement learning, maximizing the entropy enables the policy to behave more randomly. My question comes in three parts: (1) In the equation below in the cross-entropy term what does the dot â€¢ symbol stand for? (2) if maximizing the entropy also makes the policy behave more randomly - then does that mean that it prevents training an optimum policy to convergence? (3) I have seen entropy being implemented as entropy = -tf.reduce_sum(policy * log_policy, 1, name="entropy") However the policy is the output of the softmax and not the actual label as is usually the case for cross entropy . Is there a reason why the label (0 for move left, or 1 for move right) was not used.
