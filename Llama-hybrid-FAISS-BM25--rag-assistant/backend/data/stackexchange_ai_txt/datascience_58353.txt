[site]: datascience
[post_id]: 58353
[parent_id]: 
[tags]: 
How Linear SVM Regression and Multiple Linear Regression different in terms of the regression result?

They starts from the same equation as below. y = w*x + b But they solve it differently. MLR specified the w and b by minimizing the square error whereas SVM specified w and b by minimizing the loss function defined by C and epsilon. I am wondering if the result of regression is significantly different. I guess that if the given data set is clean and well-explained by input features, the resultant w and b between SVM and MLR will be close. Putting my original question differently, I don't find any reasons to use linear SVM regression over multiple linear regression.
