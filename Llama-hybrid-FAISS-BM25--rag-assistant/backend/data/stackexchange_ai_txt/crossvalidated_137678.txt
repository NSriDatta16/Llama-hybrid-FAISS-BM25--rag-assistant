[site]: crossvalidated
[post_id]: 137678
[parent_id]: 72446
[tags]: 
When you say "better results" and provide the different errors you got, is that evaluated in-sample or out-of-sample? SVM tuning will attempt to give you the best tuning parameters for out-of-sample prediction. But for in-sample "performance," higher gamma and higher cost will always do "better." I put 'performance' and 'better' in quotes here, b/c higher values of gamma and cost will not actually give you a better estimate of the underlying mapping between independent and outcome variables, but will "overfit" the training data. Keep in mind, SVM is capable of arbitrary complexity, so if you let it, it will perfectly fit your data. (That's assuming there are no instances of identical X's producing different Y's, but that almost surely won't happen with continuous data.) When you fit so tightly, if actually harms predictive ability, b/c there is a lot of spurious complexity in the prediction function, so my guess is that gamma=0.02 will outperform out-of-sample, while gamma=0.042 will dominate in-sample. If you're interested in prediction, go with 0.02. There aren't many reasons to go with in-sample performance, but there are instances when you want to be a little liberal with the cost and gamma parameters. (For example, if you're using SVM-regression to produce a residual which has purged variation related to all of the explanatory variables, a little over-fitting can be beneficial.) But in most cases, go with the out-of-sample prediction accuracy. However, if you evaluated this out-of-sample and found that the higher gamma did better, then I must say that I'm surprised. It's theoretically possible for the performance manifold (the 3-d surface of out-of-sample MSE, cost and gamma) to be very spike-y, which can lead to poor tuning outcomes, but looking at the plot above, it looks pretty well-behaved. Hope that helps!
