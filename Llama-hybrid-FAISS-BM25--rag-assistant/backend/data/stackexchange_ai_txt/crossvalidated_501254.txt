[site]: crossvalidated
[post_id]: 501254
[parent_id]: 280248
[tags]: 
Maybe you can use Support Vector machines for this kind of classifications. You can implement a neural network to extract relevant information from the input, convert to a lower-dimensional vector, and then pass it to an SVM. This might work because for an SVM to predict a class, the penultimate layer input just has to be over a particular threshold. So, if two of such nodes are over their threshold values as calculated during training, they both will be labelled as ones, whereas the rest would be zeros. import torch import torch.nn as nn class SVM(nn.Module): def __init__(self, input_nodes, output_nodes): super().__init__() self.fully_connected = nn.Linear(input_nodes, output_nodes) def forward(self, x): fwd = self.fully_connected(x) # Forward pass return fwd This is a starter code for implementing SVMs in PyTorch, which you train like any other network in PyTorch in a one v/s all manner. The loss function to be used here is hinge loss . This is an implementation of a linear kernel . You may experiment with different types of kernels available to optimize the performance of your model. And as far as calculating ROC scores, you can also calculate it in a one v/s all way
