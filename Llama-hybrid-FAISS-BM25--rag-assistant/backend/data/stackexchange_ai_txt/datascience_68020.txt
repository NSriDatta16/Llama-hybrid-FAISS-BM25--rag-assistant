[site]: datascience
[post_id]: 68020
[parent_id]: 
[tags]: 
What is the feedforward network in a transformer trained on?

After reading the 'Attention is all you need' article, I understand the general architecture of a transformer. However, it is unclear to me how the feed forward neural network learns. What I learned about neural nets is that they learn based on a target variable, through back propagation according to a particular loss function. Looking at the architecture of a Transformer, it is unclear to me what the target variables are in these feed forward nets. Can someone explain this to me?
