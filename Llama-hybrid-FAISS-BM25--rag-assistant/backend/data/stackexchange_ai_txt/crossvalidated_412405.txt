[site]: crossvalidated
[post_id]: 412405
[parent_id]: 412402
[tags]: 
Mathematics is about expressing ideas even if they cannot be solved. Expressing an idea as a function (in this case a policy) allows us to write it down and move it around in a quantitative context. This (often) ends up allowing us to make some quantitative use of it. It turns out that in this particular example a policy over a discrete action space can expressed as the probability of an action, giving us the ability to take derivatives. This (and the existence of natively continuous action spaces) is the basis of a sub-field in Reinforcement Learning in which policies are approximated by a function (recently, a neural network) directly.
