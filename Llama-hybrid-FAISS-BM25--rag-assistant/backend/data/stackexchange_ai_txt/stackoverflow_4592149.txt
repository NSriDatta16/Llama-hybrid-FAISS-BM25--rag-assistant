[site]: stackoverflow
[post_id]: 4592149
[parent_id]: 
[tags]: 
Calculating a "based" data checksum. (SHA1/2, etc)

I'm not sure exactly how to ask this, but here's what I'm hoping for, given a structure that could contain 5+n keys (thus, there are 5 keys mandatory to my system, additional keys are optional) - I would like a hashing mechanism that is able to determine that a 6 key hash, with 5 identical keys, is a superset of the 5 key struct, and offers additional information. Specifically a hashing mechanism, as there are constraints which preclude sending the complete struct over the wire on every request. For clarification, here's some information (sample requires 2+n keys): --- name: codebeaker occupation: developer Hashed with SHA-512 , and -256 this comes out to look like: SHA-512 04fe500f2b3e779aba9ecb171224a04d35cc8453eb1521c7e31fd48b56b1cce9 b1e8af775e177e110982bfb16a6ca8652d7d9812ab8a8c316015dc9d6b3b54f7 SHA-256 4833be7086726e7ffd82db206f94f0a4f9fdf7fba00692f626157afed4587c74 When adding an additional key, (example below) I would like to be able to deduce that the extended dataset is a superset of the first. --- name: codebeaker occupation: developer telephone: 49 (0) 123 45 67 However, unsurprisingly, in MD5 , SHA-n and any other hashing function I have looked into, there's no way to do this, example: SHA-512 2fe2c1f01e39506010ea104581b737f95db6b6f71b1497788afc80a4abe26ab0 fc4913054278af69a89c152406579b7b00c3d4eb881982393a1ace83aeb7b6a2 SHA-256 77c2942e9095e55e13c548e5ef1f874396bfb64f7653e4794d6d91d0d3a168e2 (Obviously) there are no similarities... Our use case, this data, formatted as a struct is fed into our system by a 3rd party. Processing the data is hugely expensive, 2-3 seconds per operation, we can get about 50% of that time back, if we know we have a result from a previous run, however - Bayesian, and Levenstein text-difference algorithms aren't suitable here, as we often see key/value pairs that are acronyms, and other text which can appear similar, when being completely unrelated. What we need is a way to checksum data (I might be biasing my response here) - so that we can determine that B is a superset of A if it contains all the same keys, with the same data. However, often there is so much data in the key/value entries in our struc that sending it over the wire every time, only to determine that we already saw a more complete copy, would be expensive and wasteful.
