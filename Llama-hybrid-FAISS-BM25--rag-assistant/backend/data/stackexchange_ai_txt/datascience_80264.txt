[site]: datascience
[post_id]: 80264
[parent_id]: 80184
[tags]: 
So, the main question is about how to represent the Chinese characters in your Chinese word segmentation task. Since effectively these characters are non-ordinal categorical variables, we would represent these as one hot encodings ( https://medium.com/@michaeldelsole/what-is-one-hot-encoding-and-how-to-do-it-f0ae272f1179 ) of dimensionality n = number of unique Chinese characters in your dataset. Sometimes n can be very large. So in this instance, we typically have an Embedding layer, which can reduce data sparsity and collapse the number of dimensions. ( https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding#:~:text=Arguments%20%20%20%20input_dim%20%20%20,the%20embed%20...%20%202%20more%20rows%20 )
