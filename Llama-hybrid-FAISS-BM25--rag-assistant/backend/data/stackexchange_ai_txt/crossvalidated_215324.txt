[site]: crossvalidated
[post_id]: 215324
[parent_id]: 215308
[tags]: 
You can run stochastic gradient descent / batch gradient descent to solve the regression objective. Since your feature matrix is sparse, this should run pretty fast. If the regression equation is $y=Ax$ each SGD step is of the form $$ x_{t+1} = x_t + \eta (y_t - a_t^T x_t) a_t $$ Now if each row $a_t^T$ has just $z$ entries on average, each update step will take approx $2z$ multiplication and $z$ additions.
