[site]: crossvalidated
[post_id]: 507160
[parent_id]: 507129
[tags]: 
If you want to know the OOB prediction, it is stored under the attributes oob_decision_function_ . This is a probability obtained by averaging predictions across all your trees where the row or observation is OOB. First use an example dataset: import numpy as np from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import make_classification from sklearn.metrics import accuracy_score X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0,random_state=123, shuffle=False) clf = RandomForestClassifier(max_depth=2, random_state=123,oob_score=True) clf.fit(X,y) clf.oob_score_ 0.95 Then we can check the OOB predictions: clf.oob_decision_function_ Out[115]: array([[0.76976691, 0.23023309], [0.78910912, 0.21089088], [0.398826 , 0.601174 ], ..., [0.1952597 , 0.8047403 ], [0.12296672, 0.87703328], [0.13481899, 0.86518101]]) You can get the predicted labels: pred = np.argmax(clf.oob_decision_function_,axis=1) Check against the accuracy: accuracy_score(pred,y) 0.95
