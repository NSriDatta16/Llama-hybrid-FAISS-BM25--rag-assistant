[site]: crossvalidated
[post_id]: 383788
[parent_id]: 
[tags]: 
Training a SOM in batch mode

I was reading the Somoclu parallel implementation of Self-Organizing Maps (SOMs) and they say that in order to make the algorithm parallelizable, a batch training mode has to be followed. The equation to update the weights is given in the 4th page of the document I linked above: $$\mathbf{w}_k(t_f)= \frac{\sum_{t=t_i}^{t_f} h_{bk}(t) \mathbf{x}(t)} {\sum_{t=t_i}^{t_f} h_{bk}(t)}$$ Where $h_{bk}$ is the vecinity function. I don't understand why that formulation works. Shouldn't the factor $(\mathbf{x} - \mathbf{w})$ be used at some point to achieve convergence? What troubles me is that past values of the weights are not used in the update rule. Does that equation make sense? If so, why?
