[site]: crossvalidated
[post_id]: 446084
[parent_id]: 
[tags]: 
Basic misunderstanding about calculating correlation coefficient

I'm trying to build intuition and understand how the calculation of correlation coefficient ( r ) works. I'm reading the book "Statistics" by David Freedman et al, where they provide, in chapter 8, a series of steps to calculate r . Essentially, the method provided in the book is: transform each variable (i.e., for both x and y ) data points from raw to standard units multiply each data point's Zx by its Zy. average the products. Voil√†. The average of products is the correlation coefficient r . But something doesn't make sense to me. Let's say that hypothetically I have data that, after transformation to standard units, turns out to be: This means that the two variables x and y should have correlation of 1, because they perfectly match in their respective deviation from each variable's mean. But when apply the calculation method provided above, I get this bizarre result: Average of Products $= \frac{9+4+1+0+9+4+1}{7} = 4$ Well, that's clearly wrong. We know that r ranges from -1 to 1, so what's wrong in my understanding?
