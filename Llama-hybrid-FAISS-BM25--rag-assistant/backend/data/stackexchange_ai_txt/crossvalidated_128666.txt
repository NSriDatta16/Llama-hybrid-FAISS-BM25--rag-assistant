[site]: crossvalidated
[post_id]: 128666
[parent_id]: 
[tags]: 
computing the posterior of two Gaussian probability distributions

I am a bit confused how to solve a Bayesian statistics problem. I have a parameter $\epsilon^s$ which is defined as following: $$\epsilon^s=\frac{\epsilon-g(\pi,z)}{1-g^*(\pi,z)\epsilon}$$ where $g(\pi,z)$ has an analytical description (model) and it is a function of $z$ and $\pi$, but the empirical discrete probability of $z$ can be estimated, $p(z)$. The probability of $\epsilon^s$ is given by $$p_{\epsilon^s}(\epsilon^s)=\frac{1}{2\pi\sigma^2[1-\exp(-\frac{1}{2\sigma^2})]}\exp\left(-\frac{|\epsilon^s|^2}{2\sigma^2}\right)$$ and I assume $p_{\epsilon}(\epsilon|g)\equiv p_{\epsilon^s}(\epsilon^s|g)$. Now I would like to compute the likelihood of probability of measured $\epsilon$, i.e. $\epsilon^{m}=\epsilon+\epsilon^{err}$, for the given $g$ $$p_{\epsilon^m}(\epsilon^m|g)=\int p_{\epsilon}(\epsilon|g)p_{\epsilon^{err}}(\epsilon-\epsilon^m)d\epsilon$$ assuming a Gaussian probability distribution for the measurement error of $\epsilon$ ($\epsilon^{err}$). The likelihood for a set of $n$ measured $\epsilon$ and for a $g$ quantity with $\pi$ free parameters of the model is given by $$L(\pi)=\prod_{i=1}^np_{\epsilon^m}(\epsilon^m_i|g_i)$$ My questions: What is the best way to compute $p_{\epsilon^m}(\epsilon^m_i|g_i)$ assuming both probabilities are Gaussian? how could I include the probability of $p(z)$ in the calculations and marginalize over? Can MCMC be a good method to solve this problem? I will appreciate for any help!
