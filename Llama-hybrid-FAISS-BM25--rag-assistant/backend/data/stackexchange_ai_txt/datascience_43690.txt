[site]: datascience
[post_id]: 43690
[parent_id]: 
[tags]: 
Strangeness in validation loss between CPU vs GPU when training CNN

I've been training an implementation of Mask R-CNN and it was training very successfully on my CPU but I've just set up my GPU and it is giving some strange results when looking at my validation loss. It is as if the learning rate got turned up when I moved to using my GPU. Has anyone ever experienced this or know what could cause this difference? I didn't think there was any difference in the actual computation on CPU vs GPU, is there? Training on CPU: Training on GPU:
