[site]: datascience
[post_id]: 32572
[parent_id]: 
[tags]: 
ML model to transform words

I build model that on input have correct word. On output there is possible word written by human (it contain some errors). My training dataset looks that: input - output hello - helo hello - heelo hello - hellou between - betwen between - beetween between - beetwen between - bettwen between - bitween etc. During preprocessing I add a measure of the distortion of a word. Then I hardcoding letters for numbers. My current model's using CNN. The number of neurons of input is the same as the longest word in training dataset and the number of neurons of output is the same as the longest word in traning dataset. This model doesn't work as I excepted. Word on the output is not look as I except. eg. input - output house - gjrtdd Question: How can I build/improve model for this task? Is CNN a good idea? What other methods can I use for this task?
