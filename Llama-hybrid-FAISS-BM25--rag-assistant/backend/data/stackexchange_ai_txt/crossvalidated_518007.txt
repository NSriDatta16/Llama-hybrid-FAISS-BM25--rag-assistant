[site]: crossvalidated
[post_id]: 518007
[parent_id]: 517967
[tags]: 
Turning my comments into an answer: there isn’t cross-validation in this strategy, and it’s not more informative about model performance than measuring accuracy after gluing the nine test sets together. Well, say I have two models. If I test on all 9 chunks glued together at once, then model B might lose to model A if it performs poorly on one particular part of that total chunk. But if I split it up into 9 chunks, then I might see that model B "wins" 8 times out of 9, but just happens to do particularly badly at the 9th set. This is a more informative validation test than just testing it on the glued together chunks. Consider that what you’re doing, in the limit, would be to take every sample in the combined test set, check whether A or B performed better, and aggregate that. That’s what accuracy already does, though. If your test set is fragmented into 9 parts, this tells you more about the specifics of those samples than about A and B.
