[site]: datascience
[post_id]: 37539
[parent_id]: 37534
[tags]: 
You don't need to assign an RNN cell to each entry in a sequence, you just need one. A single cell can process sequences because of its recursive nature(its output feeds back into itself): $$ h_t = f(h_{t-1}, W, x_t) $$ where $h_t$ is the hidden state at step $t$, $W$ is the weight used for the cell, and $x_t$ is the current input at step $t$ . Hopefully, you can see how it is only necessary for us one weight matrix, $W$, instead of multiple as your understanding would imply. Where you got the notion of multiple RNN cells is probably when we feed the hidden state as the input, $x$, into another RNN cell. More layers of RNN cells, mean you can learn a more complex sequence. Conclusively, your RNN cell cell can't work without new inputs, therefore it end when your sequence ends. Also, it is recommended to use LSTM or GRU over vanilla RNN units.
