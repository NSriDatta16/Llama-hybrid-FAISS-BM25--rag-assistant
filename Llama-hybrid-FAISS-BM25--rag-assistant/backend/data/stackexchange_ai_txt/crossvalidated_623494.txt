[site]: crossvalidated
[post_id]: 623494
[parent_id]: 
[tags]: 
Least square control function for estimate of the variance

In the book "An Introduction of the Bootstrap" of Bradley Efron and Robert Tibshirani chapter 23, a least square method combined with bootstrap is presented for the estimation of the variance. The method works with the resampling vector. Suppose that you have a dataset of size $n$ $\mathbf{X} = (X_1,\ldots,X_n)$ . We will note a sample from the $b$ -th bootstrap of $\mathbf{X}$ as $X^*_b = (X_{1,b}^*,...,X_{n,b}^*)$ . The resampling vector of the $b$ bootstrap is defined as follows: $$ \mathbf{P}^*_b = (P^*_{1,b},\ldots,P^*_{n,b}), $$ with $P_j = \#(x_{i,b}^* = x_j)/n.$ The problem Let us note $T()$ the statistics we are interested in. At each step, it is demanded to link $T()$ and $\mathbf{P}^*_b$ by a linear model: $$ T(\mathbf{P}^*_b) = a_0 + \mathbf{a}^T\mathbf{P}^*_b \tag 1, $$ where $a_0$ and $\mathbf{a}$ are the least square estimators. When I do the computation for the least square in R, one component of the parameters is equal to NA. To be more precise the $n$ -th component of $\mathbf{a}$ is NA. I think I have found why, it is because there is a constraint on the vector $\mathbf{P}^*_b$ that is $\sum_{i=1}^n P^*_{i,b} = 1$ implying that at least one component is dependent on the others. So how can I obtain the least square estimators of equation $(1)$ given this dependency? Did I miss something? The procedure is described in pages 346-347 of the book.
