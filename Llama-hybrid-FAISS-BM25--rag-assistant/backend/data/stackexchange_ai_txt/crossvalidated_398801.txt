[site]: crossvalidated
[post_id]: 398801
[parent_id]: 398774
[tags]: 
"Too good to be true" is not the definition of overfitting. I am not saying you are not overfitting, but that you do not have to. For example, if you trained a classifier to detect if written text is in English or Chinese, you would very fast get >99% accuracy because this would be a very simple problem. On another hand, there are problems where you would never reach 70%. As about your problem, you said that you have time series data and you are using $k$ -fold cross validation. This means that likely you may be overfitting because using such way of validating the results, you potentially leaking information from the future into your training set. This is not how you validate time-series. Instead you should split your data in such way that you train on the past and test on the future data .
