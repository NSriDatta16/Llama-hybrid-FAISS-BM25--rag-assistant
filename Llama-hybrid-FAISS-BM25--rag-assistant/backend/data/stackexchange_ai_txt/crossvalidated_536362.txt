[site]: crossvalidated
[post_id]: 536362
[parent_id]: 
[tags]: 
Confidence Interval for Random Set Coverage

Question: If I pick n random integers from the range [0:m-1], what is x such that I have a 95% chance of picking x or more unique values? How do I generalize this to create a 99% one sided confidence interval? (Each pick has a uniform 1/m chance of picking each integer in the range) My Attempt (WRONG): Odds of picking value i on one read: 1/m Odds of not picking value i on one read: (m-1)/m Odds of not picking value i on n reads: ((m-1)/m)^n Expected number of unique values: coverage = m * (1 - ((m-1)/m)^n) Up to this point seems to be right based on empirical tests. To build the confidence interval, I assume all m values in the range have the same independent chance of being chosen on each read (WRONG), and use the binomial distribution. from scipy.stats import binom n,p = m, coverage mean, var, skew, kurt = binom.stats(n,p, moments='mvsk') min_bound, max_bound = binom.interval(0.95,n,p) This ever so slightly inflates the 95% confidence interval, such that nearly all of my empirical tests end up inside the interval. What distribution am I supposed to be using here instead? How can I calculate a one sided interval for this distribution (since python can only do a 2 sided one) Why?: I'm building a model for genome read coverage and I need to create a lower bound for percentage of genome (of length g) covered given n reads of length k. Rather than trying to compute it directly, I'm using this simplification: Divide the genome into m=g/k buckets, each of length ~k. Assume each read covers exactly 1 bucket.
