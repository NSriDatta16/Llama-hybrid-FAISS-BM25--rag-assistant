[site]: crossvalidated
[post_id]: 269012
[parent_id]: 
[tags]: 
Can I use oversampling with leave one out cross validation?

I have a dataset with a categorical outcome no/yes, 8 predictors, in 31 examples, and I'm trying to classify the examples using different algorithms in the caret package. There are 9 "no" and 22 "yes". The code I'm using is as follows: ## SVM set.seed(101) ctrl= trainControl(method= "LOOCV",sampling="up", classProbs = TRUE,savePredictions = TRUE, summaryFunction = twoClassSummary) svm = train(remission ~ ., data = num.m, method = "svmLinear", trControl=ctrl, metric="ROC") svm print(svm) predictors(svm) I've read that oversampling should only be applied after cross-validating when using loocv, but I'm not sure how to do this. How would be the proper way to solve this problem?
