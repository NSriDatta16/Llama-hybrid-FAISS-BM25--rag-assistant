[site]: datascience
[post_id]: 121611
[parent_id]: 121599
[tags]: 
ctree or a conditional tree is a non-parametric decision tree. TreeDecisionClassifier in Python is the closest, but there isn't a direct equivalent of a conditional tree in Python's sci-kit learn, which appears the context of the question. It may be possible to modify the scikit learn's decision tree to be a conditional tree - in theory a conditional tree is a subset of a decision tree - but I don't know whether this has been achieved. Purely personally I wouldn't use sci-kit learn's decision tree because it is prone to overtraining. If I received a manuscript singly using a decision tree, I would return it requesting alternative models to at least supplement the decision tree analysis and request checks for overtraining. Thus in this regard it doesn't have a good reputation. A random forest model would be used instead. ctree is cool. So to answer your question directly I would not replace a conditional tree with scikit learn's decision tree. If you do then you need to check for overfitting (IMO). However, there was talk of implementing a conditional tree in sci-kit learn. A random forest is an averaged conditional tree, thus I personally would see it as the preferred Python model for replacing a ctree , but its not the same thing. What would I do? Well if you are happy with ctree and cforest then I would use sci-kit learn's random forest. Beyond that I don't know enough about your data to make a call (I do evolution). Random forests and conditional trees are good with sparse data, so possibly if there are lots of questions that have been skipped (that might be relevant). Random forests don't deal with imbalance very well . I don't know your targets, but I could imagine the outcomes could be imbalanced because at a wild guess there are more neutrals then any other category. xgboost, or extreme gradient boosting, is trendy. It will replace random forests (IMO), especially to overcome imbalance and copes with high variance. On the surface its just as easy to use. The parameterisation can be computationally demanding, but there's short-cuts and there's an interaction analysis for examining the features of the survey. This would be particularly true if you want to improve your survey. However its more complex to grasp all the caveats. I know about surveys in clinical data and getting a good survey is not trivial. The survey and even the investigator can generate bias, but I suspect it will also depend on the morbidities of the patients. In new clinical surveys a model survey is used that is known to be robust. Its definitely not an easy area of investigation.
