[site]: crossvalidated
[post_id]: 341630
[parent_id]: 341622
[tags]: 
Hierarchical clustering is a nice tool to identify homogeneous subsets of responses (rows) with respect to the measured variables (your columns). If that is really what you're after, then following your clustering you will want to get a sense of the characteristics of each cluster. For variables that are categorical, you could calculate, for each cluster, the proportion of responses for each level of your categorical variables. For quantitative variables, the mean or median response for each variable in each cluster is usually useful. Parallel coordinate plots are also quite useful, especially when you have a large set of quantitative variables from which you derived your clusters. For example, here's a parallel coordinate plot showing attributes of the states, separated into four clusters. You can see that within each cluster states share a common pattern of responses across the variables. This is both a nice way to see what makes each cluster unique, and what makes clusters different. If your main interest is not in finding (and characterizing) homogeneous subsets (of rows) in your data, then you'll want to explore some different analyses. For instance, if you're interested in how your variables relate to each other, you might considering Multiple Correspondence Analysis (MCA), which, like its quantitative cousin Principle Components Analysis (PCA) will allow you to explore how your response variables relate to each other.
