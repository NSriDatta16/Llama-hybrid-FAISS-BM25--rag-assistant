[site]: datascience
[post_id]: 9032
[parent_id]: 9027
[tags]: 
In a neural network model, you can use autoencoders . The basic idea of an autoencoder is to learn a hidden layer of features by creating a network that simply copies the input vector at the output. So the training features and training "labels" are initially identical, no supervised labels are required. This can work using a classic triangular network architecture with progressively smaller layers that capture a compressed and hopefully useful set of derived features. The network's hidden layers learn representations based on the larger unsupervised data set. These layers can then be used to initialise a regular supervised learning network to be trained using the actual labels. A similar idea is pre-training layers using a Restricted Boltzmann Machine , which can be used in a very similar way, although based on different principles.
