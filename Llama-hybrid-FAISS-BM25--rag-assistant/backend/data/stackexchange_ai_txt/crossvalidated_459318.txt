[site]: crossvalidated
[post_id]: 459318
[parent_id]: 459296
[tags]: 
In short: The example is correct but not easy to follow. You understand things correctly around nested CV but you probably did not follow the example. I do not blame you; it took me a slow read to see it is right. The example defines two K-Folds cross-validators. One called inner_cv and one called outer_cv . Notice that while both are simple 4-fold CV procedures they do not refer to the same data. OK, let's go line by line now: clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv) says: Fit the estimator svm via a parameter search using p_grid using the cross_validation procedure is based on the inner_cv cross-validator. Inner CV object is then used explicitly through the line clf.fit(X_iris, y_iris) ; we take the X_iris dataset, all 150 instances of it , break it into 4 pieces as dictated by inner_cv in clf , do CV using those 4 pieces (folds) and fit our object. clf.best_score_ then gives us the mean cross-validated score of the best estimator among the ones defined by hyperparameters p_grid . cross_val_score(clf, X=X_iris, y=y_iris, cv=outer_cv) says: Give us the scores of the estimator clf for each run of the cross validation defined by outer_cv . To do that, cross_val_score will go ahead and do the following: Take the X_iris dataset, all 150 instances of it , break it into 4 pieces (this is our outer CV). In the three pieces that are defined by the the outer_CV (~113 instances) as our training and validation set, train the clf estimator (the svm ) by taking a piece of ~85 instances and validating the performance of that estimator using a piece of ~28 instances. After doing K (inner) repeats, return the best estimator among the ones defined by hyperparameters p_grid . (that is our inner CV) In the remaining one piece (~37 instances) that is our unseen test fold, it will go ahead and estimate the associated cost. To do that, it will take the best estimator as provided by the inner loop, use it to predict on the value on the test fold, compare their goodness of fit and finish up. This is repeated K (outer) times. As you see the command cross_val_score(clf, X=X_iris, y=y_iris, cv=outer_cv) does exactly what you described in your code implementing nested CV. Just that function hides all the details; the primary detail being that clf is not really an previously optimised classifier object but rather a procedure where an inner procedure does a CV. To that extent, if cross_val_score was presented with an object that had the best parameters from GridSearchCV but did not do any internal CV itself, cross_val_score would effectively give us the same results as GridSearchCV .
