[site]: crossvalidated
[post_id]: 614840
[parent_id]: 614723
[tags]: 
You can look at the a priori inferential properties of estimators (which treats both the data and parameters as random), but this is weaker than standard analysis If you look at a statistical problem from a perspective where both the data and the model parameters are treated as random, you are essentially looking at the a priori properties of estimators. This is an exercise that can be done fruitfully, and it falls within the general class of analysis of the Bayesian properties of estimators. However, performing analysis of this kind is typically weaker than looking at the classical properties of estimators. To see what this type of analysis looks like, suppose we consider some estimation/inferential method, which as you point out, is built on the basis of its properties conditional on the model parameters but unconditional on the data. For example, an exact confidence interval for a model parameter $\theta \in \Theta$ (based on a data vector $\mathbf{x}$ ) would have the following property (which is essentially the defining property of an exact confidence interval): $$\mathbb{P}(\theta \in \text{CI}( \mathbf{X}, \alpha) | \theta ) = 1-\alpha \quad \quad \quad \text{for all } \theta \in \Theta.$$ Now, if we take any prior distribution $\pi$ for the model parameter then the above property implies the weaker property: $$\mathbb{P}(\theta \in \text{CI}( \mathbf{X}, \alpha)) = \int \limits_\Theta \mathbb{P}(\theta \in \text{CI}( \mathbf{X}, \alpha) | \theta ) \cdot \pi(\theta) \ d\theta = 1-\alpha.$$ As you can see, because the coverage property for a CI holds under all specific parameter values $\theta$ (which is how we analyse estimators/inference methods in classical analysis), this implies that it must also hold (marginally) for any prior distribution over the possible values of $\theta$ . Note that the latter is a weaker property than the underlying property defining the exact confidence interval, but it is interesting to note. This tells us that an exact confidence interval formed by classical methods is such that a priori we expect it to have the correct coverage. This is what it looks like to analyse the properties of a statistical estimator treating both the data and the parameter as random. I note your overarching question about whether it would be possible to form a new hybrid approach to estimation/inference by combining classical methods and Bayesian methods. That might be possible in principle, but because the above a priori analysis is weaker than the standard classical approach to looking at estimation, it is unlikely that this would assist you to formulate a better method than existing approaches.
