[site]: crossvalidated
[post_id]: 348503
[parent_id]: 348330
[tags]: 
The test data shows you how well your model has generalized. When you run the test data through your model, it is the moment you've been waiting for: is it good enough? In the machine learning world, it is very common to present all of the train, validation and the test metrics, but it is the test accuracy that is the most important. However, if you get a low $R^2$ score on one, and not the other, then something is off! E.g. If the $R^2_{\text{test}}\ll R^2_{\text{training}}$ , then it indicates that your model does not generalize well. That is, if e.g. your test set only contains "unseen" data points, then your model would not appear to extrapolate well (aka a form of covariate shift). In conclusion: you should compare them! However, in many cases, it's the test-set results you're most interested in.
