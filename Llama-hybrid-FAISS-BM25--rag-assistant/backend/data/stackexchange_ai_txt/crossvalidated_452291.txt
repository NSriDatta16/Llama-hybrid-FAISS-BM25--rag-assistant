[site]: crossvalidated
[post_id]: 452291
[parent_id]: 451813
[tags]: 
Yes, I would not trust the inferences (unless the higher R-hat were for the log-kernel, lp__ , or perhaps for a generated quantity that does not go into the log-kernel). This question was considered in a paper by Jeff Gill whose abstract is Increasingly, political science researchers are turning to Markov chain Monte Carlo methods to solve inferential problems with complex models and problematic data. This is an enormously powerful set of tools based on replacing difficult or impossible analytical work with simulated empirical draws from the distributions of interest. Although practitioners are generally aware of the importance of convergence of the Markov chain, many are not fully aware of the difficulties in fully assessing convergence across multiple dimensions. In most applied circumstances, every parameter dimension must be converged for the others to converge. The usual culprit is slow mixing of the Markov chain and therefore slow convergence towards the target distribution. This work demonstrates the partial convergence problem for the two dominant algorithms and illustrates these issues with empirical examples. In the case of the dynamic Hamiltonian MCMC algorithm used by Stan --- which makes joint proposals for the next iteration of the parameters --- I do not generally see how the Markov Chain could be performing well if it is misbehaving on any margin. Moreover, a R-hat of 1.1 is extremely large in the Stan era, and we should be worried if any R-hat were greater than 1.01.
