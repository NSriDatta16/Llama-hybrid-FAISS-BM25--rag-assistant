[site]: datascience
[post_id]: 109340
[parent_id]: 109302
[tags]: 
Have you considered an SVD -based method? SVD is often associated with dimensionality reduction, which you are trying to avoid, but can also be used as the base of clustering algorithms. SVD is nice in your case because calculating the SVD of a sparse matrix is a well studied problem and there should be some fairly mature and efficient code in some standard library to help you. You say "I know the cardinality and sparsity is a pain" but I would suggest that cardinality is the pain and sparsity is a partial salve. There is a nice paper that looks at relaxing the K-mean clustering problem into something that admits a polynomial-time algorithm (and a good linear approximation algorithm). From the introduction: There are many notions of similarity and many notions of what a “good” clustering is in the literature. In general, clustering problems turn out to be NP-hard; in some cases, there are polynomial-time approximation algorithms. Our aim here is to deal with very large matrices (with more than 10^5 rows and columns and more than 10^6 non-zero entries), where a polynomial time bound on the algorithm is not useful in practice. Formally, we deal with the case where m and n vary and k (the number of clusters) is fixed; we seek linear time algorithms (with small constants) to cluster such data sets. We will argue that the basic Singular Value Decomposition (SVD) of matrices provides us with an excellent tool. As with most clustering problems, this assumes that the number of clusters, k, is fixed. Your question mentions "unknown number of groups". You will probably have to fit a model for each value of k and have some way to picking the right number of clusters. Again, SVD might be helpful here because the clusters will be related to the singular values and you might be able to figure something out from the spectrum (list of singular values) of the matrix.
