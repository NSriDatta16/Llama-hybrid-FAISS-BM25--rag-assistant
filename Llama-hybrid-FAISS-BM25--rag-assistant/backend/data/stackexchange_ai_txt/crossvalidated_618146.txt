[site]: crossvalidated
[post_id]: 618146
[parent_id]: 618121
[tags]: 
I don't believe it's the case that $\frac{s}{\sqrt{n}}$ is an unbiased estimator for $\sigma_{g}$ . The reason for this is that $s$ is not an unbiased estimator for $\sigma$ . One thing I'm not understanding from what you've said, is the difference between S and s. You say that S is the unbiased sample standard deviation and s is its estimate, but how are these different things? I would have though that $$s= \sqrt{\frac{\sum_{i=1}^{N}(x_{i}-\bar{x})^{2}}{N-1}}$$ and this is an estimator, defined wrt your sample. There is no S, some true value/latent parameter you're trying to estimate. That aside though, the above s is not an unbiased estimator for $\sigma$ . If you didn't take the square root, then you have an unbiased estimator for $\sigma ^{2}$ , but that does not mean its square root is an unbiased estimator for $\sigma$ . In fact, to quote wikipedia directly, It is not possible to find an estimate of the standard deviation which is unbiased for all population distributions, as the bias depends on the particular distribution. Much of the following relates to estimation assuming a normal distribution. That aside though, I feel your question was getting at something else, but I'm not quite getting it (perhaps related to the S vs s confusion?). If we ignored this issue that the square root of the unbiased estimator of the variance is not an unbiased estimator of the standard deviation, is this not all pretty straightforward? You want an unbiased estimator for $\sigma_{g}$ . In words, if you take a sample of size n, that sample will have a standard deviation. You could take infinite such samples, each would have a variance, and then you could take the average of those variances, you want to estimate what that value would be, from a single sample of size n. You also know from basic probability that if you knew $\sigma$ , then it's easy, $\sigma_{g}=\frac{\sigma}{\sqrt{n}}$ . So isn't it fairly straightforward to say that if you have an unbiased estimator $\hat{\sigma}$ for $\sigma$ , then $\frac{\hat{\sigma}}{\sqrt{n}}$ will be an unbiased estimator for $\sigma_{g}?$ From there, we're back at the point that technically, the estimator s above is not an unbiased estimator for $\sigma$ , but it's pretty close , and thus dividing s by $\sqrt{n}$ is going to be a pretty good estimator for $\sigma_{g}.$ Appreciate this isn't a proof, more of a going through the logical steps one by one. Does this make sense or is there a particular step here you disagree with ?
