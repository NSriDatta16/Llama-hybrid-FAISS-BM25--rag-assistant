[site]: crossvalidated
[post_id]: 570331
[parent_id]: 570123
[tags]: 
There are a lot of ways to perform parameter estimation. This wikipedia page mentions a dozen of different types or related concepts: Commonly used estimators (estimation methods) and topics related to them include: Maximum likelihood estimators Bayes estimators Method of moments estimators Cramér–Rao bound Least squares Minimum mean squared error (MMSE), also known as Bayes least squared error (BLSE) Maximum a posteriori (MAP) Minimum variance unbiased estimator (MVUE) Nonlinear system identification Best linear unbiased estimator (BLUE) Unbiased estimators — see estimator bias. Particle filter Markov chain Monte Carlo (MCMC) Kalman filter, and its various derivatives Wiener filter As Christian Henning mentioned in the comments the beta distribution has some simple solutions for a few of those methods. This shows that there are a lot of various ways to estimate the parameters. These have all different advantages and disadvantages. Whichever is the 'most optimal way' will depend on the context. This is not a standard straightforward filling in a function in R-code as if it is some oracle that gives you an answer to any dataset. You have to think yourselves as well about what you want the function/algorithm (the "oracle") to do for you.
