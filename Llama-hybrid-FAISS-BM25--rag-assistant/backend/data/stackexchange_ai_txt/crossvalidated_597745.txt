[site]: crossvalidated
[post_id]: 597745
[parent_id]: 26568
[tags]: 
I agree with @Greg Snow that there should not be a distinction between prediction interval and confidence interval for binary outcome models as in linear models. He noted the difference between a binomial outcome (y successes out of j trials among n groups) and a binary outcome (success or failure of one subject among n subjects). The former may have both a prediction interval for an individual proportion and a confidence interval for the population mean of proportions, while the latter has a confidence interval for the population probability. Additionally, I discovered that @carbocation incorrectly implemented Collett's equation for calculating the variance and standard error of a predicted logit. A correct implementation should lead to identical results to glm() predictions. The equation (3.11) by Collett (2002, p. 98) is given in scalar, which might the reason to cause a confusion and result in the error. Collett, D. (2002). Modelling binary data (2nd ed.). Chapman and Hall/CRC. In the context of @carbocation R scripts, the correct codes to generate the standard error of a predicted logit are # Prediction: this.student.prediction This procedure of matrix multiplication to generate standard error of a predicted value applies to many other types of models. To address the question in the comment by @Rafael, a standard error is simply the standard deviation of an estimate for a population parameter. When using individual scores to estimate a population mean, the standard error of a population mean estimate is created by dividing the standard deviation of individual scores by sqrt(n) where n is the sample size of individual scores. For an estimated model, however, model estimates, such as coefficients and predicted logits of probabilities according to a logistic regression, are already of the population parameters and are not a sample of individual scores. Thus, the standard deviation of model estimates, such as coefficients and predicted outcomes, are their standard error. Such uncertainty is from sampling errors of population parameters instead of from variability among individual subjects. This is also why a bootstrapped estimate of the standard error of a statistic with an unknown distribution uses the standard deviation of the observed statistics among bootstrapped samples, which does not shrink when taking more bootstrapped samples.
