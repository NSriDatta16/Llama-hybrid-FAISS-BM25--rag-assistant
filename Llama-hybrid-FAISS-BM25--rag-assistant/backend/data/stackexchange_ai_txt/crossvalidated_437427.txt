[site]: crossvalidated
[post_id]: 437427
[parent_id]: 437422
[tags]: 
No, it’s not. It’s a special case of stacking in general and used widely in practice, Especially with different methods one after another. In typical stacking you use several models and a second level on top of these as a meta model. The meta model uses predictions from 1st level models and learns on top of them. You've just one model in your first level and a combiner in the second level with additional features (i.e. base features again). This is similar (not the same) to adding layers to neural networks. I didn't encounter your specific case (i.e. RF after RF), but I recall several other problems first using a typical baseline method and then fit another model on predictions/residuals using extra features to boost it. TL;DR This is not data leakage.
