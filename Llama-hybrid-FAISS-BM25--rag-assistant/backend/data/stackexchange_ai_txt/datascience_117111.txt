[site]: datascience
[post_id]: 117111
[parent_id]: 
[tags]: 
In a convolutional layer, is it standard practice to modify stride and padding to get a desired output?

I'm trying to implement the CNN described in A Framework of Hierarchical Deep Q-Network for Portfolio Management (see screenshot). In the paper, the author describes the first CNN layer as having a kernel of 1x3, taking in a price tensor with shape (2,10,4) and outputting 32 feature maps of size 2x5. The actual quote is: 1st and 2nd CNN Layers: As shown in Fig. 1,t he ﬁrst CNN layer receives the price tensor Ptwithdimension (2, 10, 4). The ﬁlter of this layer is in size of 1 × 3, and the activation function we use here isSelu which is deﬁned in (Klambauer et al., 2017). In this layer, we obtain 32 feature maps and each one is in size of 2 × 5, and these feature maps are received by the next CNN layer. In the second CNN layer, the ﬁlters are of size 1 × 5 and 64 feature maps are produced. The only way I can figure out how to do this using conv2D in PyTorch is by adding stride and padding. Is there something I am missing with regard to how to set up this neural network, or is it just implied that I have to add the appropriate stride and padding? Moreover, is choosing the output size before the features/kernel putting the chicken before the egg, so to speak? Is it better to tailor the input of the next layer to the output of the previous layer rather than trying to finesse one layer's output to fit into a predetermined input on the next layer? Thanks!
