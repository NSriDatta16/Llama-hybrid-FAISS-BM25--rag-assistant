[site]: crossvalidated
[post_id]: 460637
[parent_id]: 460095
[tags]: 
I have just found a difference in my implementation that makes the whole performance different: the random permutation of the attributes. According to the original paper, the permutation (order-agnostic training) should improve the performance in the density estimation, yet, I believe, if the training/testing compute an average over the permutations. I do not do any averaging. That downplayed the performance vs the PyTorch implementation...I believe this solves the question, but I leave it here for anyone who might want to throw a glance at my code. Thanks!
