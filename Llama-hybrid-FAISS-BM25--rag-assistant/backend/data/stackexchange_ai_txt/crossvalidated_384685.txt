[site]: crossvalidated
[post_id]: 384685
[parent_id]: 384593
[tags]: 
Following is an intuitive explanation. Any data = Behavior Pattern + Noise Our objective is to find the pattern using Deep Learning model in the form of weights and biases for various nodes. The objective of the DL model is to minimum error or maximum accuracy. In the process of minimizing error, it would have learnt the pattern but the error would not reach a absolute zero. If the training is continued for more epochs, model tries to reach zero error where it is starting to learn the noise of training data. This noise can change from data sample to sample and hence you would observe the following curves when number of epochs is plotted against accuracy / error for training vs validation sets. Yes. Accuracy would drop marginally but our objective was NOT to be good only on training data. Hence generalization / regularization is required for the model. Early Stopping is one technique that can help.
