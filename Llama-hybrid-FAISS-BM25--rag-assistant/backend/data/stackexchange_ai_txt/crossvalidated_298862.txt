[site]: crossvalidated
[post_id]: 298862
[parent_id]: 104686
[tags]: 
There are several options: collect more data to try balance your dataset (this is most of the times not possible, consider as example churn analysis) downsample the majority class upsample the minority class adding more copies of the positive examples. This is well explained in the Smote paper. doing some kind of resampling taking examples from the positive and the negative set. This is useful if your are running algorithms based on SGD another new point coming from Deep Learning can be to use an adversarial-network to generate new examples for the positive class by training an generator and a discriminator. The generator from noise as input generate new examples trying to cheat the discriminator. Vice versa, the discriminator try to be not cheated by the generator.
