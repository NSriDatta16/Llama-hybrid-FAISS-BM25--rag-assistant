[site]: crossvalidated
[post_id]: 413902
[parent_id]: 413649
[tags]: 
There have already been given many good answers to your question, but I'd like to add a few points that have not yet been raised. 1. Not all parameters in a model need to have an interesting interpretation By this I mean that sometimes models can have so called " nuisance parameters ", i.e. parts of a model that are not of primary interest but that we need in order to draw conclusions about the things we do care about. In the case of simple linear regression on the form $Y_i = \beta_0 + \beta_1 X_i + \varepsilon$ , we might not be interested in knowing the average value of $Y_i$ when $X_i = 0$ (which would be the intercept). In your example, drawing conclusions about the number of stores when the GDP is 0 is not interesting, but without the intercept $\beta_1$ will not be correctly estimated. 2. Even when the intercept is not needed, estimating it is seldom costly There are indeed cases where not including the intercept in the model is appropriate. However, in cases where one could see an argument for excluding it, including the intercept is usually not that costly since you only need to estimate one more parameter in your model, thus losing you one degree of freedom. Unless your dataset is very small, the difference between estimating one or two coefficients in a linear regression model is negliable. Furthermore, if the intercept truly is zero, then it will in large samples be estimated to close to zero (in a correctly specified model). 3. Correlation is not causation The old saying in statistics that states that just because two variables $A$ and $B$ are correlated does not mean that $A$ causes $B$ . This is true when it comes to correlation and it is true when it comes to linear regression. In your specific model, what is it that you want to estimate? If it is the effect that GDP has on the number of stores, then remember that this is not a causal relationship but an association. In particular, you are with your model saying that the number of stores depends on the GDP, whereas it would seem to me (but I am not an economist!) that the GDP would be dependent on the number of stores. This is then a case of what is known as reverse causality. Furthermore, you are not adjusting for other variables in your model, so the association between GDP and number of stores would be confounded by variables associated with both GDP and number of stores, e.g. population size, which complicates the interpretation of the parameters in the model. If your aim is to just estimate the association between GDP and number of stores, then I would instead recommend just estimating the correlation between the two. It contains the same information as a simple OLS regression does, but without the implicit bagage of one variable being the dependent variable and one the explanatory.
