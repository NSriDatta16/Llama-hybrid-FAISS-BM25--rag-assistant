[site]: crossvalidated
[post_id]: 15759
[parent_id]: 15713
[tags]: 
To answer your literal question, "Is it valid to include a baseline measure as control variable when testing the effect of an independent variable on change scores?", the answer is no . The answer is no, because by construction the baseline score is correlated with the error term when the change score is used as the dependent variable, hence the estimated effect of the baseline on the change score is uninterpretable. Using $Y_1$ as the initial weight $Y_2$ as the end weight $\Delta{Y}$ as the change in weight (i.e. $\Delta{Y} = Y_2 - Y_1$) $T$ as a randomly assigned treatment, and $X$ as other exogenous factors that affect weight (e.g. other control variables that are related to the outcome but should be uncorrelated with treatment due to random assignment) One then has a model regressing $\Delta{Y}$ on $T$ and $X$; $$\Delta{Y} = \beta_1T + \beta_2X + e$$ Which by definition is equivalent to; $$Y_2 - Y_1 = \beta_1T + \beta_2X + e$$ Now, if you include the baseline as a covariate, one should see a problem, in that you have the $Y_1$ term on both sides of the equation. This shows that $\beta_3Y_1$ is uninterpretable, because it is inherently correlated with the error term. $$\begin{align*}Y_2 - Y_1 &= \beta_1T + \beta_2X + \beta_3Y_1 + e \\ Y_2 &= \beta_1T + \beta_2X + \beta_3Y_1 + (e + Y_1) \end{align*}$$ Now, part of the confusion in the various answers seems to stem from the fact that different models will yield identical results for the treatment effect , $\beta_1T$ in my above formulation. So, if one were to compare the treatment effect for the model using change scores as the dependent variable to the model using the "levels" (with each model including the baseline $Y_1$ as a covariate), ones interpretation of the treatment effect would be the same. In the two models that follow $\beta_1T$ will be the same, and so will the inferences based on them (Bruce Weaver has some SPSS code posted demonstrating the equivalence as well). $$\begin{align*} Change\ Score\ Model&: Y_2 - Y_1 = \beta_1T + \beta_2X + \beta_3Y_1 + e \\ Levels\ Model&: Y_2 = \beta_1T + \beta_2X + \beta_3Y_1 + e \end{align*}$$ So some will argue (as Felix has in this thread, and as Bruce Weaver has done on some discussions over on the SPSS google group ) that since the models result in the same estimated treatment effect, it does not matter which one you choose. I disagree, because the baseline covariate in the change score model can not be interpreted, you should never include the baseline as a covariate (regardless of whether the estimated treatment effect is the same or not). So this brings up another question, what is the point in using the change scores as dependent variables? As Felix already noted as well, the model using the change score as the dependent variable excluding the baseline as a covariate is different than the model using the levels. To clarify, the subsequent models will give different treatment effects (especially in the case that the treatment is correlated with baseline); $$\begin{align*} Change\ Score\ Model\ Without\ Baseline&: Y_2 - Y_1 = \beta_1T + \beta_2X + e \\ Levels\ Model&: Y_2 = \beta_1T + \beta_2X + \beta_3Y_1 + e \end{align*}$$ This has been noted in prior literature as "Lord's Paradox". So which model is right? Well, in the case of randomized experiments, I would say the Levels model is preferable (although if you did a good job randomizing, the average treatment effect should be very close between the models). Other's have noted reasons why the levels model is preferable, Charlie's answer makes a good point in that you can estimate interaction effects with the baseline in the levels model (but you can't in the change score model). Whuber in this response to a very similar question demonstrates how the change scores induce correlations between different treatments. In situations in which the treatment is not randomly assigned, the model using change scores as the dependent variable should be given more consideration. The main benefit of the change score model, is that any time invariant predictors of the outcome are controlled for. So say in the above formulation, $X$ is constant throughout time (for example say a genetic predisposition to be at a certain weight), and that $X$ is correlated with whether an individual chooses to exercise (and $X$ is unobserved). In that instance, the change score model is preferable. Also in instances in which selection into treatment is correlated with the baseline value, the change score model may be preferable. Paul Allison in his paper, Change Scores as Dependent Variables in Regression Analysis , gives these same examples (and largely influenced my perspective on the topic, so I highly suggest to read it). This isn't to say that change scores are always preferable in non-randomized settings. In the case that you expect the baseline to have an actual causal effect on the post weight, you should use the levels model. In the case that you expect the baseline to have a causal effect, and the selection into treatment is correlated with the baseline, the treatment effect is confounded with the baseline effect. I've ignored the note by Charlie that the logarithm of the weight could be used as the dependent variable. While I don't doubt that could be a possibility, it is somewhat non sequitur to the initial question. Another question has discussed when it is appropriate to use the logarithms of the variable (and those still apply in this case). There is probably prior literature on the subject that would help guide you as to whether using the logged weight is appropriate as well. Citation Allison, Paul D. 1990. Change scores as dependent variables in regression analysis . Sociological Methodology 20: 93-114. Public PDF version .
