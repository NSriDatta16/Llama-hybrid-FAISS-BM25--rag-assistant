[site]: crossvalidated
[post_id]: 43481
[parent_id]: 
[tags]: 
Same (poor) results with linear and non-linear classifiers

I am doing classification of "text quality" using four classes and using 30 features with 1300 samples. I am using the following classifiers: LDAC based on linear discriminant analysis from mlpy . svm with rbf and gridsearch svm with polynomial kernel degree 5 and gridsearch and random forest. The svm and random forest classifiers are based on scikit-learn . I am getting similar (poor) accuracy results with all the classifiers. I get approx 57.1% with LDAC, svm and random forests vary from 57.8- 58.1%. The accuracy is based on cross validation and the corresponding confusion matrices (sum of diagonal/total). Why am I getting similar results with all the classifiers? Any suggestions about the reasons for having similar results when using linear and non-linear classfiers? Is this agreement between linear/non-linear classifiers at low-level a strong hint of flaws in some specific area? I appreciate any comments here in order to try to improve this situation!
