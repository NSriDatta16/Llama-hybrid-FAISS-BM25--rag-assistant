[site]: crossvalidated
[post_id]: 44167
[parent_id]: 
[tags]: 
Model comparison across multiple correlated responses

I have two multivariate linear regression models (multiple outcomes, i.e., the responses are a matrix), and I'm measuring their performance using $R^2$ in cross-validation, over these individual responses, and across all responses. I'd also like to quantify the difference in $R^2$ using a p-value, for example t-test (after Fisher transform of $R^2$ for better normality etc). Now, these responses are highly correlated with each other. Therefore, averaging the $R^2$ over the responses into a single estimate worries me as they are not independent, and a significance test that ignores this might be badly biased. Should I instead get a separate p-value for each outcome and then use some multiple-testing correction?
