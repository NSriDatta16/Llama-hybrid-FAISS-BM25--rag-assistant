[site]: crossvalidated
[post_id]: 258509
[parent_id]: 
[tags]: 
Sparse vs compact representations

In sparse representations, we like to find representation of the input where most elements are nearly zero. On the other hand, in some applications we prefer dense representations such as word embedding methods in NLP (word2vec for example). What is the merit of each of these representations and where each are preferred?
