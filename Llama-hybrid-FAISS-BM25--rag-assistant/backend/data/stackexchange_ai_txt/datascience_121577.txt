[site]: datascience
[post_id]: 121577
[parent_id]: 
[tags]: 
Random Forest Classification model performing much better with 70:30 TEST:TRAIN rather than the opposite

I'm working on a Classification problem as a side project and I'm receiving results contrary to what I'd expect. With 100,000 records, each with 7 components for X, the model is performing much better with 70% of the data being used to test, rather than what I'd expect: 70% training split to work better. Has anyone had this before or know why this could be? I'm wondering if maybe the large size of the data is worsening the model somehow.
