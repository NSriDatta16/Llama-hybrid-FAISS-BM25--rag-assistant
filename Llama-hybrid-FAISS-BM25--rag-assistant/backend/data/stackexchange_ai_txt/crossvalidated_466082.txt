[site]: crossvalidated
[post_id]: 466082
[parent_id]: 465208
[tags]: 
Real images (images from reality) with dimensions (H, W, C) make up only a tiny subset of all possible (H, W, C) tensors. In the same way, the activation tensors resulting from real images in a neural network layer make up only a subset of all possible tensors of the same dimensions. Subsets like these are what is meant by a "manifold" in ML research. To the best of my knowledge, they are not always proven to be smooth or locally Euclidean as in mathematics, but I don't think it hurts to imagine them that way. Given a set of real images, those will result in a set of "real activation tensors", which will be members of ("lie on") that "real activation manifold", which is the manifold the authors are interested in.
