[site]: datascience
[post_id]: 117098
[parent_id]: 
[tags]: 
What will happen if we apply Gradient Ascent?

I have built a simple neural network on MNIST, but instead of moving toward the opposite direction of gradients, I moved in the same direction of it just by applying( pytorch ): For m in model.parameters(): m.weight.grad *= -1 I just wanted to know what will happen in prediction. I got these results as confusion matrix. Are we able to interpret the results?
