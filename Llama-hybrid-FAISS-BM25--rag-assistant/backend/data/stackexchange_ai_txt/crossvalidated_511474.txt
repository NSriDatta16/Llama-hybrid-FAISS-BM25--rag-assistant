[site]: crossvalidated
[post_id]: 511474
[parent_id]: 
[tags]: 
What kind of regularization can I use for CNN aside from L1/L2/Dropout?

I am building a CNN to estimate a sequence of pitches existed in a song with this architecture: model = Sequential() kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None) # conv 1 model.add(Conv1D(filters=256, kernel_size=2, kernel_initializer=kernel_initializer, bias_initializer='zeros', padding="same", activation='relu', input_shape=(image_width, image_height))) model.add(MaxPooling1D(pool_size=2)) model.add(BatchNormalization()) # conv 2 model.add(Conv1D(filters=512, kernel_size=2, activation='relu', padding="same")) model.add(MaxPooling1D(pool_size=2)) model.add(BatchNormalization()) # conv 3 model.add(Conv1D(filters=1024, kernel_size=2, activation='relu', padding="same")) model.add(BatchNormalization()) model.add(Dropout(0.5)) model.add(Dense(51, activation='softmax', activity_regularizer=tf.keras.regularizers.l2(0.01))) epochs = 300 batch_size = 50 weight_optimizer = keras.optimizers.Adam(lr=0.0001) model.compile(optimizer = weight_optimizer , loss = "categorical_crossentropy", metrics=['accuracy', f1_m, precision_m, recall_m]) history = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, verbose = 1, validation_split=0.2) This results to an overfitting model, where the train_accuracy at 97% max, but validation_accuracy only at 30% max. Loss is ranging from 2-5. I try to use regularizer: kernel_regularizer=tf.keras.regularizers.l1(0.01), activity_regularizer=tf.keras.regularizers.l2(0.01) at every conv1d layer and dense layer, and resulting at a very high loss value, at the end of the epoch, it still produce a loss at about 200. Is there any kind of regularizer I can use aside from L1/L2/Dropout/BatchNormalization in Python?
