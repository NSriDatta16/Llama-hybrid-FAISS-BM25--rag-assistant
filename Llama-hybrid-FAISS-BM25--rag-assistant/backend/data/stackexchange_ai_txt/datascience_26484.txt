[site]: datascience
[post_id]: 26484
[parent_id]: 
[tags]: 
What are the major differences between Facebook's ELF RF framework and TensorFlows "Agents"?

I recently read a few papers, especially ELF: An Extensive, Lightweight, and Flexible Research Platform for Real-time Strategy Games TensorFlow Agents: Efficient Batched Reinforcement Learning in TensorFlow As far as I can understand, ELF uses two separate environments (C++ and Python), because they say Most existing RL environments (OpenAI Gym, ...) provide Python interfaces which wrap only single game instances. As a result, parallelism needs to be built in Python when applying modern RL methods. However, thread-level parallelism in Python can only poorly utilize multi-core processors, due to the Global Interpreter Lock (GIL). Process-level parallelism will also introduce extra data exchange overhead between processes and increase complexity to framework design. In contrast, our parallelism is achieved with C++ threads for better scaling on multi-core CPUs. The team from DeepMind (which developed the TensorFlow Agent lib) on the other hand explain it as such: Our implementation is completely defined within the TensorFlow graph. First, we parallelize the forward pass of the neural network by vectorizing the agent computation to produce a batch of actions from a batch of observations. [...] Using a batch size during inference allows us to leverage the internal thread pool of the TensorFlow session, or hardware accelerators such as GPUs and TPUs. So, how are those two different? Sure, ELF uses C++, because they say doing it in Python is tedious and not efficient. TF agents uses "vectorization" and runs everything in the TensorFlow graph. I know, TF uses C underneath and a lot of Protobuffers to communicate data between Python & the underlying C code. So did FB with their ELF just reinvent the wheel or did they do something else that is clever and the TF team didn't adopt?
