[site]: crossvalidated
[post_id]: 541399
[parent_id]: 541391
[tags]: 
Generally the "AI/Machine Learning" people don't really view and evaluate error and probability the same way statisticians do. A "standard" way of evaluating this type of model would be with a confusion matrix , which in this case would simply be a 3X3 crosstabulation of all how each data point was classified. This is the "Machine Learning" approach to accuracy: point estimations and correct classification are more important than properly calibrated confidence. That being said, if you're using a softmax activation function on your final layer, then by definition these are probabilities, or, perhaps more precisely, expected values across a multinomial distribution . So your interpretation is totally valid. This is a more "statistical way" of thinking about the output. Edit: If we wanted to "sort the cases by confidence" the simplest option would be simply to sort by the variance of the vector of the three outputs. Outputs with high variance mean the model is "less confident" in its answer.
