[site]: crossvalidated
[post_id]: 23213
[parent_id]: 23144
[tags]: 
The NPS works well as a performance monitoring or controlling tool. But what you want to find out is something else: You want to identify the true drivers of satisfaction. The NPS is an aggregate score. If you want to say something about drivers of satisfaction, than you have to develop a model which explains the 10-point-scale "ultimate question". However, rating scales are contaminated with scale usage heterogeneity (see paper ). If you run a regression model, you will find that those sub-questions are highly correlated, causing high VIFs and maybe no significant betas, depending on how many sub-questions you have. You might also be overconfident in the significance of sub-questions, depending on the exact model set-up. Consider this simple R script: nobs=1000 p=12 means = rnorm(nobs) vars = 1/rgamma(nobs,3,3) data=matrix(,nobs,p) for(i in 1:nobs){ data[i,]=rnorm(p,means[i],sqrt(vars[i])) } cor(data) Despite the fact that there is no relationship between the 12 variables, the correlations are far from being 0. If you further reduce the scale level (Promotor yes/no), you throw away information. However, scale-adjusting models are very challenging, especially when you have ordinal and categorical variables, and if you look for a ready-made solution. You could treat bottom, middle and top box as categorical outcomes and use a Bayesian Network to model the relationships. BNs treat everything categorical, thus providing a nice general purpose tool. Have you considered a conjoint experiment? Depending on the service or product this is a nice alternative.
