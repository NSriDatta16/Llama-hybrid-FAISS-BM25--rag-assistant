[site]: crossvalidated
[post_id]: 251879
[parent_id]: 
[tags]: 
Cause of Very low AUC during 10-fold Cross-Validation

I'm using 10-fold cross-validation (CV) with $L1$-penalized Logistic Regression to estimate expected prediction error. Briefly, each sample is part of the prediction set for exactly one fold, and I use this prediction compared to the ground truth of that sample, over all samples, to estimate the AUC below. I think this is relatively standard practice. $N=28$, $p=50$. Each feature is a real value in the interval $[0,2]$. The AUC that I estimate via this is really poor to the extent that the reversed classifier would be useful. Shown is for one regularization parameter $C$ for sklearn 's implementation of Logistic Regression , but this effect is relatively robust across parameters (I tried $C=1 \times 10^{-5}$ up to $C=1 \times 10^{26}$), type of penalty ($L2$ vs. $L1$, Elastic Net, etc.), $k$ for $k$-fold CV, and even type of model (I also tried Support Vector Classifiers and Linear Discrimant Anslysis). My question is the following: beyond a simple coding bug , does anyone have any ideas what properties of the data and model(s) would lead to this behavior? Thanks for your thoughts.
