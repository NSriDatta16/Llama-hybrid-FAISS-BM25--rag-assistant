[site]: crossvalidated
[post_id]: 131009
[parent_id]: 130985
[tags]: 
Others have answered your earlier paragraphs, so let me address your last one. Your point's validity depends on the interpretation of "evaluation". If it's used in the sense of a final run on unseen data to give a sense of how well your chosen model might be expected to work in the future, your point is correct. If "evaluation" is used more in the sense of what I'd call a "test" set -- that is, to evaluate the results of training multiple models in order to choose one -- then evaluating on the training data will lead to overfitting.
