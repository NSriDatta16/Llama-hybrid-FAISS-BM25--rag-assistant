[site]: crossvalidated
[post_id]: 558970
[parent_id]: 
[tags]: 
What is the theoretical justification for alternatives to MSE minimisation?

I'm trying to wrap my head around the connection between statistical regression and its probability theoretical justification. In many books on statistics/machine learning, one is introduced to the idea of the loss function, which is then typically followed by a phrase of the flavour 'a popular choice for this function is mean squared loss'. As far as I understand, the justification for this choice stems from the theorem that $$ \arg\min_{Z \in L^2(\mathcal{G})} \ \mathbb{E} \left[ (X - Z)^2 \right] = \mathbb{E} \left[ X \Vert \mathcal{G} \right] \tag{1} $$ where $X$ is the random variable to be estimated based on the information contained in $\mathcal{G}$ . As far as I understand, probability theory teaches us that the conditional expectation $\mathbb{E}[X \Vert \mathcal{G}]$ is the best such estimate. If that's the case, why should our loss function still be a choice? Clearly we should be statistically estimating $\mathbb{E}[X \Vert \mathcal{G}]$ , which by (*) implies minimizing the MSE. An answer which I have often read is that we simply define the conditional expectation to satisfy (1), but that's doesn't seem true, as we have conditional expectations for any random variable in $L^1$ . More importantly, there exists an intuitive theoretical explanation for why this definition gives us an estimator capturing all the information available after observing $\mathcal{G}$ : we're using $\mathcal{G}$ to partition the total probability into possible paths and averaging over the remaining randomness in each of these. This interpretation in terms of information and $\sigma$ -algebras has nothing to do, as far as I can tell, with minimizing MSE, we could have come up with it without ever knowing (1). So my question really is: does minimizing MSE represent the theoretically optimal criterion, and if so, are we saying that any alternative (such as LAD) inherently represents a loss of theoretical optimality in favour of good estimation properties, etc.? Are necessarily leaving (as the explanation in the previous paragraph suggests) information contained in $\mathcal{G}$ on the table? And how do we quantify 'how much information' of $\mathcal{G}$ an estimator based on a different criterion (say, the median in case of LAD) utilises? I've asked this question already on Mathematics Stack Exchange but I'm still not completely satisfied, so I was hoping someone here could maybe illuminate me. Judging by the number of similar questions on this subject, this is probably a phase all students of statistics pass through.
