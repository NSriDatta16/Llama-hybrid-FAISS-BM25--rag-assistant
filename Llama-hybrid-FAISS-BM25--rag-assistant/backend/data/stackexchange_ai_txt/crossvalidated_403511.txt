[site]: crossvalidated
[post_id]: 403511
[parent_id]: 403502
[tags]: 
I guess that by 1D signal you mean time-series data, where you assume temporal dependence between the values. In such cases convolutional neural networks (CNN) are one of the possible approaches. The most popular neural network approach to such data is to use recurrent neural networks (RNN), but you can alternatively use CNNs, or hybrid approach (quasi-recurrent neural networks, QRNN) as discussed by Bradbury et al (2016) , and also illustrated on their figure below. There also other approaches, like using attention alone, as in Transformer network described by Vaswani et al (â€Ž2017) , where the information about time is passed via Fourier series features . With RNN , you would use a cell that takes as input previous hidden state and current input value, to return output and another hidden state, so the information flows via the hidden states . With CNN, you would use sliding window of some width, that would look of certain (learned) patterns in the data, and stack such windows on top of each other, so that higher-level windows would look for patterns within the lower-level patterns. Using such sliding windows may be helpful for finding things such as repeating patterns within the data (e.g. seasonal patterns). QRNN layers mix both approaches. In fact, one of the advantages of CNN and QRNN architectures is that they are faster then RNN .
