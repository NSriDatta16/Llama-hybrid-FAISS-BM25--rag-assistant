[site]: crossvalidated
[post_id]: 437883
[parent_id]: 437805
[tags]: 
ANOVA and logistic regression have different aims. A bit loosely speaking, ANOVA uses a continuous response variable and predicts the value of that variable, while logistic regression uses a binary response variable and predicts the category. ANOVA then attempts to find the mean of the response variable, conditioned on the group membership. You can use a classifier such as logistic regression to see how well you can separate your data. In that case, you would invert the problem: instead of predicting the continuous measurements from the group membership, predict the group membership from the continuous measurements. To get the p-value, look at the parameter on the continuous variable. While I am unfamiliar with Stata, R uses Wald confidence intervals by default, and I have been doing logistic regression parameter inference lately via likelihood ratio testing. A parameter significantly different from zero indicates that the variable gives insight into the group to which the observation belongs. By the way, ANOVA is a linear regression. We have some posts about this fact. I will link one that I liked. https://stats.stackexchange.com/a/76292/247274 EDIT I found another: https://stats.stackexchange.com/a/16956/247274 . I will note that, when there are only two groups, this is identical to the equal-variance t-test. (Remember that R uses the unequal-variance Welch test by default, and other software may, too.) Allowing for some numerical imprecision on a computer, the F-stat from the method in this link and the square of the t-test's t-stat will be the same, and the resulting p-values will be the same.
