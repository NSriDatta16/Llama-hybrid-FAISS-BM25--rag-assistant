[site]: crossvalidated
[post_id]: 28920
[parent_id]: 28909
[tags]: 
I'd look at the problem from a slightly different angle: how complex a model can you afford with only 10 subjects / 100 samples? And that question I usually answer with: much less than 100 PCs. Note that I work on a different type of data (vibrational spectra), so things may vary a bit. In my field a common set up would be using 10 or 25 or 50 PCs calculated from O (1000) spectra of O (10) subjects. Here's what I'd do: Look at the variance covered by those 100 PCs. I usually find that only few components really contribute to the variance in our data. I very much prefer PLS as pre-treatment for clasification over PCA as it does a much better job at sorting out directions that have a high variation which does not help the classification (in my case that could be focus variations, differing sample thickness, ...). In my experience, I often get similar classifiers with 10 PLS latent variables or 25 to 50 PCs. Validation samples need to be processed with the PCA rotation calculated from the training set only, otherwise the validation can (and in such extreme cases as yours most probably will) have a large overoptimistic bias. In other words, if you do out-of-bootstrap or cross validation, the PCA or PLS preprocessing needs to be calculated for each train/test set combination separately.
