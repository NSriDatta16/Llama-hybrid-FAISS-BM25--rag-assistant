[site]: datascience
[post_id]: 24263
[parent_id]: 
[tags]: 
What are key dataset requirements for topic models and word embeddings?

I have a dataset of 2000 documents where avg doc size is 300 words. The vocab is dominated by domain-specific words. My goal is to find similar documents. For this, I tried LDA, LSI, Doc2Vec (topics=100) but results are not great. LSI is better than the others in my dataset. I also tried word2vec (size=100) & word movers distance but again no luck. I am thinking of trying POS tags & then building some ontology model but not sure. Are my results poor because of a bad dataset? What are some other techniques that I can try?
