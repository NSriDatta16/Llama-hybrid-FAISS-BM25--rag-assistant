[site]: stackoverflow
[post_id]: 3951446
[parent_id]: 3951369
[tags]: 
Here are two ideas that you could try out: Length/format patterns - I think you could be able to identify some patterns in the individual columns of the file. For example, values in some columns may be shorter and values in some columsn may be shorter. Values in some columns are typically numbers or from a limited set of values (e.g. months) or at least contain often some sub-string. When you can identify these patterns (based on statistics calculated from items correctly delmited items), then you should could create algorithm that uses these to guess which of the delimiters should be ignored (e.g. when a column would be shorter than expected). Grammatical rules - another idea inspired by your example - are the commas that are not escaped usually followed by some strings (e.g. words "and" or "about"?) If yes, you could use this information to guess which delmiters should be escaped. Finally, if none of these ad hoc techniques can solve your problem, then you can use some heavy statistics to do the estimation. There are some machine learning frameworks that can do the heavy statistics for you, but it is still quite compilicated problem. For example on .NET, you could use Infer.NET from Microsoft Research.
