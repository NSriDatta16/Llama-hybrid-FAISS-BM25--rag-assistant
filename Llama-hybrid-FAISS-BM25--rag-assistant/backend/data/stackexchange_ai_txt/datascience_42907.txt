[site]: datascience
[post_id]: 42907
[parent_id]: 
[tags]: 
how to implement infoGAN's loss function in Keras' functional API

I have been trying to make an infoGAN based on this , but it is in pure tensorflow and I can't really figure out how I would implement the Q_loss in Keras (preferably the functional API). here is what I have so far: def G_loss(y_true, y_pred): return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred, labels=y_true)) def D_loss(y_true, y_pred): return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred, labels=y_true)) def Q_loss(y_true, y_pred): return ??? def get_generator(): inputs = tf.keras.Input(shape=(noise_dim+c_dim,)) x = tf.keras.layers.Dense(256, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02))(inputs) x = tf.keras.layers.LeakyReLU(0.2)(x) x = tf.keras.layers.Dense(512)(x) x = tf.keras.layers.LeakyReLU(0.2)(x) out = tf.keras.layers.Dense(784, activation=tf.nn.tanh)(x) generator = tf.keras.Model(inputs=inputs, outputs=out) generator.compile(optimizer=get_optimizer(), loss=G_loss) return generator def get_discriminator(): inputs = tf.keras.Input(shape=(784,)) x = tf.keras.layers.Dense(1024, kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.02), \ kernel_constraint=clipping(0.01), bias_constraint=clipping(0.01))(inputs) x = tf.keras.layers.LeakyReLU(0.2)(x) x = tf.keras.layers.Dense(512, kernel_constraint=clipping(0.01), bias_constraint=clipping(0.01))(x) x = tf.keras.layers.LeakyReLU(0.2)(x) x = tf.keras.layers.Dense(256, kernel_constraint=clipping(0.01), bias_constraint=clipping(0.01))(x) x = tf.keras.layers.LeakyReLU(0.2)(x) critic_output = tf.keras.layers.Dense(1, kernel_constraint=clipping(0.01), bias_constraint=clipping(0.01), name="critic_output")(x) x = tf.keras.layers.Dense(256, kernel_constraint=clipping(0.01), bias_constraint=clipping(0.01))(critic_output) x = tf.keras.layers.LeakyReLU(0.2)(x) outputs = tf.keras.layers.Dense(c_dim, kernel_constraint=clipping(0.01), bias_constraint=clipping(0.01))(x) discriminator = tf.keras.Model(inputs=inputs, outputs=[outputs, critic_output]) discriminator.compile(optimizer=get_optimizer(), loss=D_loss) return discriminator def get_gan(discriminator, generator): discriminator.trainable = False gan_input = tf.keras.Input(shape=(noise_dim+c_dim, )) gan_output = discriminator(generator(gan_input)) gan = tf.keras.Model(inputs=gan_input, outputs=gan_output) gan.compile(optimizer=get_optimizer(), loss=Q_loss) return gan generator = get_generator() discriminator = get_discriminator() full_gan = get_gan(discriminator, generator) In an infoGAN, there is a loss function for the discriminator (here, the actual discriminator output is named "critic_output"), and one for the Q net you have connected after it (here, the 2 layers after the critic_output layer). Which needs the G_loss value, like here (code from the link at the beginning) # Entropy of Q: lambda*L(G,Q) q_H = tf.reduce_mean(lambd*tf.nn.sigmoid_cross_entropy_with_logits(logits = tf.nn.softmax(Qcx), labels = c_sim)) # infoGAN loss function: Loss = V(D,G) - lambda*L(G,Q) q_loss = tf.abs((g_loss - q_H)) This is what I don't know how to implement in Keras, I have already found how to have multiple output, which I did in the discriminator net. It has the critic output (value needed to compute the G_loss) and the Q net output. But how would I implement this q_loss? I havent tried it but I know about the wrapper function for keras' loss function needing extra parameter (example): def G_loss(lambd): def loss(y_true, y_pred): return lambd * tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred, labels=y_true)) return loss althought I have read that it is only for constants (hyperparameters). How would I give it the value of the G_loss function?
