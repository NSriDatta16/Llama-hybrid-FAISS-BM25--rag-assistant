[site]: crossvalidated
[post_id]: 599577
[parent_id]: 599418
[tags]: 
The observation that logistic regression estimates probabilities , not a decision boundary, is sufficient to answer the entire question. Changing the weights changes the probability estimates. The question's focus on classification, instead of probability estimation, is the origin of the confusion. Logistic regression is not a classifier Our training data will either be linearly separable or non-linear separable. In both cases the decision boundary is defined by: $$ f(\mathbf{x}) = \mathbf{w} \cdot \mathbf{x} + b = 0 $$ and we classify them based on the value of $\sigma(\mathbf{w} \cdot \mathbf{x} + b)$ . Logistic regression is not a classifier; instead, logistic regression estimates the probabilities of class membership . Using a decision rule to create a binary decision using a threshold is an entirely ancillary procedure that a person might decide to use atop logistic regression. However, conflating classification and regression is the origin of a great many misunderstandings. See: Why isn't Logistic Regression called Logistic Classification? Separability implies we can arbitrarily improve the model fit (increase the log-likelihood, equivalently decrease the cross-entropy), which means the estimated probabilities will tend to 0 and 1, with no "middle." So these probability estimates aren't enormously useful if you need to characterize uncertainty, or prioritize which observations are greater risk of some condition. Another reason you might care about separability is if you're trying to precisely estimate a coefficient. A very large coefficient might have a correspondingly large variance. Or, in a slightly different flavor, we might wonder whether randomly switching a small number of labels might significantly change the estimated coefficients. This thread How to deal with perfect separation in logistic regression? has a number of suggestions for alternatives to penalization to "deal with" separability in logistic regression. Each solution addresses the problem of separability, but with a slightly different perspective viz. goals and trade-offs. Weights growing arbitrarily large is not inherently a problem So gradient descent would keep increasing the weights without bound. Is there a problem? Whether this is a problem depends on your goals. Your question starts from the premise that the only thing you care about is a decision function. If this is the case, then separability doesn't obstruct your goals, so you don't need to take special steps to fix a non-problem. Separability and overfitting are distinct Now, in the answer of a related question it is stated that there is overfitting (in the case of separable data) when the weights go to infinity. Sorry, but I don't get it. When we regularize in Linear regression for example, we regularize in order to avoid fitting noise and not because large weights are somehow "bad". Although this text links to an answer that I wrote, what you've written does not follow from the text of the answer. I do not make the claim that there is overfitting when the weights go to infinity. I state that adding a penalty bounds the weights away from infinity. This is true when separability is present, and it's trivially true when separability is not present. Independently, I also state that penalization can be used to prevent overfitting. But models can overfit even when separability is not present. Overfitting is a separate issue from separability. My answer does not say that large weights are "bad," whatever that might mean. Large weights and overfitting are distinct Can someone explain how large weights translate to overfitting when the data are linearly separable? The reasoning here is backwards. If the data are linearly separable, then the weights can be arbitrarily increased in magnitude and improve the model fit (decrease cross-entropy/increase log-likelihood). When separability is present, the fit can be improved arbitrarily by increasing the magnitude of the weights; the result is that the weights grow large. But it is not true that large weights imply overfitting on their own . Neither is it true that large weights on their own imply separability. I think the previous points make this clear, but we also have a number of answers about why shrinkage methods work; notably, shrinkage methods can be used to reduce overfitting whether or not separability is present. See: Why does shrinkage work? When is a biased estimator preferable to unbiased one?
