[site]: crossvalidated
[post_id]: 320341
[parent_id]: 320331
[tags]: 
Your approach actually implies an explosion of the number of parameters of the output layer that does not scale well with the size of the image and the number of objects. Similar to the case of a fully connected MLP and a convolutional network. You loose the position invariance. The way that is actually approached is to learn and output the enclosing box of the object, that is, (x,y) coordinates of the top left corner, and the width and height of the box. But in order to be fast, one needs a complex pipeline: first extract candidate regions containing possible objects, and a classifier that finally decides if the region corresponds to an object, and if so, which one. The current state of the art approach is Faster R-CNN , which you can find also in GitHub . The fundamental idea is that the features are learned at a first stage (learning these features is computationally very expensive). Then two networks are trained on these features: one to learn which regions contain objects (the region proposal network) and a second one that detects an object in a given region. This way you have a high degree of parameter sharing, which improves runtime significantly.
