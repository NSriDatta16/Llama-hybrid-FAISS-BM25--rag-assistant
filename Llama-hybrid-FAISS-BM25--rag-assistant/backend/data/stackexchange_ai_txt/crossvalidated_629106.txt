[site]: crossvalidated
[post_id]: 629106
[parent_id]: 
[tags]: 
hundreds of linear mixed models

I have collected hundreds of electrophysiological indexes along with several demographic variables on about 400 healthy subjects on which the indices are collected through repeated measures at subsequent time points. I would like to see what are the variation and trends from Time0 to Time5. Basically, I'm trying to look at the mean response of each physiological index at different time points, accounting for the variability between subjects. So I am using LMMs to model this relation. The problem is that this solution is time-consuming for hundreds of variables (one dependent variable each time), and also difficult to look at in a reporting document. One way could be doing dimensionality reduction ( Hundreds of multiple linear regression models ), but that would misrepresent the original variables. My question is the following. Is that even acceptable from a scientific perspective to build hundreds of models? I highly doubt that a data analyst would do that, so I appreciate any comments or thoughts on this.
