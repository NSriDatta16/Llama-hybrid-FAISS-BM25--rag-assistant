[site]: datascience
[post_id]: 32446
[parent_id]: 31077
[tags]: 
If you are using WGAN with Gradient Penalty, I think the Framework you are using is the limited factor since computing all the gradients will take time. If you are using WGAN with Gradient Penalty one way to get faster results is to omit the gradient penalty and just do weight clipping as mentioned in original WGAN Paper . But be careful in Improved WGAN (with gradient penalty) they showed, weight clipping can lead to bias in the discriminator. But for my experience with GANs WGAN GP gave the overall best results and I will spend the time training for it. But also your training routine could be part of the problem since lot of reference implementations try to get an rate of which the generator updated, e.g. 1 generator update for 10-100 discriminator updates (which in some scenarios totally makes sense). So there are several factors for slow training but most important is that gradient penalty is computational expensive.
