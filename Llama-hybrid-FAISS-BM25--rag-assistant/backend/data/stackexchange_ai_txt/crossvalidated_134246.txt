[site]: crossvalidated
[post_id]: 134246
[parent_id]: 134151
[tags]: 
I believe that what you're looking for is Stochastic Gradient Descent on the Logistic Regression objective function. The gist of it is that it estimates the gradient of the objective based on a sample of the data (as opposed to the whole dataset), and tweaks the model parameters based on that estimate to maximize/minimize the objective. I've not used it but it does seem like SkLearn provides an implementation, see the partial_fit method off the sklearn.linear_model.SGDClassifier class . Another library that's likely to be fast for online learning is vowpal wabbit .
