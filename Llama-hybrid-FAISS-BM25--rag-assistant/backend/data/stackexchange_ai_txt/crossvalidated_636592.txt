[site]: crossvalidated
[post_id]: 636592
[parent_id]: 
[tags]: 
Bayesian optimization for parametric curve fitting?

I am relatively new to Gaussian Processes and Bayesian Optimization. My question is very simple: Suppose I am trying to learn a function from a parametric family of curves which best describes the observed data. For eg. I could be trying to learn a polynomial function $f(x) = ax^2 + bx +c$ and assume the observation model is $y_i \sim \mathcal{N}(f(x_i), \epsilon^2)$ . Also assume that I specify prior beliefs on the parameters $a, b, c, \epsilon$ . Also assume that $0 . Also suppose $x \in$ $\mathbb{N}$ , so that there are only $100$ choices for $x$ I can observe data at maximum of $40$ points, ie, $x_1, \ldots x_{40} \in (0, 100]$ The question then becomes: how should I sequentially go about spacing $x_i$ in a well defined manner so that I am most confident about my choice of the learnt $f(x)$ . Whatever I found so far deals with Gaussian Process which optimizes sampling assuming a blackbox function. But here, I am looking to learn a specified parametric function. I am not looking for an answer, but I am seeking guidance on where to look. What are the keywords that describe my problem? Because whenever I look up Bayesian Optimization, it always has Gaussian Process.
