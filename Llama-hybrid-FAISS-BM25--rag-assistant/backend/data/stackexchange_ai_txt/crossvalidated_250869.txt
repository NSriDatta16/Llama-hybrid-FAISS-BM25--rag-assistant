[site]: crossvalidated
[post_id]: 250869
[parent_id]: 250793
[tags]: 
"What is the exact statement of what we are inferring? Is it that the treatment was actually effective in the group of patients we analyzed? Some deeper inference?" I think you are confusing the terms of art with the discussion. One of the challenges of talking about things in multiple paradigms is that the different paradigms may use the same words to define different things, or they may not directly discuss something that is of critical importance to one paradigm, but not the other. Both Frequentists and Bayesians, for example, have a concept called an "expectation," but they both define it in a manner that is nonsensical in the other paradigm. I think this is what is happening here. Sampling statistics have to concern themselves with the "population," precisely because they work in the sample space. It isn't that a Bayesian does not care, it is that it doesn't impact their calculation on anything as directly. A second problem is that Bayesian statistics isn't one field as there are multiple axiomatic structures you could use. How you discuss reality may change if you use de Finetti's axioms instead of Cox's. It also could depend upon whether you are an objectivist Bayesian who believes as Frequentists do that population parameters are fixed points, but whose location is unknown, versus subjectivist Bayesians who believe that the population parameter is a distribution that nature draws from and not a fixed point. Someone like Jaynes, who uses Cox's postulates, would create hypothesis in terms of logical assertions. For example, hypothesis one could be that a drug is non-harmful. Hypothesis two would be that it is harmful. Implicitly, this is a universal statement and hence a population statement. The population is never mentioned. Both methods depend upon the sample for inference, but a Bayesian can have an infinite number of hypothesis. It is more important for a Bayesian to be clear in what they are asserting and why. There is one other difference that is important. When you use a Frequentist method you are concerned with the sampling distribution of the statistic and not the sampling distribution of the data. Infinitely many distributions will have a population mean and they will all use either a t-test or z-test. The Bayesian is concerned with the sampling distribution of the data, but not the parameters. Consider a set of independent events that map to a probability over the set [0,1] in $d$ dimensions. It will be approximately multivariate normal as the sample size becomes large enough. Now let us assume that although the events are independent, the components that make up the dimensions are not. They are part of a system. Let us also assume they share a common variance, $\sigma^2_i=\sigma^2_j,\forall{i,j}\in{D}$, and that information about any one mean exists in the other means. The Bayesian posterior for the set $\mu_i,i\in{1\dots{d}}$ for independent dimensions with independent variances and no shared information on the means would look very different from one where you assume a common variance $\sigma^2$ and shared information. The Frequentist tests would be no different but the Bayesian posteriors would be. Bayesian methods are concerned about the population through the likelihood function because it models how the data is generated in the first place in nature. That is why Bayesian model selection methods are so important, because you may not know the true model in nature that the population uses.
