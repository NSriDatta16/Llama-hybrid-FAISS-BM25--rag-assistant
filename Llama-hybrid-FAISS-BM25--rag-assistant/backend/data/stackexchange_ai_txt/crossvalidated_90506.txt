[site]: crossvalidated
[post_id]: 90506
[parent_id]: 89643
[tags]: 
I have no experience relating to Bayesian Neural Nets and HMC, but with a related task. That involved using neural nets as an unormalized probability model (i.e. an energy based model) where training involved generating "contrastive/negative samples" from the model distribution via HMC. I suppose the problem is somewhat similar, since both models share some factors. (More specifically, ${\partial y \over \partial w}$ where $w$ is the first layer's weights and $y$ the output of the net. Bayesian neural nets have a $\partial L / \partial y$ in front, EBMs a different $\partial E / \partial y$ in front and a $\partial w / \partial x = w$ at the end.) Long story short: to get decent results using adaptive step rates to reach a desired acceptance rate was making a huge difference. You can find some code here , but it is python. The approach is described in "Learning Deep Energy Models", Ngiam et al and there is a footnote on the exact settings for HMC.
