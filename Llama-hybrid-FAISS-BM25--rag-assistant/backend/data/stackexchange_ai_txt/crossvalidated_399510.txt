[site]: crossvalidated
[post_id]: 399510
[parent_id]: 
[tags]: 
Random forest feature importance with max_depth = 1

I am using sklearn to estimate a random forest classifier. Out of curiosity I have set max_features=None and max_depth=1 . Everything else is left untouched. I would expect the feature importance, which I get via feture_importances_ to consist of only 1 value. However, the feature_importance has values for all values of my features. How can that be possible and what am I missing?
