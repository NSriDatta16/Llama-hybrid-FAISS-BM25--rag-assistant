[site]: crossvalidated
[post_id]: 176840
[parent_id]: 
[tags]: 
Including previous predictions as features in time series forecasting

I have a time series that I am trying to model using a Random Forest of regression trees as part of the scikit-learn ensemble library. In order to prepare the model for forecasting, I have included as features the five previous hourly target values in the training set, among other features: +-----+-----+-----+-----+-----+------------+ | n-1 | n-2 | n-3 | n-4 | n-5 | y | +-----+-----+-----+-----+-----+------------+ | 10 | 11 | 4 | 36 | 18 | 15 | | 15 | 10 | 11 | 4 | 36 | 4 | | 4 | 15 | 10 | 11 | 4 | 21 | | 21 | 4 | 15 | 10 | 11 | 9 | | 9 | 21 | 4 | 15 | 10 | 55 | +-----+-----+-----+-----+-----+------------+ However, when I use the model to predict future values (say, 5 hours into the future), I face a similar imputation question: how should I fill the null values? +-----+-----+-----+-----+-----+------------+ | n-1 | n-2 | n-3 | n-4 | n-5 | yhat | +-----+-----+-----+-----+-----+------------+ | 11 | 31 | 42 | 6 | 12 | 15 | | NA | 11 | 31 | 42 | 6 | 4 | | NA | NA | 11 | 31 | 42 | 21 | | NA | NA | NA | 11 | 31 | 9 | | NA | NA | NA | NA | 11 | 55 | +-----+-----+-----+-----+-----+------------+ One idea is to predict one row at a time, and then use the predictions to fill the values in the subsequent row. One reason this might be bad is that the prediction values are probably off themselves, and so I am just compounding (potentially) my errors as I get further into the future (but which may be inevitable anyway). The other idea is, if only "n-1" is missing, just fill it with "n-2". But there will be rows for which all "n-1" to "n-5" are missing. In that case, I suppose they could just be filled with whichever were the most recent "n-1" to "n-5" values from the recent past. Is one (or some strategy not considered) to be preferred?
