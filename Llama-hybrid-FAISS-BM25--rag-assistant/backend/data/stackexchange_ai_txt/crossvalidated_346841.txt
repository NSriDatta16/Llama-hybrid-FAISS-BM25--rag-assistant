[site]: crossvalidated
[post_id]: 346841
[parent_id]: 
[tags]: 
Q-learning with slow rewards

A team in my company has implemented a basic model-free Q-Learning agent in relation to inventory control. The problem (in my eyes) is that it only knows its reward once per day based on revenue gain for the actions taken. In my experience, model-free agents often take thousands or millions of episodes to train effectively and so we're looking at many years for the agent to converge. Is this reasoning valid? I feel like this is an obvious question, I just want to make sure before I call them out.
