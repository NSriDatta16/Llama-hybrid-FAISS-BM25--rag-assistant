[site]: crossvalidated
[post_id]: 376205
[parent_id]: 
[tags]: 
Stationary vs. Trend-Stationary Time Series: Auto.Arima difference parameter

I have the following time series training_ts that looks like this: It appears to be stationary or "trend-stationary". When I analyze the stationarity using adf and kpss as well as nsdiffs , I receive the following output: > adf.test(training_ts) Augmented Dickey-Fuller Test data: training_ts Dickey-Fuller = -5.5779, Lag order = 11, p-value = 0.01 alternative hypothesis: stationary Warning message: In adf.test(training_ts) : p-value smaller than printed p-value > kpss.test(training_ts, null = c("Level")) KPSS Test for Level Stationarity data: training_ts KPSS Level = 10.369, Truncation lag parameter = 9, p-value = 0.01 Warning message: In kpss.test(training_ts, null = c("Level")) : p-value smaller than printed p-value > kpss.test(training_ts, null = c("Trend")) KPSS Test for Trend Stationarity data: training_ts KPSS Trend = 0.52976, Truncation lag parameter = 9, p-value = 0.01 Warning message: In kpss.test(training_ts, null = c("Trend")) : p-value smaller than printed p-value > nsdiffs(training_ts) [1] 0 All of which seems to suggest that training_ts is indeed stationary. My next step is then to use the auto.arima package to do some forecasting with external regressors ( training_xregs ). However, the model that auto.arima returns is a d = 1 model, which is counterintuitive given that the nsdiff, adf.test, kpss.test output suggests training_ts is already stationary. Here is the auto.arima output: > arima_model = auto.arima(y = training_ts, trace = TRUE, approximation = TRUE, xreg = training_xregs[, 2:ncol(training_xregs)]) Fitting models using approximations to speed things up... Regression with ARIMA(2,1,2)(1,0,1)[7] errors : 9939.105 Regression with ARIMA(0,1,0) errors : 10624.08 Regression with ARIMA(1,1,0)(1,0,0)[7] errors : 10289.05 Regression with ARIMA(0,1,1)(0,0,1)[7] errors : 9949.029 ARIMA(0,1,0) : 10622.07 Regression with ARIMA(2,1,2)(0,0,1)[7] errors : 9936.425 Regression with ARIMA(2,1,2) errors : 9944.379 Regression with ARIMA(2,1,2)(0,0,2)[7] errors : 9935.7 Regression with ARIMA(1,1,2)(0,0,2)[7] errors : 9933.618 Regression with ARIMA(1,1,1)(0,0,2)[7] errors : 9932.408 Regression with ARIMA(0,1,0)(0,0,2)[7] errors : 10623.19 ARIMA(1,1,1)(0,0,2)[7] : 9930.753 ARIMA(1,1,1)(1,0,2)[7] : 9934.871 ARIMA(1,1,1)(0,0,1)[7] : 9931.152 ARIMA(0,1,1)(0,0,2)[7] : 9946.309 ARIMA(2,1,1)(0,0,2)[7] : 9932.426 ARIMA(1,1,0)(0,0,2)[7] : 10279.04 ARIMA(1,1,2)(0,0,2)[7] : 9931.963 ARIMA(0,1,0)(0,0,2)[7] : 10621.17 ARIMA(2,1,2)(0,0,2)[7] : 9934.051 Now re-fitting the best model(s) without approximations... ARIMA(1,1,1)(0,0,2)[7] : 9934.814 Best model: Regression with ARIMA(1,1,1)(0,0,2)[7] errors So auto.arima believes that training_ts is not a stationary time series. Which is confusing given the above. I then used auto.arima to specify a d=0 difference order with the following results: > arima_model = auto.arima(y = training_ts, d = 0, trace = TRUE, approximation = TRUE, xreg = training_xregs[, 2:ncol(training_xregs)]) Fitting models using approximations to speed things up... ARIMA(2,0,2)(1,0,1)[7] with non-zero mean : 9937.261 ARIMA(0,0,0) with non-zero mean : 11318.17 ARIMA(1,0,0)(1,0,0)[7] with non-zero mean : 10311.81 ARIMA(0,0,1)(0,0,1)[7] with non-zero mean : 10593.26 ARIMA(0,0,0) with zero mean : 11343.59 ARIMA(2,0,2)(0,0,1)[7] with non-zero mean : Inf ARIMA(2,0,2)(2,0,1)[7] with non-zero mean : 9945.74 ARIMA(2,0,2)(1,0,0)[7] with non-zero mean : Inf ARIMA(2,0,2)(1,0,2)[7] with non-zero mean : Inf ARIMA(2,0,2) with non-zero mean : Inf ARIMA(2,0,2)(2,0,2)[7] with non-zero mean : Inf ARIMA(1,0,2)(1,0,1)[7] with non-zero mean : 9937.014 ARIMA(1,0,1)(1,0,1)[7] with non-zero mean : Inf ARIMA(1,0,3)(1,0,1)[7] with non-zero mean : 9937.009 ARIMA(0,0,2)(1,0,1)[7] with non-zero mean : Inf ARIMA(2,0,4)(1,0,1)[7] with non-zero mean : 9941.742 ARIMA(1,0,3)(1,0,1)[7] with zero mean : 9937.686 ARIMA(1,0,3)(0,0,1)[7] with non-zero mean : Inf ARIMA(1,0,3)(2,0,1)[7] with non-zero mean : 9945.782 ARIMA(1,0,3)(1,0,0)[7] with non-zero mean : Inf ARIMA(1,0,3)(1,0,2)[7] with non-zero mean : 9939.034 ARIMA(1,0,3) with non-zero mean : Inf ARIMA(1,0,3)(2,0,2)[7] with non-zero mean : 9944.402 ARIMA(0,0,3)(1,0,1)[7] with non-zero mean : Inf ARIMA(2,0,3)(1,0,1)[7] with non-zero mean : 9939.694 ARIMA(1,0,4)(1,0,1)[7] with non-zero mean : 9938.988 Now re-fitting the best model(s) without approximations... ARIMA(1,0,3)(1,0,1)[7] with non-zero mean : 9934.032 Best model: Regression with ARIMA(1,0,3)(1,0,1)[7] errors So the error for the d = 0 model is less than the d = 1 error. A few questions: Is training_ts truly stationary or is it "trend stationary"? And if it is "trend stationary", I'll assume that means that when the trend is removed, the variance is stable vs. a truly stationary time series that has a stable variance without adjusting for the trend. If training_ts is truly stationary, as adf.test, kpss.test, nsdiffs seem to suggest, why would auto.arima return a d = 1 model with a higher error than the specified d = 0 model? If 'training_ts' is "trend-stationary", should I be using the 'd = 1' model? I assumed that auto.arima would handle trend-stationary time series by removing the trend without a need to apply any differencing? Thank you!
