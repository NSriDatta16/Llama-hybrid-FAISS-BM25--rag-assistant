[site]: crossvalidated
[post_id]: 160380
[parent_id]: 
[tags]: 
Are the total false positives and false negatives of a large confusion matrix equal?

I have a confusion matrix which is 20x20 that is the product of a random forest classification of ~20k instances. Each of these instances was put into a specific class where rows are actual class and cols are predicted class (1-20; labels not shown): [[ 641 0 0 0 5 0 0 0 0 0 18 0 1 4 2 0 0 1 1 0] [ 0 525 3 7 0 0 0 6 0 97 0 8 0 0 1 1 14 0 0 8] [ 0 0 217 12 0 0 0 0 0 0 0 15 0 0 0 0 0 0 0 0] [ 0 0 6 185 0 1 0 2 0 0 0 5 0 0 0 0 1 0 0 0] [ 1 0 0 0 541 2 0 0 0 0 6 1 0 2 1 0 1 2 0 7] [ 0 3 0 0 0 503 36 2 1 1 0 26 0 0 1 0 43 0 0 54] [ 0 3 0 0 0 3 692 2 5 4 0 15 0 2 1 3 96 2 2 21] [ 0 2 1 12 0 1 3 400 252 1 0 9 0 0 0 1 11 0 0 5] [ 0 5 0 11 0 3 4 354 370 0 0 21 0 0 0 0 13 0 0 3] [ 0 51 0 7 0 1 1 9 3 649 0 16 0 0 0 0 6 0 0 1] [ 1 0 0 0 3 0 1 0 0 0 2595 0 1 6 1 5 3 1 4 0] [ 0 7 6 3 1 8 2 17 4 2 0 487 0 0 0 0 14 0 0 3] [ 0 1 0 0 0 0 0 0 0 0 20 0 843 823 6 28 9 2 39 10] [ 1 0 0 0 0 0 1 0 1 0 15 0 1071 659 9 26 12 0 56 8] [ 0 6 2 1 0 0 0 3 3 2 1 4 0 0 1057 4 9 163 1 94] [ 0 1 0 0 1 1 2 1 0 1 1 2 0 1 1 1160 38 10 4 68] [ 0 17 1 0 0 0 2 5 3 1 0 15 0 0 0 13 1310 1 9 28] [ 0 11 1 0 0 1 0 2 1 0 0 4 0 0 178 13 10 1023 2 90] [ 1 0 0 0 0 0 0 0 0 0 15 0 18 44 0 16 1 0 1273 3] [ 0 13 5 0 0 2 2 11 1 6 0 12 0 0 27 29 76 51 3 1038]] I then separately calculate the precision and recall for each of the 20 classes with standard equations (prec = TP/(TP + FP); rec = TP/(TP + FN)). That's fine. However, what I want now is a micro-average of the precision and recall. In other words, I want to use these equations to find micro precision and recall, where C = 20. However, upon doing this, the two values are always the same because total FN and FP of the confusion matrix are always equal! Is this true? For example, all the TPs (diagonals) on the CM above add up to 16,168. All the FPs (all col. values not including diagonal box) add up to 4775, and all FNs (all row values not including diagonal box) necessarily also add up to 4775. So my micro precision and recall in this case are both 0.772. I have a feeling this is not correct.
