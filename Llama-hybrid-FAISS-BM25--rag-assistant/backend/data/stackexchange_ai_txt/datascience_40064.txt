[site]: datascience
[post_id]: 40064
[parent_id]: 40011
[tags]: 
Could be a simple error you did in the code (maybe while extracting the dataset) that we can't see in your code sample. The constant loss you showed is a very weird behaviour indeed. Anyway... You are trying something really ambitious without a pre-trained embedding like word2vec and an architecture so simple. I suggest you to give a look at my github repo where (if you are really interested in not using pre-trained embedding) there is an example that starts with random embedding and adjust it while training reaching 87.72% on the TestSet with a CNN. You can easily convert it to LSTM.
