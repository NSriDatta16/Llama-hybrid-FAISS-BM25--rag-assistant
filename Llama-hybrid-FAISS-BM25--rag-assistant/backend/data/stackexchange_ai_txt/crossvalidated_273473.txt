[site]: crossvalidated
[post_id]: 273473
[parent_id]: 
[tags]: 
Bayesian inference on a sum of iid random variables with known distribution

Let $X_1$, $X_2$, ..., $X_n$ be iid RV's following a mixture distribution of two lognormals such that the pdf of each $X_i$ is $f_{mix}(x)=pf_1(x) + (1-p)f_2(x)$ where $f_1(x)$ and $f_2(x)$ are lognormal pdfs with parameters $\mu_1,\sigma$ and $\mu_2,\sigma$, respectively. Define $S_i$ as a sum of 10 $X$s, e.g. $S_1 = X_1 +..+ X_{10}, \ \ S_2 = X_{11} +..+X_{20},...$ I am given only $S_1,S_2,\dots,S_{n/10}$. How can I infer the mixing proportion parameter $p$ here? That means, I want to know what the proportion of the two lognormals in my mixture is among the 10 samples is (but I only have the sum measurement). Note that the sum of lognormals is not lognormally distributed. My problem could be related to this one, but I am not sure: Bayesian inference on a sum of iid real-valued random variables update : assume that I have many samples of $S_i$. If that helps we can assume that the $\mu$s are well separated, making the mixture nicely bimodal. Generally in mixtures it is that the mixing proportions sum to 1. This is also why I thought about the Dirichlet process. I have no restrictions on the values of $p$ otherwise.
