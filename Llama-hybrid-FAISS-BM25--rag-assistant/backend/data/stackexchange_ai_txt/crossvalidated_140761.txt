[site]: crossvalidated
[post_id]: 140761
[parent_id]: 
[tags]: 
Survival analysis: Multiply impute 5 datasets to average one propensity score then analyze OR pool the estimate from 5 imputed datasets?

I have a question regarding the use of propensity score in a survival analysis with use of mutliple imputation to handle missing data. The question is of theoretical nature and may well apply to other situations. I have a data set of n individuals. The aim is to estimate the effect of a treatment on a binary outcome (death). The analysis is based on propensity score; the propensity score is derived by means of logistic regression, which includes 30 predictors variables. Effect estimation is carried out by means of Cox regression (which uses the propensity score in various ways [stratification, covariate adjustments etc]). There are a large number of patients, and on average 2â€“7% missing for each variable (of which there are 30 included in the prop. score). Thus, I have a large data set with a substantial amount of missing data (at least in terms of complete cases) which is why I use multiple imputation - 5 complete data sets are imputed. Now the question is what to do with the muliply imputed data sets; which one of the strategies below should I prefer? 1. Calculate one average propensity score for each individual using the 5 separate data sets. That way, each individual will have one propensity score, which is the average from the n complete data sets. Then do the Cox regression.. 2. Analyze each separate multiply imputed data set (with Cox regression), and then pool the 5 hazard ratio estimates to one hazard ratio. The second method appears to be used more often, but is it better/worse? Any thoughts about this?
