[site]: datascience
[post_id]: 27169
[parent_id]: 
[tags]: 
Taking average of multiple neural networks?

I'm fitting a neural network using a very small data set, so try splitting the data into training and validation sets. (there is a separate test set) If I split training/validation randomly multiple times, construct a neural network for each training/validation split, and take average of predicted values of the neural networks on the test set, can it be called a ensemble model? Or is there a specific name for such a technique? Edit: I just found that a similar technique is called 'repeated random sub-sampling validation,' but the RRSSV splits the data into training and test set (though it is called 'validation data' according to Wikipedia, it's actually test data). My method splits the given data into training and validation set, and use separate test data. I think my method can also be called RRSSV .
