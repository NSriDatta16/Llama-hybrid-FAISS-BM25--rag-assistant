[site]: crossvalidated
[post_id]: 631379
[parent_id]: 631374
[tags]: 
Welcome to CV! First, I don't mean to question your approach but it's usually better to run one large model with all of your data instead of running separate models for, say, men and women, let alone "women in age category 1", "women in age category 2" etc. Maybe you have reasons for this, but I'd consider if it was possible to run a model with everyone in it and use gender and age as predictors. (However, technically speaking, you can use the subset function within the glm function the way you have specified.) Second, I may understand your issue with reporting wrong, but to me model building/fitting and reporting are two different things. When you have run your model, take the statistics you want to report from your output and put them in a table (in one way or another). For instance, regarding your example, take the ORs and CIs and report them along with the coefficients? Edited to add: if I run a logistic regression with a predictor with several category levels, I usually extract the mean probabilities for each level and report them along with pairwise contrasts. Emmeans package is great for this. Third, regarding Furthermore, I'm fairly new to logistic regression all together. I can interpret an R summary-output of a regression, but I'm not sure how to adapt the model to make it better. -this very much depends on what do you mean by making it better? Roughly, if you are trying to do inference (i.e. say something about the underlying population on the basis of your results), the best course of action is to decide what model you want to test on theoretical basis, and then stick with that model and report parameters from that model. Whereas if your goal is to maximize variance in mortality explained in this particular sample, you can for instance compare pseudo-R-squared values or likelihood ratios across models.
