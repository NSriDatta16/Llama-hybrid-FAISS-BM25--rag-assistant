[site]: datascience
[post_id]: 84024
[parent_id]: 83991
[tags]: 
What you're proposing is some very simple form of ensemble learning. You need to have at least a sample of labelled data in order to evaluate any method. Using this labelled data you can: evaluate each of the three methods on their own evaluate your idea of averaging the 3 methods predictions if you have enough labelled data, you could even train a model which combines their predictions optimally (this would be full-fledged stacked generalization )
