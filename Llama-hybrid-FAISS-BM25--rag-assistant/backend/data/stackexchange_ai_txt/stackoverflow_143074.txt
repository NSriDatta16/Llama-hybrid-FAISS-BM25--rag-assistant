[site]: stackoverflow
[post_id]: 143074
[parent_id]: 137226
[tags]: 
1. What are the patterns you use to determine the frequent queries? Depends on what level you are dealing with the database. If you're a DBA or a have access to the tools, db's like Oracle allow you to run jobs and generate stats/reports over a specified period of time. If you're a developer writing an application against a db, you can just do performance profiling within your app. 2. How do you select the optimization factors? I try and get a general feel for how the table is being used and the data it contains. I go about with the following questions. Is it going to be updated a ton and on what fields do updates occur? Does it have columns with low cardinality? Is it worth indexing? (tables that are very small can be slowed down if accessed by an index) How much maintenance/headache is it worth to have it run faster? Ratio of updates/inserts vs queries? etc. 3. What are the types of changes one can make? -- If using Oracle, keep statistics up to date! =) -- Normalization/De-Normalization either one can improve performance depending on the usage of the table. I almost always normalize and then only if I can in no other practical way make the query faster will de-normalize. A nice way to denormalize for queries and when your situation allows it is to keep the real tables normalized and create a denormalized "table" with a materialized view. -- Index judiciously. Too many can be bad on many levels. BitMap indexes are great in Oracle as long as you're not updating the column frequently and that column has a low cardinality. -- Using Index organized tables. -- Partitioned and sub-partitioned tables and indexes -- Use stored procedures to reduce round trips by applications, increase security, and enable query optimization without affecting users. -- Pin tables in memory if appropriate (accessed a lot and fairly small) -- Device partitioning between index and table database files. ..... the list goes on. =) Hope this is helpful for you.
