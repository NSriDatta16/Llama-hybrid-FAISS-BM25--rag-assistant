[site]: datascience
[post_id]: 72328
[parent_id]: 72325
[tags]: 
Perhabs your network is overfitting. Overfitting is where networks tuned its parameters perfectly to your training data and therefore it has very low loss on training set. Unfortunately, it will perform badly when new samples are provided within test set. Overfitting is broadly descipted almost everywhere: https://en.wikipedia.org/wiki/Overfitting What you can do with overfitting: try neural network with simplier structure, it should help your network to preserve ability to generalize knowledge, use early stopping; try to measure validation loss at every epoch. And when it gets higher for like 3 epochs in a row - stop network training, dropout: dropout is simple technique that prevents big networks from overfitting by dropping certains connection in each epochs training then averaging results. It is easy to use because it is implemented in many libraries like Keras or PyTorch. $l_1$ and $l_2$ regularization: they are modification to your loss function making it involve sum of weights. Minimizing sum of net's weights prevents situation when network is oversensitive to particular inputs. The other cause for this situation could be bas data division into training, validation and test set. Training and validation set's loss is low - perhabs they are pretty similiar or correlated, so loss function decreases for both of them. Then relation you try to find could by badly represented by samples in training set and it is fit badly. I would check that division too.
