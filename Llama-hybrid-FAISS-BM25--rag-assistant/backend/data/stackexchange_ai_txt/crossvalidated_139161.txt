[site]: crossvalidated
[post_id]: 139161
[parent_id]: 139131
[tags]: 
Possibility of usage of negative weights depends on the distribution of $W(\boldsymbol{\theta}, \boldsymbol{\alpha})$. For example, let's consider a linear regression model with independent Gaussian noise, so for $i$-th observation we have $$ \theta^0_i = \alpha \theta_i^1 + \varepsilon, \varepsilon \sim \mathcal{N}(0, \sigma^2). $$ We get the log likelihood of the form: $$ l(\boldsymbol{\theta}, \boldsymbol{\alpha}) = -\frac{1}{2 \sigma^2} \sum_{i = 1}^n (\theta^0_i - \alpha \theta_i^1)^2 + c, $$ with $c$ doesn't depend on $\boldsymbol{\alpha}$. This function is quadratic in $\boldsymbol{\alpha}$ and exact analytic solution is available for Maximum Likelihood estimation. Suppose that we weight our likelihood with $w_i, i = \overline{1, n}$. If some weight is negative, it can be the case that the maximum of weighted likelihood is $+\infty$ (if $\sum_{i = 1}^n w_i (\theta_i^1)^2 So, allowance of negative weights depends on used statistical model and requires additional attention to ensure that provided solution makes physical sense.
