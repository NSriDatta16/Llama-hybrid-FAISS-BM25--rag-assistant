[site]: crossvalidated
[post_id]: 422940
[parent_id]: 422935
[tags]: 
Some good answers have been already posted, so I will just post a remark here that was important to me some time ago, that aims to be very intuitive and pragmatical. When you have a situation like this, think about the opposite case. You have a sample and you estimate a mean (for example) which turns out to be terribly big. So, at first glance, you would say that this estimate reveals that the population mean is actually different from 0, because the sample mean is terribly $big$ . However, what does $big$ mean in statistical terms? Or, analogously, what about the standard error? Is it $big$ when adjusted for the standard error? The test will incorporate the effect of the standard error in the judgement of the estimated mean. So if the standard error is too high, then the test will tell you that we cannot reject the null, even if the estimated mean seems to be large. Because the test will relativize the value of the estimated mean and will compare it to the standard error. So if you have too much standard error then the high standard error means that the estimated mean is too noisy to draw a statistical robust conclusion that the population has a mean which is different from 0. Here, as long as I have actually understood your point, you have the opposite case: the estimated mean is very low, but the fact that you have a very low standard error reflecting a very low population standard deviation around the true mean, allows you to draw a statistically-motivated inference on the population mean being non-zero (with a certain probability of error in this inference depending on the significance level). In other words, the test will always interprets the estimated value of the mean in light of the corresponding standard error to formulate a decision. So a $big/small$ estimated mean may mean nothing, if not compared to the standard error
