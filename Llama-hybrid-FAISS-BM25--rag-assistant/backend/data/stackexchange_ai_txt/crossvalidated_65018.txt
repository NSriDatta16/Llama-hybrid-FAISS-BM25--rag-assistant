[site]: crossvalidated
[post_id]: 65018
[parent_id]: 61461
[tags]: 
The approach of using the minimun common resolution, hourly in this case, is quite usual and hourly samples are de-facto a standard for IT systems capacity planning. You will not get a better resolution by interpolating the data nor using the peak will be of any help either without knowing more information on the transaction distribution. More granular data does not imply finding a better correlation as you'll probably start adding noise (sampling noise for example) which the hourly average is reducing. If the correlation is good, you can estimate the service demand to be used in a QN model. If the correlation does not explain the usage of the CPU according to a QN model, try to analyze your CPU in frequency to see if you can identify periodic activity on the server which is not contributed by the transactions being managed.
