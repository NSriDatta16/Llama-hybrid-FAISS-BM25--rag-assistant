[site]: datascience
[post_id]: 23095
[parent_id]: 9909
[tags]: 
RBM maximizes probability of visible units $p(\mathbf{v})$, defined by the model, over all training data. It is equivalent to minimizing the KL-divergence between the model distribution and the (empirical) data distribution (more details here ). Maximum likelihood learning typically is performed by gradient descent. There are analytical expressions for the gradients of log-likelihood w.r.t. model weights, but they are intractable for regular-sized RBMs because of the exponential number of terms in the respective sums. Therefore the gradients themselves are approximated by MCMC-based algorithm called Contrastive Divergence (or its variants).
