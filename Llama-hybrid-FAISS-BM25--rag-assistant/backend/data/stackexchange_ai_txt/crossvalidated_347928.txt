[site]: crossvalidated
[post_id]: 347928
[parent_id]: 347664
[tags]: 
The RNN architecture seems to be fine. I eventually achieved better results with the following changes: rnn:forget() needs to be called at the end of each training iteration to clear out the previous state. try many more iterations - reasonable convergence required several 10s of thousands. the size of the hidden state really matters and it's worth playing around with the size and seeing how quickly the error falls in each case. In this particular circumstance about 30 nodes appears to be close to the sweet-spot.
