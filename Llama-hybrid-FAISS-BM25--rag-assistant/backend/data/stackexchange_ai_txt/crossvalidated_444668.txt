[site]: crossvalidated
[post_id]: 444668
[parent_id]: 444665
[tags]: 
I'm not familiar with automatic differentiation for blackbox functions. In machine learning, the loss is typically elementary, or close to it. For example, a simple feedforward neural network consists of matrix multiplications (multiplication is certainly elementary), sigmoid (which is elementary), and perhaps you have some cross-entropy loss, which is also elementary.
