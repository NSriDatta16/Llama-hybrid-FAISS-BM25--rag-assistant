[site]: crossvalidated
[post_id]: 490050
[parent_id]: 490047
[tags]: 
First, there is no reason to use the original Bonferroni Correction any more. As the Wikipedia page notes, the Holm modification to the that method is uniformly more powerful while maintaining the same control over family-wise error rate. There are extensions and alternatives that might provide even better power. Second, I personally find false-discovery rate (FDR) easier to explain and more useful in practice with this type of study than family-wise error rate (FWER). An FDR of 5% essentially means that 5% of the nominally positive results are likely to be false-positives. Even a businessman should be able to understand that. An FWER of 5% means that if I do the same experiment multiple times then in only 5% of experiments will I find any false positives. How many people really understand the frequentist meaning of p-values that underlie FWER, and how many people would really want to miss multiple true positive findings just because there might just be a true negative hiding somewhere in the results? Third, with a binary outcome you should use a more efficient logistic regression model to handle your data. Your "treatments" would be coded as 26 levels of a single (unordered) factor variable. The logistic regression would determine whether there were any significant differences among the treatments with respect to outcome. If not, you stop. If there are, standard approaches like those used for analysis of variance provide principled ways to deal with multiple comparisons that can be more powerful than what you would get with Holm-Bonferroni.
