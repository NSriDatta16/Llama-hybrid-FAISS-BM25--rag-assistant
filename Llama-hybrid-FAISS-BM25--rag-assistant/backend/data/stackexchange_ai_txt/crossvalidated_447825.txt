[site]: crossvalidated
[post_id]: 447825
[parent_id]: 
[tags]: 
lme4: what is gained by scaling variables?

I am performing a multilevel logistic regression with glmer from the lme4 -package. Currently, it's a very simple model of the form: glmer(y ~ x + (1 | group), data = data, family = binomial) . Running this in R returns the model fit accompanied by a warning message: "Model is nearly unidentifiable: very large eigenvalue" . Therefore, I centered the variable x by using scale(x) , as was mentioned for example here . This indeed lets the warning message disappear. Hooray! However, the output of the model is actually almost the same as before. The only things that changed are the estimate of the coefficient for y and its standard error, which is not surprising at all, the intercept and the correlation between the intercept and y . Everything else is the same as before scaling, e.g. the estimate of the random effects, the p-value of the coefficient of y , the AIC, BIC, deviance. So, basically, all parameters that I am interested in are the same, regardless whether I center my variables or not. One thing that changes for sure, is the coefficient of my centered variable. However, this changes not in a good way, since I can't properly interpret the coefficient of a centered variable (or at least not as properly as the coefficient of the original variable). Thus, my questions are: Is my first model with the non-centered variable necessarily problematic? If the answer to the first questions is "yes", is my second model with the centered variable really non-problematic, since it gives essentially the same output as the other model? Should I do more to improve my models?
