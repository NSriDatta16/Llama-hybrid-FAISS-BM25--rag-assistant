[site]: crossvalidated
[post_id]: 27340
[parent_id]: 27332
[tags]: 
Stationarity means that the marginal distribution of the process does not change with time. A weaker forms states that the mean and the variance stay the same over time. So anything that violates it will be deemed non-stationary, for whatever silly reasons. For instance, a deterministic $y_t = \sin t$ is non-stationary, as its mean keeps changing, although at the face of it, this is a pretty simple and predictable process. All the tests you are considering have a specific alternative in mind: a random walk process $$ y_t = y_{t-1} + \epsilon_t $$ or some easy modification of it (e.g., include additional lags $y_{t-2}$, $y_{t-3}$ with small coefficients). This is a simple model of an efficient financial market, where no information whatsoever can be used to predict the future changes in prices. Most economists think about their time series as coming from ARIMA models; these time series have well defined periods when stuff happens (month, quarter, or year), so it rarely gets worse than an integrated time series for them. So these tests are not designed for more complex violations of stationarity, like mean change, variance change, change in the autoregressive coefficients, etc., although tests for these effects have obviously been developed, too. In engineering or natural sciences, you are more likely to encounter time series with more complicated issues, like long range dependence, fractional integration, pink noise, etc. With the lack of clear guidance from the description of the process regarding the typical time scales (how often does the climate change?), it usually makes more sense to analyze the data in the frequency domain (while for economists, the frequency domain is quite clear: there are annual seasonal cycles, plus longer 3-4-5 year business cycles; few surprises can occur otherwise). So basically I told you why you don't want to do what you set out to do. If you don't understand time series, you would be better off finding somebody who does and paying consultancy fee, rather than having your project screwed up because you've done something silly. Having said that, the formal solution to your problem would be to reject the null hypothesis of a stationary series when, for a given series, at least one test has a $p$-value below $0.05/(3M)$ where $M$ is the total number of series, $3$ is the number of tests you perform on them, $0.05$ is the favorite 5% significance level, and the whole expression is known as Bonferroni correction for multiple testing. The output does not show the $p$-values with sufficient accuracy, so you would need to pull them as the returned class members, such as pp.test(x)$p.value . You'll be doing this in cycle, anyway, so it would probably suffice if you suppress all of the output, and only produce the name(s) of the variable(s) that fail stationarity.
