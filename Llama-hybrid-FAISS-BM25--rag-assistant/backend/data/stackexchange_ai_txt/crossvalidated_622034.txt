[site]: crossvalidated
[post_id]: 622034
[parent_id]: 
[tags]: 
Why are equally-wide confidence intervals used with the Benjamini-Hochberg correction?

This paper says: *2. For any p-values that are significant after FDR correction, construct a CI for the corresponding test with coverage $1-\alpha^{'}$ , where $\alpha^{'}$ is: $\alpha^{'}=\frac{k}{m}\alpha$ . It also says FCR adjusted BH-selected CIs guarantee the expected FCR is less than or equal to $\alpha$ if the different tests being compared are independent or exhibit positive regression dependency*. However, it then states that a problem with such approach is that we don’t have CIs for non-significant findings. My question is: Why are we restricted to cases where adjusted CIs have all the same length? If different formulas are used to build adjusted p-values depending on ranking, while doesn’t this hold for CIs? I understand this would make the CI length dependent on other comparisons, but this is already happening by making the CI width depend on the number of significant findings. For example, if there are 5 tests, the first CI has coverage $99\%$ , the second one $98\%$ , the third one $97\%$ , the fourth one $96\%$ and the fifth one $95\%$ . In case some p-values are modified to prevent them from becoming larger than the one following them in the ranking (by making them equal to the following one), why couldn't the same thing be done with the CI? I'm referring to what described here: What's the formula for the Benjamini-Hochberg adjusted p-value? Second, make sure that the resulting sequence is non-decreasing: if it ever starts decreasing, make the preceding p-value equal to the subsequent (repeatedly, until the whole sequence becomes non-decreasing). My point is: one could adopt a series of CIs with a decreasing range and, when a p-value is adjusted to prevent it from being larger than the subsequent one, adjust the corresponding CI in the same way.
