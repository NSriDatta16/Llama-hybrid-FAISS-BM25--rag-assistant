[site]: crossvalidated
[post_id]: 423748
[parent_id]: 418121
[tags]: 
In the end, although I appreciated the answer from user20160, I found it impractical to implement. Instead, I went ahead with the idea I mentioned in my question, and problems didn't materialize. Specifically: I began with the GP model I already had, and a roughly plausible mapping of confidence scores to variances. I chose 5000 random subsets of the data, each representing consecutive samples from one instrument, over a representative period of time. For each data-slice, 75% of the points were chosen (using sklearn train_test_split ) as a "training set" and used to fit the GP model (with frozen kernel), and the remaining 25% were a left-out "validation" set. For each point in the left-out set, the GP prediction was run for the same time coordinate, and the difference between the measurement value and the predicted mean was recorded, along with the point's confidence score. The points were bucketed by confidence score, and the RMSE for each bucket calculated and plotted. These lined up very nicely, so I used weighted least squares to fit a line to them and plugged that in as my new confidence function. Then I iterated, re-optimizing the kernel using the new confidence function, and re-fitting the confidence function using the new kernel. This didn't diverge, and in fact converged quickly, with no significant changes after the first two iterations. It seems a little bit muddled-up to me what I'm actually measuring â€” when I take the difference between the GP predicted mean and the measurement value, neither one is the true value, and the error I get back is the sum of the measurement error (which I want) and the prediction error (which depends on the model accuracy, and the accuracy of the other data points in the set). Nonetheless, the results came out okay, which I guess means that my scenario is pretty well-behaved. It occurs to me that I might want to ignore the y-intercept of the fitted confidence function, simply take its slope, and normalize it so that it gives a variance of 0 at the highest possible confidence score, and increases to the left, allowing for a white-noise term in my kernel to account for any excess variance, and allowing the optimizer to adjust this term. However, I didn't do this.
