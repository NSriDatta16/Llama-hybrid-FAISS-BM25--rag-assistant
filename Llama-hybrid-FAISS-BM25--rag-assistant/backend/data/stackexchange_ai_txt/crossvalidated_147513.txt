[site]: crossvalidated
[post_id]: 147513
[parent_id]: 
[tags]: 
Marginal likelihood vs. prior predictive probability

In the Bayesian framework, to me, it seems that the marginal likelihood and the prior predictive distribution/probability are equal. Is that the case? Or maybe this just holds for single data points? Why differ between these two terms? Marginal likelihood (evidence): $$ p(\mathbb{X}|\alpha) = \int_\theta p(\mathbb{X}|\theta) \, p(\theta|\alpha)\ \operatorname{d}\!\theta $$ Prior predictive distribution: $$ p(\tilde{x}|\alpha) = \int_{\theta} p(\tilde{x}|\theta) \, p(\theta|\alpha) \operatorname{d}\!\theta $$
