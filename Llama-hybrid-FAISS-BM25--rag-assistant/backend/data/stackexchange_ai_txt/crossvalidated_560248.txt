[site]: crossvalidated
[post_id]: 560248
[parent_id]: 487550
[tags]: 
The obvious caveat is that $R^2$ can be driven high by modeling the noise. In the extreme, this means that you are just playing connect-the-dots. The result is that your model lacks an ability to generalize, meaning that your ability to predict in the future is minimal and that your understanding of the process that generated the observations is minimal. This is why machine learning people like out-of-sample testing. If you get an increase in $R^2$ while also getting the $R^2$ to increase when you apply the models to out-of-sample data, you would have more confidence in the model fitting to the signal rather than the noise. Alternatives, perhaps preferable to out-of-sample testing, include metrics like adjusted $R^2$ and various forms of information criteria (which penalize a model for having high numbers of parameters, meaning that you don't just need a bigger model to improve the fit but improve the fit a lot in order for adjusted $R^2$ or information criteria to improve).
