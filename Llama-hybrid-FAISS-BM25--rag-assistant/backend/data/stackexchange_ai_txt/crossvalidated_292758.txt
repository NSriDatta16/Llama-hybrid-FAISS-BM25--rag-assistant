[site]: crossvalidated
[post_id]: 292758
[parent_id]: 
[tags]: 
An approach to analyse error in ABC posterior

I trying to understand approximate Bayesian computation (ABC) better so please evaluate my idea to analyse the error in the ABC posterior: Choose arbitrary constant values $\theta_0$ for model parameters $\theta$. Generate $n$ sets of synthetic data $X$. Use an ABC algorithm to compute an approximate posterior distribution $P(X|\theta)$ for each set of synthetic data $X_i$. There should be $n$ posterior distributions in total. For each posterior distribution $P_i(\theta|X)$ compute an empirical inverse cumulative distribution $F^{-1}(\theta)$ Substitute the original constant model $\theta_0$ parameters into the inverse CDF $F^{-1}(\theta_0)$ and record the result for each posterior distribution $Y_i = F_i^{-1}(\theta_0)$. Draw a histogram of the $n$ samples of $Y$. In the case that the posterior distribution is exact (no error) then $Y$ should be uniformly distributed on $[0,1]$. The tolerance parameter $\epsilon$ usually acts to widen the posterior distribution and hence in this case the distribution of $Y$ will be more concentrated in the centre of the $[0,1]$ interval. The deviation from a uniform distribution offers insights into the accuracy of the posterior distribution obtained through ABC. Does this idea make sense? Is there already an established technique similar to this? If so then please link it. Thanks in advance for your help.
