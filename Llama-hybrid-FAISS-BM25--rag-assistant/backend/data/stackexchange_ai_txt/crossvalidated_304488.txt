[site]: crossvalidated
[post_id]: 304488
[parent_id]: 304437
[tags]: 
I had similar questions when read papers from other filed. And asked a lot of question related to this, such as this one in Education Data Mining community: Why use squared loss on probabilities instead of logistic loss? Here I will present a lot of personal opinions. I feel loss function does not matter too much in many practical use cases. Some researcher may know more about squared loss and build system of it, it work still work and solve real world problems. The researchers may never know logistic loss or hinge loss, and want to try it. Further, they may not interested to find the optimal math model, but want to solve real problems that no one attempted to solve before. This is another example: if you check this answer to my question, all of them are sort of similar. What are the impacts of choosing different loss functions in classification to approximate 0-1 loss More thoughts: a machine learning research may spend a lot of time on what model to chose, and how to optimize the model. This is because a machine learning researcher may not have the ability to collect more data / get more measures. And a machine learning researcher's job is getting better math, not solve a specific real world problem better. On the other hand, in real world, if the data is better, it beats every thing. So, choosing neural network or random forest may not matter too much. All of these models are similar to a person want to use machine learning as a tool to solve real world problems. A person not interested on developing math or tools may spend more time on using specific domain knowledge to make system better. As I mentioned in the comment. And if one is sloppy with math, he/she still be able to build something that works.
