[site]: crossvalidated
[post_id]: 187033
[parent_id]: 186858
[tags]: 
Doing an outer loop of cross validation around your random forest does make sense in a number of situations, e.g. if your data is clustered such as containing repeated measurements. The key there is to set up the cross validation so that you get out-of-(suspected)-cluster predictions. I'm not sure which metrics should I look at You need to look at the metrics that are important for your application, both for out-of-bag and cross validation. should I just look at it's average and STD I'd recommend repeated/iterated $k$-fold cross validation. With that you can measure the stability of the predictions for the same test case wrt. slight changes in the training data. Aggregation helps to improve this stability, so IMHO it should be checked afterwards.
