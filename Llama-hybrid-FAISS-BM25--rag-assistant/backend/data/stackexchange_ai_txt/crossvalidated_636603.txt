[site]: crossvalidated
[post_id]: 636603
[parent_id]: 
[tags]: 
Logistic regression sample size calculation and 10:1 rule of thumb

I need to calculate the sample size for a proposed logistic regression. For the dependent variable, outcome is coded as disease or no disease. The major predictor is a continuous variable. There are 10 potential covariates but some might be removed after model fitting, due to not being statistically significant or clinically irrelevant. I read the other posts here. These are the possible ways. Say prevalence of disease = $0.2$ , then the following methods could be used: Use the general rule of thumb (e.g. Peduzzi, 1996), number of events = $10 * 10 / (0.2) = 500$ . How about the number of non events? That's needed to calculate the total sample size. Should I use $500 \times 2$ , $500/0.2$ , or ...? However, in reality, it might be impossible to recruit that many people. A way I can think of is to reduce the number of predictors. Other general rules like $1:10$ , $1:15$ , $1:20$ exist. In any case, these rules will produce a much smaller number of events than option 1. Even if I use $1:20$ , this gives me $10*20 = 200$ , which is half of option 1. (Hsieh, 1998) makes use of the odds ratio of the major predictor, plus the multiple correlation coefficient. Unfortunately, we don't have this info. We can only guess. From a budget perspective, Option 2 needs much fewer people than Option 1. Do people often prefer Option 2? Is there a big difference between Option 3 and the others? Is one superior than the other? If I don't take the covariates into account for calculating sample size, but I adjust these potential confounders in the analysis, will there be a problem?
