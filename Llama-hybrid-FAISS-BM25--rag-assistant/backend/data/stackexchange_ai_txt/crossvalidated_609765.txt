[site]: crossvalidated
[post_id]: 609765
[parent_id]: 511105
[tags]: 
An adjusted $R^2$ is problematic in practice for many machine learning models, since the degrees of freedom range from complicated to calculate to totally unclear. Combine that with the fact that many models are fit after performing preliminary steps like hyperparameter tuning, and calculating the degrees of freedom turns into a real mess. The degrees of freedom matter to the adjusted $R^2$ because the standard adjusted $R^2$ from OLS linear regression uses a comparison of the residual variance of your model and the residual variance of a model that predicts the mean of $y$ every time, and adjusted $R^2$ considers unbiased estimators of those respective variances whose calculations require use of the degrees of freedom (that's the $n-p-1$ in the link). If you want an $R^2$ -style measure of model performance that penalizes the model for having many parameters that put it at risk of overfitting, you might want to calculate an out-of-sample $R^2$ -style metric. As I discuss here , several calculations can be defended as out-of-sample $R^2$ -style calculations, though the one that makes the most sense to me that I discuss here uses the following formula. $$ 1-\left(\dfrac{ \overset{N}{\underset{i=1}{\sum}}\left( y_i-\hat y_i \right)^2 }{ \overset{N}{\underset{i=1}{\sum}}\left( y_i-\bar y_{\text{training}} \right)^2 }\right) $$ If you can get a handle on the degrees of freedom, however, something like adjusted $R^2$ makes perfect sense as a comparison of variances that are estimated with unbiased estimators. Being explicit: If you get a handle on the degrees of freedom, I say this makes perfect sense. (However, do not underestimate the difficulty of getting a handle on the degrees of freedom.) I would interpret such a statistic as a comparison of unbiased estimates of error variances.
