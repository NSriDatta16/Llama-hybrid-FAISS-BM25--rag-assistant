[site]: crossvalidated
[post_id]: 190876
[parent_id]: 60446
[tags]: 
I recommend you read Andrew Gelman's blog post Think identifiability Bayesian inference . Right off the bat, I can tell you that identifiability does not have to do with a model by itself (as in "an unidentifiable model"), rather than with the combination of this model with some data. That is to say, it has to do with the data also. The same model may be identifiable with some data, and unidentifiable with some other data. In a Bayesian context, it is not clear as to what exactly identifiability means. As the link I provided says, it is not a "black-or-white" case. Rather, it has to with the amount of information learned from the data, or the "distance" of the posterior from the prior. A perhaps suitable measure of information might be the Information Entropy , and while you are at it, the "distance" between two probability distributions (prior and posterior in this case) may be quantified by the Kullback-Leibler divergence , both of which can be found in the Wikipedia page on information theory . So you could say that, for a given model and data, if the posterior carries the same amount of information as the prior, then nothing was learned about the model from this data, and the case is unidentifiable . If on the other hand, the data are informative about the model parameters, then the posterior will be more informative than the prior (less information entropy than the prior, and KL divergence is positive) and the case is identifiable . Based on all the intermediate states, that is, how much information gain happened, we can talk about more or less identifiable cases when the information gain from the prior to the posterior is more or less respectively.
