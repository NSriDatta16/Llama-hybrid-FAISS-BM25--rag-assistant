[site]: crossvalidated
[post_id]: 462699
[parent_id]: 198839
[tags]: 
The motivation : Therefore in my view the only reason why OOBE is a pessimistic estimation of forest's error is only because it usually trains by a smaller number of samples than usually done with k-fold cross-validation (where 10 folds is common). does not seem correct. It is not true that OOBE error estimate being pessimistic is due to it being trained on a smaller number of samples, actually the contrary applies. In fact, each single random forest's tree is trained on a bootstrapped sample of the training set, so meanwhile it is true that on average every single tree sees about 66% of the training set, but overall the random forest ensemble sees more than that (depending on the number of trees fitted) because the out-of-bag samples of individual trees may not overlap . Hence, supposing we fit a random forest composed of $B$ trees to the entire training set composed of $n$ samples (as in the OOBE case) we have that: on average each sample $z_i$ appears in the training set of $\frac{2}{3}B$ and in the out-of-bag samples of the remaining $\frac{1}{3}B$ the probability that $z_j$ does not appear in neither the training set of $m$ selected trees is $p_m = (\frac{1}{3})^m$ From the two points above it follows that the OOBE on sample $z_i$ is on average computed considering a subset of $\frac{1}{3}B$ trees that collectively are trained on $n_{OOB}(B) = n-1-np_{\frac{B}{3}} = n(1-p_{\frac{B}{3}})-1$ data samples on average. When we estimate the error with k-fold cv instead we are doing the following (let's take $k=10$ ): we fit $B$ trees using $0.9n$ data samples, but again each tree use a bootstrapped version of the training set, so collectively the ensemble sees $n_{10-Fold}(B) = 0.9n(1-p_B)$ data samples on average. Then, considering that $p_{\frac{B}{3}} implies that $n_{OOB} > n_{10-fold}$ we conclude that the ensemble collective training set is larger in the OOB case whenever $B>6$ , which is almost always in practice. Conclusion Given what we found above, what can we say of the OOB vs k-fold CV estimate for random forests? Is the OOB pessimistic ? Since the OOBE is evaluated on ensembles that have collectively seen more data it should actually be a less pessimistically biased estimate of the test error with respect to k-fold CV. However, since OOBE ensembles are composed of less trees and are trained on overlapping training sets, the variance of the estimate can be larger. Actually, it can even be showed that for $\lim_{B\to\infty} $ the OOBE converges to the LOO-CV error estimate (leave one out cross validation)[1] which is unbiased but with higher variance with respect to k-fold CV with $k . So neither estimator is by default better than the other, even though OOBE has a clear computational advantage since you can "fit and test" your forest at the same time. [1] Hastie, T., Tibshirani, R., Friedman, J. (2001). The Elements of Statistical Learning.
