[site]: crossvalidated
[post_id]: 237426
[parent_id]: 
[tags]: 
Theoretical foundations of meta-analysis

I am hoping someone can give me some guidance (or references) relating to the mean and variance of the distribution of the mean of sample means. I am thinking about a large number of populations, each with $\mu_{i}$ and $\sigma^2_{i}$. I will refer to the mean of the $\mu_{i}$ as $\mu_{Meta}$ and the variance of the $\mu_{i}$ as $\sigma^2_{Meta}$. Let's say random samples of size $n_{j}$ are drawn from a randomly chosen $k$ of these populations; $j=1:k$. The means ($m_{j}$) of each of these $k$ samples are computed. Then these $k$ means are averaged as a weighted sum to produce $M$, the mean of sample means. This is the statistic of interest. If population variances are equal (i.e., $\sigma^2=\sigma^2_{1}=\sigma^2_{2},...,=\sigma^2_{N}$), and sample sizes are equal (i.e., $n=n_{1}=n_{2},...,=n_{k}$), then I assume that $M$ is an unbiased estimate of $\mu_{Meta}$, so $\mu_{M}$ = $\mu_{Meta}$. I also assume that the distribution of $M$ has variance $\sigma^2_{M}$ = ($\sigma^2_{Meta}$ + $\sigma^2$)/$n$. My question is about what happens when sample sizes ($n_{j}$) and population variances ($\sigma^2_{i}$) are unequal. If we assume that $n_{1}+n_{2},...,+n_{k} = K$, my intuition (from Matlab simulations) is that $\sigma^2_{M}$ = ($\sigma^2_{Meta}$ + $m_{\sigma^2} )/m_{n}$, where $m_{\sigma^2}$ is the mean of all $\sigma^2_{i}$ and $m_{n}$ is the mean sample size, i.e., $K/k$. Is this true? If so it would seem (for those on this site) to be pretty elementary and references should exist in standard texts. Thanks for thinking about this, Rick
