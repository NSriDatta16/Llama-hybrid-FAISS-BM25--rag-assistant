[site]: crossvalidated
[post_id]: 493423
[parent_id]: 493072
[tags]: 
With a binary response it is better to plan for using logistic regression. You can still use interactions with logistic regression. But you will need a quite large sample size! But first look at your candidate variables and how we can model them. age, income bracket and level of education have underlying continuous (or ordinal) variables, and maybe that could be used to reduce the complexity of the model. As a start assume we code those variables as integers, and assume quadratic models, and about equal number of observations for each level. So for an example, assume gender (which I take as binary ...), those three ordinal variables, each with 5 levels, and one more categorical variable, nominal, with 5 levels. Then one replication of a full factorial will need $2\cdot 5^3\cdot 5=1250$ runs. The number of variables (columns, that is) counting the number of dummys needed for the categorical variable is $p=\underbrace{1}_{\text{intercept}}+3\cdot \underbrace{2}_{\text{linear and square}}+\underbrace{1}_{\text{gender}}+\underbrace{4}_{5-1}=12$ . One rule of thumb for logistic regression is that the number of (candidate) predictors $p$ should be less than $m/10$ or $m/20$ , where $m$ is $n\cdot\min(p,1-p)$ (see for instance Understanding the 10:1 events per variable rule ), with $p=0.1$ (pessimistic ...) that is $m=n\cdot 0.1=n/10$ . Putting this together, using $m/20$ this gives $n\ge 200\cdot p=200\cdot 12=2400$ . That is about twice replicates of the full factorial, but might be pessimistic for a designed experiment. But it is not clear that this is the best design, but it could be a starting point. Optimal design ideas could be used, in R (on CRAN) there is a package OptimalDesign which maybe can be used, or you could use simulation to test different designs. There is also a package acebayes , covered in this arxiv paper .
