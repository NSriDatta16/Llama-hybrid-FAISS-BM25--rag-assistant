[site]: crossvalidated
[post_id]: 247061
[parent_id]: 
[tags]: 
Which one is better in a CNN, smaller input size or bigger input size followed by larger kernels and strides?

What do you suggest and why? AlexNet , VGG , GoogleNet , etc use 227/224 input images, and then use large kernels such as 11x11 or 7x7 and drastically decrease the input size, followed by pooling till the input is ~ 54x54 and then continue using that. Why not using 54x54 from the start? The point here is, It seems to me, the first layer at which down-sampling is carried out, has very little need for such large input. Feeding a 54x54 image, and then keeping the size intact for the next several layers, provides much more wealth of information compared to getting a large input, to only learn edges and then send a 54x54 image to the immediate next layer for further processings. to me this seems an un-necessary processing burden.
