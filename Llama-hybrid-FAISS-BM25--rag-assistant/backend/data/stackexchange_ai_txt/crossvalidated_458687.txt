[site]: crossvalidated
[post_id]: 458687
[parent_id]: 
[tags]: 
Is there problem with low epoch, high accuracy?

I am training a complex neural network model and it starts to overfit epoch 3-4 so I stopped training at that level. So I don't think that there is any wrong thing because my model is not overfitting (I check train/val scores and also use earlystopping ). My model works well in the test set so it is also nice thing for me. However, I wonder how should I interpret the low epoch size? Yes, it shows that my model is too complex for my problem and fastly overfitting but it also increases the accuracy. So if I stop training in the third epoch everything is fine (not overfit, increase the model accuracy ). My question is: Am I missing any part of this training process or do you think that there is any wrong thing in my train procedure?
