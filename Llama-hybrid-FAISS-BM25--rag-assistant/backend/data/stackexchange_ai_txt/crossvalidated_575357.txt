[site]: crossvalidated
[post_id]: 575357
[parent_id]: 575328
[tags]: 
My informal answer is that maximum likelihood estimation, the method behind logistic regression, finds the set of parameters that fit the data the best given some assumptions. If your dataset satisfies those assumptions very well and you have lots of data, then it is difficult to do better. This paper about logistic regression vs random forest (I just found the paper by Googling) reports that RF performed better than LR according to the considered accuracy measured in approximately 69% of the datasets. So it suggests that is not unusual for logistic regression to beat random forest. Also, Wikipedia reports that on the MNIST dataset, the linear classifier has error rate of 7.6% which is higher than other methods but I would say it is pretty good in absolute terms. My impression is that older techniques like logistic regression are a bit underrated relative to modern ones like random forest or SVM but in many cases they are still preferable. My 2p-
