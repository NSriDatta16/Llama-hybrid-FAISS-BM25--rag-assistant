[site]: crossvalidated
[post_id]: 290563
[parent_id]: 261271
[tags]: 
Your approach sounds very theoretical. Did you analyze the imputations of the packages you mentioned? Often imputation packages have requirements (e.g. MCAR data), but will still do a reasonable good job on data not fulfilling these conditions. Only a actual test and comparison of algorithms will show you which one is best suited for your data . The testing procedure can look like this: Find a interval with no (or very few) missing data Artificially add missing data in this interval. (these should resemble the NA patterns in the rest of the data) Apply different imputation methods to this dataset. (e.g. methods from imputeTS, mtsdi, AMELIA) Since you have the real values for your artificially deleted NA values, you can now compare how good alle the algorithms did on your data Additional info: The Amelia package also has some options to support the imputation of multivariate time series (see in the manual under 4.6) Also other packages like mice could be tried In general if you have multivariate time series, this means you have correlations between your different variables plus you have correlations of each variable in the time axis. ( here is a talk from useR! 2017 conference which among other things explains this) In theory it sounds like it would make most sense if you try to use both of the correlations. But if the correlations in time is for example very strong, univariate time series imputation methods from imputeTS might even work best. On the other hand, if the correlation between your variables is very strong, non time series imputation packages could work best. (like mice, VIM, missMDA and others)
