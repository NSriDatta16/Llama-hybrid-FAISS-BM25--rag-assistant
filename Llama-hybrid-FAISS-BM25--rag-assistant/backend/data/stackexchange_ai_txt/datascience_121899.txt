[site]: datascience
[post_id]: 121899
[parent_id]: 
[tags]: 
Are there any prebuilt models that I can apply to electronic health records

I've been given a task by work to extract relevant disease and medication information from patient history case notes. There are about 5000 case notes, and they are about a paragraph long; They contain information on diseases/medication, family member's diseases, hospital admissions/scans and health behaviours (smoking, drinking, etc.). While I'm have some knowledge of how NLP works, I'm a statistician, not a data scientist. I see from ChatGPT, automation of this task is possible, but I'm unsure if it's something someone in my position is able to do. I'm aware of clincal BERT but I'm not sure how applicable it is to my problem. As far as I know, clinical BERT is a pretrained model for word embeddings, and I feel like this get's me some of the way towards something useful. I have some queries though. Firstly, am I going down the right path in looking at something like clinical BERT How would a model that is pretrained on a corpus of text handle text that it has not formed embeddings for, e.g., spelling errors, abbreviations and synonyms If it can do the above, do I have to train it myself to define disease and medication with NER fine tuning Does fine tuning involve providing a list of all disease and medications I expect to see in my case notes? Or, once it is fine tuned on a few examples, will it be able to identify unlisted diseases/medaction? I realise these questions are pretty superficial; I just need to know if it's worth going down this route; or, if the models that have the capacity of doing what I need are beyond what I can realistically develop, and I may as well get a head start on extracting this information manually. Any guidance would be really appreciated. Thanks!
