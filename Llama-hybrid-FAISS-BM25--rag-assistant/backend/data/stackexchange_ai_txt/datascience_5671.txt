[site]: datascience
[post_id]: 5671
[parent_id]: 685
[tags]: 
A lot of the features you mentioned are categorical, and with so many levels of each, the dimensions of your problem will expand. Rather than initially focusing on Lasso and Ridge regression, why don't you first look for clusters among the samples (records) to learn about the data set? Under you current approach, you're throwing everything into a model and expecting a high AUC(?). You may find several clusters where frequencies of the category levels predominate in one or more potential clusters. If you don't know what the cluster structure is of the samples (records), try k-means clustering based on centroids of feature values to see if there are unique clusters. Once you get a handle on the cluster structure, then address regression issues. Your regression models may be breaking down, in part, because of large inhomogeneities in your data, along with the previously suggested issues. Machine learning is all about performing unsupervised class discovery followed by class prediction (your output binary variable). At this point, it's not clear that you studied the data to learn about its cluster structure, and rather threw it into a supervised model expecting to attain high AUC values.
