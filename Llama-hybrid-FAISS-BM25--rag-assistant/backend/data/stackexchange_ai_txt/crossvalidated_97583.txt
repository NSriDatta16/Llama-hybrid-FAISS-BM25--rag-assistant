[site]: crossvalidated
[post_id]: 97583
[parent_id]: 63767
[tags]: 
In general Monte Carlo (MC) refers to estimating an integral by using random sampling to avoid curse of dimensionality problem. Also, once you have the samples, it's possible to compute the expectations of any random variable with respect to the sampled distribution. A subclass of MC is MCMC you set up a Markov chain whose stationary distribution is the target distribution that you want to sample from. The main thing about many MCMC methods is that due to the fact that you've set up a Markov chain, the samples are positively correlated and thereby increases the variance of your integral/expectation estimates. The better situation is to make your samples independent (or have carefully constructed negative correlation) to reduce the variance. However, many distributions that you want to sample from are incredibly complicated objects and are difficult to sample from directly. Hence the construction and use of MCMC.
