[site]: crossvalidated
[post_id]: 348881
[parent_id]: 
[tags]: 
Why does unbiasedness not imply consistency

I'm reading deep learning by Ian Goodfellow et al. It introduces bias as $$Bias(\theta)=E(\hat\theta)-\theta$$ where $\hat\theta$ and $\theta$ are the estimated parameter and the underlying real parameter, respectively. Consistency, on the other hand, is defined by $$\lim_{m\to\infty}\hat\theta_m=\theta$$ meaning that for any $\epsilon > 0$ , $P(|\hat\theta_m-\theta|>\epsilon)\to0$ as $m\to\infty$ Then it says consistency implies unbiasedness but not vice versa: Consistency ensures that the bias induced by the estimator diminishes as the number of data examples grows. However, the reverse is not true—asymptotic unbiasedness does not imply consistency. For example, consider estimating the mean parameter μ of a normal distribution N (x; μ, σ2 ), with a dataset consisting of m samples: ${x^{(1)}, . . . , x^{(m)}}$ . We could use the first sample $x^{(1)}$ of the dataset as an unbiased estimator: $\hatθ = x^{(1)}$ . In that case, $E(\hat θ_m) = θ$ so the estimator is unbiased no matter how many data points are seen. This, of course, implies that the estimate is asymptotically unbiased. However, this is not a consistent estimator as it is not the case that $\hatθ_m → θ$ as $m → ∞$ I'm not sure whether I've understood the above paragraph and the concepts of unbiasedness and consistency correctly, I hope someone could help me check it. Thanks in advance. As far as I understand, consistency implies both unbiasedness and low variance and therefore, unbiasedness alone is not sufficient to imply consistency.
