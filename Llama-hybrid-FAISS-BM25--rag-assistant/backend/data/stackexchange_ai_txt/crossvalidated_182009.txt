[site]: crossvalidated
[post_id]: 182009
[parent_id]: 181588
[tags]: 
In worst case scenario, your features are completely unrelated to your target or related to your target in such a complicated way, that even RF cannot learn any reproducible pattern. A RF model will as default(no class weight, no stratification) assume same target distribution as of training set. If e.g. the most prevalent class make up 80% of the training set, the RF model can still use this information alone to roughly predict any new sample as member of this class, and achieve only a 20% class err.rate. In your case, if your training data is balanced such that each class is represented by 100%/6=16.7%, the expected worst performance is cross-validated 83.3% err.rate. "What am I doing wrong?" - probably nothing, just too poor variables to predict your target any better. Try some 'feature engineering' or get some new variables. Maybe you realize 50% err.rate for your problem is not that bad at all. If you could predict with 50% err.rate the winner of the next 50 Tennis grand-slam tournaments, you probably could earn a fortune on sport betting. "I was thinking that maybe the number of samples is too large with respect to the number of features" -That is never a problem. Feel free to discard a random fraction of your samples. It won't make your model better though. I can warmly recommend the tutorial competition at kaggle: Titanic , which can teach you how to assess your RF model performance.
