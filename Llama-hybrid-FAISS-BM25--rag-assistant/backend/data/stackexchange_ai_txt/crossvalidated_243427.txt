[site]: crossvalidated
[post_id]: 243427
[parent_id]: 243417
[tags]: 
First, OLS is nothing more than an algorithm for fitting a linear model of the form $$ y = \mathbf{X\beta} + \epsilon $$ In other words, you are positing that the phenomenon $y$ is a linear function of the variables $\mathbf{X}$, plus some additively separable disturbance term. If this is a good assumption, then there is some true, constant $\mathbf{\beta}$, and you apply some estimator -- such as OLS -- to estimate what it is. If your sample is non-random -- there is some correlation between your $\mathbf{X}$'s and your error term -- then OLS estimates of $\mathbf{\hat\beta}$ will not be equal in expectation to the true $\mathbf{\beta}$. This is to say that they are biased. In other words, if you were to take many many samples from the population of $\mathbf{X}$ and $y$, your average $\mathbf{\hat\beta}$ would not equal $\beta$.
