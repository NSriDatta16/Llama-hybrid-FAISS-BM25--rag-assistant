[site]: datascience
[post_id]: 124772
[parent_id]: 
[tags]: 
Accuracy Drop in ViT with Patch Embedding: Investigating the Impact of Added Convolutional Layers

I'm currently working on incorporating a patch embedding layer into my Vision Transformer (ViT). I've defined this layer using four 2D convolutional and initialized it with a normal distribution. The remaining layers of the model use pre-trained weights. However, during inference without training, I noticed a significant accuracy drop to 0%. Initially, the model achieved 45% accuracy with only one 2D convolutional layer (ViT uses one conv as patch embedding). Any insights on why this accuracy drop occurred would be appreciated.
