[site]: crossvalidated
[post_id]: 438102
[parent_id]: 
[tags]: 
How to create training data for CNN using remote sensing imagery

Before I start with the issue I would like to touch base with some background information. I had been working with Random Forest for classification of Remote Sensing data, here the classification was based on the pixel value of the remotely sensed imagery. So creating training CSV dataset was not difficult where my attributes in the CSV files were [ClassCode, B1, B2, B3, B4] Where the ClassCode was the number assigned to the class and B1, B2, B3, B4 were the pxiel values extracted from remote sensing data Now I am moving forward with implementing deep learning using CNN on remote sensing data. I have ground-truth sample defining my classes for classification. I have been reading on some sample code available online where training samples are created not based on single-pixel value but the entire image. In major samples for example, https://towardsdatascience.com/a-simple-cnn-multi-image-classifier-31c463324fa The training data is created using an entire image, in the example above its types of animals and the result generated is just a label stating if the imagery passed is animal type "chicken" where I was expecting the result would be imagery classifying all the pixel where chicken is seen in imagery. My objective is to generate classified imagery from satellite data: I have training data from ground-truth as polygons on the imagery above stating the classes, for example, vegetation, road, buildings, etc. And the output should be as following: Now running the trained model on imagery is really simple the only challenge that I am facing as of now is how do I create training data to train the CNN model using the satellite imagery and training polygons. Any help would be really appreciated!
