[site]: crossvalidated
[post_id]: 212360
[parent_id]: 212352
[tags]: 
If the choice of which people are in the 50 was not made with reference to the observed data in any way then you could do something -- but I don't think a Fisher exact test would work One might consider a permutation test -- you could even use your statistic (average number of times my target pairs talk, across all events, divided by the average number of times a pair from the total population talks across all events)* as the test statistic * note that the numerator and denominator aren't independent. Ordinarily I might suggest trying a slightly different statistic but with a permutation test you might as well go ahead with the one you had in mind -- the dependence won't cause any issue for the permutation test. With 2000 people (and so 1999000 pairs) it might be better to look at a randomization test (sampling the permutation distribution) rather than a full permutation test. Since under the null hypothesis of no difference, the choice of who is in the group of 50 is arbitrary, you proceed by randomly choosing 50 people to be in the group, compute the statistic and repeat a large number of times (say something like 10000, or 100000 or more if you can manage it) and then see what proportion of those randomly generated values (plus the original observed statistic) are at least as large as the original observed statistic. This proportion is an estimate of the p-value (if you repeated the exercise the p-value would be slightly different each time, though the variation decreases if the number of resamples increases.) Note that the denominator of your statistic is unchanged each time, so you could as easily leave it out without altering the relative ordering of the simulations. This could then be reduced further to choosing random sets of 50 and simply counting the conversations within those pairs.
