[site]: crossvalidated
[post_id]: 545452
[parent_id]: 545366
[tags]: 
A frequent confusion in this type of modeling is that much of what you read about "machine learning" works very well when there are tens of thousands or cases and hundreds to thousands of predictors or more, but can get you into trouble with data sets of this size. First , this is far too small a data set to set aside separate subsets for predictor selection and model development. At this scale, build the model with the whole data set and validate as best as you can internally by repeated modeling on bootstrap samples from the data. Section 6.2 of Statistical Learning with Sparsity (SLS) shows how to do this with LASSO modeling. Second , you have to have a clear view of why you want to do predictor selection. (a) If your interest is in predicting new cases and all of your 39 predictors will be available for new cases, ridge regression allows you to use all the available information in a principled way (with penalization that should also remove your complete separation problem). This is different, say, from gene-expression studies where you have 20,000 potential predictors and have to reduce the predictor numbers to a substantially smaller set of a few dozen to allow reasonably affordable clinical tests. It's also possible to use your knowledge of the subject matter to combine related predictors in a way that doesn't depend on knowing their relationships to outcome. If some predictors are unlikely to be available in the future and you are trying to do prediction, why include them in the model at all? See Chapter 4 of Frank Harrell's course notes or book for valuable guidance on many such aspects of regression and predictor selection, guidance that can be applied before you jump into LASSO. (b) If you are doing predictor selection to identify the "most important" predictors, you are likely to be disappointed in the results. With about the same number of predictors as you have members of the minority outcome class, your predictors are likely to be highly inter-correlated. LASSO might select one such predictor from a correlated set on these data, a completely different predictor from that correlated set on a new data sample. You can see that in modeling on bootstrap samples, as shown in Section 6.2 of SLS, cited above. Third , you have to be very careful that the approaches you are using are suitable for your application. The warning from adaptive LASSO that "adaptive weights for the LASSO method are not uniquely determined because the full least squares model is singular" suggests that the software was trying to do a least-squares fit on your binary outcomes. That's not a good approach. I have no experience with adaptive LASSO and don't know how well it works (if at all) with binary outcomes. If you are wedded to adaptive LASSO and it can be applied to binary outcomes, you should set the initial weights based on single-predictor logistic regressions instead, generalizing the recommendation on page 86 of SLS for the linear regression case. My understanding is that adaptive LASSO is designed to give even more sparsity in retained predictor numbers than regular LASSO, which doesn't seem wise in this case. With 42 members of the minority outcome class, a standard logistic regression LASSO with penalty optimized via cross-validated deviance should return about 3 or 4 predictors--if predictor selection is really what you need.
