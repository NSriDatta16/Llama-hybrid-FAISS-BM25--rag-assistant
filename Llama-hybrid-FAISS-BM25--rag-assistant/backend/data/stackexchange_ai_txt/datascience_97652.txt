[site]: datascience
[post_id]: 97652
[parent_id]: 97617
[tags]: 
you can start by using torchscript, it may require changing ur whole code, and switching to transformers( by loading the backbone of the model and the last layers) so basically u get out from GIL interpreter, coz it does not support multithreading. by with torchscript u can run ur model in c++ env, there's also onnx which I believe it enhances performance. if ur use case is not a real-time and you are using an API, you can use a queue mechanism like rabbitmq
