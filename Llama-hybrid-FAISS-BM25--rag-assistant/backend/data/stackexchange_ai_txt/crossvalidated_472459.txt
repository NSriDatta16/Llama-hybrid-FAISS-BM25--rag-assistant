[site]: crossvalidated
[post_id]: 472459
[parent_id]: 
[tags]: 
Sigmoid function calculation range

I know that for big datasets we should try to consider calculations effort and try to minimize execution speed if it does not harm quality. In many models, like regression, neural network, probably somewhere else, sigmoid function is used as a cost function. Input values in range (- infinity, -4] give output 0.01 or less. Input values in range [4, infinity) give output 0.99 or more. Could we just map such values to 0.01 or 0.99 directly to improve calculation speed? Does it make sense to improve performance against some inaccuracy in cost function?
