[site]: crossvalidated
[post_id]: 385900
[parent_id]: 385863
[tags]: 
Yes, it is possible to assign topics to sentences, or, more generally, to give each sentence a probability of belonging to each topic. Many LDA inference methods provide a probability of each word belonging to each topic, which you can simply aggregate by averaging to determine the probability of each sentence belonging to each topic. If you want to assign a single topic to each sentence, you can simply choose the topic with the highest probability; how you break ties is up to you. I am not an expert in gensim, but that project appears to use variational inference for LDA. In this case, you will want the variational parameter giving a probability distribution on words belonging to topics, but I don't see by glancing through the docs/source how to attain this. Here's the heuristic I would use: just look at the matrix relating terms to topics, and for each sentence, add up the topic contributions of each term. This ignores information about other sentences in the document, but it should be a reasonable approximation. Consult the method "get_term_topics" belonging to the LDA object to obtain this. Is LDA on sentences equivalent to LDA on documents? The answer here is no. In deciding what topic each word of the corpus comes from, LDA inference algos borrow information from what other words are in the corpus through a parameter (denoted by $\theta$ in the original LDA paper ) which gives the topic prevalence for each document. Therefore, doing LDA with each sentence being considered its own document will give a different result, since sentences won't "borrow strength" from one another. I would conjecture that you will get a somewhat similar result, but it won't be the same. Further, standard LDA inference algos have difficulty with short documents (such as tweets, which are sometimes aggregated so as to have longer docs, see e.g. this article ), so you may see some degradation in the quality of the results.
