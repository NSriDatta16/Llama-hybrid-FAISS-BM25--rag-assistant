[site]: crossvalidated
[post_id]: 378128
[parent_id]: 223256
[tags]: 
Deep learning frameworks often mix models and losses and refer to the cross-entropy of a multinomial model with softmax nonlinearity by cross_entropy , which is misleading. In general, you can define cross-entropy for arbitrary models . For a Gaussian model with varying mean but fixed diagonal covariance, it is equivalent to MSE. For a general covariance, cross-entropy would correspond to a squared Mahalanobis distance . For an exponential distribution, the cross-entropy loss would look like $$f_\theta(x) y - \log f_\theta(x),$$ where $y$ is continuous but non-negative. So yes , cross-entropy can be used for regression.
