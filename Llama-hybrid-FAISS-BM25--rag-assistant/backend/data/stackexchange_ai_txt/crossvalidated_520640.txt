[site]: crossvalidated
[post_id]: 520640
[parent_id]: 
[tags]: 
Fine-tuning VGG-Face for Facial Expression Recognition on FER2013 - Grayscale vs RGB Images

I am experimenting with Facial Expression Recognition and want to use a pretrained CNN model and a multi-stage fine tuning strategy to deal with scarce data. I came across the work of Knyazev et al. (2017) . The authors fine tune a VGG-Face Face Recognition model on the FER2013 Facial Expression Recognition dataset. Unfortunately, they don't explain how they fine-tune a model trained on RGB images on a grayscale image dataset. Is it possible (and practical) to fine tune a CNN originally trained on RGB images on a target dataset consisting of grayscale images? What is the general approach?
