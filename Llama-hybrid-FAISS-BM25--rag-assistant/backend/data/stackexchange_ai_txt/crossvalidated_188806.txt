[site]: crossvalidated
[post_id]: 188806
[parent_id]: 
[tags]: 
Sampling Effects on Time Series Models

I am working extensively with financial time series models, mostly AR(I)MA, and Kalman. One issue I keep facing is the sampling frequency. Initially I was thinking if offered the possibility to sample more frequently from an underlying process I should be sampling as frequently as possible so that I will have a much bigger number of samples, hence my model parameters will have less variation. In reality this idea didn't turn out to be good. What happened is that if the underlying process is not exhibiting enough variation, increasing the sampling frequency actually meant getting a lot of repeating (same) values. And building a model on such values results in models with very very small model coefficients which don't predict well into the future (of course the definition of "well" is subjective and increased frequency requires to predict much more sample steps into the future to achieve the same time-step in a lower frequency setting). The model learns what it encounters the most - a flat line. I wanted to do an adaptive sampling approach, i.e. sample more frequently when there is variation, and less frequently when there is not. This is not easy, however. First of all it is not clear what kind of bias I am introducing by doing so (and will differ depending on how I trigger the sample/skip). Secondly, time series models like ARIMA are not well suited for uneven sample steps. Is there a good way to deal with this problem? It also makes me wonder how one achieves a seamless transition between continuous time models and discrete time models if models are so dramatically affected by sampling frequency (especially when time steps get smaller and smaller)? Any pointers to external resources will also be appreciated. Thanks
