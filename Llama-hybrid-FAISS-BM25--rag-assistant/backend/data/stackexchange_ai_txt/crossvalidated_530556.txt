[site]: crossvalidated
[post_id]: 530556
[parent_id]: 522116
[tags]: 
I think I acquired some insights into this question after posting it 1.5 months ago, and since there are no other answers, I'll share them: Plain RNNs are, in practice, incapable of learning long-term dependencies, and while LSTMs can do it, they are still focused on recent inputs. This suits LMs just fine, because LMs are evaluated via PPL and similar scores, under which the recent past is extremely informative. Why are some people using Transformers for LMs then, despite this? Two reasons: Memory consumption and efficiency (Transformers are still efficient with small batch sizes, while large batch sizes use a lot of memory in both LSTMs and Transformers) Human perception of the quality of generated text is different from PPL. Researchers are actually trying to get their models to pay more attention to the less recent past, which is where Transformers are better. So why did Transformers beat LSTMs on the translation tasks then? Two more reasons: The BLEU score, used to evaluate translations, is different from PPL Translation needs non-local attention more than plain LMs do (Texts get re-ordered significantly, when translated)
