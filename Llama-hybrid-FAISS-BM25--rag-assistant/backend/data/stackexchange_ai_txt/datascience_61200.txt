[site]: datascience
[post_id]: 61200
[parent_id]: 61194
[tags]: 
Without seeing the rest of your code, this is a bit tricky to answer, but you have to make sure that reward = -temp_penalty , i.e. the negtive penalty, otherwise you would learn exactly the behaviour you described. Here I'm assuming you excluded all other potential sources of error. Further, I think it might be helpful to issue a reward if the agent stays within the limits you defined, i.e. in the else -clause set temp_penalty = -1. or something like that. I personally found this type of tweaking to be very helpful for DQN.
