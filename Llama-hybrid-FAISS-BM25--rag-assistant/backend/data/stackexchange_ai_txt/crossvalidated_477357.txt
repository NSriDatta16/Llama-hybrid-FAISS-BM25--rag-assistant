[site]: crossvalidated
[post_id]: 477357
[parent_id]: 477226
[tags]: 
Trimming (winsorizing) propensity scores has been extensively written about. It is one solution to addressing extreme weights due to small treatment propensities. There are a number of other solutions, which I'll briefly describe below. Changing the estimand to the average treatment effect in the treated (ATT) . ATT weights ( $w = A + (1-A)\frac{e}{1-e} = e \times w_{ATE}$ , where $e$ is the propensity score and $w_{ATE} = \frac{A}{e} + \frac{1-A}{1-e}$ ) tend to have fewer problems with instability. The target population corresponds to a different group than the ATE, but it's a specific group. Changing the estimand to the average treatment effect in the overlap (ATO) or average treatment effect in a caliper-matched sample (ATM) . ATO weights ( $w = A(1-e) + (1-A)e = e(1-e)w_{ATE}$ ) have a nice property that they yield an effect estimate with the smallest standard error of any weighted estimate, so the problems of instability are mitigated (Li et al., 2018). Weights are bounded at 0 and 1 so they are never too larger or too small. ATM weights ( $w = \text{min}\{e, 1-e\}w_{ATE}$ ) are also fairly stable and generalize to the same target population as a caliper-matched sample (Li & Green, 2013). Both of these estimands are not well-defined prior to estimating the weights, but they both yield stable weights. Estimating ATE weights using a method that prevents extreme weights . Entropy balancing (EB; Hainmueller, 2012) and stable balancing weights (SBW; Zubizarreta, 2015) both involve directly estimating weights without an explicit propensity score model by specifying an optimization problem that minimizes the variability of the weights subject to balance constraints. For EB, the variability is the negative entropy ( $\sum w \text{log}w$ ). For SBW, the variability is the variance of the weights ( $\sum (w - \bar w)^2$ ). Both methods are easy to use and available in the R package WeightIt (of which I am the author). Because both methods restrict the variability of the weights, extreme weights are unlikely and estimates tend to have lower standard errors than standard PS weights. These methods can be used to estimate the ATE or ATT. Trimming (winsorizing) the weights . This involves choosing a threshold and setting all weights above that threshold to the threshold (this can also be done at the level of the propensity scores). This method is ad-hoc in the sense that there is no theory to guide and researchers must rely on heuristics. When trimming ATE weights, the target population can change when using this method, and if you're going to change the target population, you might as well use ATO weights. Trimming is available in WeightIt using the trim() function. Optimally truncating the weighted sample . This involves choosing a threshold and removing all units from the sample whose weights (or propensity scores) fall outside the threshold. This method was described by Crump et al. (2009), who describe an algorithm for choosing the threshold that yields an effect estimate with the lowest standard error (assuming equal variances in the treatment groups). Doing so changes the estimand to the treatment effect in the remaining sample, which is not a well-defined group prior to estimating the weights. This method is available in WeightIt by setting estimand = "ATOS" (i.e., "optimal subset"). Given these options, how should you choose how to proceed? First, decide how important your target population is to you. If your sample represents a meaningful population that you want to generalize to, you should stick with ATE weights and use EB or SBW. If your sample doesn't represent a meaningful population and you just want to see if a causal effect exists for some population, you should use ATO or ATM weights. Use ATM weights if you want your results to be comparable to those from studies that used caliper matching, and use ATO weights if you want your estimate to generalize to units with an equal chance of receiving treatment or control (also known as the clinical equipoise). Trimming and truncating can be used as well, but there is little reason to given these recent, easy-to-use methods for accomplishing the same goal. See Desai & Franklin (2019) for an accessible primer on how to make these decisions. Some studies that compared these methods include Zhou, Matsuka, & Thomas (2020) compare ATE, ATM, ATO, and ATOS weights (note that the "entropy" weights they examine are not EB weights and they say "trim" when they mean "truncate") Li & Thomas (2018) compare ATE, ATO, and several forms of trimmed weights Wang & Zubizarreta (2020) compare EB and SBW, focusing on cases of good and bad overlap Crump, R. K., Hotz, V. J., Imbens, G. W., & Mitnik, O. A. (2009). Dealing with limited overlap in estimation of average treatment effects. Biometrika, 96(1), 187–199. https://doi.org/10.1093/biomet/asn055 Desai, R. J., & Franklin, J. M. (2019). Alternative approaches for confounding adjustment in observational studies using weighting based on the propensity score: A primer for practitioners. BMJ, 367, l5657. https://doi.org/10.1136/bmj.l5657 Hainmueller, J. (2012). Entropy balancing for causal effects: A multivariate reweighting method to produce balanced samples in observational studies. Political Analysis, 20(1), 25–46. https://doi.org/10.1093/pan/mpr025 Li, L., & Greene, T. (2013). A weighting analogue to pair matching in propensity score analysis. The International Journal of Biostatistics, 9(2). https://doi.org/10.1515/ijb-2012-0030 Li, F., Morgan, K. L., & Zaslavsky, A. M. (2018). Balancing covariates via propensity score weighting. Journal of the American Statistical Association, 113(521), 390–400. https://doi.org/10.1080/01621459.2016.1260466 Li, F., & Thomas, L. E. (2018). Addressing Extreme Propensity Scores via the Overlap Weights. American Journal of Epidemiology. https://doi.org/10.1093/aje/kwy201 Wang, Y., & Zubizarreta, J. R. (2020). Minimal dispersion approximately balancing weights: Asymptotic properties and practical considerations. Biometrika, 107(1), 93–105. https://doi.org/10.1093/biomet/asz050 Zhou, Y., Matsouaka, R. A., & Thomas, L. (2020). Propensity score weighting under limited overlap and model misspecification. ArXiv:2006.04038 [Stat]. http://arxiv.org/abs/2006.04038 Zubizarreta, J. R. (2015). Stable weights that balance covariates for estimation with incomplete outcome data. Journal of the American Statistical Association, 110(511), 910–922. https://doi.org/10.1080/01621459.2015.1023805
