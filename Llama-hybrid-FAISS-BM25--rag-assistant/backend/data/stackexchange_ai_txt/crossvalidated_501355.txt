[site]: crossvalidated
[post_id]: 501355
[parent_id]: 501279
[tags]: 
Term Frequency is not based on a corpus (except in setting the vocabulary, which is based on the training set ): it is just the count of terms within a single document. But you are correct about the Inverse Document Frequency part: sklearn uses the statistics from the training set when transforming new data. You can test that pretty quickly by transforming a test dataset's first row separately from the entire test dataset: you ought to get the same transformed value for the first row, independent of what other rows are in the test set. You may also like to read through the toy example in the User Guide , or have a look at the source code for TfidfVectorizer.transform (note that super here is a CountVectorizer and self._tfidf is a TfidfTransformer ) and TfidfTransformer.transform .
