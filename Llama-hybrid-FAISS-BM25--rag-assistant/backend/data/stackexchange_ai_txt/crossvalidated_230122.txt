[site]: crossvalidated
[post_id]: 230122
[parent_id]: 
[tags]: 
How to explain conditional independence between two nodes in a Bayesian network for some values of another node but not all?

Imagine three back to back directed nodes. A -> B -> C Knowing B, A and C are ought to become independant. Imagine B to be binary A & C have positive correlation. After I correct for B, for B=0, A & C become independent while for B=1 they become negatively correlated. The network is learned by bnlearn in R, I;m showing a branch which is Markov Blanketed from the rest I'm confused about the remaining correlation. Is it a sign that the network is not trained well or what? Best
