[site]: datascience
[post_id]: 61427
[parent_id]: 
[tags]: 
K-fold-cross-validation if training dataset is much smaller than test dataset?

I'm a beginner in machine learning and I have a special case in which I have only a small training dataset of about 500 images and a test dataset of 10,000 images. Does it still make sense to do a 10-fold-cross-validation or Repeated-Cross-validation on the training data? Or would this be not necessary anymore due to the large test dataset? Many thanks in advance
