[site]: crossvalidated
[post_id]: 575988
[parent_id]: 
[tags]: 
How to find the optimal coefficients of the two predict_proba output matrices of two different classifiers using regression and maximizing accuracy?

I am performing classification, where there are six labels and two predict_proba (predicted probabilities) matrices as outputs. These two predict_proba matrices correspond to the outputs of two different sklearn classifiers, which are XGB (A) and SVM (B). That is, if there are 1,000 samples and 6 classes, the matrix A can be of the size 1,000 * 6 , which is also the case for B. I am multiplying these two predict_proba matrices by two coefficients, which are x and y . That is, the multiplication process is A * x + B * y . Here, I am trying to find the optimum coefficients x and y (which can be scalar or vector) that lead to the best accuracy results. How can I find these optimal coefficients using meta-regression? As I said, by multiplying predict_proba matrices by x and y , and summing the output matrices (i.e. A * x + B * y ), I am trying to maximize the overall accuracy. If possible, could you please share the code on how to implement it showing the libraries and frameworks required as well? In this case, shall I also resort to the use of thresholding as well by tweaking it (as in https://scikit-lego.readthedocs.io/en/latest/meta.html#Meta-Models )? That is, I am trying to leverage a meta-model here.
