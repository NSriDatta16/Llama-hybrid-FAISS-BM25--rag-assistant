[site]: crossvalidated
[post_id]: 512257
[parent_id]: 488844
[tags]: 
It would be a good idea to employ adaptive batching, that is you pad a batch(append zeros) by the longest case in that and in the reference mode the batch size is just one and the length is the length of that case. You don't need bucketing but enjoy the speeding up. You can do that by first padding all cases in the data pipeline by the max length and second truncating any batch according to the longest actual length in the graph. Since the time complexity is quadratic to the length of the input the reference would also be fast for those short inputs since the length is variable. For more information please refer to this tutorial: Smart Batching Tutorial - Speed Up BERT Training .
