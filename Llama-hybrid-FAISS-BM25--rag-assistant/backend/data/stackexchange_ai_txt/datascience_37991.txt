[site]: datascience
[post_id]: 37991
[parent_id]: 37990
[tags]: 
Well, let's say in this way. Although there are numerous learning approaches, each is useful for a particular situation. It is possible that for a problem you have multiple choices. Each of learning approaches has a special application domain and that is why people usually know where to use decision trees and where to choose neural networks, e.g. in situations that all of your inputs are real-valued numbers, attempting to use decision trees is not a wise choice. I try to explain the main things that an ML practitioner usually considers. Number of Available Features The number of features is important due to not being able to visualise them easily in cases there are so many features. This may lead to not being able to recognize whether the data is linearly separable or not. So many features do not imply that the dataset is not linearly separable. Consequently, say you want to use neural nets for modelling the problem. You shouldn't begin with a complicated network with so many layers and neurons. You have to begin with a single neuron, equivalent to logistic regression for classification tasks, to figure out whether your data is linearly separable or not. If you observe that you don't have good performance, you can add extra neurons and layers. How? Take a look at How to set the number of neurons and layers in neural networks . Feature Space About choosing ML approaches, it is simple to consider the limitations of each algorithm with respect to the feature space. E.g. decision trees are not very good for problems with many features which some of them are numerical features. They may get really big. SVMs are not very good for non-linear problems with so many features due to the fact that you have to specify the kernel size. For different regions in the feature space, a single kernel size may not be valuable. To generalize, problems that have very large input space are usually handled using neural networks. If the problem has so many features but they are e.g. binary features or categorical features with a small number of choices, then the problem has smaller feature space, input space, and other ML approaches can be considered. Size of Dataset Depending on your problem, feature types and feature ranges, the input space may be very small or very big. Consequently, the number of possible data may differ depending upon the input space. For large input space, as mentioned, neural nets are very powerful for mappings. Distributions and Bayes Error For different tasks, e.g. classification, you have to do statistical analysis for knowing your available dataset better. You have to investigate if there are input patterns that there are same but their labels differ. If so, why? Is that for expert error or not. The current feature space is not valid for understanding the problem. After addressing these questions you can employ Bayes error to investigate the best approach will have what accuracy on your data.
