[site]: datascience
[post_id]: 78542
[parent_id]: 
[tags]: 
How do we decide between XGBoost, RandomForest and Decision tree?

What do we take into consideration while deciding which technique should be used when dealing with a particular dataset? I understand that there isn't any hard and fast rule to this. Do we use XGBoost only when there are a lot of features in the dataset and RandomForest for otherwise cases? Or are we suppose to hit and trial and find whichever gets us better results everytime?
