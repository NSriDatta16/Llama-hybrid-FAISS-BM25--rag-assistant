[site]: crossvalidated
[post_id]: 353936
[parent_id]: 353935
[tags]: 
The problem is generally to find a hypothesis for which the generalization bound is small. For example, if you want to find the best SVM to classify your data, your hypothesis class is given exactly by a set of weights $w$ and biases $b$. The fact that you try to maximize the margin is reflected only in the fact that this will give you a good generalization bound later on. But this works only because SVMs are a relatively simple class. However, if you take a very complex class, all NNs of all sizes with appropriate nonlinearities, say, you have a problem. Now your hypothesis class is so large that you can fit arbitrary training data without actually learning anything useful from the data.
