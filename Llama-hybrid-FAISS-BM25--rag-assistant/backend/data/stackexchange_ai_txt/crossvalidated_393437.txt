[site]: crossvalidated
[post_id]: 393437
[parent_id]: 386558
[tags]: 
I believe it was not implemented in scikit-learn because in contrast with Random Forest algorithm, Isolation Forest feature to split at each node is selected at random. So it is not possible to have a notion of feature importance similar to RF. Having said that, If you are very confident about the results of Isolation Forest classifier and you have a capacity to train another model then you could use the output of Isolation Forest i.e -1/1 values as target-class to train a Random Forest classifier. This will give you feature importance for detecting anomaly. Please note that I haven't tried this myself, so I can't comment on accuracy of this proposed approach.
