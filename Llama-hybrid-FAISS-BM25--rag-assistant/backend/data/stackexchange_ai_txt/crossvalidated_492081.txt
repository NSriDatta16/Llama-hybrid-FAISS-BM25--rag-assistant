[site]: crossvalidated
[post_id]: 492081
[parent_id]: 292291
[tags]: 
What is regularization, really? Perhaps you are conflating L1/L2 regularization (aka. Lasso/ridge regression, Tikhonov regularization...), the most ubiquitous type, as the only type of regularization Regularization is actually anything that prevents overfitting , that you can do to a learning algorithm [ Wikipedia ]. Dropout, batch normalization, early stopping, model ensembling, feature selection, and many of the techniques others have pointed out here... are all just different regularization techniques! Bias-variance tradeoff Perhaps thinking about this issue in terms of the bias-variance tradeoff , a fundamental machine learning concept, could greatly clarify your thoughts. If our goal is prediction accuracy, we want to reduce the expected error of a supervised learner $\hat{f}$ , which can be decomposed into bias, variance, and irreducible error: $$ {\displaystyle \operatorname {E} _{D}{\Big [}{\big (}y-{\hat {f}}(x;D){\big )}^{2}{\Big ]}={\Big (}\operatorname {Bias} _{D}{\big [}{\hat {f}}(x;D){\big ]}{\Big )}^{2}+\operatorname {Var} _{D}{\big [}{\hat {f}}(x;D){\big ]}+\sigma ^{2}} $$ Regularization penalizes complex models, to try to reduce the variance of the estimator (more than the bias is increased), to ultimately reduce the expected error. Philosophically, this is akin to Occam's razor, where we introduce an inductive bias for simplicity on the assumption that "simpler is better". We usually want to regularize From a Bayesian viewpoint, we can also show that including L1/L2 regularization means placing a prior and obtaining a MAP estimate, instead of an MLE estimate ( see here ). Overfitting is simply when your model is unable to generalize well to your actual data of interest ("test" or "production" dataset), usually because it has fit to your training data too well . We always want to prevent this with some form of regularization.
