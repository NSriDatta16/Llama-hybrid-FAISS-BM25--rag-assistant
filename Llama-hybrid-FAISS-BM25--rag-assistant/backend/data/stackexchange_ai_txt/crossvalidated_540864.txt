[site]: crossvalidated
[post_id]: 540864
[parent_id]: 540858
[tags]: 
Yes, out-of-bag error is an estimate of the error rate (which is 1 - accuracy) that this training approach has for new data from the same distribution. This estimate is based on the predictions that you get for each data point by using only averaging those trees, for which the record was not in the training data. If you have a low number of trees the OOB error might be not a good estimate of the error rate that training an algorithm like this has on new data, because each tree in RF tends to be underfit and only once you combine enough trees the RF gets better (so if there's only a small number of trees per record, it may underestimate performance). On the other hand, once you have a huge number of trees it becomes a pretty good estimate like you get from a train-validation split with a lot of data (or cross-validation). What makes it difficult to interpret in your particular case is that the OOB error is estimated on the training data distribution. When you do SMOTE, you change the training data distribution vs. the true distribution, which affects accuracy (which is of course a performance measure that is affected by class prevalence). So, I would not compare OOB error between the two scenarios you have for that reason.
