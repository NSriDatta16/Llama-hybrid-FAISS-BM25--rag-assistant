[site]: crossvalidated
[post_id]: 617262
[parent_id]: 617202
[tags]: 
First, the CLT doesn't guarantee that the mean of samples will be normally distributed. But more importantly, what you seem to be getting at is that the CLT is sufficient for the expected value of your estimator to be equal to the population parameter of the mean. This is known as being "unbiased". Taking the population mean (assuming it's known) does result in an unbiased estimator, but in a trivial and not very useful way. Just having an estimator that's unbiased is an exceedingly unimpressive accomplishment. The mean is the absolute floor of machine learning performance. It's a benchmark that every other method had been improve upon, otherwise the method is pointless. For instance, suppose you're trying to predict what a student's college grades will be based on their high school grades and SAT score. The simplest machine learning model would be to simply take the mean of all the students at the college, and give that as output. That would an unbiased estimate, but in a pointless way. The goal of machine learning is to see how much better you can do than just taking the mean of all the X overall. It's about getting as educated of a guess about each individual in a sample, not predicting what the average over the whole sample will be. It's about identifying features of particular Xs that are informative as possible, and getting the mean of the Xs that have those particular features, rather than of all the Xs. For instance, if you have a student with a high school GPA of 3.4 and an SAT of 1400, you want to know what the mean college GPA of all students with high school GPA of 3.4 and an SAT of 1400 is, not what the mean college GPA over all students is.
