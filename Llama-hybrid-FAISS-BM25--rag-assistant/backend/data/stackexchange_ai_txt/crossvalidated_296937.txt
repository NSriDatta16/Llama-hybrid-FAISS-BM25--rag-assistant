[site]: crossvalidated
[post_id]: 296937
[parent_id]: 296774
[tags]: 
I think that things get mixed up when you make the assumption of Gaussian residuals. Please note that I'm not much of a Bayesian, so I can't speak to the necessity of Gaussian residuals for the LASSO estimate to be the maximum a posteriori (MAP) estimate of the linear regression with a Laplace prior on model weights $\theta$, as you note in the question. But Gaussian residuals are certainly not required for ordinary least squares (OLS) to provide the best linear unbiased estimates (BLUE) of the $\theta_i$ in your equation (1). Under the Gauss-Markov theorem all you need to assume about residuals for OLS to provide BLUE are that residuals have zero mean, are homoscedastic, and are uncorrelated. So even standard frequentist OLS doesn't need to assume Gaussian residuals; such residuals just help in some frequentist statistical tests. LASSO as expressed in your equation (2) similarly need not make any assumptions about the residuals to provide potentially useful penalized estimates of the $\theta_i$. In practice a range of values for $\lambda$ is evaluated with cross-validation or other resampling to provide a final model (including the choice of $\lambda$) that provides a particular bias/variance tradeoff. But equation (2) can certainly be solved over a range of $\lambda$ values without any assumption about the distribution of the residuals. The distribution of the residuals might, however, affect how useful those estimates are. For working out the distribution $p(y \vert \mathbf{x},\theta_{\text{LASSO}})$ you certainly are welcome to assume Gaussian residuals, but neither ordinary nor penalized regressions require such a strict assumption.
