[site]: crossvalidated
[post_id]: 151208
[parent_id]: 
[tags]: 
Problems due to analyzing variables from different levels at one single level

Please ease the following paragraph from the first chapter , Introduction to Multilevel Analysis , p.3 of the book : Historically , multilevel problems have led to analysis approaches that moved all variables by aggregation or disaggregation to one single level of interest followed by an ordinary multiple regression , analysis of variance , or some other 'standard' analysis method . However , analyzing variables from different levels at one single common level is inadequate , and leads to two distinct types of problems . The first problem is statistical . If data are aggregated , the result is that different data values from many sub-units are combined into fewer values for fewer higher-level units . As a result , much information is lost, and the statistical analysis loses power . On the other hand , if data are disaggregated , the result is that a few data values from a small number of super-units are 'blown up' into many more values for a much larger number of sub-units . Ordinary statistical tests treat all these disaggregated data values as independent information from the much larger sample of sub-units . The proper sample size for these variables is of course the number of higher level units . Using the larger number of disaggregated cases for the sample size leads to significance tests that reject the null-hypothsis far more often than the nominal alpha level suggests . In other words : investigators come up with many 'significant' results that are totally spurious . EDIT : My question is , (1) In aggregation , how is information lost ? And how do we loose statistical power ? (2) In disaggregation , how does the issue of sample size occur ? Do they mean if we use the sample size of lower level when we do actually need to use the sample size of higher level , then the sample size becomes large which increases the chance of rejecting the true null hypothesis ?
