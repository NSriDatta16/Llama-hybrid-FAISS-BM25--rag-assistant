[site]: crossvalidated
[post_id]: 619439
[parent_id]: 231981
[tags]: 
In this answer , cross-entropy is exposed as a possibility, since it does not assume the underlying distributions are discrete. Another possibility is the Beta distribution (a continuous distribution with support $\in [0,1]$ , which is often elicited in problems involving the Bernoulli distribution (it often appears in conjugate priors). A third possibility is the Continuous Bernoulli , which was created with the exact purpose of correcting the likelihood function in Variation Autoencoders applied to continuous data bounded between $[0,1]$ (for example, normalized pixel intensity values). Cross-entropy, while a valid loss function, does not lead to a proper likelihood in this context, requiring this continuity correction.
