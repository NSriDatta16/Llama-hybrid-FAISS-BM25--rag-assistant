[site]: crossvalidated
[post_id]: 393226
[parent_id]: 
[tags]: 
Why does modelling t-SNE 2D coordinates with a neural network fail to produce a perfect fit?

In short, I want to train a neural network to project my high dimensional objects to a 2D plane coordinates which was created using t-SNE ( Rtsne package for R). I processed 0.5 million of 128-dimensional points to this picture: It is just OK to me. I see the clusters. Now I train the NN with the same inputs and two outputs in an attempt to get a machine capable of mapping future samples to this plane. However, I could not get a close approximation with even very complex NN (3 layers, 1014, 512, 2 neurons), as well as with a weaker model. So, I wonder if this is technically not possible to get exact approximation due to some randomness in the process of the t-SNE convergence, in other words, if there are contradictory examples? Update 1 - Experiments with NN architecture: I Z-normalized inputs to unit standard deviation and zero mean. I normalized outputs to the range [0;1]. I use Keras for R: Per amoeba's idea I decided to kick off with the following architecture: # set NN input % #common_dense1 %>% x_dense2 %>% x_dense3 %>% x_dense4 %>% x_dense5 %>% x_dense6 tsne_model_output_y % #common_dense1 %>% y_dense2 %>% y_dense3 %>% y_dense4 %>% y_dense5 %>% y_dense6 tsne_output Please note it is a parallel architecture, where each coordinate is modeled using its own layers. I roughly estimated this model comtains 2.2 Billion of parameters. Learning rate is 1e-3. Final MSE: 0.013. Which means average absolute error is 0.114 (or 11% given the scale of the outputs). This is worse than I've seen before. Next I will decrease the leraning rate to 5e-4 for another 500 epochs. Stage 2 - smaller learning rate, larger batch size: It seems we are stuck.
