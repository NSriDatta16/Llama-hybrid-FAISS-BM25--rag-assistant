[site]: crossvalidated
[post_id]: 637020
[parent_id]: 
[tags]: 
Confidence interval for non i.i.d. sample

I'm facing this machine learning problem in real life, that turns to stem from a statistics problem. Given a test set S of size N samples with a statistic x (x is the mean accuracy across the N samples), I want to know if the test set S is large enough for my prescribed confidence interval width and confidence level (otherwise, I'll collect more test samples). If my N samples are i.i.d, the theory is commonly found online and is rather straightforward. However, I know there are some dependencies between my samples. If I assume i.i.d. (which doesn't hold), I can compute my sample variance and get the needed sample size N' for my given prescribed confidence interval width and confidence level, but I find that in practice this N' is not large enough. This makes sense to me intuitively, since the correlations in the data would kind of make the actual effective sample size smaller. I find some methods that rely on bootstrapping like http://www-i6.informatik.rwth-aachen.de/PostScript/InterneArbeiten/Bisani_BootstrapEstimatesForConfidenceIntervalsInASRPerformanceEvaluation_ICASSP_2004.pdf , but they assume I know how to split my data into non--correlated subsets, which I don't. My question is what is a correct or practical way to approach the question "is my test set large enough for my prescribed confidence interval width and confidence level, when my samples are non i.i.d.?"
