[site]: datascience
[post_id]: 23334
[parent_id]: 
[tags]: 
Genetic neural network to satisfy variable number of inputs and outputs

I have what I propose as a solution to my problem, however I haven't ever seen it mentioned in this way, so I worry that there is a valid reason not to do things this way. I have a dataset of > 100,000 events, where each event has a winner. I have plenty of data points, some data on the event itself, and some data on each entrant. The number of entrants in each event is variable, and I want to build a neural network around picking a likely winner of the events. As the number of entrants is variable, what appears to be common advice is to have enough inputs for the maximum case scenario, and 0 them out for events where there are empty slots. This feels somewhat inelegant, and I had a slightly different idea. I was going to have a NN where the inputs are information about the event, and information about 1 entrant. I would then have a single output (a float between 0 and 1). I would run this through, getting 1 output for each entrant in an event, then I would be left with a number of floats, equal to the number of entrants in the event. I would then select the highest value, and use the entrant that refers to as the choice for the winner. Is there a reason I shouldn't be doing it this way? Is there a better solution I haven't yet come across?
