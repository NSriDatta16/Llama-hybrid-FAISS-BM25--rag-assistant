[site]: crossvalidated
[post_id]: 557451
[parent_id]: 
[tags]: 
Conditional independence tests not respecting d-separation

Wrong example, please refer to the second example I just tried to model a Bayesian network composed of 3 variables as follows $A\sim N(0,1)$ $B\sim A + N(0,1)$ $T\sim A + B + N(0,1)$ In the DAG associated to this experiment, $A$ represents a backdoor path from $B$ to $T$ therefore I expect that, by conditioning on $A$ , the dependence between $B$ and $T$ decreases. However, in the simulated scenario (R code below) this does not seem to happen since the p-value when testing $B\perp T|\emptyset$ is lower than the p-value of the test $B\perp T|A$ . Any idea of why this happens? May that be because the probability distribution of the variables is not faithful to the DAG as pointed in the answer here ? library(bnlearn) set.seed(120395) A = rnorm(n = 100, mean = 0, sd = sqrt(1)) B = A + rnorm(n = 100, mean = 0, sd = sqrt(1)) T = A + B + rnorm(n = 100, mean = 0, sd = sqrt(1)) df $p.value, t2$ p.value)) Output: 6.70679e-37 1.66561e-20 New corrected example Let us consider $A\sim N(0,1)$ $B\sim A + N(0,1)$ $C\sim A + B + N(0,1)$ $D\sim A + B + C + N(0,1)$ $T\sim A + B + C + D + N(0,1)$ The DAG associated to this experiment is the following Let us study association between $C$ and $T$ . The d-separation criteria tells us that in this BN, without conditioning on any variable all the paths from $C$ to $T$ are open and I expect that, by closing some of them, the dependency between $C$ and $T$ decreases. In this particular graph, we expect the dependence by conditioning on $\{A,D\}$ to be higher than the one obtained by conditioning on $\{A,B,D\}$ since the latter case blocks $T\leftarrow B \rightarrow C$ as well as the paths through $A$ and $D$ . Putting this in formulas, we expect to see $dep(C,T|\{A,D\}) > dep(C,T|\{A,B,D\})$ By using the negative p-value as a dependence measure (as suggested here ) these assumptions are violated since the R code outputs $dep(C,T|\{A,D\}) = -pvalue_{C\perp T|\{A,D\}} = -1.78*10^{-09}$ $dep(C,T|\{A,B,D\}) = -pvalue_{C\perp T|\{A,B,D\}}= -1.52*10^{-11}$ therefore $dep(C,T|\{A,D\}) Any idea why this happens? May that be that the p-values (and the negative p-values as well) are not suited for studying dependency comparisons as the one I did? Here's the code for this example library(bnlearn) set.seed(120395) A = rnorm(n = 100, mean = 0, sd = sqrt(1)) B = A + rnorm(n = 100, mean = 0, sd = sqrt(1)) C = A + B + rnorm(n = 100, mean = 0, sd = sqrt(1)) D = A + B + C + rnorm(n = 100, mean = 0, sd = sqrt(1)) T = A + B + C + D + rnorm(n = 100, mean = 0, sd = sqrt(1)) df $p.value, t2$ p.value, t3 $p.value, t4$ p.value, t5 $p.value, t6$ p.value, t7 $p.value, t8$ p.value)) Output: [1] 5.008861e-67 2.379113e-42 2.425548e-32 6.708171e-09 2.204601e-25 [6] 1.783842e-09 1.329351e-09 1.521039e-11
