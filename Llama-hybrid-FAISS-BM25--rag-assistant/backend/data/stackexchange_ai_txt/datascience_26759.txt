[site]: datascience
[post_id]: 26759
[parent_id]: 23669
[tags]: 
Try a random forest, or a regularized model like lasso instead. They're less susceptible to overwriting. RF has the added benefit that you can use the OOB estimate to evaluate performance, so you don't have to slice up your tiny dataset into train and test. Boosting generally isn't a good choice for small data and tends to overfit as you've observed. If you insist on boosting, robust boosting is a modified variant that is specifically designed to work better on small datasets.
