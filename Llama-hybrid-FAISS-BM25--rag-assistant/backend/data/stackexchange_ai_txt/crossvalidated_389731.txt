[site]: crossvalidated
[post_id]: 389731
[parent_id]: 
[tags]: 
Why is loss treated as 0 or infinity here?

I'm reading a beginner's book about deep learning and in the introduction , the following cautionary tale is written: Now, assume that you built a classifier and trained it to predict if a mushroom is poisonous based on a photograph. Say our poison-detection classifier outputs $\mathbb{P}(y=deathcap|image)=0.2$ . In other words, the classifier is 80% confident that our mushroom is not a death cap. Still, you’d have to be a fool to eat it. That’s because the certain benefit of a delicious dinner isn’t worth a 20% risk of dying from it. In other words, the effect of the uncertain risk by far outweighs the benefit. Let’s look at this in math. Basically, we need to compute the expected risk that we incur, i.e. we need to multiply the probability of the outcome with the benefit (or harm) associated with it: $$L(action|x)= \mathbb{E}_{y∼p(y|x)}[loss(action,y)]$$ Hence, the loss $L$ incurred by eating the mushroom is $L(a=eat|x)=0.2\cdot\infty+0.8\cdot0=\infty$ , whereas the cost of discarding it is $L(a=discard|x)=0.2\cdot0+0.8\cdot1=0.8$ . I am confused about why the loss calculations are framed this way. Why is the $loss$ function's range $[0, \infty)$ ? Could someone explain these expectation calculations?
