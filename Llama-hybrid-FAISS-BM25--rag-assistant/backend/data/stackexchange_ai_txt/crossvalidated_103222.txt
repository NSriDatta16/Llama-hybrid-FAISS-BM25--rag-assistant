[site]: crossvalidated
[post_id]: 103222
[parent_id]: 102967
[tags]: 
I think there might be a bit of confusion here. The efficacy of the permutation approach to compute $p$-values is not questioned in the paper you are citing. Random forest's Gini importance is blamed to be biased towards categorical variables with lots of values. Also Random forest's variable importance based on the accuracy reduction after permutations is biased, even if you use sampling with no replacement: i.e. cforest is biased as well. That does not compute $p$-values indeed. Moreover, you cited Altmann's paper which does not mention partial permutations. I guess you are talking about Deng2011 . There is quite a bit of literature about biases of importance measures that can be solved with $p$-values computations. You might get back to Splitting Criterion papers like Kononenko1995 and Dobra2001 (beware the latter talks about bias in selection rather than in magnitude). In Deng2011, the permutation approach simulates via Monte Carlo a $p$-value. The $p$-value takes into account the distribution of the feature importance under the null hypothesis of independence between feature and class. A $p$-value is unbiased because it compares the feature importance value you obtain to the one you would obtain at random. Partial permutation have a different null hypothesis behind: the feature and the class are "almost" independent. The amount of independence in the null hypothesis is quantified by the permutation ratio $\delta$. $\delta$ is chosen to enhance interpretability I guess: if it is too high all $p$-values will be close to 1 and the decimal digits will differentiate between more and less important features. The authors indeed propose the default value to be $\delta = 0.2$, much less than 1.
