[site]: datascience
[post_id]: 90787
[parent_id]: 90783
[tags]: 
No, this is not a problem. If we zoom into the scaled dot product attention blocks, which happen before the projection with $W^O$ we see this: There, you can see how the masking of the current and future positions happens inside the scaled dot product attention, which happens before the multiplication by $W^O$ . Therefore, the values learned for $W^O$ are trained only with the information from the previous tokens in the decoder.
