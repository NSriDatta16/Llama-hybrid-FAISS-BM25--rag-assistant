[site]: crossvalidated
[post_id]: 349597
[parent_id]: 
[tags]: 
Time series standardization

So, I'm studying and replicating the techniques applied in this paper . The paper uses the Granger causality test to perform association analysis between bitcoin's price fluctuation and bitcoin forum's comments sentiment. When studying the Granger causality test, I saw that the time series must be stationary. Otherwise the results might not be trustful. For that, the article says all data were transformed into z-scores for standardization against the previous 10 days . It also says: On a certain date $t$ ($t = 10$ in the paper), the z-score of a certain item $\mathbb{E}$, denoted by $Z_\mathbb{E}$, was defined as: $Z_{\mathbb{E}_t} = (\mathbb{E} - \overline{x}(\mathbb{E})) \div \sigma(\mathbb{E})$, where $\overline{x}(\mathbb{E})$ and $\sigma(\mathbb{E})$ respectively represent the mean and standard deviation of each item for every date. From that statement I understood that one would calculate the mean and standard deviation of a 10 days period (say from day ""x"" to day ""x+9"", including both day ""x"" and ""x+9"") and then calculate the zscore for the day ""x+10"". Then, repeat this process for every date available. So my quetions are: Is this a correct interpretation? Is it a a common approach on transforming the time series into stationary? Is this approach anyway similar to first differentiation approach?
