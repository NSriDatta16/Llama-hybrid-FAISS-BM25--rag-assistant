[site]: crossvalidated
[post_id]: 611640
[parent_id]: 611106
[tags]: 
First of all, I would argue that for making predictions in machine learning in many cases you don't really need to care about the data-generating process. If you are using something like $k$ NN regression, the only thing that you're doing is predicting the mean of the most similar datapoints in the training data, it doesn't make any assumptions about the data-generating process. The same applies to most of the other machine learning. Moreover, keep in mind that the idea of a data-generating process is just an abstraction helping us to formalize the statistical model for the particular data. There is no "the" data-generating process. No data was "generated" from something like Gaussian (or any other) distribution because there is no such thing in nature as Gaussian distribution, it's a mathematical concept. For the purpose of inference, we want our model to be simple, so it is easy to interpret. For making predictions, we want it to be accurate, possibly at the price of being less interpretable. Neither of the models is single correct, they are both wrong, but each is useful in its own way .
