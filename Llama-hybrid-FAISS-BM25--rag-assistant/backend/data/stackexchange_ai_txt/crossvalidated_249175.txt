[site]: crossvalidated
[post_id]: 249175
[parent_id]: 
[tags]: 
Parameter or Network Switching?

I watched a lot of video lectures on reinforcement learning with neural networks and have been making some notes from them. One of the lectures briefly discussed something called parameter or network switching. From memory, it involved training two neural networks in parallel, with different sets of parameters, with the purpose being that the resulting networks would provide more stable results. Unfortunately, I can't find anything else on the topic in Google, and can't find which video lecture mentioned this. I remember that it was mentioned in the same lecture as Experience Replay. Where can I find more information on parameter/network switching? I think I might have written down the wrong words as typing those words into Google don't give me relevant results.
