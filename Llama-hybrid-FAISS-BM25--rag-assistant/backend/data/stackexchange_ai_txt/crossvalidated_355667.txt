[site]: crossvalidated
[post_id]: 355667
[parent_id]: 
[tags]: 
Does assigning "prior weights" in a binomial GLM have the same effect as maximizing a weighted likelihood?

I am doing logistic regression where there is some uncertainty about the labels for some of the points. For example, I might only be 90% sure that person 1 is actually a "Yes"--meaning I'm 10% sure that person is a "No". I want to handle this problem by weighting the likelihood. Specifically, I want to enter two rows of data for each person, one with a "Yes" outcome and one with a "No" outcome. For "Person 1" I referred to above, I would weight the "Yes" row by 0.9 and the "No" row by 0.1. I am doing this in the context of a generalized linear model or generalized additive model. where weights are often used to signify the (in R) number of trials out of which a binomial outcome is taken. In gam (mgcv), the documentation says: weights: prior weights on the contribution of the data to the log likelihood. Note that a weight of 2, for example, is equivalent to having made exactly the same observation twice. If you want to reweight the contributions of each datum without changing the overall magnitude of the log likelihood, then you should normalize the weights (e.g. weights This seems to fit the bill but I don't know what "prior weights" means here exactly. In a quick simulation, this logic seems to hold up. x 0 x2 The reason I think prior weights might mean the number of trials out of which the binomial was taken, is because when you use fractional weights you get this warning: In eval(expr, envir, enclos) : non-integer #successes in a binomial glm! But the results still seem consistent with the weighted likelihood I'm envisioning (e.g. in the example above change weights of 0 and 1 to 0.0001 and 0.9999 and you'll see what I mean)
