[site]: crossvalidated
[post_id]: 281113
[parent_id]: 280051
[tags]: 
Here is a response, hopefully not too simplistic. A single-layer SOM can perform some tasks that require multiple layers of perceptrons. For example, the XOR problem can be solved by a SOM, but not by a single layer perceptron. In terms of reconstructive models, SOM has a codebook vector like a vector quantization method. A SOM essentially encodes each input as the best matching value in the codebook. As the SOM units train, they learn to fit the distribution, such that the codebook vectors approach the training data, while maintaining a topological arrangement (nodes close to each other are similar to one another). So I think my answer is that the SOM already achieves something similar to an autoencoder, if you use the codebook values as the output. It might even work better for certain classes of data (perhaps strongly topological?), but my feeling is that, for many general tasks, it may be difficult to tune the SOM to perform as well as the others. On the other hand, SOM could be a good way to understand or explore the topology of your data.
