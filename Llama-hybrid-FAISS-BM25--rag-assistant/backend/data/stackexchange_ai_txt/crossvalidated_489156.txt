[site]: crossvalidated
[post_id]: 489156
[parent_id]: 
[tags]: 
Why maximizing the expected value of log likelihood under the posterior distribution of latent variables maximize the observed data log-likelihood?

I am trying to understand the Expectation-Maximization algorithm and I am not able to get the intuition of a particular step. I am able to verify the mathematical derivation but I want to understand the why we encounter this particular term. In the EM algorithm, we know that our log likelihood $\ln p(X|\theta)$ can be written as $\mathcal{L}(q,\theta) + KL(q||p)$ . And $\mathcal{L}(q,\theta) = \mathcal{Q}(θ, θ^{old}) + const$ where the $const$ is the entropy of the the distribution $q(Z)= p(Z|X,θ^{old})$ . And the term $\mathcal{Q}(θ, θ^{old})$ represents the expectation of the complete-data log likelihood under the posterior distribution $p(Z|X,θ^{old})$ . Here is what I am unable to grasp. Why does maximizing the expected value of complete data log likelihood under the posterior distribution w.r.t $θ$ give a better estimate $θ^{new}$ ? I can get the intuition of why maximizing the log likelihood( and not the expected value of log likelihood under some distribution ) gives the $θ_{max}$ as we know from the maximum likelihood estimation. But why maximizing the expectation of log likelihood under some distribution also give a better estimate of $θ$ ? Also, here what I can mathematically see, $\mathcal{Q}(θ, θ^{old}) = \sum\limits_{Z} p(Z|X,θ^{old})\ln p(X,Z|θ)$ I can see that by expanding I get, $\ln p(X,Z|θ) = \ln p(Z|X,θ) + \ln p(X|θ)$ and substituting I get, $\sum\limits_{Z} p(Z|X,θ^{old})\ln p(Z|X,θ) + \sum\limits_{Z} p(Z|X,θ^{old})\ln p(X|θ)$ , in which the 2nd term simply becomes $\ln p(X|θ)$ because it is independent of $Z$ . Thus, $\mathcal{Q}(θ, θ^{old}) = \sum\limits_{Z} p(Z|X,θ^{old})\ln p(Z|X,θ) + \ln p(X|θ)$ . And when I substitute value of $\ln p(X|θ)$ and $\mathcal{L}(q,\theta)$ and rearranging, I get $\sum\limits_{Z} p(Z|X,θ^{old})\ln p(Z|X,θ) = -( KL(q||p) + const)$ . I am not sure how to make sense of this. I am referring to Section 9.4 of Patter Recognition and Machine Learning by C. Bishop, if that helps.
