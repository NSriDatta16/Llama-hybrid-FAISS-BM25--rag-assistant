[site]: crossvalidated
[post_id]: 507854
[parent_id]: 507853
[tags]: 
Regarding I'm looking for a strong publication I can cite to prove that SVMs perform worse for time series classification tasks in comparison to other methods (such as ANNs, Decision Trees, Gradient Boosting Machines, etc...), you might be seeking a reference for a claim that is not generally correct. A key thing to remember is, there is no free lunch in model selection. As Dikran Marsupian says in this answer , the no free lunch theorems say that there is no a-priori superiority for any classifier system over the others, so the best classifier for a particular task is itself task-dependent and adds: However there is more compelling theory for the SVM that suggests it is likely to be better choice than many other approaches for many problems. I bet there exists a data generating process and a sample size for which SVM systematically beats other methods. Regarding I found several posts indicating or justifying that SVMs are not popular nowadays, that deep learning rendered kernel methods obsolete or that SVMs have severe drawbacks (such as parameter sensitivity or the need to conduct a grid search for the parameters), this might be true as of now. Perhaps a lot of time series that people are forecasting and writing about lend themselves more easily to those other methods. But popularity and optimality do not always go hand in hand, and the no free lunch theorem remains applicable.
