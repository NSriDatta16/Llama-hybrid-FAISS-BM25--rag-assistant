[site]: crossvalidated
[post_id]: 350411
[parent_id]: 
[tags]: 
Confusion about multimodal machine learning

I recently browsed through this tutorial on multimodal data. Attention: Multimodal in the sense of feature of very different type, that express the same thing -think picture and voice of someone talking -not in the sense of a probability distribution with multiple modes, according to the slides. What I do not understand about the whole approach to multimodal machine learning techniques is why they are only applied only in the case of features that obviously express the same thing - and not also in the case of features for which it is not clear if they express the same thing. Example: you want to predict which webshop visitors are likely to buy stuff and you measure, e.g., their mouse movements as well as the time they spent looking at products; these features might be correlated too. For example, the whole search for correlations between the feature that are assumed to express the same thing could also be applied in the case I outlined above. Of course, applying multimodal techniques in the latter case might not yield anything, but it seems no one is even trying.
