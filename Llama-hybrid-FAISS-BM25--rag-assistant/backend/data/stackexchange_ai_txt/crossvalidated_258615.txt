[site]: crossvalidated
[post_id]: 258615
[parent_id]: 258610
[tags]: 
Handling NaN values belongs to the feature engineering part of developing machine learning models. Different types of models make different assumption about the underline features distributions and inner correlations. So how can you handle NaN values? First try understanding how these NaN values came to be? Is it a bug in the pipeline? corrupted data? inability to measure? Once you get a good sense on the source of these values, Following these questions might be of help: 1) Does the data has rows(samples) with many NaN features. Is dropping these lines from the sample data will create Bias? Will too much samples be lost? 2) Do specific features appear many times with a NaN value?. If so, is there a good explanation to the samples where the value is not NaN. Is it possible defining a new feature based on this explanation. For example mapping the NaN values to 0 and all others to 1. After finished with the first two steps, start filling the missing values. How to choose what value should be filled? The simplest solution is using the average of the feature. Another possible solution is using last row value. This makes sense if samples have some kind of natural order, like in a stochastic process. Here you can even go on drawing random value from a predefined distribution. For example, if the feature represent time referenced metric, then using a Poisson distribution makes sense. As you can understand, handling NaN values involves you understanding how they were created and making assumptions on what is the expected behavior of each feature.
