[site]: crossvalidated
[post_id]: 562163
[parent_id]: 562100
[tags]: 
This is essentially a problem of Bayesian inference --- if you have a prior distribution for $N$ then you can find its posterior given an observation $Y=y$ . To do this, first note that: $$Y|N \sim \text{Pois}(N \lambda).$$ To obtain the posterior of interest, take a prior mass function $\pi_N$ and you then have: $$\begin{align} \mathbb{P}(N=n|Y=y) &= \frac{p(N=n,Y=y)}{\sum_n p(N=n,Y=y)} \\[6pt] &= \frac{\text{Pois}(y|n \lambda) \cdot \pi_N(n)}{\sum_{n=0}^\infty \text{Pois}(y|n \lambda) \cdot \pi_N(n)} \\[6pt] &= \frac{n^y \cdot e^{-n \lambda} \cdot \pi_N(n)}{\sum_{n=0}^\infty n^y \cdot e^{-n \lambda} \cdot \pi_N(n)}. \\[6pt] \end{align}$$
