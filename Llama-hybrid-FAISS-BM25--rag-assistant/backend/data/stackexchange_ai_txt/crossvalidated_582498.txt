[site]: crossvalidated
[post_id]: 582498
[parent_id]: 
[tags]: 
how to get relative risk from a GAM with a distributed lag model

I would like to obtain a relative risk/ risk ratio from a GAM with a distributed lag model. I have a GAM (implemented in mgcv in R) predicting daily deaths from time series data consisting of daily temperature, humidity and rainfall. The GAM includes a distributed lag model because deaths may occur over several days following a high heat day. What I'd like to do is compute and plot the relative risk (accumulated across all lags) against temperature for a given reference temperature, e.g. the temperature at which the risk is lowest, with corresponding confidence intervals.(Additionally, I'd also like to plot the relative risk against temperature for different lags separately). I'm not sure how to go about this and would really appreciate some pointers. (I am aware of the predict.gam function but am not sure if and how it should be used in this case). I found a post by Simon Wood on a related issue and also a paper (see supplement/ additional file for code) which extracts an RR from a GAM, but I understand not all of it, and I'm also not sure how I would apply this to a GAM with time series data and distributed lag. Below is a reproducible example of my GAM: library(mgcv) set.seed(3) # make reproducible example simdat $f/5) simdat$ y $deaths, time = simdat$ time) dat $temp temp) dat $rain rain) dat $humidity humidity) mod I'd be very grateful for any suggestions you may have! UPDATE: There is a way to get overall relative risk, by using predict.gam() with the type = terms argument, and then for each prediction temperature summing over the lag periods. However, this does not (I think?) allow calculation of confidence intervals around the RRs. Via the r-help mailing list Simon Wood pointed out that using type = lpmatrix allows to get CIs. My problem is that I don't know how to work this for a model with distributed lag.
