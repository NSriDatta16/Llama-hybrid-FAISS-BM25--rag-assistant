[site]: crossvalidated
[post_id]: 361372
[parent_id]: 361042
[tags]: 
I guess you mean cosine similarity applied to word embeddings, which in turn are usually (L2) normalized before that, so cosine similarity is then just cosine of angle between the vectors and the same a nice measure of their 'similarity' - according to general idea of mapping words into n-dim space of 'latent semantic features'. Don't think it fits into concept of n-dim random variables and mentioned measures of correlation.
