[site]: crossvalidated
[post_id]: 203819
[parent_id]: 203810
[tags]: 
I don't know a frequentist test for your problem (a one-sided Wilcoxon signed-rank test or sign test won't work because the differences are not identically distributed). But perhaps your problem could be solved easily using a Bayesian approach. For example: Let $d_i = 1(x_i Let's say $\pi$ is the (unknown) probability that $x \begin{align} p(\pi \mid \mathcal{D}) &\propto p(\mathcal{D} \mid \pi) p(\pi) =\prod_i \pi^{d_i} (1 - \pi)^{1 - d_i} \propto \text{Beta}\left(\pi; 1 + \sum_i d_i, 1 + N - \sum_i d_i \right), \end{align} where $\mathcal{D} = \{d_1, ..., d_N\}$. I.e., our posterior beliefs over $\pi$ are beta distributed . From this we can easily derive the probability that the modified optimization tends to be faster, $P(\pi > .5 \mid \mathcal{D})$. If instead of using a uniform prior we want to make the reasonable assumption that $\pi$ is more likely to be around .5 then one of the extreme values, we could use a beta prior with parameters $\alpha = \beta$, $\alpha > 1$ and get $$p(\pi \mid \mathcal{D}) = \text{Beta}\left(\pi; \alpha + \sum_i d_i, \beta + N - \sum_i d_i \right).$$ In Python code: import numpy as np import scipy as sp # prior alpha = beta = 2 # data x = np.asarray([1, 4, 5, 7, 10, 11]) y = np.asarray([3, 4, 6, 8, 9, 12]) # statistic d = np.asarray(x
