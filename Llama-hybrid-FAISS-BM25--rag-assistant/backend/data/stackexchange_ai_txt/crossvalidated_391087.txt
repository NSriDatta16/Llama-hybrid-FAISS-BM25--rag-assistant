[site]: crossvalidated
[post_id]: 391087
[parent_id]: 
[tags]: 
Vanishing reward function in Q-Learning

Imagine that the agent receives a positive reward upon reaching a state $s$ . Once the state $s$ has been reached the positive reward associated with it vanishes and appears somewhere else in the state space, say at state $s'$ . The reward associated to $s'$ also vanishes when the agent visits that state once and re-appears at state $s$ . This goes periodically forever. Will discounted Q-learning converge to the optimal policy in this setup? Is yes, is there any proof out there, I couldn't find anything.
