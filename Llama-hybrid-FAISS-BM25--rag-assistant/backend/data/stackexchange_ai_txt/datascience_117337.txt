[site]: datascience
[post_id]: 117337
[parent_id]: 
[tags]: 
99% accuracy in train and 96% in test is too much overfitting?

I have a binary classification problem, the classes are quite balanced (57%-43%), with a GridSearch with Random Forest Classifier I obtained the best hyperparameters and I applied the model to train and test. Now I have 99% accuracy on train and 96% on test. Is it too much overfitting? Is it a problem? Just for information this is my param_grid for the GridSearch param_grid = {'n_estimators' : [100, 300, 500, 800, 1200], 'max_depth' : [5, 8, 15, 25], 'min_samples_split' : [2, 5, 10], 'min_samples_leaf' : [1, 2, 5]} Best hyperparameters: max_depth=25,min_samples_leaf=1,min_samples_split=2,n_estimators=1200 X_train is 102864 rows × 23 columns. X_test is 25976 rows × 23 columns.
