[site]: datascience
[post_id]: 54075
[parent_id]: 54072
[tags]: 
It's very difficult to understand the effect of each variable on the final output, since the weights of an input variable propagate their effect to all the units of the following hidden layers. Truth is, Neural Networks are very powerful predictors, but they are not very good when it comes to estimate feature importance. One (very time consuming) way of doing it would be: substitute each variable with random noise that has the same mean and variance, and observe how the model's performance changes. Repeat this for all your variables. If performance gets significantly lower once you substituted a variable with random noise, then the contribution of it to the final accuracy has to be relevant. As a more viable alternative, train a tree-based classifier (Random Forest or XGBoost) on the output. This class of models returns importance scores. You can use Neural Network for prediction, and the tree-based model to estimate what variable is more relevant for your task.
