[site]: crossvalidated
[post_id]: 506765
[parent_id]: 
[tags]: 
Which statistical analysis/design to use on clinical hospital data with varying amounts of available data for each patient?

We are currently working in our local hospital on a paper about the influence of the nephrologist on patients with kidney failure. We are aiming to look at a couple of clinical (laboratory) outcomes such as blood pressure and eGFR (reflects the functioning of the kidney). All the outcomes are numeric (about 10). We will gather data from patients from 1 year before treatment to 1.5 year after the start of the treatment. However, the amount of available data varies across the patients. For some patients we only have a few data points, for other patients we have quite a lot of data points. For this reason we are thinking to look/compare the average values at different moments. Something like: t1: 1 year till 0.5 year prior treatment t2: 0.5 year prior treatment till start treatment t3: start treatment till 0.5 after start treatment t4: 0.5 year after start treatment till 1 year after start treatment t5: 1 year after start treatment till 1.5 year after start treatment However, I'm not quite sure if this is the right way to go. The goal is to look if the clinical values are stabilizing (or improving) after the start of the treatment. In other words if the kidney of the patients is detoriating at a slower speed. My questions are: What kind of model would be most suitable for this kind of data and question? Would it be an option to look at the slope coefficients of the clinical values at the different moments? Are there minimal requirements on the amount of data for each patient? I hope my question is clear, if not please let me know, and I will try to explain it some more. Any help/advice is appreciated! Thanks already in advance!
