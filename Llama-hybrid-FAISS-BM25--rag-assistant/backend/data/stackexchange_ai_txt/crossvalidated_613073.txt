[site]: crossvalidated
[post_id]: 613073
[parent_id]: 593525
[tags]: 
To test whether the intercept differs among 50 states, consider using likelihood ratio test between one model without state as either random or fixed effects and another model with random intercepts by state, illustrated https://rpubs.com/DKCH2020/578881 . If you do pairwise comparisons between each state pair, I agree with Roland's comment at How to retrieve standard errors from random effects in nlme? that it requires modeling state as fixed effects, meaning that there will be 50 - 1 = 49 coefficients estimated representing the difference in V1 between each state and a reference state. As a result, there could be 50*49/2 = 1225 pairs of differences, which makes the results intangible. Instead, you can designate one single state (e.g. your major study area) as the reference to reduce the number of pairwise comparisons to 49. In that case, you can use adjusted CIs to visualize the state comparisons. See Wright, T., Klein, M., & Wieczorek, J. (2019). A primer on visualizations for comparing populations, including the issue of overlapping confidence intervals. The American Statistician, 73(2), 165â€“178. https://doi.org/10.1080/00031305.2017.1392359 . To retrieve standard errors of standard deviations or variances of random effects, see https://stats.oarc.ucla.edu/r/faq/how-can-i-calculate-standard-errors-for-variance-components-from-mixed-models/ . Because standard deviations and variances of random effects have skewed sample distribution, however, standard errors for these statistics can be misleading. Instead, reporting profile confidence intervals is encouraged. See https://github.com/lme4/lme4/issues/497 .
