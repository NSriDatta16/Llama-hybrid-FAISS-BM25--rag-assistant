[site]: datascience
[post_id]: 12403
[parent_id]: 
[tags]: 
How can the process of hypertuning of XGBoost parameters be automated?

I'm using xgboost for training a model on a data with extreme class imbalance. After referring from here . After performing grid search and some manual settings, I found that the following parameters work the best for me: weight How can the process of setting optimal hyperparameters for xgboost be automated for best AUC? Please note that some of these parameters aren't supported by the caret implementation of xgboost but are very important for the model I have to design.
