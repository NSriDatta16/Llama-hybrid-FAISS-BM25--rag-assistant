[site]: crossvalidated
[post_id]: 183940
[parent_id]: 
[tags]: 
Better accuracy with validation set than test set

I trained a model with some algorithms like random forest, logistic regression and so on. My dataset was split into 80% CV train data (so actually 60% of data to train the model and 20 % for testing with cv). I built my model and now I'm using the last 20% (which I didn't used the whole time) but I'm wondering why is the predictive accuracy better with the validation set than with the training set? specificity validation: 0.62962963 sensitivity validation: 0.94761905 on the left is the mean, on the right is the standard deviation (+/-) with a 10 times cross validation specificity_train: 0.55 (+/- 0.10) recall_train: 0.94 (+/- 0.02) Did I something wrong? Thought this is the normal / best way to test, if the model is overfitted or not. Or is it OK due to the standard deviation?
