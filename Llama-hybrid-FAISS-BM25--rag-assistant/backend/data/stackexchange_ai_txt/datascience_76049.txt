[site]: datascience
[post_id]: 76049
[parent_id]: 75949
[tags]: 
I know this tutorial, it's a good start for RNNs but it contains a lot of passages and transformations that could have been kept shorter. First, he defines a function called series_to_supervised() to process data to be fed into an RNN. Paragraph 3, line 37: reframed = series_to_supervised(scaled, 1, 1) This reframed dataframe contains all data, either y columns and all the X variables to make a prediction. In the following code block it is turned into a numpy array at line 2: values = reframed.values Ok, so now all our information is store in values . Now it's time to separate it in train and test: train = values[:n_train_hours, :] test = values[n_train_hours:, :] And again, each train and test is separated in x and y pieces: # split into input and outputs train_X, train_y = train[:, :-1], train[:, -1] test_X, test_y = test[:, :-1], test[:, -1] Line 7-8. This is where the dependent variable is separated from the rest. Knowing it was the last column, it was extracted with index -1 (i.e. the last element). As I said, this tutorial is a good start to learn time series prediction with RNNs. However, I find that sometimes he tried to simplify the steps so much... that he ended up with some messy parts. All those objects: reframed , values , train , test , ... there was no need to make so many of them. That apart, I'm a fan of the blog. It provided a lot of useful tips on RNNs.
