[site]: datascience
[post_id]: 109749
[parent_id]: 108770
[tags]: 
You could also split your data like this: ~~~~ train ~~~~ test ~~~~ train ~~~~ test ~~~~ ... Then, you always use one pair of train and test to train and test the model. you can then tune your model hyperparameters based on the average loss it achieves on all the individual test sets in individual runs, given the current value of the hyperparameter. make sure you do not feed any of the test data (also not the lookback window) into the training procedure. this is crucial. compared to the other suggested approach, mine has the advantage that the training set size is always the same. his has the advantage that you train the model on more data.
