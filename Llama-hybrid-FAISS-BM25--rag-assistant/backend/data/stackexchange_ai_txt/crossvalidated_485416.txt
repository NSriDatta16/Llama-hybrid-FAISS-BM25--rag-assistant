[site]: crossvalidated
[post_id]: 485416
[parent_id]: 
[tags]: 
contaminate data with label then take it away

I have an idea for a training strategy (for an ML model), can you please tell me whether it has a name, and whether it makes sense. I need a model for binary classification with a massive class imbalance problem (~1:100000). There are a lot of features. In the process of sanity testing I started feeding the label as feature into the model - unsurprisingly the model performed well (that was the sanity test). Now I want to slowly withdraw the 'bad feature' by making it less and less correlated with the label, whilst looking at how model performs and what hyper-parameters give good results. So my question is this. Can one use it as a training strategy? Start with contaminated features. Train model, then spoil the contamination by adding noise (making features less contaminated). Train again, and keep going until the 'bad feature' is no longer bad (i.e. completely uncorrelated with label). Thanks EDIT It would seem I expressed myself poorly. What I meant is that the model is trained successively but without re-initializing the weights. You start with one feature (feature_A) essentially being the label - model preforms well. Next time, with the same weights, model sees data where feature_A is no longer as good of a predictor, so the model will adapt to pay more attention to other features. Do it again and again, until feature_A is no longer predicts the label at all, but the model is now (hopefully) adapted to make good predictions nevertheless. I guess my simplistic thinking is that if there exists a uniquely correct composition of features that allows to make good predictions, I would be able to push the model to pay attention to the
