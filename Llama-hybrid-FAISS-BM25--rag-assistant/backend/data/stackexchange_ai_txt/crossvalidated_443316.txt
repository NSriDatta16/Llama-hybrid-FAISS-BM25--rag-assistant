[site]: crossvalidated
[post_id]: 443316
[parent_id]: 
[tags]: 
Method for decomposing time-intervals of univariate Time-Series

I am no expert in time-series analysis but trying to get a more of a grasp of it. So, during a Light/Dark transition test the activity of animals is tracked. During the light-phase, usually low to no activity while during dark-phases a high activity can be observed. While this is the natural activity, we also research deviations and different behavior patterns. So in the first case, the result is a non-stationary time series which of course depends on the external variable of whether its light or dark. A visualization of the "natural" behavior is as followed (heavily idealized): The problem is, that the obtained time series have large amounts of time points. So I would like to decompose the univariate time series into sub-time series, whereas every sub-time series should be one of the four phases (in the specific example presented) that can be observed: Now the most simple solution (at least in my opinion) would be to apply linear regression and define a threshold for the correlation coefficient which determines when a new phase would start. Now, the implementation for the specific pattern presented is not exactly what I am asking for. As there are more, different patterns in the dataset a specific solution for the presented pattern would not seal the deal. I would like to ask the community whether they know of examples where people tried this: to apply an algorithm that identifies characteristic phases of a time series and decomposes it into them. I would be very glad for pointers toward great literature, tutorials, or something else.
