[site]: crossvalidated
[post_id]: 443806
[parent_id]: 
[tags]: 
What exactly is InstanceNormalization and BatchNormalization?

I know this is a question that has been asked a lot. I know there are many good explanations on this topic and videos. However, I still have a hard time to understand the relationship visually between the normalization methods and convolutional neural network. So I looked at some articles and they all explained it with the figure below: In general, I understand that Batch Norm is a normalization that is done over batches. I understand that it helps the learning and that you calculate the mean and standard deviation for each batch. However. When I try to refer this to a convolutional neural network (below) I don't really understand what exactly the H, W, C and N is. What I think they describe is the following: N describes the number of batches and in the figure, this number is 6. This means that everytime I am training one run I use 8 images per batch. C describes the channels and they refer to the number of feature maps. H, W I don't understand. What I am seeking is a 1:1 relationship of what (H, W), C and N is versus for Convolutional Neural Networks. Can anyone help me here?
