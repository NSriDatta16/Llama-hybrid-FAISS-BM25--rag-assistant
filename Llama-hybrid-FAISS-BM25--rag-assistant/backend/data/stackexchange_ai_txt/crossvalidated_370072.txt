[site]: crossvalidated
[post_id]: 370072
[parent_id]: 
[tags]: 
What information, other than directly observed data, can a likelihood encode?

Background Typically, the likelihood function is defined as the probability of observed data under an assumed model. So something like: $$L(\theta | {\bf x}, {\mathcal M}) = p_{\mathcal M}({\bf x}|\theta)$$ Here, the likelihood function explicitly depends on the data $\bf x$ . If observations are censored, the problem is framed in a clever way where, for example, if we observe the random variable $Y$ up until a certain value $l$ and $y_l$ if $Y \geq y_l$ , the observation itself is treated as a random variable with a Bernoulli distribution, so the problem of writing down a likelihood for the model again becomes a well defined and solvable problem. My question: What if you observe something else that's not data? For example, lets say $f(x)$ and $g(x)$ are functions. My model for both $f$ and $g$ is a Gaussian Process (as a GP is a model on functions). If I had observed some data for $f$ and $g$ , I could easily write down a likelihood: $$log \; L(\theta;{\bf y}_f, {\bf y}_g) = c - \frac{1}{2} y_f^T\Sigma^{-1}_{x, \theta}y_f - \frac{1}{2} y_g^T\Sigma^{-1}_{x, \theta}y_g$$ Problem Now, what if one "observes" that $g = sin(f)$ ? Can this information be encoded within the likelihood? Would it be correct to say that: $$log \; L(\theta;{\bf y}_f, {\bf y}_g) = c - \frac{1}{2} y_f^T\Sigma^{-1}_{x, \theta}y_f - \frac{1}{2} sin(y_f)^T\Sigma^{-1}_{x, \theta}sin(y_f)$$ Ideally, it's true that f really should be treated as a transformation of a random variable, but sometimes the transformation can be non-monotonic and here , it was pointed out that a reasonable distribution cannot be 'assigned' to a non-monotonic transformation of a RV knowing nothing about what the transformation actually is. I understand that changing the likelihood in this manner changes the probability law, and it enforces a joint distribution that might not actually be a distribution, but why would this be wrong? I've sincerely "observed" that all my $y_g$ s were just $sin(y_f)$ s! If this can't be done, then how could one account for this information? Edit in the light of @dwcoder's answer: I had briefly considered these arguments while writing the likelihood that I stated above; there are two main reasons (within the context of this answer) for why I wrote the likelihood the way I did: (The excuse) For my specific example, the likelihood has two components to it, which are the MVN densities of the two GPs. If we add a third contribution, such as the likelihood of the statement $y_g = sin(y_f) + \epsilon$ and let $\epsilon \rightarrow 0$ a.s., my guess is that it enforces the likelihood that I wrote above (because $y_g$ and $y_f$ are free parameters and the additional term forces $y_g$ to be close to $sin(y_f)$ ). (The reason) When it comes to model building, I had always thought that we first build a model with some assumptions, do the experiment, and then feed in the results. What if before the experiment I do not actually know what the relationship between $y_f$ and $y_g$ will be, and this is a result of the experiment? I'm not really trying to encode assumptions directly into the likelihood - I'm trying to avoid encoding the results into my model, before I see them. ... which is essentially my question - the standard frameworks such as the one in Edwards have well formed arguments, but sometimes, there is more information in an experiment over and above the observed data points corresponding to the model's random variables. At what point does "information" stop being something you can plug into the likelihood and become something for which you need special care to put into a model? I still don't understand why it's wrong to state the likelihood the way I did. As for building a model that in some way captures the dependance between $y_g$ and $y_f$ - I don't see why this is needed. Two independent samples/draws from RBF-GPs, when plotted against each other, have very nice & smooth 'joint relationships'. For example, here's a simulation: The two components are independent on average , but each set of samples has a great amount of interdependence. How would one account for this given that the independent GPs model is the "true" model? Edit 2: Another thing that comes to mind is that, a likelihood doesn't have to integrate to anything - it simply reflects the probability of observing something (or atleast, it's proportional to it). Hence, evaluating the above density at $y_f$ and $sin(y_f)$ doesn't lose the interpretation of the likelihood.
