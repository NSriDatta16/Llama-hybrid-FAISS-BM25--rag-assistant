[site]: crossvalidated
[post_id]: 616107
[parent_id]: 
[tags]: 
Is there a better way to self-train on tabular data?

Context: I'm training a classifier on some fraud data. Only a chunk of data is labeled (~2000) so I'm trying a self-training approach, what I'm doing for now is: Iteratively training a model then labeling the unlabeled samples and feeding the samples where the model is more sure about the label to a training set for a new model It worked for me, it improved my model's performance on a holdout set. My questions: Is there a better way, or other things to try? I only found litterature using this approach in a deep learning context and I've been wondering if there is work on this for tabular data. I also was wondering if there is a way to inject noise in the data or the model (I'm using Catboost) like it's usually done in deep learning (image augmentation, dropout ...), in deep learning this helps the new model be different that the old model and enforce invariances in the decision function.
