[site]: datascience
[post_id]: 42970
[parent_id]: 
[tags]: 
How does Q-Learning deal with mixed strategies?

I'm trying to understand how Q-learning deals with games where the optimal policy is a mixed strategy. The Bellman equation says that you should choose $max_a(Q(s,a))$ but this implies a single unique action for each $s$ . Is Q-learning just not appropriate if you believe that the problem has a mixed strategy?
