[site]: datascience
[post_id]: 33292
[parent_id]: 33285
[tags]: 
At least as far as I know reducing the size of images is always lossy and you can not retrieve the original image due to the fact that you are throwing away information. Although there are solutions for dimensionality reduction like PCA , they are linear approaches. It depends on your task that what you want to do but there is a solution if you have a classification problem. Try to use a spatial transformer module before the input of the predefined network and send the output of that module to your predefined network. For your grid sampler, you can set the size of the grid to $48 * 48$. For more details take a look at here . Concretely, the grid generator first creates a normalized meshgrid of the same size as the input image U of shape $(H, W)$, that is, a set of indices $(x^t,y^t)$ that cover the whole input feature map (the subscript $t$ here stands for target coordinates in the output feature map). Then, since we’re applying an affine transformation to this grid and would like to use translations, we proceed by adding a row of ones to our coordinate vector to obtain its homogeneous equivalent. This is the little trick we also talked about last week. Finally, we reshape our 6 parameter $θ$ to a $2x3$ matrix and perform the following multiplication which results in our desired parametrised sampling grid... since bilinear interpolation is differentiable, it is perfectly suitable for the task at hand. Armed with the input feature map and our parametrised sampling grid, we proceed with bilinear sampling and obtain our output feature map $V$ of shape $(H’, W’, C’)$. Note that this implies that we can perform downsampling and upsampling by specifying the shape of our sampling grid. (take that pooling!) We definitely aren’t restricted to bilinear sampling, and there are other sampling kernels we can use, but the important takeaway is that it must be differentiable to allow the loss gradients to flow all the way back to our localisation network.
