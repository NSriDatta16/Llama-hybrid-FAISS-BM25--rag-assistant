[site]: crossvalidated
[post_id]: 103788
[parent_id]: 
[tags]: 
Random forest ML algorithm suitable for use on cluster based HPC?

I have developed a script using pythons scipy package to analyse a rather large model that I wish to solve, the model contains over 12gb of data, including over 500 parameters. Now running small simulations of about 0.5gb of data with 20 parameters can still take my computer a decent amount of time if given a reasonable number of iterations through the random forest classifier. Currently my script is only using one core, so I guess that could be the first step, to make the script multi-threaded. But this will not be enough given how complex the model is. I am willing to explore the use of a cluster based HPC solution but I am not sure how to go about this. Any advice on the above would be appreciated. Thanks AEA
