[site]: crossvalidated
[post_id]: 303041
[parent_id]: 
[tags]: 
How to determine the stable state of time series?

I have a year of spatial sensor data in the format unixtime x y z . The sensor is attached to a flexible strained submerged string. The string is occasionally pulled and, after some time, let go. This means that a sensor coordinate oscillates over time with different amplitudes and takes a dive on occasion. The measurements are taken irregularly, every 1-5 minutes. However, there may be long (weeks) periods when no data is taken. The problem here is to identify a "stable position" of the sensor - a set of coordinates that minimizes possible positioning error, assuming that the string is not being pulled. So far, I have come to 3 ideas: Quick and manual: Look at the time series, and average coordinates over the longest "stable" period. Use a high-pass filter, then average the coordinates. Literally optimize total distance from time series to stable point over $R^3$ (possibly add amplitude-dependent weights). It seems like this kind of problem should arise frequently in time-series research, but I lack experience and vocabulary to define it properly. Is there a standard approach to it? edit:
