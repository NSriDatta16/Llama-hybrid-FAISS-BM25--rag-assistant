[site]: stackoverflow
[post_id]: 4932305
[parent_id]: 4932259
[tags]: 
Better in terms of simplicity, without initial size. Better in terms of performance, try that out yourself. Found an SO thread, Performance of Hashmap with Different Initial Capacity And Load Factor Load Factor The performance of most collision resolution methods does not depend directly on the number n of stored entries, but depends strongly on the table's load factor, the ratio n/s between n and the size s of its bucket array. Sometimes this is referred to as the fill factor, as it represents the portion of the s buckets in the structure that are filled with one of the n stored entries. With a good hash function, the average lookup cost is nearly constant as the load factor increases from 0 up to 0.7(about 2/3 full) or so. -- Wikipedia on Load Factor Now your new question if i use it with initial capacity of 100 or higher will it effect the code? Its not a good idea, you are good to go with default thing. Don't think too much about this in the start. As he said, "premature optimisation is the root of all evil". It wouldn't give any real benefit, whatsoever.
