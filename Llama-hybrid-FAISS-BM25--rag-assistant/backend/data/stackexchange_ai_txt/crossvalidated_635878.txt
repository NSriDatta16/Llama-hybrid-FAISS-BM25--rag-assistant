[site]: crossvalidated
[post_id]: 635878
[parent_id]: 635864
[tags]: 
I would suggest looking at forecast accuracy / cross validation. By testing the model on part of the dataset that was not used to fit the model. In other settings such as multivariable regression, it is common to split the data randomly. With time series this obviously won't work, and instead a sequential approach is needed such as a rolling window which involves training the model on a fixed-size segment of the data and forecasting the next point. The window then rolls forward by one observation, and the process repeats. Another approach is an expanding window which is similar but the training set expands to include all data up to the current point in each iteration. You can also look at metrics such as AIC/BIC and Root Mean Squared Error (RMSE).
