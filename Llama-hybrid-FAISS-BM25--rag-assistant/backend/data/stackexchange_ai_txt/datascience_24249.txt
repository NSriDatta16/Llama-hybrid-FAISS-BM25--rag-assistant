[site]: datascience
[post_id]: 24249
[parent_id]: 
[tags]: 
Reinforcement Learning different patients

I have historical data with labels and features about medical data about treating cancer. The labels represents: How happy is the patient after the treatment (other patients did a survey in the past). From scale 1 till 7. There features are numerical: Via facial recognition we extracted six types emotions on a scale from zero till one. This is performed for patients who are not able to talk and are in electric wheelchair with a tablet. I trained a random Forrest Regressor. That predicts how happy will be patient on a scale from 1 till 7. After the patient is done with the treatment the patient fills in a survey behind a screen. Each patient has a unique user ID. How would you apply personalization via reinforcement learning in order to know happy the patient will be during the next treatment. The happiness of the patients it's face should be updated if this is not correct for this user. For example: I want the agent to update the model for this patient it's belief (the old model that we trained) Let's say we predicted 6, but actually it was 4 next time this same patient arrives, we want to estimate the patients happiness with the new updated model. My model can be correct for patient A, and incorrect for patient B. Because for patient B some emotion was more or less important compared to patient A. How would you solve this problem and it should be scalable for 2000+ patients. Patients with cancer are coming back to the hospital for treatment (on average 10 or 20 treatments). And each patient has an Unique ID. The model is making the prediction. Based on the predictions the doctors "receive" an happiness estimation. The model makes: the wrong prediction for patient B but the correct one for patient A. Because patient B indicated after the treatment that the estimation was incorrect based on the scale scores. But Patient A indicated that his prediction was correct.
