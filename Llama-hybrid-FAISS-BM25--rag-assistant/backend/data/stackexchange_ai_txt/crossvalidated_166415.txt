[site]: crossvalidated
[post_id]: 166415
[parent_id]: 166390
[tags]: 
I would probably use a full "basic" example: https://github.com/gwtaylor/theano-rnn/blob/master/rnn.py You can look at the Theano docs to see what math has been abstracted away. Basic strategy of what you're looking for is here I think... compute the gradient of cost with respect to theta = (W, W_in, W_out) # gradients on the weights using BPTT gparams = [] for param in self.rnn.params: gparam = T.grad(cost, param) gparams.append(gparam) updates = {} for param, gparam in zip(self.rnn.params, gparams): weight_update = self.rnn.updates[param] upd = mom * weight_update - l_r * gparam updates[weight_update] = upd updates[param] = param + upd
