[site]: crossvalidated
[post_id]: 176313
[parent_id]: 
[tags]: 
Quadratic loss function implying conditional expectation

I am reading Bishop's pattern recognition book . In the decision theory part he first derives that using a quadratic loss function implies that our estimate $y(x)$ should be the conditional expectation $\mathbb{E}[t|x]$. Then, armed with this knowledge he wants to show a simpler proof: \begin{align*}L(t, y(x)) &= (y(x) - t)^2 \\&= (y(x) - \mathbb{E}[t|x] + \mathbb{E}[t|x] - t)^2 \\&= (y - \mathbb{E}[t|x])^2 + 2(y(x) - \mathbb{E}[t|x])(\mathbb{E}[t|x] - t) + (\mathbb{E}[t|x] - t)^2\end{align*} So far so good but now he says "performing the integral over t, we see that the cross-term vanishes and we obtain an expression for the loss function in the form" $$\mathbb{E}[L] = \int (y - \mathbb{E}[t|x])^2 p(x) dx + \int (\mathbb{E}[t|x] - t)^2 p(x) dx$$ Now, how does the cross-term vanish exactly? Also how can the above expression still contain $t$ (he just integrated over it, so he probably means $(\mathbb{E}[t|x] - \mathbb{E}[t])^2$ ?). This is on page 47 of Bishop: Pattern Recognition And Machine Learning
