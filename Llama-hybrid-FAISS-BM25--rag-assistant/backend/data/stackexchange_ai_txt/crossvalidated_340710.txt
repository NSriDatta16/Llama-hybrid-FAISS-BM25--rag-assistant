[site]: crossvalidated
[post_id]: 340710
[parent_id]: 
[tags]: 
Time Series Classification with Varying Sampling Frequency

I'm new to signal processing and am wondering how to deal with a time-series classification problem when I have unequally spaced data. Skimming through recent literature, including The great time series classification bake off: a review and experimental evaluation of recent algorithmic advances there seem to be a plethora of options such as BOSS, WEASEL, DTW etc. However, based on my limited understanding it seems that all of these methods take in 1-dimensional data, and expect very long time-series. This would seem to assume an identical (and high) sampling frequency across all trials. Due to device limitations on my equipment, I do not have equal sampling frequency even within one series. I do have timestamps on each data point so I can calculate all data point times relative to the first point of each series but they will be unevenly spaced, e.g. (imaginary data, (time, value)): [(0, 5), (12, 5.3), (13, 4.6), (17, 4.6), (18, 5.0)] I'm wondering if there are ways to implement these approaches (or alternatives) to deal with the unequal spacing. If not, then can do something like fit a spline to the data and sample from the splines? Also, do these approaches work with a small number of points? Most of my series will have 5 to 20 points. Though the device records these points in such a way that the shape of the time series could be recreated within a certain margin of error by interpolating between each of the points. I can of course arbitrarily increase this with the spline sampling. I have labelled training data and will be using the developed model to predict the class (binary) of new time-series.
