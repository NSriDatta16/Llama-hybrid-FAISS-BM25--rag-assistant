[site]: datascience
[post_id]: 37344
[parent_id]: 
[tags]: 
Weights and Bias set to NaN

I am performing linear regression on one of UCI Machine learning repository data set. Below is the code :- import tensorflow as tf import matplotlib.pyplot as plt import csv import os import numpy as np import pandas as pd from sklearn.model_selection import train_test_split wine_data = pd.read_csv('data/winequality-red.csv', delimiter=';') n_samples = wine_data.shape[0] train_x = wine_data.iloc[:, :11].values train_y = wine_data.iloc[:, 11].values training_epochs = 1000 learning_rate = 0.03 n_input = 11 n_classes = 1 display_step = 10 X = tf.placeholder(shape=[None, n_input], dtype=tf.float32) Y = tf.placeholder(shape=[None], dtype=tf.float32) # Weights and Biases. W = tf.Variable(tf.truncated_normal([n_input, n_classes])) b = tf.Variable(np.random.randn()) # Construct Linear Model. prediction = tf.matmul(X, W) + b loss = tf.reduce_sum(tf.pow(prediction - Y, 2))/(2 * n_samples) optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for step in range(1, training_epochs + 1): sess.run(optimizer, feed_dict = {X: train_x, Y: train_y}) if step % display_step == 0 or step == 1: cost, x, y = sess.run([loss, W, b], feed_dict = {X: train_x, Y: train_y}) print (x) print (y) print ('Step ' + str(step) + ', Minibatch Loss = ' + \ '{:.4f}'.format(cost)) print ('Training Done!!!') Now, weights and biases get set to Nan only after single step. [[14430.979 ] [ 918.5443 ] [ 484.25635] [ 4654.437 ] [ 151.41441] [31196.336 ] [97207.76 ] [ 1732.7361 ] [ 5743.218 ] [ 1149.8185 ] [18074.775 ]] 1735.9697 Step 1, Minibatch Loss = 32277641302114304.0000 [[nan] [nan] [nan] [nan] [nan] [nan] [nan] [nan] [nan] [nan] [nan]] nan Step 10, Minibatch Loss = nan What all reasons could result weight and biases carry Nan?
