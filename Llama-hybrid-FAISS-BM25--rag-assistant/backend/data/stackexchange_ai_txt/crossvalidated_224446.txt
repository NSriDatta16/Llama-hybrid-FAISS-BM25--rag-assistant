[site]: crossvalidated
[post_id]: 224446
[parent_id]: 122538
[tags]: 
Why do most seasonal time series and forecasting algorithms presume that the seasonal period is (are) known? Here are a few reasons: For most applications, seasonal cycle lengths are known. Retail sales exhibit intra-yearly and intra-weekly seasonality. In Islamic countries, they exhibit a known irregular seasonality connected with the Islamic calendar. Electric power demand exhibits intra-daily, intra-weekly and intra-yearly seasonality. All these are known, and in such applications, no other seasonalities make sense. I have been active in forecasting for about ten years now, and I at least have never come across a paper, conference talk or use case where the length of the seasonal cycle(s) needed to be estimated. Of course you can estimate seasonal cycle lengths. However, the problem is that there are enormously many possibilities, so your estimates - both of the seasonal cycle length(s) and of the coefficients of your model - will have a high variance. If you have a lot of data, this can work. But if you have enough data to reliably estimate seasonal cycle length, i.e., multiple cycles of each potential length, you will likely be more concerned about whether your data generating process has changed during your history. That said, a frequency domain decomposition could be said to model seasonalities of unknown lengths, without explicitly estimating the lengths of these seasonalities.
