[site]: datascience
[post_id]: 17651
[parent_id]: 17645
[tags]: 
Overfitting happens when the model fits the training dataset more than it fits the underlying distribution. In a way, it models the specific sample rather than producing a more general model of the phenomena or underlying process. It can be presented using Bayesian methods . If I use Naive Bayes then I have a simple model that might not fit either the dataset or the distribution too well but of low complexity. Now suppose that we use a very large Bayesian network. It might end up not being able to gain more insight and use the complexity to model the dataset (or even just trash). So, overfitting is possible in unsupervised learning. In PCA we start with a model in the size of the dataset. We have assumptions about the way the data behaves and use them to reduce the model size by removing parts which don't explain the main factors of variation. Since we reduce the model size one could expect to benefit always. However, we face problems. First, a model in the size of the dataset is extremely large (given such a large size you can model any dataset). Compressing it a bit is not enough. Another problem is that it is possible that our assumptions are not correct. Then we will have a smaller model be it won't be aligned with the distribution. Again, it this case it might overfit or just not fit the model. Though that, PCA is aimed to reduce the dimensionality, what lead to a smaller model and possibly reduce the chance of overfitting. So, in case that the distribution fits the PCA assumptions, it should help. To summarize, overfitting is possible in unsupervised learning too. PCA might help with it, on a suitable data.
