[site]: datascience
[post_id]: 17953
[parent_id]: 
[tags]: 
What are 2D dimensionality reduction algorithms good for?

It seems to me that t-SNE and other dimensionality reduction algorithms which reduce the dimensionality to two dimensions are mainly used to get an impression of the dataset. If done well, they look nice (e.g. like this ), but I wonder if this is better than just showing random images / grouping them by class on a grid. I would like to get an answer to the following aspects: How is t-SNE* better than just taking a random (probably stratified) sample of the data? How is t-SNE* better than just fitting a neural network with a 2-neuron bottleneck to the data and then taking the (normalized) value of the 2 neurons for an embedding? Does t-SNE* give any guarantees? Is t-SNE* good for the construction of classifiers? I mean: If you already have a classifier which is much better than random / guessing the most frequent class, does t-SNE help you to make better classifiers? How? There are many dimensionality reduction algorithms . How does one compare the non-linear ones? When is one algorithm better than others? Especially: Are they better than bottleneck features of neural networks? *: You could probably answer this for other dimensionality reduction algorithms as well, but t-SNE seems to be the most popular one. Please note: I do see the advantage of a reduced dimensionality for compression / easier optimization / faster inference. However, the reduction to 2 dimensions seems to be only for visualization. Hence my question if one can see more in those embeddings than a visually pleasing image of the dataset.
