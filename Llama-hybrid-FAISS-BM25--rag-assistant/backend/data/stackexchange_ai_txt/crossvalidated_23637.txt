[site]: crossvalidated
[post_id]: 23637
[parent_id]: 23589
[tags]: 
Here is a weak verification: if you write the Bayes factor as $$ B_{12}(x) = m_1(x)/m_2(x)\,, $$ you can simulate samples from either $m_1$ or $m_2$ (by simulating from the joint distribution under either model). For each of those samples, you can compute the average log-Bayes factor, which should be positive in the first case and negative in the second case (because it is a Kullback-Leibler divergence). Establishing those signs is not a proof everything's fine with your implementation, but at least it should hold!
