[site]: stackoverflow
[post_id]: 131102
[parent_id]: 130486
[tags]: 
If inputs in the second file are needed only once (as they are read), you could potentially cut the memory usage in half. Depending on your algorithm, you might even be able to just hold both filehandles open and a small hash of not-used-yet values in memory. An example would be a merge or comparison of sorted data -- you only need to hold the current line from each file and compare it to each other as you go, skipping ahead until the cmp changes. Another approach might be to make multiple passes, especially if you have one or more otherwise-idle cores in your machine. Open read pipes and have subprocesses feed you the data in manageable pre-organized chunks. For more generic algorithms, you can only avoid paying for the memory size by trading it for the cost of disk speed. In most cases, loading every data source into memory only wins on development time -- then you pay for it in footprint and/or speed when N gets large.
