[site]: crossvalidated
[post_id]: 582103
[parent_id]: 
[tags]: 
Sliding parameters over a ML model

I'm analysing the performance of an algorithm based on neural networks and I have to tune two parameters( number of past days to consider for the turbidity and volume of water flowing) by hand. So considering we've got $X = {x_1,x_2,...,x_n}$ and ${Y=y_1,y_2,...,y_n}$ each having N parameters, doing an exhaustive search for the optimal pair $(x_i,y_j)$ would result in N^2 executions, each taking 20 min therefore lots of time. Question is: Can I keep one variable constant $X=x_1$ for example and try out all the pairs $(x_1,y_j)$ for $j=1,...,n$ and then find a $y^*$ for which the results are optimal. Then set $Y=y^*$ while trying out the pairs $(x_i,y^*)$ for $i=1,...,n$ ranges and get an optimal solution $x^*$ . Can I rightly conclude that $(x^*,y^*)$ gives the best choice of parameters for the model?
