[site]: crossvalidated
[post_id]: 272896
[parent_id]: 
[tags]: 
Balancing distribution of two datasets by exchanging samples

I have fun little problem that I want to try to solve. I've been given a dataset which I will randomly split up into two sets. But now I want these two sets to have the same distribution. Consider the following two randomly generated datasets: A: #1: 3 7 3 #2: 3 7 3 #3: 1 1 1 B: #1: 2 2 2 #2: 2 2 2 #3: 1 1 1 #4: 1 1 1 #5: 2 2 2 #6: 3 7 3 #7: 1 1 1 #8: 2 2 2 #9: 3 7 3 EDIT I want the means over the classes to be as similar as possible. Currently the means are as follows: A := [2.3, 5, 2.3] B := [1.9, 2.7, 1.9] But by moving one sample between them, A(#1 or #2) B(#1 or #2 or #5 or #8), the means become A := [2.0, 3.3, 2,0] B := [2.0, 3.3, 2,0] The reason I want this is, for some classes, the randomized split-up dataset is quite different. Don't get me wrong, its quite good, but I started to wonder if I could make the split even better. I currently do this by randomly switching images between dataset, calculate the norm distance between the means (as in, I use the means as vectors) then keep that exchange if the norm distance goes down. But this made me wonder if there was a better approach to this possible. I want essentially to be able to calculate, that by exchanging A(#1 or #2) B(#1 or #2 or #5 or #8) will give me the same distribution over both sets. Note that this is just a sample case, in real life the datasets can be as big as 40.000+ and generally can never have exactly the same distribution. I am planning on using this method for balancing datasets for deep learning. Best regards, Adam
