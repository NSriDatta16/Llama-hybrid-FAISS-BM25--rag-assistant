[site]: crossvalidated
[post_id]: 235584
[parent_id]: 67791
[tags]: 
I think one option would follow by analogy of predict on newdata in R . This supposes using mice to single-impute and then access the final regression model after burn in and convergence. This model is then used to make a one-time prediction as in predict.glm where newdata is a data set in which $Z=1$ has been replaced for all units and $x$ and $y$ are copies from the imputed data. Alternatively you may be also able to create multiple imputed data sets, giving you sets of parameters which you can use on the new data frame, where again $Z=1$ throughout, giving you multiply imputed data sets for variance control. This way you get predictions for all units of course, even those units without missing data, but you can replace those predictions again by the originally observed information. The only difficulty with this approach is how to access the final model in mice . Quick eyeballing of the documentation (p.77) shows the model parameters are not default output in mids objects. This perhaps requires contacting the authors or programming the imputation by chained equations yourself following van Buuren (2012) or perhaps Raghunathan (2001). Raghunathan, T. E., Lepkowski, J., van Hoewyk, J., & Solenberger, P. (2001). A multivariate technique for multiply imputing missing values using a sequence of regression models. Survey Methodology, 27 (1), 85â€“95. van Buuren, S. (2012). Flexible Imputation of Missing Data . Boca Raton: CRC Press.
