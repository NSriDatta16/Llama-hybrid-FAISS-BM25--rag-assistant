[site]: crossvalidated
[post_id]: 599461
[parent_id]: 420973
[tags]: 
Interesting approach. I am not sure if it is the best possible though. If you are using random forests there are other measures you might use to get feature relevance (e.g., decrease in accuracy if a feature is removed). This has advantages. It is an easy and conceptually simpler approach. Many complex XAI techniques such as LIME are often not robust. That is, if you analyze fairly similar models, the explanations can vary a lot. You have to check if LIME (or whatever technique you are using) is robust. Furthermore, explainability techniques like LIME serve to understand static models. There are other methods focusing on time aspects.
