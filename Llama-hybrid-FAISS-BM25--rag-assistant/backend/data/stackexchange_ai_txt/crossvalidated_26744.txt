[site]: crossvalidated
[post_id]: 26744
[parent_id]: 26733
[tags]: 
The issues arise with the idea of 'small' amounts of non-normality and 'some' autocorrelation. Until it's clear how to operationalise these then you're stuck with tests of normality (not near normality). There is, as you imply, quite a conceptual difference between an insensitive test of normality and a sensitive test of near normality. You can use the first as the second, but it probably won't be quite right and will behave differently in various limits. It seems to me you can proceed in two ways: General normality tests do not allow you to control which aspects of non-normality to treat as more serious than others. So can you define what aspect of normality is actually important? If you are more concerned about, e.g. fat tails or skew then you could test for these separately. Similarly, if you estimate the first order autocorrelation you can use the confidence interval on that parameter to determine how much is 'too much'. But you still have to decide what the correct order is (@Jason O. Jensen assumes it is one, but that will depend on the generation process) and whether you trust the test. If I remember correctly, the size of different normality tests (e.g. KS and Shapiro-Wilks) vary with level autocorrelation, sometimes even depending on its sign. And this in addition to the variation in their power with respect to various alternatives... Second, you say that you generate the data yourself. I'm imagining that either you are testing some kind of random number generator or you are wondering whether something has achieved an asymptotically normal distribution. For the former case, you probably have some idea about what is likely to be wrong, so can test for that, as suggested above. In the latter case, I have less intuition. It is probable that the MCMC convergence literature has something useful to say about this case.
