[site]: stackoverflow
[post_id]: 4107316
[parent_id]: 
[tags]: 
How to distinguish in master data and calculated interpolated data?

I'm getting a bunch of vectors with datapoints for a fixed set of values, in the example below you see an example of a vector with a value per time point 1D:2 2D: 7D:5 1M:6 6M:6.5 But alas not for all the timepoints is a value available. All vectors are stored in a database and with a trigger we calcuate the missing values by interpolation, or possibly a more advanced algorithm. Somehow I want to be able to tell which data points have been calculated and which have been original delivered to us. Of course I can add a flag column to the table with values indicating whether the value was a master value or is calculated, but I'm wondering whether there is a more sophisticated way. We probably don't need to determine on a regular basis, so cpu cycles are not an issue for determining or insertion. The example above shows some nice looking numbers but in reality it would look more somethin like 3.1415966533. The database for storage is called oracle 10. cheers.
