[site]: crossvalidated
[post_id]: 410097
[parent_id]: 409785
[tags]: 
I'm assuming that you don't know the parameters before or after the breakpoint, that you don't require continuity at the breakpoint (in your example you do have continuity at the breakpoint, but you mentioned doing two separate fits pre- and post-breakpoint, which would contradict it being a requirement), and that the standard deviation of the errors is the same before and after the breakpoint. So I'm assuming that your observations are drawn from the following model: $$X_t \sim \begin{cases} \beta_0 + \beta_1 t + N(0, \sigma^2) & \text{if } t This is a bit different from a usual fit because you have different types of models before and after the change, but you can still calculate a best estimate for the breakpoint $\tau$ . You can do this by calculating the likelihood for every value of $\tau$ and then choosing the one that maximises the likelihood. calculateLogLikelihood = function(x, tau) { n = length(x) t = 1:n # define a sequence that is 1 if we are pre-breakpoint and 0 otherwise # (when we do the regression this will give us beta_0) preTauIntercept = c(rep(1, tau - 1), rep(0, n - tau + 1)) # define a sequence that is 1, 2, 3, ... if we are pre-breakpoint and 0 otherwise preTauTime = c(1:(tau - 1), rep(0, n - tau + 1)) # define a sequence that is 0 if we are pre-breakpoint and 1 otherwise postTauIntercept = c(rep(0, tau - 1), rep(1, n - tau + 1)) # define a sequence that is 0 if we are pre-breakpoint and log10(10 + t - tau otherwise) postTauLogTime = c(rep(0, tau - 1), log10(10 + 0:(n - tau))) # fit a model using these 4 variables and with no default intercept lmTau = lm(x ~ preTauIntercept + preTauTime + postTauIntercept + postTauLogTime + 0) return(logLik(lmTau)) } set.seed(1) x = c(1:30*0.3+rnorm(30,sd=0.4), log10(0:50+10)*10+rnorm(51,sd=0.4)) # cycle through all possible values of tau, requiring at least two observations in each segment logLikelihoods = numeric(77) for (tau in 3:(81 - 2)) { logLikelihoods[tau - 2] = calculateLogLikelihood(x, tau) } bestTau = 2 + which.max(logLikelihoods) # Plot the data and the best estimated breakpoint plot(1:81, x, xlab = "t", ylab = "x[t]", pch = 16, cex = 0.5) abline(v = bestTau) # Plot the likelihood as a function of tau plot(3:(81 - 2), logLikelihoods, type = "l", xlab = "Tau", ylab = "Log Likelihood") abline(v = bestTau) For this random seed, the estimate of $\tau$ is actually exactly correct, I get an estimate of $31$ . The plots are as follows: Postscript Thinking about making a confidence interval for the breakpoint, I've implemented a version of the bootstraping method described in Bootstrapping confidence intervals for the change-point of time series by Marie Hušková, Claudia Kirch . The bootstrapping method is as follows: Use the data $x_1, \dots, x_n$ to calculate MLE estimates for $\tau, \beta_0, \beta_1, \beta_2, \beta_3, \sigma$ . Generate $B$ data sets $x^1, x^2, \dots, x^B$ from the distribution, using MLE parameters. For each $x^b$ calculate the maximum likelihood estimate of $\tau$ , $\tau^b$ . Estimate the distribution and quantiles of $\tau$ from the bootstrap estimates $\tau^1, \tau^2, \dots, \tau^B$ . Looking at the output from the original fit, we have Coefficients: Estimate Std. Error t value Pr(>|t|) preTauIntercept 0.105215 0.136669 0.770 0.444 preTauTime 0.295340 0.007698 38.364 So the following code generates the bootstrap samples, which are shown in the plot below: calculateBestTau = function(x) { n = length(x) logLikelihoods = numeric(n - 4) for (tau in 3:(n - 2)) { logLikelihoods[tau - 2] = calculateLogLikelihood(x, tau) } bestTau = 2 + which.max(logLikelihoods) return(bestTau) } # multiple sims based on MLE estimates for the parameters B = 1000 bestTaus = numeric(B) set.seed(1000) for (b in 1:B) { xb = c(0.105215 + 1:30 * 0.295340 + rnorm(30, sd = 0.365), 0.188212 + log10(0:50 + 10) * 9.902841 + rnorm(51, sd = 0.365)) bestTaus[b] = calculateBestTau(xb) } plot(table(bestTaus)/B, xlab = "Tau", ylab = "Probability") And estimating a 95% confidence interval using quantile(bestTaus, c(0.025, 0.975)) outputs $[29, 33]$ .
