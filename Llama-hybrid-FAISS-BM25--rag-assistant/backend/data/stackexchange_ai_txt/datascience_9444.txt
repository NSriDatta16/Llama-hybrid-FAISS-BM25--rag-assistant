[site]: datascience
[post_id]: 9444
[parent_id]: 
[tags]: 
Neural network with multiple kinds of output

Introduction: I am trying to build a neural network similar to the following one http://www.nature.com/articles/srep11476 to predict two different features at the same time: Secondary structure: discrete label with three classes (Helix, Sheet and Coil) Psi/Phi angles: continuous value (-pi to pi in rad or -180/180 in degrees) To do so, I use an output layer with softmax activation for the secondary structure and a tanh layer for the angles to predict sin(phi), cos(phi), sin(psi) and cos(psi), which are subsequently converted back to angles phi/psi. Note that this is done to avoid problems with the periodicity of angles. The cost for the individual features is a cross entropy for the secondary structure and a mean square error for the angles. Problem I want to predict both features at the same time by having two different output layers and then train the network with a cost that takes into account both features. Question 1: the mean square error cost should be done at the sin/cos level or at the angle level (rad or deg)? sin/cos is constrained from -1/1, the rad from -pi/pi and the deg from -180 to 180 Question 2: how can I merge the cross entropy cost for the secondary structure with the mean squared error for the angles in order to make a single cost? I cannot use a simple sum since they have different ranges.
