[site]: datascience
[post_id]: 23909
[parent_id]: 23906
[tags]: 
You generally don't. Scikit-learn is primarily aimed to help new data scientists quickly get comfortable with data science That being said, some strategies for scaling are discussed here: http://scikit-learn.org/stable/modules/scaling_strategies.html This includes using out-of-core models, reducing data size with PCA, and various incremental learners Besides that, your best bet is to use a beefier computer Also, remember that once a model is trained, it can be pickled and shared. Training/testing is usually the time/cpu consuming process. So, once you have a model, you should be able to implement it on machines less beefy than the train/test machine
