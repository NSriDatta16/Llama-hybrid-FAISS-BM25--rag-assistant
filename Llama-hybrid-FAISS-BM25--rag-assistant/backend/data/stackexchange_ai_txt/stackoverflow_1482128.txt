[site]: stackoverflow
[post_id]: 1482128
[parent_id]: 1471002
[tags]: 
Here's a solution that works no matter how big the file is. But it doesn't use RAM exclusively, so its slower than a RAM-based solution. You can also specify the amount of RAM you want this thing to use. The solution uses a temporary file that the program treats as a database with SQLite. #!/usr/bin/perl use DBI; use Digest::SHA 'sha1_base64'; use Modern::Perl; my $input= shift; my $temp= 'unique.tmp'; my $cache_size_in_mb= 100; unlink $temp if -f $temp; my $cx= DBI->connect("dbi:SQLite:dbname=$temp"); $cx->do("PRAGMA cache_size = " . $cache_size_in_mb * 1000); $cx->do("create table x (id varchar(86) primary key, line int unique)"); my $find= $cx->prepare("select line from x where id = ?"); my $list= $cx->prepare("select line from x order by line"); my $insert= $cx->prepare("insert into x (id, line) values(?, ?)"); open(FILE, $input) or die $!; my ($line_number, $next_line_number, $line, $sha)= 1; while($line= ) { $line=~ s/\s+$//s; $sha= sha1_base64($line); unless($cx->selectrow_array($find, undef, $sha)) { $insert->execute($sha, $line_number)} $line_number++; } seek FILE, 0, 0; $list->execute; $line_number= 1; $next_line_number= $list->fetchrow_array; while($line= ) { $line=~ s/\s+$//s; if($next_line_number == $line_number) { say $line; $next_line_number= $list->fetchrow_array; last unless $next_line_number; } $line_number++; } close FILE;
