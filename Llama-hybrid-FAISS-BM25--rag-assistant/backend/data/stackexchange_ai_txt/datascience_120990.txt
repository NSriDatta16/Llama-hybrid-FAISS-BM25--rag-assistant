[site]: datascience
[post_id]: 120990
[parent_id]: 
[tags]: 
Incompatible Shape Error [32, 150,150,3] vs [32] for an Autoencoder

Please Help, I am trying to make an Autoencoder from a dataset of 533,248 images but I can't seem to get the shape right when I go to fit my model. The code I have is below. SRC_DIR = r"/tmp/Dataset" BATCH_SIZE = 32 IMG_HGT = 150 IMG_WID = 150 AUTOTUNE = tf.data.AUTOTUNE x_train = tf.keras.utils.image_dataset_from_directory( SRC_DIR, validation_split=0.199952, subset="training", seed = 123, shuffle = False, image_size=(IMG_HGT, IMG_WID), batch_size = BATCH_SIZE ) x_test = tf.keras.utils.image_dataset_from_directory( SRC_DIR, validation_split=0.199952, subset="validation", seed = 123, shuffle = False, image_size=(IMG_HGT, IMG_WID), batch_size = BATCH_SIZE ) class_names = x_train.class_names print(class_names) x_train = x_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE) x_test = x_test.cache().prefetch(buffer_size=AUTOTUNE) print(x_train) print(x_test) latent_dim = 64 class Autoencoder(Model): def __init__(self,latent_dim): super(Autoencoder, self).__init__() self.latent_dim=latent_dim self.encoder = tf.keras.Sequential([ layers.Rescaling(1./255, input_shape = (IMG_HGT, IMG_WID,3)), layers.Flatten(), layers.Dense(latent_dim, activation='relu'), ]) self.decoder = tf.keras.Sequential([ layers.Dense(IMG_HGT * IMG_WID * 3, activation = 'sigmoid'), layers.Reshape((IMG_HGT, IMG_WID,3)) ]) def call(self,x): encoded = self.encoder(x) decoded = self.decoder(encoded) return decoded autoencoder= Autoencoder(latent_dim) autoencoder.compile(optimizer='adam', loss = losses.MeanSquaredError()) autoencoder.fit(x_train, epochs = 1, batch_size=BATCH_SIZE, shuffle=False, validation_data=x_test) The output of my code is below: Found 533248 files belonging to 3 classes. Using 426624 files for training. Found 533248 files belonging to 3 classes. Using 106624 files for validation. ['AD', 'MCI', 'NL'] The received Error is below: InvalidArgumentError Traceback (most recent call last) in () 83 autoencoder= Autoencoder(latent_dim) 84 autoencoder.compile(optimizer='adam', loss = losses.MeanSquaredError()) ---> 85 autoencoder.fit(x_train, 86 epochs = 1, 87 batch_size=BATCH_SIZE, 1 frames /usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) 50 try: 51 ctx.ensure_initialized() ---> 52 tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name, 53 inputs, attrs, num_outputs) 54 except core._NotOkStatusException as e: InvalidArgumentError: Graph execution error: Detected at node 'gradient_tape/mean_squared_error/BroadcastGradientArgs' defined at (most recent call last): File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main return _run_code(code, main_globals, None, File "/usr/lib/python3.9/runpy.py", line 87, in _run_code exec(code, run_globals) File "/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py", line 16, in app.launch_new_instance() File "/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py", line 992, in launch_instance app.start() File "/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py", line 619, in start self.io_loop.start() File "/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py", line 215, in start self.asyncio_loop.run_forever() File "/usr/lib/python3.9/asyncio/base_events.py", line 601, in run_forever self._run_once() File "/usr/lib/python3.9/asyncio/base_events.py", line 1905, in _run_once handle._run() File "/usr/lib/python3.9/asyncio/events.py", line 80, in _run self._context.run(self._callback, *self._args) File "/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py", line 687, in lambda f: self._run_callback(functools.partial(callback, future)) File "/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py", line 740, in _run_callback ret = callback() File "/usr/local/lib/python3.9/dist-packages/tornado/gen.py", line 821, in inner self.ctx_run(self.run) File "/usr/local/lib/python3.9/dist-packages/tornado/gen.py", line 782, in run yielded = self.gen.send(value) File "/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py", line 361, in process_one yield gen.maybe_future(dispatch(*args)) File "/usr/local/lib/python3.9/dist-packages/tornado/gen.py", line 234, in wrapper yielded = ctx_run(next, result) File "/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py", line 261, in dispatch_shell yield gen.maybe_future(handler(stream, idents, msg)) File "/usr/local/lib/python3.9/dist-packages/tornado/gen.py", line 234, in wrapper yielded = ctx_run(next, result) File "/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py", line 539, in execute_request self.do_execute( File "/usr/local/lib/python3.9/dist-packages/tornado/gen.py", line 234, in wrapper yielded = ctx_run(next, result) File "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py", line 302, in do_execute res = shell.run_cell(code, store_history=store_history, silent=silent) File "/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py", line 539, in run_cell return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs) File "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py", line 2975, in run_cell result = self._run_cell( File "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py", line 3030, in _run_cell return runner(coro) File "/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py", line 78, in _pseudo_sync_runner coro.send(None) File "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py", line 3257, in run_cell_async has_raised = await self.run_ast_nodes(code_ast.body, cell_name, File "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py", line 3473, in run_ast_nodes if (await self.run_code(code, result, async_=asy)): File "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py", line 3553, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File " ", line 85, in autoencoder.fit(x_train, File "/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py", line 65, in error_handler return fn(*args, **kwargs) File "/usr/local/lib/python3.9/dist-packages/keras/engine/training.py", line 1685, in fit tmp_logs = self.train_function(iterator) File "/usr/local/lib/python3.9/dist-packages/keras/engine/training.py", line 1284, in train_function return step_function(self, iterator) File "/usr/local/lib/python3.9/dist-packages/keras/engine/training.py", line 1268, in step_function outputs = model.distribute_strategy.run(run_step, args=(data,)) File "/usr/local/lib/python3.9/dist-packages/keras/engine/training.py", line 1249, in run_step outputs = model.train_step(data) File "/usr/local/lib/python3.9/dist-packages/keras/engine/training.py", line 1054, in train_step self.optimizer.minimize(loss, self.trainable_variables, tape=tape) File "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer.py", line 542, in minimize grads_and_vars = self.compute_gradients(loss, var_list, tape) File "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer.py", line 275, in compute_gradients grads = tape.gradient(loss, var_list) Node: 'gradient_tape/mean_squared_error/BroadcastGradientArgs' Incompatible shapes: [32,150,150,3] vs. [32] [[{{node gradient_tape/mean_squared_error/BroadcastGradientArgs}}]] [Op:__inference_train_function_843] I'm very confused because I double checked the input shapes from x_train and x_test and they're both [none,150,150,3] so I don't know why the shapes are not compatible since I can't tell the model.fit the expected input shape. Thanks ahead of time!!!
