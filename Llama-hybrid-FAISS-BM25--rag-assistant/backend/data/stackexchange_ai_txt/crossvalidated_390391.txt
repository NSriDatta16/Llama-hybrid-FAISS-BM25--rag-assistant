[site]: crossvalidated
[post_id]: 390391
[parent_id]: 13643
[tags]: 
In Linear regression analysis, bias refer to the error that is introduced by approximating a real-life problem, which may be complicated, by a much simpler model. In simple terms, you assume a simple linear model such as y*=(a*)x+b* where as in real life the business problem could be y = ax^3 + bx^2+c. It can be said that the expected test MSE(Mean squared error) from a regression problem can be decomposed as below. E(y0 - f*(x0))^2 = Var(f*(x0)) + [Bias(f*(x0))]^2 + Var(e) f* -> functional form assumed for linear regression model y0 -> original response value recorded in test data x0 -> orginal predictor value recorded in test data e -> irreducible error So, the goal is selecting a best method in arriving a model that achieves low variance and low bias. Note: An Introduction to Statistical Learning by Trevor Hastie & Robert Tibshirani has a good insights on this topic
