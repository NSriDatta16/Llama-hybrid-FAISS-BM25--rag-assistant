[site]: datascience
[post_id]: 90042
[parent_id]: 19802
[tags]: 
I had also run into this problem several times, so I've created an open source modelstore Python library which seeks to tackle the problem of simplifying the best practices around versioning, storing, and downloading models. As others have pointed out, the best practices around this area are still forming. The whole area is fairly straightforward if you are saving one model, but starts becoming complicated as you need to store many models or newly trained versions of existing models. I've seen teams save models into shared drives, Cloud Storage/s3 buckets or git repos, manually or using ad hoc scripts. To unify this, there are options like MLFlow's artifact storage which is great if you can set up and maintain a tracking server. Or, as others have mentioned, there are tools like DVC. The modelstore library unifies the versioning and saving of an ML model into a single upload() command, and also provides a download() function to get that model back from storage. Here is (broadly) what it looks like: from modelstore import ModelStore modelstore = ModelStore.from_aws_s3(os.environ["AWS_BUCKET_NAME"]) model = train() # Replace with your code # Here's an sklearn example - the library currently supports 9 different ML frameworks modelstore.sklearn.upload("my-model", model) The upload() command will create a tar archive containing your model and some meta-data about it, and upload it to a specific path in your storage.
