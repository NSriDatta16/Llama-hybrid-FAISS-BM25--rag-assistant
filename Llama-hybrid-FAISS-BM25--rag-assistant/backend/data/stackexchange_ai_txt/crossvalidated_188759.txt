[site]: crossvalidated
[post_id]: 188759
[parent_id]: 188722
[tags]: 
I've figured it out in the meantime. So calling predict(model1, type='prob') or model2 for that matter, will evaluate the whole training data. It is the same as predict(model2,type='prob') == predict(model2$finalModel, iris,type='prob') Using the predict function on the random Forest model will evaluate the OOB data, so predict(model2$finalModel, type='prob') == as.data.frame(predict(model3, type='prob')) Which leads to predict(model2$finalModel, iris,type='prob') == predict(model3,type='prob') and this was what was missing when comparing the models results and assessing for reproducibility. I've left out the call to all.equal in the code above for clarity.
