[site]: crossvalidated
[post_id]: 263284
[parent_id]: 
[tags]: 
What exactly are "input" and "output" word representations?

So, I was reading Distributed Representations of Words and Phrases and their Compositionality , and I can't understand this part on page 3: What exactly are these representations? One-hot vectors? Resulting embeddings? Implementation-dependent stuff? This short piece is the only time they are mentioned in the paper (at least somewhat explicitly, that is). I just can't wrap my head around the architecture of this thing, as in "here's how it all looks in matrices and vectors form".
