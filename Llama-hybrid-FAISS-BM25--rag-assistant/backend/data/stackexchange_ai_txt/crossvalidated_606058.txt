[site]: crossvalidated
[post_id]: 606058
[parent_id]: 
[tags]: 
Should I include a constant term when testing the significance of variables against a null model?

I have a one-hot vector $y \in \{0,1\}^{n}$ giving the case/control status of a group of genetic samples. I also have a genetic vector $G \in \{0,1,2\}^{n}$ and a vector of covariates $K \in \mathbb{R}^{n}$ . I'm hoping to show that the matrix $G$ helps explain $y$ even in the presence of $K$ , so I first run a null logistic regression to find the optimal constants $\beta_{0},\beta_{1}$ for the null estimate $$\text{logit}(y_{prob,null}) = \beta_{0} +\beta_{1}K.$$ Then I use that estimate to find the optimal constant $\beta_{2}$ for my genomic vector $G$ in $$\text{logit}(y_{prob})=\text{logit}(y_{prob,null})+\beta_{2}G.$$ My question is, is it appropriate to add a second constant $\beta_{3}$ when building the model involving $G$ , i.e. to jointly optimize $\beta_{2},\beta_{3}$ in $$\text{logit}(y_{prob})=\text{logit}(y_{prob,null})+\beta_{2}G+\beta_{3}?$$ I think not, but using this second constant seems to improve the fit slightly, so I wanted to hear the statistical community's opinion.
