[site]: stackoverflow
[post_id]: 4465668
[parent_id]: 4463504
[tags]: 
First off, regarding the referenced link to Nathanael Jones blog, although disk IO is much slower than in memory operations most websites are not disk IO bound, and most of his solutions are quite frankly uneducated crap. Generally speaking there are only a very few situations in which you become DISK io bound. The first is the database server itself. If it doesn't have enough RAM to keep the relevant parts of the database in memory then disk speed of THAT server is crucial; especially in a high transaction situation. Second, you can be disk IO bound if your application directly reads and writes a lot of files. Very very few apps do this. I'm not counting the .aspx or.html files of your application because those can be cached by the existing framework and IIS. Basically, just ignore him. The whole filesystem to database syncing idea as a method to improve performance is of no value to about 99.999% of sites. If nothing else the database should be pushing files to the web server file system, not the other way around. I have seen exactly 1 site in 20 years of development that required this. They serve several million page views a day. Also, he is flat wrong about making a database call across a network being faster than loading an equivalent amount of data from a local file. Next, the actual area that we are really bound at is in sending data across the network to the client browser. This is ALWAYS slower than reading a file from a disk; even with no traffic on the line. Hard drives move data much faster than your network card can. Taking it one step further; modern hard drives are orders of magnitude faster than your internet connection. The best thing you can do to improve performance is just to limit the number of connection requests a single page load requires. Optimization here means having 1 css file, not 20; having just a couple .js file references, not 100; and combining graphics into sprites where feasible. It's faster to transfer 1 big file than 100 small files due to how TCP works. Maybe on an overloaded shared server you might have an issue. However, the reality is that an overloaded shared server is going to be network congested long before it's disk queue length grows out of control. With that out of the way, let's look at your actual issue. The javascript items have two preferred locations: 1. As .js files on the web server or 2. embedded in your master page. Just do option 1, they will be cached by the web server. Further, they will be cached by the client browser meaning you won't have to For your header and footer, the code for this should be in your master page. Don't do server side includes, that just complicates things. Build a normal .net website that leverages master pages for your "chrome" content. You can enable partial page caching at the application level which will handle all of caching for you. When you update the header or footer content, just redeploy the site.
