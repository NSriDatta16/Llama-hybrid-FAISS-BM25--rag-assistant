[site]: datascience
[post_id]: 68693
[parent_id]: 
[tags]: 
Bias Formula in Machine Learning expanded using ground truth

Why is Bias calculated for $f(x)$ ? Shouldn't it be calculated for $Y$ (which is $f(x)$ + Noise $\epsilon$ )? We are fitting our model to $Y$ , So shouldn't we be calculating bias wrt to $Y$ ? Also, I tried to calculate bias for different polynomial fitting with degree $d=3,9,20$ using $f(x)$ . I got the same bias. I got expected bias values when I calculated using $Y$ . But my calculation doesn't match with the actual formula. Basically my doubt is: Why is Bias formula $E[\hat{f}(x_0) - f(x_0)]$ and not $E[\hat{f}(x_0) - Y]$ ? Is it because noise is accounted for separately using variance (Irreducible error)? If suppose I haven't separately accounted for noise, then I can calculate bias using $Y$ ? Bias should be calculated wrt to the Ground Truth right? According to my understanding ground truth is $Y$ which is $f(x) + \epsilon$ . Please correct me if am wrong.
