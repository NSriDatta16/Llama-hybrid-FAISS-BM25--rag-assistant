[site]: crossvalidated
[post_id]: 544910
[parent_id]: 
[tags]: 
Feature creation based on irregular time series with strictly monotonic values

I am given the following problem to run predictive maintenance on the following mess: I have some IoT sensors out in the field, but I cannot easily change the software on them. Also, data collection there is not cheap and thus, I am faced with the following problem of how to create useful features from the following messy data: First, the sampling is highly irregular (sometimes minutes, sometimes only every couple of days, sometimes weeks between measurements). Second, I mostly get cumulated data, i.e. strictly monotonic increases like: This machine was in continuous operation for 0-1h: 15 times 1-2h: 267 times 2-5h: â€¦ at the first instance of the sampling, in the next instance it might be: 0-1h: 24 times 1-2h: 345 times ... I.e., Data accumulates and typical measures like the mean or frequencies are not directly applicable before differentiation, which did not work well for me. How would you recommend pre-processing the data to take care of the irregularities and the strictly cumulated nature of the data, so that I could feed them into a simple machine learning algorithm (tree, linreg, ..)? What are the typical pitfalls? Literature recommendations? An idea I have tried: Normalize the increase between two sampling instances (i.e. (C(t_i)-C(t_i-1))/(t_i-t_i-1)) but it tends not to work well, as sometimes the difference is weeks and the differentiation is stable, but sometimes it is only hours and thus, very noisy. Adding additional smoothing drains out the signal more ... Is there a canonical way to work with data like that? Is there a standard way to handle this?
