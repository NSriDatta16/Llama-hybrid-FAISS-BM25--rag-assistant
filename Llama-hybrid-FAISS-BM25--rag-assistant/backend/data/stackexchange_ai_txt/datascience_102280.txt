[site]: datascience
[post_id]: 102280
[parent_id]: 
[tags]: 
after overcoming the overfitting, how to increase training accuracy?

I am building a CNN using keras for a classification task. I started with a simple model as a starting point and as almost all ML problems go, especially if the dataset is not very big, I faced an almost immediate major overfitting as you can see in graph In order to try to overcome this overfitting I started with reducing the network size to half of its size (half the number of units per layer) and adding L2 weight regulaizers which improved the overfitting a little as you can see here then I added droput layers which also helped especially with the noise in the validation curve After this, in order to increase the training data I used data augmentation with the ImageDataGenerator class from keras which works as expected (decreasing the train metrics while improving the validation metrics) and seems to help a lot with the overfitting As the validation curves start to follow the training curves, it seems like the task now is how to improve the training metrics and here comes my question, the training metrics are almost stable after 10 epochs and they don't improve no matter how many epochs are increased and the only thing I could think of trying is trying to reduce the learning rate when the training accuracy stops improving, so I added a ReduceLROnPlateau callback which reduces the learning to 20% of the previous one if the training accuracy doesn't increase for 3 epochs but this doesn't do the trick, the training accuracy is still stuck around 90-92% So, I am wondering if there is anything else that could help increasing the training accuracy or is it just a lack of data problem and the only possible solution is to increase the dataset.
