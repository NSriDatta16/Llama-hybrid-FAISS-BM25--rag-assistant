[site]: datascience
[post_id]: 6459
[parent_id]: 
[tags]: 
What features from sound waves to use for an AI song composer?

I am planning on making an AI song composer that would take in a bunch of songs of one instrument, extract musical notes (like ABCDEFG) and certain features from the sound wave, preform machine learning (most likely through recurrent neural networks), and output a sequence of ABCDEFG notes (aka generate its own songs / music). I think that this would be an unsupervised learning problem, but I am not really sure. I figured that I would use recurrent neural networks, but I have a few questions on how to approach this: - What features from the sound wave I should extract so that the output music is melodious? - Is it possible, with recurrent neural networks, to output a vector of sequenced musical notes (ABCDEF)? - Any smart way I can feed in the features of the soundwaves as well as sequence of musical notes?
