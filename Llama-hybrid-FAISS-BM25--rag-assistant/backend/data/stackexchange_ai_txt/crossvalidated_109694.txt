[site]: crossvalidated
[post_id]: 109694
[parent_id]: 
[tags]: 
Using empirical null distribution to adjust odds ratios

I am doing a case-control study analysis with 2500 cases and 2500 controls. I am interested in finding out if the cases have higher odds of having a particular disease than the controls, so I am calculating odds ratios for each of the 1000 diseases using a logistic regression model. I want to know which odds ratios > 1 are actually significant enough to the point where I can say that the case is at higher risk for the disease than the control. To do so, I employed Efron's method of estimating the empirical null distribution and local FDR values (link: http://www.uni-leipzig.de/~strimmer/lab/courses/ss06/seminar/papers/B/efron2004.pdf ). Most of the odds ratios should be 1 (betas are 0), corresponding to z-value of 0. When I estimate the empirical null distribution, it is not distributed ~ N(0, 1) but rather N(mu, sigma). So this allows me to identify significant odds ratios. However, I want to know if I can transform the odds ratios using the empirical null distribution as such: z-value for beta coefficients is equal to coefficient/standard error. z-values are distributed N(mu, sigma). Normalize the z-values: (z - mu)/sigma. Multiply the new z-values by the standard error. Now, you have new coefficients and odds ratios, which have a more accurate distribution of odds ratios (most of them are around 1). Is this a valid approach?
