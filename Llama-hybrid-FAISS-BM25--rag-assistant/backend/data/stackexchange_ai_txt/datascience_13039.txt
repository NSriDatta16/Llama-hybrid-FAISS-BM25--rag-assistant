[site]: datascience
[post_id]: 13039
[parent_id]: 13010
[tags]: 
Wrong question. Big data is not a question of this or that language, but cluster computing. For me it's implicit in the definition; if you can find a way to process your data on your laptop it just isn't big data. Spark is the de facto standard today for cluster computing. It comes with many of its own munging primitives, borrowed from numerous languages (think dataframes and functional programming), and bindings to them. Scala is the best language in terms of Spark API coverage, followed by python, then R. If you want to experiment with Spark you can rent managed instances from Google on DataProc or spin up your own .
