[site]: crossvalidated
[post_id]: 401453
[parent_id]: 345196
[tags]: 
"The task of the agent is to learn from this indirect , delayed reward, to choose sequences of actions that produce the greatest cumulative reward" - Machine Learning, Tom Mitchell. The same being said in many other sources. My understanding is, in Reinforcement Learning rewards are indirect way of telling the agent what is right and wrong unlike in Supervised Learning we directly give an output to input and let the model learn the function. There are also direct and indirect rewards in multi-agent reinforcement learning. This is a different context.
