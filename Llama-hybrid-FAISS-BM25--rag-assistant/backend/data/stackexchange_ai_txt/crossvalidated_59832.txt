[site]: crossvalidated
[post_id]: 59832
[parent_id]: 59829
[tags]: 
Bootstrapping is a resampling method to estimate the sampling distribution of your regression coefficients and therefore calculate the standard errors/confidence intervals of your regression coefficients. This post has a nice explanation. For a discussion of how many replications you need, see this post. The nonparametric bootstrap resamples repeatedly and randomly draws your observations with replacement (i.e. some observations are drawn only once, others multiple times and some never at all), then calculates the logistic regression and stores the coefficients. This is repeated $n$ times. So you'll end up with 10'000 different regression coefficients. These 10'000 coefficients can then be used to calculate their confidence intervals. As a pseudo-random number generator is used, you could just set the seed to an arbitrary number to ensure that you have exactly the same results each time (see example below). To really have stable estimates, I would suggest more than 1000 replications, maybe 10'000. You could run the bootstrap several times and see if the estimates change much whether you do 1000 or 10'000 replications. In plain english: you should take replications until you reach convergence. If your bootstrap estimates vary between your estimates and the observed, single model, this could indicate that the observed model does not appropriately reflect the structure of your sample. The function boot in R , for example, puts out the "bias" which is the difference between the regression coefficients of your single model and the mean of the bootstrap samples. When performing the bootstrap, you are not interested in a single bootstrap sample, but in the distribution of statistics (e.g. regression coefficients) over the, say, 10'000 bootstrap samples. I'd say 10'000 is better than 1000. With modern Computers, this shouldn't pose a problem. In the example below, it took my PC around 45 seconds to draw 10'000 samples. This varies with your sample size of course. The bigger your sample size, the higher the number of iterations should be to ensure that every observation is taken into account. What do you mean "the results vary each time"? Recall that in every bootstrap step, the observations are newly drawn with replacement. Therefore, you're likely to end up with slightly different regression coefficients because your observations differ. But as I've said: you are not really interested in the result of a single bootstrap sample. When your number of replications is high enough, the bootstrap should yield very similar confidence intervals and point estimates every time. Here is an example in R : library(boot) mydata $rank rank) my.mod |z|) (Intercept) -3.989979 1.139951 -3.500 0.000465 *** gre 0.002264 0.001094 2.070 0.038465 * gpa 0.804038 0.331819 2.423 0.015388 * rank2 -0.675443 0.316490 -2.134 0.032829 * rank3 -1.340204 0.345306 -3.881 0.000104 *** rank4 -1.551464 0.417832 -3.713 0.000205 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 # Set up the non-parametric bootstrap logit.bootstrap The bootstrap-ouput displays the original regression coefficients ("original") and their bias, which is the difference between the original coefficients and the bootstrapped ones. It also gives the standard errors. Note that they are bit larger than the original standard errors. From the confidence intervals, the bias-corrected ("bca") are usually preferred. It gives the confidence intervals on the original scale. For confidence intervals for the odds ratios, just exponentiate the confidence limits.
