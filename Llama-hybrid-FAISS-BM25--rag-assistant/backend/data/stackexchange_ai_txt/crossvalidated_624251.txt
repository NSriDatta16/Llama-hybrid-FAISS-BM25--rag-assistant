[site]: crossvalidated
[post_id]: 624251
[parent_id]: 624198
[tags]: 
As I mentioned in the comment, mixed/hierarchical/multilevel models are the general way to address this form of non-independence. The model is modified to deal with the correlations between points measured on the same individuals by adding what is called a random effect . The simplest form of this is a random intercept, in which each individual's predictions are offset from the population mean by a constant value, and those values are generally assumed to be drawn from a normal distribution. This is an excellent thread introducing the topic: What is the difference between fixed effect, random effect and mixed effect models? . I recommend taking a look at it and our many other useful threads tagged mixed-model , because there are some subtle issues to keep in mind when fitting and interpreting them. In your case, because you have a binary response, you need a Generalised Linear Mixed Model (GLMM) with an appropriate link function (link functions allow you to predict responses with non-Gaussian distributions). Here's an example of how you can do this in R . library(lme4) glmer(Trip_Chain_complexity ~ Gender + Employment + Age + (1 | Person_ID), data = dat, family = binomial) The (1 | Person_ID) term at the end indicates the random intercept. This model can be extended to allow for random slopes , which are a topic worth visiting when you have a good grasp of the basics. This can also be addressed in a Bayesian framework, of course, and the brms package is a good place to start if you'd like to try that. rstan is the more complex and presumably full-featured package for this. The hierarchical-bayesian tag has plenty of relevant threads on this. EDIT: Peter Flom makes some good points below in his comment (and in his answer, +1). If your dataset is small and the snippet here is representative of it, then the model I coded above may not be identifiable . This is less of a concern in Bayesian statistics and so the brms / rstan approach should still work fine. This blog post by Andrew Gelman discusses identifiability from a Bayesian perspective: https://statmodeling.stat.columbia.edu/2014/02/12/think-identifiability-bayesian-inference/ The basic syntax for the model above is identical in brms : library(brms) brm(Trip_Chain_complexity ~ Gender + Employment + Age + (1 | Person_ID), data = dat, family = binomial) brms chooses default priors that will work but it's much better if you set them yourself based on your knowledge. There are also a number of other settings that it would help to change, such as the number of iterations to run the chains for, and the number of cores. It has good vignettes online that you can use to understand this better: https://paul-buerkner.github.io/brms/articles/
