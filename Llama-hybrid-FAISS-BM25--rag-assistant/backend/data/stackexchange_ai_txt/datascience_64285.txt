[site]: datascience
[post_id]: 64285
[parent_id]: 
[tags]: 
How to estimate the marginal distribution of a class with respect to one predictor in a classification task?

I have a dataset with a binary dependent variable $y \in \{0,1\}$ and a set of predictors $x1,x2,..,t$ . Here, $t$ is the time in minutes (in 24 hrs, that is $t \in (0,1440)$ ). I want to estimate the marginal probability distribution of $y$ with respect to $t$ . I am approaching this problem as a binary classification task and creating a classifier with all $x1,x2,..,t$ predictors, then, am planning to vary $t$ between 0 to 1440 and try to estimate the probabilities. Will this work? Is there any efficient method to do this? Also, please suggest some machine learning/deep learning algorithms for this task? I am betting on RF, Xgboost, Deep Neural networks. I have 84k records. (Note that I want to estimate $P(y=1|\{x1..t_i\}$ , probability of y=1 as time increases over the day)
