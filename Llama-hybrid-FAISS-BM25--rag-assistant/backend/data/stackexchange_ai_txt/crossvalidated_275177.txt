[site]: crossvalidated
[post_id]: 275177
[parent_id]: 275164
[tags]: 
These two parameters are also called as Kernel Hyper parameters. When the length scales $l$ become larger then the sampled functions become flatter and vice versa. The amplitude of the sampled functions become larger when $\sigma_f$ become larger and the functions become more wiggly shaped. Please refer the figure and the book by Prof Rasmussen (Gaussian Processes for Machine Learning). So, the values taken up by these two parameters are of extreme importance in interpolations as the next input point to be search at for the response value. If the code misses the input point due abnormal kernel hyper parameters, then computer has to search for more and thus before convergence it has to work for more iterations.
