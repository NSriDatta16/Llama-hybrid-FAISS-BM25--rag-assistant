[site]: crossvalidated
[post_id]: 100532
[parent_id]: 100527
[tags]: 
There's no way to estimate what large or small Ns are unless you have some estimate of effects. So, the first thing you need to do is work out the range of plausible effect sizes. That will vary across models and model parameters. That's OK. The observed effects will also vary across studies with significant findings with the observed effects being higher in low N studies. You already recognize that findings of low N studies are less plausible so you should get a weighted average effect placing more value on the large N findings. Essentially, you need to first do a meta-analysis before critiquing the Ns. After that you could use power analysis to work out cutoffs for adequate sample sizes. If you have a reasonable estimate of the effect then it's pretty simple. For example, if you have an effect size of 0.6 using t-tests then anything under 30 subjects per group is going to be less than 60% of finding the effect. With 45/group you get a power of 0.8 but you have to go all the way up to 60 to get 0.9. I'm not suggesting those levels per se but you should be able to come up with a reasonable argument to pick some values. Even better would be to just report the post-hoc power of the studies using the aggregate effect size (or range of power from plausible range of effect sizes). This could be used as a way to generate a critique of the subject numbers in studies without having to generate some arbitrary cutoffs.
