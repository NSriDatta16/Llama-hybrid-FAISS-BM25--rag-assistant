[site]: crossvalidated
[post_id]: 140394
[parent_id]: 
[tags]: 
Estimating conditional effect of logistic regression

I'd like to examine the conditional effect of a new variable, say $\mathbf{Z}$, on a logistic regression previously fit to my response vector $\mathbf{Y}$ using the predictor(s) $\mathbf{X}$. Say that the logistic regression has already been fit to the predictors $\mathbf{X}$ and that I can't/don't want to change the coefficients associated with $\mathbf{X}$. (The dataset used to fit this logistic regression was "better" in some sense than the dataset that follows, but did not contain $\mathbf{Z}$.) I'd now like to add $\mathbf{Z}$ to my set of predictors. (Although the dataset I'm using is "worse", I still feel it's good enough to estimate the effect of $\mathbf{Z}$.) But I only want the effect of $\mathbf{Z}$ on $\mathbf{Y}$ given by current predictions based on $\mathbf{X}$. I know that, since these models are nested, I can use the Deviance to conduct a hypothesis test of whether or not to include $\mathbf{Z}$ in the new model (under the assumption that the coefficients on $\mathbf{X}$ could be changed), but what about the actual parameter estimates? In the linear regression case, I could simply fit a regression using $\mathbf{Z}$ to the residuals of the model based on $\mathbf{X}$ but this is problematic in the logistic regression setting, since the residuals don't exist in their usual sense. I have been performing an optimization by minimizing the log-loss with respect to $\mathbf{Z}$ while keeping the coefficients on $\mathbf{X}$ constant. This workaround doesn't give me the standard errors I'd like, although I can repeat this procedure on subsamples of the data to get an estimate of this (assuming I have enough data). Is there an alternative (better) way to do this?
