[site]: crossvalidated
[post_id]: 28814
[parent_id]: 28813
[tags]: 
Indeed, as you have mentioned it yourself, the lack of independence (and relevance) of the explanatory variables is crucial. Also, it is not a surprise at all that Random Forest is behaving in a much better way than a Naive Bayes classifier since it is much more robust to overfitting, especially in your situation where you have almost five times more explanatory variables than observations. Virtually any 'ensemble method' will do better than a simple Naive Bayes classifier. You could try to do an ensembling of Naives Bayes classifier, in the spririt of what is described in this short text .
