[site]: crossvalidated
[post_id]: 333373
[parent_id]: 333332
[tags]: 
The condition for the probability distribution with density $\pi(\cdot)$ to be stationary for the Markov transition kernel $K$ with density $k(\cdot|\cdot)$ is that, for all measurable sets $A$ $$\pi(A)=\int_A \left\{\int\pi(\theta)k(\theta'|\theta)\text{d}\theta\right\}\text{d}\theta'$$ so indeed detailed balance does not have to hold for $K$ to be a correct transition kernel. In the Metropolis-Hastings special case, the transition kernel $K$ is decomposed as $$K(\text{d}\theta'|\theta)=\alpha(\theta'|\theta)P(\theta'|\theta)\text{d}\theta'+(1-\varrho(\theta))\delta_{\theta}(\text{d}\theta')$$where $\text{d}\theta$ denotes the dominating measure of the target distribution (Lebesgue, counting &tc.), $\delta_\theta$ denotes the Dirac mass at $\theta$ and $$\varrho(\theta)=\int \alpha(\theta'|\theta)P(\theta'|\theta)\text{d}\theta'$$is the average acceptance probability when the Markov chain is standing at $\theta$. With regard to your questions, $\alpha(\theta'|\theta)$ is customarily called the acceptance probability , not the transition probability as the Markov chain does not necessarily move from its current value $\theta$ to the next value $\theta'$, which can thus be rejected. The term transition probability is attached to the kernel $K$; Computing the product $\alpha(\theta'|\theta)P(\theta'|\theta)$ may prove handy to decide on the acceptance or rejection of the proposed value $\theta$ but in most situations the proposed value $\theta'$ must be simulated first. In any case, (i) the acceptance probability does not become$$\min\{1,\pi(\theta')/\pi(\theta)\}$$and (ii) the product $\alpha(\theta'|\theta)P(\theta'|\theta)$ is not a probability distribution. In a paper with Randal Douc , we devised an approach that relates to this product, called vanilla Rao-Blackwellisation by integrating out the rejection step. That is, we considered only the accepted values and weighted them by their estimated number of replications: since an MCMC estimator of $\mathbb{E}[h(\theta)]$ writes as $$\hat{h}=\frac{1}{T}\sum_{t=1}^T h(\theta^T)$$ for a Markov chain $(\theta^t)$, it also writes as $$\hat{h}=\frac{1}{T}\sum_{i=1}^{I_T} n_i h(\xi^i)$$ where the $\xi^i$'s are the distinct values in the sequence $\{\theta^1,\ldots,\theta^T\}$ and the $n_i$'s the numbers of times they are repeated. Since this number $n_i$ is a Geometric rv with probability $\varrho(\xi^i)$, its expectation is $1/\varrho(\xi^i)$, which can be unbiasedly estimated. This step improves the variance of the MCMC estimator, but does not modify running simulations from $P(\cdot|\theta)$. There also exist other versions of the Metropolis-Hastings algorithm where the decision to reject is taken before the new value $\theta'$ is simulated from $P(\cdot|\theta)$, called delayed acceptance .
