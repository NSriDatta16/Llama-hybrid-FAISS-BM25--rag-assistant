[site]: datascience
[post_id]: 121497
[parent_id]: 
[tags]: 
LSTM multivariate time-series with categorical, numerical and non-temporal inputs

I have a dataset that contains different data types and I'm working on a prediction task of dataset features with LSTM network, but I'm struggling in finding the right way to construct the neural network. These are an example of the features I have: Temporal one-hot encoded data about activity sequences. For example, activity sequence A-B-C is represented as [[1,0,0],[0,1,0],[0,0,1]] . Temporal numerical data about timestamp of the activities (normalized). For example, for the first sample I have activity A-B-C and the related vector of timestamps is [0,0.2,0.5] . Non-temporal one-hot encoded data about country. For example France is represented as [1,0,0,0] . Non-temporal one-hot encoded data about the object type. For example a desk is represented as [0,1,0] . Each sample in the dataset have all these four features. At each timestep, the first two information change, while the last two remain fixed for the whole sample. I'm performing different prediction experiments. In the first experiment I need to predict the next activity, in the second experiment I have to predict the timestamp of the next activity. I'm currently approaching the task with two different neural network, since the second prediction is related to the output of the first one. I'm currently getting high accuracy score with different configuration, but I want to understand the correct way to approach the problem. The first two features need to be fed to LSTM layers. I understand that concatenating the vectors at the beginning, creating for example a vector [[1,0,0,0],[0,1,0,0.2],[0,0,1,0.5]] , is not the right way to approach the problem since they have two different representation. So I think I can fed the data to two different LSTM layers in parallel, and then concatenate the outputs. Is this the right way? My concers about this method is that the timestamp information is related to the activities information (I'm using the timestamp feature to help the network in the prediction task), since each timestamp refers to one activity. Is there a way to concatenate one-hot encoding and numerical data? Will I lose information if I separate the two inputs? Regarding the non-temporal features, should I concatenate the vectors, getting for example the vector [1,0,0,0,0,1,0] and then pass it through a Dense layer? Is it right to fed the network with a vector like this, which is not normalized? I thought of passing each input through a Dense layer, then concatenate the outputs and pass through another Dense layer and then concatenate with the LSTM output. The image shows the architecture I'm currently using, where each inputs pass though a layer first, but I would like to find a way to aggregate at least the non-temporal information, since I have so many non-temporal features.
