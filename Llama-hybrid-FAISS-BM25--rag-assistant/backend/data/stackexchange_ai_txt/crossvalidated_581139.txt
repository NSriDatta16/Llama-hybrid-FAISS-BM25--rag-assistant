[site]: crossvalidated
[post_id]: 581139
[parent_id]: 
[tags]: 
Reasonable to incorporate sample size into beta-binomial?

Setup: The relationship between the beta and binomial distributions is well known. $$\frac{\pi^{\alpha - 1} (1 - \pi)^{\beta - 1}}{B(\alpha, \beta)} \leftrightarrow {{n}\choose{x}}\pi^{x} (1 - \pi)^{n-x}$$ By comparing the two, one can see: $\alpha - 1$ is analogous to the number of successes, $x$ $\beta - 1$ is analogous to the number of failures, $n-x$ , and thus $\alpha + \beta - 2$ is analogous to the number of trials, $n$ . I am faced with the problem of testing whether two independent binomial random variables of different size have the following relation: First we observe a random binomial, $X_1 \sim Bin(n_1, p_1)$ . Later, we observe another random binomial, $X_2 \sim Bin(n_2, p_2)$ . $H_0: p2 = 0.65p_1$ $H_a: p2 \ge 0.65p_1$ My thought is to take a Bayesian approach. If I assume an uniform prior for $\pi_1$ , $\pi_1 \sim Beta(1,1)$ , then the posterior distribution is $\pi_1 | x_1 \sim Beta(x_1 + 1, n_1 - x_1 + 1)$ Question: Is it reasonable to do the following? Since we know the outcome of the first trial $\{x_1, n_1\}$ , as well as the size of the second trial, $n_2$ , I want to choose $\alpha_2$ and $\beta_2$ such that: $\frac{\alpha_2}{\alpha_2 + \beta_2} = \frac{13}{20} \frac{x_1 + 1}{n_1 + 2}$ , and $\alpha_2 + \beta_2 = n_2 + 2$ This suggests choosing the following values of $\alpha_2$ and $\beta_2$ : $\alpha_2$ $$ \begin{align} \frac{\alpha_2}{\alpha_2 + \beta_2} = \frac{\alpha_2}{n_2 + 2} & = \frac{13}{20} \frac{x_1 + 1}{n_1 + 2} \\ \alpha_2 & = \frac{13}{20} \frac{x_1 + 1}{n_1 + 2} (n_2 + 2) \end{align} $$ This intuitively make sense, since we believe the number of successes, $x_2$ , will be roughly $\frac{13}{20} p_1$ of the $n_2$ trials (i.e. $\alpha_2 + \beta_2 = n_2 + 2$ ). $\beta_2$ $$ \begin{align} \beta_2 = n_2 + 2 - \alpha_2 & = n_2 + 2 - \frac{13}{20} \frac{x_1 + 1}{n_1 + 2} (n_2 + 2) \\ & = \left(1 - \frac{13}{20} \frac{x_1 + 1}{n_1 + 2}\right) (n_2 + 2) \end{align} $$ So, the prior would be $\pi_2 \sim Beta\left(\frac{13}{20} \frac{x_1 + 1}{n_1 + 2} (n_2 + 2), \left(1 - \frac{13}{20} \frac{x_1 + 1}{n_1 + 2}\right) (n_2 + 2)\right)$ Then the posterior distribution is $\pi_2 | x_2 \sim Beta\left(\frac{13}{20} \frac{x_1 + 1}{n_1 + 2} (n_2 + 2) + x_2, \left(1 - \frac{13}{20} \frac{x_1 + 1}{n_1 + 2}\right) (n_2 + 2) + n_2 - x_2\right)$ Is this reasonable? Thanks for any thoughts you have on the matter. EDIT: Based on Whuber's critique (and whuber is a stats.stackexchange God), perhaps I can replace the $n_2 + 2$ in my prior specification of $\pi_2$ with some other constant, $k$ ? This would maintain my assumption that $E(\Pi_2) = \frac{13}{20}E(\Pi_1)$ , but I can adjust $k$ to modify the variance and thereby reflect my confidence in the chosen value? So, the prior would be $\pi_2 \sim Beta\left(k * \frac{13}{20} \frac{x_1 + 1}{n_1 + 2}, k * \left(1 - \frac{13}{20} \frac{x_1 + 1}{n_1 + 2}\right) \right)$ Then the posterior distribution is $\pi_2 | x_2 \sim Beta\left(k * \frac{13}{20} \frac{x_1 + 1}{n_1 + 2} + x_2, k * \left(1 - \frac{13}{20} \frac{x_1 + 1}{n_1 + 2}\right) + n_2 - x_2\right)$
