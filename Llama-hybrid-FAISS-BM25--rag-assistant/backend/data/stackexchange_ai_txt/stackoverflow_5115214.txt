[site]: stackoverflow
[post_id]: 5115214
[parent_id]: 5112992
[tags]: 
The main issue with writing to the disk is that the time taken to write is not a linear function of the number bytes, but an affine one with a huge constant. In computing terms, it means that, for IO, you have a good throughput (less than memory, but quite good still), however you have poor latency (a tad better than network normally). If you look at evaluation articles of HDD or SSD, you'll notice that the read/write tests are separated in two categories: throughput in random reads throughput in contiguous reads The latter is normally significantly greater than the former. Normally, the OS and the IO library should abstract this for you, but as you noticed, if your routine is IO intensive, you might gain by increasing the buffer size. This is normal, the library is generally tailored for all kinds of uses and thus offers a good middle-ground for average applications. If your application is not "average", then it might not perform as fast as it could.
