[site]: crossvalidated
[post_id]: 247311
[parent_id]: 
[tags]: 
Deep learning: Loss change dramatically every epoch

I am using Keras for building a Siamese neural network, two inputs have the following format: x[:, 0]: shape is (20000, 600), each array looks like [12, 23, 3, 16...0, 0, 0...] x[:, 1]: shape is (20000, 600), each array looks like [7832, 12342, 8976, 1642...0, 0, 0...] model.fit([x[:, 0],x[:, 1]], y, batch_size=64, nb_epoch=10) After I used the fit function, the loss would changed dramatically. Epoch 1/10 20000/20000 [==============================] - 3s - loss:26157091.5761 Epoch 2/10 20000/20000 [==============================] - 1s - loss: 26103.3771 Epoch 3/10 20000/20000 [==============================] - 1s - loss: 66322.9797 Epoch 4/10 20000/20000 [==============================] - 1s - loss: 33068.0571 Epoch 5/10 20000/20000 [==============================] - 1s - loss: 3271.2368 Epoch 6/10 20000/20000 [==============================] - 1s - loss: 124758.9755 Epoch 7/10 20000/20000 [==============================] - 1s - loss: 11452.0805 Epoch 8/10 20000/20000 [==============================] - 1s - loss: 31291.7847 Epoch 9/10 20000/20000 [==============================] - 1s - loss: 2562.3131 Epoch 10/10 20000/20000 [==============================] - 1s - loss: 0.4973 * Accuracy on training set: 50.00% Epoch 1/10 20000/20000 [==============================] - 3s - loss: 23972822.8330 Epoch 2/10 20000/20000 [==============================] - 1s - loss: 31353.3295 Epoch 3/10 20000/20000 [==============================] - 1s - loss: 33149.6620 Epoch 4/10 20000/20000 [==============================] - 1s - loss: 22481.5665 Epoch 5/10 20000/20000 [==============================] - 1s - loss: 103161.4879 Epoch 6/10 20000/20000 [==============================] - 1s - loss: 11121.0753 Epoch 7/10 20000/20000 [==============================] - 1s - loss: 122371.6265 Epoch 8/10 20000/20000 [==============================] - 1s - loss: 49855.2024 Epoch 9/10 20000/20000 [==============================] - 1s - loss: 41485.7752 Epoch 10/10 20000/20000 [==============================] - 1s - loss: 2243.4557 * Accuracy on training set: 50.05% ...... I am thinking of this issue possibly was caused by the difference of x[:,0] and x[:,1] though they have same shape and same dimension. Do I need to do the normalization to make two inputs into the same range( like 0 to 1)?
