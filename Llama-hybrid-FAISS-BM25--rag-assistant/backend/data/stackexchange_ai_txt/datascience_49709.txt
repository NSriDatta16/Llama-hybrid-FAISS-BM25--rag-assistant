[site]: datascience
[post_id]: 49709
[parent_id]: 
[tags]: 
What is the best architecture for Auto-Encoder for image reconstruction?

I am trying to use Convultional Auto-Encoder for its latent space (embedding layer), specifically, I want to use the embedding for K-nearest neighbor search in the latent space (similar idea to word2vec). My input is 3x224x224 (ImageNet), I could not find any article that elaborates a specific architecture (in terms of number of filters, number of conv layers, etc.) I tried some arbitrary architectures like: Encoder: Conv(channels=3,filters=16,kernel=3) Conv(channels=16,filters=32,kernel=3) Conv(channels=32,filters=64,kernel=3) Decoder: Deconv(channels=64,filters=32,kernel=3) Deconv(channels=32,filters=16,kernel=3) Deconv(channels=16,filters=3,kernel=3) But I'd like to start my hyper-parameters search from a set up that proved itself on a similar task. Can you refer me to a source or suggest an architecture that worked for you for this purpose?
