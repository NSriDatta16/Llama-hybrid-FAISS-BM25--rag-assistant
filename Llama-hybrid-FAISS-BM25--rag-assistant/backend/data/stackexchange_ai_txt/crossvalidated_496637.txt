[site]: crossvalidated
[post_id]: 496637
[parent_id]: 
[tags]: 
Why is my training curve and validation curve on the same level and how to find a proper architecture for an ANN?

I have build a neural network model. All in all it doesn't work properly, but since it is part of my Master Thesis I've to evaluate it and find some explanations. The learning curve looks like this: And the validation curve looks like this: Some questions to this: How can it be that learning and validation curves for training and validation are quite the same? Is there an error in the model or is this quite common (for underfitting models)? How to find the best architecture of a MLPClassifier? I have 7 input features and 7 classes in the target (~ 800.000 datapoints). If I start with 1 hidden layer and 10 neurons, I get an acc of ~43 %. If I increase the number of layers and neurons, the acc gets better, up to ~ 55-60%, but the validation time is also increasing very much. For example: training and validation with 1 layer and 10 neurons lasts up to a few minutes, and training and validation with 100 in one, two or three layers takes hours. When should I stopp with increasing the number of neurons and layers, what is a sufficient training time and when does it take definetely too long? The code: from sklearn.model_selection import learning_curve start_time = time.time() train_sizes, train_scores, test_scores =\ learning_curve(estimator = MLPClassifier(hidden_layer_sizes = (100,), max_iter=500), X = X_train, y = y_train, train_sizes = np.linspace(0.1,1,5), cv = 3, n_jobs = -1) elapsed_time = time.time() - start_time time.strftime("%H:%M:%S", time.gmtime(elapsed_time)) train_mean = np.mean(train_scores, axis=1) train_std = np.std(train_scores, axis=1) test_mean = np.mean(test_scores, axis=1) test_std = np.std(test_scores, axis=1) plt.plot(train_sizes, train_mean, color = "blue", marker = 'o', markersize = 5,label ='Training accuracy') plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color = 'blue') plt.plot(train_sizes, test_mean, color='red', linestyle = '--', marker = 's',markersize = 5, label = 'Validation accuracy') plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color = 'green') plt.grid() plt.xlabel('Number of training examples') plt.ylabel('Accuracy') plt.legend(loc = 'lower right') plt.ylim([0.25, 1.01]) plt.show Thanks for help ---EDIT--- I am trying to classify soil classes based on laboratory tests but with data from field tests (CPT) as input. There are 7 soil classes which can be classified and the data from the field test has no known empirical or statistical relationship with the classes, so basically I am trying to find those patterns with the machine learning model...
