[site]: crossvalidated
[post_id]: 495728
[parent_id]: 
[tags]: 
Custom scoring function random forest classification

I am using scikit-learn to build a classifier which receives an imput X (vector of size 784 which is a 28x28 image representing a hand-written digit from 0 to 9) and predicts the number that is present on the image. Instead of using traditional accuracy, I would like the algorithm to penalize more the cases when digits from {5, 6, 7, 8, 9} are predicted to be from {0, 1, 2, 3, 4}. From what I understand it is not possible to change the loss function of a sklearn classifier so I have tried to change the scoring function used through GridSearchCV to tune the hyperparameters. Here is the custom scoring function I wrote : def loss_fn(y_true,y_pred): loss_score = 0 N = len(y_true) for i in range(N): if y_true[i] != y_pred[i]: if int(y_true[i]) >= 5 and int(y_pred[i]) It is a very naive function that accounts for 2 when a digit from {5, 6, 7, 8, 9} is predicted to be from {0, 1, 2, 3, 4} and 1 when the classifier makes a "normal" mistake. Here is my Random Forest classifier ? from sklearn.ensemble import RandomForestClassifier rfc = RandomForestClassifier() param_grid = { 'n_estimators': [600, 800, 1000, 1200], 'max_features': ['auto', 'sqrt', 'log2'] } custom_scorer = make_scorer(loss_fn) clf = GridSearchCV(rfc, param_grid, cv=3, scoring = custom_scorer) clf.fit(X_train, y_train) print('Returned hyperparameter: {}'.format(clf.best_params_)) print('Best classification accuracy in train is: {}'.format(clf.best_score_)) print('Classification accuracy on test is: {}'.format(clf.score(X_test, y_test))) Actually when I use the custom function and I try to classifiy my testing dataset I have one more digit from {5, 6, 7, 8, 9} are predicted to be from {0, 1, 2, 3, 4} than what I get without any custom function. So, it doesn't work at all and I wonder why... Is my custom scoring function too naive ? Am I making a mistake in the implementation ? Is the lack of results due to the fact that changing the scoring function makes very little difference giving the loss function on which the algorithm is trained remains unchanged ? Should I put more parameters in the param_grid ?
