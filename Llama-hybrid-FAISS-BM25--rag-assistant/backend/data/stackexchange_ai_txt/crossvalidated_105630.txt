[site]: crossvalidated
[post_id]: 105630
[parent_id]: 101003
[tags]: 
I assume you are not limited to R, since this is a big data problem you probably shouldn't be. You can try MLlib , which is Apache Spark's scalable machine learning library. Apache Spark , in turn, is a fast and general engine for in-memory large-scale data processing. These operate on a Hadoop framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Note that 'thousands of machines' is optional(!), you can set it up on your local work/home desktop as well. Going back to MLlib, it comes with the below algorithms out of the box: K-means clustering with K-means|| initialization. L1- and L2-regularized linear regression. L1- and L2-regularized logistic regression. Alternating least squares collaborative filtering, with explicit ratings or implicit feedback. Naive Bayes multinomial classification. Stochastic gradient descent. If you are regularly working with big data, you may need to adopt a Hadoop solution.
