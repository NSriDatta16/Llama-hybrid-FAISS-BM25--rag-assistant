[site]: crossvalidated
[post_id]: 314715
[parent_id]: 312610
[tags]: 
There is some confusion in the question I'll try to clarify. You say you want to find " how much better " one sensor is compared to the other. But the data and method only addresses finding out how far they are from each-other , which is not the same at all. The fact is the first problem (how much better) can't be estimated with these data. The second problem can be solved a bit the way you do. To explain the key difference, I'll simplify the problem a bit and assume that each sensor is just equal to the measured variable plus noise. You measure a value $X$ with two sensors $Y_1,Y_2$ with noise. You can't see $X$. Formally: $Y_1=X+\epsilon_1$ $Y_2=X+\epsilon_2$ Thus $Y_2=Y_1+(\epsilon_2-\epsilon_1)$ There is a small problem regarding the independence of noises, but ignoring this "detail", you can measure the variance of $\epsilon_2-\epsilon_1$ as the average squared difference. Adding linear dependence makes the problem a little trickier, linear regression can be used carefully. I don't focus on this. What I wanted to clarify is that this method does not tell you how much one sensor is better than the other. This just tells you how far they are from each other. You cannot know: the variance of each $\epsilon_2$ and $\epsilon_1$ nothing such as a ratio of these variances not even which sensor is better A case would be that $Y_1$ is perfect and the difference is $Y_2$'s fault, the other way round, or any situation in between. There is absolutely no way you can know this with such data. The only way you can approach this problem is assuming something about the dynamics of $X$ across measurements. If you assume $X$ is constant for example, then you can estimate the variance of $\epsilon_1$ using basic variance estimator. Same for $\epsilon_2$. If $X$ evolves in a more complicated way, you can see it as an hidden state and use the Kalman filter. It's not easy to do.
