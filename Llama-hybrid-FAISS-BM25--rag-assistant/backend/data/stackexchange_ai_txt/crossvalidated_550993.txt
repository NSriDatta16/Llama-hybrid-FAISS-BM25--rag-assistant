[site]: crossvalidated
[post_id]: 550993
[parent_id]: 550991
[tags]: 
Adding my guess as an answer. When splitting the data into train/test sets you do a 0.8/0.2 split. Which, with the sample size of 500, should be 400/100. Then you train kNN on 400 and test the accuracy on the remaining 100. If the split is random, then the class balance will not be equal. Hence, the classifier will learn to predict the more frequent class on the training set, but due to the split the same class will be less frequent in the remaining (test) set. As a result, after the point the classifier starts to always return the more frequent class, your error, will be less than 50% on the training data but more than 50% on the testing data. Your error (close to 55%) is also consistent with this interpretation. Here is a quick R simulation (ran 10000 times) to check the average error we expect on the testing set with such a strategy: mean(replicate(10000, max(table(sample(rep(letters[1:2], each=250), 100))))) [1] 53.5586 NOTE: for the simulation I didn't do any classification but simply simulated drawing random 100 samples out of equally balanced set of 500 samples and checking the frequency of higher class (the class your method would misclassify at k = 400). For why this starts to happen at around k=385 - my guess is that this is the breaking point when the classifier starts to simply predict the most frequent class. Or in other words - within your training data there is about 15 samples worth of imbalance between the classes. And up to that point the classifier fluctuates between one class and another, but after this point each additional neighbour will be of the majority class.
