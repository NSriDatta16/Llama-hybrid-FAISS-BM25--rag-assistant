[site]: crossvalidated
[post_id]: 269893
[parent_id]: 
[tags]: 
2D convolution with depth

Lets say I have a convolutional neural network where my input images are of dimensions 25x25x3 (3 depth channels for colour) and pass it through a convolution layer of 5 kernels, each 3x3 The depth of each kernel will always be the same as the input depth, so my kernels are actually 3x3x3 The layer will convolve each 3x3x3 kernel over the 25x25x3 input image. Each kernel convolution will produce a 25x25x1 feature map (which then get stacked to produce the output volume of 25x25x5) I'm confused as to how 2D convolutions (with depth 3) produce a feature map with only depth 1 I'm imagining separate convolutions over the spatial dimensions (3x3 over 25x25, separately for each of the 3 depth channels). How do the spatial convolutions across 3 depth channels then get condensed down to 1 output depth channel (for each kernel)? What is the operation there? Is it simply summation? max? or something else?
