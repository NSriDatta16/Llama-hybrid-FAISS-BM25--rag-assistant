[site]: datascience
[post_id]: 5162
[parent_id]: 2504
[tags]: 
In addition to other answers (and there's some good link in the comments) it depends on what the problem is or what kinds of questions you want to answer. As I can only suggest based on my own experience, then in case of a classification task, the possible methods can be severely limited based on class balance in dataset. Once you go to a larger than around 1:10 class imbalance, then most classification methods just stop working. You'll be left with methods based on random forest and maybe neural nets (haven't tried yet). I work with the class balance in the range of 1:500 to 1:1000 and have found that neither down- or upsampling works. Luckily my dataset is "only" 6mln observations by 200 variables and I'm able to run boosted trees on the whole set in reasonable time. So to directly answer your question: you should come up with a bunch of questions you would want to answer and in case of classification then check the class balances of the target variables. you should check the distribution (not in mathematical sense) of missing values in all of your data and document what you find. Some ML methods are fine with missing values while others are not and you need to look into data imputation (which has its own set of rules and guidelines and problems).
