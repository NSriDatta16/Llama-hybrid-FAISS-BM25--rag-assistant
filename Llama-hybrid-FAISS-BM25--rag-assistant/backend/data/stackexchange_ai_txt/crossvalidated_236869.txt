[site]: crossvalidated
[post_id]: 236869
[parent_id]: 236846
[tags]: 
Q1. There are many possible causes for this. There's noise associated with point estimates of evaluation metrics, and these might make your performance on test data seem better than on train data. Now, on average, it's not reasonable to expect a model behaves better on data it has never seen than on data it was trained on. The maximum AUC you see on test data might be an artifact, created by a specific distribution of the samples in a fold. Q2. While I never used ggplot like that, it seems gc_prob_ex receives the predictions from the train set and not from the test set.
