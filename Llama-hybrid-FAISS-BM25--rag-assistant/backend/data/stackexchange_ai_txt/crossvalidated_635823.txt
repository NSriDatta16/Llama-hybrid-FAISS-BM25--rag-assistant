[site]: crossvalidated
[post_id]: 635823
[parent_id]: 635811
[tags]: 
Leverage can be heuristically defined as "how unusual the case is in terms of its values on the IVs." This doesn't say anything about how much it distorts the relationship between IVs and DVs, only how rare it is as a predictor . For a bivariate case, leverage can be formally defined as: $$ \large \text{leverage} = \frac{1}{n} + \frac{(x_i - \bar{x})^2}{\sum (x-\bar{x})^2} $$ where $n$ is the number of observations, $x_i$ is a given raw data point, $\bar{x}$ is the mean of $x$ , and the denominator $\sum x^2$ is the sum of the squared $x$ values. Keep in mind that if $x_i$ is close to the value of $\bar{x}$ , this will essentially reduce to zero and thus the equation will reduce to $\frac{1}{n}$ and have very little impact, so this formula is sensitive to distances from the mean (how far away our given $x$ is from where it "should be'). A residual on the other hand is essentially "how bad a regression is at guessing a given data point." It is formally defined as: $$ \large \text{residual} = y - \hat{y}, $$ where $y$ is the given raw data value of $y$ and $\hat{y}$ is the predicted value of $y$ . Notice now that the first formula is explicitly related to $x$ while the second formula is defined by the relationship between $x$ and $y$ , as $\hat{y}$ is the predicted value of $y$ given $x$ . So while leverage can have an impact on the residuals and the overall relationship on the coefficients, the leverage is more loosely related to the absolute distance of residuals than one may think. Here is a simulated example of data using R programming which has one extreme value of $x$ which has a high leverage but otherwise does not have a large residual, nor does it severely distort the relationship between $x$ an $y$ : #### Leverage Function #### lev % as_tibble() %>% mutate(leverage = lev(x.new)) df #### Plot #### df %>% ggplot(aes(x.new, y.new))+ geom_point(aes(size=leverage))+ geom_smooth( method = "lm", color = "darkred", se = F, formula = y ~ x )+ geom_vline( xintercept = mean(x.new), linetype = "dashed" )+ theme_bw()+ theme(legend.position = "bottom")+ labs(x="X", y="Y", title = "Leverage of Points", size="Amount of Leverage") You can see the relationship in the plot below, where the size of the data points indicates it's respective leverage. The dashed line shows the mean of $x$ , and you can see points which stray far away from that tend to increase in leverage but are otherwise closely fit around the regression line. Now of course leverage and residuals have a close relationship when it comes to things like influence , which is the amount a data point changes the coefficients. To indicate the difference, we can add a very influential point here which also has high leverage, then fit the original data and the data with the influential point to compare: #### Fit Model to Original Data #### fit1 % add_row(x.new = 6, y.new = 30, leverage = lev(6)) fit2 We can see now that fit2 has a relatively inflated slope compared to fit1 : > coef(fit1) (Intercept) x.new 0.1452786 2.0558130 > coef(fit2) (Intercept) x.new 0.4654817 2.9833302 We can showcase how refitting the data can showcase not only how this new data point creates a large residual, but also reweights the residual of the previous point that had not substantial influence but still high leverage. #### Augment Data #### library(broom) aug1 % ggplot(aes(x=x.new, y=y.new))+ geom_point(size=3)+ geom_smooth( method = "lm", color = "darkred", se=F )+ theme_bw()+ geom_segment(aes(xend = x.new, yend = .fitted))+ labs(x="X", y="Y", title="Original Fit") p2 % ggplot(aes(x=x.new, y=y.new))+ geom_point(size=3)+ geom_smooth( method = "lm", color = "darkred", se=F )+ theme_bw()+ geom_segment(aes(xend = x.new, yend = .fitted))+ labs(x="X", y="Y", title="Refitted Data") #### Plot Them Together #### ggpubr::ggarrange(p1,p2) Comparing the two, we can now see the difference (note here that the size of the data points are now all the same to simplify). We can also see that in the initial fit, the distance between the data point and the regression line is barely noticeable (shown with the black line coming from the data point), whereas in the second fit, we can see that the new data point reweights the relationship between $x$ and $y$ and consequently makes both itself and the previously large leverage point now influential, as depicted with the longer residual lines:
