[site]: crossvalidated
[post_id]: 221487
[parent_id]: 221459
[tags]: 
In case different parametrization per user is conceptually possible with your approach, you could look at a number of metrics (as you already indicated in your question): You could calculate the ROC curve per individual user in a 1-vs-all manner. You could visualize those in case you have few users altogether. Further, from the thereby obtained AUC values you could look at the average AUC (e.g. mean, median) and spread of AUC (e.g. sd, mad) over all users. Those indicate how strong your approach overall is (on average), and how likely it is for your approach to work better/worse for individual users - without specifying any thresholds so far. the average EER and spread of EER over all users. This indicates what the average EER could be expected to be, and how likely it is to get better/worse results if thresholds are allowed to be set individually for each user. When only considering one chosen, final threshold : you could look at the TPR and TNR (and their counterparts) for all users - specifically at the average (mean/median) and spread (sd/mad) of those. They indicate what the average positive and negative prediction performance is for users, and how likely those can be better/worse - which might be the most important metrics to report in the end.
