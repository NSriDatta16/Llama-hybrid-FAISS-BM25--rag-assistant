[site]: stackoverflow
[post_id]: 423735
[parent_id]: 423663
[tags]: 
Yes, this is the usual way of doing things. Render something into a texture. Draw a fullscreen quad with a shader that reads that texture and does some operations. Simple effects (e.g. grayscale, color correction, etc.) can be done by reading one pixel and outputting one pixel in the fragment shader. More complex operations (e.g. swirling patterns) can be done by reading one pixel from offset location and outputting one pixel. Even more complex operations can be done by reading multiple pixels. In some cases multiple temporary textures would be needed. E.g. blur with high radius is often done this way: Render into a texture. Render into another (smaller) texture, with a shader that computes each output pixel as average of multiple source pixels. Use this smaller texture to render into another small texture, with a shader that does proper Gaussian blur or something. ... repeat In all of the above cases though, each output pixel should be independent of other output pixels. It can use one more more input pixels just fine. An example of processing operation that does not map well is Summed Area Table, where each output pixel is dependent on input pixel and the value of adjacent output pixel. Still, it is possible to do those kinds on the GPU ( example pdf ).
