[site]: crossvalidated
[post_id]: 411798
[parent_id]: 
[tags]: 
Pairwise matching of case and control group for a machine learning classifier

If I want to test whether an illness is associated with alterations of a dependent variable Y (example: grey matter volume) I can perform under some assumptions a t-test. If I am aware of a confounder C, a variable that has an effect of Y but per se is not directly related to the illness (example: age), it is a good idea to choose the sample of participants in such a way that case and control participants are pairwise matched according to C (example: pairwise age matched), to reduce the risk to reveal differences that are due to the confounder rather than the illness. The same should be true when trying to build a machine learning classifier. Having a CASE CONTROL sample where the CASE and CONTROL groups differ by age has the risk that the classifier learns to classify based on features realated to age, instead of illness, so it will generalize badly. Pairwise age matching should then also determine how the sample is split into train, validate and test samples. However, despite this seeming a good idea to me (one also ends up with balanced sets), I haven't found discussion of this topic online. Could anybody please confirm or confute this? More in general, how does the treatment of confounding variables differ in a machine learning versus a GLM setting? If I am correct, a test train split implementation that accounts for a matching variable is contained for example in the sklearn package using the stratify parameter.
