[site]: crossvalidated
[post_id]: 126691
[parent_id]: 108477
[tags]: 
What do you mean "a deep learning approach"? You can represent text as a bag of words (a vector of word counts, or binary variables (word presence), with dimensions indexed by a reference dictionary). Word embeddings are continuous valued vectors used to embed individual words, and can also be combined to represent groups of words (e.g. additively or using a recurrent neural net). Usually for smaller amounts of text (like 1 sentence at a time), in the applications I can remember. See the papers: "learning word embeddings efficiently with noise-contrastive estimation" by Mnih and Kavokuoglu, and "A neural probabilistic language model" by Bengio et al.
