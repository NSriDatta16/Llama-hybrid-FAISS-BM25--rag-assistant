[site]: datascience
[post_id]: 97410
[parent_id]: 
[tags]: 
How to train a deep neural network to return the input as it is?

The task is to train a neural network to return the input as it is, like X -> X or Y -> Y . The network should contain at least two layers. Obviously, the output must be linear (resorting or not to scaling). Using linear activation functions in hidden layers or in the output layer if the network does not have hidden ones causes overflow. Sigmoids in the hidden layers and a linear output seem to work, but only in case I have specified the learning rate accurately enough (it needs to be as accurate as up to 4e-6 or other values depending on the data). But even in this case the network only appeared to be capable of returning the values which had been included in the training set. The amount of hidden nodes also needs to be times as more as there are the output nodes. My task concerns image processing, and first of all I want to train my network to return the input image as it is without any processing.
