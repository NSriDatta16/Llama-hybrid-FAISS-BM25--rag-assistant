[site]: crossvalidated
[post_id]: 164793
[parent_id]: 41276
[tags]: 
The goal with cross validation is to estimate how well your model will perform on new data. So you are correct in that you'll fit the model on a subset of your data ($k-1$ folds). Then you'll use the test set (fold $k$) to make predictions using the model you just built. You'll now have the true values and predicted values for fold k (your test set), which is generally all you need to calculate different performance measures. Repeat $k$ times and average to get the average performance of your model. Chapter 5 of An Introduction to Statistical Learning provides a good overview of k-fold cross validation. Edit: If the concern is that you need people from each group/cohort in both your train and test sets, then you could do stratified sampling of each of your groups, such that you end up with members of each cohort in both your test and train sets.
