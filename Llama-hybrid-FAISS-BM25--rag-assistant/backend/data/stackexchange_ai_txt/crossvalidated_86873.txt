[site]: crossvalidated
[post_id]: 86873
[parent_id]: 86608
[tags]: 
It all depends. What's the objective? Is it error minimization? Do you build up your CNN layerwise, or all at once? How many layers you should be using depends on the local field size of the neurons and the number of neurons. You can imagine that you can achieve similar functionality as a two layer CNN with a one layer CNN with neurons with bigger local fields. The local field sizes further depend on the actual data. If you want to be able to recognize objects which are only up to 10x10 pixels big, you can suffice with quite small CNNs, of course. In most literature you see networks with 3 or 4 (combined convolution and sampling) layers. I would recommend local field sizes between 3x3 and 8x8. It seems to me to be logical to do subsampling/pooling over fields of the same size, but you can choose to do more computation for more accuracy by choosing smaller subsampling/pooling window sizes. The number of neurons to use in each layer can depend on the objective you train your network on. It can also depend on the complexity of the kind of objects to recognize. It can range from 3 to 20. You can't expect anyone to give you the final answer on what architecture you should use. You should see for yourself by extensive testing. You train a lot of CNNs on your data with different settings and then choose the settings which produced a network which performed best on the testing data.
