[site]: crossvalidated
[post_id]: 388177
[parent_id]: 386075
[tags]: 
Should I use the gender (or any data correlated to it) as an input and try to correct their effect, or avoid to use these data? There are several implications of this question that boil down to the following, Do I want to be a social engineer; an activist whose role is to change the status quo because I have decided that society is sick and requires therapy? The obvious answer to this depends on whether or not such a change is beneficial or harmful. For example, the answer to "What would we gain from gender equality for nursing staff?" might be that having at least one male nurse available for inserting urinary catheters in males would not require that as many as 50% of nurses be male. So, the social engineering approach examines different cultures, contexts and problems with known gender bias, and posits functional benefits to be had from alterations of the root cause(s) of that bias. This is an essential step in the decision making process. Now, the answer to question 1. is a resounding no, that is, once one has decided that society needs fixing, one just adds a star, or fraction there of (see below), to female applicants, but be very careful of what you wish for because this is affirmative action, which is itself inherently discriminatory. Any AI outcomes will change to reflect the new hiring norms, once those become established as a new functional norm. How do I check the absence of discrimination against gender? Simple enough, after ratings are assigned, one does a post hoc analysis to see what the distribution of ratings are for males and female and compare them. How do I correct my model for data that are statistically discriminant but I don't want to be for ethical reasons? This is unavoidably done after the fact, i.e., post hoc . Forethought is also necessary, but the type of forethought most needed is a concerted attempt to examine critically what the social engineer's assumptions are. That is, assuming (for the sake of argument, see below) it to be sociologically justifiable to eliminate all gender bias, one merely adjusts the female ratings to follow the same empirical distribution as the males. In the teaching business this would be called grading on a curve . Further, let us suppose that it may not be desirable to do a full elimination of gender bias (it may be too disruptive to do so), then one can do a partial elimination of bias, e.g., a pairwise weighted average of each native female rating and its fully corrected rating, with whatever weights one wishes to assign that is thought (or tested as being) least harmful and/or most beneficial. Gender disparity cannot be altered properly by hiring policies alone as in some fields there is a relative scarcity of women candidates. For example, in Poland, 14.3% of IT students were female in 2018, and in Australia 17% . Once hired, retention of women in tech-intensive industries was problematic (Women in business roles in tech-intensive industries leave for other industries at high ratesâ€”53% of women, compared to 31% of men.) Thus, female job satisfaction may be more important than hiring policy alone. One first needs to identify a tangible benefit for having any particular percentage of females in the work place, and there are some hints about this, for example, in 2016 , women on corporate boards (16%) were almost twice as likely as their male counterparts (9%) to have professional technology experience among 518 Forbes Global 2000 companies. Thus tech-savviness appears to contribute more to female than male net worth. From this discussion, it should be obvious that before making gender specific assumptions, a substantial effort should be directed toward identifying more global concrete benefits of specific policies of which hiring policy is only a small, albeit important, part, and probably not the most important starting point. That latter is plausibly the retention of hires because turnover is bad for moral and may be the root cause of gender bias in hiring. My management experience has taught me that even small changes in work output (e.g. 10-20%) are quite effective in eventually eliminating wait lists, that is, there is no need to immediately increase output 100% by doubling staff numbers as the effect of that will shorten the wait list only slightly faster than a smaller change will, but will then be disruptive as staff will subsequently be standing around hoping that work will walk in the door. That is, if one decides to do social engineering, it can be harmful to attempt a full correction; it doesn't work that way. Try that with an abrupt course correction in a sailboat, and one may wind up exercising one's swimming lessons. The equivalent for treating gender bias (if the prescription fits), would be to only hire females. That would solve the problem (and create others). So, my advice would be to gradually correct any perceived (better would be demonstrated) problem (e.g., female job retention), to subsequently reorient to see the effect of any policy change, and adjust as needed thereafter. In summary, effectual social engineering requires a holistic approach to complicated situations, and merely identifying that there may be a problem does not tell us there is one, does not tell us what causes it, does not tell us how to correct it, and indeed all it tells us is that we have to put on our thinking caps.
