[site]: crossvalidated
[post_id]: 414917
[parent_id]: 398779
[tags]: 
Mean encoding seems to be popular in machine learning, but you should try better ways. The problem that dummy coding (or "one-hot") with many levels uses much memory, can be solved with sparse matrices. But still there might be too many parameters with one for each level, so some kind of collapsing of levels could be useful, see Principled way of collapsing categorical variables with many levels? . What you should do might also depend on which kind of model you are using (you didn't tell us). For one idea see Strange encoding for categorical features .
