[site]: datascience
[post_id]: 37658
[parent_id]: 37636
[tags]: 
[Wow.A Great problem] Possible solution: (Personal opinion) First Opinion is: Use SVM or KNN instead of a neural net as your data is trivial like 2D vector. Second Opinion is: As you aren't trying to predict the next text possibility of a particular patient so in this case RNN(LSTM,GRU) might not help you. So a simple solution is Autoencoder to compress the data and then run a simple logistic regression or svm or may be a neural net. How? 1.As your Patient numbers are not same in all cases so you should represent his/her all medical test data into a single vector.That is where Autoencoder comes into play.example: Suppose we have 3 patient: First-3 test , second-2 test ,three-5 test. Our goal is to compress each patient data into 2 dimension vector(as your features are RBC and WBC , 2 features , so it will learn well if we compress it into 2D vector). (inside asterik sign(*) your data goes) First Patient=[[*],[*],[*]] # three test Second Patient=[[*],[*]] # two test Third Patient=[[*],[*],[*],[*],[*]] # five test Now you compress the data via Variational autoencoder . scale your data as wbc>>rbc then use variational autoencoder to get the latent space vector use dimesion=2 in latent space via Dense(2) now when you get the vectors just add the vectors of test for each patient Like : For First patient you got three vector in latent space like- [2.33,4.2]+[5.11,9.22]+[0.21,6.32]=result..and You got the representaion for First patient. after you got all of them a trivial svm/polynomial regression would be just fine. Let me know how you solved it.
