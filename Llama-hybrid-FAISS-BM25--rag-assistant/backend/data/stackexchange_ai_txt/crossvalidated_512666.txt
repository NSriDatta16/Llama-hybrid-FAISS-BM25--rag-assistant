[site]: crossvalidated
[post_id]: 512666
[parent_id]: 
[tags]: 
On the predictive distribution of a Bayesian structural time-series model

I am trying to understand the structure and, in particular, normality properties of the predictive distribution of a Bayesian structural time-series model. My reasoning is as follows. The posterior distribution of model parameters (such as various standard deviations) is non-Gaussian in general. The inference via MCMC yields posterior draws from this distribution, and variational inference yields posterior draws from a surrogate, which is a collection of independent Gaussians. For each draw, regardless of the inference method used, the Kalman filter gives a multivariate Gaussian. The final posterior is a mixture of the multivariate Gaussians corresponding to the posterior draws of the model parameters. This implies that the predictive posterior is non-Gaussian; it is a mixture of Gaussians. Does the above hold? If not, what is the correct explanation? For some context, I am studying tfp.sts.forecast in TensorFlow Probability: https://github.com/tensorflow/probability/blob/v0.12.1/tensorflow_probability/python/sts/forecast.py#L173-L375
