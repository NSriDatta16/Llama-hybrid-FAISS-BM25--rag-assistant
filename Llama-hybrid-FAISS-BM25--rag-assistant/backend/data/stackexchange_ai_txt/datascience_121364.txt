[site]: datascience
[post_id]: 121364
[parent_id]: 
[tags]: 
computer vision transformers: ViT does not have a decoder?

from https://www.youtube.com/watch?v=TrdevFK_am4 that explains the paper titled, "AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE" compare that to the architecture shown here https://jalammar.github.io/illustrated-transformer/ So the ViT has a simpler architecture? It seems like the output of the encoder is the input to the MLP for the classification tasks. Also I was referred to this repo https://github.com/lucidrains/vit-pytorch for learning purposes. Are there any other ones I should know about? I took a computational photography class at GaTech OMSCS (my specialization says robotics and computational perception) but that was in 2019 so I need to do some catching up, not to mention computer vision is different from photography. Please feel free to link to additional resources which I should be going through.
