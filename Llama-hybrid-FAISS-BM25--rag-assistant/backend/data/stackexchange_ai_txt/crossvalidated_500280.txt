[site]: crossvalidated
[post_id]: 500280
[parent_id]: 228373
[tags]: 
I've done research in the field of Content Based Image Retrieval, where the goal was to have an embedding that is correlated to some similarity measure. So in this situation you don't care for the distance between embeddings to have an particular value (matching some arbitrarily scaled similarity distance measure). You just want them correlated. In some of the experiments pearson correlation loss (keras) was used as the cost function. I don't recall having any training difficulties with it (using Adam optimizer). Although it was applied batch-wise (and not on all outputs), the model had improved correlation ("real" correlation over the entire test set) compared to logcosh cost function.
