[site]: crossvalidated
[post_id]: 58331
[parent_id]: 58310
[tags]: 
Answering this (good) question responsibly probably requires addressing meta-analysis topics beyond conventional meta-regression. I've encountered this issue in consulting clients' meta-analyses but haven't yet found or developed a satisfactory solution, so this answer isn't definitive. Below I mention five relevant ideas with selected reference citations. First, I'll introduce terminology and notation for clarification. I assume you have paired effect-size (ES) data from $k$ independent studies, such as Study $i$'s ES estimates $y_{Di}$ for drinking problems (DP) and $y_{Ai}$ for anxiety, $i = 1, 2, \ldots, k$, as well as each estimate's conditional/sampling variance (i.e., squared standard error), say $v_{Di}$ and $v_{Ai}$. Let's denote Study $i$'s two ES parameters (i.e., true or infinite-sample ESs) as $\theta_{Di}$ and $\theta_{Ai}$. Taking the traditional random-effects view that these ES parameters vary randomly among studies, we could denote their between-studies means and variances as $\mu_D = \mathrm{E}(\theta_{Di})$ and $\tau_D^2 = \mathrm{Var}(\theta_{Di})$ for DP and as $\mu_A = \mathrm{E}(\theta_{Ai})$ and $\tau_A^2 = \mathrm{Var}(\theta_{Ai})$ for anxiety. In a conventional meta-analysis for each of DP and anxiety separately (e.g., with precisions as weights), we might assume each ES estimate's sampling distribution is normal with known variance—that is, $y_{Di} | \theta_{Di} \sim \mathcal{N}(\theta_{Di}, v_{Di})$ and $y_{Ai} | \theta_{Ai} \sim \mathcal{N}(\theta_{Ai}, v_{Ai})$ with $v_{Di}$ and $v_{Ai}$ known—at least for large within-study samples. We don't necessarily need to take a random-effects view of this problem, but we should permit both $\theta_{Di}$ and $\theta_{Ai}$ to vary among studies for questions about their association to make sense. We might be able to do this in a heterogeneous fixed-effects framework as well, if we're careful about procedures and interpretation (e.g., Bonett, 2009). Also, I don't know whether your ESs are correlations, (standardized) mean differences, (log) odds ratios, or another measure, but the ES metric doesn't matter much for most of what I say below. Now, on to the five ideas. 1. Ecological Bias: Assessing an association between your two ESs addresses a study-level question, not a subject-level question. I've seen meta-analysts inappropriately interpret a positive association between two ESs like yours as follows: Subjects for whom the intervention decreases anxiety more tend to decrease more on DP. Analyses of study-level ES data don't support statements like that; this has to do with ecological bias or the ecological fallacy (e.g., Berlin et al., 2002; McIntosh, 1996). Incidentally, if you had individual patient/participant data (IPD) from the studies or certain additional sample estimates (e.g., each group's correlation between anxiety and DP), then you could address certain subject-level questions about moderation or mediation involving the intervention, anxiety, and DP, such as the intervention's effect on the anxiety-DP association, or the intervention's indirect effect on DP via anxiety (e.g., intervention $\rightarrow$ anxiety $\rightarrow$ DP). 2. Meta-Regression Problems: Although you could regress $y_{Di}$ on $y_{Ai}$ using a conventional meta-regression procedure that treats $y_{Ai}$ as a fixed, known covariate/regressor/predictor, that's probably not entirely appropriate. To understand potential problems with this, consider what we might do instead if it were possible: Regress $\theta_{Di}$ on $\theta_{Ai}$ using ordinary regression (e.g., OLS) to estimate or test whether or how $\theta_{Di}$'s mean covaries with $\theta_{Ai}$. If we had each study's $\theta_{Ai}$, then using conventional meta-regression to regress $y_{Di}$ on $\theta_{Ai}$ would give us what we want, because the (simple) between-studies model is $\theta_{Di} = \beta_0 + \beta_1\theta_{Ai} + u_i$, where $u_i$ is random error. Using the same approach to regress $y_{Di}$ on $y_{Ai}$, however, ignores two problems: $y_{Ai}$ differs from $\theta_{Ai}$ due to sampling error (e.g., quantified by $v_{Ai}$) and has a within-study correlation with $y_{Di}$ due to the subject-level correlation between anxiety and DP. I suspect one or both of those problems would distort the estimate of association between $\theta_{Di}$ and $\theta_{Ai}$, such as due to regression dilution/attenuation bias. 3. Baseline Risk: Several authors have addressed problems analogous to those in #2 for meta-analyses of an intervention's effect on a binary outcome. In such meta-analyses, there's often a concern that the treatment effect covaries with the outcome's probability or rate in an untreated population (e.g., larger effect for subjects at higher risk). It's tempting to use conventional meta-regression to predict the treatment effect from a control group's risk or event rate, since the latter represents the underlying/population/baseline risk. Several authors, however, have demonstrated limitations of this simple strategy or proposed alternative techniques (e.g., Dohoo et al., 2007; Ghidey et al., 2007; Schmid et al., 1998). Some of those techniques might be suitable for or adaptable to your situation involving two multiple-endpoint ESs. 4. Bivariate Meta-Analysis: You might treat this as a bivariate problem, where Study $i$'s pair $y_i = [y_{Di}, y_{Ai}]$ is an estimate of $\theta_i = [\theta_{Di}, \theta_{Ai}]$ with conditional covariance matrix $\mathbf{V}_i = [v_{Di}, v_{\mathrm{DA}i}; v_{\mathrm{AD}i}, v_{Ai}]$—here commas separate columns and a semi-colon separates rows. We could, in principle, use bivariate random-effects meta-analysis to estimate $\mu = [\mu_D, \mu_A]$ and the between-studies covariance-component matrix $\mathbf{T} = [\tau_D^2, \tau_{DA}; \tau_{AD}, \tau_A^2]$. This could be done even if some studies contribute only $y_{Di}$ or only $y_{Ai}$ (e.g., Jackson et al., 2010; White, 2011). Besides $\tau_{DA} = \tau_{AD}$, you could also estimate other measures of the association between anxiety and DP as functions of $\mu$ and $\mathbf{T}$, such as the correlation between $\theta_{Di}$ and $\theta_{Ai}$, or the $\theta_{Di}$-on-$\theta_{Ai}$ regression slope. I'm unsure, however, how best to make inferences about any such measure of the anxiety-DP association: Do we treat both $\theta_{Di}$ and $\theta_{Ai}$ as random, or is $\theta_{Ai}$ best treated as fixed (as we might if regressing $\theta_{Di}$ on $\theta_{Ai}$), and what procedures are best for tests, confidence intervals, or other inferential results (e.g., delta method, bootstrap, profile likelihood)? Unhappily, computing the conditional covariance $v_{\mathrm{DA}i} = v_{\mathrm{AD}i}$ may be difficult, because it depends on the rarely reported within-group association between anxiety and DP; I won't address here strategies for handling this (e.g., Riley et al., 2010). 5. SEM for Meta-Analysis: Some of Mike Cheung's work on formulating meta-analytic models as structural equation models (SEMs) might offer a solution. He's proposed ways to implement a wide variety of uni- and multivariate fixed-, random-, and mixed-effects meta-analysis models using SEM software, and he provides software for this: http://courses.nus.edu.sg/course/psycwlm/internet/metaSEM/index.html In particular, Cheung (2009) included an example in which one ES is treated as a mediator between a study-level covariate and another ES, which is more complex than your situation of predicting one ES with another. References Berlin, J. A., Santanna, J., Schmid, C. H., Szczech, L. A., & Feldman, H. I. (2002). Individual patient- versus group-level data meta-regressions for the investigation of treatment effect modifiers: Ecological bias rears its ugly head. Statistics in Medicine, 21, 371-387. doi:10.1002/sim.1023 Bonett, D. G. (2009). Meta-analytic interval estimation for standardized and unstandardized mean differences. Psychological Methods, 14, 225–238. doi:10.1037/a0016619 Cheung, M. W.-L. (2009, May). Modeling multivariate effect sizes with structural equation models. In A. R. Hafdahl (Chair), Advances in meta-analysis for multivariable linear models. Invited symposium presented at the meeting of the Association for Psychological Science, San Francisco, CA. Dohoo, I., Stryhn, H., & Sanchez, J. (2007). Evaluation of underlying risk as a source of heterogeneity in meta-analyses: A simulation study of Bayesian and frequentist implementations of three models. Preventive Veterinary Medicine, 81, 38-55. doi:10.1016/j.prevetmed.2007.04.010 Ghidey, W., Lesaffre, E., & Stijnen, T. (2007). Semi-parametric modelling of the distribution of the baseline risk in meta-analysis. Statistics in Medicine, 26, 5434-5444. doi:10.1002/sim.3066 Jackson, D., White, I. R., & Thompson, S. G. (2010). Extending DerSimonian and Laird's methodology to perform multivariate random effects meta-analyses. Statistics in Medicine, 29, 1282-1297. doi:10.1002/sim.3602 McIntosh, M. W. (1996). Controlling for an ecological parameter in meta-analyses and hierarchical models (Doctoral dissertation). Available from ProQuest Dissertations and Theses database. (UMI No. 9631547) Riley, R. D., Thompson, J. R., & Abrams, K. R. (2008). An alternative model for bivariate random-effects meta-analysis when the within-study correlations are unknown. Biostatistics, 9, 172-186. doi:10.1093/biostatistics/kxm023 Schmid, C. H., Lau, J., McIntosh, M. W., & Cappelleri, J.C. (1998). An empirical study of the effect of the control rate as a predictor of treatment efficacy in meta-analysis of clinical trials. Statistics in Medicine, 17, 1923-1942. doi:10.1002/(SICI)1097-0258(19980915)17:17 3.0.CO;2-6 White, I. R. (2011). Multivariate random-effects meta-regression: Updates to mvmeta. Stata Journal, 11, 255-270.
