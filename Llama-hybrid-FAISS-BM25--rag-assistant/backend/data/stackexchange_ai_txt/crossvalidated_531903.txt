[site]: crossvalidated
[post_id]: 531903
[parent_id]: 
[tags]: 
Get AP score with Precision and Recall values

To display a Precision-Recall curve, I calculated my values of Recalls and Precision by varying the confidence threshold from 0 to 1. The PR curve is right but I don't understand exactly how to calculate the AP score , the area under my curve. Based on the scikit learn formula here I did : precision = [0.9117647058823529, 0.9117647058823529, 0.9090909090909091, ..] recall = [0.32978723404255317, 0.34065934065934067, 0.3448275862068966, ..] AP = sum([(recall[i]-recall[i-1])*precision[i] for i in range(len(precision)-1)]) print(AP) But the value of my AP score is not correct. Of course sizes of the recall and precision lists are identical. Why is my formula wrong and How do I calculate the AP score? Thanks for your attention.
