[site]: crossvalidated
[post_id]: 189370
[parent_id]: 189322
[tags]: 
When logistic regression is used as part of a classification problem, the data space is separated by a straight line (resp. Hyperplane in dimensions above 2). Subjects are assigned to a class according to which side of the Hyperplane they are on. In that sense, the classifier is linear. Note: quick clarification. If you have $n$ features for each subject, then each subject can be mapped to a point in $R^n$. Classification trees also split the sample space into regions but the boundary would not be linear. You would get a bunch of box like regions, I believe. Neural networks and kernel classifieds allow more complex divisions of the sample space.
