[site]: crossvalidated
[post_id]: 638568
[parent_id]: 638332
[tags]: 
I have no direct solution to the problems below, but I believe that it important to mention, to warn that a straightforward answer is not as simple as it looks like and it should be nuanced that they do not give an exact solution. It is possible to fit different models based on different hypotheses, and compute the likelihood in the fitted point. But a tricky part of the question is that the true variance might be different from the fitted variance, and the problem becomes a variant of the Behrens Fisher problem. In addition, one may compare likelihoods, but it is not ensured that we will see the true model as relatively most often with the highest likelihood. An example computation is below where we have 5 populations and for small effect sizes the special population is recognized less than 20% of the time. (the computations below are for different groups sizes to make the effect more clear, and we tested the hypothesis $\mu_{special} \neq \mu_{default}$ instead of the more difficult $\mu_{special} > \mu_{default}$ ) set.seed(1) power = function(effect = 0, n = 500) { count = 0 ### counter to keep track of right decisions ### simulate n times for (i in 1:n) { ### simulate a sample x1 = rnorm(5) x2 = rnorm(5) x3 = rnorm(5) x4 = rnorm(5) y = rnorm(50,effect,1) ### compute log-likelihood for different models l1 = logLik(lm(c(x1,x2,x3,x4) ~ 1))+logLik(lm(c(y) ~ 1)) l2 = logLik(lm(c(x2,x3,x4,y) ~ 1))+logLik(lm(c(x1) ~ 1)) l3 = logLik(lm(c(x1,x3,x4,y) ~ 1))+logLik(lm(c(x2) ~ 1)) l4 = logLik(lm(c(x1,x2,x4,y) ~ 1))+logLik(lm(c(x3) ~ 1)) l5 = logLik(lm(c(x1,x2,x3,y) ~ 1))+logLik(lm(c(x4) ~ 1)) ### convert to likelihood p1 = exp(l1-min(l1,l2,l3,l4,l5)) p2 = exp(l2-min(l1,l2,l3,l4,l5)) p3 = exp(l3-min(l1,l2,l3,l4,l5)) p4 = exp(l4-min(l1,l2,l3,l4,l5)) p5 = exp(l5-min(l1,l2,l3,l4,l5)) ### keep track when the true group has the highest likelihood if (p1 > max(p2,p3,p4,p5)) {count = count +1} } return(count/n) } ### create a plot plot(c(-1,2), c(0.2,0.2), xlim = c(0,0.5), xlab = "effect size", ylim = c(0,1), ylab = "fraction recognized", type = "l", lty = 2) ### add points for probability of correct decisions as function of effect size for (effect in seq(0,0.5,0.05)) { points(effect,power(effect)) } This relates to the discrepancy between frequentist and bayesian analyses. A Bayesian analysis will give the probabilities conditional on the observations and not conditional on the hypothesis. That's why we can get low Why does a 95% Confidence Interval (CI) not imply a 95% chance of containing the mean?
