[site]: crossvalidated
[post_id]: 597478
[parent_id]: 
[tags]: 
What is the proper way to assess the presence of an interaction of two categorical variables?

Main question Assume that one can administer a treatment to patients in two different conditions. What is the proper way to conclude (or reject) that the treatment response behaves differently in the two conditions? Details I have a visual representation of the data given by this R code: library(dplyr) library(ggplot2) data % group_by(treatment, condition) %>% summarise(value = mean(value)) eps Which produces the following plot (orange arrows where drawn manually): Now, visually it looks like the treatment responses (orange arrows) behave differently in condition C1 (average values get slightly lower) compared to C2 (average values increase). Assuming a linear model, I hoped to see a significant interaction term between the two factors condition and treatment , but the line lm(value ~ treatment * condition, data = data) yields a p-value of $p = 0.639$ an adj. R-squared of $\bar{R}^2 = -0.126$ . Even if I compare it to a simpler linear model without interaction term, via fit_interaction I get a p-value of $p = 0.393$ . Including patient as a confounding factor, by putting it as an additional covariant (i.e. adding + patient in all of the formulas above) slightly increases p-values but is still far away from significance. My question now is : Are the two arrows, despite visual suspicion, simply not significantly different or am I doing something wrong?
