[site]: crossvalidated
[post_id]: 79183
[parent_id]: 79168
[tags]: 
So you can eliminate the last few principal components, as they will not cause a lot of loss of data, and you can compress the data. Right? yes, you're right. And if there are $N$ variables $V_1, V_2, \cdots , V_N$, you then have $N$ Principal Component $PC_1, PC_2, \cdots , PC_N$, and every variable $V_i$ has an information (a contribution) in every PC $PC_i$. In Sparse PCA there are $PC_i$ without information of some variables $V_j, V_l, \cdots$, the variables with coefficient zero. Then, if in one plane $(PC_i, PC_{j})$, there are fewer variables than expected ($N$), it's easier to clear the linear relations between them in this plane.
