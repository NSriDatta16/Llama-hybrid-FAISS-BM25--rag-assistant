[site]: datascience
[post_id]: 73786
[parent_id]: 73782
[tags]: 
Good question. Here is my take on it: The following piece code creates the union of both the imputed features and the indication of which ones were imputed. transformer = FeatureUnion( transformer_list=[ ('features', SimpleImputer(strategy='mean')), ('indicators', MissingIndicator())]) I can see it becoming useful for a learner that may learn to not rely as much on features that are often missing. Or perhaps, the fact that some features are missing at all can be helpful for the learner. As, missing values can mean that something happened differently in the data collection, which can be useful to make a prediction. Let's say I have the following problem: I want to classify users based on their watching habits on my fancy streaming platform. Users have to rate a movie thumbs up or thumbs down. Of course, not all my users will watch all movies, so I'll have blank values. By using let's say the SimpleImputer , I'll basically make an educated guess on how they would have liked the movies they didn't watch. That can be useful as then I can compare users across all movies. However, knowing which movies the user has watched altogether is probably as informative. This is what the MissingIndicator provides you.
