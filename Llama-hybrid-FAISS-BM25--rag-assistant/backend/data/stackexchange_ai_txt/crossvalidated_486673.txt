[site]: crossvalidated
[post_id]: 486673
[parent_id]: 486672
[tags]: 
It’s because statistics puts an emphasis on model inference, while machine learning puts an emphasis on accurate predictions. We like normal residuals in linear regression because then the usual $\hat{\beta}=(X^TX)^{-1}X^Ty$ is a maximum likelihood estimator. We like uncorrelated predictors because then we get tighter confidence intervals on the parameters than we would if the predictors were correlated. In machine learning, we often don’t care about how we get the answer, just that the result has a tight fit both in- and out-of-sample. Leo Breiman has a famous article on the "two cultures" of modeling: Breiman, Leo. "Statistical modeling: The two cultures (with comments and a rejoinder by the author)." Statistical science 16.3 (2001): 199-231.
