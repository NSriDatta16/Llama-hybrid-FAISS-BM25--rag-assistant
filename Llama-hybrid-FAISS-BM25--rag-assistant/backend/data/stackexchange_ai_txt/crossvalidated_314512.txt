[site]: crossvalidated
[post_id]: 314512
[parent_id]: 
[tags]: 
Conceptual Understanding of Kernels

I'm currently reading up on Kernels specifically related to SVM . My understanding of Kernels is that the data points are projected to another dimension and an SVM run on these new values. My understanding seems to fall down on how the initial kernel values are created. From my reading it seems that the first step is to create a value 'l' for every single x value and then get a similarity score (Kernel score using a Gaussian formula) between the actual value x and the value of l. This seems to be done for each value of x for every single value of y. So for example if I have 3 attributes, I have 3 values for 'l'. I get a similarity score (the kernel) between the three values of x and every single value of y resulting in a 3*3 comparison. I then put the results into a vector and use that vector when minimizing my cost function for SVM. My questions are: Is my understanding correct? Does this mean that if I had not used the kernel I would have had 3 attributes to estimate parameters against? On the flip side with the kernel function in play would I have nine? Thank you kindly for your time
