[site]: datascience
[post_id]: 55161
[parent_id]: 
[tags]: 
Random seed in Machine learning model comparison

I would like to ask a question about the random population generation gin splitting the dataset in machine learning classification models. For example, I used seed = 1 and got accuracy of 0.7 and seed = 5 and got accuracy of 0.8 and seed= 2000 and got accuracy of 0.89 using Adaboost. I found a research paper using the same dataset i used and accuracy achieved is 0.94 using xgboost model without specifying the seed used in developing the model. Same exists for other research papers as well. Which results I need to pick to compare my model with other models proposed in the literature? Meanwhile I implemented all the models proposed in literature with the different seed and found that results are different when compared to the paper. And sometimes without using my result with adaboost is better. I need help to compare my proposal with other works.
