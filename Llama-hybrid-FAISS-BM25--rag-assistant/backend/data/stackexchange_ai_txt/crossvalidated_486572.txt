[site]: crossvalidated
[post_id]: 486572
[parent_id]: 486566
[tags]: 
AIC is defined as $$ \text{AIC} = 2k - 2\ln(\mathcal{L}) $$ where $k$ is the number of parameters and $\ln(\mathcal{L})$ is log-likelihood. First of all, random forest is not fitted using maximum likelihood and there is no obvious likelihood function for it. Second problem is the number of parameters $k$ , for linear regression this is simply the number of $\beta$ parameters, but what would it be for random forest? Would it be number of trees, maybe their depth, maybe number of splits, all of the above? You use the number of parameters $k$ to penalize the model, so if you have $m$ features for linear regression with no interaction terms and intercept, $k = m+1$ , but if you used something else for random forest, then the penalty could be much higher, but would it fair? If you want to penalize random forests for complexity vs linear regression, then they will always many orders of magnitude more complex, so this doesn't seem to be a meaningful in here. This applies to many other machine learning models as well, since it is often not obvious how would we measure their complexity, hence it is hard to come up with a penalty for that.
