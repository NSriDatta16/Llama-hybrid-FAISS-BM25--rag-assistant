[site]: crossvalidated
[post_id]: 80052
[parent_id]: 80039
[tags]: 
You may have a confused understanding of the differences between bootstraps, the interpretation of frequentist statistics, and stratified sampling. In particular, sampling 100 PSUs from 10 distinct clusters is beneficial when you have pre-selected such clusters based on either distribution of cluster level confounding variables or representative convenience sampling. (e.g. sampling 100 kids from 10 school districts rather than 1000 kids randomly from among 400 school districts). This is stratified sampling and is used to 1. alleviate confounding, 2. improve response rate, 3. make survey methods more affordable. One can conceive, in general, if a random experiment were conducted in which 100 individuals were sampled and if this process were repeated 10 times, we might be able to infer the distribution of the test statistics from each replication based on confidence intervals generated from a single replication. This is the concept of inference in the frequentist sense, and the interpretation of the confidence interval is the coverage rate for an infinite number replications of the experiment performed at the same sample size. The bootstrap is very closely related to the frequentist interpretation of test statistics and their standard error estimates. That's why the bootstrap (often) gives consistent estimates of these exact SEs in the presence of violations of model based assumptions. This is because we abandon any asymptotic or probability model based assumptions about the data generating process. We instead conceive of the empirical distribution function (which assigns probability 1/n to each of the n observations in our analysis) and calculate statistics by quite literally replicating our experiment an infinite number of times (we don't actually do this, but regular estimates converge to stable values with a few 1000 replications very easily). So returning back to the concept of sampling 1,000 individuals. In a frequentist analysis, you can calculate estimates, standard errors, and perform inference in the usual way. The interpretation of those values follow the usual format. As far as the validity of the results, there are usually limit theorems which assure us that, under certain regularity conditions, the exact distribution of the test statistic should be very closely approximated by the limiting distribution of the test statistic. The bootstrap eschews similar limit theorems (although it has its own set of limit theorems, ref Glivenko Cantelli), and estimates the exact distribution of the test statistic.
