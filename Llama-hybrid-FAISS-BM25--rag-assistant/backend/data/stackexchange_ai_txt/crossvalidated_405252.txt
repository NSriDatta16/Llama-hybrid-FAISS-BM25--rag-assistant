[site]: crossvalidated
[post_id]: 405252
[parent_id]: 
[tags]: 
Is it acceptable to test on 0.01% of the training data?

I'm doing a cross-corpus evaluation on text classification with a LinearSVM. I was wondering if it is acceptable to skew the training-testing split more than the usual 80-20% split. Specifically, I have 6,183 texts per class (3 classes total) and 79 texts per class in the testing stage. My training corpus has more texts, so I wanted to leverage the number of texts I have in this particular corpus. For the testing corpus, I do not have enough texts to meet the 20% benchmark. Would I be flouting some rules if I were to train using 19629 (6183*3) texts then testing on 237 (79*3)? Should I downsize the training corpus to meet the 80-20% split?
