[site]: crossvalidated
[post_id]: 317930
[parent_id]: 274815
[tags]: 
How do you define what a "mis-specified" model is? Does this mean the model... makes "bad" predictions? is not of the form $p_{T}(x) $ for some "true model"? is missing a parameter? leads to "bad" conclusions? If you think of the ways a given model could be mis-specified, you will essentially be extracting information on how to make a better model. Include that extra information in your model! If you think about what a "model" is in the bayesian framework, you can always make a model that cannot be mis-specified. One way to do this is by adding more parameters to your current model. By adding more parameters, you make your model more flexible and adaptable. Machine Learning methods make full use of this idea. This underlies things like "nueral networks" and "regression trees". You do need to think about priors though (similar to regularising for ML). For example, you have given the "linear model" as your example, so you have... $$\text {model 1: }x_i =\theta + \sigma e_i $$ Where $e_i \sim N (0,1)$. Now suppose we add a new parameter for each observation.... $$\text {model 2: }x_i =\theta + \sigma \frac{e_i}{w_i} $$ Where $e_i \sim N (0,1)$ as before. How does this change things? You could say "model 1 is mis-specified if model 2 is true". But model 2 is harder to estimate, as it has many more parameters. Also, if information about $\theta $ is what we care about, does it matter if model 1 is "wrong"? If you assume that $w_i\sim N (0,1) $ (like a "model 2a") then we basically have "cauchy errors" instead of "normal errors" and the model expects outliers in the data. Hence, by adding parameters to your model, and choosing a prior for them, I have created a "more robust model". However the model still expects symmetry in the error terms. By choosing a different prior, this could be accounted for as well...
