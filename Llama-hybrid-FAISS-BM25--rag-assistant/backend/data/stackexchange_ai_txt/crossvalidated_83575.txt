[site]: crossvalidated
[post_id]: 83575
[parent_id]: 83573
[tags]: 
Your question has two main parts. A better measure of impurity? Better for what purpose? There are many measures of impurity (heterogeneity, diversity, fragmentation, many other names). Suppose that a calculation gives you proportions $p_i, i = 1, \cdots, I$ of the observations in each of $I$ categories. Then most of the simpler measures are members of a family $$C(j,k) = \sum_{i=1}^I p_i^j \ [\ln(1/p_i)]^k.$$ Checking this out, $j = 2, k = 0$ gives you $\sum_{i=1}^I p_i^2$, $j = 0, k = 0$ gives you the number of categories present and $j = k = 1$ gives you entropy. So, you choose your weighting through $j, k$ according to what you want emphasised. (More complicated and/or more general families are popular, but I think this one deserves to be well known. I owe the generalisation to Good, I.J. 1953. The population frequencies of species and the estimation of population parameters. Biometrika 40: 237-264.) But (all that said) when looking at measured variables people tend to use standard deviation, interquartile range, etc., as is covered in almost any introduction to statistics. Plotting continuous distributions without binning? Surely. Search for quantile plots, cumulative distribution plots, density estimation. See e.g. this article for an introduction to quantile plots. A meta-answer is what, if anything, are you reading? You seem to be diving in straight at the machine learning end without having learned any basic statistics.
