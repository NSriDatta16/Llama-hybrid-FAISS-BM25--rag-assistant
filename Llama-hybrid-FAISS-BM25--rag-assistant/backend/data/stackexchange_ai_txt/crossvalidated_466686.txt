[site]: crossvalidated
[post_id]: 466686
[parent_id]: 466677
[tags]: 
Rejecting until an acceptance without repeating the current value induces a bias in the algorithm since it does not simulate from the proposal but from another distribution. Many questions on this forum address this issue What is the probability of rejection in rejection sampling? What is the difference between Metropolis-Hastings, Gibbs, Importance, and Rejection sampling? General questions on MCMC handling metropolis hastings rejection during a Gibbs sweep A simple experiment with a toy target like $\mathcal N(0,1)$ and a toy transition like the Normal random walk $\mathcal N(x,2)$ should show the difference in the outcome. A more advanced study of the chain of accepted values is found in our paper Vanilla Rao-Blackwellisation . The crux of this paper is that the stationary distribution density for the accepted chain is $$\tilde{\pi}(x)\propto\pi(x)\rho(x)=\pi(x)\int \alpha(x,y)q(x,y)\,\text{d}y$$ where $\pi(\cdot)$ is the original target density $q(\cdot,\cdot)$ is the proposal density in the Metropolis algorithm $\alpha(\cdot,\cdot)$ is the Metropolis acceptance probability associated with $\pi$ and $q$ . Hence $\rho(x)$ is the average probability of acceptance when starting Metropolis from $x$ . This may sound surprising or counter-intuitive but one can show that the transition from one accepted value to the next is endowed with density $$\tilde{q}(x,y)=\dfrac{\alpha(x,y)q(x,y)}{\rho(x)}$$ and that $\tilde\pi$ is stationary for this transition.
