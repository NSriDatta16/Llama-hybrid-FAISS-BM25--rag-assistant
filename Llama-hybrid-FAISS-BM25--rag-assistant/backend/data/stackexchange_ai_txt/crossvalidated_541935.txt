[site]: crossvalidated
[post_id]: 541935
[parent_id]: 541748
[tags]: 
First, observe that Python implementations of Box-Cox transform, both in scipy.special and in sklearn.preprocessing , use only single lambda parameter and work only with positive values of x . Second, observe that the transformed values are never $ (except when $\lambda = 0$ , in which case $\ln x$ is used). Consequently, if your predictor produces a $y , it cannot be back-transformed into a real number. Yeoâ€“Johnson transformation is more robust (at least I haven't found a counter-example where it fails). But, you won't find it in scipy.special . Do you have a reason why you cannot use sklearn.preprocessing.PowerTransformer ?
