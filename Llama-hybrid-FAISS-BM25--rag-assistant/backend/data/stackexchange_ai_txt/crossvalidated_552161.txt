[site]: crossvalidated
[post_id]: 552161
[parent_id]: 552158
[tags]: 
Are there any standard proofs suggesting that Shrinkage is able to "shrink" multiple parameters towards 0 (i.e. promise sparse results)? If you take regression with $\ell_1$ penalty $$ \underset{\boldsymbol\beta}{\operatorname{arg\,min}} \;\| \boldsymbol{y} - \mathbf{X}\boldsymbol\beta \|_2^2 + \lambda \| \boldsymbol\beta \|_1 $$ Then for regularization to have no effect (be the same as regular linear regression), the $\lambda \| \boldsymbol\beta \|_1$ term would need to be always zero. The term is minimized by minimizing the weights. Are there any standard proofs that suggest overfitting is more likely to be caused by models with many parameters compared to fewer parameters? (modern ML models like GPT3 are said to have "millions of parameters" and perform without overfitting) Model with more parameters is more flexible so it can more easily fit perfectly to the (training) data. That said, there’s some recent research showing the “double descent” phenomenon, where this does not hold. However keep in mind that we are concerned with number of parameters relatively to size of data and the number of patterns in the data to be learned, where language data consists of millions of samples and there’s an infinite number of words and their combinations that are possible, so relatively the number of parameters of GPT3 is not necessarily huge. In general, are there any standard proofs that highlight the usefulness and utility of Shrinkage ? Yes, you can find them in any machine learning handbook since regularization is always discussed.
