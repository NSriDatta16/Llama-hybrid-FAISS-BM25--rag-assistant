[site]: crossvalidated
[post_id]: 424547
[parent_id]: 
[tags]: 
How do you evaluate the prediction accuracy of linear mixed models?

How does one evaluate prediction accuracy with uncertainty for linear mixed models? Let's say I do bootstrapping and do train/test each time, and want to generate confidence intervals for some accuracy number like MAE. Clearly the within-subjects observations are not independent, so I can't just take the MAE of all observations. I could take the MAE within each subject, and average them. Then generate confidence intervals for the mean of within-subjects MAEs. This seems valid, but is there something better to do? Any references/book sections to read would also be appreciated.
