[site]: crossvalidated
[post_id]: 223050
[parent_id]: 
[tags]: 
MCMC for Probit/Logit model with some 1's flipped to 0's

I would like help constructing a sampler for the following model, which is the latent variable interpretation of either logistic or probit glm (doesn't matter which one to me), with a small twist: there is a probability $p$ that "successes" are flipped to failures after the fact. Model: Let $X$ represent the design matrix. Let $\vec{y}$ represent a vector of binary responses $z = X \vec{\beta} + \vec{\epsilon}$ $\epsilon_i \sim Logis(0,s)$ or $\epsilon_i \sim Normal(0,\phi)$ $y_i = 1$ if $z_i > 0$ AND $rbernoulli(p) == 0$, $y_i = 0$ otherwise $p \sim beta(\alpha,\beta)$ $\beta_j \sim Normal(0,0.001)$ Whether or not an observation is flipped from 1 to 0 is independent of an observation's "ability" (X values), conditional on our other parameters. Observations may not be flipped from 0 to 1. Toy Example: At the University of Foo, statistics students are selected to receive the Bar Award based on things such as academic achievement, extra-curricular participation, and community service. Professors convene and decide to give a certain number of students the award, writing the awardees' names on separate slips of paper, and handing them to the department head to give out the awards. However, as they often are, this department head is quite clumsy and, at random, loses some of the deserving students' names. We need to build a model to predict student success, taking into account that some of the "losers" are deserving of the award. Last year, we found that 3 of the 20 original awardee's names were lost. Using a Jeffreys' prior with binomial likelihood to estimate the probability of droppage, we develop a $Beta(3.5,17.5)$ posterior on $p$. I would love to see references to papers where something like this is done, or some help in constructing a sampler for this problem. My own efforts have not lead anywhere. My Math: As requested, I am putting here my attempt at a solution. Above, I have the prior for $\beta$ as a normal. It doesn't really matter to me what it is, so long as it is not very informative. My attempts will use marginal Jeffreys' priors for $\beta$ and $\phi$: $P(\beta) \propto 1$ $P(\phi) \propto 1/\phi$ These are the Jeffreys priors for regular old linear models, I assume I can use them in the latent varaible model as well. Please inform me if I am wrong. $$(\vec{z} - X \vec{beta}) \sim N(0,\phi I)$$ $$P(\vec{z},\vec{\beta},\phi | X,y) \propto | \phi I| ^{1/2} e^{-1/2 (z - X \beta)' (\phi I)(z - X\beta)}$$ $$\propto | \phi I| ^{1/2} e^{-\phi/2 (z' - \beta' X')(z - X\beta)}$$ $$\propto | \phi I| ^{1/2} e^{-\phi/2 (z'z - \beta'X'z - z'X\beta + \beta'X'X\beta)}$$ $$\propto | \phi I| ^{1/2} e^{-\phi/2(\beta'X'X\beta - 2z'X\beta )}$$ It would seem $\beta$ is normally distributed conditional on $z$ and $\phi$. I am not sure how to tie all of this to $y$ and $p$.
