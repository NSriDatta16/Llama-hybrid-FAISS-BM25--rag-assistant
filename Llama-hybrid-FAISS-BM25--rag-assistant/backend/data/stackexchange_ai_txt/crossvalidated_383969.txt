[site]: crossvalidated
[post_id]: 383969
[parent_id]: 
[tags]: 
Question about Validation Set for hyperparameter tuning

Okay, I'm still a bit confused as to this Training/Validation/Test Set split. I might be wrong here, but from what I understand, the model is first applied to the Training set, to "learn" from it and figure out the parameters to be used. Then comes the Validation set, and this is where I'm confused. I've read that the validation set is used for Hyperparameter tuning, to figure out which value of hyperparameter would be appropriate to use in the model. ( After which, you can then apply and assess your final model on the test set. ) Now let's suppose the model I'm applying is a Lasso or Logistic Regression, and the hyperparameter I'm tuning is Lambda. Or the model could even be, say, a Polynomial SVM, and the hyperparameters I'm adjusting is Degree and C. My question is, as I'm tuning/adjusting these hyperparameters, wouldn't the value of my parameters change in the process? For example, for a Lasso Regression, the lambda is used as a weight to restrict the coefficients from getting too large. Therefore as I adjust lambda, the coefficient values change. Therefore what was the point of initially fitting the model to the training set in the first place?
