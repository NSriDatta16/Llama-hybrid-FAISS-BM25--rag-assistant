[site]: crossvalidated
[post_id]: 168567
[parent_id]: 166915
[tags]: 
I tried it with a much smaller dataset and did indeed notice a small increase in time to completion. This is likely due to a different impurity function in rpartScore , although why it is taking that much longer is not entirely clear (particularly why absolute vs. squared differences in scores perform so differently). Here's what you could do: 1. Try split = "quad", that seems to converge faster (default is "abs") 2. Try a subset of your data, this way you can at least see whether it does not run due to memory allocation problems or something else is going on. 3. Try to debug it, although the fact that it speeds up if you change the split argument seems to indicate pretty clearly that's where the problem is. 4. perhaps try random forests with new permutation-based variable importance measures
