[site]: crossvalidated
[post_id]: 412977
[parent_id]: 
[tags]: 
Can someone provide a brief explanation as to why reproducing kernel Hilbert space is so popular in machine learning?

I thought functional analysis was long thought to be old fashioned and generally a dead research area. It seems that all of a sudden there is a huge fascination with so-called reproducing kernel Hilbert space in the machine learning community. Specifically, with some applications of the Mercer's theorem. A Hilbert space is a complete vector space equipped with an inner product. Nearly all of machine learning works with the Hilbert space $(\mathbb{R}^n, \langle, \rangle)$ already. So I don't see the point of looking into this particular one. Can anyone provide a simple application that illustrates why it needs to be done within this reproducing kernel Hilbert space setup?
