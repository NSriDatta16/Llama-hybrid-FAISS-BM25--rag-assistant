[site]: crossvalidated
[post_id]: 587134
[parent_id]: 
[tags]: 
How many independet test-train splits (with independent training) should I perform?

I recently read some literature by Bagnall et al https://arxiv.org/pdf/1602.01711.pdf "The Great Time Series Classification Bake Off". If I understand them correctly, they advise to perform multiple (independent) test-train splits to compare different models and their performance: Split the data into test train data Train a model on the training data from scratch Evaluate the model on the test data and obtain a performance measure Repeat, starting from (including) step 1 while This procedure (equivalent to repeaded crossvalidation) then gives a distribution of performance measures. While it is clear that this loop 1-4 is computationally demanding, we have the advantage of not relying on a single test-train split. I wonder if there is any further literature on this or if there are known drawbacks with this method. Could we somehow run into overfitting with this procedure (even if the models in step 2 are guaranteed to be erased after evaluation of the performance) ?
