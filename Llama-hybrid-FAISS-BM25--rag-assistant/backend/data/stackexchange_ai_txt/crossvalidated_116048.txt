[site]: crossvalidated
[post_id]: 116048
[parent_id]: 8182
[tags]: 
I think the answer to your question is negative: it is not possible. Standard PCA can be used for feature selection, because each principal component is a linear combination of original features, and so one can see which original features contribute most to the most prominent principal components, see e.g. here: Using principal component analysis (PCA) for feature selection . But in kernel PCA each principal component is a linear combination of features in the target space , and for e.g. Gaussian kernel (which is often used) the target space is infinite-dimensional. So the concept of "loadings" does not really make sense for kPCA, and in fact, kernel principal components are computed directly, bypassing computation of principal axes (which for standard PCA are given in R by prcomp$rotation ) altogether, thanks to what is known as kernel trick . See e.g. here: Is Kernel PCA with linear kernel equivalent to standard PCA? for more details. So no, it is not possible. At least there is no easy way.
