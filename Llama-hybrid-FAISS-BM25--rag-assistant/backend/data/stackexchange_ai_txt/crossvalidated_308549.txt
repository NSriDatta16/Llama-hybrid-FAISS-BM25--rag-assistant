[site]: crossvalidated
[post_id]: 308549
[parent_id]: 
[tags]: 
Find the number of clusters in huge unlabeled ECG time series data set

We are a project group working with ECG and we could use theoretical approval of our approach to deal with the problem. Our present approach is to cluster the ECG's, validate the formed clusters by cluster validity indexes and then compare each cluster with the features of the diagnosis attached to the ECG's to try to find correlation. We have 50.000 ECG's each with 8 median leads (representative median complex with noise reduction where each lead are time aligned) with 600 samples for each lead. Our approach is to use state-of-the-art shape-based clustering algorithms and evaluate them in relation to CVI and correlation with diagnosis features. For algorithms to evaluate we will use: k-Shape Fuzzy c-Shape Baseline: Hierarchical clustering with Euclidean distance as metric and computed for both average linkage and ward. For Internal CVI (Since we do not have any unlabeled ECG's): Silhouette index Calinski-Harabasz index Davies-Bouldin index (S_Dbw validity index) Our current problem and where we especially would like some feedback is to find a window of k to run the two algorithms within. The time complexity of silhouette index do not allow us to try k with 1-50.000. We have talked about a window of running k with 5-200 but we do not have theory to back this window up. An approach to find a window could be to reduce the dimension of each ECG leads using PAA , run k-Shape from 1-50.000 on this reduced data set, find a window of interesting k's and the run the two algorithms on the full ECG samples. We would really appreciate feedback on our current approach and a point in the right direction if you think there are cleverer ways to achieve our goal.
