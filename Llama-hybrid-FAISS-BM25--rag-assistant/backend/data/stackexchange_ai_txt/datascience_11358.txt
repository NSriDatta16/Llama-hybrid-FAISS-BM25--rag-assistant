[site]: datascience
[post_id]: 11358
[parent_id]: 11292
[tags]: 
Unfortunately scikit-learn does not handle categorical features well - they must be encoded. One-hot-encoding is great and can be implemented in sklearn very easily. So if you have an array of feature columns, X, and a class label vector, y from sklearn import OneHotEncoder ohe = OneHotEncoder(categorical_features=[0]) X = ohe.fit_transform(X).toarray() will perform the encoding for you (The categorical_features attribute gives the index of the feature you want encoded). More to your point though, if your feature has many levels, one-hot encoding can leave you with a sparse and inefficient X array. In this case it may be beneficial to do a count transform, possibly replacing each level with its corresponding log-odds ratio. Count Transforms The link above does a more thorough job explaining it, but, in layman's terms, for each categorical feature you: count the number of times a level(category) belongs to class0 or class1 add 0.5 to each count (this takes care of instances when a level belongs strictly to one class) calculate the probability that it belongs to either class. calculate the log of the odds ratio replace each level with its corresponding log odds ratio In this manner you get numerical values representing each of the feature's many levels without creating a dummy variable for each level. Still, 20 variables is a lot, and you may want to use PCA for data compression and dimension reduction. One of the great things about tree based methods in general is that they do not require standardization. That being said, from a data science perspective, I would train several different models (tree based methods, svms, logistic regression, knn, etc.), and see which one yields the best results. All methods besides CART benefit from scaling, so try from sklearn.preprocessing import StandardScaler stdsc = StandardScaler() X_train_std = stdsc.fit_transform(X_train) X_test_std = stdsc.transform(X_test) I hope that answers most of what you're asking. I'm not sure why you would want to concatenate two very different variables like cities and urls, but if you encode them or do a count transform your X array should be just fine and you can leave them separated. Also, you shouldn't have to worry about the length of a given variable - python is object oriented (if you're getting error messages complaining about 'length', you've likely just confused your indices).
