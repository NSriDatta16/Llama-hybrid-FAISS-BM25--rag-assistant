[site]: crossvalidated
[post_id]: 279849
[parent_id]: 279841
[tags]: 
Classical approach for neural network is to take a batch of samples and calculate average gradient over these samples. For the Jacobian instead of calculating average gradient - you calculate gradient per each sample separately. At the end you end up with matrix that has N rows and M columns, where N is a number of sample propagated through the network and M is total number of parameter in the network. Every row in the Jacobian is the full gradient per individual input sample. Important to say that computing Jacobian for Neural Network is inefficient in case if you deal with large number of input samples.
