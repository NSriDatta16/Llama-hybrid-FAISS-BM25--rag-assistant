[site]: crossvalidated
[post_id]: 195531
[parent_id]: 195522
[tags]: 
You are talking about semantic segmentation, I suppose. Don't worry, I know a thing or two about computer vision. ;) Personally I would not use or build such clustering algorithms anymore. Unsupervised Deep Learning with CNNs or stacks of RBMs do a much better job these days. I have used this for image segmentation and it has shown much more promising results than coming up with your own clustering algorithm. I assume you actually segmented the whole image in different parts and not only one object (which would make this easy) but I will stick with the first explaination. There is not really all that much you can do here. You could use a bag-of-words representation for each image (how many pixels fall into each cluster) and compare those (k-means comes to mind). [Won't work, see discussion below] What also comes to mind: If you know which segment is which, i.e. you can achieve a 1-to-1 matching of all segments of one image to another (bijective relationship), you could compare, e.g. the color values in the patches. If you do not know anything about the relationship, then this could still be done by finding the closest matches of segmentation patches. However, this usually ends up in some Simulated Annealing optimization problem and will be very slow. If the segments were already classified into their meaningful categories, there might be more you can do but I doubt they are. If you only segmented a single object in each image and it is centered, then just devide the area of intersection by the area of the union (pascal measure.).
