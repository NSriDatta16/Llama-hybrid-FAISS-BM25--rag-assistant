[site]: crossvalidated
[post_id]: 64835
[parent_id]: 
[tags]: 
$n$-th order Markov model with $m$ conditional probabilities

Initial Problem I am working on a problem that determines the completion of projects. There are eight stages for the project to be in before completion, with the ninth stage being completion. There is a certain number of days between each project ranging from [0, $\infty$), i.e. the project can go from Stage 1 to Stage 2 on the same day. I have data for about 10000 projects with 6000 being completed and 4000 not-yet-completed and are currently at one of the given stages. If, out of the 6000 completed projects 5000 of them took 0 days to go from Stage 1 to Stage 2, that should be (with $S_{12}$ the route between Stages 1 and 2) as $P(S_{12}|t=0)=\frac{5}{6}$. If 100 projects took 1 day, then that should be $P(S_{12}|t=1)=\frac{1}{60}$ and so on and so forth. Method I think the best way to go about this is by using an absorbing Markov chain, with the ninth stage as the absorbing node. (Please excuse any errors in assumptions or usage of terms with Markov chains as my experience is limited to reading Wikipedia and posts here.) So the way I think the chain should look: Each stage has a line with an arrow pointing to the next stage (except the last) along with an arrow pointing from each stage to itself. Issues "The past doesn't matter." Even though that's a rule for Markov chains, we do care if it took, say, 90 days to go from Stage 1 to Stage 2. Thus, when we get to Stage 6 that may imply that this project tends to lag between stages. This being the case, should it be an 8th order Markov Chain? 9th order? (Not sure if the fact that it's absorbing changes things.) Conditional Probabilities: Above, I mentioned using probabilities such as $P(S_{12}|t=0)=\frac{5}{6}$. Before getting more into the Markov chain aspect, does it make sense how I computed the conditional probabilities from the data? Assuming they are correct, my understanding of computing Markov chains is that one eventually gets to $xP^n$ and then runs that for $n=${however long they want the process}. My $P$ matrix is now a 9x9 matrix, but it seems like I should have a different $P$ matrix for each time interval. Meaning: For 0-day projects the first element is $\frac{1}{6}$ since there is a $\frac{1}{6}$ chance of the project staying in Stage 1, and the element one row below should be $\frac{5}{6}$ since that's the probability of moving to Stage 2 in 0 days. This would be in my $P_0$ matrix. My $P_1$ would have $\frac{59}{60}$ as the first element and $\frac{1}{60}$ as the second. Let's say I do this all the way up to $P_{730}$ and the last matrix would be $P_{>730}$ (to make things easier). Now that I have 732 probability matrices, what do I do with them? As mentioned above, if I wanted to do 10 days with a regular Markov matrix I would just make $n=10$ for the eigenvalue/vector decomposition of $xP^n$. But instead do I just do $x P_0 P_1 P_2 P_3 P_4 P_5 P_6 P_7 P_8 P_9$? Eventually we would like to get to a point that for any project we can predict what date it should be finished. Any help would be much appreciated.
