[site]: crossvalidated
[post_id]: 338831
[parent_id]: 338827
[tags]: 
I would like to suggest OP to think about the Bayes Error first. I have tested the accuracy on both Train and test dataset but it was not that great (80 for train, 70 for test data). Why do you think the accuracy is not great? What is the "threshold" to be considered as great performance? Note that, for some data, getting 70% accuracy would be awesome. Say online advertising prediction, can we have some model that 70% of the time, the the user will buy the product we recommended? For other applications 95% accuracy can be bad, for example, MNIST handwritten digit recognition problem . My answers to the questions 1) Adding extra features ? In general, adding features could be helpful, but have the risk of over fitting. 2) Removing the existing features ? If you discover you are overfitting, removing features could be helpful 3) Standardizig the dataset ? Not helping if you are using logistic regression without regularization. BTW, hope I am not rude and my answer is helpful.
