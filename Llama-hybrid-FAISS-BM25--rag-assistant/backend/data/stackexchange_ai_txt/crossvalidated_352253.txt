[site]: crossvalidated
[post_id]: 352253
[parent_id]: 
[tags]: 
Should I use the same weight initialization for each fold in cross validation?

Say, for example, I have 5 splits of my data. Can I randomly initialize the weights for my neural network at the start of each split? Or should I save the initial weights randomly initialized for the first fold, then on the second fold, load up the randomly initialized weight for the first fold before training? The latter seems more sound, though would this have a big effect on my results?
