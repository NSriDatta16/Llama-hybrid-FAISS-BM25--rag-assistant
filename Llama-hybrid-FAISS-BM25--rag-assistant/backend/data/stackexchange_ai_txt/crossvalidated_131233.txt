[site]: crossvalidated
[post_id]: 131233
[parent_id]: 
[tags]: 
Neural network over-fitting

I've learned that over-fitting can be detected by plotting the training error and the testing error versus the epochs. Like in: I've been reading this blogpost where they say the neural network, net5 is over-fitting and they provide this figure: Which is strange to me, since the validation and training error of net5 keeps dropping (but slowly). Why would they claim it is over fitting ? Is it because the validation error is stagnating ?
