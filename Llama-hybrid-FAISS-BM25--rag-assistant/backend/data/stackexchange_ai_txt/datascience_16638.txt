[site]: datascience
[post_id]: 16638
[parent_id]: 16379
[tags]: 
Word Embedding for Pos tags can easily be trained using pos tags sequence. There are lot of ways that you can get the trained model. I did it by gensim's word2vec api. Here is the link to it: https://radimrehurek.com/gensim/models/word2vec.html Also if you want memory efficient solution, radim(creater of gensim) provides a great tutorial: https://rare-technologies.com/word2vec-tutorial/ You just need to pass pos sequence of your training data, resulting vector size, min frequency count etc. You can view api's documentation for more detail.
