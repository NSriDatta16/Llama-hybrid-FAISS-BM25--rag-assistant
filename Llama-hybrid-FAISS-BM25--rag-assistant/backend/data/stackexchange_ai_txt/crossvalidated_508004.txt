[site]: crossvalidated
[post_id]: 508004
[parent_id]: 
[tags]: 
For variational autoencoder, how can we fix prior and likelihood distributions?

Before starting to describe my question, sorry for my poor English if you can't understand my descriptions. To my knowledge, generally, the Gaussian distribution is choosed as prior in VAE. Also, the likelihood distributions are fixed as specific distributions like Gaussian, Bernoulli, Poisson, ... to approximate ELBO(evidence lowerbound) easier. And, I understood that normal distributions have some nice properties for constructing neural networks and sampling. However, I'm confused how can we fix prior and likelihood distributions. What if the true distribution, p(x|θ), is too complex to approximate after fixing prior and likelihood? Is it enough to fix prior and likelihood to predict arbitray distribution p(x|θ)? I tried to find proper references for the question, but I cannot find. Thanks for reading my question.
