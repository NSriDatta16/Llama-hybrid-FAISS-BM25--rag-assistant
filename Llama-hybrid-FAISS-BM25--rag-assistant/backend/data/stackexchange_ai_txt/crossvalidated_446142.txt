[site]: crossvalidated
[post_id]: 446142
[parent_id]: 
[tags]: 
Number of input neurons in a LSTM Autoencoder

My training data of shape (2110, 5, 29) . When building a LSTM Autoencoder can the number of LSTM cells in my first LSTM layer be more than dimensions of the original input (i.e. 29)? Is it always the case that having more input neurons than features will lead to the network just copying the input value to the remaining neurons? So do we prefer this: num_observations = X.shape[0] # 2110 num_features = X.shape[2] # 29 time_steps = 5 input_shape = (time_steps, num_features) # number of LSTM cells = 100 model = LSTM(100, return_sequences=True, input_shape=input_shape) ... over this? num_observations = X.shape[0] # 2110 num_features = X.shape[2] # 29 time_steps = 5 input_shape = (time_steps, num_features) # number of LSTM cells = 25 model = LSTM(25, return_sequences=True, input_shape=input_shape) ...
