[site]: crossvalidated
[post_id]: 322543
[parent_id]: 
[tags]: 
Is redundancy across different modalities required in multimodal machine learning

There are lots of articles available pertaining to 'multi-modal machine learning'. Among the major challenges, there is a one of representation i.e. "how to represent and summarize multi-modal data in a way that exploits the complementarity and redundancy of multiple modalities" In context to the above quoted text, it is quite clear that complementarity across different modalities needs to be exploited for better performance. What about redundancy ? Do we need to preserve the redundant data present across different modalities ? Kindly explain the same. From the notion of dimensionality reduction and similar concepts, I do not see any point in preserving the redundancies as such. Any counter explanation ? By the way, the above quoted text could be found in "Multimodal Machine Learning:A Survey and Taxonomy" by Tadas Baltru≈°aitis, Chaitanya Ahuja, and Louis-Philippe Morency , 2017 available at https://arxiv.org/pdf/1705.09406.pdf on the first page itself.
