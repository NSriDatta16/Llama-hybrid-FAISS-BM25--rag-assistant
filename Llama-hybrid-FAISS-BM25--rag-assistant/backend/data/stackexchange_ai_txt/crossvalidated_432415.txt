[site]: crossvalidated
[post_id]: 432415
[parent_id]: 432413
[tags]: 
This depends a bit on your interpretation, but in a general sense no, you can not conclude that. You think your data is generated by some probabilistic process, which you do not "observe" or know. For example, you collect some data, but either you can not collect all relevant data for all observations, or the observations that you have do not cover the space of what reality might be. Let's say that data is $X$ , but is only a subset of all possible data that either exists (and you don't have it), or that may exist (if things were different, for example if the sun was shining when you collect the data instead of it raining all over you!). What that means is that your estimates $\hat{a}$ and $\hat{b}$ are functions of the data $X$ . If your data were different, say $X'$ , then you'd get different estimates $\hat{a}'$ and $\hat{b}'$ . So, in as much as your data is probabilistic - coming from some unknown process, your estimates are as well, because you derive them based on that data. In practice, you may say that you observe some $y$ , some $x$ and you know that there is also some $\epsilon$ you do not observe, so that for each observation $$y = a+b x + \epsilon$$ And $\epsilon$ has some probabilistic distribution. Then clearly, your estimates of $\hat{a}$ , say, are a function not only of $x$ , but also of the $\epsilon$ you do not see. And therefore, $\hat{a}$ also has a probability distribution. If you had a different $\epsilon$ , you'd have a different $\hat{a}$ . And if you know that, for example, $\epsilon$ is normally distributed, and $x$ is something you can decide on, then (with some work) you'd even be able to show that $\hat{a}$ is also normally distributed. Here is a yet another way to think about this. Let's assume you do your regression and get some $\hat{a}$ . Now, tomorrow you collect new data, and you run your regression again. Now you get another, different $\hat{a}$ . And if you repeat that for many, many times, then all the different $\hat{a}$ you get form a distribution. For frequentist statisticans, this is the sense of how $\hat{a}$ has a distribution. For Bayesians, in contrast, it would encode what other values $\hat{a}$ might have had, and how certain you are about that.
