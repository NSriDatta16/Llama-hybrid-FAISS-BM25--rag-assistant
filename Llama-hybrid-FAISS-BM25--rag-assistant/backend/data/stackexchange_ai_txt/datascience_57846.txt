[site]: datascience
[post_id]: 57846
[parent_id]: 57644
[tags]: 
It's quite a weird problem, at least for me... Following your approach you'll end up with $5^5$ classes, which is an intractable problem with typical Neural Networks. You can visist this paper, which shows a solution with mathematical rigour: https://arxiv.org/pdf/1806.02507.pdf I'll also expose three possible naive solutions, awating for people who have faced a similar problem: Convert your 5 columns into binary columns (3 bits for 5 levels) and treat the problem as a multi-label classification with 15 classes https://en.wikipedia.org/wiki/Multi-label_classification . You can fit 5 multi-class models for each column (divide and conquer navie approach, it seems to be the state-of-the art phylosohpy) I've never tried beta-regression, but it would make sense: you can convert your target labels to frequencies of occurrence, think about pruning targets with really low probability. Then, you can perform a preliminary beta regression to predict the occurrence-target. Further on, you may have other classification models depending on the probability given by the beta regressor, let's say 5 models for targets between 0-10%, 10-20% and so on... Treat your problem as a regression problem, but some questions arise: is '11111' truly close to '11112' in your dataset? i.e. are your labels a ordered set? So my question is if I should go on with the approach or are there better ideas? It is possible to use ANN to predict several properties (i.e. classes) at the same time? Yes, an ANN can output more than one class for a sample (but will not work in such a large scale): https://www.researchgate.net/publication/3297607_Multilabel_Neural_Networks_with_Applications_to_Functional_Genomics_and_Text_Categorization https://arxiv.org/pdf/1312.5419.pdf
