[site]: datascience
[post_id]: 54416
[parent_id]: 52060
[tags]: 
Not that I know of. Notice that those heat maps rely on the human knowing what they want , and then devising this heat map approach to visualizing it. For many papers interested in latent generative disentanglement, the most popular way to "check" the quality is via interpolating in the latent space and visualizing the output, seeing it across each disentangled dimension. One can then "see" whether they are indeed disentangled or not. Ideally there is some other way to quantify this disentanglement, but it usually requires additional information. For instance, for images, one might have labels that one can use (e.g., brightness, person identity). Or, as in the $\beta$ -VAE paper, one can use a toy problem where the underlying latent factors are known . Then one can devise a way to check whether one has actually separated those latent factors. Ultimately evaluation depends on the data and task. If one just wants to visualize the latent space, usually these interpolations plots are popular. But it is qualitative. Often a quantitative evaluation of the latent space requires an additional downstream task.
