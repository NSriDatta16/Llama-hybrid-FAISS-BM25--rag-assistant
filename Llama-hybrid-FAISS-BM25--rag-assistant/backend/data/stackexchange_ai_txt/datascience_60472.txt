[site]: datascience
[post_id]: 60472
[parent_id]: 
[tags]: 
(Feature selection) In which cases it is legitimate to remove features manually?

I am dealing with the feature in which only one category takes up about 90%, the instances of more than 30 other categories are sparse. Is it reasonable to remove this feature before building an estimator? I've experimented with the case when including and excluding this feature, and the later case showed a slightly(very slightly...) better performance. I am wondering if there is any machine learning principle, such as we should avoid 'human learning' and just let 'machine learning' do. What would be the best way to deal with this sort of features? I am currently using Scikit-learn. I am a total beginner in data science, so any opinion will be valuable to me. :)
