[site]: crossvalidated
[post_id]: 619759
[parent_id]: 619756
[tags]: 
There are two approaches: The "classic" one, where you use something like bag-of-words , maybe with manual features (e.g. detect that something is a "brand" by matching the names of the brands of products), etc. The "modern" approach would be to use a language model (e.g. BERT ) to transform the sentences into a latent representation. You can think of the language model in this scenario as using an encoder in autoencoder , that takes the text as input and returns a representation in the form of a numeric vector of a pre-specified size. Those embeddings are known to encode the meanings in the sentences, though the results would be better if the model was trained on similar data as yours, so using an off-the-shelf pre-trained model may not create great features.
