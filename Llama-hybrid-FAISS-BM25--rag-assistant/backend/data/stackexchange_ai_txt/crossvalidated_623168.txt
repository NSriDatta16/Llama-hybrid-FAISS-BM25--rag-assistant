[site]: crossvalidated
[post_id]: 623168
[parent_id]: 
[tags]: 
BIC to test good fitting of data to a model

I want to use the Bayesian Information Criterion in order to measure how well a gaussian and 0 order polynomial fit (using python), the one with the lowest BIC should then be the 'best fit' ? My parameters are already known by using scipy.curve_fit , then all I should have to do is determine $\mathcal{L}$ the maximum of the likelihood function. I had an answer previously on another forum but it quickly disappeared and someone told me that I could do the following but I do not understand how to get this formula (it work for both the polynomial and the gaussian): # get log likelihood logLgauss = -((n - 1) / 2) * np.log(np.sum((data - gauss_fit)**2)) # get log likelihood logLhoriz = -((n - 1) / 2) * np.log(np.sum((data - line_fit)**2)) ngaussparams = 4 # number of Gaussian model parameters bicgauss = ngaussparams * np.log(n) - 2 * logLgauss nlineparams = 1 # number of parameters for the flat line bicline = nlineparams * np.log(n) - 2 * logLhoriz
