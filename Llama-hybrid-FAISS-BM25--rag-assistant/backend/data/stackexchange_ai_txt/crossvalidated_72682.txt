[site]: crossvalidated
[post_id]: 72682
[parent_id]: 72670
[tags]: 
Define neural network to be $f$, time-series to be $x$, lag order to be $n$ and forecast horizon to be $h$. $ f(x_{t-1}, x_{t-2},..,x_{t-n}) = [x_t, x_{t+1},..,x_{t+h}]$ Assume you have the following time series, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] You define $n=2$, $h=1$. Your inputs for that time-series are circulant matrix like. x = [[ 1, 0], [ 2, 1], [ 3, 2], [ 4, 3], [ 5, 4], [ 6, 5], [ 7, 6], [ 8, 7]] Your outputs are y = [2, 3, 4, 5, 6, 7, 8, 9] So the length of your input layer is given by $n$, the length of your output layer is given by $h$, where your first input neuron is $x_{t-1}$ and your last input in $x_{t-n}$. Same goes for the forecast horizon. Instead of having multiple outputs for the forecast horizon, you can use a forecast horizon of 1 then recurse on the predictions to obtain any forecast horizon you want. For classic parametric stationary time series models the limit of the recursive behaviour of the system is well-studied. Your problem is a little more involved though. You have inputs and outputs of the system and you want the predict outputs to follow some reference trajectory. One solution is to use Narma-L2, which approximates the system by linear feedback using two neural networks. Define control inputs to be $c$ and production outputs to be $p$. Define reference production outputs to be $r$ You train two neural networks of the forms $g(c_{t-1}, .., c_{t-n}, p_{t-1},..,p_{t-n}) = c_{t}$ and $k(c_{t-1}, .., c_{t-n}, p_{t-1},..,p_{t-n}) = p_{t}$. The prediction for control inputs is then $c_t = \frac{r - k(c_{t-1}, .., c_{t-n}, p_{t-1},..,p_{t-n})}{g(c_{t-1}, .., c_{t-n}, p_{t-1},..,p_{t-n})}$ Also, neural networks are a PITA. There's plenty of good nonparametric regression models that are easier to train, like Gaussian Process Regression for instance. See: Neural Network NARMA Control of a Gyroscopic Inverted Pendulum
