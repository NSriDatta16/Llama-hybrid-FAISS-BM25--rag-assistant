[site]: datascience
[post_id]: 126682
[parent_id]: 
[tags]: 
Effect of feature selection when coupled with XGB models

I ran Boruta feature selection prior to XGB training\testing step and didn't see any difference, although ~30/200 features were rejected prior to going into the training. Can it be that internal feature selection of XGB is comparable to Boruta step and assigns nearly 0 importance to the same 30 features? My logic is simple - because these 200 features are the initial dataset it is very hard to believe it is also the optimal set. Therefore feature selection should bring some extra performance, except it is not. How do I test the above assumption? If I take a less smart model like logistic regression and test it with and without Boruta - can I expect significant difference in f1 or auc? Surely, someone already answered this question before systematically... any good links to papers? If I have to say to my team that we don't need feature selection step, I can use all support :)
