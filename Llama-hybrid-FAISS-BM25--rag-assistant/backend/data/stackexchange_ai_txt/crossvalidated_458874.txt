[site]: crossvalidated
[post_id]: 458874
[parent_id]: 458858
[tags]: 
A cheap way to make a feature is to randomly sample values. These values can be drawn from any probability distribution you can imagine. But whenever these features have no relationship to the outcome, I wouldn't expect these features to improve the quality of the model; and if they do improve the model, this effect must be spurious because they have no relationship to the outcome. This reasoning is true for random forests and any other model -- "add more features" is only useful when those features have some relationship to what you're trying to predict. Likewise, itâ€™s not surprising when a model is improved (or at least not made worse) by including additional relevant predictors, so random forest is not remarkable in that regard either.
