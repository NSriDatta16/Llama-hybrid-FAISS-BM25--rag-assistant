[site]: datascience
[post_id]: 22784
[parent_id]: 22771
[tags]: 
Discrete is the way to go. The reason is simple if you visualize a decision tree it involves drawing a decision boundary based on a set of constraints which are in the form of features. It would be much easier to draw these decision boundaries based on discrete features compared to its continuous counterpart. If the values are continuous it becomes difficult for the classifier to effectively draw this boundary and might have some skew in its results. There is a useful video series in Udacity, Intro into Machine learning, please refer the decision tree section they show a really good visualization on how decision trees work. Link: https://in.udacity.com/course/intro-to-machine-learning--ud120 Please check that out it may help you understand better.
