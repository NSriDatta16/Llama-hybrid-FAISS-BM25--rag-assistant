[site]: datascience
[post_id]: 60478
[parent_id]: 60017
[tags]: 
Since you are using LSTMs for classification using the multivariate time series data, you need to model your time-series data into a supervised learning problem and specify the previous time steps you need to look before by specifying the time-lag count You need to look into the to_supervised function and specify the number of outputs your model has. In your case, it is 4. Split your train and test set from the whole set of data. A 70:30 ratio for the train, test would be a good start. Also, note that you need to scale your values using the sklearn.preprocessing.MinMaxScaler() function. You need to reshape your train and test values into (batch_size/sample_size, time_steps, feature_size) as an LSTM Layer in Keras expects your data to be fed in a 3D array format. For eg: Your training shape would be train.shape = (batch_size, 100, 3) And for the model building in Keras model = Sequential() model.add(LSTM(number_of_hidden_units, activation='relu', input_shape=(n_timesteps = 100, n_features = 3))) model.add(Dense(4, activation='softmax')) #since number of output classes is 4 model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) model.summary() model.fit(X_train, y_train, validation_data=(X_test, y_test), no_of_epochs, batch_size) Note that I have just given a rough outline of the model building and left out the hyperparameters at your convenience. You can either stack more LSTM layers onto the model or tune the number of hidden_layers in the model Refer Multi-Class Classification for more details on it.
