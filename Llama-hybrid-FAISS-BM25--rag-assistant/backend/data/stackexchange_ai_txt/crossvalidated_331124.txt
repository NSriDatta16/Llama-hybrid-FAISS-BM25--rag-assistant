[site]: crossvalidated
[post_id]: 331124
[parent_id]: 
[tags]: 
Bayesian linear regression , variance

I'm currently reading Gaussian processes for machine learning and I don't understand something (or need an intuitive explaination) in the following paragraph: To make the above notation clearer, from pp. 8-9 of that book, the function we are predicting is the dependent variable $\mathrm{y_*} = f^*(\boldsymbol{\mathrm{x_*}}) = \boldsymbol{\mathrm{w^T x_*}}$ where $\boldsymbol{\mathrm{w}}$ is the vector of regression coefficients (usually denoted by beta in other books). The matrix $A = ( X X^{\mathrm{T}} + \mathbb{V}(\boldsymbol{\mathrm{w}}) ) / \mathbb{V}(\varepsilon)$ is the posterior covariance of the regression coefficient vector. The predictive variance is quadratic form of the test input with the posterior covariance matrix, showing that the predictive uncertainties grow with the magnitude of the test input In don't get why (intuitively) when fitting a linear regression the uncertainty grows with the magnitude of the input $\boldsymbol{\mathrm{x_*}}$. Let's imagine that naive example where I have this three points in my dataset: $$(x_1, y_1) = (1, 1),$$ $$(x_2, y_2) = (2, 2),$$ $$(x_3, y_3) = (10, 10).$$ In my mind the uncertainty is lower at $x = 10.01$ than at $x = 6$ (for example), because we have a close training data point near $x = 10$. Thanks per advance for your help !
