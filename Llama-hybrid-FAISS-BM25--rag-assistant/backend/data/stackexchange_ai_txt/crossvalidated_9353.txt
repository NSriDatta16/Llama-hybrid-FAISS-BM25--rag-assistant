[site]: crossvalidated
[post_id]: 9353
[parent_id]: 9352
[tags]: 
It is very probably the settings for the hyper-parameters that are the issue, leading to severe over-fitting of the data. Without proper tuning of the hyper-parameters, and SVM can perform arbitrarily badly, especially for high dimensional data (it is the tuning of the regularisation parameter that gives robustness against over-fitting in high dimensional spaces). I would suggest nested cross-validation, with the outer (leave-oue-out) cross-validation used form performance estimation and the hyper-parameters tuned independently in each fold by minimising a cross-validation based model selection criterion (I use Nelder-Mead simplex method rather than grid search). The short answer, is never use default hyper-parameter values, always tune them afresh for each new (partition of the) dataset.
