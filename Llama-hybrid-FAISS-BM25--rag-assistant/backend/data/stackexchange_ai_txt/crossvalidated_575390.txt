[site]: crossvalidated
[post_id]: 575390
[parent_id]: 575382
[tags]: 
As the comment by J. Delaney says, the result would hold even without conditioning on $x_{t-1}, x_{t-2},\cdots$ . The statement in the OP's question might be the result of a bad cut-and-paste job from a statement about Markov chains that avers that knowledge of the (possibly infinite) sequence of past states $x_{t-1}. x_{t-2},\cdots$ is not relevant to determining the current state; only the the most recent past state $x_{t-1}$ is relevant. That is, (among other properties), $$E[x_t\mid x_{t-1}, x_{t-2},\cdots] = E[x_t\mid x_{t-1}].$$ When $x_t$ is included in the conditioning variables, then of course, for each possible value $c$ that $x_t$ might take on, $$E[x_t \mid x_t=c, x_{t-1}, \cdots] = E[x_t \mid x_t=c] = c,$$ and thus the random variable $E[x_t\mid x_t, x_{t-1}, x_{t-2},\cdots]$ , which is a function of the conditioning random variables, has the property that $$E[x_t\mid x_t, x_{t-1}, x_{t-2},\cdots] = E[x_t\mid x_t] = x_t.$$
