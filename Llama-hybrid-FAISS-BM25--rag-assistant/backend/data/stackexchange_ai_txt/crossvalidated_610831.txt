[site]: crossvalidated
[post_id]: 610831
[parent_id]: 610829
[tags]: 
Kind of but not really. First, you'd normally talk about weights on decisions; specifically, weights on different types of errors . Second, you ideally should separate the prior probability or prevalence (the fraction of observations that are truly positive) from the weight or loss applied to each type of error. You can have balanced training data (prevalence=0.5) but decide that false positives are (say) much less important than false negatives and adjust the loss function to give more weight to false negatives. Or you could have imbalanced training data but decide that false positives and negatives are about equally important. These are separate concepts. After getting past these we get to a fourth point. If you have unbalanced data but you want to have approximately equal numbers of false positives and false negatives, one way to do this is to oversample the minority class. Making this decision is one reason to compute the prevalence. Oversampling the minority class for this reason is in some ways just a hack -- you can also get approximately equal numbers of false positives and false negatives by adjusting the loss function. These two approaches are exactly equivalent for logistic regression. They are often pretty close for other classifiers; this paper by Leo Breiman and co-workers compares them for random forests. And, finally, a fourth point. If you have unbalanced data and don't adjust the loss function or oversample, your classifier could end up predicting that everything most likely goes in the majority class. That's because everything mostly likely goes in the majority class , and it is often a feature, not a bug. Medical students have to be taught "when you hear hooves, think horses, not zebras", because rare diseases are over-represented in medical training relative to medical practice. Sometimes you want your classifier to think zebras, but often you want it to think horses.
