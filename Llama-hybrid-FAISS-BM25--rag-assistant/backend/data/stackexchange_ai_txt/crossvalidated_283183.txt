[site]: crossvalidated
[post_id]: 283183
[parent_id]: 
[tags]: 
Accuracy of an estimator is the degree of closeness of the estimates to the estimand. Accuracy of a forecast rule is the degree of closeness of the forecasts to the corresponding realization. Accuracy can be contrasted to precision ; accuracy is about bias while precision is about variability. Given a set of estimates or forecasts, the estimator or the forecast rule that have generated them can be said to be accurate if the average of the set is close to the estimand or the realization, respectively. Meanwhile, the estimator or the forecast rule can be said to be precise if the values are close to each other ( little scattered ). The two concepts are independent of each other, so a particular estimator or forecast rule be either accurate, or precise, or both, or neither. Although the two words, precision and accuracy can be synonymous in colloquial use, they are deliberately contrasted in the context of the scientific method. For example, lack of accuracy (large bias) may result from a systematic error. Eliminating the systematic error improves accuracy but does not change precision. Meanwhile, lack of precision (large variability) may result from a small sample on which the estimation or forecasting is based. Increasing the sample size alone may improve precision but not accuracy. Statistical literature may prefer the terms bias and variability instead of accuracy and precision : bias is the amount of inaccuracy and variability is the amount of imprecision. (Loosely based on Wikipedia's article "Accuracy and precision" .) Accuracy is not a good performance measure for classifiers.
