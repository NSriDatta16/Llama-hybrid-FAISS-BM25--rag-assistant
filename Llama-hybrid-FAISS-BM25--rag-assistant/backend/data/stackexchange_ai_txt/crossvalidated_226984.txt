[site]: crossvalidated
[post_id]: 226984
[parent_id]: 226983
[tags]: 
Start with something simpler. Say you have a parameter that can many values and you want to see which value is best for that parameter. What would you do? You would loop through all the values for that parameter and try them out. How do you try them out? This is where k-fold cross validation comes in. (It need not be 10 fold by the way). You split the training data into 10 folds and loop through the folds. For each fold, you train the model on the other 9 folds and then evaluate the model on the held out fold. So, for each parameter value, you will have k (in your example, 10) values. You can average these 10 and this will give an evaluation of how that parameter value is. This pseudo code might be clearer (in this case, I assume you are trying to minimize the error): best_parameter_value
