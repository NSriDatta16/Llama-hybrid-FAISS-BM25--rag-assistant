[site]: datascience
[post_id]: 22301
[parent_id]: 
[tags]: 
Best way to tokenize tweet

While working with Twitter datasets, one thing that always confuses me is, How to tokenize the tweets. I have seen different open-source implementations using different schemes for tokenization. They handle URL-mentions, Capitalization, User-mention etc. differently. I usually follow the script accompanying the GloVE code: https://nlp.stanford.edu/projects/glove/ . Are there any std. rules / best practices one should follow while tokenizing tweets? So much variation in different code-bases confuses me sometimes.
