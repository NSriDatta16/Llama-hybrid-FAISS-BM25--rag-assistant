[site]: crossvalidated
[post_id]: 393873
[parent_id]: 
[tags]: 
Downsample a stochastic process without losing correlation statistics?

I have a stochastic variable $X(t)$ which changes at a discrete set of random times $t_1, t_2, \dots$ . I can simulate this stochastic process to obtain a series $X(t_1), X(t_2),\dots$ However, the transitions are so common that saving the entire simulation is too memory intensive. My first approach was to only store the state of the process $(t_i, X(t_i))$ if $t_i-t_k> \Delta t$ , where $t_k$ was the last time at which the state was saved. So $\Delta t$ is a sampling interval and $1/\Delta t$ is a sampling rate. However, downsampling in this way, only recording the state of the system about every $\Delta t$ , biases the statistics of transition times. For example, it's difficult to estimate the distribution of the time between transitions, i.e., of $\delta t = t_i-t_{i-1}$ if I downsample in this way, since I ignored all $\delta t . Is there a way to downsample a stochastic time series that (even approximately) preserves the statistics of transition times? Please note I have to downsample on the fly, i.e., as the simulation runs. So I wonder if there is a random way to save the state of the process which generates an approximately unbiased statistical sample, preserving the relative number of transitions at each timescale.
