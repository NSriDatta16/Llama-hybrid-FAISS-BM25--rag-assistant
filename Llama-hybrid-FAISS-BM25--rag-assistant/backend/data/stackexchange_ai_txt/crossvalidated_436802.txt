[site]: crossvalidated
[post_id]: 436802
[parent_id]: 
[tags]: 
Neural Network Batch Training

I have read a few threads on implementing batch training in neural networks. Still I don't understand some specifics of the implementation: When backpropagating the accumulated error of a given batch $\{X_1, \dots, X_{m}\}$ of size $m$ into a hidden layer, which $X_i$ is used to calculate the error term of the hidden units? The formula states that for a output unit (hidden units have the same term in their error equation) $j$ the error term used to calculate $\Delta w_{ij}$ is $\delta_j= \varphi'(\sum_{i=1}^{n}x_i w_{ij})(o_j-t_j)$ where $\varphi$ is the used activation function. Should $(x_1, \dots , x_n)$ be an average regarding the batch inputs $\{X_1, \dots, X_{m}\}$ ? Also when calculating the average errors: Should I use a simple average by summing up the errors for each component of the output vector individually and then dividing with the batch size to get average error for each output neuron? Thanks for reading my question.
