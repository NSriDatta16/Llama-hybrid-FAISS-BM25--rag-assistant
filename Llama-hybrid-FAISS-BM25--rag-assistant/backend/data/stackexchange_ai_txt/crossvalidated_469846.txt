[site]: crossvalidated
[post_id]: 469846
[parent_id]: 469657
[tags]: 
Stationary means that the statistics that describe the random process are constant. ‘A memoryless Markov process’ is another way to say stationary as is saying that the probability generating function has no “feedback” terms, but if you recognized those words you might not be asking this question. FWIW “weakly stationary” isn't quite the same, a constant or knowable rate of change of the stats would be weakly stationary, as would something that averages out, but it’s a little more involved so consider this fair warning that there’s more to know in case that’s part of the puzzle, but describing everything that isn’t stationary in detail would turn a simple answer a complex answer. Why is stationary important? The commonly used statistical formulae are crafted to use a data set to extract an imprecise description with an estimable accuracy of an otherwise unknown random process. The formulae assume that adding more samples increases the accuracy of the description by reducing the uncertainty. For that the Mean Central tendency, i.e. ergodic in the mean, has to be true. If the random process itself is changing, e.g. the average value or the variance is changing, then an essential underlying assumption is invalid, you can’t make a better estimate. As a general “what happens” if the mean is moving as a linear function of time, the computed mean will represent the mean at a weighted mean time, and the computed variance will be inflated. Is possible to compute an ‘optimal a posteriori” (after the fact) estimate of a non stationary process and then use that to extract meaningful stats because the best estimate of the time function minimizes the variance. It’s also easy to hypothesize some high order time function and create a complex model that appears to be valid and predictive that in fact has no predictive power because it modeled a snapshot of randomness, not an underlying time trend.
