[site]: crossvalidated
[post_id]: 2215
[parent_id]: 2197
[tags]: 
I think we need to know more about the nature of the data to make recommendations on how to deal with the missing values. An exploratory task that jumps out to me is to look at the behavior of variables A through H when I is present, versus A through H when J is present. Is there anything interesting to take into account for subsequent modeling? Instead of resampling a descriptive statistic, like correlation, I would consider resampling the data itself. For example, you could use the bootstrap to create 500 new (I,J) pairs based upon the 500 values you actually have for these variables. But, again, the exploratory work may inform a resampling scheme beyond a "naive", IID approach. In general, as others have noted, filling in missing data goes by "imputation" and there are different techniques depending on the context. For example, in one setting I might simply use a median value, or a spline fit, but for a missing data point in a time series I might impute with a value generated from an ARMA time series model. Your outlined solution would be "bootstrapping" if you resample from the observed data. I think of Monte Carlo as any method that uses probabilistic sampling of data as input into a computation. When the sampling is from a non-parametric or parametric distribution that you use to model how the data was generated, I still call it Monte Carlo. But, when the sampling is done from an empirical distribution (i.e., the observed data itself, not a model of the data generating process) I call it bootstrapping.
