[site]: crossvalidated
[post_id]: 188922
[parent_id]: 
[tags]: 
Why does Random Forest use randomness at all?

My understanding of RF is you take a random selection of the data, as well as a random selection of the feature set. You then take the average of these decision trees to get a good guess, and your overfit should be kept in check by the fact that the trees are looking at different data/features. But why is it necessary to do this randomly? Couldn't you just as well calculate all the permutations (up to some limit) and run the model on that? Edit To make it a bit more concrete, let's say I have some dataset with a billion rows of data and 10 features. I could choose something like 2 features randomly selected. If I do that, there are 45 (10c2) pairs of features a tree could be picking. Now knowing there's 45 pairs, why don't I just evenly sample each pair, instead of sampling randomly? I'm not going to get a completely even set if I do say a random 4500 trees. But I could just say I'll do 100 trees in each feature pair.
