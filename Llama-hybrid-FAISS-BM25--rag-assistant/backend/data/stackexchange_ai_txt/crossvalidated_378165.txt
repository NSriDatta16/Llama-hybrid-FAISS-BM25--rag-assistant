[site]: crossvalidated
[post_id]: 378165
[parent_id]: 377334
[tags]: 
I think that your problem is not really about stability, I will try to formulate an answer in 3 steps. First, How to measure similarity between features ? This is a full area of research and there is no way to find an absolute answer. Similarity is most commonly measured using RMSE indeed but you can find a lot of different functions that will measure the distance between 2 vectors. Finding the right similarity function is mainly linked to the question "what is your objective?" which brings me to the second point. Second, Your objective is not clearly defined. Why do you want your algo to predict less 0s ? You need a clear metric to evaluate your full process, data cleaning/selection, feature engineering and training. From what I understand you haven't defined any metric but you don't fully like the RMSE that your RNN is trying to minimize. Yet it is giving you the best possible outcome, and this outcome includes a lot of 0s... Moreover when you train your RNN, it minimizes a Loss. By removing some points you are affecting your loss. Exemple: If you had 2 points with similar features and price, it means that the weight of that combinaison would be 2 compare to a point (feature, price) that would be alone. Now you are removing that point, making its weight back to one. This is a problem because if your train set and test set look alike and both represent reality, you do want this point to appear twice. Each mistake on this point will cost you double once your algo will be used. In your case, I understand that this is not important for you, so you need to define a metric that will take that non-importance into account. This metric should be directly derived from your application and include your intuition that too many prediction around 0 is bad (for some business knowledge that you have). Here is a very basic example of metric to illustrate my words: $ MSE_+ = \frac{1}{N} \sum_{i} (\hat y_i - y_i)^2*(y_i>0)$ with $y_i$ being the true value, $\hat y_i$ the predicted value. This metric will only care to predict well if there is a change in price, which correspond to $y_i>0$ . Third, Solutions you can explore. Once you have defined that metric you will able to optimize your problem, from the data point selection to the training. You mainly have 3 options: Weighting strategies . You can weight each samples in your loss function so that the mistake on some points count less than on others. You set up different weighting strategies and you train your RNN. Then you evaluate on a separate data set each strategies according to your new metric, and you pick the best. So your RNN is not directly optimizing your metric but this process of weighting and cross-validation will do it. Customize your loss function . If your metric has certain properties you will be able to easily implement the Loss function and derive the gradient. Then the gradient descent taking place during the training of your RNN will directly optimize your metric. Go on with your strategy (which is most likely the same as weighting with some weights equal to 0). In that case you will have to define multiple similarity functions as well some $\epsilon$ values and cross validate to find the best combinaison. I hope this will help you move forward.
