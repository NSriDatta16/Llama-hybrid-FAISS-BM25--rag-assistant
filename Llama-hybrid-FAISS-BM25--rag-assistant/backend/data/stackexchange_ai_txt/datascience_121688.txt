[site]: datascience
[post_id]: 121688
[parent_id]: 
[tags]: 
How to intrepret low F1 score and high AUC on training set?

I am currently working on a very imbalanced dataset: 24 million transactions (rows of data) 30,000 fraudulent transactions (0.1% of total transactions) and I am using XGBoost as the model to predict whether a transaction is fraudulent or not. After tuning some hyperparameters via optuna, I have received such results F1 Score on Training Data : 0.5881226277372263 F1 Score on Validation Data : 0.8699220352892901 ROC AUC score on Training Data : 0.9991431591607794 ROC AUC score on Validation Data : 0.9254554224474641 Although the ROC AUC score are quite high, the F1 score of my trainig data is quite low and its ROC AUC score is abnormally high. I was wondering what is wrong with my model, or my data? Am I overfitting, and are these results acceptable?
