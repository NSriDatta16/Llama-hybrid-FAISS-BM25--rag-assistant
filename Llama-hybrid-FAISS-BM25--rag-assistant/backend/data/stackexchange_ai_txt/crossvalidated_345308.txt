[site]: crossvalidated
[post_id]: 345308
[parent_id]: 345300
[tags]: 
The question is too broad to me to answer. But theory is always important when come to design the algorithms. Think about how the popular machine learning algorithms such as Neural Network, we need to know what is gradient / how to calculate gradient, to build the model from data. If your daily job is downloading programs and run it on your data, without totally understand it, theory may not be very useful. But if you are working on the algorithm design / the person to invent new models, the theory is essential. In addition, the terms you mentioned (L1/L2 regularization, ill conditioning，sparsity, VC dimension, gradient descent, logistic regression, entropy，information gain) are very important in most piratical problems also. For example, L1 regularization will give a more sparse system, which may save time on production execution. But comparing to L2, it is harder to optimize, this means we need more time to build the model. ill conditioning / numerical stability is also very important. Many algorithms will work in theory but not work in practice because computers can only represent a big or small number in certain degree.
