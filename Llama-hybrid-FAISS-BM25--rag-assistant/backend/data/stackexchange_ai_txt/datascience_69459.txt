[site]: datascience
[post_id]: 69459
[parent_id]: 
[tags]: 
Autoencoder for Dimensionality Reduction - varying result - parameter tuning

I'm not an expert in autoencoders or neural networks by any means, so forgive me if this is a silly question. The problem and steps taken to solve problem are as follows: There exists a data set with 5200 rows and 113 features from industrial sensors [Numeric Type]. The task is to use Autoencoder for the unsupervised dimensionality reduction purpose. The goal is to gain a result with 3 features so as to plot the data for visiualization and further machine learning models input. The overall construction of Autoencoder is as: Preprocessing step using minmax scaling: train_scaled = minmax_scale(clean_Data_numeric, axis = 0) df = pd.DataFrame(data=train_scaled) df.head() Splitting the data set: X_train, X_test = train_test_split(train_scaled, train_size = 0.8, random_state = seed(2017)) Constructing the Autoencoder: ncol = train_scaled.shape[1] encoding_dim = 3 input_dim = Input(shape = (ncol, )) # Encoder Layers encoded1 = Dense(40, activation = 'relu')(input_dim) encoded2 = Dense(20, activation = 'relu')(encoded1) encoded13 = Dense(encoding_dim, activation = 'relu')(encoded2) # Decoder Layers decoded1 = Dense(20, activation = 'relu')(encoded13) decoded2 = Dense(40, activation = 'relu')(decoded1) decoded13 = Dense(ncol, activation = 'sigmoid')(decoded2) # Combine Encoder and Deocder layers autoencoder = Model(inputs = input_dim, outputs = decoded13) # Compile the Model autoencoder.compile(optimizer = 'adadelta', loss = 'mean_squared_error') Autoencoder summary: Model: "model_17" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_14 (InputLayer) (None, 113) 0 _________________________________________________________________ dense_112 (Dense) (None, 40) 4560 _________________________________________________________________ dense_113 (Dense) (None, 20) 820 _________________________________________________________________ dense_114 (Dense) (None, 3) 63 _________________________________________________________________ dense_115 (Dense) (None, 20) 80 _________________________________________________________________ dense_116 (Dense) (None, 40) 840 _________________________________________________________________ dense_117 (Dense) (None, 113) 4633 ================================================================= Total params: 10,996 Trainable params: 10,996 Non-trainable params: 0 Fitting: autoencoder.fit(X_train, X_train, nb_epoch = 5, batch_size = 32, shuffle = False, validation_data = (X_test, X_test)) Evaluation: encoder = Model(inputs = input_dim, outputs = encoded13) encoded_input = Input(shape = (encoding_dim, )) encoded_train = pd.DataFrame(encoder.predict(train_scaled)) encoded_train = encoded_train.add_prefix('feature_') print(encoded_train.shape) encoded_train.head() ------------------------------------- (5287, 3) feature_0 feature_1 feature_2 0 0.021782 11.836038 1.777279 1 0.018666 11.803829 1.770958 2 0.000000 11.711332 1.765472 3 0.025804 11.797852 1.765566 4 0.001563 11.896879 1.787951 Now, The problem is each time I run the autoencoder with different setting like nb_epoch = 5, batch_size = 32, shuffle = False nb_epoch = 10, batch_size = 64, shuffle = True I will get totally different result for 3 features, and in case of plotting the features, The total shape of 3D points are different each time of running. Thus, How can I be certain that I am using right parameter and setting for my autoencoder? Which parameter should be used for this setting which be ended up in accurate 3D representation of points by 3 features? Thank You
