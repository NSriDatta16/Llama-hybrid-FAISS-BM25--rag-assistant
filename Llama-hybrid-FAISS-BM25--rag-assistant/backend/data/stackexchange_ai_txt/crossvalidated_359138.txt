[site]: crossvalidated
[post_id]: 359138
[parent_id]: 359125
[tags]: 
There is no theoretical reason . However, under certain conditions the central limit theorem (CLT) can be applied, which leads to geometrical Brownian motion (GBM), and subsequently to lognormal prices. I'll outline the reasoning and the empirical evidence further. The evidence is rather easy to observe. Go to any source of market price data, such as Yahoo!Finance or Fred . Look up the prices of actively traded securities, e.g. SPY ETF. Take the logarithm of prices, then get the differences. This is the series of so called log-returns : $r_t=\ln (p_t/p_{t-1})$. Draw a histogram, and observe that it looks bell shaped. If you take it that this is a normal distribution, then the distribution of the price ratio $p_t/p_{t-1}$ would be log normal. You could run some normality tests on the distribution of log returns and see that it may not (and often doesn't) pass as normal distribution. For instance, weekly returns of Apple shares over past three years do not pass normality test, but the same for Exxon Mobil does pass the test as you can see in next two pictures: So, the reality is that GBM is a simplification. I'd say it's simplest model that is still useful and is used today in many applications. The theoretical part comes from the following reasoning. The prices of securities in markets reflect everything that is known by humankind about these securities. The prices may change only when new information arrives. The new information is truly knew, it can't be devised from what's known about the universe. In that it's truly random. Moreover, the new information and subsequently price changes are independent from the past. In this kind of a framework, you can posit that maybe for a infinitesimal time period we have: $$r_{t+\delta t}=\mu+\varepsilon_{t+\delta t},$$ where $\varepsilon_{t+\delta t}$ is from some distribution. We may not know what is the distribution, but we assume that the draws from this distribution are independent, i.e. the variance of updates $var[\varepsilon_{s},\varepsilon_{t}]=0$ for $s\ne t$. Under these conditions, we apply the central limit theorem and get that for a finite time step $\Delta t$ the distribution of the errors must be normal: $$r_{t+\Delta t}=\mu+\varepsilon_{t+\Delta t},$$ because $\varepsilon_{t+\Delta t}=\sum_{\delta t} \varepsilon_{t+\delta t}$ I'm being quite liberal with the notation here just to hint you to the reasoning. If you agree with this approach, then you'd agree that the distribution of log returns must be normal for a small finite time interval $\Delta t$. Again, the reality is such that this assumption can be grossly incorrect, e.g. financial time series are known to have fat tails. The GBM assumption is used a lot even in its simplest form today in practice. It's like Newtonian mechanics, a very useful approximation of reality, vs. special relativity theory. You wouldn't use Newtonian mechanics when designing a particle accelerator or GPS satellite system, but certainly can use it to launch a mortar in a battlefield.
