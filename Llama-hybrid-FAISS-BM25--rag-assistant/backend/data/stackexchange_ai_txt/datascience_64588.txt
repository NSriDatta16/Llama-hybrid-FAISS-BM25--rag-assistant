[site]: datascience
[post_id]: 64588
[parent_id]: 
[tags]: 
Keras Embedding layer weights

I am trying to analyze the weights in a trained Keras embedding layer. The goal is to understand how well (or how poorly) we're capturing relationships between some specific tokens in our texts, separate from the rest of our model. In my case I have a 10,000 word dictionary, which I have embedded into 128 dimensions. dictLen When I export the weights in that layer after training via get_weights() , I get a matrix of 10,001x128 values. So far so good, but I'm a little confused about something: I'm adding 1 to my dictionary length to account for token 0, the unknown or null token. My understanding is that the embedding layer and subsequent layers will treat that value specially, but then why does it appear to have a trained weight when I export the entire set? And can I safely assume that the first row in the exported matrix is for value 0, and thus token 1 will be row 2 and so on?
