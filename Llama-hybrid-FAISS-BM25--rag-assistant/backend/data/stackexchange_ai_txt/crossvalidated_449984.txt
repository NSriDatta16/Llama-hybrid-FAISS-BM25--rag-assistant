[site]: crossvalidated
[post_id]: 449984
[parent_id]: 
[tags]: 
Which algorithm/loss function for better precision on a balanced binary classification problem

I have a huge tabular dataset consisting of millions of samples for a binary classification problem. The set is very balanced almost 1:1. The data is however very noisy and I only care about precision and not accuracy. What is needed is that when one model predicts 1 it's actually a 1 (same for 0), in other words the true positive rate and true negative rate. Therefore , it's fine if the model can only predict accurately a few of the samples but the predictions must be accurate. XGBoost using a threshold probabilityis giving me the best result but it's still not good enough. Can you suggest something better, like a better algorithm or a loss/metric function to use
