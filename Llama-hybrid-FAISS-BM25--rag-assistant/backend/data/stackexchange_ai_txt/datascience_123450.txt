[site]: datascience
[post_id]: 123450
[parent_id]: 
[tags]: 
SVM: difference between soft and kernel technique

Most articles and textbooks say that soft margin SVM is used is the data is messy/not linearly separable. We introduce slack variables to make the data linearly separable. Kernels are used when the data is nonlinearly separable. In other words, to me it is the same thing: using kernels when the data is not linearly separable. Based on my understanding kernels are used to map datasets into higher dimensions so that they could be linearly separable. Confusion : I don't understand the difference between soft svm and kernel svm when both these methods are used for non-linearly separable data. Why do we need kernel trick when soft svm is able to handle non-linearly separable data by introducing slack variables? Is it because these are different approaches? Then what are their advantages if they are different approaches? what is the advantage of soft svm compared to using kernels?
