[site]: datascience
[post_id]: 1026
[parent_id]: 810
[tags]: 
I think there are two separate issues to consider: Training time, and prediction accuracy. Take a simple example : consider you have two classes, that have a multivariate normal distribution. Basically, you need to estimate the respective class means and class covariances. Now the first thing you care about is your estimate of the difference in the class means: but your performance is limited by the accuracy of the worst estimated mean: it's no good estimating one mean to the 100th decimal place - if the other mean is only estimated to 1 decimal place. So it's a waste of computing resources to use all the data - you can instead undersample the more common class AND reweight the classes appropriately. ( those computing resources can then be used exploring different input variables etc) Now the second issue is predictive accuracy: different algorithms use different error metrics, which may or may not agree with your own objectives. For example, logistic regression will penalize overall probability error, so if most of your data is from one class, then it will tend to try to improve accurate probability estimates ( e.g. 90 vs 95% probability) of that one class rather than trying to identify the rare class. In that case, you would definitely want to try to reweight to emphasize the rare class ( and subsequently adjust the estimate [by adjusting the bias term] to get the probability estimates realigned)
