[site]: crossvalidated
[post_id]: 171516
[parent_id]: 
[tags]: 
Optimal stopping rule for sequential subsampling?

I have a set of ranking models added sequential one at a time. Where each model generate ranks for the sample. Finally the expected rank is done by taking the average rank from all models. scenario I have to specify the number of ranking model beforehand. However, in my problem I want a stopping criteria where I don't know the size of the ranking models. A situation where I have a sequence of infinite ranking models. I have tried to apply sequential stopping criteria based on fixed confidence interval on the top K ranked points. However, this method didn't work well since I need to specify the threshold value for stopping the width of the confidence interval. In such case, defining threshold value lead me to domain dependent problem. Where I need to find optimal threshold value empirically for each domain. I have tried to follow the approach mentioned in this paper Fixed-width Sequential Stopping Rules for a class of stochastic programs Can someone suggest a better idea or point me to any related reference material? Thanks
