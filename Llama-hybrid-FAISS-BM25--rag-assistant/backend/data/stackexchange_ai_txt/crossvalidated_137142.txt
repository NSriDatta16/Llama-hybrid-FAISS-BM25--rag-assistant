[site]: crossvalidated
[post_id]: 137142
[parent_id]: 137130
[tags]: 
When you are given a prior $p(\theta)$ and a likelihood $f(x|\theta)$ that are either not computable in closed form or such that the posterior distribution $$p(\theta|x)\propto p(\theta)f(x|\theta)$$is not of a standard type, simulating directly from this target towards a Monte Carlo approximation of the posterior distribution is not feasible. A typical example is made of hierarchical models with non-conjugate priors, such as those found in the BUGS book . Indirect simulation methods such as accept-reject, ratio-of-uniform, or importance-sampling techniques customarily run into numerical and precision difficulties when the dimension of the parameter $\theta$ increases beyond a few units. On the opposite, Markov chain Monte Carlo methods are more ameanable to large dimensions in that they can explore the posterior distribution on a local basis, i.e. in a neighbourhood of the current value, and on a smaller number of components, i.e., on subspaces. For instance, the Gibbs sampler validates the notion that simulating from a one-dimensional target at a time, namely the full conditional distributions associated with $p(\theta|x)$, is sufficient to achieve simulation from the true posterior in the long run. Markov chain Monte Carlo methods also some degree of universality in that algorithms like the Metropolis-Hastings algorithm is formally available for any posterior distribution $p(\theta|x)$ that can be computed up to a constant. In cases when $p(\theta)f(x|\theta)$ cannot be easily computed, alternatives exist, either by completing this distribution into a manageable distribution over a larger space, as in$$p(\theta)f(x|\theta)\propto \int g(z|\theta,x) p(\theta)f(x|\theta)\text{d}z$$ or through non-Markovian methods like ABC . MCMC methods have given a much broader reach for Bayesian methods, as illustrated by the upsurge that followed the popularisation of the method by Alan Gelfand and Adrian Smith in 1990.
