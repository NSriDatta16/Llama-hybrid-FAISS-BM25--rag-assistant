[site]: crossvalidated
[post_id]: 167815
[parent_id]: 167289
[tags]: 
There may be a few additional aspects worth considering (which are a little too long for a comment). Whether or not there is a multiple testing problem in a given application quite strongly depends on which coefficients a researcher looks at. In many applications, one is only interested in 1-2 key variables, and the others only act as "controls". Say, in a fixed effects panel data model we may feel that we need individual specific intercepts to control for unobserved heterogeneity, but we are typically not really interested in these $N$ fixed effects per se. On the other hand, in for example growth econometrics, we sift through all possible determinants for growth and as such, we are willing to look at all significant variables. In the latter case, we do have a multiple testing problem, but not necessarily in the former. I would argue that there are indeed several high-powered (at least, higher powered than Bonferroni) alternatives for performing such a model selection exercise. These include Bayesian model averaging, extreme-bounds analysis, General-to-specific, penalized methods (Lasso and related methods) and also methods directly deriving from the multiple testing literature. The latter group includes classical ones based on the Benjamini-Hochberg method, but also more recent bootstrap-based methods. To do some shameless self-promotion, these are compared and applied in a paper of mine .
