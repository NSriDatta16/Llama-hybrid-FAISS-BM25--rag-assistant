[site]: crossvalidated
[post_id]: 632728
[parent_id]: 632727
[tags]: 
Why can a model's SHAP values change on a new dataset? WHY SHOULDN'T THEY? When you calculate a mean on a new data set, you expect to get a slightly (or radically) different value. When you calculate a variance on a new data set, you expect to get a slightly (or radically) different value. When you calculate a regression coefficient on a new data set, you expect to get a slightly (or radically) different value. There is variability to measures of feature importance just like there is variability to other statistics of interest. After all, the SHAP value (for example) is a function of random variables and, thus, a random variable itself. You calculate the SHAP value from some new numbers. I would expect the output to differ at least a bit. What amazes me is how little attention this gets. Many people seem to be willing to take measure of feature importance (such as SHAP) as absolute truth, when they would demand some kind of uncertainty quantificataion (e.g., test statistic, p-value, confidence interval, credible interval, etc) from a mean or a regression coefficient. As you see from your work, there is variability to the SHAP values and ranks of feature importance. In this linked video of a keynote presentation, Vanderbilt's Frank Harrell basically dares practitioners to calculate bootstrap confidence intervals of their measures of feature importance, with a remark that if such a practitioner is afraid to calculate that confidence interval, then they shouldn't be using the technique they're using.
