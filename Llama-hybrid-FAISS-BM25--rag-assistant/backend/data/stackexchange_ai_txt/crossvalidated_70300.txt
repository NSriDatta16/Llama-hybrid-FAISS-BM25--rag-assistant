[site]: crossvalidated
[post_id]: 70300
[parent_id]: 
[tags]: 
Activation Functions

In the linear regression models, the model prediction $y(x, w)$ is given by a linear function of the parameters $w$. In the simplest case, the model is also linear in the input variables and therefore takes the form $y(x) = w^T x + w_0$, so that $y$ is a real number. For classification problems, however, we wish to predict discrete class labels, or more generally posterior probabilities that lie in the range $(0, 1)$. To achieve this, we consider a generalization of this model in which we transform the linear function of w using a nonlinear function $f(\cdot)$ so that $$y(x) = f(w^T x + w_0).$$ Question: I am taking my first course in machine learning and am unable to wrap my head around the reason for the need to transform the linear function of $w$ into a non-linear function. And also could someone post a simple example of such a transformation.
