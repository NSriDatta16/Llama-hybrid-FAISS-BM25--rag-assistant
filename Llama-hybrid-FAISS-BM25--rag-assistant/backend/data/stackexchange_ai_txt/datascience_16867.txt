[site]: datascience
[post_id]: 16867
[parent_id]: 16860
[tags]: 
You're trying to fit a very complicated function. There is no reason to expect that neural networks will be very good at this. Neural networks aren't magic pixie dust. They can do some things well, but don't expect a silver bullet. You're trying to get the neural network to learn to compute some complicated function. We do know that given sufficiently nodes and sufficiently many layers, you can get an arbitrarily good approximation to this function, but there's no a priori reason to expect it should be possible with the particular (small) number of nodes and layers you chose. In fact, two layers suffices, if you have sufficiently many nodes -- but we have no way to compute how many nodes are needed. In particular, the function you are trying to compute amounts to computing $x_0,x_1,x_2$ from $a,b,c,d$, where $$\begin{align*} x_k &= - {1 \over 3a} \left(b + \eta^k C + {\Delta_0 \over \eta^k C}\right)\\ \Delta_0 &= b^2 - 3ac\\ C &= \sqrt[3]{\Delta_1 \pm \sqrt{\Delta_1^2 - 4\Delta_0^3} \over 2}\\ \Delta_1 &= 2b^3 - 9abc + 27a^2d\\ \eta &= -{1 \over 2} + {1 \over 2} \sqrt{3} i \end{align*}$$ (This comes from the general formula for solving a cubic equation.) That's an extremely messy function, and thus it might be challenging to approximate using a neural network of the architecture you present. You can always try increasing the number of nodes and/or number of layers, but there's no a priori theory to tell you what the right number is.
