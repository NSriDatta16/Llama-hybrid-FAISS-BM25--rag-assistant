[site]: crossvalidated
[post_id]: 370188
[parent_id]: 370186
[tags]: 
Your input_shape shouldn't include your batch_size dimension. If you want to perform batch optimization, then you should put input_shape=(1,) and specify in addition batch_size=156060 - but this won't work with LSTM (or any RNN for that matter). If you're fine with mini-batch optimization, then specify a different size for batch_size . You can also set the batch_size parameter inside fit instead - this will be a little bit more flexible. LSTM's though will expect a time-dimension. Your input should be of shape: (156060,time_steps,num_features) it doesn't make sense that your input is of shape (156060,1) if you are trying to train a LSTM. I would learn a bit more about what a LSTM is and what it does before just trying to plug in numbers willy nilly.
