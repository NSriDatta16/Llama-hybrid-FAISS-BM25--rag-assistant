[site]: crossvalidated
[post_id]: 560204
[parent_id]: 558183
[tags]: 
A typical testable assumption would be that the errors of the model are i.i.d. Then the likelihood of the vector (corresponding to a sample) of the dependent variable is the product of the individual likelihoods of each element in the vector, or equivalently, the log-likelihood of the vector of the dependent variable is the sum of the individual log-likelihoods of each element in the vector. This feature is typically used in formulating the likelihood function. You can test the assumption using residuals. People usually look for violations of independence (though it is also possible to inspect the "identically distributed" part of the i.i.d. assumption, too). Thus they seek patterns in the residuals revealing some sort of dependence. E.g. in a time series setting, these could be nonzero autocorrelation, autoregressive conditional heteroskedasticity, level shifts and changes of the unconditional variance, among other. Tests such as Ljung-Box, Breusch-Godfrey, ARCH-LM and various structural breaks tests are used for detecting these types of dependence. Then there are some regularity conditions (see Wikipedia ) to ensure nice behavior such as consistency and asymptotic normality of the MLE, but I do not know if any of them are tested using residuals.
