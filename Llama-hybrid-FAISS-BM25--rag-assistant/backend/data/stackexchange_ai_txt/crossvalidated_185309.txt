[site]: crossvalidated
[post_id]: 185309
[parent_id]: 
[tags]: 
relationship between the Q value and the reward function in reinforcement learning

In the paper by Ng and Russell (2000), a section there discusses about the need to maximize the difference between the quality of the optimal action and the quality of the next best action. The quality of the action is simply the $Q(s,a)$ function and the action of maximizing the difference between the first and second best is given by: $$ \max \left ( \sum \left ( Q_{\text{best}} - \max Q_\text{next best} \right) \right) $$ Putting it all together, the optimization problem becomes maximize $\sum \min \{ (P_{a_1}(i) - P_{a}(i))(I - \gamma P_{a_1}(i))^{-1}R\} -\gamma |R|_1$ My question: What happened to the $Q$ values? Why did it not appear in the optimization problem. I was so expecting it to appear since we went to the trouble of maximizing the difference between the first and second best values.
