[site]: stackoverflow
[post_id]: 669869
[parent_id]: 669845
[tags]: 
First thing that comes to mind: one could track execution time of the queries and if it passes some threshold which is considered normal (average maybe) it gets logged along with some profiling information (which is discarded otherwise). It's might also be feasible to profile individual parts of the query (like data acquisition from db, logic and so on), then again compare the times against some averages. One pitfall is that some pages/queries are bound to be processed significantly longer then others because of the difference in the amount of "work" they do. One would have to keep a whole lot of averages for different parts of the site / different types of queries in order to get rid of constant flow of normal queries that execute longer by design. This is a very simple approach though, I'm sure there are better ways to do it.
