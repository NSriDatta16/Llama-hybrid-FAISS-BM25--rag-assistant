[site]: crossvalidated
[post_id]: 637783
[parent_id]: 637773
[tags]: 
Does unsupervised learning not increase the risk of throwing out relevant variables? As Frank says, "Manipulations of X in unsupervised learning may result in a loss of information for predicting Y" so yes, there is a risk of losing some information. But, again to Frank's point, when the loss is small then the gain in other avenues can be large. A different way to think about this is the alternative strategy: use Y to select variables that predict Y. That seems like cheating â€” study the answers to find the questions you need to study for to get a good score on the test. There are plenty of examples of this being a bad idea. Frank is a notable opponent of things like stepwise regression, and so I'm sure you can find something he has written on the topic to demonstrate why using Y to select X is a bad idea. In Regression Modeling Strategies page 79 (4.7 Data Reduction) reads: Data reduction is aimed at reducing the number of parameters to estimate in the model, without distorting statistical inference for the parameters. This is accomplished by ignoring Y during data reduction. Manipulations of X in unsupervised learning may result in a loss of information for predicting Y , but when the information loss is small, the gain in power and reduction of overfitting more than offset the loss Does unsupervised learning not increase the risk of throwing out relevant variables? How do you argue to a researcher/PI who has no stat background that losing those is more than offset by the gains in power and alleviation of overfitting? Lastly are there situations where this trade is not worth it? I would like to think that unsupervised methods are not worth it when interpretability is a key issue. PCA is an illustrative example. PCA will take linear combinations of the features, but how am I to interpret the first PC? It is a mix of many variables, and so the typical interpretation from a linear model ( a unit increase in x results in a $\beta$ change in the outcome ) does not easily map onto our original variables.
