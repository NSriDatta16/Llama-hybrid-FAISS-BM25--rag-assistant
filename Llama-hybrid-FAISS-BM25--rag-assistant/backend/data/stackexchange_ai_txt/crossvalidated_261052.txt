[site]: crossvalidated
[post_id]: 261052
[parent_id]: 261038
[tags]: 
It's a good question! The issue is not even mentioned on my time series books (I probably need better books :) First of all, note that you're not forced to use linear regression to detrend a time series, if the series has a stochastic trend (unit root) - you could simply take the first difference. But you do have to use linear regression, if the series has a deterministic trend. In this case it's true that the residuals are not iid , as you say. Just think of a series which has a linear trend, seasonal components, cyclic components, etc. all together - after linear regression the residuals are all but independent. The point is that you're not then using linear regression to make predictions or to form prediction intervals. It's just a part of your procedure for inference: you still need to apply other methods to arrive at uncorrelated residuals. So, while linear regression per se is not a valid inference procedure (it is not the correct statistical model) for most time series, a procedure which includes linear regression as one of its steps may be a valid model, if the model it assumes corresponds to the data generating process for the time series.
