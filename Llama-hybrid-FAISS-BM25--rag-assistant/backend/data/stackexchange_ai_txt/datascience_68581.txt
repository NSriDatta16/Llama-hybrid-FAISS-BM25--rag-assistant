[site]: datascience
[post_id]: 68581
[parent_id]: 30860
[tags]: 
Predict target (e.g. using a Random Forest) and retrieve "most important features" (from feature importance analysis). Cluster samples with selected features (e.g. using k-means). You must also scale based on variable importance. However, I am afraid the clustering technique used in the 2nd step might not catch behaviours found in the 1st step which might explain churn (suppose there is a complex interaction in some trees in the RF, this interaction might not be cought in the k-means algorithm). Scaling based on varimp will help with this. Actually I am not sure this is at all correct. Lets say conditional XOR based on two variables. That will divide the plane into 4 even squares where one class will be in diagonally opposite of the two squares. This does not exactly explain what is happening but it does show it. But then how to see into multidimensional space? Use hierarchical clustering diagram and color each end point by their resulting class. Look into random forest "proximity plots". Section 15.3.3 in elements of statistical learning .
