[site]: crossvalidated
[post_id]: 553821
[parent_id]: 551194
[tags]: 
There are many ways of representing a 3D rotation as some vector in $\mathbb{R}^n$ . However, many of these representations have the disadvantage that arbitrarily small rotations / change in rotation can lead to large differences the vector representation. For example, with euler angles, a small movement near the poles might be represented as a 180-degree rotation on one of the axes. In general, this is undesireable because it is hard for neural networks to learn "discontinuous" things, and easy for neural networks to learn "nicely behaved" things. Quanternions are one representation of rotations which don't suffer from this behavior, so they are a suitable input to neural nets.
