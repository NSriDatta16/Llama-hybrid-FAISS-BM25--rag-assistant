[site]: datascience
[post_id]: 75635
[parent_id]: 
[tags]: 
in NLP academic paper, would it be okay to refer the "token embeddings" as "tokens"?

I am writing a paper in Natural Language Processing (NLP), and I just have a quick question about terminology. In language models like Transformers, "token" refers to individual word in a text sequence, whereas there is a special term "token embedding" to refer to the embedding that results after token gets passed through the initial embedding layer. Would it be problematic if I just refer a "token embedding" as a "token"? (e.g. "interaction between hidden embeddings and token embeddings" ---> "interaction between hidden embeddings and tokens") I am trying to accommodate the different terminologies, but my sentences are getting really wordy... Thank you,
