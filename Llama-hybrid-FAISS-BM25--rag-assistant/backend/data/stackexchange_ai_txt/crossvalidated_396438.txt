[site]: crossvalidated
[post_id]: 396438
[parent_id]: 396429
[tags]: 
The short answer to your question is that you cannot use the pseudo $R^2$ from the full model. Your intuition is correct that it is inflated and disingenuous. That said, you should not use the pseudo $R^2$ from the final model, either. Part of the reason is that pseudo $R^2$ does not really mean what people think it means, and part of the reason is that any attempt to assess goodness of fit after stepwise selection will be irrevocably flawed. Put simply, you should not use stepwise selection at all. From there, decide how you want to assess your model. Generally, regression models are designed to pick out conditional means (i.e., the mean of $Y$ when $X$ equals some particular value). So goodness of fit would mean that the model's fitted values are approximately right. You could assess this in various ways, such as plots or tests against saturated models, etc. Alternatively, you could see how well the model predicts out of sample. This could be done via cross validation and Brier scores or calibration. The question of dropping the NA's is a different issue. That is called 'complete case analysis'. It is valid (but somewhat underpowered) under the assumption that the missingness is MCAR, and often still valid even under MAR (depending on the specifics of the situation). Here are some threads to read that might help you: Algorithms for automatic model selection Why are p-values misleading after performing a stepwise selection? Sane stepwise regression? Backward selection for Cox model using R Which pseudo- $R^2$ measure is the one to report for logistic regression (Cox & Snell or Nagelkerke)? Is $R^2$ useful or dangerous? Is listwise deletion / complete case analysis biased if data are not missing completely at random?
