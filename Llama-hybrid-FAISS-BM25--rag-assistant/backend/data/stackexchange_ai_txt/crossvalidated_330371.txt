[site]: crossvalidated
[post_id]: 330371
[parent_id]: 
[tags]: 
nested cross validation and class imbalance

I cannot find any answer or literature to my problem. I have completed a nested cross validation using the mlr package in R. Before I conducted the nested cross validation I first tried to improve my class imbalance for my dependant variable. To do this I used the ROSE package to generate synthetic values. I then scaled these synthetically generated values between 0 and 1 to allow me to try multiple algorithms (neural networks etc.). My question is would the synthetic values and scaling cause any issues in my outer loop and therefore would this give bias in my overall performance. ps I tried running the nested cross validation with the original data class imbalance and the models did not perform well according to AUC. however after the class improvement using rose my AUC improved significantly.
