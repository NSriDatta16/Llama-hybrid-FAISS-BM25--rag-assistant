[site]: crossvalidated
[post_id]: 248916
[parent_id]: 248812
[tags]: 
The answers so far emphasize the predictive failure of logistic regression. However there's also issues of poor feature importance/inference. For example, when your classes are highly correlate or highly nonlinear, the coefficients of your logistic regression will not correctly predict the gain/loss from each individual feature. In gung's example, if you were to train a logistic regression on the picture of points shown, it will likely create a linear split somewhere in the middle of the red region (for example a vertical line), implying that an increase of say, $x_1$, will lead to a higher probability of being a red class, which is true for $x_1$ starting to the left of the prediction boundary, and false for $x_1$ starting to the right.
