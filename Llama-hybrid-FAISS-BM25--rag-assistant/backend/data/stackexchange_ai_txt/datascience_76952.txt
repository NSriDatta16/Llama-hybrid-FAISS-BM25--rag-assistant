[site]: datascience
[post_id]: 76952
[parent_id]: 
[tags]: 
What is the best way to select unimportant columns for binary classification?

There is a dataset with one binary attribute (dependent variable) 0 or 1. Distribution 57/43 My task is to find such combinations of signs in which the accuracy of predictions 0/1 will increase to 70% and higher. And the second task is to create a template for the future for quick and convenient viewing of data and preliminary assessment. There are also 80 independent variables that we will predict. How can you quickly conduct visual analytics and discard those that do not have predictive value? I know the R language a little, it seems to me that rendering in it is much easier than in Python. So far, such a plan. Make data visualization in R. How to do it quickly and conveniently on 80 grounds and immediately discard unnecessary? Or is it not necessary to do this? Download in Python and through Pandas quickly make the run a simple ML algorithm or even just bust to find out which model is best suited and has the least fitting effect. Now broke the sample on Train / test 70/30 I will once advice on the first paragraph
