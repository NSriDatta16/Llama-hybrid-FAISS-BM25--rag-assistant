[site]: crossvalidated
[post_id]: 256316
[parent_id]: 256275
[tags]: 
The beta coefficients reported in tables of logistic regression models are usually log odds, also known as the logit. The logit model can be written as $$ \ln\left\{\frac{\text{Pr}(y=1|\text{x})}{\text{Pr}(y=0|\text{x})}\right\}=\ln\Omega(\text{x})=\beta_0+\beta_1x$$ for binary dependent and independent variable. The interpretation of coefficient ($\beta_1$) is similar to that of, let's say, simple linear regression, but the unit of the dependent variable is log odds (logit). So, we can simply interpret it as "for a unit change (let's say, if your independent variable is binary, from 0 to 1) in $x$, log odds of the outcome is expected to change by $\beta_1$ units" (if there would be other independent variables, we would add "holding other variables constant"). But as it has been noted in various sources, the interpretation of the logit might not be intuitive for the audience. In this case, the logit coefficients are transformed into odds. This has been accomplished by exponentiating both sides of the equation: $$\Omega(\text{x})=e^{\beta_0}e^{\beta{_1}{x}}$$ As a result of this transformation, our model becomes multiplicative and the interpretation of the coefficient changes: "for a unit change in $x$, the odds of the outcome are expected to change by a factor of exp($\beta_1$)." To make the interpretation of the odds easier, it can be reported as a percentage change, using a simple formula: $ \% \Delta=(e^{\beta_1}-1)*100$. I think this is the source of confusion. After using this formula the interpretation becomes: "for a unit change in $x$, the odds of the outcome are expected to change by $[(e^{\beta_1}-1)*100]$%." That is why in some tables in addition to $\beta$'s, $\text{exp}(\beta)$'s are reported as well. So I guess, in those papers you are referring to, they multiply $\text{exp}(\beta)$ by 100 after subtracting 1, not the beta coefficient (log odds/logit). I recommend Pampel's book (2000) as a short and simple introduction to logistic regression. It explains logits, odds, and predicted probabilities nicely. Pampel, F. C. (2000). Logistic Regression: A Primer . Thousand Oaks London New Delhi: Sage Publications.
