[site]: crossvalidated
[post_id]: 534514
[parent_id]: 
[tags]: 
How to tune parameters for novelty detection with only normal dataset

There exists multiple novelty detection methods. I'll discuss two: One-class SVM LOF Both of them have parameters. For example, the SVM has a $\nu$ parameter and if the SVM uses the RBF kernel, it has a smoothing parameter. The LOF has the parameter $k$ . To get good results, these parameters have to be tuned. However, in novelty detection, you only have one dataset which is normal on which the models are trained. Now in papers I see that the models are then tested on nonnormal data and the parameters are tuned to get a good prediction. However, then the training process uses both normal and nonnormal data which is not desired (if we assume tuning part of the training phase). I am in the situation were I only have only normal data. How can I tune the hyperparameters? Is this just a limitation of the methods? Maybe models with automatic tuning would resolve the issue.
