[site]: crossvalidated
[post_id]: 571449
[parent_id]: 571441
[tags]: 
Per Nuclear Hoagie's comment, if you have a labeled training data set a machine learning/classification approach may be possible. Otherwise, I'd start by visualizing the data. If times are recorded to the second (or even more precisely) it's probably reasonable to expect terminal digits to be uniformly distributed. There's a lot of literature on this as a test of data quality applied to different applications. So that's one place to start. Here are a few references: Rath, G. J. (1966). Randomization by Humans. The American Journal of Psychology, 79(1), 97â€“103. https://doi.org/10.2307/1420712 Schulz, M. A., Schmalbach, B., Brugger, P., & Witt, K. (2012). Analysing humanly generated random number sequences: a pattern-based approach. PloS one, 7(7), e41531. https://doi.org/10.1371/journal.pone.0041531 Another approach would be to look for duplicates. This can also be a marker of fabricated data. Here's a relevant paper related to surveys: Kuriakose, N., & Robbins, M. (2016). Don't get duped: Fraud through duplication in public opinion surveys. Statistical Journal of the IAOS, 32(3), 283-291. https://doi.org/10.3233/SJI-160978 I suspect there's also some reasonable assumptions about call times, etc. Visualizing this could be a good starting place and then perhaps you can supplement this with domain knowledge, e.g. I would expect much higher call frequencies at 2:00 p.m. than 2:00 a.m. Finally, you might want to try ascertain if the data looks too neat such that it might have been generated by a random sample of a particular distribution. This example from Datacoloda might be helpful.
