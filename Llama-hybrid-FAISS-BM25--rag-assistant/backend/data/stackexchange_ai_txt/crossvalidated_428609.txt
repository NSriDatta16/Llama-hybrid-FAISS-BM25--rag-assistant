[site]: crossvalidated
[post_id]: 428609
[parent_id]: 428554
[tags]: 
You could construct a new MDP which is the same as your old MDP, with the exception that the new state is actually the concatenation of (up to) $k+1$ states of your old MDP, where $k$ is the amount of delay. In your new MDP, the reward from going from state $s$ to $s'$ is obtained by computing the reward for going from state $s_0$ to $s_0'$ in the original MDP, where $s_0$ gets the first "sub-state" in the concatenated state. Our new MDP is indeed markov, and rewards are no longer delayed.
