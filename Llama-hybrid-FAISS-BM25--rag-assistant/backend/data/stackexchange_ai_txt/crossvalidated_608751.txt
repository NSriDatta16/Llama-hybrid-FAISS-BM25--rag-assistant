[site]: crossvalidated
[post_id]: 608751
[parent_id]: 608694
[tags]: 
As hashed over a bit in the comments. The usefulness of the model here is going to hinge heavily on how likely it is that the distribution of your future data is to match the training/validation data. I think it would be a serious mistake to assume they will match unless you could think of a super obvious reason why they wouldn't. I would assume there will be differences and test that hypothesis. If the generation of this data is stationary and highly likely to remain similar, then the model is probably useful, but you should make an attempt to quantify this (e.g. if your current data was gathered at different times, separate it into the earliest and latest data and check model performance within each subgroup and see if there are time-based trends in the data itself (look for time/geography/population-based trends in a wide range of statistics, means, medians, maxes, mins, curl, etc...) or if there is any other potential reason the data might change, e.g. new professional guidelines). I wouldn't recommend assuming the model will generalize even with good looking generalization on train/test/validation sets until you get a new real-world independent validation set. And then the model might work just for your company with exactly how you gather data right now, if you outsource the data gathering any sort of new semi-systemic idiosyncrasy might throw a serious wrench in the works. Likewise, it may not work at another branch office, etc... This sort of issue is a plague in precision medicine, in part because the large whole genome and exome data sets and GWAS studies are so biased towards white Europeans but when you want to go to clinical application you're suddenly not treating only white Europeans. Then there are false positives... you can have a SNP associated with their descent look associated with disease but have it turn out to be socioeconomic rather than genetic, etc... This is in part why ML hasn't obliterated much simpler statistical tests in that field. One of the rationales some have offered for including more diverse populations in GWAS is merely to reduce the false positives showing up for the currently available data. I try not to read that too cynically. Also, I'm aware of various attempts to use more recent ML methods (deep learning, gradient boosted trees, xgboost) for imputation in this field, but none of them have broken into mainstream use despite very flattering initial papers. Largely because when they are applied to new independent data they don't perform better than the HMMs and often quite a bit worse. When group B says they want to see much better performance, the actual threshold is arbitrary, but I think the sentiment is that they expect some loss of utility due to data differences and, unless the initial performance was strong, expect it is likely for the edge the model has to evaporate or even be harmful. Edit: I read now the comments where you say it is a logistic regression. Usually people tend not to say "My machine learning model" when it's a logistic regression even though it can indeed be considered machine learning. You are certainly less likely to have some of the issues described above when using simpler models like that, but it can still happen. I do lean towards it being useful, but it can still be worth validating the common assumptions (e.g. stationality).
