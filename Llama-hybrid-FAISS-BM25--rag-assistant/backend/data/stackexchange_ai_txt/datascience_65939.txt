[site]: datascience
[post_id]: 65939
[parent_id]: 65692
[tags]: 
It sounds like a great opportunity for feature engineering. You're contemplating this in your last paragraph so you're on the right track, but I'll elaborate on a possible solution here. You could use the features that you know will exist in the test set to construct synthetic features based on the context information. For example, you could predict the traffic given the datetime and location, whereas zoning would only be based on location. Similar with demographics and transit. Your goal at this stage would be to construct an algorithm to build each synthetic feature, knowing you will have to apply it per row on the test data (and any incoming data upon deployment). Then train your algorithm using the features that will exist in the test set and the synthetic features (not the extra context information). After that, construct the synthetic features in the test data. You're not creating new data here, you're just transforming features into what will hopefully be more descriptive features. Now you can use the real and synthetic features to evaluate the model you trained previously. I'm not saying this will definitely give you better results, but it's something I would explore. Ultimately this is just giving your ML algorithm a head start. Instead of blindly training a generic algorithm on the features that exist, we can use logic and common sense (and some extra information) to build part of the algorithm first (the feature transformations) to give the final classifier a better chance. Additionally, this way you can encode the information from the extra training data without having to deal with missing features in your test set.
