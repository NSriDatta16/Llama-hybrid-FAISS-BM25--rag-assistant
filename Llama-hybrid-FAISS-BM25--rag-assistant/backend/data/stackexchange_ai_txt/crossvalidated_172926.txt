[site]: crossvalidated
[post_id]: 172926
[parent_id]: 
[tags]: 
Linear regression with dichotomous outcomes

I recently came across an article and I wanted to get some opinions on it. The article essentially says that you can use linear regression (as opposed to logistic regression) when you have a dichotomous outcome and get nearly the same results. There is also a point about getting predicted values outside of 0 and 1 stating that you can take the negative values and values greater than 1 and transform them to be 0 and 1. There's obviously more than that in the article, but I'm curious what others' opinions are about this. Despite what we learn in statistics courses, is linear regression okay with a dichotomous outcome? What would be the issues with forcing inadmissable predicted values to 0 and 1? I searched on here and didn't find another question like this, but forgive me if there is! I'm still new to StackExchange. Here's a citation for the article: Hellevik, O. Linear versus logistic regression when the dependent variable is a dichotomy. 2009. Qual Quant, 43, 59-74. DOI 10.1007/s11135-007-9077-3
