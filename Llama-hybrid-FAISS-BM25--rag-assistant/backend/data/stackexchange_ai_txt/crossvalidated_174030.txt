[site]: crossvalidated
[post_id]: 174030
[parent_id]: 
[tags]: 
is it sensible to use monte carlo to predict sum of time-series over an interval?

I have created a model that forecasts out a time series at the daily level along with prediction intervals two months into the future. There is little to no auto-correlation in the time series so I used a regression-based model. The model's out-of-sample accuracy is generally excellent. I am now examining what the sum of activity (e.g., how many $$ will be spent) will be over a period (e.g., 11-1-2015 to 12-1-2015). To find the sum activity, I can just add up the prediction's for each day. I would like to place a confidence interval around my sum estimate ( e.g., predicted sum = $10,000 and there is a 95% chance we will spend between $7,000 and $13,000 ). So one question, if I assume that the uncertainty around my daily estimate is normally distributed, is it sensible to run monte-carlo simulations in which I: get a number for each day from the N(that days mean, Ïƒ2 derived from that days prediction interval) sum those numbers for the whole time period to get a predicted sum for that time period repeat a million times calculate distribution of predicted sums If this approach is not sensible or if there is a more standard alternative, can you let me know?
