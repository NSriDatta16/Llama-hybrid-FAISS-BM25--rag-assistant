[site]: crossvalidated
[post_id]: 527153
[parent_id]: 525949
[tags]: 
I would recommend you read West, Mike, and Jeff Harrison. Bayesian forecasting and dynamic models. Springer Science & Business Media, 2006 are there obvious theoretical issues with this setup? Yes, a few. A state space model is defined by an observation equation and a state equation. Terminology for these two equations varies across Kalman filter, linear dynamical systems, and dynamic linear models literature. Using your notation, the observation measurement $y_t^*$ is typically a composite of state $u_t$ and measurement error $o_t$ : $$ y_t^* = u_t + o_t ~.$$ $o_t$ and $o_s$ are independent for $s \neq t$ . It is not clear what measurement process would require the equation you provided. model the t-distributed variables using scale mixtures No. The $t$ -distribution is used to model normally distributed values when you (the modeler) do not know the variance of the values. The $t$ -distribution quickly converges to a normal distribution with increasing number of observations as the modeler "learns" the variance of the measurements. Inverse-gamma is useful to combine a prior distribution with observed data, forming a more precise posterior distribution. You certainly do not need both. Modeling unknown measurement noise is explained in West & Harrison. In your description, variance of observation noise $o_t$ is unknown and variance of evolution noise $\nu_t$ is known. West & Harrison address this scenario in one chapter. West & Harrison covers AR process modeling; and, shows mixture models for the detection and handling of outliers in state modeling. Observation noise $o_t$ is modeled to arise from a mixture of "typical" and "outlier" distributions. For instance, maybe typical measurement error is $o_t \sim N(0,V)$ and outlier measurement error is $o_t \sim N(0,100 V)$ . Good luck. I think you will make good progress using the book and a simple mixture model.
