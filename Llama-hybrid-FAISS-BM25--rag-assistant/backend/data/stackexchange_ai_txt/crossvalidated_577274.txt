[site]: crossvalidated
[post_id]: 577274
[parent_id]: 577230
[tags]: 
Shuffling does not harm. It helps with the gradient updates. For time series data, we prepare the data such that the entries of previous time instants are fed into RNNs in order, i.e. $X, y$ , where $X$ contains the previous time instants' targets or features. Shuffling is applied for different data samples, i.e. $(X_1,y_1), (X_2,y_2) ...$ Each libraries' shuffling logic can be different. In MLPRegressor , it says Whether to shuffle samples in each iteration So, in each iteration (probably epoch), the data is shuffled. So, at every epoch, the batches will be different.
