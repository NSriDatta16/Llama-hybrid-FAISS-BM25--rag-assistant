[site]: datascience
[post_id]: 55371
[parent_id]: 
[tags]: 
Which machine learning methods can be used to address MonteCarlo sampling problems?

I would like to pick the brains of machine learning experts here to point me to a branch of machine learning technique that is best suited for my context. I would like to estimate the average value $\bar{f}$ of a function $f$ specified generally as $$\bar{f} = \sum_{v\in\mathbb{Z}_2^n}p(v) f(v)$$ where $p(.)$ is a probability distribution over $n-$ bit sequences, $$p:\mathbb{Z}_2^n \rightarrow [0,1],$$ $$\sum_{v\in\mathbb{Z}_2^n}p(v) = 1.$$ The function $f$ maps sequences to real numbers, $$f:\mathbb{Z}_2^n \rightarrow [0,1].$$ Furthermore, changes to $p(v)$ and $f(v)$ resulting from local changes to $v$ , can be computed efficiently. This is a candidate problem for Monte Carlo sampling, where samples from $\mathbb{Z}_{2}^n$ are drawn according to $p(v)$ . The drawbacks of this method is that sometimes the estimated mean can suffer from large statistical in cases where f(.) is large for rare events. I’m new to the field of machine learning and was wondering if there’s a branch of this field that addresses problems of this nature. Any references would be greatly appreciated.
