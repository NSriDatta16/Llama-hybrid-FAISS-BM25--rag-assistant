[site]: crossvalidated
[post_id]: 281156
[parent_id]: 
[tags]: 
Interpretation of the Chi Square test for two time series in R

I've used R's "chisq.test()" function to calculate the chi square statistic between two time series, the first is a stock market series of a bank with a length 4262, and the second is a simulation of the first using some model with the same length. I used chisq.test as a measure of independence of the two series. Using R, I get the following output. Pearson's Chi-squared test data: as.numeric(banks[, 2]) and as.numeric(banks[, 3]) X-squared = 16117000, df = 16094000, p-value = 3.434e-05 Regardless of whether this method is correct, I don't understand where the high degrees of freedom comes from. I assumed the chi square test measures the statistic between two series using a 2 X length contingency table, with one column as observed and the other as expected. Can anyone tell me what is actually being calculated in this test?
