[site]: crossvalidated
[post_id]: 488367
[parent_id]: 
[tags]: 
Connection between Bayesian A/B testing and Fisher's exact test (specific example on Hydroxychloroquine trials)

I understand that there are multiple comparisons floating around between Fisher's Exact Test and Bayesian A/B Testing , here's an example . While I do understand these are fundamentally making different distributional assumptions about the data, I'm still confused as to which assumptions are driving the difference. What would be illuminating is an explanation about: Which "data generating story" corresponds to which test and why they're fundamentally different Which "data generating story" and therefore modeling approach is more appropriate for trial data such as below Let's focus on a very specific and currently relevant data set: using Hydroxychloroquine as post-exposure prophylaxis against COVID-19. The following data were presented in this paper : Incidence of new illness (COVID-19) for participants receiving hydroxychloroquine (49 of 414 [11.8%]) Incidence of new illness (COVID-19) for participants receiving placebo (58 of 407 [14.3%]) The absolute difference was −2.4 percentage points (95% confidence interval, −7.0 to 2.2; P=0.35 In the "STATISTICAL ANALYSIS" section, "We assessed the incidence of Covid-19 disease by day 14 with Fisher’s exact test" Fisher's Exact Test I was able to run a two-sided fisher.test in R and get the advertised P=0.35. I conceptually understand that the "null hypothesis" being tested is if these two samples (hydroxychloroquine vs. placebo patients getting sick) come from the same distribution. From the wiki article on the test: "The formula above gives the exact hypergeometric probability of observing this particular arrangement of the data, assuming the given marginal totals". Applying this to our specific example: a = patients who got hydroxychloroquine and got sick = 49 b = patients who got placebo and got sick = 58 c = patients who got hydroxychloroquine and did not get sick = 365 d = patients who got placebo and did not get sick = 349 Converting the data above to match the hypergeometric PMF/CDF variables: k = a = 49 n = a + c = 414 N = a + b + c + d = 821 K = a + b = 107 I was able to get the one-sided "less" fisher.test by computing the hypergeometric CDF using this calculator . This ties out with R's ~17.8%. Conceptually this to me means: "The probability of observing 49 or less people taking hydroxychloroquine and getting sick by pure chance in a sample of 414 from a population of 821 patients in which 107 total people got sick". The two-sided value reported in the paper is roughly twice this. This is roughly analogous to something like a two sided t-test. I understand this is a bit awkward to do as described in the wiki entry. Bayesian A/B Testing Let us ignore the problem of picking priors for now. Using the data above we can define two distributions of the proportion of people who get sick: B_hydroxychloroquine ~ Beta(49 + 1, 365 + 1) B_control ~ Beta(58 + 1, 349 + 1) We can estimate the probability (B_hydroxychloroquine - B_control) > 0 via simulation. It turns out to be ~15.3% (+/- 0.1% from simulation variance). Conceptually this to me means: "The probability that the proportion of people taking hydroxychloroquine and getting sick is greater than the proportion of people taking placebo and getting sick". What would be the equivalent to the two-sided fisher.test for the Bayesian A/B example? (My only guess is just to multiply the probability by two). Code Sample set.seed(101) n_sims 1 = %.3f\n', mean(ratio), quantile(ratio, probs = 0.025), quantile(ratio, probs = 0.975), mean(ratio > 1) ) ) # diff 0 = %.3f\n', mean(diff), quantile(diff, probs = 0.025), quantile(diff, probs = 0.975), mean(diff > 0) ) ) # contingency_table
