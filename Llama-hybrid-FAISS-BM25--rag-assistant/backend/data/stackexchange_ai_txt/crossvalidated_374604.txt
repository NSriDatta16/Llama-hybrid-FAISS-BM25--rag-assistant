[site]: crossvalidated
[post_id]: 374604
[parent_id]: 374588
[tags]: 
To accompany @RLave's answer, another important part why decision trees are favored by the practitioners is their fast estimation (due to very simple algorithm, as described, since despite from cut-points no parameters need to be estimated; and the restrictions, if imposed, are computationally simple) despite relatively large data, plus fast implementation for execution. Nowadays the implementation part may not be that important, but note that it is easy to implement a fast decision tree model using several cheap detectors and a logic board. So this adds a lot in practice, even though in most cases the trees are not the best accuracy wise. Random Forest and Boosting algorithms tries to tackle this, but either way they're often just a rough approximation of some complex nonlinear model. NB: Would've commented this, but not enough rep.
