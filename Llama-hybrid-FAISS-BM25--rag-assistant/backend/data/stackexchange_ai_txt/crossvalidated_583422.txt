[site]: crossvalidated
[post_id]: 583422
[parent_id]: 
[tags]: 
How to decide $X_n, n \in [0,\infty)$ is a Markov chain and how to compute transition probability matrix?

Three white and three black balls are distributed in two urns in such a way that each contains three balls. We say that the system is in state i, i = 0, 1, 2, 3, if the first urn contains i white balls. At each step, we draw one ball from each urn and place the ball drawn from the first urn into the second, and conversely with the ball from the second urn. Let $X_n$ denote the state of the system after the nth step. Explain why ${X_n, n = 0, 1, 2, . . .}$ is a Markov chain and calculate its transition probability matrix. Solution: Author computed transition probability matrix as follows: $$\begin{bmatrix} 0 & 1 & 0 & 0 \\ \frac19 & \frac49 & \frac49 & 0 \\ 0 & \frac49 & \frac49 & \frac19 \\ 0 & 0 & 1 & 0 \end{bmatrix}$$ After making some careful thinking, I came to the conclusion that author's computations for the above matrix is correct.
