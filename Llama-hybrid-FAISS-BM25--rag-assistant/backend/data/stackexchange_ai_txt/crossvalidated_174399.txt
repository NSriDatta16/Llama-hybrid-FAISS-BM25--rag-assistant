[site]: crossvalidated
[post_id]: 174399
[parent_id]: 174205
[tags]: 
I think you're on to the answer. Since your model will be used in predicting future games, the time component needs to be reflected in your validation and/or test sets. You can just split your data by time and use games from the end of the season to validate. This will not give you a way to measure the variability in your model's performance like cross validation. If that is what you want, you can use a rolling cross validation with this method. Let's say you have 10 games in a season, you can build the model with first 4 games, predict and record the performance on the next 2 games(games 5-6), next rebuild the model on the first 5 games using the same model parameters from the first '4 game model' and predict the next 2 games( games 6-7) and so on. Then average the performance across all 3 game test sets to get a mean performance of your model.
