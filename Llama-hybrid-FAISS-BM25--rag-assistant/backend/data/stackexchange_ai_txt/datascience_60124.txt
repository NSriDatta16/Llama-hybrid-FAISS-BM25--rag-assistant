[site]: datascience
[post_id]: 60124
[parent_id]: 
[tags]: 
Using Hausdorff Distance with Time

My company tracks objects. I have developed an algorithm that tries to identify objects that are attached to each other. It does this in real time and starts trying to identify objects after roughly 5 minutes of travel. Currently this uses some basic time filtering plus a Hausdorff distance algorithm to ensure it tracks objects that leave at roughly the right time and follow roughly the right path/trajectory. Note that these tracked object will certainly report their time & position at irregular intervals. (Between 30s and 5minutes per update) This alone achieves a great level of accuracy. However in certain cases four objects will leave at roughly the same time. Two primary objects each with an attached secondary object (i.e. 2 + 2). In this case the system fails. I thought that if I could somehow include time in the Hausdorff distance it may help improve the accuracy. Is this actually a viable solution and how might I modify my Hausdorff algorithm to also include a time series parameter? Failing this is there a suitable machine learning algorithm that would be worth looking at?
