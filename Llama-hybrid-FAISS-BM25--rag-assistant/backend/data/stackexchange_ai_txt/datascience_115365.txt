[site]: datascience
[post_id]: 115365
[parent_id]: 115361
[tags]: 
It depends on the task and many other things. CNNs and RNNs have different inductive biases. CNN applies the same function independently to each input slice and therefore it could be done in parallel (hence the higher speed). The drawback is that the output state of CNN only covers a limited input window. You can increase the size of the span from which an output state gets the information, but it will always be limited. For some tasks that are solvable by searching for some typical word patterns in the text, this might be good enough. LSTMs are a theoretically stronger model and it can in theory learn to model arbitrarily long dependencies between its inputs (unlike the CNN with the limited window size). In practice, this is not often the case because the training signal that you get from the closeby neighbors is much stronger than the long-distance dependencies. Regarding the speed: computing $n$ -th of an RNN requires knowing what the $(n-1)$ -th state is, which makes parallelization impossible.
