[site]: datascience
[post_id]: 37656
[parent_id]: 37368
[tags]: 
For the sake of completeness, fastText uses sub-word information (character level n-grams) when creating embeddings and then for classification with some interesting results: can give prediction for the unknown words that have some similarity with known ones with interesting results for modelling syntactic relations like 'went' - 'go' + 'give' = 'gave'
