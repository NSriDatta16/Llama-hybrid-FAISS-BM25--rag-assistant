[site]: crossvalidated
[post_id]: 361264
[parent_id]: 141919
[tags]: 
you cannot use early stopping and K-fold cross validation in combination. because the early stopping select best model from validation set, the performance needs to be verified by test set. but in K-fold cross validation, there is not test set, if you using early stopping to select best model from validation set, and it will verified again in validation set. the K-fold cross validation is getting the average performance (measured by accuracy) of best model, and it is meanless.
