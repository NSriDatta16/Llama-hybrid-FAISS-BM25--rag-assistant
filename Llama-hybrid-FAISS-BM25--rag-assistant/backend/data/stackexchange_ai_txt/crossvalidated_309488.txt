[site]: crossvalidated
[post_id]: 309488
[parent_id]: 309483
[tags]: 
As noted, typical statistical approaches based on L2 norms include the std dev as well as the coefficient of variation (which, for nonnegative metrics, produces a scale invariant measure) as well as the dispersion index (ratio of the variance to the mean). If the data is financial then it is also possible to calculate "upside" and/or "downside" measures of risk, aka above- or below-target semi-deviation , as described in these wiki articles ( https://en.wikipedia.org/wiki/Downside_risk or https://en.wikipedia.org/wiki/Upside_risk ). L1 norm-based measures are possible, for instance, the MAD or mean absolute deviation and the MADM, the median absolute deviation from the median. Other nonparametric estimates include the interquartile range, the interdecile range, as well as metrics discussed by Rousseeuw and Croux in their paper, Alternatives to the Median Absolute Deviation (ungated copy here ... http://web.ipac.caltech.edu/staff/fmasci/home/astro_refs/BetterThanMAD.pdf ). Information-theoretic approaches include measures of entropy ( https://en.wikipedia.org/wiki/Entropy_(information_theory) ), such as Theil's U or the many variants of indexes of information diversity (e.g., https://en.wikipedia.org/wiki/Generalized_entropy_index ). Hyndman's contention is that his MASE metric is optimal for time series data. MASE is a normalized loss function. After creating train and test data, the test data residuals are normalized or divided by the average error in the training data. If MASE See his paper, Hyndman and Koehler, Another look at measures of forecast accuracy, International Journal of Forecasting, 22(4):679-688, 2006, https://robjhyndman.com/papers/mase.pdf , p. 3
