[site]: datascience
[post_id]: 99683
[parent_id]: 99673
[tags]: 
To make it short - no. When you train a model (e.g a Neural Network) you parse some data X into the model, the model predicts something, $\hat{y}$ , you look at the correct target, $y$ , corresponding to X . Then you say "to reduce the difference between $\hat{y}$ and $y$ , what should my weights be?". Then the weights gets updated, and you parse in another round of X and $y$ untill you are happy. The validation set is used, often after each epoch but you could use it whenever you want, to say "If I stop training my network now - how would it act on unseen data"? If there is a too big difference between the error from the training and the validation error, then your model is overfitting and you need to correct that by e.g dropout. One of the core ideas behind the validation set is to not let the model learn from it, since it should act as "unseen/new" data.
