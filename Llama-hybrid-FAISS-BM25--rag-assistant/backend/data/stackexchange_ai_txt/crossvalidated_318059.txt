[site]: crossvalidated
[post_id]: 318059
[parent_id]: 315297
[tags]: 
After the discussion here, I can provide at least a partial answer. Apparently, pairwise calculation of correlation coefficients, especially if the data matrix has missing data, leads to a correlation matrix that is only positive semi-definite, not positive definite. Eigenvalues that are too extreme. According to http://epublications.bond.edu.au/cgi/viewcontent.cgi?article=1099&context=ejsie it is possible to counteract this effect by "shrinking" the matrix. To this purpose, a weighted average of the correlation matrix $R$ with a form matrix $F$ is calculated: $\hat{r}_{ij} = (1-\omega) r_{ij} + \omega f_{ij}$ with $\omega$ a weight factor from [0..1] (in the literature, it is often called $\lambda$, but as this symbol is used for eigenvalues already I have re-christend it). According to https://cssanalytics.files.wordpress.com/2013/10/shrinkage-simpler-is-better.pdf it doesn't really matter which form matrix one uses, I have tried both the identity matrix $I$ and the average matrix $\bar{R}$ (for each variable $i$ calculate the average correlation with all other variables $\bar{r}_i$, then $\bar{r}_{ij} = (\bar{r}_i + \bar{r}_j)/2$). The results are indeed very similar. What I still don't understand is why $R$ is so affected by missing data. I have done simulations with 10,000 data from $y = 1 + 2x + \epsilon$, with $\epsilon$ a Gaussian random number so that $r = 0.825$. Then I have set random elements of this matrix to NaN and recalculated $r$. For up to 20% missing data, the maximal deviation of $r$ was 0.01, and most of the data fell within Â± 0.005. Even for 50% missing data the maximum deviation was 0.015, for 70% 0.02. Surely this is not such a big effect?
