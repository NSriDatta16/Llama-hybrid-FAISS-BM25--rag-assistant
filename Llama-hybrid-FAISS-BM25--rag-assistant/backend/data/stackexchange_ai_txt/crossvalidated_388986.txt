[site]: crossvalidated
[post_id]: 388986
[parent_id]: 388970
[tags]: 
This is called mean-squared-error loss. If you try to use this loss, and train the model with gradient descent, you may run into a problem. This is because it sounds like you have a classification task, since you write about "labels". A neural network for classification with no hidden layer and softmax outputs is exactly a logistic regression. If you attempt to use mean-squared-error loss to estimate a logistic regression, you'll run into problems because this optimization task is not convex. Fo more information, see What is happening here, when I use squared loss in logistic regression setting?
