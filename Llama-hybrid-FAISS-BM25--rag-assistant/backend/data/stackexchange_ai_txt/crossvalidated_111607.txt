[site]: crossvalidated
[post_id]: 111607
[parent_id]: 111602
[tags]: 
There are several ways of deriving the test statistic for tests of the Pearson correlation, $\rho$. To obtain a $p$-value, it is worth emphasizing that you need both a test and a sampling distribution of a test statistic under the null hypothesis. Your title and question seems to have some confusion between Pearson correlation and the "variance explained" $r^2$. I will consider the correlation coefficient first. There is no "best" way to test the Pearson correlation which I'm aware of. Fisher's Z transformation is one such way, based on hyperbolic transformations, so that the inference is a little bit more efficient. This is certainly a "good" approach, but the sad bit is that inference for this parameter is consistent with inference about the slope parameter $\beta$ for association: they tell the same story in the long run. The reason why statisticians have (classically) wholly preferred tests of $\beta$ is because we do have a "best" test: linear regression, which is the BLUE estimator. In the days of modern statistics, we don't really care if a test is "best" any more, but linear regression has plenty of other fantastic properties that justify its continued usage for determining the association between two variables. In general, your intuition is right: they're essentially the same thing, and we focus our attention upon $\beta$ as a more practical measure of association. The $r^2$ is a function of both the slope and the intercept. If either of these values are nonzero, the $r^2$ should have a discernable sampling distribution relative to that which would be expected if the linear parameters were zero. However, deriving distributions of $r^2$ under the null and comparing to $r^2$ under some alternative hypothesis doesn't give me much confidence that this test has much power to detect what we want it to. Just a gut feeling. Again turning to "best" estimators, OLS gives us "best" estimates of both the slope and the intercept, so we have that confidence that our test is at least good for determining the same (if any) association by directly testing the model parameters. To me, jointly testing the $\alpha$ and $\beta$ with OLS is superior to any test about $r^2$ except in a rare case of (perhaps) a non-nested predictive modeling calibration application... but BIC would probably be a better measure in that scenario anyway.
