[site]: crossvalidated
[post_id]: 186973
[parent_id]: 31110
[tags]: 
Imagine a Bayesian linear regression: $$Y_i = x\beta_i + \epsilon_i$$ $$\beta_i \sim N(\beta_0,\Sigma_0)$$ One version of sparsity is to use a Laplace distribution (aka double exponential) as a prior for the $\beta$ coefficient in a Bayesian linear regression, as opposed to the Normal distribution one often uses. Here is a visual: The double exponential places much more weight around zero which "pulls" in small $\beta_i$ values and makes them 0, while leaving large values of $\beta_i$ still nonzero. This effectively zeros out many values in your parameter matrix, and hence induces sparsity. This is similar to the frequentist lasso.
