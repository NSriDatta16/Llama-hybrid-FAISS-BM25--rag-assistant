[site]: datascience
[post_id]: 77344
[parent_id]: 49334
[tags]: 
There’s a brilliant free interactive book here that explains how neural networks work if you want to understand them in more detail. The chapter I have linked to demonstrates that as long as there is at least one hidden layer, neural networks can approximate any function. As fractalnature says above, if there were no hidden layers each of your output neurons would actually be a generalised linear model that linearly combines the input features. Your neural network would effectively be a one vs rest classifier . In many cases this would perform well, and it would certainly be easier to train than a neural network, but it wouldn’t be able to achieve the same performance as it wouldn’t be able to model non linear relationships between the features.
