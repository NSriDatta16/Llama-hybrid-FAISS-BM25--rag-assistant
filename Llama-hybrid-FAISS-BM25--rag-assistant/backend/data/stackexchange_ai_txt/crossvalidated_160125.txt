[site]: crossvalidated
[post_id]: 160125
[parent_id]: 160103
[tags]: 
This is a general property of averaging processes and not specific to the normal distribution. If you have independent and identically distributed random variables $X_1, X_2, \ldots , X_n$ with $\text{Var}(X_1) = \sigma^2 $$ \begin{align} \text{Var} \left ( \frac{\sum_{i=1}^{n} X_i}{n} \right ) &= \frac{1}{n^2} \sum_{i=1}^{n} \text{Var}(X_i) \\ &= \frac{n \sigma^2}{n^2} \\ &= \frac{\sigma^2}{n} \end{align} $$ This makes sense if we think of each observation as a measurement of some average value $\mu$ plus an error term: $X_i = \mu + \epsilon_i$, where $\text{E}(\epsilon_i) = 0$. If we average up enough of these, we expect the error terms to roughly cancel and for the average to become increasingly concentrated around $\mu$.
