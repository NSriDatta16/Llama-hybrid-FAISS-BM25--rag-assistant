[site]: crossvalidated
[post_id]: 124651
[parent_id]: 
[tags]: 
How do I incorporate the biases in my feed-forward neural network

I'm trying to implement a FFNN. I'm doing this as an excercise to understand how biases play a role in the classification. I trained a NN using a package in R with the inputs being 1..100 and the labels being their square root in the range 1..10. The network topology is 1:10:1. I have all the weights and biases exported. If I implement the FF pass as I think I have to, I always get a value between 0 and 1. Which is very logical, because that's what the sigmoid function does. But in R, I get the correct answers for the root-able numbers being in the range of 1..10. So I'm thinking I'm implementing the biases wrong. For example, given a NN with the topology 1:4:1: If I have a weight vector $w$ with the weights $[0.12, 0.86, 0.20, 0.5]$ from my input neurons to the hidden layer, and I have the corresponding biases $b$ with values $[7.12, -6.20, 0.90, -3.6]$. What would my feed-forward pass look like from the input layer, through the hidden layer? I would appreciate a vectorized implementation, because my eventual implementation will have very large matrices.
