[site]: datascience
[post_id]: 43745
[parent_id]: 43739
[tags]: 
So, before just diving into the performance of the CNNs based on the two methods, just lets start with what they both will do to the input. The first method (IMG/255.0, and we'll call it scaling) will have the data scaled between 0 and 1. The second method (IMG - mean/STD, we'll call it centering) will have inputs ranging from arbitrary numbers (can be both positive and negative) with 0 being the mean. Scaling will improve the convergence speed of the model, whereas centering will not only speed up the convergence of the model, but will also deal with the gradient exploding and vanishing problem. As mentioned in CS231 , centering is enough, since it does the scaling thing as well. Lastly, as long as you don't have a very deep model, the two techniques won't make a lot of difference because batch-normalisation takes care of pretty much everything regarding image normalization, where all the layers receive the normalized data, and not only just the first one.
