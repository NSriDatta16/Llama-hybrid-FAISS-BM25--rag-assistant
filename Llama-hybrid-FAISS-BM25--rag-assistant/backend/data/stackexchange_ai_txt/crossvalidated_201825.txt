[site]: crossvalidated
[post_id]: 201825
[parent_id]: 
[tags]: 
Bounding the loss for kernel regularization algorithms

Some learning bounds depend on a quantity $M$ that is the maximum loss a learning algorithm can have: so $L(h(x),y) \leq M$, where $h(x)$ is the prediction of the model, and $y$ is the label, and $L$ is some loss function such as square or hinge loss. I'm interested in explicitly calculating $M$ or obtaining an expression for $M$. I'm looking at kernel regularization algorithms that minimize an objective of the form: $$\frac{1}{m}\sum_i L(h(x_i),y_i) + \lambda ||h||_K^2$$ such as ridge regression or SVM's.
