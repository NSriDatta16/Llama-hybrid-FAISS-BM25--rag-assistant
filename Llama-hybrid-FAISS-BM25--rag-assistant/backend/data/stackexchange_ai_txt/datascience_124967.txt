[site]: datascience
[post_id]: 124967
[parent_id]: 124899
[tags]: 
My baseline for this task is as follows (to analyze the abstract): tokenize abstract, normalize tokens, vectorize tokens (FastText, BERT, ...), add vectors, cluster with DBSCAN, changing threshold and analyzing clusters. It's fashionable to try to do the same with keywords. But it's all baseline. Advanced topic modeling of scientific articles requires models that take into account the hierarchy of topics, different modalities (abstract s and keywords), and so on. For a similar task, I recently used BigARTM .
