[site]: crossvalidated
[post_id]: 252644
[parent_id]: 
[tags]: 
does bp need to be simultanious? - XOR learning problem

I have a problem with XOR learning. I have 2(inputs),2,1(output) neuron neural network with sigmoidal function and normal sets (0,0.9)->0.9 (0.9,0.9)->0.1 (0.9,0.1)->0.9 (0.1,0.1)->0.1 of learning sets, plus bias neuron with 1.0 output connected to hidden layer and output layer. Despite changing biased neuron output and randomizing order of using learning set, the usual output of this network is like: 0.5070491199305279 0.506573763380741 0.5065628483577969 0.5070403151187465 which is zero given to sigmoidal function and mostly they tend to return almost the same output. like 0.4308536422848425 0.4308546005321358 0.43085460201816195 0.4308536440377257 Do you think that this is problem concerned with a fact that my backpropagation isn't simultaneous (I change weights every one case not after full set). Or maybe my network is missing something? Values of inputs and outputs for third case;
