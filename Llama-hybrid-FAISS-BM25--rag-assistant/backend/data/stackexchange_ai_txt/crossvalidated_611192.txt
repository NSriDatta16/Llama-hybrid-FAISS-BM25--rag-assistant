[site]: crossvalidated
[post_id]: 611192
[parent_id]: 611185
[tags]: 
You might just as well ask, "Why is the sample correlation between two independent variables always non-zero?" and the answer is the same: samples never conserve the properties of the probability models that generate them unless they are, somehow, perfectly balanced. Consider this example where I generate data that have errors generated straight from empirical normal quantiles. That is that the ECDF of the residual very closely matches the normal distribution. library(boot) set.seed(123) x $y x + data$e f Gives: > confint(f) 2.5 % 97.5 % (Intercept) -0.02422861 0.02422861 x 0.98623908 1.01376092 > boot.ci(b, type='norm') BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS Based on 1000 bootstrap replicates CALL : boot.ci(boot.out = b, type = "norm") Intervals : Level Normal 95% ( 0.9861, 1.0140 ) Calculations and Intervals on Original Scale Which agrees out to nearly 4 decimal places. The asymptotic result is that these are the same, but in finite samples, you'll never have perfectly normal residuals. It's true that Gauss-Markov does not require that errors are normally distributed. It is an asymptotic result. But the question bears consideration: if the bootstrapped error estimate is very different from the model-based error estimate, should you go with the bootstrapped error estimate because the probability model is misspecified? It can go both ways. Change the above to a simulation to consider the 80% coverage of the CIs. library(boot) set.seed(123) `%has%` ci[1] & true $y x + data$e f Gives: > rowMeans(res) olscover bscover 0.795 0.782 In other words, the bootstrap fails to produce CIs that cover at the nominal 80% rate. The difference is not substantial, and the simulation isn't exactly fast, but you can play with it to understand the risks. The bootstrap is just slower to converge, so in small sample like this N=7 regression, when the OLS assumptions hold, the OLS is the better answer. On the other hand, you don't know when those assumptions are true, and if you have decent power, the bootstrap is a robust safeguard against model misspecifications.
