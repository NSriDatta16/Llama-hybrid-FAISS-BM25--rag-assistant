[site]: crossvalidated
[post_id]: 281207
[parent_id]: 15303
[tags]: 
I think the issue is that there are two things involved here. A typical example of random effects might be predicting the grade point average (GPA) of a college student based on a number of factors including their average score in a series of tests during high school. The average score is continuous . You would typically have a varying intercept, or intercept and slope, for the average score for each individual. The individual is obviously categorical . So when you say "only applies to categorical variables" it's a little vague. Say you only consider a random intercept for the average score. In this case, your random intercept for a continuous quantity and in fact is probably modeled as something like a gaussian variable with a mean and standard deviation to be determined by the procedure. But this random intercept is determined across a population of students where each student is identified by a categorical variable. You could use a "continuous" variable instead of student ID. Maybe you could choose a student's height. But it would essentially have to be treated as if it were categorical. If your height measurements were very precise you'd again end up with a unique height for every student so would have accomplished nothing different. If your height measurements were not very precise, you'd end up lumping multiple students together at each height. (Mixing their scores in a possibly ill-defined way.) This is sort-of the opposite of interactions. In an interaction, you're multiplying two variables and essentially treating both as continuous. A categorical variable would be broken up into a set of 0/1 dummy variables and the 0 or 1 would be multiplied times the other variable in the interaction. The bottom line is that a "random effect" is in some sense just a coefficient which has a distribution (is modeled) rather than a fixed value.
