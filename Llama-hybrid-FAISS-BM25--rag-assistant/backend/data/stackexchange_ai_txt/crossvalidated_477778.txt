[site]: crossvalidated
[post_id]: 477778
[parent_id]: 477264
[tags]: 
Assuming you want to use the Wald tests or the Likelihood ratio tests, which are standard, you need to verify that the likelihood function is correct. A major assumption is that the binary dependent variable data values are conditionally independent, given the predictor variables' data. This assumption is needed to allow for the construction of the likelihood function as the product of individual likelihoods. You can assess this assumption first by knowledge of the data-generating process - is it time series? Is it repeated measures or longitudinal? Cluster samples? All those cases would indicate possible dependence structure. After that, if the data generating mechanism does follow such a dependence producing mechanism, you can "test" whether it is a problem by fitting a model that allows such a dependence structure and comparing a likelihood-based measure of fit with that of a comparable model that assumes independence. There is no normality or homoscedasticity assumption here; both are subsumed under the assumption of a Bernoulli distribution for the dependent variable, which is automatically true with binary response, and therefore need not be tested. (Both normality and homoscedasticity are obviously false here because of the Bernoulli response, but you don't care, because you are in fact assuming a Bernoulli response.) The other major assumption needed for correctness of the likelihood function is that the conditional probability of a particular outcome is linearly related to the predictor variables on the logit scale. While this assumption is crucial, it is obviously false to one degree or another, except in degenerate cases such as when there is only one predictor variable that can itself take only two values. To assess the validity of this assumption you can fit models that allow curvature, such as models with transformed X variables, models with interactions, models with quadratics, etc., and compare likelihood-based measures of fit. A final caveat, some might call it an assumption: These tests are large sample tests, so they are better with large sample sizes. You can assess whether the the sample sizes are large enough by repeatedly simulating data from a process like the one that produced your data, but with zero effects, using the same sample size, and counting the proportion of p
