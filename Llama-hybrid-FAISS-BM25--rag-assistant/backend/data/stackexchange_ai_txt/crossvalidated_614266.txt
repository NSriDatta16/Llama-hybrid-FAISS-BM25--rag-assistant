[site]: crossvalidated
[post_id]: 614266
[parent_id]: 
[tags]: 
Comparing RMSE values across different datasets

I am working on a PV energy production forecasting problem. With various ML models (ANN, RNN, LSTM) I am trying to predict the energy for the following day, based on the historical data. The aggregated dataset consists of multiple individual datasets from PV systems with different peak values. My idea is to normalize each PV system by production_value / max_production_value before aggregating the datasets. So far so good, however, when forecasting the production (always one day in the future) a question arises. I want to see which day was forecasted most accurately, and for that I am using the RMSE. The problem is, even if my data is normalized, the production is in summer higher than in winter. (Summer production after normalizing ~1, and in winter ~0.4). Now when I compare the RMSE of a summer day with the RMSE of a winter day, the winter has a lower RMSE. Even after a visual inspection it is visible that summer days are more accurate. Now I am looking for a way to quantify the error in a way that is comparable in this case. I was thinking about normalizing each day again before calculating the RMSE. However, I have the feeling there should exist a more straight forward way.
