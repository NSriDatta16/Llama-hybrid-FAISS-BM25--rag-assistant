[site]: crossvalidated
[post_id]: 548651
[parent_id]: 548302
[tags]: 
You need to collect relevant data. The 1000 symbols that you have right now are not representative of the task that you want to achieve. You have 1000 symbols that are "perfect" -- they're centered in the square, they're the same size, the backgrounds are uniform gray, they're all the same resolution. But the problem you're trying to solve isn't about how to label these perfect images; it's about how to address the cases of imperfect images. However, new examples may indeed come, for example improperly cropped squares, or re-sized images (smaller resolution). In an extreme case someone might even provide a very improperly cropped square which would include some background around it. The bg may be anything, no constraints. In such case - should I recognize the borders of the squares first and then proceed (how?) What you need to do is collect examples of the kinds of images that you will be classifying -- the ones with weird backgrounds, improper cropping, are resized, etc. One shortcut to collect this kind of data is to apply transformations to your perfect images -- translate the character, make the background look like one of the imperfect backgrounds, etc. But this is only a viable strategy insofar as the transformations that you apply are relevant to the transformations you'll encounter when using the model. This is why data collection is important -- you won't know about the transformations that you don't know about, so you'll need to collect examples. After you've collected data, this seems like a standard character recognition task. One common approach is to use convolutional neural networks, but there are many others.
