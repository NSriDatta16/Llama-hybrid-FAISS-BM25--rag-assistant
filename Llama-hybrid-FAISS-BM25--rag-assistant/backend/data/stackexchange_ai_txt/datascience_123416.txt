[site]: datascience
[post_id]: 123416
[parent_id]: 
[tags]: 
Is it possible to train an ML model that predicts two different types of variables (numeric, categorial)? Is learning a ranking function possible?

Problem setup: We are given a set of training instances and an algorithm C, composed of two randomized algorithms, A and B. Algorithm A has no hyperparameters. In contrast, B has only one hyperparameter, which can take an integer value between one and 10. Training data generation: Algorithm A is executed multiple times on each training instance to produce a set of initial solutions. Note that we can extract a feature vector from each initial solution. While the produced objective values of the initial solutions can be identical, the feature vector may differ. However, in practice, this is unlikely. Given a set of initial solutions produced by algorithm A, algorithm B is subsequently performed with different hyperparameter settings (one to 10) on each initial solution to improve its solution quality further. In this way, we obtain a training set: The inputs are the initial solution qualities (or better, their corresponding feature vectors), and the labels are the final solution qualities and the chosen hyperparameters in algorithm B, e.g. Initial Solution (A) Hyperparameter (B) Final Solution (A+B) 5.4 1 3.1 6.6 2 2.2 6.7 2 2.5 4.1 5 5.3 (A) Solution produced by algorithm A: Input (feature vector). (B) Hyparameter used in algorithm B: Label. (A+B) final solution obtained by executing algorithm A and then algorithm B: Label. The input to the ML model is the feature vector of the initial solution. The output is the final solution quality and the hyperparameter used in algorithm B. Goal: First possibility: For a given test instance, algorithm A produces a set of initial solutions, e.g., ten initial solutions. Given the set of initial solutions (feature vectors), the trained ML model takes as input the feature vector w.r.t each initial solution and should output the final solution quality and the chosen hyperparameter for algorithm B. I aim to train an ML model that predicts which initial solution w.r.t. its corresponding feature vector is most promising to obtain a high-quality solution after applying algorithm B. Solution Approach: Applying the trained ML model to each initial solution and its feature vector makes it possible to induce a ranking. However, in this scenario, we must sequentially apply the ML model to each initial solution (feature vector). This approach is very inefficient. Isnt it? Second possibility: Learn a ranking function; see Questions. Questions: Is it possible to train an ML model that outputs two values (one numerical and one categorical value)? I know that training an MLP that outputs two numerical values is possible, and rounding the categorical variable could be an option. However, the prediction quality will be imprecise due to the bias induced by rounding. Isnt it? Another option would be to train two MLPs. One for predicting the final solution and one for the hyperparameter. However, since runtime plays an important role, I wonder if applying two MLPs in sequence is much slower than applying only one MLP. Basically, my goal is to learn a ranking function, trained on the initial solution qualities (feature vectors), that takes as input a set of initial solutions and outputs a ranking and the chosen hyperparameter of algorithm B., e.g., Initial Solution (ML input) Hyperparameter (ML output) Final Solution Rank (ML output) 4.7 2 5.1 3 1.2 4 1.2 1 7.3 2 6.5 4 5.8 7 2.3 2 What is the most suitable approach to solve this task? And which ML model should I use? It should produce predictions extremely fast. To the best of my knowledge, SVM is most suitable when dealing with fewer number of features. Each initial solution has 16 features, and thus, SVM is the most suitable ML model for my task. isnt it? But can SVM be applied to my task? What about MLPs?
