[site]: datascience
[post_id]: 116412
[parent_id]: 
[tags]: 
Of all the books ever published in English, what percentage are available for NLP training?

I notice a lot of NLP models are trained on news articles and Wikipedia content and some books. I wonder if NLP models would be better if they were trained on more books. I assume we don't have datasets/corpus of all books published in English for example. Is this true? Does anyone have any idea what percentage of books published in English are available as NLP training data?
