[site]: crossvalidated
[post_id]: 401663
[parent_id]: 401655
[tags]: 
Two things to try: model.add(LSTM(100, input_shape= (10, 5))) model.add(Dense(50, activation='relu')) model.add(Dense(25, activation='relu')) model.add(Dense(10, activation='relu')) model.add(Dense(1, activation='sigmoid')) and try batch_size=32 . The default is 16, I think, and 1,000 is pretty large. I've found that large jumps down in the number of dense units (100 to 1) are more fragile than more moderate jumps. The LSTM cells are creating features, and the Dense layers are creating a classifier, and my guess is you need a better classifier.
