[site]: crossvalidated
[post_id]: 518029
[parent_id]: 29811
[tags]: 
I want to add some thoughts on the problem at hand, so that the discussion may roll on. However, I propose something else to think about, so others may comment on this. When reading this post and the post in the highlighted link , we try to overcome the bias in the RF (possibly in the tails) and to correct biased output of the RF , by applying another method, e.g. elastic net . However doing an elastic net first, and then doing the RF or vice versa has not led to a well-received solution. We try to stack methods one after another to overcome their downsides, but with no success. The Problem may be buried in the procedural usage of two methods after each method gave its word on all features in the equation. I'm not speaking about parallelism here. I mean, what if we gave word for every feature with a function of its own. When we do a RF to predict the outcome of some function $f(x)$ we try to model all features $x_1 x_2$ , the whole equation, all at once with one method. In other words summed trees or the opinion of all trees come to an averaged conclusion on how to deal with all features in the equation. The elastic net does the same when choosing $\lambda$ for regularization. But we are doing it on all features at once, and that means, that one or maybe two features have a downside from this. Someone has to draw the short straw . Maybe the Find as the previous poster stated is not the real Find , as it wants to find another method to correct the misbehavior. Maybe the real Find lies not in stacking methods after another. What if we can try to give word to every feature by applying one method for every feature. Like $y = a_0 * + a_1*f_1(x_1) + ... + a_n*f_n(x_n)$ . I did not heard of it, until I read it myself. I'm talking about the interpret ML package by microsoft. Although at the moment It only supports trees as base learners (Dr. Robert KÃ¼bler) it may shed some light on the problem. I just wanted to give some thought that we may have to look for a different way instead of 'correcting' our route. Paper Microsoft: https://arxiv.org/pdf/1909.09223.pdf Medium: https://towardsdatascience.com/the-explainable-boosting-machine-f24152509ebb
