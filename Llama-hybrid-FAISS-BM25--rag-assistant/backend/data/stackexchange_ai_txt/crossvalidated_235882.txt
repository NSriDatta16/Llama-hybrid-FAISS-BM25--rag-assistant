[site]: crossvalidated
[post_id]: 235882
[parent_id]: 
[tags]: 
PCA in numpy and sklearn produces different results

Am i misunderstanding something. This is my code using sklearn import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D from sklearn import decomposition from sklearn import datasets from sklearn.preprocessing import StandardScaler pca = decomposition.PCA(n_components=3) x = np.array([ [0.387,4878, 5.42], [0.723,12104,5.25], [1,12756,5.52], [1.524,6787,3.94], ]) pca.fit_transform(x) Output: array([[ -4.25324997e+03, -8.41288672e-01, -8.37858943e-03], [ 2.97275001e+03, -1.25977271e-01, 1.82476780e-01], [ 3.62475003e+03, -1.56843494e-01, -1.65224286e-01], [ -2.34425007e+03, 1.12410944e+00, -8.87390454e-03]]) Using numpy methods x_std = StandardScaler().fit_transform(x) cov = np.cov(x_std.T) ev , eig = np.linalg.eig(cov) a = eig.dot(x_std.T) Output array([[ 0.06406894, 0.94063993, -1.62373172], [-0.35357757, 0.7509653 , 0.63365168], [ 0.29312477, 0.6710958 , 1.11766206], [-0.00361615, -2.36270102, -0.12758202]]) I have kept all 3 components but it doesnt seem to allow me to retain my original data. May I know why is it so? If I want to obtain back my original matrix what should I do?
