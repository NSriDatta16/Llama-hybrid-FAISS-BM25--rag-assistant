[site]: crossvalidated
[post_id]: 215733
[parent_id]: 
[tags]: 
SVM subgradient-descent (Pegasos algorithm)

I am trying to implement the Pegasos algorithm for large scale SVM training . I'm following the main paper Pegasos . Everything worked fine but the results are quite disappointing. The code: % I have my data matrix (m x n) where m % is the no. of samples and n is the % dimensionality. % X(i) is i-th data vector % Y(i) is class {-1,+1} % I have 200 examples of dimensionality 2 % and data is linearly separable W = zeros([n, 1]); % the weight vector lambda = 1e-5; % the regularization param T = 5000; % max iter k = 100; % batch size for t = 1 : T % iterate T times A = randperm(m, k); % choose random subset % of k data vector eta_t = 1 / (lambda * t); % eta of the algo % at iteration t Ap = []; for q = A % choose the examples which % satisfy the condition if (W*X(q)) * Y(q) I commented in the code which I think is enough to understand the meaning of each line. And for the algorithm, refer to Fig.2 of the paper given. And the result after training is this. Sometimes the result is even worse. Where did I go wrong. Any help is appreciated.
