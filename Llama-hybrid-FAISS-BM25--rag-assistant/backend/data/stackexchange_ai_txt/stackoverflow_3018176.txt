[site]: stackoverflow
[post_id]: 3018176
[parent_id]: 3018097
[tags]: 
As I sit here with umpteen versions of various windows VMs on my work machine I never really need that on the Mac. The biggest reason is the way that applications are deployed in bundles on the Mac. Ideally, installation is a copy and uninstallation is dragging the app to the trash. On windows you have much more shared state between applications that must be accounted for that most apps don't have on the Mac. Now if you are writing a device driver or VPN client or something that needs to get into those parts of the system then you don't have that luxury. Where I really feel the need for virtualization is when I want to target different versions of OS X, or do some sort of regression check to see if things really did work different under version X.Y.X. So how do we achieve what you are going for, the default is don't care because you don't have the same risks due to app bundles. Or if you care then buy a bunch of external hard drives to boot off of and swap them out as need be. (I only did that once for two versions of OS X, so I cannot say it really is industry practice.)
