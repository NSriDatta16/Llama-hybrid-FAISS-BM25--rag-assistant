[site]: crossvalidated
[post_id]: 301267
[parent_id]: 
[tags]: 
Intuitive Understanding of LSTMs

I have some general understanding of how LSTMs Neural Networks function, but no experience. Does the following make sense in the context of how an LSTM network functions? Imagine this process (loosely based on encryption): Input Data -> Process A -> Process B -> Process C -> Output B -> Process D -> Output Data \_ Output A _______________________/ A Process can be considered to be a mathematical or bitwise operation. Outputs are numerical data. Can LSTM memory units be used to store Output A and Output B per training step? Can data in the memory units be used within the same training step, for, say, some fully connected layers later on?
