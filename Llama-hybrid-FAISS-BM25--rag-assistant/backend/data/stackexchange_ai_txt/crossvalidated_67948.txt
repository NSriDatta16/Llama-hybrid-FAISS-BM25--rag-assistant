[site]: crossvalidated
[post_id]: 67948
[parent_id]: 67940
[tags]: 
I'm working on that competition (stumbleUpon) as well. Although I'm not an expert in machine learning, I would say that maybe the most important part of such an analysis is the so-called 'feature engineering'. That is, do not use all the HTML code as a text, I'm not sure that much information is hidden in the text itself (because you feed your algorithm with a lot of junk). Instead, try to identify more specific features that you could extract from the HTML code such as 'Number of tags' etc. You could also use the AlchemyAPI (it's free) to complete some missing data. I'd also advise to visit some of the webpages yourself and identify anything that shows whether each page is 'evergreen' or not. Then you can use these hints and extract the relevant data from the HTML code. Of course, it's very easy to try out various algorithms (trees in all their forms, nnets and kernel SVMs) once you have pre-processed your data.
