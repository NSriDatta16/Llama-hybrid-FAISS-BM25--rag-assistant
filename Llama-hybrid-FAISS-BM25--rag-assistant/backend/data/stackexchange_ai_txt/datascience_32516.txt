[site]: datascience
[post_id]: 32516
[parent_id]: 32478
[tags]: 
The only way to find out is to try it, but I doubt it. A Kalman makes a specific assumption about the "priors", i.e., about the nature of how the signals are related over time. This is based on knowledge about the physics of movement and how this affects the sensor values, combined with some assumptions about the likelihood of different kinds of movements. Assuming the model and assumptions are accurate, this helps provide a more accurate estimate of the orientation. In contrast, a recurrent neural network has no knowledge built in, and no useful "priors". It has no model about the physics of movements and no assumptions. In principle, this makes it more general. But in practice, it means that, if you have a limited amount of data, it is likely to be less accurate. In general, a strong prior and useful model can be very helpful. In the limit, as you have an unlimited amount of data, you might not need a model. But with a limited amount of data, the model can be helpful. The Kalman filter provides a pretty reasonable model, and when trying to work with data from IMUs, we typically have only a limited amount of data. The place where RNNs could be more effective would be if the assumptions made by the Kalman filter's model do not correspond to reality. Then, you could imagine that RNNs could possibly learn the dynamics, because they don't assume a particular model, whereas Kalman filter is locked into a particular model. I don't particularly expect this to happen in practice, but it's a possibility. Overall, from first principles, I would expect/predict RNNs to be less effective than Kalman filtering. But that's just speculation/guessing. If you really want to know, the way to find out for sure is to try some experiments.
