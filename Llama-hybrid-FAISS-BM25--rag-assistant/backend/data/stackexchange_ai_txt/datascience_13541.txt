[site]: datascience
[post_id]: 13541
[parent_id]: 13504
[tags]: 
A large component of data science work in industry is data wrangling. It is quite important to have some basic understanding of data storage systems as you will often have to extract the data you need yourself (unless you work for a large company). Hadoop may not be a necessary skill, but knowing something of relational data stores (SQL) and object storage (No-SQL) will be very useful. A person often needs to be able to process data quickly too, so you will need to know something of optimisations such as indexing. I work in python and R (as do most practitioners I know personally), but find that python is easier to deploy in a production environment. Much of the work relies on libraries these days, so it useful to know the language's library landscape (when it comes to project timelines, familiarity with your tools reduces the pressure on yourself and your team immensely). It is quite common that people experiment in jupyter/ipython notebooks and make their code available online (e.g. KDNuggets post ). We often use notebooks at work and commit them to the code-base to provide the empirical backing for the solution. I would recommend you find some cool notebooks that interface with a database, and see if you can run their code (it is python typically). At least this way you will start to get a feel for more of the grunt work associated with the tools (considering that you already have the theoretical background).
