[site]: crossvalidated
[post_id]: 6348
[parent_id]: 6330
[tags]: 
Some caveats before to proceed. As I often suggest to my students, use auto.arima() things only as a first approximation to your final result or if you want to have parsimonious model when you check that your rival theory-based model do better. Data You have clearly to start from the description of time series data you are working with. In macro-econometrics you usually work with aggregated data, and geometric means (surprisingly) have more empirical evidence for macro time series data, probably because most of them decomposable into exponentially growing trend . By the way Rob's suggestion "visually" works for time series with clear seasonal part , as slowly varying annual data is less clear for the increases in variation. Luckily exponentially growing trend is usually seen (if it seems to be linear, than no need for logs). Model If your analysis is based on some theory that states that some weighted geometric mean $Y(t) = X_1^{\alpha_1}(t)...X_k^{\alpha_k}(t)\varepsilon(t)$ more known as the multiplicative regression model is the one you have to work with. Then you usually move to a log-log regression model , that is linear in parameters and most of your variables, but some growth rates, are transformed. In financial econometrics logs are a common thing due to the popularity of log-returns, because... Log transformations have nice properties In log-log regression model it is the interpretation of estimated parameter, say $\alpha_i$ as the elasticity of $Y(t)$ on $X_i(t)$. In error-correction models we have an empirically stronger assumption that proportions are more stable ( stationary ) than the absolute differences. In financial econometrics it is easy to aggregate the log-returns over time . There are many other reasons not mentioned here. Finally Note that log-transformation is usually applied to non-negative (level) variables. If you observe the differences of two time series (net export, for instance) it is not even possible to take the log, you have either to search for original data in levels or assume the form of common trend that was subtracted. [ addition after edit ] If you still want a statistical criterion for when to do log transformation a simple solution would be any test for heteroscedasticity. In the case of increasing variance I would recommend Goldfeld-Quandt Test or similar to it. In R it is located in library(lmtest) and is denoted by gqtest(y~1) function. Simply regress on intercept term if you don't have any regression model, y is your dependent variable.
