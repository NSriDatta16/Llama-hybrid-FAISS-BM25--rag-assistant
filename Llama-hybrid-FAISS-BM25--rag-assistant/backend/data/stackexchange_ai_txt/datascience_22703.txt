[site]: datascience
[post_id]: 22703
[parent_id]: 
[tags]: 
What are the advantages of Skip-Gram methods?

Concerning the notion of word embeddings, Skip-Gram methods aim for computing the probability of a word given its neighborhood. I do not understand the rationale behind it, since it is possible to infer this information by looking directly into the co-occurrence matrix. In general, I cannot understand those methods aiming to capture as much relevant information from the original co-occurrence matrix as possible. Isn't it easier to work on the co-occurrence matrix directly? Thank you very much in advance.
