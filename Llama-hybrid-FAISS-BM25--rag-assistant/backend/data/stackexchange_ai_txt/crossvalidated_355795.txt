[site]: crossvalidated
[post_id]: 355795
[parent_id]: 355787
[tags]: 
PCA is not solving the eigenproblem on the data itself, but rather on the correlation matrix of the data. The correlation matrix of the identity matrix is $ cor \Big( \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} \Big) = \begin{bmatrix} 1 & -1 \\ -1 & 1 \end{bmatrix} $ But clearly there is only one component here: $[1 -1]^T$ because the second column is simply the first times $-1$. Normalize to get $\begin{bmatrix} \frac{1}{\sqrt(2)} \\ \frac{-1}{\sqrt(2)} \end{bmatrix}$ Which is the first basis vector of pca.components_ in your code. To get the second basis vector, we choose the only vector orthogonal to the first. Note that our original data, the identity matrix, actually exhibits perfect multiple colinearity. Because only the first basis vector is needed to represent our data, it gets a loading and an explained variance of 1, while the other gets 0. The fact that it is not exactly zero is simply due to numerical imprecision; it is simply not possible to represent $\sqrt{2}$ exactly as a floating point number so when we try we are off by an small amount. That's where the 2.8e-34 in your code comes from.
