[site]: crossvalidated
[post_id]: 622435
[parent_id]: 620764
[tags]: 
First, a side note: There are no nonparametric tests for comparing means. A mean is an inherently parametric thing. Nonparametric tests primarily test whether responses in one group tend to be larger than responses in another group (stochastic ordering; concordance probability). A second side note: Regarding the Wilcoxon signed-rank test. This test, unlike the unpaired Wilcoxon-Mann-Whitney two-sample rank test, yields different answers depending on how you transform Y. The rank difference test solves this problem. But you have come up against a problem. We have flexible ordinal regression models for the unpaired situation, and we have the rank difference and signed-rank tests for the paired situation where there are no covariates to adjust for. But we are lacking in methods for robustly analyzing paired data where other variables need to be considered. The only approach I can think of, and for which feedback would be much appreciated, is this. Let X be the pre response value and Y be the post response, and Z be another covariate such as previous experience. Fit an ordinal model such as the proportional odds model that generalizes the unpaired Wilcoxon and Kruskal-Wallis methods. Symbolically the model is Y ~ X + Z, which can be extended to Y ~ f(X) + Z + g(X)Z where linearity of X is relaxed by expanding X to multiple columns using spline functions f and g, noting that this would require more data but allows Z to modify how the pre relates to the post. This is an analysis that is conditional on pre. Then from the fitted model we estimate Pr(Y > X | X, Z) for a variety of X and Z values. Thus we are estimating the probability that the post exceeds the pre for all values of pre. Probabilities above 0.5 would indicate increases in Y in going from pre to post. Another thing to consider: Conditional logistic regression is a generalization of the McNemar test for paired binary data, and may somehow come into play.
