[site]: datascience
[post_id]: 112119
[parent_id]: 
[tags]: 
Range of values of BERT and other embeddings?

Are the values in all NLP models' embeddings between the range -1 to 1? If not, what models use a different range (or decimal points)? And what could be the reason for that shift/change?
