[site]: stackoverflow
[post_id]: 1810248
[parent_id]: 
[tags]: 
What kind of learning algorithm would you use to build a model of how long it takes a human to solve a given Sudoku situation?

I don't have much experience in machine learning, pattern recognition, data mining, etc. and in their underlying theory and systems. I would like to develop an artificial model of the time it takes a human to make a move in a given Sudoku puzzle. So what I'm looking for as an output from the machine learning process is a model that can give predictions on how long does it take for a target human to make a move in a given Sudoku situation. Same input doesn't always map to same outcome. It takes different times for the human to make a move with the same situation, but my hypothesis is that there's a tendency in the resulting probability distribution. (My educated guess is that it is ~normal.) I have ideas about the factors that influence the distribution (like #empty slots) but would preferably leave it to the system to figure these patterns out. Please notice, that I'm not interested in the patterns, just the model. I can generate sample and test data easily by running sudoku puzzles and measuring the times it takes to make the moves. What kind of learning algorithm would you suggest to use for this? I was thinking NNs, but I'm not sure if they can have the desired property of giving weighted random outcomes for the same input.
