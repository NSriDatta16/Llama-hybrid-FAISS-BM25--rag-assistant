[site]: crossvalidated
[post_id]: 402633
[parent_id]: 
[tags]: 
Measuring similarity between document and category

Lets say I have a word embedding model, a set of documents and N categories. Lets say the categories are "cars" and "planes". I want to categorize the documents as either being about cars or planes. So, I pick a bag of words from the document from which I remove stop words and the like. I take the resulting list of words and average out the distance between the word vector for "car" and the words in my list. I do the same for the word "plane". Finally, I categorize the document as belonging to the category which gives me the smallest average distance between the category and the words in the document. The reason I am asking this is because I see that "cosine similarity" is a standard feature in gensim. Is that a better way to do classification of documents? I always thought like words in a well-trained word embedding model would have shorter euclidean distance than words that are different definition-wise. When is it better to use cosine similarity? Also, are there other methods I should consider?
