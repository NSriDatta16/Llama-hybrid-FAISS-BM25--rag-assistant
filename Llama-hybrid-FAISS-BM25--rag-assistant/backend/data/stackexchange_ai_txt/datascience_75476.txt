[site]: datascience
[post_id]: 75476
[parent_id]: 51731
[tags]: 
One reason that the older learning algorithms did not perform very well was that the algorithms were not that much powerful and deep to be able to extract different features in the images. It was not possible to use a very deep neural network because of the problems such as vanishing gradients. However, now, there are different methods (e.g., ResNet concept in case of CNN, LSTM in case of RNN) and also different nonlinearity functions (e.g., Relu) that could be useful to prevent overfitting. Now because of these improvements, we are able to use very deep neural networks. There is a still an issue, and that is overfitting. When, the neural network is very deep, the chance of the overfitting is very high. The solution for that is to use a large dataset. In summary, using a large dataset now could be useful to improve the performance of the training dataset because very deep neural networks are able to detect and extarct different features of data. On the other hand, using a very large dataset set could also prevent from overfitting.
