[site]: crossvalidated
[post_id]: 430409
[parent_id]: 
[tags]: 
How to calculate uncertainty of probability derived from random samples?

I'm running many simulations based on random samples, each of which produces a True or False result. The goal is to calculate the probability that the result will be True, which I can easily calculate using (number of True results / total number of tests). As I increase the number of simulations, this probability value varies less and less, converging to a specific number that depends on the thing I'm testing. How do I calculate the "uncertainty" of this probability estimate as I run the simulations? In other words, as the number of simulations increases, this "uncertainty" number would get smaller and smaller, while the "probability" number varies less and less. Do I have to do multiple trials of a certain number of simulations each, calculate the probability for each trial, and then measure the uncertainty of those probabilities as a group? Or is there a way to calculate it directly along with the overall average from running n simulations in a row? In other words, the more simulations I run, the more accurate my result is. How do I calculate how accurate it is?
