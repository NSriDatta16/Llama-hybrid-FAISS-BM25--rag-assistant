[site]: stackoverflow
[post_id]: 2060075
[parent_id]: 2060008
[tags]: 
You could break down the problem into four sets of random users: US users, level 2, choose 35% of total sample desired Canada users, level 2, choose 15% of total sample desired US users, level 3, choose 35% of total sample desired Canada users, level 3, choose 15% of total sample desired If there's a third criterion, split the problem down into eight sets. And so on. It may seem artificial to get exactly 50% level 2 and 50% level 3 in both sets of users, US and Canada. Since it's supposed to be random, you might expect it to vary a bit more. Plus what if there aren't very many level 3 users from Canada to make up 15% of the total? As the criteria get more and more selective, you're naturally taking away from the randomness of the total sample. Eventually you could have a long list of criteria such that only one subset of your users could satisfy it, and then there'd be no randomness at all. Re your comment: Right, SQL isn't the best solution for every type of problem. You may be better off handling the problem with an iterative algorithm instead of a single set-based SQL query. For example: Pick one random row. If the row has been chosen already in a previous iteration, discard it. If the row helps keep the pace of choosing a total sample that is 70% US, 30% Canada, 50% level 2, 50% level 3, keep it. Otherwise, discard it. If you reach the desired number of samples, stop. Loop back to step 1. Of course, it gets tricky if you pick a row that helps to balance the 70/30% ratio of nations, but imbalances the 50/50% ratio of levels. Do you discard it or not? And also you may want to ignore the ratios when you've only picked the first few rows. As @Hogan commented, this might be an unsolvable NP-Complete problem. But many such problems have a solution that gives you a "good enough" result, though not a provably optimal result.
