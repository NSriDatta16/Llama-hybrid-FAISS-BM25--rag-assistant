[site]: crossvalidated
[post_id]: 9584
[parent_id]: 9581
[tags]: 
## dummy data require(MASS) set.seed(1) dat So my data are in object dat , you have read your data in and called it something. Use that object instead of dat in this code below: [@sridher - the codes below are the three lines I mentioned!] set.seed(2) ## *k*-means uses a random start klust The first line ( set.seed(2) ) fixes the random number generator at a given starting point so the results are reproducible. We do this because kmeans() , if not given the starting cluster centres will randomly choose centers samples from your data as the cluster centres. The second line calls kmeans() on the standardised data (all the variables in my data set are in different units, so scaling them to zero mean and unit variance would seem appropriate). We ask for 3 groups by specifying centers = 3 . The third line prints the fitted k -means object to the screen showing the output from the function. This is just an example though. Why three groups? I don't even do any subsequent analysis of the clustering solution. Furthermore, you probably want to run the kmeans() code several times to make sure you get similar clusterings each time, but using different random starts --- set a different seed for each run. There is a lot more to clustering than just throwing your data at an algorithm! You can automate that bit to some extent using the cascadeKM() function in package vegan : require(vegan) fit which suggests 2 groups is the best solution for these data: but we know the data generation process had three groups, and as such k -means and the summary stats of the results have not been able to correctly identify the presence of three groups in this small sample of data. With some real data this time, using the famous Iris data set fit2 which clearly favours 3 groups, , which is good seeing as there really are three species in the data set > with(iris, unique(Species)) [1] setosa versicolor virginica Levels: setosa versicolor virginica
