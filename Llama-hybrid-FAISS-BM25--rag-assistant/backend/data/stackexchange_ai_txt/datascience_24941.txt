[site]: datascience
[post_id]: 24941
[parent_id]: 
[tags]: 
Trying to create an RNN with one character memory

I'm trying to create an RNN with a one character memory. Here is my model base on an M-GRU (Minimal Gated Recurrent Unit) : $$f_t = \sigma (W_f[h_t,x_t]+b_f)$$ $$\tilde{h_t} = \tanh(W_h[h_t,x_t]+b_h)$$ $$h_{t+1} = (1-f_t)*\tilde{h_t} + f_t*h_t$$ $x_t$ is the input and $h_t$ is the hidden state of the RNN. $f$ is the update gate for the state. Then I have the first and second elements of the vector $h_t$ have a special meaning to be the strength of setting or getting the memory. $s=h_t[0]$, $g=h_t[1]$ This adds the input to the memory with strength $s$ and then softmaxed $$m_{t+1} = softmax( m_{t} + s x_t )$$ Then the candidate output is (it seems to generalise less well without the tanh but converges nicer): $$c = tanh(W_c h_{t+1}+b_c) $$ Then the real output is given by adding the memory with strength g: $$o_{t+1} = softmax( c + g m_{t+1} )$$ Then it passes $h_{t+1}$ and $m_{t+1}$ onto the next time step. Then I tried it on some data "21(22)52(33)5421(44)32112(99)1232(33)132..." where basically it is random numbers except inside the brackets. Then I try give it an starting string "(x" which if it successfully works it should output "x)" even though it never saw the character "x" before. It almost works but is not really converging well. Here's a typical output: "(xx)7456725(11)9756x89994x548(33)383351051)(44)9887))1039(11))5407(77)953201(99)x1x85)53)(99))3846" Is there a better model you know of that does this better (but simpler than a Neural Turing Machine)?
