[site]: stackoverflow
[post_id]: 3149286
[parent_id]: 
[tags]: 
Architectural tips on building a shared resource for different processess

In the company I work at we're dealing with a huge problem: we have a system that consists in several units of processing. We made it this way so each module has specific functionality. The integration between these modules is done using a queue system (which is not fast but we're working on it) and replicating messages between these modules. The problem is that this is generating a great deal of overhead as four of these systems are requiring the same kind of data, and maintaining consistency for these modules is bad. Another requirement for the system is redundancy, so I was thinking to kill these two problems in one shot. So I was thinking of using some kind of shared resource. I've looked at shared memories (which are great but could lead to locking inconsistencies if the module crashes leading to inconsistencies in the program), and maybe do some "raw copy" from the segment to another computer to do redundancy. So I've began to search for alternatives, ideas and something like that. I've found one that is noSQL, but I don't know if the speed that I'm requiring would suffice this. I need something (ideally): Memory-like fast That could provide me redundancy (active-passive is ok, active active is good)
