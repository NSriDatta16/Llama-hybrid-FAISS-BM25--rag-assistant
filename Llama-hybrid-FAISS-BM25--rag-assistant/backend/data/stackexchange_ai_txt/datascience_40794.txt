[site]: datascience
[post_id]: 40794
[parent_id]: 36596
[tags]: 
I would say that feature scaling wouldn't significantly effect the performance of a model. What I would focus on would be what method of scaling you're using. Standard Scaling is less effected by outliers but has varying ranges, normalization squishes data ranges to 0-1 but is more effected by outliers, etc. Some Algorithms depend on the scaling method you are using, for example, neural networks often expect inputs between 0-1. Then again, libraries like Scikit-Learn are built by experts that understand the inner workings of the model, so if the model has internal scaling, then I would just leave it be.
