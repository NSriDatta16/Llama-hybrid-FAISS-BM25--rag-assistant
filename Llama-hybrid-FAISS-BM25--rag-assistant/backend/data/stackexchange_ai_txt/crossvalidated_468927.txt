[site]: crossvalidated
[post_id]: 468927
[parent_id]: 
[tags]: 
When computing parameters, why is dimensions of hidden-output state of an LSTM-cell assumed same as the number of LSTM-cell?

I was trying to figure out how to estimate the number of parameters in an LSTM layer. What is the relationship of number of parameters with the num lstm-cells, input-dimension, and hidden output-state dimension of the LSTM layer? If the LSTM input is 512-d (word embedding dimension), output hidden dimension is 256, and there are 256 lstm units (bidirectional layer) in each of the bidirectional LSTM layers, what's the params per cell and total in the layers? I came across this link https://stackoverflow.com/questions/38080035/how-to-calculate-the-number-of-parameters-of-an-lstm-network , and it seems to suggest that hidden output state dimension = number of lstm cells in the layer. Why is that?
