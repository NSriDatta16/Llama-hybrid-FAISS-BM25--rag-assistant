[site]: datascience
[post_id]: 125004
[parent_id]: 
[tags]: 
Explanation : Simpler models beat BERT base

I have been trying to train different models for a multi-class classification task of texts. My data set consists of rows of text and its label. The texts are short sentences. I tried the following models : after generating embeddings using distilbert-base-uncased i trained : Random Forest Classifier :F1-Score: 0.59 SVM :F1-Score: 0.63 Gradient Boosting Classifier:F1-Score: 0.65 MLPClassifier:F1-Score: 0.68 then : -BERT base :F1-Score: 0.40 Since BERT is supposed to be the most powerful model for this use case I was surprised with the result, I was trying to find an explanation and hypothesis for that. So has anyone faced similar results before . what do you think may be the reason?
