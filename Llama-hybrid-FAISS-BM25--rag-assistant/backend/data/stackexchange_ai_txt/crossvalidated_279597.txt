[site]: crossvalidated
[post_id]: 279597
[parent_id]: 
[tags]: 
Each feature's weights to the output

I used several time series as features (3 features as input) into LSTM model (1 output on regression) on TF 1.1.0. The main function started a session as below: model = SKCompat(learn.Estimator(model_fn=lstm_model, model_dir=LOG_DIR, params={'learning_rate': Learning_rate})) model.fit(trainX, trainY, steps=steps) and the lstm_model function as below mainly: lstm_cell = tf.contrib.rnn.LSTMCell(hidden, state_is_tuple=True) lstm_cell = tf.contrib.rnn.DropoutWrapper(cell=lstm_cell, output_keep_prob=0.1) (output, state) = tf.nn.dynamic_rnn(cell=lstm_cell, inputs=features, dtype=tf.float32) After training and saving the model (saved automatically by the default tf function itself), I could read the weights of the LSTM cell by 'import_meta_graph' and 'restore' in the main function. The weights looks like a (131, 512) array. The problem is how to know the weights of each feature from such a weights array, i.e. each feature's weights to the output?
