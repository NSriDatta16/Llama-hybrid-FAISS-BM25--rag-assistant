[site]: crossvalidated
[post_id]: 498016
[parent_id]: 498014
[tags]: 
gung is saying that in order to know which of the two is most common, we need to a) have access to lots of classification problems in the wild, and then b) have access to the true processes so that we can compare the model to the truth. Think of it this way. When your niece asks if you like her picture of a frog, you know if the drawing is good or bad because you can compare it to a real frog. Without knowledge of what a frog looks like, you can't tell if the drawing is good or bad. Same with models. Models will always either over or underfit because all models are approximations. To know which is more prevalent, we would need to know how the data were actually generated, which obviates the need for a model in the first place. My intuition says that we almost always underfit (except in image problems, where I'm willing to bet we overfit). If a non-trivial proportion of classification tasks are tackled with logistic regression, there is no reason to believe the truth is linear on the log odds scale save mathematical convenience. Hence, underfitting. But that is just anecdote.
