[site]: crossvalidated
[post_id]: 88975
[parent_id]: 
[tags]: 
Impact of data dimensionality on computation complexity of SVM?

What is the impact of data dimensionality on computation complexity of SVM? I found on the literature that the complexity of SVM is $O(N^3)$, where $N$ is the number of training examples. If the number of dimension (e.g., $D$) does not impact the training time why it s better to reduce the dimensionality for training high-dimension dataset? Is it just to avoid overfitting? BTW, I m using SVDD (support vector data description) from RRTools.
