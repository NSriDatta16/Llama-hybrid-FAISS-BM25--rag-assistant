[site]: crossvalidated
[post_id]: 297875
[parent_id]: 297871
[tags]: 
Generally speaking, the more data is available, the better. In fact, papers have found that training a model on 300 million images is better than only 30 million -- it's not the case that our models can be fully "saturated" with just a few million images. However, obtaining ground truth labels for millions of images can be very expensive. Increasing the sample efficiency of models is a very active area of research. For example, there is lots of work in classifying images with only one sample. The best approach, from a pragmatic point of view, is to gather as much data as possible, since it generally leads to better results.
