[site]: crossvalidated
[post_id]: 414245
[parent_id]: 414233
[tags]: 
Yes, neural networks can learn how to play video games. reinforcement-learning (RL) is the standard approach to solving game-playing using neural networks. A key paper in this area is Deepmind's Atari-playing RL agent , but researchers have extended this approach to more complex games like Doom , Starcraft II and DOTA . If you're not familiar with this research, I'd suggest picking up Maxim Lapan's Deep Reinforcement Learning Hands-On . The core idea of reinforcement learning is that the agent learns how to interpret the current state of the environment and take actions to maximize its payoff. RL is a different strategy compared to language-generating models, because it's not merely imitating past results; instead, it's learning how to make decisions to maximize rewards, even when the environment is changing. That said, it's possible that the strategy you're using is not the best approach to solving this problem. Neural network construction involves a fair amount of experimentation to get a result that is good enough for your particular needs; for elaboration on this, see What should I do when my neural network doesn't learn? Second, a key exception to Deepmind's success is Metroid-like games such as Montezuma's Revenge , which are harder for the agent to learn because there are extremely long lags between actions (picking up torches or gems) and their payoffs. If your platform game has a similar kind of lag between action and payoff, then your model may struggle. And, as always, you should write unit tests and validate that your code is doing what you want it to. My suggestion is to start with a problem that you know can be solved to a certain level of success by neural networks, such as Breakout , and see how well your method works. If your method can't learn to play Breakout , it might not be a viable strategy.
