[site]: crossvalidated
[post_id]: 330154
[parent_id]: 330153
[tags]: 
The random forest algorithm, as implemented by Breiman, is designed such that each predictor is given a fair chance to manifest its importance in the overall forest model. The reason for this is that each tree is built by taking a random set of features, and then choosing the feature with the best split at each node, starting with the root. Features/predictors which are relevant will influence the tree heavily in the first few splits. Regarding your predictor x1, which has a strong predicting power for a certain range of z values, then the resulting forest should pick up on this. Specifically, if the x1 predictor be important, then it should be involved with splits in many trees, most likely early on in the building of the tree. For how much of your input data does x1 behave this way? If only for a small percentage then the model rightfully should not pick up on it. Or, perhaps there are other predictors which are more important, but you are just not aware of it. In general, if you use a clean data set and tune your model, you can have a reasonable level of faith in the random forest model you build. Of course, you can check the importance, compare against the best constant model, etc., to make sure the model is statistically meaningful.
