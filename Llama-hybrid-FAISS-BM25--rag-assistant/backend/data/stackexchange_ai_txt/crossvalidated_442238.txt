[site]: crossvalidated
[post_id]: 442238
[parent_id]: 441921
[tags]: 
This seems to be something like a self-study exercise so I won't presently give a full solution to every part but I will get you a fair way along. Basic results on expectations and variances: $\qquad$ 1. $ E(\sum_i s_i) = \sum_i E(s_i)$ $\qquad$ 2. $ \text{Var}(\sum_i s_i) = \sum_i \text{Var}(s_i), \:$ for independent variates For iid exponentials with mean $\mu$ , for given $C_j$ , $S_j$ has population mean $C_j\, \mu$ and $S_j/C_j = \overline{s}$ has population mean $\mu$ . You could estimate $\mu$ from a single $(S,C)$ pair. If you have more than one of them, you will want to weight them appropriately in a weighted average. For iid normals with mean $\mu$ and standard deviation $\sigma$ , for given $C_j$ , $S_j$ has population mean $C_j\, \mu$ and $S_j/C_j = \overline{s}$ has population mean $\mu$ . The variance of $S_j$ is $C_j\, \sigma^2$ , and the variance of $\bar{s}$ is $\sigma^2/C_j$ . If you only have $S$ and $C$ values available to you, you'll require more than one of them to estimate $\sigma$ . Usually, you'd solve problems like this via the method of maximum likelihood , rather than just by equating moments , but in these two cases, that turns out to be essentially the same thing.
