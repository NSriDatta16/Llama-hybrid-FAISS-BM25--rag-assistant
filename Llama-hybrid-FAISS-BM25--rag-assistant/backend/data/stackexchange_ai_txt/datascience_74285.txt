[site]: datascience
[post_id]: 74285
[parent_id]: 74206
[tags]: 
That depends on the latent representation the model has learned. Typically it won't be rotational invariant because there are no inbuilt mechanism in vanilla CNN or constraints enforcing that! If you want to learn rotational invariant representation then either you can use a Rotation Invariant CNN or you may set up the training objective of the Siamese network such that when you pass random rotated versions of the same image of the same input, you classify as positive or else negative. The 2nd method is enforcing the constraint that your representation must be rotational invariant.
