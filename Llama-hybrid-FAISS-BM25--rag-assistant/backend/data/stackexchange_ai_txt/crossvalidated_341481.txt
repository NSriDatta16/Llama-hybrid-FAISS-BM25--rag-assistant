[site]: crossvalidated
[post_id]: 341481
[parent_id]: 
[tags]: 
Puzzling contradiction in introductory textbook regarding standard deviation and sample size

I am reading Facts From Figures by MJ Moroney. In one part of the textbook (chapter 10, pages 136-137) he writes of samples taken from a population with a normal distribution, that their "standard deviation decreases as the square root of n, the number of items in the sample". He gives a formula where "the standard deviation for the distribution of the individual items" is divided by the square root of the number in the sample to give "the standard deviation for the averages of samples of n items". His example is a population of men with an average weight of 140 pounds with a standard deviation of 20 pounds, and he calculates that the standard deviation of the average weight of a group of four men at a time would be 10 pounds, and for a group of one hundred men it would be two pounds. But later in the book (chapter 13, pages 225-227), he writes that the expected value of the variance in a sample of n items is obtained from the population variance by multiplying the population variance by ((n-1)/n). (The Bessel correction.) I am aware that variance is the square of standard deviation, but after doing some simple algebra to convert the first equation described above to deal with variance rather than standard deviation, then for a sample size of 100 the conversion factor in the first equation is 100, but in the second equation the conversion factor is about 1. A considerable difference. Please can someone explain my misunderstanding. Surely the standard deviation of a population describes the standard deviation of the individuals within that population.
