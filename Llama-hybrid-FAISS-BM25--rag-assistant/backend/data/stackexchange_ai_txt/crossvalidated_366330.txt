[site]: crossvalidated
[post_id]: 366330
[parent_id]: 366272
[tags]: 
While one can't prove a negative with an example. Still I feel an example would be suggestive; and perhaps useful. And it does show how one would (attempt to) solve similar problems. In the case of I want to make binary predictions, using features that are binary vectors , a Random Forest is a solid choice. I guess this kind of answers the second part of your question: what is a good algorithm. We well want to preprocess the SHA256 strings, into binary (Boolean) vectors, as each bit is statistically independent, thus each bit is a good feature. So that will make our inputs 256 element boolean vectors. Demo Here is a demonstration of how the whole thing can be done using the Julia DecisionTree.jl library. You can copy paste the below into the julia prompt. using SHA using DecisionTree using Statistics: mean using Random: randstring const maxlen=10_000 # longest string (document) to be hashed. gen_plaintext(x) = gen_plaintext(Val{x}()) gen_plaintext(::Val{true}) = "1" * randstring(rand(0:maxlen-1)) gen_plaintext(::Val{false}) = randstring(rand(1:maxlen)) bitvector(x) = BitVector(digits(x, base=2, pad=8sizeof(x))) bitvector(x::AbstractVector) = reduce(vcat, bitvector.(x)) function gen_observation(class) plaintext = gen_plaintext(class) obs = bitvector(sha256(plaintext)) obs end function feature_mat(obs) convert(Array, reduce(hcat, obs)') end ######################################## const train_labels = rand(Bool, 100_000) const train_obs = gen_observation.(train_labels) const train_feature_mat = feature_mat(train_obs) const test_labels = rand(Bool, 100_000) const test_obs = gen_observation.(test_labels) const test_feature_mat = feature_mat(test_obs) # Train the model const model = build_forest(train_labels, train_feature_mat) @show model #Training Set accuracy: @show mean(apply_forest(model, train_feature_mat) .== train_labels) #Test Set accuracy: @show mean(apply_forest(model, test_feature_mat) .== test_labels) Results When I did this, training on 100,000 random ASCII strings of length up to 10,000. Here are the results I saw: Train the model julia> const model = build_forest(train_labels, train_feature_mat) Ensemble of Decision Trees Trees: 10 Avg Leaves: 16124.7 Avg Depth: 17.9 Training Set accuracy: julia> mean(apply_forest(model, train_feature_mat) .== train_labels) 0.95162 Test Set accuracy: julia> mean(apply_forest(model, test_feature_mat) .== test_labels) 0.5016 Discussion So that is basically nothing. We went from 95% on the training set, to barely over 50% on the test set. Someone could apply proper hypothesis tests, to see if we can reject the null hypothesis, but I am pretty certain we can't. It is a tiny improvement over the guess rate. That suggests that it can't be learned. If a Random Forest, can go from well fitted to hitting just the guess rate. Random Forests are pretty capable of learning difficult inputs. If there was something to learn, I would expect at least a few percent. You can play around with different hash functions by changing the code. Which could be interesting I got basically same results when using the julia in built hash function (which is not a cryptographically secure hsah, but still is a good hash so should indeed send similar strings apart). I also got basically the same results for CRC32c .
