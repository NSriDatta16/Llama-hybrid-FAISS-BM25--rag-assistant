[site]: crossvalidated
[post_id]: 450373
[parent_id]: 450229
[tags]: 
As mentioned in Variational Autoencoder âˆ’ Dimension of the latent space , there is a heuristic upper-bound for the latent variable dimension: the size of the training data. If you encoder is sufficiently powered (we assume it is anyways for VAEs), if your latent variable is $N$ dimensional and you have $N$ training samples, then your encoder can simply encode each sample in one dimension of the latent, severely overfitting your model. In practice, however, that bound is probably tighter, since the encoder is non-linear it can fit the training data into a lower dimensional latent and yet overfit. One possible test for this is to decode random latents and see what they look like (assuming you are modeling images).
