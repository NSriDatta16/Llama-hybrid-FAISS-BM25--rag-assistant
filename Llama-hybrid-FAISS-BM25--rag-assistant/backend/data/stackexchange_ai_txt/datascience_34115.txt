[site]: datascience
[post_id]: 34115
[parent_id]: 
[tags]: 
Isolation Forest Feature Importance

As of scikit-learn version 0.19.1, there is no implementation for calculating feature importance in an Isolation Forest. I'm also having trouble finding any online resources proposing ways to get at the problem. Does anyone know of any established methods for doing this or have any suggestions? Here are some ideas I've been thinking about: Calculate some kind of 'isolation metric' for each node in each tree (such as % of samples split) and get an average of this metric for each splitting feature. After the model has been fit, go through each feature one at a time, randomly permute the data for that feature, and calculate the anomaly scores. Then calculate the average change in the anomaly scores. All insights welcome. Thanks!
