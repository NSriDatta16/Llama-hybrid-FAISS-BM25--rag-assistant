[site]: crossvalidated
[post_id]: 612674
[parent_id]: 134282
[tags]: 
Let's try to understand using a data matrix $X$ of dimension $n \times d$ , where $d \gg n$ and $rank(X)=n$ . Then $\underset{n \times d}{X}=\underset{n \times n}{U}\underset{n \times n}{\Sigma} \underset{n \times d}{V^T}$ (reduced SVD) with $X^TX=V\Sigma^TU^TU\Sigma V^T=V\Sigma^2V^T$ (since unitary / orthonormal $U$ , $V$ and diagonal $\Sigma$ ) and the covariance matrix (assuming $X$ is already mean centered, i.e., the columns of $X$ have $0$ means) $C=E[X^TX]-E[X]^TE[X]=\frac{X^TX}{n-1}-0=V\frac{\Sigma^2}{n-1}V^T=\tilde{V}\Lambda \tilde{V}^T$ (PCA, by spectral decomposition) $\implies \Lambda = \frac{\Sigma^2}{n-1}$ and $V=\tilde{V}$ upto sign flip. Let's validate the above with eigenfaces (i.e., the principal components / eigenvectors of the covariance matrix for such a face dataset) using the following face dataset: import numpy as np from sklearn.decomposition import PCA from sklearn.datasets import fetch_olivetti_faces X = fetch_olivetti_faces().data X.shape # 400 face images of size 64×64 flattened # (400,4096) n = len(X) # z-score normalize X = X - np.mean(X, axis=0) # mean-centering # X = X / np.std(X, axis=0) # scaling to have sd=1 # choose first k eigenvalues / eigenvectors for dimensionality reduction k = 25 # SVD U, Σ, Vt = np.linalg.svd(X, full_matrices=False) # PCA pca = PCA(k).fit(X) PC = pca.components_.T #Vt.shape, PC.shape Now let's compare the eigenvalues and eigenvectors computed: # first k eigenvalues of Λ = Σ^2/(n-1) # from SVD print(Σ[:k]**2/(n-1)) # from SVD # [18.840178 11.071763 6.304614 3.9545844 2.8560426 2.49771 # 1.9200633 1.611159 1.5492224 1.3229507 1.2621089 1.1369102 # 0.98639774 0.90758985 0.84092826 0.77355367 0.7271429 0.64526594 # 0.59645116 0.5910001 0.55270135 0.48628208 0.4619924 0.45075357 # 0.4321357 ] print(pca.explained_variance_[:k]) # from PCA # [18.840164 11.07176 6.3046117 3.9545813 2.8560433 2.4977121 # 1.9200654 1.6111585 1.549223 1.3229507 1.2621082 1.1369106 # 0.98639697 0.9075892 0.84092826 0.773553 0.72714305 0.64526534 # 0.59645087 0.5909973 0.55269724 0.4862703 0.461944 0.45075053 0.43211046] # plot PC the k dominant principal components / eigenvectors as images # 1. using PC obtained with PCA # 2. using Vt[:k,:].T obtained from SVD Here the differences in the eigenvectors are due to sign ambiguity (refer to https://www.osti.gov/servlets/purl/920802 )
