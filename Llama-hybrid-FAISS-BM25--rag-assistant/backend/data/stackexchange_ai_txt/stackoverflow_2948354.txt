[site]: stackoverflow
[post_id]: 2948354
[parent_id]: 2948337
[tags]: 
Strange question - unit testing is supposed to be automatic, thus repeatable and easy to run. For many (including me) "manual unit test" is a contradiction in terms. Manual testing may be useful in those cases when one can't make automated tests. These typically are not at the unit test level, but higher - e.g. integration, GUI, stress etc. tests. With unit tests, you are testing small pieces of your code (typically individual methods/classes) at a time. The tests are written in code themselves, so they can (almost always) be run automatically by a unit testing framework. Update: now that you give a more concrete context to your question, it is easier to give a concrete answer :-) I am convinced to say that automated unit tests practically always pay for themselves many times over the lifetime of a SW project. Setting them up is costlier than manual testing, but the more you run them, the more time you save - and the more early feedback you get about where your code is broken by new changes. Covering legacy code with unit tests is definitely not easy, but if the product is valuable for your company and is expected to be continued for years, it is still a worthy effort. Especially so since in real life, a production system tends to outlive its expected lifetime. One aspect is, you "try to check all the code paths we've written" - with automated unit tests combined with a code coverage tool, you can automagically see - often right within your IDE, if the coverage tool is integrated well - what code paths are not covered by your latest unit tests. I recommend Working Effectively with Legacy Code - it contains a wealth of valuable knowledge on how to write unit tests for tangled, badly written legacy code.
