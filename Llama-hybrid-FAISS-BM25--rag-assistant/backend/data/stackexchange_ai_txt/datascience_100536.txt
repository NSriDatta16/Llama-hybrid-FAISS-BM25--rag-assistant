[site]: datascience
[post_id]: 100536
[parent_id]: 
[tags]: 
Sentiment analysis with the help of word embeddings

I am doing sentiment analysis with GloVe and Fast Text word embeddings on a tweet dataset (using tensorflow & keras). I am trying to compare two models in terms of 'accuracy'. But each time, I run the Jupyter notebook, the accuracy keeps on varying. Sometimes the GloVe model gives better accuracy and sometimes the Fast Text model. What is the reason behind it? Is there any way to keep the accuracy of the two models constant.
