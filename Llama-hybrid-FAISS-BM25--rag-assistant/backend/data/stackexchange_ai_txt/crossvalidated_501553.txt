[site]: crossvalidated
[post_id]: 501553
[parent_id]: 
[tags]: 
Is $K$ independent binary logistic regression the same as a $K$-class softmax regression?

One of the "correct" regression models to multi-nominal classification problems is softmax regression, with the final prediction being the category with the highest predicted probability. Just as a fun exercise, I wonder what if I train a binary logistic model for each class, and pick the one with the highest probability across these models as the prediction? (yeah I'm comparing the output probability from different models) To clarify, the categories are mutually exclusive. More concretely, I wonder does taking the argmax across $K$ binary logistic regression predictors always gives the same result as taking that across the $K$ -dimensional probability vector output by a softmax regression predictor, when both models are trained on the same dataset? Below is my attempt at answering. Logistic regression: $$\forall j \in \{K\}, P(Y_j = 1) = \frac{e^{x^T\beta_j}}{1 + e^{x^T\beta_j}}.$$ Softmax regression: $$\forall j \in \{K\}, P(Y_j = 1) = \frac{e^{x^T\beta_j}}{\sum_{k=1}^K e^{x^T\beta_k}}.$$ Since $\forall x, e^x > 0$ , we have $\forall m, n \in \{K\}$ , $$\frac{e^{x^T\beta_m}}{1 + e^{x^T\beta_m}} > \frac{e^{x^T\beta_n}}{1 + e^{x^T\beta_n}} \Longleftrightarrow e^{x^T\beta_m} > e^{x^T\beta_n} \Longleftrightarrow\frac{e^{x^T\beta_m}}{\sum_{k=1}^K e^{x^T\beta_k}} > \frac{e^{x^T\beta_m}}{\sum_{k=1}^K e^{x^T\beta_k}}.$$ Now the question boils down to: when trained on the same sample, and given the same $x$ , does $x^T\beta_m > x^T\beta_n$ in logistic regression always imply $x^T\beta_m > x^T\beta_n$ in softmax regression, or vice versa?
