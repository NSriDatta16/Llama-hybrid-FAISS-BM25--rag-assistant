[site]: crossvalidated
[post_id]: 609079
[parent_id]: 148280
[tags]: 
I believe that the OOB stuff works differently on Random Forrests and Gradient Boosting. On Random Forrests, you can train a tree on a portion of the data (train data) and thus any predictions on the OOB data are clean-room predictions. So, the implementation would keep two separate arrays in order to implement OOB predictions. Each of these two array has the same length as the data passed in to the fit() method. The first array (y_hat_oob) would keep a sum of the OOB y_hats for each OOB data point, and the second array (oob_count) would keep a count of how many predictions (trees) contributed to each OOB prediction (for each data point). So, let's say you have 10 data points (0..9) and your first bag uses points (0..4) for training and (5..9) for OOB. You fit() a tree on points (0..4) and use that tree to predict() on points (5..9). You add the predictions to the y_hat_oob array for points (5..9) and you add 1 to the oob_count array in points (5..9). Now, let's say your bag 2 uses points (5..9) for training and thus points (0..4) for oob. You do the same, store the oob predictions in the y_hat_oob array points (0..4) and increment the corresponding counts. Now you have two trees in your model, but since you use only 0.5 of your data for oob, then your oob contains predictions from only (number of trees) * (proportion of oob data) trees (2 * 0.5 = 1). To get the actual y_hat_oob at the end of training, you'd need to divide y_hat_oob by count_oob -- this does the same as averaging all the predictions from all the tree models. Ok, so that's Random Forrests, and this was the easy one. For Gradient Boosting, I believe there is a problem. Because each tree depends on the predictions from prior trees, you can't take the same approach as with Random Forrests. What you CAN do is calculate the OOB "improvement" in "performance" due to the latest iteration/model. You'd calculate the error/performance on the iteration OOB data using the models of the prior iteration. Now, once the new iteration model is fit(), then you can recalculate the error/performance on the same OOB data and calculate the difference. That will give you and estimate of the OOB "improvement" in performance due to the latest iteration. At least this is how I understand things. Hope that helps.
