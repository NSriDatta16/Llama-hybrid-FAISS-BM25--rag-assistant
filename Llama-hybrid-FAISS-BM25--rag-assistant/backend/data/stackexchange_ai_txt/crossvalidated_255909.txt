[site]: crossvalidated
[post_id]: 255909
[parent_id]: 
[tags]: 
Square of MAD as variance equivalent

I have to estimate the error of a 1D array. The usual way of doing this to take the SD of it and square it. The issue is the following: The values in the array represent the time series of the intensity of a source. Whilst the source is mostly quiescent, there are times for which the source becomes active (the values increase/decrease). Whilst there are some constraints on when that is, one cannot be quite sure. I thus thought of taking the median absolute deviation MAD instead of the SD of the values during quiescence phase ... and then square them ?
