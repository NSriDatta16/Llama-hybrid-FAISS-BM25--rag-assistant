[site]: crossvalidated
[post_id]: 418535
[parent_id]: 418510
[tags]: 
According to the VAE paper https://arxiv.org/pdf/1312.6114.pdf , for any input $\mathrm{x}^i$ , the encoder outputs a mean $\mu^{(i)}$ and a variance $\sigma^{2(i)}$ . Then the decoder samples $\epsilon^{(i)}$ from a normal $\mathcal{N}(0,1)$ distribution and applies the reparametrization trick to generate $\mathrm{z}^{(i)}= \mu^{(i)} + \epsilon^{(i)} \sigma^{2(i)}$ so that $$ \textrm{q}_{\phi} \left(\mathrm{z} | \mathrm{x}^{(i)}\right)= \mathcal{N} \left( z ; \mu^{(i)}, \sigma^{2(i)} I \right) $$ Now, imagine that the VAE is trained. Denote $z$ for image $i$ of digit $k$ by $z_i^k$ . We have $$z_i^k \sim \mathcal{N}(\mu_i^k, {\sigma^2}_i^{k}).$$ Hence, $$z_1^5 - z_2^5 \sim \mathcal{N}(\mu_1^5 - \mu_2^5, {\sigma^2}_1^{5} + {\sigma^2}_2^{5})$$ and, $$z_1^5 - z_1^8 \sim \mathcal{N}(\mu_1^5 - \mu_1^8, {\sigma^2}_1^{5} + {\sigma^2}_1^{8})$$ Since $\mu_2^5$ will be closer to $\mu_1^5$ than $\mu_1^8$ , $\mu_1^5 - \mu_2^5$ will be closer to 0 than $\mu_1^5 - \mu_1^8$ , the probability of the event that $|z_1^5 - z_2^5| will be very high.
