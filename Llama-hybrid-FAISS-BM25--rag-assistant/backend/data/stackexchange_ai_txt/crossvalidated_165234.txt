[site]: crossvalidated
[post_id]: 165234
[parent_id]: 165194
[tags]: 
Requirements for hierarchical clustering Hierarchical clustering can be used with arbitrary similarity and dissimilarity measures. (Most tools expect a dissimilarity, but will allow negative values - it's up to you to ensure whether small or large valued will be preferred.). Only methods based on centroids or variance (such as Ward's method) are special, and should be used with squared Euclidean. (To understand why, please study these linkages carefully.) Single-linkage, average-linkage, complete-linkage are not much affected, it will still be the minimum / average / maximum of the pairwise dissimilarities. Correlation as distance measure If you preprocess your data ( $n$ observations, $p$ features) such that each feature has $\mu=0$ and $\sigma=1$ (which disallows constant features!), then correlation reduces to cosine: $$ \text{Corr} (X,Y) = \frac{\text{Cov}(X, Y)} {\sigma_X \sigma_Y} = \frac{\mathbb{E} \left[ (X - \mu_X) (Y - \mu_Y) \right]} {\sigma_X \sigma_Y} = \mathbb{E} [XY] = \frac1n \left $$ Under the same conditions, squared Euclidean distance also reduces to cosine: $$ d_\text{Euclid}^2(X,Y) = \sum (X_i - Y_i)^2 = \sum X_i^2 + \sum Y_i^2 - 2 \sum X_i Y_i \\ = 2n - 2\left = 2n \left[1 - \text{Corr}(X, Y)\right] $$ Therefore, unless your data is degenerate, using correlation for hierarchical clustering should be okay. Just preprocess it as explained above, then use squared Euclidean distance.
