[site]: datascience
[post_id]: 56038
[parent_id]: 
[tags]: 
multi gpu with axes dont match array?

If I train a model using 2 GPUs, using multi_gpu_model and the ModelCheckpoint callback to save the best, it gives this error when calling load_model on the checkpoint saved model. I would like to train the model using multiple gpus, but run it again on a single GPU. This seems to fail. keras version: 2.2.4-tf My code: from tensorflow.keras.utils import multi_gpu_model def get_model(): base_model = ResNet50(weights='imagenet', input_shape=(image_size,image_size,3), include_top=False) #base_model.trainable = False model = models.Sequential() model.add(base_model) model.add(layers.GlobalAveragePooling2D()) model.add(layers.Dense(1024, activation='relu')) model.add(layers.Dropout(0.5)) model.add(layers.Dense(196, activation='softmax')) model.summary() model = multi_gpu_model(model,gpus=2) #optimizer = optimizers.SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True) optimizer = optimizers.RMSprop(lr=0.0001) model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc']) return model prediction = [] for i, name in enumerate(model_names): model = get_model() model.load_weights(name) test_generator.reset() pred = model.predict_generator( generator=test_generator, steps = len(df_test)/BATCH_SIZE, verbose=1 ) prediction.append(pred) y_pred = np.mean(prediction, axis=0) > > --------------------------------------------------------------------------- ValueError Traceback (most recent call > last) in > 2 for i, name in enumerate(model_names): > 3 model = get_model() > ----> 4 model.load_weights(name) > 5 > 6 test_generator.reset() > > ~/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py > in load_weights(self, filepath, by_name) > 160 raise ValueError('Load weights is not yet supported with TPUStrategy ' > 161 'with steps_per_run greater than 1.') > --> 162 return super(Model, self).load_weights(filepath, by_name) > 163 > 164 @trackable.no_automatic_dependency_tracking > > ~/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py > in load_weights(self, filepath, by_name) 1413 > saving.load_weights_from_hdf5_group_by_name(f, self.layers) 1414 > else: > -> 1415 saving.load_weights_from_hdf5_group(f, self.layers) 1416 1417 def _updated_config(self): > > ~/venv/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py > in load_weights_from_hdf5_group(f, layers) > 681 symbolic_weights = _legacy_weights(layer) > 682 weight_values = preprocess_weights_for_loading( > --> 683 layer, weight_values, original_keras_version, original_backend) > 684 if len(weight_values) != len(symbolic_weights): > 685 raise ValueError('Layer #' + str(k) + ' (named "' + layer.name + > > ~/venv/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py > in preprocess_weights_for_loading(layer, weights, > original_keras_version, original_backend) > 306 weights = convert_nested_time_distributed(weights) > 307 elif layer.__class__.__name__ in ['Model', 'Sequential']: > --> 308 weights = convert_nested_model(weights) > 309 > 310 if original_keras_version == '1': > > ~/venv/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py > in convert_nested_model(weights) > 294 weights=weights[:num_weights], > 295 original_keras_version=original_keras_version, > --> 296 original_backend=original_backend)) > 297 weights = weights[num_weights:] > 298 return new_weights > > ~/venv/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py > in preprocess_weights_for_loading(layer, weights, > original_keras_version, original_backend) > 306 weights = convert_nested_time_distributed(weights) > 307 elif layer.__class__.__name__ in ['Model', 'Sequential']: > --> 308 weights = convert_nested_model(weights) > 309 > 310 if original_keras_version == '1': > > ~/venv/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py > in convert_nested_model(weights) > 282 weights=weights[:num_weights], > 283 original_keras_version=original_keras_version, > --> 284 original_backend=original_backend)) > 285 weights = weights[num_weights:] > 286 > > ~/venv/lib/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py > in preprocess_weights_for_loading(layer, weights, > original_keras_version, original_backend) > 388 weights[1] = conv_utils.convert_kernel(weights[1]) > 389 if K.int_shape(layer.weights[0]) != weights[0].shape: > --> 390 weights[0] = np.transpose(weights[0], (3, 2, 0, 1)) > 391 if layer.__class__.__name__ == 'ConvLSTM2D': > 392 weights[1] = np.transpose(weights[1], (3, 2, 0, 1)) > > ~/venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py in > transpose(a, axes) > 637 > 638 """ > --> 639 return _wrapfunc(a, 'transpose', axes) > 640 > 641 > > ~/venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py in > _wrapfunc(obj, method, *args, **kwds) > 54 def _wrapfunc(obj, method, *args, **kwds): > 55 try: > ---> 56 return getattr(obj, method)(*args, **kwds) > 57 > 58 # An AttributeError occurs if the object does not have > > ValueError: axes don't match array
