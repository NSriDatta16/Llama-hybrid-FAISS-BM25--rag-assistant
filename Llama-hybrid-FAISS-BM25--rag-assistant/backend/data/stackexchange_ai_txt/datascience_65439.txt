[site]: datascience
[post_id]: 65439
[parent_id]: 
[tags]: 
Regression for Deskew Document problem

I am currently at an impasse regarding my regression problem. My goal is to generate a model that rotates correctly an image. My images are documents (invoices for example). Each document is either in grayscale or binarized . Initially, I have around 150 images deskewed. I generate, with rotate function around 5000 images rotated. For each image, I generate 36 new images with an angle different (normalized between 0 and 1). def rotate_with_white_background(img, angle): # converted to have an alpha layer im2 = img.convert('RGBA') # rotated image rot = im2.rotate(angle, expand=True, resample=Image.BICUBIC) # a white image same size as rotated image fff = Image.new('RGBA', rot.size, (255,)*4) # create a composite image using the alpha layer of rot as a mask out = Image.composite(rot, fff, rot) # save your work (converting back to mode='1' or whatever..) return out.convert(img.mode) list_angle = list(range(0,360,10)) for img in list_img: for angle in list_angle: full_name_img_in = os.path.join(pathin, img) image = Image.open(full_name_img_in) image_skew = rotate_with_white_background(image, angle) full_name_img_out = os.path.join(pathout_no_resize, os.path.splitext(img)[0] + str(angle) + "t.png") image_skew.save(full_name_img_out) My data is stocked on folders. In the train folder, I have as many sub-folders as angle generated. So to load my data, I use regression_flow_from_directory . def regression_flow_from_directory_one_output(flow_from_directory_gen, list_of_values): for x, y in flow_from_directory_gen: y = list(map(lambda x: int(x), y)) yield x, list_of_values[y] datagen = ImageDataGenerator(rescale = 1/255) resize = (244,244) batch_size = 8 # load and iterate training dataset train_it = datagen.flow_from_directory(path_train_commun, class_mode="sparse", batch_size=batch_size, target_size=resize, color_mode="grayscale") # load and iterate test dataset test_it = datagen.flow_from_directory(path_test_commun, class_mode="sparse", batch_size=batch_size, target_size=resize, color_mode="grayscale") train_it_generator_img_with_label_one = regression_flow_from_directory_one_output(train_it, list_of_values_tuple) test_it_generator_img_with_label_one = regression_flow_from_directory_one_output(test_it, list_of_values_tuple) Then, I use resnet_v1 to create my model. This is my code: def resnet_v1(input_shape, depth, num_classes=10): if (depth - 2) % 6 != 0: raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])') # Start model definition. num_filters = 16 num_res_blocks = int((depth - 2) / 6) inputs = Input(shape=input_shape) x = resnet_layer(inputs=inputs) # Instantiate the stack of residual units for stack in range(3): for res_block in range(num_res_blocks): strides = 1 if stack > 0 and res_block == 0: # first layer but not first stack strides = 2 # downsample y = resnet_layer(inputs=x, num_filters=num_filters, strides=strides) y = resnet_layer(inputs=y, num_filters=num_filters, activation=None) if stack > 0 and res_block == 0: # first layer but not first stack # linear projection residual shortcut connection to match # changed dims x = resnet_layer(inputs=x, num_filters=num_filters, kernel_size=1, strides=strides, activation=None, batch_normalization=False) x = keras.layers.add([x, y]) x = Activation('relu')(x) num_filters *= 2 # Add classifier on top. # v1 does not use BN after last shortcut connection-ReLU x = AveragePooling2D(pool_size=8)(x) y = Flatten()(x) z1 = Dense(128, activation='relu')(y) z3 = Dense(64, activation='relu')(z1) outputs_angle_value = Dense(1, activation='sigmoid', name='output_angle_value')(z3) # Instantiate model. model = Model(inputs=inputs, outputs=outputs_angle_value) return model input_shape = (244,244,1) depth = 8 from keras_radam import RAdam opt = RAdam(total_steps=5000, warmup_proportion=0.1, min_lr=1e-5) model_one_output = resnet_v1(input_shape, depth) model_one_output.compile(loss= angle_error_regression, optimizer=opt) history = model_one_output.fit_generator( train_it_generator_img_with_label_one, steps_per_epoch= nb_data_in_train / 8, epochs=50, validation_data= test_it_generator_img_with_label_one, validation_steps= nb_data_test / 8, callbacks=[tensorboard, early_stop, checkpoint], verbose=1 ) Throughout the epochs loss decreases but when I predict the results are very bad. I tried to increase the number of epochs , change the loss and activation, generate more data. If someone has an idea, I would be grateful. :)
