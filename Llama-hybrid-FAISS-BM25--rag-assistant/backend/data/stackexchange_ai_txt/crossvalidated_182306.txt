[site]: crossvalidated
[post_id]: 182306
[parent_id]: 181516
[tags]: 
If you take logs then do regression on the log scale that will fit a mean on the log-scale. If you then exponentiate the log-scale prediction you won't get a mean prediction on the original variable. In fact if you want the mean the prediction will be too low on average. That may be fine, though. If the error distribution on the log scale is close to symmetric (which you can assess approximately by looking at the residuals) you'd essentially also have a median prediction on the log-scale; and if you exponentiate in that case you'd still have a median for the original-scale variable. [if mean = median on the log scale then mean > median on the original scale, as long as there's any variability at all] If your residuals look more-or-less symmetric and you're happy being under half the time and over half the time in your prediction (which is reasonable in some acses), then sure, just exponentiate. If you want to get the average right there's a number of issues to deal with, one way to do it approximately (assuming your $n$ is so large you're prepared to ignore uncertainty in the variance estimate -- it's something of a fudge) would be to scale up your predictions by $\exp(s^2)$ (though that would still be too low for several reasons), where $s$ is the residual standard deviation. However, prediction intervals for the next observation can just be exponentiated. [Personally, if I was really trying to get a mean prediction, I'd consider a gamma GLM with log-link which would have a pretty similar sort of fit on the log-scale - since if it's a reasonable model the transformation issue is avoided. If your residuals from the regression are a bit left skew that would probably be an excellent choice]
