[site]: stackoverflow
[post_id]: 2489994
[parent_id]: 2489595
[tags]: 
Your idea is interesting if only a bit naive (but no worries, naive questions are useful in the area of NLP). Leaving other practical questions aside (e.g. Parsing, POS-tagging, stemming, and of course the very issue of identifying/mapping a given word... I discuss them, very briefly, thereafter), there are several difficulties with the very principle of your suggestion [of a numeric scale where semantically close words are coded in proximity]: Polysemy (fancy word indicating the fact that some words can have multiple, unrelated meaning) Semantics are multi-dimensional. For example the noun "gumption" conveys both an idea of "energy" and an idea of "enthusiasm" Some concepts are completely unrelated to others, for example say 'tea' and 'carpet' belong to two different sets of words, but trying to place these on a linear scale would implicitly void the idea that distance on this scale (other than maybe very small distances) have any connection to semantics. Expressions: within a sentence, a particular concept is sometimes carried by an expression rather than the individual words. For example "Renaissance man" or "Table of Content". Semantics sometimes (often) come from context. For example "boss" is often referring to somebody's supervisor, is also Bruce Springsteen's nickname. In a nutshell a) meaning (or " definition ", as called in the question, or " semantics " as called by linguists) is a tricky thing which doesn't lend itself to being mapped onto a line, or even a tree. Other graphs such as networks can be used, but even then things can get a bit tricky when applied beyond relatively restricted domains. and b) associating words with meanings is also tricky because of polysemy, expressions etc. Never the less, if you'd like to attempt the kind of mapping suggested in the question, maybe in the context of a specific domain (say that of sport commentary or mechanics repairs) and/or understanding that some words will just have to be arbitrarily mapped, before "diving in", you may want to get familiar with the following NLP (Natural Language Processing) disciplines and resources : Part-of-Speech (POS) Tagging Stemming WordNet and other lexical databases Stanford Natural Language Processing Group including their annotated resource list for statistical and Corpus-based NLP software Natural Language ToolKit (NLTK) (Python based, but very didactic) With regards to your interest in using tools written in C++ , you'll probably find several of these, for various purposes (and of various quality !). You may also find that although they sometimes bind to primitives written in C/C++ for performances reasons, many of the modern frameworks and tools of NLP tend to use Java or even script languages like Python. I do not have direct experience with C++ based NLP software. If you do not find what you need (in C++), I discourage you, vehemently, to try and implement something yourself, at least before you have previously reviewed extensively previous art and have a good understanding for the underlying difficulties.
