[site]: crossvalidated
[post_id]: 167127
[parent_id]: 
[tags]: 
Average of Monte-Carlo estimates: Increasing observations vs. iterations

In the context of Monte Carlo simulations, I would like to understand better the difference between increasing the number of iterations vs. the number of observations. As an example, please consider the following simple R code that is supposed to confirm the unbiasedness of OLS: set.seed(1) beta The average of the estimates is pretty close to the true beta values and would become even closer if I increased Niter or NObs . In the current case, I am only interested in the average of the estimates. If I was interested in their distribution, I would need a sufficiently large Niter to get as many observed estimates as possile. But when I only want to check the average, what is the difference between increasing Niter vs. NObs ? Increasing Niter (100) by 1 gives NObs (1000) observations more. Is this equivalent to increasing NObs by 10 which also gives 1000 additional observations over the 100 iterations?
