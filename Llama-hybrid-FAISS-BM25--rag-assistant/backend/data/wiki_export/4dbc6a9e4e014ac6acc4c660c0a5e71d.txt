In probability theory, the inverse Gaussian distribution (also known as the Wald distribution) is a two-parameter family of continuous probability distributions with support on (0,∞).

Its probability density function is given by

 

for x > 0, where  is the mean and  is the shape parameter.

The inverse Gaussian distribution has several properties analogous to a Gaussian distribution.  The name can be misleading:  it is an "inverse" only in that, while the Gaussian describes a Brownian motion's level at a fixed time, the inverse Gaussian describes the distribution of the time a Brownian motion with positive drift takes to reach a fixed positive level.

Its cumulant generating function (logarithm of the characteristic function) is the inverse of the cumulant generating function of a Gaussian random variable.

To indicate that a random variable X is inverse Gaussian-distributed with mean μ and shape parameter λ we write .

Properties

Single parameter form
The probability density function (pdf) of the inverse Gaussian distribution has a single parameter form given by

In this form, the mean and variance of the distribution are equal, 

Also, the cumulative distribution function (cdf) of the single parameter inverse Gaussian distribution is related to the standard normal distribution by

where ,  and the  is the cdf of standard normal distribution. The variables  and  are related to each other by the identity 

In the single parameter form, the MGF simplifies to

An inverse Gaussian distribution in double parameter form  can be transformed into a single parameter form  by appropriate scaling  where 

The standard form of inverse Gaussian distribution is

Summation

If Xi has an  distribution for i = 1, 2, ..., n
and all Xi are independent, then

Note that

is constant for all i. This is a necessary condition for the summation. Otherwise S would not be Inverse Gaussian distributed.

Scaling
For any t > 0 it holds that

Exponential family

The inverse Gaussian distribution is a two-parameter exponential family with natural parameters −λ/(2μ2) and −λ/2, and natural statistics X and 1/X.

For  fixed, it is also a single-parameter natural exponential family distribution where the base distribution has density

 

Indeed, with ,

is a density over the reals. Evaluating the integral, we get

Substituting  makes the above expression equal to .

Relationship with Brownian motion
Let the stochastic process Xt be given by

where Wt is a standard Brownian motion. That is, Xt is a Brownian motion with drift .

Then the first passage time for a fixed level  by Xt is distributed according to an inverse-Gaussian:

i.e

(cf. Schrödinger equation 19, Smoluchowski, equation 8, and Folks, equation 1).

Suppose that we have a Brownian motion  with drift  defined by:

And suppose that we wish to find the probability density function for the time when the process first hits some barrier  - known as the first passage time. The Fokker-Planck equation describing the evolution of the probability distribution  is:

where  is the Dirac delta function. This is a boundary value problem (BVP) with a single absorbing boundary condition , which may be solved using the method of images. Based on the initial condition, the fundamental solution to the Fokker-Planck equation, denoted by , is:

Define a point , such that . This will allow the original and mirror solutions to cancel out exactly at the barrier at each instant in time. This implies that the initial condition should be augmented to become:

where  is a constant. Due to the linearity of the BVP, the solution to the Fokker-Planck equation with this initial condition is:

Now we must determine the value of . The fully absorbing boundary condition implies that:

At , we have that . Substituting this back into the above equation, we find that:

Therefore, the full solution to the BVP is:

Now that we have the full probability density function, we are ready to find the first passage time distribution . The simplest route is to first compute the survival function , which is defined as:

where  is the cumulative distribution function of the standard normal distribution. The survival function gives us the probability that the Brownian motion process has not crossed the barrier  at some time . Finally, the first passage time distribution  is obtained from the identity:

Assuming that , the first passage time follows an inverse Gaussian distribution:

When drift is zero
A common special case of the above arises when the Brownian motion has no drift.  In that case, parameter μ tends to infinity, and the first passage time for fixed level α has probability density function

 

(see also Bachelier). This is a Lévy distribution with parameters  and .

Maximum likelihood
The model where

with all wi known, (μ, λ) unknown and all Xi independent has the following likelihood function

Solving the likelihood equation yields the following maximum likelihood estimates

 and  are independent and

Sampling from an inverse-Gaussian distribution
The following algorithm may be used.
Generate a random variate from a normal distribution with mean 0 and standard deviation equal 1

Square the value

and use the relation

Generate another random variate, this time sampled from a uniform distribution between 0 and 1

If

then return

else return
Sample code in Java:

public double inverseGaussian(double mu, double lambda) {
    Random rand = new Random();
    double v = rand.nextGaussian();  // Sample from a normal distribution with a mean of 0 and 1 standard deviation
    double y = v * v;
    double x = mu + (mu * mu * y) / (2 * lambda) - (mu / (2 * lambda)) * Math.sqrt(4 * mu * lambda * y + mu * mu * y * y);
    double test = rand.nextDouble();  // Sample from a uniform distribution between 0 and 1
    if (test <= (mu) / (mu + x))
        return x;
    else
        return (mu * mu) / x;
}

And to plot Wald distribution in Python using matplotlib and NumPy:
import matplotlib.pyplot as plt
import numpy as np

h = plt.hist(np.random.wald(3, 2, 100000), bins=200, density=True)

plt.show()

Related distributions
 If , then  for any number 
 If  then 
 If  for  then 
 If  then 
 If , then .

The convolution of an inverse Gaussian distribution (a Wald distribution) and an exponential (an ex-Wald distribution) is used as a model for response times in psychology, with visual search as one example.

History

This distribution appears to have been first derived in 1900 by Louis Bachelier as the time a stock reaches a certain price for the first time. In 1915 it was used independently by Erwin Schrödinger and Marian v. Smoluchowski as the time to first passage of a Brownian motion. In the field of reproduction modeling it is known as the Hadwiger function, after Hugo Hadwiger who described it in 1940. Abraham Wald re-derived this distribution in 1944 as the limiting form of a sample in a sequential probability ratio test. The name inverse Gaussian was proposed by Maurice Tweedie in 1945. Tweedie investigated this distribution in 1956 and 1957 and established some of its statistical properties. The distribution was extensively reviewed by Folks and Chhikara in 1978.

Numeric computation and software

Despite the simple formula for the probability density function, numerical probability calculations for the inverse Gaussian distribution nevertheless require special care to achieve full machine accuracy in floating point arithmetic for all parameter values.  Functions for the inverse Gaussian distribution are provided for the R programming language by several packages including rmutil, SuppDists, STAR, invGauss, LaplacesDemon, and statmod.

See also
Generalized inverse Gaussian distribution
 Tweedie distributions—The inverse Gaussian distribution is a member of the family of Tweedie exponential dispersion models
Stopping time

References

Further reading

External links
 Inverse Gaussian Distribution in Wolfram website.

Continuous distributions
Exponential family distributions
Infinitely divisible probability distributions
Articles with example Java code
Articles with example Python (programming language) code