In mathematics, a moment matrix is a special symmetric square matrix whose rows and columns are indexed by monomials. The entries of the matrix depend on the product of the indexing monomials only (cf. Hankel matrices.)

Moment matrices play an important role in polynomial fitting, polynomial optimization (since positive semidefinite moment matrices correspond to polynomials which are sums of squares) and econometrics.

Application in regression
A multiple linear regression model can be written as

where  is the explained variable,  are the explanatory variables,  is the error, and  are unknown coefficients to be estimated. Given observations , we have a system of  linear equations that can be expressed in matrix notation.

or

where  and  are each a vector of dimension ,  is the design matrix of order , and  is a vector of dimension . Under the Gaussâ€“Markov assumptions, the best linear unbiased estimator of  is the linear least squares estimator , involving the two moment matrices  and  defined as

and

where  is a square normal matrix of dimension , and  is a vector of dimension .

See also
 Design matrix
 Gramian matrix
 Projection matrix

References

External links
 

Matrices
Least squares