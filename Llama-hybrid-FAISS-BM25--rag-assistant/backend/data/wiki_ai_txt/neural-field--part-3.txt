learning Instead of relying on the latent code to adapt the neural field to a specific task, it is also possible to exploit gradient-based meta-learning. In this case, the neural field is seen as the specialization of an underlying meta-neural-field, whose parameters are modified to fit the specific task, through a few steps of gradient descent. An extension of this meta-learning framework is the CAVIA algorithm, that splits the trainable parameters in context-specific and shared groups, improving parallelization and interpretability, while reducing meta-overfitting. This strategy is similar to the auto-decoding conditional neural field, but the training procedure is substantially different. Applications Thanks to the possibility of efficiently modelling diverse mathematical fields with neural networks, neural fields have been applied to a wide range of problems: 3D scene reconstruction: neural fields can be used to model the properties of 3D scenes (i.e., geometry, appearance, materials, and lighting), in both static and dynamic cases. For example, a neural field can learn signed distance functions (SDFs) or occupancy functions, which provide an efficient and continuous representation of the geometry. Another example is represented by neural radiance fields (NeRFs), that learn to render 3D scenes, by mapping coordinates and viewing angles to the corresponding radiance and density. Digital humans: neural fields can be used to model human shape and appearance and can include information on the complex movements of a human body. Generative modelling: by leveraging conditioning, neural fields can also work as deep generative models. Image processing: with respect to convolutional neural networks, neural fields offer a continuous representation of the image and, hence, are not limited to the original pixel discretization. Robotics: the strengths of neural fields in scene reconstruction are also useful in robotics, as navigation requires reconstructing the surroundings from sensor data. Moreover, neural fields can be used for planning and control. Lossy data compression Signal processing Scientific computing: scientific machine learning (SciML) recently emerged as the combination of physics-based and data-driven models, to numerically solve differential equations. In this context, the ability of neural fields to model input and solution in a continuous and differentiable manner is invaluable. For example, physics-informed neural networks (PINNs) use neural fields to include, in the training objective, the residual computed via automatic differentiation. Instead, encode-process-decode architectures (e.g. CORAL), built on conditional neural fields, have been explored as an alternative operator-learning technique. See also Artificial intelligence Machine learning Neural network (machine learning) Neural radiance field Neural operators References External links Brown University's database of neural-field architectures Neural Radiance Fields: visual computing applications GitHub-Awesome list of Implicit Neural Representations