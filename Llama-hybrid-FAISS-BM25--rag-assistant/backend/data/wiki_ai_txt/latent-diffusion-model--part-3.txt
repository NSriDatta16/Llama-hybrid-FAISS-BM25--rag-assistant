 sequence. When no embedding vector sequence is input, a cross-attentional block defaults to self-attention, with the latent array serving as the query, key, and value. In pseudocode, The detailed architecture may be found in. Training and inference The LDM is trained by using a Markov chain to gradually add noise to the training images. The model is then trained to reverse this process, starting with a noisy image and gradually removing the noise until it recovers the original image. More specifically, the training process can be described as follows: Forward diffusion process: Given a real image x 0 {\displaystyle x_{0}} , a sequence of latent variables x 1 : T {\displaystyle x_{1:T}} are generated by gradually adding Gaussian noise to the image, according to a pre-determined "noise schedule". Reverse diffusion process: Starting from a Gaussian noise sample x T {\displaystyle x_{T}} , the model learns to predict the noise added at each step, in order to reverse the diffusion process and obtain a reconstruction of the original image x 0 {\displaystyle x_{0}} . The model is trained to minimize the difference between the predicted noise and the actual noise added at each step. This is typically done using a mean squared error (MSE) loss function. Once the model is trained, it can be used to generate new images by simply running the reverse diffusion process starting from a random noise sample. The model gradually removes the noise from the sample, guided by the learned noise distribution, until it generates a final image. See the diffusion model page for details. See also Diffusion model Generative adversarial network Variational autoencoder Stable Diffusion References Further reading Wang, Phil (2024-09-07). "lucidrains/denoising-diffusion-pytorch". GitHub. Retrieved 2024-09-07. "The Annotated Diffusion Model". huggingface.co. Retrieved 2024-09-07. "U-Net for Stable Diffusion". U-Net for Stable Diffusion. Retrieved 2024-08-31. "Transformer for Stable Diffusion U-Net". Transformer for Stable Diffusion U-Net. Retrieved 2024-09-07.