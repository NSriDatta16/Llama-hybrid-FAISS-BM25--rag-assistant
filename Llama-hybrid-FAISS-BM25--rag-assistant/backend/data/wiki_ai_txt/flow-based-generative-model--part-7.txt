\mathbf {q} \in \Delta ^{n-1}} ), is the parallelotope, V = f ( U ) = / F p E D / {\displaystyle V=f(U)=/\mathbf {F_{p}ED} \!/} , where F p {\displaystyle \mathbf {F_{p}} } is the n -by- n {\displaystyle n{\text{-by-}}n} Jacobian of f {\displaystyle f} at p = e ( p ~ ) {\displaystyle \mathbf {p} =e({\tilde {\mathbf {p} }})} . Its volume is: volume ⁡ ( V ) = | det ⁡ ( D E ′ F p ′ F p E D ) | = | det ⁡ ( E ′ F p ′ F p E ) | | det ⁡ D ) | {\displaystyle \operatorname {volume} (V)={\sqrt {\left|\operatorname {det} (\mathbf {DE} '\mathbf {F_{p}} '\mathbf {F_{p}ED} )\right|}}={\sqrt {\left|\operatorname {det} (\mathbf {E} '\mathbf {F_{p}} '\mathbf {F_{p}E} )\right|}}\,\left|\operatorname {det} \mathbf {D} )\right|} so that the factor | det ⁡ D ) | {\displaystyle \left|\operatorname {det} \mathbf {D} )\right|} cancels in the volume ratio, which can now already be numerically evaluated. It can however be rewritten in a sometimes more convenient form by also introducing the representation function, r : p ↦ p ~ {\displaystyle r:\mathbf {p} \mapsto {\tilde {\mathbf {p} }}} , which simply extracts the first ( n − 1 ) {\displaystyle (n-1)} components. The Jacobian is R = [ I n 0 ] {\displaystyle \mathbf {R} ={\begin{bmatrix}\mathbf {I} _{n}&{\boldsymbol {0}}\end{bmatrix}}} . Observe that, since e ∘ r ∘ f = f {\displaystyle e\circ r\circ f=f} , the chain rule for function composition gives: E R F p = F p {\displaystyle \mathbf {ERF_{p}} =\mathbf {F_{p}} } . By plugging this expansion into the above Gram determinant and then refactoring it as a product of determinants of square matrices, we can extract the factor | det ⁡ ( E ′ E ) | = n {\displaystyle {\sqrt {\left|\operatorname {det} (\mathbf {E} '\mathbf {E} )\right|}}={\sqrt {n}}} , which now also cancels in the ratio, which finally simpifies to the determinant of the Jacobian of the "sandwiched" flow transformation, r ∘ f ∘ e {\displaystyle r\circ f\circ e} : R f Δ ( p ) = volume ⁡ ( V ) volume ⁡ ( U ) = | det ⁡ ( R F p E ) | {\displaystyle R_{f}^{\Delta }(\mathbf {p} )={\frac {\operatorname {volume} (V)}{\operatorname {volume} (U)}}=\left|\operatorname {det} (\mathbf {RF_{p}E} )\right|} which, if p ∼ P P {\displaystyle \mathbf {p} \sim P_{\mathbf {P} }} , can be used to derive the pushforward density after a change of variables, q = f ( p ) {\displaystyle \mathbf {q} =f(\mathbf {p} )} : P Q ( q ) = P P ( p ) R f Δ ( p ) , where p = f − 1 ( q ) {\displaystyle P_{\mathbf {Q} }(\mathbf {q} )={\frac {P_{\mathbf {P} }(\mathbf {p} )}{R_{f}^{\Delta }(\mathbf {p} )}}\,,\;{\text{where}}\;\;\mathbf {p} =f^{-1}(\mathbf {q} )} This formula is valid only because the simplex is flat and the Jacobian, E {\displaystyle \mathbf {E} } is constant. The more general case for curved manifolds is discussed below, after we present two concrete examples of simplex flow transforms. Simplex calibration transform A calibration transform, f cal : Δ n − 1 → Δ n − 1 {\displaystyle f_{\text{cal}}:\Delta ^{n-1}\to \Delta ^{n-1}} , which is sometimes used in machine learning for post-processing of the (class posterior) outputs of a probabilistic n {\displaystyle n} -class classifier, uses the softmax function to renormalize categorical distributions after scaling and translation of the input distributions in log-probability space. For p , q ∈ Δ n − 1 {\displaystyle \mathbf {p} ,\mathbf {q} \in \Delta ^{n-1}} and with parameters, a ≠ 0 {\displaystyle a\neq 0} and c ∈ R n {\displaystyle \mathbf {c} \in \mathbb {R} ^{n}} the transform can be specified as: q = f cal ( p ; a , c ) = softmax ⁡ ( a − 1 log ⁡ p + c ) ⟺ p = f cal − 1 ( q ; a , c ) = softmax ⁡ ( a log ⁡ q − a c ) {\displaystyle \mathbf {q} =f_{\text{cal}}(\mathbf {p} ;a,\mathbf {c} )=\operatorname {softmax} (a^{-1}\log \mathbf {p} +\mathbf {c} )\;\iff \;\mathbf {p} =f_{\text{cal}}^{-1}(\mathbf {q} ;a,\mathbf {c} )=\operatorname {softmax} (a\log \mathbf {q} -a\mathbf {c} )} where the log is applied elementwise. After some algebra the differential volume ratio can