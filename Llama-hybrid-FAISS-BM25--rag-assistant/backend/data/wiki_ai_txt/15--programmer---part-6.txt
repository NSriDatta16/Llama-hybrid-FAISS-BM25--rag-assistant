ciation errors occurred due to the limited training data, it was understandable given that contemporary deep learning models typically required 40 or more hours of audio. Ji Yunyo of NetEase News called the technology behind 15.ai "remarkably efficient" but also criticized its emotional limitations, writing that the emotional expression was relatively "neutral" and that "extreme" emotions couldn't be properly synthesized, making it less suitable for not safe for work applications. Ji also wrote that while many deepfake videos required creators to extract and edit material from hours of original content for very short results, 15.ai could achieve similar or better effects with only a few dozen minutes of training data per character. Reactions from voice actors of featured characters Some voice actors whose characters appeared on 15.ai have publicly shared their thoughts about the platform. In an April 2021 interview, John Patrick Lowrie—who voices the Sniper in Team Fortress 2—said that he had discovered 15.ai when a prospective intern showed him a skit she had created using AI voices of the Team Fortress 2 characters. Lowrie commented: "The technology still has a long way to go before you really believe that these are just human beings, but I was impressed by how much [15.ai] could do. [...] You certainly don't get the delivery that you get from an actual person who's analyzed the scene, [...] but I do think that as a fan source—for people wanting to put together mods and stuff like that—that it could be fun for fans to use the voices of characters they like." He drew an analogy to synthesized music, adding: "If you want the sound of a choir, and you want the sound of an orchestra, and you have the money, you hire a choir and an orchestra. And if you don't have the money, you have something that sounds pretty nice; but it's not the same as a choir and an orchestra." In a 2021 live broadcast on his Twitch channel, Nathan Vetterlein—the voice actor of the Scout from Team Fortress 2—listened to an AI recreation of his character's voice and commented: "It's interesting; it's all right. There's some stuff in there". Ethical concerns Other voice actors had mixed reactions to 15.ai's capabilities. While some industry professionals acknowledged the technical innovation, others raised concerns about the technology's implications for their profession. When voice actor Troy Baker announced his partnership with Voiceverse NFT, which had misappropriated 15.ai's technology, critics raised concerns about automated voice acting's potential reduction of employment opportunities for voice actors, risk of voice impersonation, and potential misuse in explicit content. Ruby Innes of Kotaku Australia wrote that "this practice could potentially put voice actors out of work considering you could just use their AI voice rather than getting them to voice act for a project and paying them." In her coverage of the Voiceverse controversy, Edith Wakelin-King of Checkpoint Gaming raised the concern that "this kind of technology has the potential to push voice actors out of work if it becomes easier and cheaper to use AI voices instead of working with the actor directly." While 15.ai limited its scope to fictional characters and did not reproduce voices of real people or celebrities, computer scientist Andrew Ng commented that similar technology could be used to do so, including for nefarious purposes. In his 2020 assessment of 15.ai, Ng outlined potential "enormously productive" applications of voice cloning, such as revolutionizing the use of virtual actors in Hollywood, enabling voice actors to participate in more cartoon and audiobook productions, and allowing content creators to use synthetic celebrity voices to narrate their scripts. However, he also cautioned that synthesizing a human's voice without consent raises ethical concerns and potential legal issues, and further warned that it could be maliciously exploited to impersonate private individuals.