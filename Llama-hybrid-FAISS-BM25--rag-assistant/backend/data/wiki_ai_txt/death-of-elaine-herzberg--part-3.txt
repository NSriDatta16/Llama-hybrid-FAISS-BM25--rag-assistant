eering wheel, which is what drivers are instructed to do so they can quickly retake control of the car. Uber had moved from two employees in every car to one. The paired employees had been splitting duties: one ready to take over if the autonomous system failed, and another to keep an eye on what the computers were detecting. The second person was responsible for keeping track of system performance as well as labeling data on a laptop computer. Mr. Kallman, the Uber spokesman, said the second person was in the car for purely data related tasks, not safety. When Uber moved to a single operator, some employees expressed safety concerns to managers, according to the two people familiar with Uber's operations. They were worried that going solo would make it harder to remain alert during hours of monotonous driving. The recorded telemetry showed the system had detected Herzberg six seconds before the crash, and classified her first as an unknown object, then as a vehicle, and finally as a bicycle, each of which had a different predicted path according to the autonomy logic. 1.3 seconds prior to the impact, the system determined that emergency braking was required, which is normally performed by the vehicle operator. However, the system was not designed to alert the operator, and did not make an emergency stop on its own accord, as "emergency braking maneuvers are not enabled while the vehicle is under computer control, to reduce the potential for erratic vehicle behavior", according to NTSB. Sensor issues Brad Templeton, who provided consulting for autonomous driving competitor Waymo, noted the car was equipped with advanced sensors, including radar and LiDAR, which would not have been affected by the darkness. Templeton stated "I know the [sensor] technology is better than that, so I do feel that it must be Uber's failure." Arrowood also recognized potential sensor issues: "Really what we are going to ask is, at what point should or could those sensors recognize the movement off to the left. Presumably she was somewhere in the darkness." In a press event conducted by Uber in Tempe in 2017, safety drivers touted the sensor technology, saying they were effective at anticipating jaywalkers, especially in the darkness, stopping the autonomous vehicles before the safety driver can even see pedestrians. However, manual intervention by the safety drivers was required to avoid a collision with another vehicle on at least one instance with a reporter from The Arizona Republic riding along. Uber announced they would replace their Ford Fusion-based self-driving fleet with cars based on the Volvo XC90 in August 2016; the XC90s sold to Uber would be prepared to receive Uber's vehicle control hardware and software, but would not include any of Volvo's own advanced driver-assistance systems. Uber characterized the sensor suite attached to the Fusion as the "desktop" model, and the one attached to the XC90 as the "laptop", hoping to develop the "smartphone" soon. According to Uber, the suite for the XC90 was developed in approximately four months. The XC90 as modified by Uber included a single roof-mounted LiDAR sensor and 10 radar sensors, providing 360Â° coverage around the vehicle. In comparison, the Fusion had seven LiDAR sensors (including one mounted on the roof) and seven radar sensors. According to Velodyne, the supplier of Uber's LiDAR, the single roof-mounted LiDAR sensor has a narrow vertical range that prevents it from detecting obstacles low to the ground, creating a blind spot around the vehicle. Marta Hall, the president of Velodyne commented "If you're going to avoid pedestrians, you're going to need to have a side lidar to see those pedestrians and avoid them, especially at night." However, the augmented radar sensor suite would be able to detect obstacles in the LiDAR blind spot. Distraction On Thursday, June 21, the Tempe Police Department released a detailed report along with media captured after the collision, including an aud