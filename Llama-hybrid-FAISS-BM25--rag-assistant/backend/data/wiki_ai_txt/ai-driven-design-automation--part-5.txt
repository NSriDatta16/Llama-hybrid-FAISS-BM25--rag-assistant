presentation learning, where the aim is to automatically learn useful and often simpler representations (features or embeddings) of circuit data. This could involve learning embeddings for analog circuit structures using methods based on graphs or understanding the function of netlists through contrastive learning methods. Reinforcement learning Reinforcement learning (RL) is a kind of machine learning where an agent, or a computer program, learns to make the best decisions by trying things out in a simulated environment. The agent takes actions, moves between different states, and gets rewards or penalties as feedback. The main goal is to get the highest total reward over time. RL is different from supervised learning because it does not need labeled data. It also differs from unsupervised learning because it learns by trial and error to achieve a specific goal. In EDA, RL is especially good for tasks that require making a series of decisions to find the best solution in very complex situations with many variables. Its adoption by commercial EDA products shows its growing importance. RL has been used for physical design problems like chip floorplanning. In this task, an agent learns to place blocks to improve things like wire length and performance. In logic synthesis, RL can guide how optimization steps are chosen and in what order they are applied to get better results, as seen in methods like AlphaSyn. Another example where RL agents can learn effective strategies is adjusting the size of gates to optimize timing. Generative AI Generative AI means artificial intelligence models that can create new content, like text, images, or code, instead of just analyzing or working with existing data. These models learn the underlying patterns and structures from the data they are trained on. They then use this knowledge to create new and original outputs. In EDA, generative AI is being used in many ways, especially through Large Language Models (LLMs) and other architectures like Generative Adversarial Networks (GANs). Large language models (LLMs) Large Language Models are deep learning models, often based on the transformer architecture. They are pre trained on huge amounts of text and code. They are very good at understanding, summarizing, creating, and predicting human language and programming languages. Their abilities are being used in EDA for jobs such as: RTL Code Generation: LLMs are used to automatically write code in a Hardware Description Language (HDL) based on written instructions or requirements. Benchmarks like VerilogEval and RTLLM have been created to check these abilities, and tools like AutoChip aim to automate this process. EDA Script Generation and Tool Interaction: Agents based on LLMs, like ChatEDA, can turn plain language commands into runnable scripts for controlling EDA tools. Architectural Design and Exploration: LLMs help in the early stages of design. They can generate high level synthesis code (for example, GPT4AIGChip), explore design options for special hardware like Compute in Memory accelerators, or help create and review design requirements (SpecLLM). Verification Assistance: Researchers are looking into using LLMs to create verification parts like SVAs from plain language descriptions. Other generative models Besides LLMs, other generative models like Generative Adversarial Networks (GANs) are also used in EDA. A GAN has two neural networks, a generator and a discriminator, which are trained in a competition against each other. The generator learns to make data samples that look like the training data, while the discriminator learns to tell the difference between real and generated samples. In physical design, GANs have been used for tasks like creating sub resolution assist features (SRAFs) to make chips easier to manufacture in lithography (GAN SRAF) and for optimizing masks (GAN OPC). Industry adoption and ecosystem The use of artificial intelligence in electronic design automation is a widespre