 W 1 {\displaystyle W_{1}^{T}AW_{1}} on its diagonal. We may retain all the eigenvalues and their corresponding eigenvectors since most of the noise are already discarded in previous step. Finally the transformation is given by: W = W 1 W 2 {\displaystyle W=W_{1}W_{2}} where W {\displaystyle W} diagonalizes both the numerator and denominator of the SNR, W T A W = D A {\displaystyle W^{T}AW=D_{A}} , W T B W = I {\displaystyle W^{T}BW=I} and the transformation of signal s {\displaystyle s} is defined as q = W T X T s = W 2 T W 1 T X T s {\displaystyle q=W^{T}X^{T}s=W_{2}^{T}W_{1}^{T}X^{T}s} . Information loss To find the information loss when we discard some of the eigenvalues and eigenvectors we can perform following analysis: η = 1 − t r a c e ( W 1 T A W 1 ) t r a c e ( D B − 1 / 2 P T A P D B − 1 / 2 ) = 1 − t r a c e ( D B ^ − 1 / 2 P ^ T A P ^ D B ^ − 1 / 2 ) t r a c e ( D B − 1 / 2 P T A P D B − 1 / 2 ) {\displaystyle {\begin{array}{lll}\eta &=&1-{\frac {trace(W_{1}^{T}AW_{1})}{trace(D_{B}^{-1/2}P^{T}APD_{B}^{-1/2})}}\\&=&1-{\frac {trace({\hat {D_{B}}}^{-1/2}{\hat {P}}^{T}A{\hat {P}}{\hat {D_{B}}}^{-1/2})}{trace(D_{B}^{-1/2}P^{T}APD_{B}^{-1/2})}}\end{array}}} Eigenmoments Eigenmoments are derived by applying the above framework on Geometric Moments. They can be derived for both 1D and 2D signals. 1D signal If we let X = [ 1 , x , x 2 , . . . , x m − 1 ] {\displaystyle X=[1,x,x^{2},...,x^{m-1}]} , i.e. the monomials, after the transformation X T {\displaystyle X^{T}} we obtain Geometric Moments, denoted by vector M {\displaystyle M} , of signal s = [ s ( x ) ] {\displaystyle s=[s(x)]} , i.e. M = X T s {\displaystyle M=X^{T}s} . In practice it is difficult to estimate the correlation signal due to insufficient number of samples, therefore parametric approaches are utilized. One such model can be defined as: r ( x 1 , x 2 ) = r ( 0 , 0 ) e − c ( x 1 − x 2 ) 2 {\displaystyle r(x_{1},x_{2})=r(0,0)e^{-c(x_{1}-x_{2})^{2}}} , where r ( 0 , 0 ) = E [ t r ( s s T ) ] {\displaystyle r(0,0)=E[tr(ss^{T})]} . This model of correlation can be replaced by other models however this model covers general natural images. Since r ( 0 , 0 ) {\displaystyle r(0,0)} does not affect the maximization it can be dropped. A = X T C X = ∫ − 1 1 ∫ − 1 1 [ x 1 j x 2 i e − c ( x 1 − x 2 ) 2 ] i , j = 0 i , j = m − 1 d x 1 d x 2 {\displaystyle A=X^{T}CX=\int _{-1}^{1}\int _{-1}^{1}[x_{1}^{j}x_{2}^{i}e^{-c(x_{1}-x_{2})^{2}}]_{i,j=0}^{i,j=m-1}dx_{1}dx_{2}} The correlation of noise can be modelled as σ n 2 δ ( x 1 , x 2 ) {\displaystyle \sigma _{n}^{2}\delta (x_{1},x_{2})} , where σ n 2 {\displaystyle \sigma _{n}^{2}} is the energy of noise. Again σ n 2 {\displaystyle \sigma _{n}^{2}} can be dropped because the constant does not have any effect on the maximization problem. B = X T N X = ∫ − 1 1 ∫ − 1 1 [ x 1 j x 2 i δ ( x 1 , x 2 ) ] i , j = 0 i , j = m − 1 d x 1 d x 2 {\displaystyle B=X^{T}NX=\int _{-1}^{1}\int _{-1}^{1}[x_{1}^{j}x_{2}^{i}\delta (x_{1},x_{2})]_{i,j=0}^{i,j=m-1}dx_{1}dx_{2}} B = X T N X = ∫ − 1 1 [ x 1 j + i ] i , j = 0 i , j = m − 1 d x 1 = X T X {\displaystyle B=X^{T}NX=\int _{-1}^{1}[x_{1}^{j+i}]_{i,j=0}^{i,j=m-1}dx_{1}=X^{T}X} Using the computed A and B and applying the algorithm discussed in previous section we find W {\displaystyle W} and set of transformed monomials Φ = [ ϕ 1 , . . . , ϕ k ] = X W {\displaystyle \Phi =[\phi _{1},...,\phi _{k}]=XW} which produces the moment kernels of EM. The moment kernels of EM decorrelate the correlation in the image. Φ T C Φ = ( X W ) T C ( X W ) = D C {\displaystyle \Phi ^{T}C\Phi =(XW)^{T}C(XW)=D_{C}} , and are orthogonal: Φ T Φ = ( X W ) T ( X W ) = W T X T X = W T X T N X W = W T B W = I {\displaystyle {\begin{array}{lll}\Phi ^{T}\Phi &=&(XW)^{T}(XW)\\&=&W^{T}X^{T}X\\&=&W^{T}X^{T}NXW\\&=&W^{T}BW\\&=&I\\\end{array}}} Example computation Taking c = 0.5 {\displaystyle c=0.5} , the dimension of moment space as m = 6 {\displaystyle m=6} and the dimension of feature space as k = 4 {\displaystyle k=4} 