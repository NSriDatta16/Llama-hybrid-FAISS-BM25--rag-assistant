 the clinical use of AI have brought about a potential need for regulations. AI studies need to be completely and transparently reported to have value to inform regulatory approval. Depending on the phase of study, international consensus-based reporting guidelines (TRIPOD+AI, DECIDE-AI, CONSORT-AI) have been developed to provide recommendations on the key details that need to be reported. While regulations exist pertaining to the collection of patient data such as the Health Insurance Portability and Accountability Act in the US (HIPAA) and the European General Data Protection Regulation (GDPR) pertaining to patients within the EU, health care AI is "severely under-regulated worldwide" as of 2025. Unclear is whether healthcare AI can be classified merely as software or as medical device. United Nations (WHO/ITU) The ITU-WHO Focus Group on Artificial Intelligence for Health (FG-AI4H) has built a platform known as the ITU-WHO AI for Health Framework for the testing and benchmarking of AI applications in health domain as a joint endeavor of ITU and WHO. As of November 2018, eight use cases were being benchmarked, including assessing breast cancer risk from histopathological imagery, guiding anti-venom selection from snake images, and diagnosing skin lesions. USA In 2015, the Office for Civil Rights (OCR) issued rules and regulations to protect the privacy of individuals' health information, requiring healthcare providers to follow certain privacy rules when using AI, to keep a record of how they use AI and to ensure that their AI systems are secure. In May 2016, the White House announced its plan to host a series of workshops and formation of the National Science and Technology Council (NSTC) Subcommittee on Machine Learning and Artificial Intelligence. In October 2016, the group published The National Artificial Intelligence Research and Development Strategic Plan, outlining its proposed priorities for Federally-funded AI research and development (within government and academia). The report notes a strategic R&D plan for the subfield of health information technology was in development stages. In January 2021, the US FDA published a new Action Plan, entitled Artificial Intelligence (AI) /Machine Learning (ML)-Based Software as a Medical Device (SaMD) Action Plan. It layed out the FDA's future plans for regulation of medical devices that would include artificial intelligence in their software with five main actions: 1. Tailored Regulatory Framework for Ai/M:-based SaMD, 2. Good Machine Learning Practice (GMLP), 3. Patient-Centered Approach Incorporating Transparency to Users, 4. Regulatory Science Methods Related to Algorithm Bias & Robustness, and 5. Real-World Performance(RWP). This plan was in direct response to stakeholders' feedback on a 2019 discussion paper also published by the FDA. Under President Biden the DHSS and the National Institute of Standards and Technology were instructed to develop regulation of healthcare AI. According to the U.S. Department of Health and Human Services, the OCR issued guidance on the ethical use of AI in healthcare in 2021. It outlined four core ethical principles that must be followed: respect for autonomy, beneficence, non-maleficence, and justice. Respect for autonomy requires that individuals have control over their own data and decisions. Beneficence requires that AI be used to do good, such as improving the quality of care and reducing health disparities. Non-maleficence requires that AI be used to do no harm, such as avoiding discrimination in decisions. Finally, justice requires that AI be used fairly, such as using the same standards for decisions no matter a person's race, gender, or income level. As of March 2021, the OCR had hired a Chief Artificial Intelligence Officer (OCAIO) to pursue the "implementation of the HHS AI strategy". With the second Trump administration deregulation of health AI began on January 20, 2025 with merely voluntary standards for collecting and sharing da