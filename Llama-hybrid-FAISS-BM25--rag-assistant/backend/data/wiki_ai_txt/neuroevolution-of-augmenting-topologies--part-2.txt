s placed in the population to participate in the ongoing evaluations. The first application of rtNEAT is a video game called Neuro-Evolving Robotic Operatives, or NERO. In the first phase of the game, individual players deploy robots in a 'sandbox' and train them to some desired tactical doctrine. Once a collection of robots has been trained, a second phase of play allows players to pit their robots in a battle against robots trained by some other player, to see how well their training regimens prepared their robots for battle. Phased pruning An extension of Ken Stanley's NEAT, developed by Colin Green, adds periodic pruning of the network topologies of candidate solutions during the evolution process. This addition addressed concern that unbounded automated growth would generate unnecessary structure. HyperNEAT HyperNEAT is specialized to evolve large scale structures. It was originally based on the CPPN theory and is an active field of research. cgNEAT Content-Generating NEAT (cgNEAT) evolves custom video game content based on user preferences. The first video game to implement cgNEAT is Galactic Arms Race, a space-shooter game in which unique particle system weapons are evolved based on player usage statistics. Each particle system weapon in the game is controlled by an evolved CPPN, similarly to the evolution technique in the NEAT Particles interactive art program. odNEAT odNEAT is an online and decentralized version of NEAT designed for multi-robot systems. odNEAT is executed onboard robots themselves during task execution to continuously optimize the parameters and the topology of the artificial neural network-based controllers. In this way, robots executing odNEAT have the potential to adapt to changing conditions and learn new behaviors as they carry out their tasks. The online evolutionary process is implemented according to a physically distributed island model. Each robot optimizes an internal population of candidate solutions (intra-island variation), and two or more robots exchange candidate solutions when they meet (inter-island migration). In this way, each robot is potentially self-sufficient and the evolutionary process capitalizes on the exchange of controllers between multiple robots for faster synthesis of effective controllers. See also Evolutionary acquisition of neural topologies References Bibliography Implementations Stanley's original, mtNEAT on GitHub, and rtNEAT, for C++ ECJ, JNEAT, NEAT 4J, ANJI, for Java SharpNEAT, for C# MultiNEAT (MultiNEAT at the Wayback Machine (archived 2021-05-15)) and mtNEAT on GitHub, for C++ and Python neat-python neat-python neat-python on GitHub, for Python NeuralFit (inexact implementation) and neat-python, for Python Encog, for Java and C# peas on GitHub, for Python RubyNEAT, for Ruby NEAT-JavaScript on GitHub, neatjs on GitHub, Neataptic on GitHub (inexact implementation), for JavaScript [1], for Elixir EvolutionNet on GitHub, for C++ goNEAT on GitHub, for Go External links The NEAT Users Page at the Wayback Machine (archived 2023-12-05) Evolutionary Complexity Research Group at UCF at the Wayback Machine (archived 2024-06-18) – Ken Stanley's former research group NERO: Neuro-Evolving Robotic Operatives – an example application of rtNEAT GAR: Galactic Arms Race – an example application of cgNEAT Picbreeder at the Wayback Machine (archived 2011-07-25) – Online, collaborative art generated by CPPNs evolved with NEAT EndlessForms at the Wayback Machine (archived 2018-11-14) – A 3D version of Picbreeder, where you interactively evolve 3D objects that are encoded with CPPNs and evolved with NEAT BEACON Blog: Evolution 101: Neuroevolution at the Wayback Machine (archived 2024-12-24) MarI/O - Machine Learning for Video Games, a YouTube video demonstrating an implementation of NEAT learning to play Super Mario World Gekko Quant: Evolving Neural Networks through Augmenting Topologies at the Wayback Machine (archived 2022-02-10) – A visual tutorial series on NEAT, including so