 also often appear in people's everyday lives through applications and tools like ChatGPT or DALL-E. Government agencies like EU Parliament have identified regulation of general-purpose AI, such as foundation models, to be a high priority. General-purpose AI systems are often characterized by large size, opacity, and potential for emergence, all of which can create unintended harms. Such systems also heavily influence downstream applications, which further exacerbates the need for regulation. In regards to prominent legislation, a number of stakeholders have pushed for the EU AI Act to include restrictions on general-purpose AI systems, all of which would also apply to foundation models. World models In 2018, researchers David Ha and Jürgen Schmidhuber defined world models in the context of reinforcement learning: an agent with a variational autoencoder model V for representing visual observations, a recurrent neural network model M for representing memory, and a linear model C for making decisions. They suggested that agents trained on world models in environments that simulate reality could be applied to real world settings. In 2022, Yann LeCun saw a world model (defined by him as a neural network that acts as a mental model for aspects of the world that are seen as relevant) as part of a larger system of cognitive architecture – other neural networks that are analogous to different regions of the brain. In his view, this framework could lead to commonsense reasoning. Business Insider traced world models to a 1971 paper by Jay Wright Forrester. World models, alongside embodied AI, multi-agent models, and neuroscience models of the brain, are seen as alternatives to large language models for achieving general artificial intelligence. Quanta Magazine traced world models back further to a 1943 publication by Kenneth Craik on mental models and the blocks world of SHRDLU in the 1960s. World models are trained on a variety of data modalities, including text, images, audio and video, and have been applied to video generation. TechCrunch noted that world models could use more data than large language models and would require significantly more computational power (including the use of thousands of GPUs for training and inference). It also noted the risk of hallucinations, coverage bias and algorithmic bias. Similarly, The Financial Times noted the difficulty and expense in collecting data to simulate the world and training models to use that data. TechCrunch saw Sora as an example of a world model, while in January 2025, Nvidia released its own set of world models. The South China Morning Post wrote that Manycore Tech was another example of companies aiming to build a world model, viewing their work as an example of spatial intelligence. In May 2025, Mohamed bin Zayed University of Artificial Intelligence released a world model for building simulations to test AI agents. Google DeepMind has also released two world models in two-dimensional space and three-dimensional space, respectively, that were trained on video data, with Google claiming that the latter can be a training environment for AI agents. Meta released a world model in June 2025, Tencent released an open source world model in July 2025, and Niantic, Inc. developed a world model using anonymized data from Pokémon Go. Other companies that are planning as of 2025 to build world models include ByteDance and xAI. Fei-Fei Li views world models as applying to robotics and creative works. Due to the complexity of these models, she advocates for more complex strategies in data acquisition, data engineering, data processing, and synthesizing data. She co-founded a startup on building world models, which, as of 2024, planned to do so in three phases: incorporating an understanding of three-dimensional space along with time; support for augmented reality; and support for robotics. World models are intended for use in interactive media and environment simulation. Creative professiona