lar method called Bayesian quadrature. In numerical integration, function evaluations f ( x 1 ) , … , f ( x n ) {\displaystyle f(x_{1}),\ldots ,f(x_{n})} at a number of points x 1 , … , x n {\displaystyle x_{1},\ldots ,x_{n}} are used to estimate the integral ∫ f ( x ) ν ( d x ) {\displaystyle \textstyle \int f(x)\nu (dx)} of a function f {\displaystyle f} against some measure ν {\displaystyle \nu } . Bayesian quadrature consists of specifying a prior distribution over f {\displaystyle f} and conditioning this prior on f ( x 1 ) , … , f ( x n ) {\displaystyle f(x_{1}),\ldots ,f(x_{n})} to obtain a posterior distribution over f {\displaystyle f} , then computing the implied posterior distribution on ∫ f ( x ) ν ( d x ) {\displaystyle \textstyle \int f(x)\nu (dx)} . The most common choice of prior is a Gaussian process as this allows us to obtain a closed-form posterior distribution on the integral which is a univariate Gaussian distribution. Bayesian quadrature is particularly useful when the function f {\displaystyle f} is expensive to evaluate and the dimension of the data is small to moderate. Optimization Probabilistic numerics have also been studied for mathematical optimization, which consist of finding the minimum or maximum of some objective function f {\displaystyle f} given (possibly noisy or indirect) evaluations of that function at a set of points. Perhaps the most notable effort in this direction is Bayesian optimization, a general approach to optimization grounded in Bayesian inference. Bayesian optimization algorithms operate by maintaining a probabilistic belief about f {\displaystyle f} throughout the optimization procedure; this often takes the form of a Gaussian process prior conditioned on observations. This belief then guides the algorithm in obtaining observations that are likely to advance the optimization process. Bayesian optimization policies are usually realized by transforming the objective function posterior into an inexpensive, differentiable acquisition function that is maximized to select each successive observation location. One prominent approach is to model optimization via Bayesian sequential experimental design, seeking to obtain a sequence of observations yielding the most optimization progress as evaluated by an appropriate utility function. A welcome side effect from this approach is that uncertainty in the objective function, as measured by the underlying probabilistic belief, can guide an optimization policy in addressing the classic exploration vs. exploitation tradeoff. Local optimization Probabilistic numerical methods have been developed in the context of stochastic optimization for deep learning, in particular to address main issues such as learning rate tuning and line searches, batch-size selection, early stopping, pruning, and first- and second-order search directions. In this setting, the optimization objective is often an empirical risk of the form L ( θ ) = 1 N ∑ n = 1 N ℓ ( y n , f θ ( x n ) ) {\displaystyle \textstyle L(\theta )={\frac {1}{N}}\sum _{n=1}^{N}\ell (y_{n},f_{\theta }(x_{n}))} defined by a dataset D = { ( x n , y n ) } n = 1 N {\displaystyle \textstyle {\mathcal {D}}=\{(x_{n},y_{n})\}_{n=1}^{N}} , and a loss ℓ ( y , f θ ( x ) ) {\displaystyle \ell (y,f_{\theta }(x))} that quantifies how well a predictive model f θ ( x ) {\displaystyle f_{\theta }(x)} parameterized by θ {\displaystyle \theta } performs on predicting the target y {\displaystyle y} from its corresponding input x {\displaystyle x} . Epistemic uncertainty arises when the dataset size N {\displaystyle N} is large and cannot be processed at once meaning that local quantities (given some θ {\displaystyle \theta } ) such as the loss function L ( θ ) {\displaystyle L(\theta )} itself or its gradient ∇ L ( θ ) {\displaystyle \nabla L(\theta )} cannot be computed in reasonable time. Hence, generally mini-batching is used to construct estimators of these quantities on a random subset of the data. Probabilis