e GPU daughterboards, each with eight GPUs. These boards are connected by an NVSwitch system that allows for full bandwidth communication across all GPUs in the system, without additional latency between boards. A higher performance variant of the DGX-2, the DGX-2H, was offered as well. The DGX-2H replaced the DGX-2's dual Intel Xeon Platinum 8168's with upgraded dual Intel Xeon Platinum 8174's. This upgrade does not increase core count per system, as both CPUs are 24 cores, nor does it enable any new functions of the system, but it does increase the base frequency of the CPUs from 2.7 GHz to 3.1 GHz. Ampere DGX A100 Server Announced and released on May 14, 2020. The DGX A100 was the 3rd generation of DGX server, including 8 Ampere-based A100 accelerators. Also included is 15 TB of PCIe gen 4 NVMe storage, 1 TB of RAM, and eight Mellanox-powered 200 GB/s HDR InfiniBand ConnectX-6 NICs. The DGX A100 is in a much smaller enclosure than its predecessor, the DGX-2, taking up only 6 Rack units. The DGX A100 also moved to a 64 core AMD EPYC 7742 CPU, the first DGX server to not be built with an Intel Xeon CPU. The initial price for the DGX A100 Server was $199,000. DGX Station A100 As the successor to the original DGX Station, the DGX Station A100, aims to fill the same niche as the DGX station in being a quiet, efficient, turnkey cluster-in-a-box solution that can be purchased, leased, or rented by smaller companies or individuals who want to utilize machine learning. It follows many of the design choices of the original DGX station, such as the tower orientation, single socket CPU mainboard, a new refrigerant-based cooling system, and a reduced number of accelerators compared to the corresponding rackmount DGX A100 of the same generation. The price for the DGX Station A100 320G is $149,000 and $99,000 for the 160G model, Nvidia also offers Station rental at ~US$9000 per month through partners in the US (rentacomputer.com) and Europe (iRent IT Systems) to help reduce the costs of implementing these systems at a small scale. The DGX Station A100 comes with two different configurations of the built in A100. Four Ampere-based A100 accelerators, configured with 40 GB (HBM) or 80 GB (HBM2e) memory,thus giving a total of 160 GB or 320 GB resulting either in DGX Station A100 variants 160G or 320G. 2.5 PFLOPS FP16 Single 64 Core AMD EPYC 7742 512 GB DDR4 1 x 1.92 TB NVMe OS drive 1 x 7.68 TB U.2 NVMe Drive Dual port 10 Gb Ethernet Single port 1 Gb BMC port Hopper DGX H100 Server Announced March 22, 2022 and planned for release in Q3 2022, The DGX H100 is the 4th generation of DGX servers, built with 8 Hopper-based H100 accelerators, for a total of 32 PFLOPs of FP8 AI compute and 640 GB of HBM3 Memory, an upgrade over the DGX A100s 640GB HBM2 memory. This upgrade also increases VRAM bandwidth to 3 TB/s. The DGX H100 increases the rackmount size to 8U to accommodate the 700W TDP of each H100 SXM card. The DGX H100 also has two 1.92 TB SSDs for Operating System storage, and 30.72 TB of Solid state storage for application data. One more notable addition is the presence of two Nvidia Bluefield 3 DPUs, and the upgrade to 400 Gbit/s InfiniBand via Mellanox ConnectX-7 NICs, double the bandwidth of the DGX A100. The DGX H100 uses new 'Cedar Fever' cards, each with four ConnectX-7 400 GB/s controllers, and two cards per system. This gives the DGX H100 3.2 Tbit/s of fabric bandwidth across Infiniband. The DGX H100 has two Xeon Platinum 8480C Scalable CPUs (Codenamed Sapphire Rapids) and 2 Terabytes of System Memory. The DGX H100 was priced at Â£379,000 or ~US$482,000 at release. DGX GH200 Announced May 2023, the DGX GH200 connects 32 Nvidia Hopper Superchips into a singular superchip, that consists totally of 256 H100 GPUs, 32 Grace Neoverse V2 72-core CPUs, 32 OSFT single-port ConnectX-7 VPI of with 400 Gbit/s InfiniBand and 16 dual-port BlueField-3 VPI with 200 Gbit/s of Mellanox [1] [2] . Nvidia DGX GH200 is designed to handle terabyte-class models