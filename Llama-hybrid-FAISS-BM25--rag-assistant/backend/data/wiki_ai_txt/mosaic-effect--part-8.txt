 re-identifying individuals even when the data met HIPAA Safe Harbor requirements. They used a combination of published demographic data and environmental measurements, such as fluoranthene levels, to computationally separate study participants by community in a de-identified dataset. By matching the patterns found in external sources and the dataset, they successfully identified which records corresponded to residents of specific towns. Individual genetic markers that appear non-identifying in isolation may, when aggregated with other datasets, reveal sensitive personal information—raising concerns about genetic intimacy and the risks associated with storing such data in forensic or biomedical databases. Humanitarian aid Humanitarian and social protection data, when merged with existing information sources, can unintentionally expose sensitive insights through the mosaic effect, raising concerns about beneficiary safety and privacy. Attempts to anonymize humanitarian data may prove insufficient, as advances in re-identification techniques enable the reconstruction of sensitive identities by correlating seemingly anonymized datasets. Humanitarian data governance bodies have called for mitigation strategies that include both technical tools such as Privacy-enhancing technologies (PETs) and procedural steps like ecosystem mapping. An analysis of 400 humanitarian datasets found over 90% shared fields with at least one other dataset, illustrating widespread potential for mosaic-style re-identification. Edward Millett, writing for Security and Human Rights, provides the example of armed actors using publicly available but separately anonymized datasets—such as a humanitarian map of refugee camps and an NGO's activity updates—to triangulate the location of demobilized child soldiers. In this scenario, while the locations of camps are public, the presence of former child soldiers is deliberately obscured; however, another organization known for working with child soldiers is identified, through unrelated data sources, as operating at a specific camp. This enables adversaries to infer the presence of child soldiers at that location by combining the datasets. Technologies like differential privacy and federated learning are highlighted as methods to preserve data utility for humanitarian planning while reducing risks of identity disclosure. Humanitarian datasets often include telecommunications records, mobile money data, geospatial information, and social media activity, all of which can pose re-identification risks when aggregated. Despite no documented cases of mosaic-related harm in humanitarian operations, data withholding may also cause harm by delaying life-saving responses. Although documented cases of harm remain rare, the potential consequences of mosaic re-identification are considered sufficiently serious to justify proactive mitigation by policymakers and data controllers. Religious privacy In a real-world case study, mosaicking prayer schedules with transit data enabled the identification of individuals by inferring religious practices from non-identifying datasets. Even when datasets are scrubbed of direct identifiers, patterns revealed through mosaicking can highlight characteristics of protected or vulnerable groups, demonstrating the limits of traditional anonymization. Before 9/11, courts rarely invoked First or Fourth Amendment limits on religious‐minority surveillance, but the later rise of the "First Amendment criminal procedure" doctrine alongside the mosaic theory established that online communications carry enforceable privacy expectations and that their monitoring can chill religious expression. Under the mosaic concepts, privacy harms stem not from any single social media post but from aggregating a user's full digital presence over time, since combined data reveal more than isolated items do. Metadata such as timestamps, locations, and communication logs can become vectors of identification in humanitarian c