R , t ) {\displaystyle (l,R,t)} , at least N = 3 {\displaystyle N=3} non-collinear points in each point set are required. More recently, Briales and Gonzalez-Jimenez have developed a semidefinite relaxation using Lagrangian duality, for the case where the model set M {\displaystyle {\mathcal {M}}} contains different 3D primitives such as points, lines and planes (which is the case when the model M {\displaystyle {\mathcal {M}}} is a 3D mesh). Interestingly, the semidefinite relaxation is empirically tight, i.e., a certifiably globally optimal solution can be extracted from the solution of the semidefinite relaxation. Robust registration The least squares formulation (cb.2) is known to perform arbitrarily badly in the presence of outliers. An outlier correspondence is a pair of measurements s i ↔ m i {\displaystyle s_{i}\leftrightarrow m_{i}} that departs from the generative model (cb.1). In this case, one can consider a different generative model as follows:where if the i − {\displaystyle i-} th pair s i ↔ m i {\displaystyle s_{i}\leftrightarrow m_{i}} is an inlier, then it obeys the outlier-free model (cb.1), i.e., s i {\displaystyle s_{i}} is obtained from m i {\displaystyle m_{i}} by a spatial transformation plus some small noise; however, if the i − {\displaystyle i-} th pair s i ↔ m i {\displaystyle s_{i}\leftrightarrow m_{i}} is an outlier, then s i {\displaystyle s_{i}} can be any arbitrary vector o i {\displaystyle o_{i}} . Since one does not know which correspondences are outliers beforehand, robust registration under the generative model (cb.3) is of paramount importance for computer vision and robotics deployed in the real world, because current feature matching techniques tend to output highly corrupted correspondences where over 95 % {\displaystyle 95\%} of the correspondences can be outliers. Next, we describe several common paradigms for robust registration. Maximum consensus Maximum consensus seeks to find the largest set of correspondences that are consistent with the generative model (cb.1) for some choice of spatial transformation ( l , R , t ) {\displaystyle (l,R,t)} . Formally speaking, maximum consensus solves the following optimization:where | I | {\displaystyle \vert {\mathcal {I}}\vert } denotes the cardinality of the set I {\displaystyle {\mathcal {I}}} . The constraint in (cb.4) enforces that every pair of measurements in the inlier set I {\displaystyle {\mathcal {I}}} must have residuals smaller than a pre-defined threshold ξ {\displaystyle \xi } . Unfortunately, recent analyses have shown that globally solving problem (cb.4) is NP-Hard, and global algorithms typically have to resort to branch-and-bound (BnB) techniques that take exponential-time complexity in the worst case. Although solving consensus maximization exactly is hard, there exist efficient heuristics that perform quite well in practice. One of the most popular heuristics is the Random Sample Consensus (RANSAC) scheme. RANSAC is an iterative hypothesize-and-verify method. At each iteration, the method first randomly samples 3 out of the total number of N {\displaystyle N} correspondences and computes a hypothesis ( l , R , t ) {\displaystyle (l,R,t)} using Horn's method, then the method evaluates the constraints in (cb.4) to count how many correspondences actually agree with such a hypothesis (i.e., it computes the residual ‖ s i − l R m i − t ‖ 2 2 / σ i 2 {\displaystyle \Vert s_{i}-lRm_{i}-t\Vert _{2}^{2}/\sigma _{i}^{2}} and compares it with the threshold ξ {\displaystyle \xi } for each pair of measurements). The algorithm terminates either after it has found a consensus set that has enough correspondences, or after it has reached the total number of allowed iterations. RANSAC is highly efficient because the main computation of each iteration is carrying out the closed-form solution in Horn's method. However, RANSAC is non-deterministic and only works well in the low-outlier-ratio regime (e.g., below 50 % {\displaystyle 50\%} ), beca