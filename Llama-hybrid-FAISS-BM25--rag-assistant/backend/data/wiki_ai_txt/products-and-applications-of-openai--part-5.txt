el that can generate videos based on short descriptive prompts as well as extend existing videos forwards or backwards in time. It can generate videos with resolution up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown. Sora's development team named it after the Japanese word for "sky", to signify its "limitless creative potential". Sora's technology is an adaptation of the technology behind the DALLÂ·E 3 text-to-image model. OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose, but did not reveal the number or the exact sources of the videos. OpenAI demonstrated some Sora-created high-definition videos to the public on February 15, 2024, stating that it could generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model, and the model's capabilities. It acknowledged some of its shortcomings, including struggles simulating complex physics. Will Douglas Heaven of the MIT Technology Review called the demonstration videos "impressive", but noted that they must have been cherry-picked and might not represent Sora's typical output. Despite skepticism from some academic leaders following Sora's public demo, notable entertainment-industry figures have shown significant interest in the technology's potential. In an interview, actor/filmmaker Tyler Perry expressed his astonishment at the technology's ability to generate realistic video from text descriptions, citing its potential to revolutionize storytelling and content creation. He said that his excitement about Sora's possibilities was so strong that he had decided to pause plans for expanding his Atlanta-based movie studio. Sora 2 was unveiled on September 30, 2025, with an iOS app at the same time. Speech-to-text Whisper Released in 2022, Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification. Music generation MuseNet Released in 2019, MuseNet is a deep neural net trained to predict subsequent musical notes in MIDI music files. It can generate songs with 10 instruments in 15 styles. According to The Verge, a song generated by MuseNet tends to start reasonably but then fall into chaos the longer it plays. In pop culture, initial applications of this tool were used as early as 2020 for the internet psychological thriller Ben Drowned to create music for the titular character. Jukebox Released in 2020, Jukebox is an open-sourced algorithm to generate music with vocals. After training on 1.2 million samples, the system accepts a genre, an artist, and a snippet of lyrics and outputs song samples. OpenAI stated the songs "show local musical coherence [and] follow traditional chord patterns" but acknowledged that the songs lack "familiar larger musical structures such as choruses that repeat" and that "there is a significant gap" between Jukebox and human-generated music. The Verge stated "It's technologically impressive, even if the results sound like mushy versions of songs that might feel familiar", while Business Insider stated "surprisingly, some of the resulting songs are catchy and sound legitimate". User interfaces Debate Game In 2018, OpenAI launched the Debate Game, which teaches machines to debate toy problems in front of a human judge. The purpose is to research whether such an approach may assist in auditing AI decisions and in developing explainable AI. Microscope Released in 2020, Microscope is a collection of visualizations of every significant layer and neuron of eight neural network models which are often studied in interpretability. Microscope was created to analyze the features that form inside these neural networks easily. The models included are AlexNet, VGG-19, different versions of Inception, and different versions of CLIP Resnet. Chat