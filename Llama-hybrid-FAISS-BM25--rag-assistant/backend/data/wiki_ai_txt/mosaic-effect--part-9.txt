ontexts, even when message content is never accessed. Transaction records, when cross-referenced with publicly available geographic or temporal data, may inadvertently expose individual religious behaviors or affiliations. In refugee camps and similar high-density environments, the risk of mosaic re-identification increases because multiple datasets often contain overlapping personal details. Purchase histories can act as proxies for religious or cultural identity, especially when combined with other behavioral or locational data. When combined with breached service data, the mosaic effect enables the construction of virtual avatars of real individuals, integrating digital, genetic, and physical identity traits for use in fraud scenarios. Mosaicked datasets can facilitate profiling, enabling adversarial actors to infer political or ideological associations and potentially use that information to discriminate or cause harm. Data enrichment firms sell access to compiled databases containing personal information such as religious beliefs, education levels, and interests, enabling mosaic-based profiling by third parties. Most users expect only friends or limited audiences to see individual posts, not law enforcement dragnetting every message indefinitely—a practice where mosaicked data itself constitutes a distinct privacy injury. Reproductive rights After the repeal of Roe v Wade in the United States, medical and behavioral records—such as period-tracking data, private messages, and search queries—have become prosecutorial targets in post-Roe data investigations. The longstanding academic debate over digital privacy abruptly became a live political and legal crisis following the reversal of Roe, with consequences for millions. Anti-abortion activists are now expected to pursue legislation mandating longer data retention periods, intensifying conflicts with technology firms. Location data is only one piece of a vast mosaic of digital information now being targeted by abortion-ban enforcers seeking to reconstruct personal behavior. A comprehensive federal privacy statute could establish uniform rules for digital data governance as states pursue more aggressive data-based abortion prosecutions. United States government Federal agencies have adopted safeguards to prevent the "mosaic effect", whereby combining multiple publicly released datasets could inadvertently reveal personal identities. Law enforcement agencies combine data from various sources to infer individuals' locations and routines, even when direct identifiers are unavailable or have been deliberately obscured. The U.S. government first became aware of the mosaic effect's risks six months after the launch of Data.gov, when security agencies flagged concerns about compilation. As open-data initiatives expand, U.S. departments routinely vet releases to ensure that new datasets cannot be cross-linked with existing information to expose individuals. Seemingly innocuous datasets could be cross-referenced to track government vehicle movements or infer agency operations. Predicting whether any given data set contributes to a harmful mosaic effect remains an inexact science, with most agencies unaware of possible combinations. Analysts have shown how open-source photos from official state media enabled accurate modeling of Iranian centrifuge cascades, later found to match cyber sabotage payloads. The case is frequently cited in support of U.S. policies restricting mosaic-style data compilation across government disclosures. Most federal agencies maintain extensive internal datasets, much of which may be sensitive depending on agency scope and exposure. Advancements in data analytics and the proliferation of open datasets have prompted agencies to conduct ongoing risk assessments aimed at forestalling mosaic-driven disclosures. Government data release policies have struggled to anticipate all future misuse scenarios involving aggregated datasets. One approach to mitigating classi