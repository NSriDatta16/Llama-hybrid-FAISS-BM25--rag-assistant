tricity and Well-being: Prioritize human well-being in AI development and deployment. Human rights Alignment: Ensure that technology do not infringe internationally recognized human rights. Inclusivity: Make AI accessible to everyone. Progress: Choose high value initiatives. Responsibility, accountability, and transparency: Foster trust via responsibility, accountability, and fairness. Robustness and Security: Make AI systems safe, secure, and resistant to manipulation or data breach. Sustainability: Choose implementations that generate long-term, useful benefits. Enabling AI Support AI by developing associated knowledge and skills such as programming and statistics. Promoting AI literacy Several governments have recognized the need to promote AI literacy, including among adults. Such programs have been published in the United States, China, Germany and Finland. Programs intended for the general public usually consist of short and easy to understand online study units. Programs intended for children are usually project-based. Programs for students at colleges and universities often address the specific professional needs of the student, depending on their field of study. Beyond the education system, AI literacy can also be developed in the community, for example in museums. Schools Schools use diverse pedagogies to promote AI literacy. These include: Performing a Turing test with an intelligent agent Creating chatbots Building apps using Blockly-based programming Project-based learning Building robots Data visualization Training AI models Artificial intelligence curricula can improve students' understanding of topics such as machine learning, neural networks, and deep learning. Case study: DAILy The DAILy (Developing AI Literacy) program was developed by MIT and Boston University with the goal of increasing AI literacy among middle school students. The program is structured as a 30-hour workshop that includes the topics of introduction to artificial intelligence, logical systems (decision trees), supervised learning, neural networks, computational learning, deepfake, and natural language generators. Students examine the moral and social implications of each topic, as well as its occupational implications. Higher education Before the second decade of the 21st century, artificial intelligence was studied mainly in STEM courses. Later, projects emerged to increase artificial intelligence education, specifically to promote AI literacy. Most courses start with one or more study units that deal with basic questions such as what artificial intelligence is, where it comes from, what it can do and what it can't do. Most courses also refer to machine learning and deep learning. Some of the courses deal with moral issues in artificial intelligence. Disciplinary policy As a response to the increase of generative AI use in education, several disciplines formed committees or task forces to examine context-specific approaches toward AI literacy. In spring 2025, the Modern Language Association and Conference on College Composition and Communication Joint Task Force finished development of three working papers, a guide on AI literacy for students, and a collection of resources addressing AI use in writing. The task force emphasized the need for “a culture of critical AI literacy” and included guidelines not only for students but also educators and institutions, highlighting the need for modeling ethical AI use in planning processes. Similarly, a committee formed by the American Historical Association Council published “Guiding Principles for Artificial Intelligence in History Education” which encouraged “clear and transparent engagement with generative AI.” The guidelines demonstrate the value of criticality when working with generative AI in thinking and research. See also Artificial intelligence Digital literacy Ethics of artificial intelligence References External links Times Higher Education: How can we teach AI literacy skills?