to recognize black women or transgender people, Elwes set out to "Queer the Dataset" through an open-sourced generative adversarial network (GAN, a type of machine learning model and an early Generative artificial intelligence). Elwes added a dataset of 1,000 photos of drag kings and queens into the GAN's 70,000 faces collected in a standardised facial recognition dataset called Flickr-Faces-HQ Dataset (FFHQ). They then created new simulacra faces, known as deep fakes. "We queer that data so it shifts all of the weights in this neural network from a space of normativity into a space of queerness and otherness. Suddenly all of the faces start to break down and you see mascara dissolve into lipstick and blue eye shadow turn into a pink wig" said Elwes in a 2023 interview for Artnet. Zizi & Me (2020–2023) Zizi & Me is an ongoing multimedia collaboration between drag queen Me The Drag Queen and a deepfake A.I. clone of Me The Drag Queen. Using neural networks trained on filmed footage, the project creates a virtual body that can mimic reference movements. The first act, which features a digital lip-sync duet to Anything You Can Do (I Can Do Better), satirises the idea of A.I. being mistaken for a human, using drag performance and cabaret to critique societal narratives about A.I. and its role in shaping identity. The project is part of The Zizi Project by Jake Elwes, which explores the intersection of drag performance and A.I. The Zizi Show - A Deepfake Drag Cabaret (2020) The Zizi Show is a deep fake drag act based on artificial intelligence (AI). It has been presented live and as interactive online artwork. It is an exploration of queer culture and the algorithms philosophy and ethics of AI. The Zizi Show was exhibited as the inaugural exhibition in the digital gallery at the V&A’s Photography Center from 2023 to 2024. Zizi in Motion: A Deepfake Drag Utopia (Movement by Wet Mess) (2023) "Zizi in Motion" is a multichannel silent video installation featuring AI-generated deepfake performances, which are dynamically re-animated through the movements of London drag artist Wet Mess. The movements of Wet Mess cause the AI-generated visuals to glitch and distort, showcasing the interaction between drag performance and artificial intelligence. The work explore the potential for queer communities to ethically and creatively reclaim and repurpose deepfake technology, using it to celebrate queer bodies and identities. Art in the Cage of Digital Reproduction (2024) In an act of protest on 26 November 2024, Elwes facilitated indirect access to an early access token for OpenAI’s Sora text-to-video model through a Hugging Face frontend under the account "PR Puppets". The accompanying statement called to 'denormalize the exploitation of artists by major AI companies for training data, R&D, and publicity'. The incident attracted international press coverage calling into question the role of artists in shaping the future of generative AI versus merely serving as data and credibility providers for tech giants. Elwes also coordinated a collection of mini essays with responses and reflections from the signees and guest writers titled "Art in the Cage of Digital Reproduction". Installations exploring interpretation and feedback loops between neural networks Elwes has created works based on the interpretations and misinterpretations between different neural networks and training datasets including: A.I. Interprets A.I. Interpreting ‘Against Interpretation’ (Sontag 1966) from 2023, Closed Loop from 2017, and Auto-Encoded Buddha from 2016. A.I. Interprets A.I. Interpreting ‘Against Interpretation’ (Sontag 1966) (2023) A.I. Interprets A.I. Interpreting ‘Against Interpretation (Sontag 1966) is a three-channel video artwork where an AI interprets Susan Sontag’s essay into images, and then and another AI reinterprets those images back into language. The piece highlights how AI-generated art can misinterpret and introduce bias. Closed Loop (2017) Closed Loop