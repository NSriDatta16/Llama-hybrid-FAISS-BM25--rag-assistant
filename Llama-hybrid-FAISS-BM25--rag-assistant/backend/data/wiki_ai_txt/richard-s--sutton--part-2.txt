 to be applied to a wide array of problems. Sutton returned to Canada in the 2000s and continued working on the topic which continued to develop in academic circles until one of its first major real world applications saw Google's AlphaGo program built on this concept defeating the then prevailing human champion. Barto and Sutton have widely been credited and accepted as pioneers of modern reinforcement learning, with the technique itself being foundational to the modern AI boom. In a 2019 essay, Sutton proposed the "bitter lesson", which criticized the field of AI research for failing to learn that "building in how we think we think does not work in the long run", arguing that "70 years of AI research [had shown] that general methods that leverage computation are ultimately the most effective, and by a large margin", beating efforts building on human knowledge about specific fields like computer vision, speech recognition, chess or Go. Sutton argues that large language models aren’t capable of learning on-the-job, and so new model architectures are required to enable continual learning. Sutton further argues that a special training phase will be unnecessary — the agent will learn on-the-fly, rendering large language models obsolete. In 2023, Sutton and John Carmack announced a partnership for the development of artificial general intelligence (AGI). Awards and honors Sutton is a fellow of the Association for the Advancement of Artificial Intelligence (AAAI) since 2001; his nomination read: "For significant contributions to many topics in machine learning, including reinforcement learning, temporal difference techniques, and neural networks." In 2003, he received the President's Award from the International Neural Network Society and in 2013, the Outstanding Achievement in Research award from the University of Massachusetts Amherst. He received the 2024 Turing Award from the Association for Computing Machinery together with Andrew Barto; the citation of the award read: "For developing the conceptual and algorithmic foundations of reinforcement learning." In 2016, Sutton was elected Fellow of the Royal Society of Canada. In 2021, he was elected Fellow of the Royal Society of London. Research and publications Sutton introduced temporal-difference methods for prediction and control, establishing convergence properties and practical algorithms. He proposed integrated learning and planning through the Dyna architecture. He co-developed the options framework for temporal abstraction in reinforcement learning. He co-authored the first modern policy gradient formulation with function approximation. His essay The Bitter Lesson summarized a view that general methods that scale with computation dominate domain-specific approaches in the long run. Selected publications References External links Richard Sutton's Homepage Richard S. Sutton publications indexed by Google Scholar