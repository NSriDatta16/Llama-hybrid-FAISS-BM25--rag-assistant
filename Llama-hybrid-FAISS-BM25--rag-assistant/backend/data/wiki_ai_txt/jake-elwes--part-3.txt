 is a two-channel video where two neural networks engage in a continuous feedback loop, one generating images based on the text output and the other creating text based on the image output. The work explores how AI models misinterpret and evolve in a surreal, self-perpetuating conversation, without human input. Auto-Encoded Buddha (2016) Auto-Encoded Buddha is a mixed-media piece where an AI attempts to generate an image of a Buddha statue, trained on 5,000 Buddha images. The AI struggles to accurately represent the Buddha, highlighting the limitations of early generative neural networks. The work is a tribute to Nam June Paik’s TV Buddha (1974). CUSP (2019) In their video work CUSP (2019) Elwes places marsh birds generated using artificial intelligence into a tidal landscape. These digitally generated and constantly shifting birds are recorded in dialogue with native birds. The video work is also accompanied by a soundscape of artificially generated bird song. Latent Space (2017) Latent Space is one of the earliest examples of generative AI in art. The video artwork uses a neural network trained on 14.2 million images from the ImageNet database to explore "latent space," a mathematical representation where AI maps learned image categories, such as trees or birds, into specific regions. Once trained, the AI understands all images of trees as existing in one area and all images of birds in another. By reverse-engineering the network, it becomes possible to generate synthetic images from coordinates within this space. The video illustrates the AI’s process of creating novel images by not moving directly between recognizable categories, but by navigating the transitional spaces between them. The work highlights the network’s ability to generate unique and unexpected visual forms. The project draws on research from Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space (2016) and the ImageNet database (2009), with special acknowledgment to Anh Nguyen and the Evolving AI Lab for their contributions. == References ==