playstyle {\begin{aligned}{\color {Blue}\mathbb {E} {\Big [}{\big (}f(x)-\mathbb {E} {\big [}{\hat {f}}(x){\big ]}{\big )}^{2}{\Big ]}}&=\mathbb {E} {\big [}f(x)^{2}{\big ]}\,-\,2\ \mathbb {E} {\Big [}f(x)\ \mathbb {E} {\big [}{\hat {f}}(x){\big ]}{\Big ]}\,+\,\mathbb {E} {\Big [}\mathbb {E} {\big [}{\hat {f}}(x){\big ]}^{2}{\Big ]}\\&=f(x)^{2}\,-\,2\ f(x)\ \mathbb {E} {\big [}{\hat {f}}(x){\big ]}\,+\,\mathbb {E} {\big [}{\hat {f}}(x){\big ]}^{2}\\&={\Big (}f(x)-\mathbb {E} {\big [}{\hat {f}}(x){\big ]}{\Big )}^{2}\end{aligned}}} This last series of equalities comes from the fact that f ( x ) {\displaystyle f(x)} is not a random variable, but a fixed, deterministic function of x {\displaystyle x} . Therefore, E ⁡ [ f ( x ) ] = f ( x ) {\displaystyle \operatorname {\mathbb {E} } \left[f(x)\right]=f(x)} . Similarly E ⁡ [ f ( x ) 2 ] = f ( x ) 2 {\displaystyle \operatorname {\mathbb {E} } \left[f(x)^{2}\right]=f(x)^{2}} , and E ⁡ [ f ( x ) E ⁡ [ f ^ ( x ) ] ] = f ( x ) E ⁡ [ E ⁡ [ f ^ ( x ) ] ] = f ( x ) E ⁡ [ f ^ ( x ) ] {\displaystyle \operatorname {\mathbb {E} } \left[f(x)\,\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]\right]=f(x)\,\operatorname {\mathbb {E} } \left[\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]\right]=f(x)\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]} . Using the same reasoning, we can expand the second term and show that it is null: E ⁡ [ ( f ( x ) − E ⁡ [ f ^ ( x ) ] ) ( E ⁡ [ f ^ ( x ) ] − f ^ ( x ) ) ] = E ⁡ [ f ( x ) E ⁡ [ f ^ ( x ) ] − f ( x ) f ^ ( x ) − E ⁡ [ f ^ ( x ) ] 2 + E ⁡ [ f ^ ( x ) ] f ^ ( x ) ] = f ( x ) E ⁡ [ f ^ ( x ) ] − f ( x ) E ⁡ [ f ^ ( x ) ] − E ⁡ [ f ^ ( x ) ] 2 + E ⁡ [ f ^ ( x ) ] 2 = 0 {\displaystyle {\begin{aligned}&{\color {PineGreen}\operatorname {\mathbb {E} } \left[\left(f(x)-\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]\right)\left(\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]-{\hat {f}}\!(x)\right)\right]}\\&=\operatorname {\mathbb {E} } \left[f(x)\,\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]\,-\,f(x){\hat {f}}\!(x)\,-\,\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]^{2}+\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]\,{\hat {f}}\!(x)\right]\\&=f(x)\,\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]\,-\,f(x)\,\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]\,-\,\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]^{2}\,+\,\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]^{2}\\&=0\end{aligned}}} Eventually, we plug our derivations back into the original equation, and identify each term: MSE = ( f ( x ) − E ⁡ [ f ^ ( x ) ] ) 2 + E ⁡ [ ( E ⁡ [ f ^ ( x ) ] − f ^ ( x ) ) 2 ] + σ 2 = Bias ⁡ [ f ^ ( x ) ] 2 + Var ⁡ [ f ^ ( x ) ] + σ 2 {\displaystyle {\begin{aligned}{\text{MSE}}&=\left(f(x)-\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]\right)^{2}+\operatorname {\mathbb {E} } \left[\left(\operatorname {\mathbb {E} } [{\hat {f}}\!(x)]-{\hat {f}}\!(x)\right)^{2}\right]+\sigma ^{2}\\&=\operatorname {Bias} \left[{\hat {f}}\!(x)\right]^{2}+\,\operatorname {Var} \left[{\hat {f}}\!(x)\right]\,+\,\sigma ^{2}\end{aligned}}} Finally, the MSE loss function (or negative log-likelihood) is obtained by taking the expectation value over x ∼ P {\displaystyle x\sim P} : MSE = E x ⁡ { Bias D [ f ^ ( x ; D ) ] 2 + Var D ⁡ [ f ^ ( x ; D ) ] } + σ 2 . {\displaystyle {\text{MSE}}=\operatorname {\mathbb {E} } _{x}\left\{\operatorname {Bias} _{D}\!\left[{\hat {f}}\!(x;D)\right]^{2}+\operatorname {Var} _{D}\left[{\hat {f}}\!(x;D)\right]\right\}+\sigma ^{2}.} Approaches Dimensionality reduction and feature selection can decrease variance by simplifying models. Similarly, a larger training set tends to decrease variance. Adding features (predictors) tends to decrease bias, at the expense of introducing additional variance. Learning algorithms typically have some tunable parameters that control bias and variance; for example, linear and Generalized linear models can be regularized to decrease their variance at the cost of increasing their bias. In artificial neural networks, the variance increases and the bias decreas