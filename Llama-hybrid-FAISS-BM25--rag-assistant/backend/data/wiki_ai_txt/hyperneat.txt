Hypercube-based NEAT, or HyperNEAT, is a generative encoding that evolves artificial neural networks (ANNs) with the principles of the widely used NeuroEvolution of Augmented Topologies (NEAT) algorithm developed by Kenneth Stanley. It is a novel technique for evolving large-scale neural networks using the geometric regularities of the task domain. It uses Compositional Pattern Producing Networks (CPPNs), which are used to generate the images for Picbreeder.org Archived 2011-07-25 at the Wayback Machine and shapes for EndlessForms.com Archived 2018-11-14 at the Wayback Machine. HyperNEAT has recently been extended to also evolve plastic ANNs and to evolve the location of every neuron in the network. Applications to date Multi-agent learning Checkers board evaluation Controlling Legged Robotsvideo Comparing Generative vs. Direct Encodings Investigating the Evolution of Modular Neural Networks Evolving Objects that can be 3D-printed Evolving the Neural Geometry and Plasticity of an ANN References External links The HyperNEAT Users Page at the Wayback Machine (archived 2024-03-09) Ken Stanley's website at UCF at the Wayback Machine (archived 2024-02-05) Evolutionary Complexity Research Group at UCF at the Wayback Machine (archived 2024-06-18) The NEAT Users Page at the Wayback Machine (archived 2023-12-05) Picbreeder at the Wayback Machine (archived 2021-04-17) EndlessForms at the Wayback Machine (archived 2018-11-14) BEACON Blog: Evolution 101: Neuroevolution at the Wayback Machine (archived 2024-12-24)