 their national service". The video had more than 400,00 views. ii) A deepfake video showed PM Keir Starmer "swearing repeatedly at a staffer". Comments from the original poster included calling Starmer a "disgusting bully". The social media site showing the video refused to delete it despite requests. Entrepreneur Steve Endacott from the south of England created "AI Steve," an AI avatar as the face of his campaign for member of parliament. United States 2024 elections Officials from the ODNI and FBI have stated that Russia, Iran, and China used generative artificial intelligence tools to create fake and divisive text, photos, video, and audio content to foster anti-Americanism and engage in covert influence campaigns. The use of artificial intelligence was described as an accelerant rather than a revolutionary change to influence efforts. Regulation of AI with regard to elections was unlikely to see a resolution for most of the 2024 United States general election season. The campaign for the 2024 Republican nominee, Donald Trump, has used deepfake videos of political opponents in campaign ads and fake images showing Trump with black supporters. In 2023, while he was still running for re-election, the presidential campaign of Joe Biden prepared a task force to respond to AI images and videos. A Democratic consultant working for Dean Phillips also admitted to using AI to generate a robocall which used Joe Biden's voice to discourage voter participation. Generative AI increased the efficiency with which political candidates were able to raise money by analyzing donor data and identifying possible donors and target audiences. Regulation By governments Philippines The Commission on Elections (COMELEC) issued guidelines on the usage of AI, to be implemented starting from the 2025 Philippine general election including the parallel Bangsamoro Parliament election. It mandates candidate to disclose usage of AI in their campaign materials and prohibits the usage of the technology to spread misinformation against their rivals. This is the first time the COMELEC has release guidelines on campaigning through social media. United States US states have attempted regulation of AI use in elections and campaigns with varying degrees of success. The National Conference of State Legislatures has compiled a list of legislation regarding AI use by state as of 2024, some carrying both civil and criminal penalties. Oregon Senate Bill 1571 requires that campaign communications in Oregon disclose the use of AI. California has enacted legislation that makes using deepfakes to discredit political opponents illegal within sixty days of an election. Self-regulation by private firms Midjourney, an AI image-generator, has started blocking users from creating fake images of the 2024 US Presidential candidates. Research from the Center for Countering Digital Hate found that image generators such as Midjourney, ChatGPT Plus, DreamStudio, and Microsoft's Image Creator create images that constitute election disinformation in 41% of the test text prompts they tried. OpenAI implemented policies to counter election misinformation such as adding digital credentials to image origin and a classifier to detect if images were AI generated. AI use in election interference by foreign governments AI has begun to be used in election interference by foreign governments. Governments thought to be using AI to interfere in external elections include Russia, Iran and China. Russia was thought to be the most prolific nation targeting the 2024 presidential election with their influencing operations "spreading synthetic images, video, audio and text online", according to U.S intelligence officials. Iran has reportedly generated fake social media posts stories and targeted "across the political spectrum on polarizing issues during the presidential election". The Chinese government has used "broader influence operations" that aim to make a global image and "amplify divisive topics in 