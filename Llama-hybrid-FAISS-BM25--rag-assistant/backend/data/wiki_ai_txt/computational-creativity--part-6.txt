eas both from symbolic AI and genetic algorithms to realize some aspects of blending theory in a practical form; his example domains range from the linguistic to the visual, and the latter most notably includes the creation of mythical monsters by combining 3-D graphical models. Linguistic creativity Language provides continuous opportunity for creativity, evident in the generation of novel sentences, phrasings, puns, neologisms, rhymes, allusions, sarcasm, irony, similes, metaphors, analogies, witticisms, and jokes. Native speakers of morphologically rich languages frequently create new word-forms that are easily understood, and some have found their way to the dictionary. The area of natural language generation has been well studied, but these creative aspects of everyday language have yet to be incorporated with any robustness or scale. Hypothesis of creative patterns In the seminal work of applied linguist Ronald Carter, he hypothesized two main creativity types involving words and word patterns: pattern-reforming creativity, and pattern-forming creativity. Pattern-reforming creativity refers to creativity by the breaking of rules, reforming and reshaping patterns of language often through individual innovation, while pattern-forming creativity refers to creativity via conformity to language rules rather than breaking them, creating convergence, symmetry and greater mutuality between interlocutors through their interactions in the form of repetitions. Story generation Substantial work has been conducted in this area of linguistic creation since the 1970s, with the development of James Meehan's TALE-SPIN system. TALE-SPIN viewed stories as narrative descriptions of a problem-solving effort, and created stories by first establishing a goal for the story's characters so that their search for a solution could be tracked and recorded. The MINSTREL system represents a complex elaboration of this basic approach, distinguishing a range of character-level goals in the story from a range of author-level goals for the story. Systems like Bringsjord's BRUTUS elaborate these ideas further to create stories with complex interpersonal themes like betrayal. Nonetheless, MINSTREL explicitly models the creative process with a set of Transform Recall Adapt Methods (TRAMs) to create novel scenes from old. The MEXICA model of Rafael Pérez y Pérez and Mike Sharples is more explicitly interested in the creative process of storytelling, and implements a version of the engagement-reflection cognitive model of creative writing. Metaphor and simile Example of a metaphor: "She was an ape." Example of a simile: "Felt like a tiger-fur blanket." The computational study of these phenomena has mainly focused on interpretation as a knowledge-based process. Computationalists such as Yorick Wilks, James Martin, Dan Fass, John Barnden, and Mark Lee have developed knowledge-based approaches to the processing of metaphors, either at a linguistic level or a logical level. Tony Veale and Yanfen Hao have developed a system, called Sardonicus, that acquires a comprehensive database of explicit similes from the web; these similes are then tagged as bona-fide (e.g., "as hard as steel") or ironic (e.g., "as hairy as a bowling ball", "as pleasant as a root canal"); similes of either type can be retrieved on demand for any given adjective. They use these similes as the basis of an on-line metaphor generation system called Aristotle that can suggest lexical metaphors for a given descriptive goal (e.g., to describe a supermodel as skinny, the source terms "pencil", "whip", "whippet", "rope", "stick-insect" and "snake" are suggested). Analogy The process of analogical reasoning has been studied from both a mapping and a retrieval perspective, the latter being key to the generation of novel analogies. The dominant school of research, as advanced by Dedre Gentner, views analogy as a structure-preserving process; this view has been implemented in the structure mapping engine 