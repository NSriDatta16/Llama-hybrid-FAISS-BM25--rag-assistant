alytics and emotion recognition software; as well as with video content creators to help them measure the perceived effectiveness of their short and long form video creative. Many products also exist to aggregate information from emotions communicated online, including via "like" button presses and via counts of positive and negative phrases in text and affect recognition is increasingly used in some kinds of games and virtual reality, both for educational purposes and to give players more natural control over their social avatars. Subfields Emotion recognition is probably to gain the best outcome if applying multiple modalities by combining different objects, including text (conversation), audio, video, and physiology to detect emotions. Emotion recognition in text Text data is a favorable research object for emotion recognition when it is free and available everywhere in human life. Compare to other types of data, the storage of text data is lighter and easy to compress to the best performance due to the frequent repetition of words and characters in languages. Emotions can be extracted from two essential text forms: written texts and conversations (dialogues). For written texts, many scholars focus on working with sentence level to extract "words/phrases" representing emotions. Emotion recognition in audio Different from emotion recognition in text, vocal signals are used for the recognition to extract emotions from audio..Unlike images and videos, which are typically two-dimensional or three-dimensional data capturing spatial or spatio-temporal features, audio is inherently one-dimensional time-series data that represents variations in sound amplitude over time. This fundamental difference makes emotion recognition from audio unique. Instead of relying on visual cues or textual semantics, audio-based emotion detection focuses on prosodic and acoustic features such as pitch, intensity, speech rate, and voice quality. Emotion recognition in video Video data is a combination of audio data, image data and sometimes texts (in case of subtitles). Emotion recognition in conversation Emotion recognition in conversation (ERC) extracts opinions between participants from massive conversational data in social platforms, such as Facebook, Twitter, YouTube, and others. ERC can take input data like text, audio, video or a combination form to detect several emotions such as fear, lust, pain, and pleasure. See also Affective computing Face perception Facial recognition system Sentiment analysis Interpersonal accuracy == References ==