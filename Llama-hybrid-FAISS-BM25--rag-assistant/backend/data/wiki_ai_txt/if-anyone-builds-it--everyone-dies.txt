If Anyone Builds It, Everyone Dies: Why Superhuman AI Would Kill Us All (published with the alternate subtitle The Case Against Superintelligent AI in the UK) is a 2025 book by Eliezer Yudkowsky and Nate Soares which details potential threats posed to humanity by artificial superintelligence. It was listed in The New York Times best-seller list on October 5, 2025. Synopsis Modern AI systems are "grown" rather than "crafted": unlike traditional software that consists of code created by humans, modern AI systems are hundreds of billions to trillions of numbers that no one understands. These numbers can be found using enormous computing power, but humans do not truly understand how they work and cannot specify nor control their values. When an AI system threatens a New York Times reporter, or calls itself "MechaHitler", no one can look inside, find the line of code responsible for that behavior, and fix it. Humans can train AI systems to be generally competent. An AI that tries to achieve goals will perform better on many metrics, so it will be selected for by the training process. However, due to the nature of modern machine learning, it is not possible for humans to specify the goals that a superintelligent AI system should try to pursue. With current technology, the AI's goals would not contain anything of value to humans. Just as humans would lose a game of chess against Stockfish, they would lose against an AI system that is generally more competent than them. It is hard to predict the exact path, as that would mean being as good at achieving goals as the AI system, but there are some paths available to it. Superintelligence would not care about humans, but it would want the resources that humans need. Humanity would thus lose and go extinct. The book's authors contend that the world's leaders, the scientific community, and everyone else need to speak up and warn the world about the danger. To avoid a catastrophe, the authors believe that humanity needs to coordinate to halt large-scale general AI development everywhere, possibly with the exception for narrow AI systems like AlphaFold that would not threaten humanity's existence. At a minimum, as the first step, humanity should make a global halt into AI research, as they get more evidence of the danger. Reception Reviews by public figures and scientists Max Tegmark acclaimed it as "The most important book of the decade", writing that "the competition to build smarter-than-human machines isn't an arms race but a suicide race, fueled by wishful thinking." It also received praise from Stephen Fry, Ben Bernanke, Vitalik Buterin, Grimes, Yoshua Bengio, Scott Aaronson, Bruce Schneier, George Church, Tim Urban, Matthew Yglesias, Christopher Clark, Dorothy Sue Cobble, Huw Price, Fiona Hill, Steve Bannon, Emma Sky, Jon Wolfsthal, Joan Feigenbaum, Patton Oswalt, Mark Ruffalo, Alex Winter, Bart Selman, Liv Boeree, Zvi Mowshowitz, Jaan Tallinn, and Emmett Shear. Critical reception Reviews of the book by critics have been mixed. Upon its release, it was included in the New York Times best-seller lists for hardcover nonfiction and for combined print and e-books nonfiction. Writing for The New York Times, Stephen Marche compared the book to that of a Scientology manual and said reading it was like being trapped in a room with irritating college students on their first mushroom trip. The Guardian called it one of the biggest books of the autumn, stating that superintelligent AI is dangerous, but humanity can still take steps to avoid disaster. It became Book of the day on September 22, 2025. In a review, The Guardian's non-fiction books editor David Shariatmadari wrote that "If Anyone Builds It, Everyone Dies is as clear as its conclusions are hard to swallow" and that anyone who cares about the future has a responsibility to read the book's arguments. Tom Whipple, the Science editor at The Times, described the book as both compelling and disturbing, noting its readability and engaging sto