learning for computational creativity While traditional computational approaches to creativity rely on the explicit formulation of prescriptions by developers and a certain degree of randomness in computer programs, machine learning methods allow computer programs to learn on heuristics from input data enabling creative capacities within the computer programs. Especially, deep artificial neural networks allow to learn patterns from input data that allow for the non-linear generation of creative artefacts. Before 1989, artificial neural networks have been used to model certain aspects of creativity. Peter Todd (1989) first trained a neural network to reproduce musical melodies from a training set of musical pieces. Then he used a change algorithm to modify the network's input parameters. The network was able to randomly generate new music in a highly uncontrolled manner. In 1992, Todd extended this work, using the so-called distal teacher approach that had been developed by Paul Munro, Paul Werbos, D. Nguyen and Bernard Widrow, Michael I. Jordan and David Rumelhart. In the new approach, there are two neural networks, one of which is supplying training patterns to another. In later efforts by Todd, a composer would select a set of melodies that define the melody space, position them on a 2-d plane with a mouse-based graphic interface, and train a connectionist network to produce those melodies, and listen to the new "interpolated" melodies that the network generates corresponding to intermediate points in the 2-d plane. Language models and hallucination Language models like GPT and LSTM are used to generate texts for creative purposes, such as novels and scripts. These models demonstrate hallucination from time to time, where erroneous materials are presented as factual. Creators make use of their hallucinatory tendency to capture unintended results. Ross Goodwin's 1 the Road, for example, uses an LSTM model trained on literature corpora to generate a novel that refers to Jack Kerouac's On the Road based on multimodal input captured by a camera, a microphone, a laptop's inner clock, and a GPS throughout the road trip. Brian Merchant commented on the novel as "pixelated poetry in its ragtag assemblage of modern American imagery". Oscar Sharp and Ross Goodwin created the experimental sci-fi short film Sunspring in 2016, written with an LSTM model, trained on their scripts and 1980-1990 sci-fi movies. Rodica Gotca critiqued their overall lack of focus on the narrative and intention to create based on the background of human culture. Nevertheless, researchers highlight the positive side of language models' hallucination for generating novel solutions, given that the correctness and consistency of the response could be controlled. Jiang et al. propose the divergence-convergence flow model for harnessing the hallucinatory effects. They summarize the types of such effects in current research into factuality hallucinations and faithfulness hallucinations, which can be divided into smaller classes like factual fabrication and instruction inconsistency. While the divergence stage involves generating potentially hallucinatory content, the convergence stage focuses on filtering the hallucinations that are useful for the user with intent recognition and evaluation metrics. Key concepts from literature Some high-level and philosophical themes recur throughout the field of computational creativity, for example as follows. Important categories of creativity Margaret Boden refers to creativity that is novel merely to the agent that produces it as "P-creativity" (or "psychological creativity"), and refers to creativity that is recognized as novel by society at large as "H-creativity" (or "historical creativity"). Exploratory and transformational creativity Boden also distinguishes between the creativity that arises from an exploration within an established conceptual space, and the creativity that arises from a deliberate transformation or transc