e nature of fair use for training AI was a lawsuit that Thomson Reuters brought against Ross Intelligence first filed in 2020. Thomson Reuters argued that Ross Intelligence had used their Westlaw headnotes, brief summaries of court decisions, to train their AI engine designed to compete with Westlaw. While Thomson Reuters' claims were initially denied by judge Stephanos Bibas of the Third Circuit on the basis that headnotes may not have been copyrightable, Bibas reevaluated his decision in February 2025 and issued a ruling favoring Thomson Reuters, in that headnotes are copyrightable, and that Ross Intelligence, which had since closed down in 2021, had inappropriately used the material. In the case of Ross's AI, the engine was not generative, and produced output that was composed of pieces of Westlaw's material, which aided in Thomson Reuter's claims of reuse, so how the case may apply to other generative AI like OpenAI is not clear. In a consolidated case brought by several authors against Meta and OpenAI, federal district judge Vince Chhabria expressed doubt that the use of unlicensed copyrighted material for training AI would fall under fair use. He stated during court hearings to Meta's lawyers that "You have companies using copyright-protected material to create a product that is capable of producing an infinite number of competing products. You are dramatically changing, you might even say obliterating, the market for that person's work, and you're saying that you don't even have to pay a license to that person. I just don't understand how that can be fair use." Chhabria ruled a summary judgment in Meta's favor in June 2025, but based only on the lack of demonstration of sufficient harm of the output that Meta's LLM could produce, thus finding Meta's use of the authors' works fell within fair use. Chhabria emphasized his ruled did not mean that any use Meta made of copyrighted materials fell within fair use. In a similar case, several authors including Andrea Bartz, Charles Graeber, and Kirk Wallace Johnson, sued Anthropic in August 2024, for using their works to train their AI model. Some of these works had been part of the Pile, intended as a collection of open source and public domain works but at times had included copyrighted works but since removed. Anthropic affirmed it has used the Pile but also had legally bought books and subsequently digitized them for training. Judge William Alsup granted a summary judgment for Anthropic that affirmed that their use of purchased books for training was within fair use, but issues related to using the Pile with unlicensed works was not, and would face a separate trial related to damages. Anthropic offered to settle on the latter matter in August 2025, preparing to pay the authors $1.5 billion, roughly $3000 for the 500,000 authors affected, and would have been the largest payout related to copyright infringement in the United States; Alsup rejected the settlement over shortcomings in the settlement details that would be forced "down the throat of authors". The U.S. Copyright Office released a report that included review of public comment on matters of AI. Among other topics, the report addressed concerns about fair use of training materials, and considered that two of the fair use factors could be of concern. One factor was the purpose and character of the created work, where the Office directed to the Supreme Court decision in Andy Warhol Foundation for the Visual Arts, Inc. v. Goldsmith that even though transformation had been performed, the works were still ultimately considered derivative works of the original copyright. The other factor was the impact on the commercial market, with the Office suggesting that AI models trained on copyrighted data to produce works in a specific style could have negative market impacts that would weaken the fair use defense. EU In the EU, such text and data mining (TDM) exceptions form part of the 2019 Directive on Copyright in the Digital Si