fined over the basis matrix E t {\displaystyle \mathbf {E} ^{t}} . PCA can be again be used to learn the appearance space. History Facial recognition can be considered the field that originated the concepts that later on converged into the formalization of the morphable models. The eigenface approach used in face recognition represented faces in a vector space and used principal component analysis to identify the main modes of variation. However, this method had limitations: it was constrained to fixed poses and illumination and lacked an effective representation of shape differences. As a result, changes in the eigenvectors did not accurately represent shifts in facial structures but caused structures to fade in and out. To address these limitations, researchers added an eigendecomposition of 2D shape variations between faces. The original eigenface approach aligned images based on a single point, while new methods established correspondences on many points. Landmark-based face warping was introduced by Craw and Cameron (1991), and the first statistical shape model, Active Shape Model, was proposed by Cootes et al. (1995). This model used shape alone, but Active Appearance Model by Cootes et al. (1998) combined shape and appearance. Since these 2D methods were effective only for fixed poses and illumination, they were extended by Vetter and Poggio (1997) to handle more diverse settings. Even though separating shape and texture was effective for face representation, handling pose and illumination variations required many separate models. On the other hand, advances in 3D computer graphics showed that simulating pose and illumination variations was straightforward. The combination of graphics methods with face modeling led to the first formulation of 3DMMs by Blanz and Vetter (1999). The analysis-by-synthesis approach enabled the mapping of the 3D and 2D domains and a new representation of 3D shape and appearance. Their work is the first to introduce a statistical model for faces that enabled 3D reconstruction from 2D images and a parametric face space for controlled manipulation. In the original definition of Blanz and Vetter, the shape of a face is represented as the vector S = ( X 1 , Y 1 , Z 1 , . . . , X n , Y n , Z n ) T ∈ R 3 n {\displaystyle S=(X_{1},Y_{1},Z_{1},...,X_{n},Y_{n},Z_{n})^{T}\in \mathbb {R} ^{3n}} that contains the 3D coordinates of the n {\displaystyle n} vertices. Similarly, the texture is represented as a vector T = ( R 1 , G 1 , B 1 , . . . , R n , G n , B n ) T ∈ R 3 n {\displaystyle T=(R_{1},G_{1},B_{1},...,R_{n},G_{n},B_{n})^{T}\in \mathbb {R} ^{3n}} that contains the three RGB color channels associated with each corresponding vertex. Due to the full correspondence between exemplar 3D faces, new shapes S m o d e l s {\displaystyle \mathbf {S} _{models}} and textures T m o d e l s {\displaystyle \mathbf {T} _{models}} can be defined as a linear combination of the m {\textstyle m} example faces: S m o d e l = ∑ i = 1 m a i S i T m o d e l = ∑ i = 1 m b i T i with ∑ i = 1 m a i = ∑ i = 1 m b i = 1 {\displaystyle \mathbf {S} _{model}=\sum _{i=1}^{m}a_{i}\mathbf {S} _{i}\qquad \mathbf {T} _{model}=\sum _{i=1}^{m}b_{i}\mathbf {T} _{i}\qquad {\text{with}}\;\sum _{i=1}^{m}a_{i}=\sum _{i=1}^{m}b_{i}=1} Thus, a new face shape and texture is parametrized by the shape a = ( a 1 , a 2 , . . . , a m ) T {\displaystyle \mathbf {a} =(a_{1},a_{2},...,a_{m})^{T}} and texture coefficients b = ( b 1 , b 2 , . . . , b m ) T {\displaystyle \mathbf {b} =(b_{1},b_{2},...,b_{m})^{T}} . To extract the statistics from the dataset, they performed PCA to generate the shape space of dimension to d {\textstyle d} and used a linear model for shape and appearance modeling. In this case, a new model can be generated in the orthogonal basis using the shape and the texture eigenvector s i {\textstyle s_{i}} and t i {\textstyle t_{i}} , respectively: S m o d e l = S ¯ + ∑ i = 1 m a i s i T m o d e l = T ¯ + ∑ i = 1 m b i t i {\displayst