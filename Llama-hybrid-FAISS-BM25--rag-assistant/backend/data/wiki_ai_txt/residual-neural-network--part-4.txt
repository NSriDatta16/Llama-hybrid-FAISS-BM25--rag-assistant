ation method that randomly drops a subset of layers and lets the signal propagate through the identity skip connections. Also known as DropPath, this regularizes training for deep models, such as vision transformers. ResNeXt (2017) combines the Inception module with ResNet. Squeeze-and-Excitation Networks (2018) added squeeze-and-excitation (SE) modules to ResNet. An SE module is applied after a convolution, and takes a tensor of shape R H × W × C {\displaystyle \mathbb {R} ^{H\times W\times C}} (height, width, channels) as input. Each channel is averaged, resulting in a vector of shape R C {\displaystyle \mathbb {R} ^{C}} . This is then passed through a multilayer perceptron (with an architecture such as linear-ReLU-linear-sigmoid) before it is multiplied with the original tensor. It won the ILSVRC in 2017. == References ==