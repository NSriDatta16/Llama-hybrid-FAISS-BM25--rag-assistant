presents the Fourier transform of some periodic function κ ϕ {\displaystyle \kappa _{\phi }} . That is, FNO parameterizes the kernel integration directly in Fourier space, using a prescribed number of Fourier modes. When the grid at which the input function is presented is uniform, the Fourier transform can be approximated using the discrete Fourier transform (DFT) with frequencies below some specified threshold. The discrete Fourier transform can be computed using a fast Fourier transform (FFT) implementation. Training Training neural operators is similar to the training process for a traditional neural network. Neural operators are typically trained in some Lp norm or Sobolev norm. In particular, for a dataset { ( a i , u i ) } i = 1 N {\displaystyle \{(a_{i},u_{i})\}_{i=1}^{N}} of size N {\displaystyle N} , neural operators minimize (a discretization of) L U ( { ( a i , u i ) } i = 1 N ) := ∑ i = 1 N ‖ u i − G θ ( a i ) ‖ U 2 {\displaystyle {\mathcal {L}}_{\mathcal {U}}(\{(a_{i},u_{i})\}_{i=1}^{N}):=\sum _{i=1}^{N}\|u_{i}-{\mathcal {G}}_{\theta }(a_{i})\|_{\mathcal {U}}^{2}} , where ‖ ⋅ ‖ U {\displaystyle \|\cdot \|_{\mathcal {U}}} is a norm on the output function space U {\displaystyle {\mathcal {U}}} . Neural operators can be trained directly using backpropagation and gradient descent-based methods. Another training paradigm is associated with physics-informed machine learning. In particular, physics-informed neural networks (PINNs) use complete physics laws to fit neural networks to solutions of PDEs. Extensions of this paradigm to operator learning are broadly called physics-informed neural operators (PINO), where loss functions can include full physics equations or partial physical laws. As opposed to standard PINNs, the PINO paradigm incorporates a data loss (as defined above) in addition to the physics loss L P D E ( a , G θ ( a ) ) {\displaystyle {\mathcal {L}}_{PDE}(a,{\mathcal {G}}_{\theta }(a))} . The physics loss L P D E ( a , G θ ( a ) ) {\displaystyle {\mathcal {L}}_{PDE}(a,{\mathcal {G}}_{\theta }(a))} quantifies how much the predicted solution of G θ ( a ) {\displaystyle {\mathcal {G}}_{\theta }(a)} violates the PDEs equation for the input a {\displaystyle a} . See also Neural network Physics-informed neural networks Neural field References External links neuralop – Python library of various neural operator architectures