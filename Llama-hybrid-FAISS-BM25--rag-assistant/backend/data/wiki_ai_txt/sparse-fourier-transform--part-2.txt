i }{N}}n'\ell }} Repeating Finally, repeating these two stages can we extract the most important components from the original signal. x n − ∑ k ′ = 1 k X k ′ e j 2 π N k ′ n {\displaystyle x_{n}-\sum _{k'=1}^{k}X_{k}'e^{j{\frac {2\pi }{N}}k'n}} Sparse Fourier transform in the discrete setting In 2012, Hassanieh, Indyk, Katabi, and Price proposed an algorithm that takes O ( k log ⁡ n log ⁡ ( n / k ) ) {\displaystyle O(k\log n\log(n/k))} samples and runs in the same running time. Sparse Fourier transform in the high dimensional setting In 2014, Indyk and Kapralov proposed an algorithm that takes 2 O ( d log ⁡ d ) k log ⁡ n {\displaystyle 2^{O(d\log d)}k\log n} samples and runs in nearly linear time in n {\displaystyle n} . In 2016, Kapralov proposed an algorithm that uses sublinear samples 2 O ( d 2 ) k log ⁡ n log ⁡ log ⁡ n {\displaystyle 2^{O(d^{2})}k\log n\log \log n} and sublinear decoding time k log O ( d ) ⁡ n {\displaystyle k\log ^{O(d)}n} . In 2019, Nakos, Song, and Wang introduced a new algorithm which uses nearly optimal samples O ( k log ⁡ n log ⁡ k ) {\displaystyle O(k\log n\log k)} and requires nearly linear time decoding time. A dimension-incremental algorithm was proposed by Potts, Volkmer based on sampling along rank-1 lattices. Sparse Fourier transform in the continuous setting There are several works about generalizing the discrete setting into the continuous setting. Implementations There are several works based on MIT, MSU, ETH and University of Technology Chemnitz [TUC]. Also, they are free online. MSU implementations ETH implementations MIT implementations GitHub TUC implementations Further reading Hassanieh, Haitham (2018). The Sparse Fourier Transform: Theory and Practice. Association for Computing Machinery and Morgan & Claypool. ISBN 978-1-94748-707-9. == References ==