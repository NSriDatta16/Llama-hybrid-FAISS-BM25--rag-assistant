s new potential contributors. Lih alleges there is serious disagreement among existing contributors on how to resolve this. In 2015 Lih feared for Wikipedia's long-term future while Brown feared problems with Wikipedia would remain and rival encyclopedias would not replace it. Viewers and fundraisers As of 2015, with more viewing by smartphones, there had been a marked decline in persons who viewed Wikipedia from their computers, and according to The Washington Post "[people are] far less likely to donate". At the time, the Wikimedia Foundation reported reserves equivalent to one year's budgeted expenditures. On the other hand, the number of paid staff had ballooned, so those expenses increased. In 2021, Andreas Kolbe, a former co-editor-in-chief of The Signpost, wrote that the Wikimedia Foundation was reaching its 10-year goal of a US$100 million endowment, five years earlier than planned, which may surprise donors and users around the world who regularly see Wikipedia fundraising banners. He also said accounting methods disguise the size of operating surpluses, top managers earn $300,000 – 400,000 a year, and over 40 people work exclusively on fundraising. Artificial Intelligence Wikipedia faces a decline in human visitors, raising concerns about its long-term sustainability and community participation. The Wikimedia Foundation (WMF), when reporting this decline, attributed this in part to the lack of clicks from users of large language models and search engines that are using content from Wikipedia. Timeline of predictions On the eve of the 20th anniversary of Wikipedia, associate professor of the Department of Communication Studies at Northeastern University Joseph Reagle conducted a retrospective study of numerous "predictions of the ends of Wikipedia" over two decades, divided into chronological waves: "Early growth (2001–2002)", "Nascent identity (2001–2005)", "Production model (2005–2010)", "Contributor attrition (2009–2017)" and the current period "(2020–)". Each wave brought its distinctive fatal predictions, which never came true; as a result, Reagle concluded Wikipedia was not in danger. Concern grew in 2023 that the ubiquity and proliferation of artificial intelligence (AI) may adversely affect Wikipedia. Rapid improvements and widespread application of AI may render Wikipedia obsolete or reduce its importance. A 2023 study found that AI, when applied to Wikipedia, works most efficiently for error-correction, while Wikipedia still needs to be written by humans. See also Good Faith Collaboration: The Culture of Wikipedia Wikipedia Zero References Further reading Gertner, Jon. (2023) "Wikipedia's Moment of Truth: Can the online encyclopedia help teach A.I. chatbots to get their facts right — without destroying itself in the process?" New York Times Magazine (July 18, 2023) online Lih, Andrew (2009). The Wikipedia Revolution: How a Bunch of Nobodies Created the World's Greatest Encyclopedia. Hachette Books. ISBN 978-1401395858. Jemielniak, Dariusz (2014). Common Knowledge?: An Ethnography of Wikipedia. Stanford University Press. ISBN 978-0804791205. WP:THREATENING2MEN Peake, Bryce (2015). "WP:THREATENING2MEN: Misogynist Infopolitics and the Hegemony of the Asshole Consensus on English Wikipedia". Ada: A Journal of Gender, New Media, and Technology (7). doi:10.7264/N3TH8JZS (inactive 12 July 2025). Archived from the original on 12 February 2020. Retrieved 16 February 2020.{{cite journal}}: CS1 maint: DOI inactive as of July 2025 (link) Reagle, Joseph Michael; Lessig, Lawrence (2010). Good Faith Collaboration: The Culture of Wikipedia. The MIT Press. ISBN 978-0262288705. Reagle, Joseph (15 October 2020). "The Many (Reported) Deaths of Wikipedia". In Jackie, Koerner (ed.). Wikipedia @ 20. Cambridge, Massachusetts: The MIT Press. p. 9. ISBN 9780262538176. Retrieved 4 December 2021. Solorio, Thamar; Hasan, Ragib; Mizan, Mainul. A Case Study of Sockpuppet Detection in Wikipedia (PDF). The University of Alabama at Birmingha