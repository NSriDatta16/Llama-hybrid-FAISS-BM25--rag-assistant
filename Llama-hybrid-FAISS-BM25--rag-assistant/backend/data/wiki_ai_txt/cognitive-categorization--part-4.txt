biases categorization decisions towards exemplars most similar to the entity to be categorized. Conceptual clustering Conceptual clustering is a machine learning paradigm for unsupervised classification that was defined by Ryszard S. Michalski in 1980. It is a modern variation of the classical approach of categorization, and derives from attempts to explain how knowledge is represented. In this approach, classes (clusters or entities) are generated by first formulating their conceptual descriptions and then classifying the entities according to the descriptions. Conceptual clustering developed mainly during the 1980s, as a machine paradigm for unsupervised learning. It is distinguished from ordinary data clustering by generating a concept description for each generated category. Conceptual clustering is closely related to fuzzy set theory, in which objects may belong to one or more groups, in varying degrees of fitness. A cognitive approach accepts that natural categories are graded (they tend to be fuzzy at their boundaries) and inconsistent in the status of their constituent members. The idea of necessary and sufficient conditions is almost never met in categories of naturally occurring things. Category learning While an exhaustive discussion of category learning is beyond the scope of this article, a brief overview of category learning and its associated theories is useful in understanding formal models of categorization. If categorization research investigates how categories are maintained and used, the field of category learning seeks to understand how categories are acquired in the first place. To accomplish this, researchers often employ novel categories of arbitrary objects (e.g., dot matrices) to ensure that participants are entirely unfamiliar with the stimuli. Category learning researchers have generally focused on two distinct forms of category learning. Classification learning tasks participants with predicting category labels for a stimulus based on its provided features. Classification learning is centered around learning between-category information and the diagnostic features of categories. In contrast, inference learning tasks participants with inferring the presence/value of a category feature based on a provided category label and/or the presence of other category features. Inference learning is centered on learning within-category information and the category's prototypical features. Category learning tasks can generally be divided into two categories, supervised and unsupervised learning. Supervised learning tasks provide learners with category labels. Learners then use information extracted from labeled example categories to classify stimuli into the appropriate category, which may involve the abstraction of a rule or concept relating observed object features to category labels. Unsupervised learning tasks do not provide learners with category labels. Learners must therefore recognize inherent structures in a data set and group stimuli together by similarity into classes. Unsupervised learning is thus a process of generating a classification structure. Tasks used to study category learning take various forms: Rule-based tasks present categories that participants can learn through explicit reasoning processes. In these kinds of tasks, classification of stimuli is accomplished via the use of an acquired rule (i.e., if stimulus is large on dimension x, respond A). Information-integration tasks require learners to synthesize perceptual information from multiple stimulus dimensions prior to making categorization decisions. Unlike rule-based tasks, information-integration tasks do not afford rules that are easily articulable. Reading an X-ray and trying to determine if a tumor is present can be thought of as a real-world instantiation of an information-integration task. Prototype distortion tasks require learners to generate a prototype for a category. Candidate exemplars for the category are then produced by 