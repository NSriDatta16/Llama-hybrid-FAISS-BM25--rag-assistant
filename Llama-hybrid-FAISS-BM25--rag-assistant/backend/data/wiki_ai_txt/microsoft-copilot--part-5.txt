 generate content. According to Microsoft, Copilot can assist users with data analysis in Microsoft Excel spreadsheets by formatting data, creating graphs, generating pivot tables, identifying trends, and summarizing information, as well as guiding users using Excel commands and suggesting formulas to investigate user questions. The company also states that Copilot is able to create PowerPoint presentations that summarize information from user-selected Word documents and Excel spreadsheets, or from user prompts. Additionally, this tool can adjust text formatting, animation timing, and presentation style and length based on user prompts; Microsoft claims this will eliminate the need for users to make manual changes. In Microsoft Outlook, Copilot can draft emails with varying length and tone based on user input. To draft these emails, Copilot can pull relevant information from other emails. Copilot is also able to summarize content from email threads, including the viewpoints of involved individuals as well as questions posed that have yet to be answered. According to Microsoft, Copilot can be used in Microsoft Teams to present information for upcoming meetings, transcribe meetings, and provide debriefs if a user joins a meeting late. After a meeting, the company claims that Copilot can also summarize discussion points, list key actions deliberated in the meeting, and answer questions that were covered in the meeting. The company has publicly introduced Microsoft 365 Chat, a Copilot feature which pulls information from content across Microsoft 365 apps, enabling it to answer user questions and perform other tasks. Reception Tom Warren, a senior editor at The Verge, has noted the conceptual similarity of Copilot and other Microsoft assistant features like Cortana and Clippy. Warren also believes that large language models, as they develop further, could change how users work and collaborate. Rowan Curran, an analyst at Forrester, states that the integration of AI into productivity software may lead to improvements in user experience. Concerns over the speed of Microsoft's recent release of AI-powered products and investments have led to questions surrounding ethical responsibilities in the testing of such products. One ethical concern the public has vocalized is that GPT-4 and similar large language models may reinforce racial or gender bias. Individuals, including Tom Warren, have also voiced concerns for Copilot after witnessing the chatbot showcasing several instances of artificial hallucinations. In June 2024, Copilot was found to have repeated misinformation about the 2024 United States presidential debates. In response to these concerns, Jon Friedman, the Corporate Vice President of Design and Research at Microsoft, stated that Microsoft was "applying [the] learning" from experience with Bing to "mitigate [the] risks" of Copilot. Microsoft claimed that it was gathering a team of researchers and engineers to identify and alleviate any potential negative impacts. The stated aim was to achieve this through the refinement of training data, blocking queries about sensitive topics, and limiting harmful information. Microsoft stated that it intended to employ InterpretML and Fairlearn to detect and rectify data bias, provide links to its sources, and state any applicable constraints. See also ChatGPT – Generative AI chatbot by OpenAI GitHub Copilot – Artificial intelligence tool character.ai – AI chatbot service Tabnine – Coding assistant Tay (chatbot) – Chatbot developed by Microsoft Zo (bot) – Chatbot developed by Microsoft References External links Media related to Microsoft Copilot at Wikimedia Commons Official website Microsoft Copilot Terms of Use (Archive—2024-10-01 -- Wayback Machine, Archive Today, Megalodon, Ghostarchive) Past versions (Archive1, Archive2, Archive3, Archive4)