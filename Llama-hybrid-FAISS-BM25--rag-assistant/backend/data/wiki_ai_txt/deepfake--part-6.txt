de loyalty to blackmailers and limit their control over the blackmailed. This phenomenon has been termed "blackmail inflation", since in theory it "devalues" authentic blackmail material. It is possible to utilize commodity GPU hardware with a small software program to generate fake content intended to blackmail anyone for whom an adversary has ample training data. However, even carefully manipulated fakes may still be detected. The inflation argument could only work in theory if blackmailers have no other incriminating evidence that is not easily faked, and if the jury were persuaded that the evidences of guilt were not sufficient to convict beyond reasonable doubt. In reality this theory risks double hazards, namely, that those who are guilty might deploy arguments of plausible deniability, arguing that the footage has been faked, possibly resulting in acquittal of a guilty person on the basis of such doubt, and second, that fake evidence might be used to prosecute those who are not aware of the deepfake argument, to secure a conviction in cases where a jury is not adequately aware of the risk of false positives due to fake evidence, or to extort a plea deal where the prosecution claims to have damning evidence. The effect of this double hazard will depend on the level of discernment of the parties in the criminal justice system and their empowerment to act on that discernment. The inflation argument could be abused in either direction as illustrated, and the notion that blackmailers would not retain further evidence or leverage is unlikely and undependable, limiting the effectiveness of the theory. The existence of efficient techniques for fabricating false evidence certainly suggests that any combination of video, audio, photographic or other generable evidence alone as the basis for conviction of a crime is by now a perilous and tenuous standard owing to the possibility of maliciously fabricated evidence, raising the importance of multiple firsthand witnesses to a crime, especially for more serious allegations. Entertainment On 8 June 2022, Daniel Emmet, a former AGT contestant, teamed up with the AI startup Metaphysic AI, to create a hyperrealistic deepfake to make it appear as Simon Cowell. Cowell, notoriously known for severely critiquing contestants, was on stage interpreting "You're The Inspiration" by Chicago. Emmet sang on stage as an image of Simon Cowell emerged on the screen behind him in flawless synchronicity. On 30 August 2022, Metaphysic AI had 'deep-fake' Simon Cowell, Howie Mandel and Terry Crews singing opera on stage. On 13 September 2022, Metaphysic AI performed with a synthetic version of Elvis Presley for the finals of America's Got Talent. The MIT artificial intelligence project 15.ai has been used for content creation for multiple Internet fandoms, particularly on social media. In 2023 the bands ABBA and KISS partnered with Industrial Light & Magic and Pophouse Entertainment to develop deepfake avatars capable of performing virtual concerts. Fraud and scams Fraudsters and scammers make use of deepfakes to trick people into fake investment schemes, financial fraud, cryptocurrencies, sending money, and following endorsements. The likenesses of celebrities and politicians have been used for large-scale scams, as well as those of private individuals, which are used in spearphishing attacks. According to the Better Business Bureau, deepfake scams are becoming more prevalent. These scams are responsible for an estimated $12 billion in fraud losses globally. According to a recent report these numbers are expected to reach $40 Billion over the next three years. Fake endorsements have misused the identities of celebrities like Taylor Swift, Tom Hanks, Oprah Winfrey, and Elon Musk; news anchors like Gayle King and Sally Bundock; and politicians like Lee Hsien Loong and Jim Chalmers. Videos of them have appeared in online advertisements on YouTube, Facebook, and TikTok, who have policies against synthetic and 