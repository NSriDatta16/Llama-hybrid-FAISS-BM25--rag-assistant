Gerald J. "Gerry" Tesauro is an American computer scientist and a researcher at IBM, known for his development of TD-Gammon, a backgammon program that taught itself to play at a world-championship level through self-play and temporal difference learning, an early success in reinforcement learning and neural networks. He subsequently researched on autonomic computing, multi-agent systems for e-commerce, and contributed to the game strategy algorithms for IBM Watson. Career Education Tesauro earned a B.S. in physics from the University of Maryland, College Park. He then pursued graduate studies in plasma physics at Princeton University, supported by a Hertz Foundation Fellowship starting in 1980. He completed his Ph.D. in theoretical physics in 1986 under the supervision of Nobel laureate Philip W. Anderson. Backgammon After completing his Ph.D., he undertook postdoctoral research at the Center for Complex Systems Research, University of Illinois at Urbana-Champaign. During this period, he began applying neural networks to games, co-authoring a NeurIPS paper in 1987 with Terrence Sejnowski on a neural network that learned to play backgammon. By the late 1980s, Tesauro joined IBM's Thomas J. Watson Research Center (IBM Research) as a research scientist, where he would spend several decades, eventually rising to the position of Principal Research Staff Member in AI Science. During late 1980s, he developed Neurogammon, a backgammon program trained on expert human games using supervised learning. Neurogammon won the backgammon tournament at the 1st Computer Olympiad in 1989, demonstrating the potential of neural networks in game AI. He developed TD-Gammon during the 1990 to 1998 period, using reinforcement learning, specifically temporal-difference (TD) learning. TD-Gammon learned through self-play, using a neural network to evaluate board positions and improving its strategy over millions of games. The program achieved world-championship-level play, capable of challenging top human players. It is often regarded as an early success of neural networks, machine learning, and RL, and often cited as a precursor in publications on later game-playing systems, such as AlphaZero. During this period, Tesauro also contributed to computer chess research at IBM, exploring machine learning methods for training evaluation functions, although the main Deep Blue project was led by others. Specifically, some linear evaluation function weights were trained by discretized comparison training. The weights primarily evaluated king safety. Since 2010, he also contributed to computer Go by working on a program called Fuego. E-commerce In the late 1990s, Tesauro shifted his focus towards multi-agent systems and their application in e-commerce, such as autonomous "pricebots", which are software agents designed to learn optimal pricing and bidding strategies in electronic marketplaces. Methods included Q-learning for dynamic pricing strategies (e.g., cooperation or undercutting) in competitive environments. It was an early application of multi-agent reinforcement learning to economic modeling and automated trading. He also explored applying neural networks to computer virus detection. Autonomic computing From the early 2000s, Tesauro became a key contributor to IBM's autonomic computing initiative, which aimed to create self-managing IT systems. He applied reinforcement learning to automate tasks like resource allocation, performance tuning, and power management in data centers and distributed systems. Examples include multiple cooperating RL agents that learned to optimize server resources (CPU, memory, power) to meet performance goals or minimize energy consumption. Tesauro is listed as an inventor on numerous U.S. patents, largely focused on autonomic computing and AI applications for systems management, filed primarily between 2004 and 2007. These usually included methods for reward-based learning of system policies, utility-based dynamic resource alloca