\neq 1} : exit = 1 {\displaystyle {\text{exit}}=1} foreach ( α , β ) ∈ Λ 2 {\displaystyle (\alpha ,\beta )\in \Lambda ^{2}} : x ^ := arg ⁡ min y ∈ A B ( x ) f ( y ) {\displaystyle \mathbf {\hat {x}} :=\arg \min _{\mathbf {y} \in \mathrm {A} \mathrm {B} (\mathbf {x} )}f(\mathbf {y} )} if f ( x ^ ) < f ( x ) {\displaystyle f(\mathbf {\hat {x}} )<f(\mathbf {x} )} : x = x ^ {\displaystyle \mathbf {x} =\mathbf {\hat {x}} } exit := 0 {\displaystyle {\text{exit}}:=0} In both cases, the optimization problem in the innermost loop can be solved exactly and efficiently with a graph cut. Both algorithms terminate certainly in a finite number of iterations of the outer loop, and in practice such number is small, with most of the improvement happening at the first iteration. The algorithms can generate different solutions depending on the initial guess, but in practice they are robust with respect to initialisation, and starting with a point where all variables are assigned to the same random value is usually sufficient to produce good quality results. The solution generated by such algorithms is not necessarily a global optimum, but it has strong guarantees of optimality. If S ( x i , x j ) {\displaystyle S(x_{i},x_{j})} is a metric and x {\displaystyle \mathbf {x} } is a solution generated by the α {\displaystyle \alpha } -expansion algorithm, or if S ( x i , x j ) {\displaystyle S(x_{i},x_{j})} is a semimetric and x {\displaystyle \mathbf {x} } is a solution generated by the α β {\displaystyle \alpha \beta } -swap algorithm, then f ( x ) {\displaystyle f(\mathbf {x} )} lies within a known and constant factor from the global minimum f ( x ∗ ) {\displaystyle f(\mathbf {x} ^{*})} : f ( x ) ≤ 2 max α ≠ β ∈ Λ S ( α , β ) min α ≠ β ∈ Λ S ( α , β ) f ( x ∗ ) . {\displaystyle f(\mathbf {x} )\leq 2{\frac {\max _{\alpha \neq \beta \in \Lambda }S(\alpha ,\beta )}{\min _{\alpha \neq \beta \in \Lambda }S(\alpha ,\beta )}}f(\mathbf {x} ^{*}).} Non-submodular functions Generally speaking, the problem of optimizing a non-submodular pseudo-Boolean function is NP-hard and cannot be solved in polynomial time with a simple graph cut. The simplest approach is to approximate the function with a similar but submodular one, for instance truncating all non-submodular terms or replacing them with similar submodular expressions. Such approach is generally sub-optimal, and it produces acceptable results only if the number of non-submodular terms is relatively small. In case of quadratic non-submodular functions, it is possible to compute in polynomial time a partial solution using algorithms such as QPBO. Higher-order functions can be reduced in polynomial time to a quadratic form that can be optimised with QPBO. Higher-order functions Quadratic functions are extensively studied and were characterised in detail, but more general results were derived also for higher-order functions. While quadratic functions can indeed model many problems of practical interest, they are limited by the fact they can represent only binary interactions between variables. The possibility to capture higher-order interactions allows to better capture the nature of the problem and it can provide higher quality results that could be difficult to achieve with quadratic models. For instance in computer vision applications, where each variable represents a pixel or voxel of the image, higher-order interactions can be used to model texture information, that would be difficult to capture using only quadratic functions. Sufficient conditions analogous to submodularity were developed to characterise higher-order pseudo-Boolean functions that can be optimised in polynomial time, and there exists algorithms analogous to α {\displaystyle \alpha } -expansion and α β {\displaystyle \alpha \beta } -swap for some families of higher-order functions. The problem is NP-hard in the general case, and approximate methods were developed for fast optimization of functions that do not satisfy such conditions. Not