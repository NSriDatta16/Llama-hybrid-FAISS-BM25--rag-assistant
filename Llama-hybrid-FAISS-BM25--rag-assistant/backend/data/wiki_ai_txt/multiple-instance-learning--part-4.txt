hey call "generalized multiple instance learning" (GMIL). The GMIL assumption specifies a set of required instances Q ⊆ X {\displaystyle Q\subseteq {\mathcal {X}}} . A bag X {\displaystyle X} is labeled positive if it contains instances which are sufficiently close to at least r {\displaystyle r} of the required instances Q {\displaystyle Q} . Under only this condition, the GMIL assumption is equivalent to the presence-based assumption. However, Scott et al. describe a further generalization in which there is a set of attraction points Q ⊆ X {\displaystyle Q\subseteq {\mathcal {X}}} and a set of repulsion points Q ¯ ⊆ X {\displaystyle {\overline {Q}}\subseteq {\mathcal {X}}} . A bag is labeled positive if and only if it contains instances which are sufficiently close to at least r {\displaystyle r} of the attraction points and are sufficiently close to at most s {\displaystyle s} of the repulsion points. This condition is strictly more general than the presence-based, though it does not fall within the above hierarchy. Collective assumption In contrast to the previous assumptions where the bags were viewed as fixed, the collective assumption views a bag B {\displaystyle B} as a distribution p ( x | B ) {\displaystyle p(x|B)} over instances X {\displaystyle {\mathcal {X}}} , and similarly view labels as a distribution p ( y | x ) {\displaystyle p(y|x)} over instances. The goal of an algorithm operating under the collective assumption is then to model the distribution p ( y | B ) = ∫ X p ( y | x ) p ( x | B ) d x {\displaystyle p(y|B)=\int _{\mathcal {X}}p(y|x)p(x|B)dx} . Since p ( x | B ) {\displaystyle p(x|B)} is typically considered fixed but unknown, algorithms instead focus on computing the empirical version: p ^ ( y | B ) = 1 n B ∑ i = 1 n B p ( y | x i ) {\displaystyle {\widehat {p}}(y|B)={\frac {1}{n_{B}}}\sum _{i=1}^{n_{B}}p(y|x_{i})} , where n B {\displaystyle n_{B}} is the number of instances in bag B {\displaystyle B} . Since p ( y | x ) {\displaystyle p(y|x)} is also typically taken to be fixed but unknown, most collective-assumption based methods focus on learning this distribution, as in the single-instance version. While the collective assumption weights every instance with equal importance, Foulds extended the collective assumption to incorporate instance weights. The weighted collective assumption is then that p ^ ( y | B ) = 1 w B ∑ i = 1 n B w ( x i ) p ( y | x i ) {\displaystyle {\widehat {p}}(y|B)={\frac {1}{w_{B}}}\sum _{i=1}^{n_{B}}w(x_{i})p(y|x_{i})} , where w : X → R + {\displaystyle w:{\mathcal {X}}\rightarrow \mathbb {R} ^{+}} is a weight function over instances and w B = ∑ x ∈ B w ( x ) {\displaystyle w_{B}=\sum _{x\in B}w(x)} . Algorithms There are two major flavors of algorithms for Multiple Instance Learning: instance-based and metadata-based, or embedding-based algorithms. The term "instance-based" denotes that the algorithm attempts to find a set of representative instances based on an MI assumption and classify future bags from these representatives. By contrast, metadata-based algorithms make no assumptions about the relationship between instances and bag labels, and instead try to extract instance-independent information (or metadata) about the bags in order to learn the concept. For a survey of some of the modern MI algorithms see Foulds and Frank. Instance-based algorithms The earliest proposed MI algorithms were a set of "iterated-discrimination" algorithms developed by Dietterich et al., and Diverse Density developed by Maron and Lozano-Pérez. Both of these algorithms operated under the standard assumption. Iterated-discrimination Broadly, all of the iterated-discrimination algorithms consist of two phases. The first phase is to grow an axis parallel rectangle (APR) which contains at least one instance from each positive bag and no instances from any negative bags. This is done iteratively: starting from a random instance x 1 ∈ B 1 {\displaystyle x_{1}\in B_{1}} in a positive bag, the APR