b service) for hosting: Git-based code repositories, including discussions and pull requests for projects; models, also with Git-based version control; datasets, mainly in text, images, and audio; web applications ("spaces"), intended for web-based/hosted demos of machine learning applications. There are numerous pre-trained models that support common tasks in different modalities, such as: Natural Language Processing: text classification, named entity recognition, question answering, language modeling, summarization, translation, multiple choice, and text generation. Computer Vision: image classification, object detection, and segmentation. Audio: automatic speech recognition and audio classification. While in the past the Hub offered near-unlimited storage in both public and private repositories, they have since implemented storage quotas. For private storage, free users are limited to 100GB of data, while users with the Pro subscription ($9/month) can store up to 1TB of data. Public storage is limited to 5TB/10TB for Free and Pro users respectively. Other libraries In addition to Transformers and the Hugging Face Hub, the Hugging Face ecosystem contains libraries for other tasks, such as dataset processing ("Datasets"), model evaluation ("Evaluate"), image generation ("Diffusers"), and machine learning demos ("Gradio"). Safetensors The safetensors format was developed around 2021 to solve problems with the pickle format in Python. It was designed for saving and loading tensors. Compared to the pickle format, it allows lazy loading and avoids security problems. After a security audit, it became the default format in 2023. The file format: size of the header: 8 bytes, an unsigned little-endian 64-bit integer. header: JSON UTF-8 string, formatted as {"TENSOR_NAME": {“dtype”: “F16”, “shape”: [1, 16, 256], “data_offsets”: [BEGIN, END]}, "NEXT_TENSOR_NAME": {…}, …}. file: a byte buffer containing the tensors. See also OpenAI Station F Kaggle References External links Official website