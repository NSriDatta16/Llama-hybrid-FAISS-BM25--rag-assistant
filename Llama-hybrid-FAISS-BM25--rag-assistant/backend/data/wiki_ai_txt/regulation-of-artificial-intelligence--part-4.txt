ns, have called for a binding international agreement to protect human rights in the age of AI. A key element of such initiatives is identifying common ground between different regional approaches, such as those of the African Union and the Council of Europe. Regional and national regulation The regulatory and policy landscape for AI is an emerging issue in regional and national jurisdictions globally, for example in the European Union and Russia. Since early 2016, many national, regional and international authorities have begun adopting strategies, actions plans and policy papers on AI. These documents cover a wide range of topics such as regulation and governance, as well as industrial strategy, research, talent and infrastructure. Different countries have approached the problem in different ways. Regarding the three largest economies, it has been said that "the United States is following a market-driven approach, China is advancing a state-driven approach, and the EU is pursuing a rights-driven approach." African Union The African Union has increasingly been active in the field. Most importantly, the African Commission on Human and Peoples' Rights published a study on AI and human rights and advocated for an African Framework Convention on AI and Human Rights. This initiative builds on earlier debates within the AU, particularly discussions on autonomous lethal weapons, which African representatives had previously raised in international forums. A distinctive feature of the proposed African Framework is its strong emphasis on collective rights, as enshrined in the African Charter on Human and Peoples' Rights. This approach is situated within the broader debate on aligning AI governance with African values, including ethical traditions such as Ubuntu ("humanity to others"). Australia In October 2023, the Australian Computer Society, Business Council of Australia, Australian Chamber of Commerce and Industry, Ai Group (aka Australian Industry Group), Council of Small Business Organisations Australia, and Tech Council of Australia jointly published an open letter calling for a national approach to AI strategy. The letter backs the federal government establishing a whole-of-government AI taskforce. Additionally, in August 2024, the Australian government set a Voluntary AI Safety Standard, which was followed by a Proposals Paper later in September of that year, outlining potential guardrails for high-risk AI that could become mandatory. These guardrails include areas such as model testing, transparency, human oversight, and record-keeping, all of which may be enforced through new legislation. As noted, however, Australia has not yet passed AI-specific laws, but existing statutes such as the Privacy Act 1988, Corporations Act 2001, and Online Safety Act 2021 all have applications which apply to AI use. In September 2024, a bill also was introduced which granted the Australian Communications and Media Authority powers to regulate AI-generated misinformation. Several agencies, including the ACMA, ACCC, and Office of the Australian Information Commissioner, are all expected to play roles in future AI regulation. Brazil On September 30, 2021, the Brazilian Chamber of Deputies (Câmara dos Deputados) approved the Brazilian Legal Framework for Artificial Intelligence (Marco Legal da Inteligência Artificial). This legislation aimed to regulate AI development and usage while promoting research and innovation in ethical AI solutions that prioritize culture, justice, fairness, and accountability. The 10-article bill established several key objectives: developing ethical principles for AI, promoting sustained research investment, and removing barriers to innovation. Article 4 specifically emphasized preventing discriminatory AI solutions, ensuring plurality, and protecting human rights. When the bill was first released to the public, it faced substantial criticism, alarming the government for critical provisions. The underlying issue is that 