in force, the more likely it is, that people will run into problems with it, that were not foreseen when the law was made. So, the further implications of one rule may conflict with another rule. "Common sense" might not be able to resolve things. In that scenario, too much precision can get in the way of justice. Very likely a special court ruling wil have to set a norm. The general problem for jurists is, whether "the arbitrariness resulting from precision is worse than the arbitrariness resulting from the application of a vague standard". David Lanius has examined nine arguments for the "value of vagueness" in different contexts. Mathematical ontology The definitional disputes about fuzziness remain unresolved so far, mainly because, as anthropologists and psychologists have documented, different languages (or symbol systems) that have been created by people to signal meanings suggest different ontologies. Put simply: it is not merely that describing "what is there" involves symbolic representations of some kind. How distinctions are drawn, influences perceptions of "what is there", and vice versa, perceptions of "what is there" influence how distinctions are drawn. This is an important reason why, as Alfred Korzybski noted, people frequently confuse the symbolic representation of reality, conveyed by languages and signs, with reality itself. For example, watching the TV news, the human brain spontaneously assumes that the TV images being shown are the same as what the TV viewers would see themselves, if they had been physically on the same scene at the same moment â€“ even although the viewers don't have access to everything that exists or happens external to the image frame shown. In this way, the TV image shapes the meaning of what there is, and it does so for most viewers at the same time. A common saying is "seeing is believing", but "believing is seeing" could also be a reality to a certain extent. Fuzziness implies, that there exists a potentially infinite number of truth values between complete truth and complete falsehood (the endpoints of a scale). If that is the case, it creates the foundational issue of what, in the case, can justify or prove the existence of the categorical absolutes which are assumed by logical or quantitative inference. If there is an infinite number of shades of grey, how do we know what is totally black and white, and how could we identify that? Tegmark's mathematical universe To illustrate the ontological issues, cosmologist Max Tegmark argues boldly that the universe consists of math: "If you accept the idea that both space itself, and all the stuff in space, have no properties at all except mathematical properties," then the idea that everything is mathematical "starts to sound a little bit less insane." Tegmark moves from the epistemic claim that mathematics is the only known symbol system which can in principle express absolutely everything, to the methodological claim that everything is reducible to mathematical relationships, and then to the ontological claim, that ultimately everything that exists is mathematical (the mathematical universe hypothesis). The argument is then reversed, so that because everything is mathematical in reality, mathematics is necessarily the ultimate universal symbol system. The main criticisms of Tegmark's approach are that (1) the steps in this argument do not necessarily follow, (2) no conclusive proof or test is possible for the claim that a total reduction of everything to mathematics is feasible, among other things because qualitative categories remain indispensable to understand and navigate what quantities mean, and (3) it may be that a complete reduction to mathematics cannot be accomplished, without at least partly altering, negating or deleting a non-mathematical significance of phenomena, experienced perhaps as qualia. An additional complication is that mathematical theory is not something fixed and final, like a pancake, anymore than language is 