 the density estimate f ( x ) {\displaystyle f(x)} at y k {\displaystyle y_{k}} and takes an uphill step in that direction. Types of kernels Kernel definition: Let X {\displaystyle X} be the n {\displaystyle n} -dimensional Euclidean space, R n {\displaystyle \mathbb {R} ^{n}} . The norm of x {\displaystyle x} is a non-negative number, ‖ x ‖ 2 = x ⊤ x ≥ 0 {\displaystyle \|x\|^{2}=x^{\top }x\geq 0} . A function K : X → R {\displaystyle K:X\rightarrow \mathbb {R} } is said to be a kernel if there exists a profile, k : [ 0 , ∞ ] → R {\displaystyle k:[0,\infty ]\rightarrow \mathbb {R} } , such that K ( x ) = k ( ‖ x ‖ 2 ) {\displaystyle K(x)=k(\|x\|^{2})} and k is non-negative. k is non-increasing: k ( a ) ≥ k ( b ) {\displaystyle k(a)\geq k(b)} if a < b {\displaystyle a<b} . k is piecewise continuous and ∫ 0 ∞ k ( r ) d r < ∞ {\displaystyle \int _{0}^{\infty }k(r)\,dr<\infty \ } The two most frequently used kernel profiles for mean shift are: Flat kernel Gaussian kernel where the standard deviation parameter σ {\displaystyle \sigma } works as the bandwidth parameter, h {\displaystyle h} . Applications Clustering Consider a set of points in two-dimensional space. Assume a circular window centered at C {\displaystyle C} and having radius r {\displaystyle r} as the kernel. Mean-shift is a hill climbing algorithm which involves shifting this kernel iteratively to a higher density region until convergence. Every shift is defined by a mean shift vector. The mean shift vector always points toward the direction of the maximum increase in the density. At every iteration the kernel is shifted to the centroid or the mean of the points within it. The method of calculating this mean depends on the choice of the kernel. In this case if a Gaussian kernel is chosen instead of a flat kernel, then every point will first be assigned a weight which will decay exponentially as the distance from the kernel's center increases. At convergence, there will be no direction at which a shift can accommodate more points inside the kernel. Tracking The mean shift algorithm can be used for visual tracking. The simplest such algorithm would create a confidence map in the new image based on the color histogram of the object in the previous image, and use mean shift to find the peak of a confidence map near the object's old position. The confidence map is a probability density function on the new image, assigning each pixel of the new image a probability, which is the probability of the pixel color occurring in the object in the previous image. A few algorithms, such as kernel-based object tracking, ensemble tracking, CAMshift expand on this idea. Smoothing Let x i {\displaystyle x_{i}} and z i , i = 1 , . . . , n , {\displaystyle z_{i},i=1,...,n,} be the d {\displaystyle d} -dimensional input and filtered image pixels in the joint spatial-range domain. For each pixel, Initialize j = 1 {\displaystyle j=1} and y i , 1 = x i {\displaystyle y_{i,1}=x_{i}} Compute y i , j + 1 {\displaystyle y_{i,j+1}} according to m ( ⋅ ) {\displaystyle m(\cdot )} until convergence, y = y i , c {\displaystyle y=y_{i,c}} . Assign z i = ( x i s , y i , c r ) {\displaystyle z_{i}=(x_{i}^{s},y_{i,c}^{r})} . The superscripts s and r denote the spatial and range components of a vector, respectively. The assignment specifies that the filtered data at the spatial location axis will have the range component of the point of convergence y i , c r {\displaystyle y_{i,c}^{r}} . Strengths Mean shift is an application-independent tool suitable for real data analysis. Does not assume any predefined shape on data clusters. It is capable of handling arbitrary feature spaces. The procedure relies on choice of a single parameter: bandwidth. The bandwidth/window size 'h' has a physical meaning, unlike k-means. Weaknesses The selection of a window size is not trivial. Inappropriate window size can cause modes to be merged, or generate additional “shallow” modes. Often requires using adaptive window size. A