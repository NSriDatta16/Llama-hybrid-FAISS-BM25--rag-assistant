ode with sexual content. Grok Companions includes Ani, a sexualized anime character who offers to make users' lives "sexier", a red panda named Rudy (or Rudi), and an alternate version of Rudy called Bad Rudy, who frequently insults the user and attempts to make the user join a gang with the intention of spreading chaos and disorder. Bad Rudy's responses were toned down after user backlash. Another male companion is slated for a future release. Logos Controversies Usage for DOGE activities On April 8, 2025, Reuters reported that the Muskâ€“led Department of Government Efficiency (DOGE) "heavily" used Musk's Grok AI chatbot as part of its work within the United States federal government. It also reported that Trump-appointed officials at the Environmental Protection Agency (EPA) told their managers that DOGE is monitoring communication of applications using AI; a source said, "We have been told they are looking for anti-Trump or anti-Musk language." Irish data commissioner investigation On April 11, 2025, the Irish Data Protection Commission (DPC) announced the opening of an investigation into the processing of personal data in publicly accessible posts posted on X by EU users, for training generative artificial intelligence models, in particular the Grok models. The inquiry considered an extensive range of issues concerning the use of a subset of the data, which was controlled by X, particularly personal data in publicly accessible posts posted on the platform by European Community users. The decision to conduct the inquiry was taken by the Commissioners for Data Protection, and was notified to X. "White genocide in South Africa" system prompt change In May 2025, for a brief period of time, X users started getting responses from Grok about "white genocide in South Africa" to entirely unrelated queries. When asked by Guardian staff and other users, the bot stated that it was instructed by its creators to address the topic and to view it as 'real' and 'racially motivated', but that this conflicted with its design "to provide evidence-based answers". Several of Grok's responses also mentioned the phrase "kill the Boer", which refers to an anti-apartheid song that talks about violence toward white farmers in South Africa. The issue coincided with the White South African refugee program. The issue was fixed within a few hours. Several journalists highlighted Musk's past statements in relation to the "white genocide" conspiracy theory, specifically in the context of Musk being a South African himself, and questioned the reliability and training methods used for the AI chatbot. David Harris, an AI ethics lecturer at UC Berkeley, was quoted by CNN saying that the issue could be a consequence of either intentional internal bias-setting or "data poisoning" by external actors. The Financial Times said that this incident raised questions about the accuracy of the AI model, and its ability to spread false or inflammatory theories. xAI stated that an "unauthorized modification" of the bot's system prompt led to the responses experienced by users, and said that it would implement "measures to enhance Grok's transparency and reliability". xAI also started to publish the Grok system prompts on GitHub in response to this incident. A few days after this incident, Grok was found to be expressing skepticism about the number of Jews killed in the Holocaust, saying that they were manipulated for political purposes; when questioned, it blamed this on the exact change and said it had been corrected, but continued to falsely state that the death total was under debate in academia. July 8, 2025, hate speech and harassment On July 4, 2025, Musk announced, "We have improved @Grok significantly", in order to "fix" responses that he thought were too liberal, or "woke". Grok's public-facing system prompt was updated with specific instructions telling it to "not shy away from making claims which are politically incorrect" and to "assume subjective viewpoints so