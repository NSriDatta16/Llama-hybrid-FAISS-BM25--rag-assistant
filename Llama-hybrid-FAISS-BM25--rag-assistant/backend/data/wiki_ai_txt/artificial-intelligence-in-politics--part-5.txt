ies to develop reliable mechanisms, and the EU's AI Act imposes obligations for transparency, detection, and tracing of AI-generated material. Other interventions like legislation targeting election-specific deepfakes, technological solutions, and voter education initiatives will need to be discussed in the future. Lawmakers across states have introduced legislation to combat election-related AI-generated disinformation, often requiring disclosure of AI use for election-related content within specific time frames before elections However, the introduction of these bills does not guarantee they will become law, and their enforceability could be challenged on free speech grounds. Penalties might only occur after the fact or be evaded by foreign entities. Some social media companies have attempted to limit the spread of false content. Their primary response is often to label content as ‘AI-generated’. This puts the onus on users to recognize labels that are not yet fully rolled out, and AI content may evade detection. Labeling policies often do not specify whether a piece of content is harmful, only that it is AI-generated. Other strategies involve developing and enforcing responsible platform design and moderation, legal mandates, and calling for journalists and the public to hold the platforms accountable. There is not yet a uniform and binding regulatory framework governing AI. The European Commission has proposed an AI Regulation setting out how AI systems can be introduced and used in the EU, designating AI systems for democratic processes as high-risk and proposing mandatory requirements. == References ==