 formula in the multidimensional case: P ( X t ) = ∑ i = 1 K ω i , t η ( X t , μ i , t , σ i , t ) {\displaystyle P(X_{t})=\sum _{i=1}^{K}\omega _{i,t}\eta \left(X_{t},\,\mu _{i,t},\sigma _{i,t}\right)} Where K is the number of distributions, ω is a weight associated to the ith Gaussian at time t and μ, Σ are the mean and standard deviation of said Gaussian respectively. η ( X t , μ i , t , σ i , t ) = 1 ( 2 π ) D / 2 1 | σ i , t | 1 / 2 exp ⁡ ( − 1 2 ( X t − μ i , t ) T σ i , t − 1 ( X t − μ i , t ) ) {\displaystyle \eta \left(X_{t},\,\mu _{i,t},\sigma _{i,t}\right)={\dfrac {1}{(2\pi )^{D/2}}}{1 \over |\sigma _{i,t}|^{1/2}}\exp \left(-{1 \over 2}(X_{t}-\mu _{i,t})^{T}\sigma _{i,t}^{-1}\left(X_{t}-\mu _{i,t}\right)\right)} Once the parameters initialization is made, a first foreground detection can be made then the parameters are updated. The first B Gaussian distribution which exceeds the threshold T is retained for a background distribution: B = argmin ⁡ ( Σ i = 1 B ω i , t > T ) {\displaystyle B=\operatorname {argmin} \left(\Sigma _{i=1}^{B}\omega _{i,t}>T\right)} The other distributions are considered to represent a foreground distribution. Then, when the new frame incomes at times t + 1 {\displaystyle t+1} , a match test is made of each pixel. A pixel matches a Gaussian distribution if the Mahalanobis distance: ( ( X t + 1 − μ i , t ) T σ i , t − 1 ( X t + 1 − μ i , t ) ) 0.5 < k ⋅ σ i , t {\displaystyle \left(\left(X_{t+1}-\mu _{i,t}\right)^{T}\sigma _{i,t}^{-1}\left(X_{t+1}-\mu _{i,t}\right)\right)^{0.5}<k\cdot \sigma _{i,t}} where k is a constant threshold equal to 2.5 {\displaystyle 2.5} . Then, two cases can occur: Case 1: A match is found with one of the k Gaussians. For the matched component, the update is done as follows: σ i , t + 1 2 = ( 1 − ρ ) σ i , t 2 + ρ ( X x + 1 − μ x + 1 ) ( X x + 1 − μ x + 1 ) T {\displaystyle \sigma _{i,t+1}^{2}=\left(1-\rho \right)\sigma _{i,t}^{2}+\rho \left(X_{x+1}-\mu _{x+1}\right)\left(X_{x+1}-\mu _{x+1}\right)^{T}} Power and Schoonees [3] used the same algorithm to segment the foreground of the image: σ i , t + 1 = ( 1 − α ) ω i , t + α P ( k ∣ X t , φ ) {\displaystyle \sigma _{i,t+1}=\left(1-\alpha \right)\omega _{i,t}+\alpha P\left(k\mid X_{t},\varphi \right)} The essential approximation to P ( k ∣ X t , φ ) {\displaystyle P\left(k\mid \ X_{t},\varphi \right)} is given by M k , t {\displaystyle M_{k,t}} : M k , t = { 1 match , 0 otherwise . {\displaystyle M_{k,t}={\begin{cases}1&{\text{match}},\\0&{\text{otherwise}}.\end{cases}}} Case 2: No match is found with any of the K {\displaystyle K} Gaussians. In this case, the least probable distribution K {\displaystyle K} is replaced with a new one with parameters: k i . t = low prior weight {\displaystyle k_{i.t}={\text{low prior weight}}} μ i , t + 1 = X t + 1 {\displaystyle \mu _{i,t+1}=X_{t+1}} σ i . t + 1 2 = large initial variance {\displaystyle \sigma _{i.t+1}^{2}={\text{large initial variance}}} Once the parameter maintenance is made, foreground detection can be made and so on. An on-line K-means approximation is used to update the Gaussians. Numerous improvements of this original method developed by Stauffer and Grimson have been proposed and a complete survey can be found in Bouwmans et al. A standard method of adaptive backgrounding is averaging the images over time, creating a background approximation which is similar to the current static scene except where motion occur. Surveys Several surveys which concern categories or sub-categories of models can be found as follows: MOG background subtraction Subspace learning background subtraction Statistical background subtraction Fuzzy background subtraction RPCA background subtraction (See Robust principal component analysis for more details) Dynamic RPCA for background/foreground separation (See Robust principal component analysis for more details) Decomposition into low-rank plus additive matrices for background/foreground Separation Deep neural networks concepts for backgrou