s 125 million parameters were also trained). OpenAI stated that GPT-3 succeeded at certain "meta-learning" tasks and could generalize the purpose of a single input-output pair. The GPT-3 release paper gave examples of translation and cross-linguistic transfer learning between English and Romanian, and between English and German. GPT-3 dramatically improved benchmark results over GPT-2. OpenAI cautioned that such scaling-up of language models could be approaching or encountering the fundamental capability limitations of predictive language models. Pre-training GPT-3 required several thousand petaflop/s-days of compute, compared to tens of petaflop/s-days for the full GPT-2 model. Like its predecessor, the GPT-3 trained model was not immediately released to the public for concerns of possible abuse, although OpenAI planned to allow access through a paid cloud API after a two-month free private beta that began in June 2020. On September 23, 2020, GPT-3 was licensed exclusively to Microsoft. Codex Announced in mid-2021, Codex is a descendant of GPT-3 that has additionally been trained on code from 54 million GitHub repositories, and is the AI powering the code autocompletion tool GitHub Copilot. In August 2021, an API was released in private beta. According to OpenAI, the model can create working code in over a dozen programming languages, most effectively in Python. Several issues with glitches, design flaws and security vulnerabilities were cited. OpenAI announced that they would discontinue support for the Codex API on March 23, 2023. GPT-4 On March 14, 2023, OpenAI announced the release of Generative Pre-trained Transformer 4 (GPT-4), capable of accepting text or image inputs. They announced that the updated technology passed a simulated law school bar exam with a score around the top 10% of test takers. (By contrast, GPT-3.5 scored around the bottom 10%.) They said that GPT-4 could also read, analyze or generate up to 25,000 words of text, and write code in all major programming languages. Observers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous GPT-3.5-based iteration, with the caveat that GPT-4 retained some of the problems with earlier revisions. GPT-4 is also capable of taking images as input on ChatGPT. OpenAI has declined to reveal various technical details and statistics about GPT-4, such as the precise size of the model. GPT-4o On May 13, 2024, OpenAI announced and released GPT-4o, which can process and generate text, images and audio. GPT-4o achieved state-of-the-art results in voice, multilingual, and vision benchmarks, setting new records in audio speech recognition and translation. It scored 88.7% on the Massive Multitask Language Understanding (MMLU) benchmark compared to 86.5% by GPT-4. On July 18, 2024, OpenAI released GPT-4o mini, a smaller version of GPT-4o replacing GPT-3.5 Turbo on the ChatGPT interface. Its API costs $0.15 per million input tokens and $0.60 per million output tokens, compared to $5 and $15, respectively, for GPT-4o. OpenAI expects it to be particularly useful for enterprises, startups and developers seeking to automate services with AI agents. In March 2025, OpenAI released GPT-4o's native image generation feature, as an alternative to DALL-E 3. GPT-4.5 On February 27, 2025, OpenAI released GPT-4.5, codenamed Orion. Sam Altman claimed that GPT-4.5 would present inaccurate information less frequently than previous models, and described it as a "giant, expensive model". GPT-4.1 On April 14, 2025, OpenAI released the GPT-4.1 model. They also released two “smaller, faster, and cheaper” models including GPT-4.1 mini and GPT-4.1 nano. GPT-5 GPT-5 is OpenAI’s flagship model released on August 7, 2025. It replaced earlier models like GPT-4o, GPT-4.5, and o3. GPT-5 uses a dynamic router that chooses between quick responses and deeper “thinking” when needed. It can perform at PhD-level across domains like math, coding, health, and multimodal tasks. It also achi