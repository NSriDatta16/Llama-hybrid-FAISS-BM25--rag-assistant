In artificial intelligence, with implications for cognitive science, the frame problem describes an issue with using first-order logic to express facts about a robot in the world. Representing the state of a robot with traditional first-order logic requires the use of many axioms that simply imply that things in the environment do not change arbitrarily. For example, Hayes describes a "block world" with rules about stacking blocks together. In a first-order logic system, additional axioms are required to make inferences about the environment (for example, that a block cannot change position unless it is physically moved). The frame problem is the problem of finding adequate collections of axioms for a viable description of a robot environment. John McCarthy and Patrick J. Hayes defined this problem in their 1969 article, Some Philosophical Problems from the Standpoint of Artificial Intelligence. In this paper, and many that came after, the formal mathematical problem was a starting point for more general discussions of the difficulty of knowledge representation for artificial intelligence. Issues such as how to provide rational default assumptions and what humans consider common sense in a virtual environment. In philosophy, the frame problem became more broadly construed in connection with the problem of limiting the beliefs that have to be updated in response to actions. In the logical context, actions are typically specified by what they change, with the implicit assumption that everything else (the frame) remains unchanged. Description The frame problem occurs even in very simple domains. A scenario with a door, which can be open or closed, and a light, which can be on or off, is statically represented by two propositions o p e n {\displaystyle \mathrm {open} } and o n {\displaystyle \mathrm {on} } . If these conditions can change, they are better represented by two predicates o p e n ( t ) {\displaystyle \mathrm {open} (t)} and o n ( t ) {\displaystyle \mathrm {on} (t)} that depend on time; such predicates are called fluents. A domain in which the door is closed and the light off at time 0, and the door opened at time 1, can be directly represented in logic by the following formulae: ¬ o p e n ( 0 ) {\displaystyle \neg \mathrm {open} (0)} ¬ o n ( 0 ) {\displaystyle \neg \mathrm {on} (0)} o p e n ( 1 ) {\displaystyle \mathrm {open} (1)} The first two formulae represent the initial situation; the third formula represents the effect of executing the action of opening the door at time 1. If such an action had preconditions, such as the door being unlocked, it would have been represented by ¬ l o c k e d ( 0 ) ⟹ o p e n ( 1 ) {\displaystyle \neg \mathrm {locked} (0)\implies \mathrm {open} (1)} . In practice, one would have a predicate e x e c u t e o p e n ( t ) {\displaystyle \mathrm {executeopen} (t)} for specifying when an action is executed and a rule ∀ t . e x e c u t e o p e n ( t ) ⟹ o p e n ( t + 1 ) {\displaystyle \forall t.\mathrm {executeopen} (t)\implies \mathrm {open} (t+1)} for specifying the effects of actions. The article on the situation calculus gives more details. While the three formulae above are a direct expression in logic of what is known, they do not suffice to correctly draw consequences. While the following conditions (representing the expected situation) are consistent with the three formulae above, they are not the only ones. Indeed, another set of conditions that is consistent with the three formulae above is: The frame problem is that specifying only which conditions are changed by the actions does not entail that all other conditions are not changed. This problem can be solved by adding the so-called “frame axioms”, which explicitly specify that all conditions not affected by actions are not changed while executing that action. For example, since the action executed at time 0 is that of opening the door, a frame axiom would state that the status of the light does not change from time 0 to time 1