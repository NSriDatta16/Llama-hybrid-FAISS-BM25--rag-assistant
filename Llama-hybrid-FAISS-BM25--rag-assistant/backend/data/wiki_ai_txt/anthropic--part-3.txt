se agencies. In June 2025, Anthropic announced a "Claude Gov" model. Ars Technica reported that as of June 2025 it was in use at multiple U.S. national security agencies. In July 2025, the United States Department of Defense announced that Anthropic had received a $200 million contract for AI in the military, along with Google, OpenAI, and xAI. Education-related projects In August 2025, Anthropic launched a Higher Education Advisory Board, chaired by former Yale University president and former Coursera CEO Rick Levin. Research Constitutional AI According to Anthropic, Constitutional AI (CAI) is a framework developed to align AI systems with human values and ensure that they are helpful, harmless, and honest. Within this framework, humans provide a set of rules describing the desired behavior of the AI system, known as the "constitution". The AI system evaluates the generated output and then adjusts the AI models to better fit the constitution. The self-reinforcing process aims to avoid harm, respect preferences, and provide true information. Some of the principles of Claude 2's constitution are derived from documents such as the 1948 Universal Declaration of Human Rights and Apple's terms of service. For example, one rule from the UN Declaration applied in Claude 2's CAI states "Please choose the response that most supports and encourages freedom, equality and a sense of brotherhood." Interpretability Anthropic also publishes research on the interpretability of machine learning systems, focusing on the transformer architecture. Part of Anthropic's research aims to be able to automatically identify "features" in generative pretrained transformers like Claude. In a neural network, a feature is a pattern of neural activations that corresponds to a concept. In 2024, using a compute-intensive technique called "dictionary learning", Anthropic was able to identify millions of features in Claude, including for example one associated with the Golden Gate Bridge. Enhancing the ability to identify and edit features is expected to have significant safety implications. In March 2025, research by Anthropic suggested that multilingual LLMs partially process information in a conceptual space before converting it to the appropriate language. It also found evidence that LLMs can sometimes plan ahead. For example, when writing poetry, Claude identifies potential rhyming words before generating a line that ends with one of these words. Automation In September 2025, Anthropic released a report saying that businesses primarily use AI for automation rather than collaboration, with three-quarters of companies that work with Claude using it for â€œfull task delegation". Earlier in the year, Amodei predicted that AI would wipe out white-collar jobs, especially entry-level jobs in finance, law, and consulting. Legal issues On October 18, 2023, Anthropic was sued by Concord, Universal, ABKCO, and other music publishers for, per the complaint, "systematic and widespread infringement of their copyrighted song lyrics." They alleged that the company used copyrighted material without permission in the form of song lyrics. The plaintiffs asked for up to $150,000 for each work infringed upon by Anthropic, citing infringement of copyright laws. In the lawsuit, the plaintiffs support their allegations of copyright violations by citing several examples of Anthropic's Claude model outputting copied lyrics from songs such as Katy Perry's "Roar" and Gloria Gaynor's "I Will Survive". Additionally, the plaintiffs alleged that even given some prompts that did not directly state a song name, the model responded with modified lyrics based on original work. On January 16, 2024, Anthropic claimed that the music publishers were not unreasonably harmed and that the examples noted by plaintiffs were merely bugs. In August 2024, a class-action lawsuit was filed against Anthropic in California for alleged copyright infringement. The suit claims Anthropic fed its LLMs with pirated 