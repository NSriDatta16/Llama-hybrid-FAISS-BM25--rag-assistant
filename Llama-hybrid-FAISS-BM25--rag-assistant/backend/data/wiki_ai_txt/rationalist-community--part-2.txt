ed to as information hazards, are dangerous and should be suppressed. Roko's basilisk and the writings of Ziz LaSota are commonly cited information hazards among rationalists. Some members and former members of the community have said that aspects of the community can be cult-like. In The New York Times, religious scholar Greg Epstein stated: "When you think about the billions at stake and the radical transformation of lives across the world because of the eccentric vision of this group, how much more cult-y does it have to be for this to be a cult? Not much." Lifestyle While the movement has online origins, the community is also active and close-knit offline. The community is especially active in the San Francisco Bay Area, where many rationalists live in intentional communities and some engage in polyamorous relationships with other rationalists. History LessWrong was originally founded in 2009, although the community had previously existed on various blogs on the Internet, including Overcoming Bias (founded in 2006). Slate Star Codex was launched in 2013, and its successor blog Astral Codex Ten was launched on January 21, 2021. Eliezer Yudkowsky created LessWrong and is regarded as a major figure within the movement. He has also published the Harry Potter fanfiction called Harry Potter and the Methods of Rationality from 2010 to 2015, which led people towards LessWrong and the rationalist community. Harry Potter and the Methods of Rationality was a highly popular fanfiction and is well-regarded within the rationalist community. Yudkowsky has used the work to solicit donations for the Center for Applied Rationality, which teaches courses based on it, and a 2013 LessWrong survey revealed a quarter of its users had found the site due to the fanfiction. In the 2010s, the rationalist community emerged as a major force in Silicon Valley. Silicon Valley founders such as Elon Musk, Peter Thiel, Vitalik Buterin, Dustin Moskovitz, and Jaan Tallinn have donated to rationalist-associated institutions or otherwise supported rationalist figures. The movement has directed hundreds of millions of dollars towards companies, research labs, and think tanks aligned with its objectives, and was influential in the abortive removal of Sam Altman from OpenAI. Bay Area organizations associated with the rationalist community include the Center for Applied Rationality, which teaches the techniques of rationality espoused by rationalists, and the Machine Intelligence Research Institute, which conducts research on AI safety. Overlapping movements and offshoots The borders of the rationalist community are blurry and subject to debate among the community and adjacent groups. The rationalist community has a large overlap with effective altruism and transhumanism. Critics such as computer scientist Timnit Gebru and philosopher Ã‰mile P. Torres link rationalists with other philosophies they collectively name TESCREAL: Transhumanism, extropianism, singularitarianism, cosmism, rationalism, effective altruism, and longtermism. Members who diverge from typical rationalist beliefs often self-describe as "rationalist-adjacent", "post-rationalist" (also known as "ingroup" and "TPOT", an acronym for "this part of Twitter") or "EA-adjacent". Effective altruism Postrationalists The postrationalists are a loose group of one-time rationalists who became disillusioned with the rationalist community, which they came to perceive as "a little culty [and] dogmatic" and as having lost focus on the less quantifiable elements of a well-lived human life. This community also goes by the acronym TPOT, standing for This Part of Twitter. The term postrationalist is also used as a hedge by people associated with the rationalist community who have drifted from its orthodoxy. Zizians The Zizians are a splinter group with an ideological emphasis on veganism and anarchism, which became well known in 2025 for being suspected of involvement in four murders. The Zizians originally formed ar