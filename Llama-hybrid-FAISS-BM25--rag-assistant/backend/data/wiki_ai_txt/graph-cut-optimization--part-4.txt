red as data term), while the function S ( x i , x j ) {\displaystyle S(x_{i},x_{j})} represents binary interactions between variables (smoothness term). In the general case, optimization of such functions is a NP-hard problem, and stochastic optimization methods such as simulated annealing are sensitive to local minima and in practice they can generate arbitrarily sub-optimal results. With graph cuts it is possible to construct move-making algorithms that allow to reach in polynomial time a local minima with strong optimality properties for a wide family of quadratic functions of practical interest (when the binary interaction S ( x i , x j ) {\displaystyle S(x_{i},x_{j})} is a metric or a semimetric), such that the value of the function in the solution lies within a constant and known factor from the global optimum. Given a function f : Λ n → R {\displaystyle f:\Lambda ^{n}\to \mathbb {R} } with Λ = { 1 , … , k } {\displaystyle \Lambda =\{1,\dots ,k\}} , and a certain assignment of values x = ( x 1 , … , x n ) ∈ Λ n {\displaystyle \mathbf {x} =(x_{1},\dots ,x_{n})\in \Lambda ^{n}} to the variables, it is possible to associate each assignment x {\displaystyle \mathbf {x} } to a partition P = { P l | l ∈ Λ } {\displaystyle P=\{P_{l}|l\in \Lambda \}} of the set of variables, such that, P l = { x i | x i = l ∈ Λ } {\displaystyle P_{l}=\{x_{i}|x_{i}=l\in \Lambda \}} . Give two distinct assignments P {\displaystyle P} and P ′ {\displaystyle P'} and a value α ∈ Λ {\displaystyle \alpha \in \Lambda } , a move that transforms P {\displaystyle P} into P ′ {\displaystyle P'} is said to be an α {\displaystyle \alpha } -expansion if P α ⊂ P α ′ {\displaystyle P_{\alpha }\subset P'_{\alpha }} and P l ′ ⊂ P l ∀ l ∈ Λ − { α } {\displaystyle P'_{l}\subset P_{l}\;\forall l\in \Lambda -\{\alpha \}} . Given a couple of values α {\displaystyle \alpha } and β {\displaystyle \beta } , a move is said to be an α β {\displaystyle \alpha \beta } -swap if P l = P l ′ ∀ l ∈ Λ − { α , β } {\displaystyle P_{l}=P'_{l}\;\forall l\in \Lambda -\{\alpha ,\beta \}} . Intuitively, an α {\displaystyle \alpha } -expansion move from x {\displaystyle \mathbf {x} } assigns the value of α {\displaystyle \alpha } to some variables that have a different value in x {\displaystyle \mathbf {x} } , while an α β {\displaystyle \alpha \beta } -swap move assigns α {\displaystyle \alpha } to some variables that have value β {\displaystyle \beta } in x {\displaystyle \mathbf {x} } and vice versa. For each iteration, the α {\displaystyle \alpha } -expansion algorithm computes, for each possible value α {\displaystyle \alpha } , the minimum of the function among all assignments A ( x ) {\displaystyle \mathrm {A} (\mathbf {x} )} that can be reached with a single α {\displaystyle \alpha } -expansion move from the current temporary solution x {\displaystyle \mathbf {x} } , and takes it as the new temporary solution. x := arbitrary value in Λ n {\displaystyle \mathbf {x} :={\text{arbitrary value in }}\Lambda ^{n}} exit := 0 {\displaystyle {\text{exit}}:=0} while exit ≠ 1 {\displaystyle {\text{exit}}\neq 1} : exit = 1 {\displaystyle {\text{exit}}=1} foreach α ∈ Λ {\displaystyle \alpha \in \Lambda } : x ^ := arg ⁡ min y ∈ A ( x ) f ( y ) {\displaystyle \mathbf {\hat {x}} :=\arg \min _{\mathbf {y} \in \mathrm {A} (\mathbf {x} )}f(\mathbf {y} )} if f ( x ^ ) < f ( x ) {\displaystyle f(\mathbf {\hat {x}} )<f(\mathbf {x} )} : x = x ^ {\displaystyle \mathbf {x} =\mathbf {\hat {x}} } exit := 0 {\displaystyle {\text{exit}}:=0} The α β {\displaystyle \alpha \beta } -swap algorithm is similar, but it searches for the minimum among all assignments A B ( x ) {\displaystyle \mathrm {A} \mathrm {B} (\mathbf {x} )} reachable with a single α β {\displaystyle \alpha \beta } -swap move from x {\displaystyle \mathbf {x} } . x := arbitrary value in Λ n {\displaystyle \mathbf {x} :={\text{arbitrary value in }}\Lambda ^{n}} exit := 0 {\displaystyle {\text{exit}}:=0} while exit ≠ 1 {\displaystyle {\text{exit}}