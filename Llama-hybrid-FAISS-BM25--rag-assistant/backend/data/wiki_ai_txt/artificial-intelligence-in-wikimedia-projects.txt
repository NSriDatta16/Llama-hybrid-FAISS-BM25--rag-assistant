Artificial intelligence is used in Wikimedia projects for the purpose of developing those projects. Various articles on Wikipedia have been created entirely with or with the help of artificial intelligence. AI-generated content can be detrimental to Wikipedia when unreliable or containing fake citations. To address the issue of low-quality AI-generated content, the Wikipedia community created in 2023 a WikiProject named AI Cleanup. In August 2025, Wikipedia adopted a policy that allowed editors to nominate suspected AI-generated articles for speedy deletion. Using artificial intelligence for Wikipedia ORES The Objective Revision Evaluation Service (ORES) project is an artificial intelligence service for grading the quality of Wikipedia edits. The Wikimedia Foundation presented the ORES project in November 2015. Wiki bots Bias reduction In August 2018, a company called Primer reported attempting to use artificial intelligence to create Wikipedia articles about women as a way to address gender bias on Wikipedia. Beginnings of generative AI In 2022, the public release of ChatGPT inspired more experimentation with AI and writing Wikipedia articles. A debate was sparked about whether and to what extent such large language models are suitable for such purposes in light of their tendency to generate plausible-sounding misinformation, including fake references; to generate prose that is not encyclopedic in tone; and to reproduce biases. Since 2023, work has been done to draft Wikipedia policy on ChatGPT and similar large language models (LLMs), e.g. at times recommending that users who are unfamiliar with LLMs should avoid using them due to the aforementioned risks, as well as noting the potential for libel or copyright infringement. On December 6, 2022, a Wikipedia contributor named Pharos created the article "Artwork title" in his sandbox, declaring he used ChatGPT to experiment with it and would extensively modify it. Another editor tagged the article as "original research", arguing that the article was initially unsourced AI-generated content, and sourced afterwards, instead of being based on reliable sources from the outset. Another editor who experimented with this early version of ChatGPT said that ChatGPT's overview of the topic was decent, but that the citations were fabricated. The Wiki Education Foundation reported that some experienced editors found AI to be useful in starting drafts or creating new articles. It said that ChatGPT "knows" what Wikipedia articles look like and can easily generate one that is written in the style of Wikipedia, but warned that ChatGPT had a tendency to use promotional language, among other issues. Miguel Garc√≠a, a former Wikimedia member from Spain, said that when ChatGPT was originally launched, the number of AI-generated articles on the site peaked. He added that the rate of AI articles has now stabilized due to the community's efforts to combat it. He said that majority of the articles that have no sources are deleted instantly or are nominated for deletion. In 2023, the Wikipedia community created a WikiProject named AI Cleanup to assist in the removal of poor quality AI content from Wikipedia. In October 2024, a study by Princeton University revealed that about 5% of 3,000 newly created articles (created in August 2024) on English Wikipedia were created using AI. The study said that some of the AI articles were on innocuous topics and that AI had likely only been used to assist in writing. For some other articles, AI had been used to promote businesses or political interests. In August 2025, the Wikipedia community created a policy that allowed users to nominate suspected AI-generated articles for speedy deletion. Editors usually recognize AI-generated articles because they use citations that are not related to the subject of the article or fabricated citations. The wording of articles is also used to recognize AI writings. For example, if an article uses language that reads like an LLM r