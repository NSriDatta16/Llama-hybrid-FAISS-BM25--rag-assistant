s the space of 256x256 images, and the data-augmentation method is "generate a gaussian noise z ∼ N ( 0 , I 256 2 ) {\displaystyle z\sim {\mathcal {N}}(0,I_{256^{2}})} , then add ϵ z {\displaystyle \epsilon z} to the image", then K trans {\displaystyle K_{\text{trans}}} is just convolution by the density function of N ( 0 , ϵ 2 I 256 2 ) {\displaystyle {\mathcal {N}}(0,\epsilon ^{2}I_{256^{2}})} . This is invertible, because convolution by a gaussian is just convolution by the heat kernel, so given any μ ∈ P ( R n ) {\displaystyle \mu \in {\mathcal {P}}(\mathbb {R} ^{n})} , the convolved distribution K trans ∗ μ {\displaystyle K_{\text{trans}}*\mu } can be obtained by heating up R n {\displaystyle \mathbb {R} ^{n}} precisely according to μ {\displaystyle \mu } , then wait for time ϵ 2 / 4 {\displaystyle \epsilon ^{2}/4} . With that, we can recover μ {\displaystyle \mu } by running the heat equation backwards in time for ϵ 2 / 4 {\displaystyle \epsilon ^{2}/4} . More examples of invertible data augmentations are found in the paper. SinGAN SinGAN pushes data augmentation to the limit, by using only a single image as training data and performing data augmentation on it. The GAN architecture is adapted to this training method by using a multi-scale pipeline. The generator G {\displaystyle G} is decomposed into a pyramid of generators G = G 1 ∘ G 2 ∘ ⋯ ∘ G N {\displaystyle G=G_{1}\circ G_{2}\circ \cdots \circ G_{N}} , with the lowest one generating the image G N ( z N ) {\displaystyle G_{N}(z_{N})} at the lowest resolution, then the generated image is scaled up to r ( G N ( z N ) ) {\displaystyle r(G_{N}(z_{N}))} , and fed to the next level to generate an image G N − 1 ( z N − 1 + r ( G N ( z N ) ) ) {\displaystyle G_{N-1}(z_{N-1}+r(G_{N}(z_{N})))} at a higher resolution, and so on. The discriminator is decomposed into a pyramid as well. StyleGAN series The StyleGAN family is a series of architectures published by Nvidia's research division. Progressive GAN Progressive GAN is a method for training GAN for large-scale image generation stably, by growing a GAN generator from small to large scale in a pyramidal fashion. Like SinGAN, it decomposes the generator as G = G 1 ∘ G 2 ∘ ⋯ ∘ G N {\displaystyle G=G_{1}\circ G_{2}\circ \cdots \circ G_{N}} , and the discriminator as D = D 1 ∘ D 2 ∘ ⋯ ∘ D N {\displaystyle D=D_{1}\circ D_{2}\circ \cdots \circ D_{N}} . During training, at first only G N , D N {\displaystyle G_{N},D_{N}} are used in a GAN game to generate 4x4 images. Then G N − 1 , D N − 1 {\displaystyle G_{N-1},D_{N-1}} are added to reach the second stage of GAN game, to generate 8x8 images, and so on, until we reach a GAN game to generate 1024x1024 images. To avoid shock between stages of the GAN game, each new layer is "blended in" (Figure 2 of the paper). For example, this is how the second stage GAN game starts: Just before, the GAN game consists of the pair G N , D N {\displaystyle G_{N},D_{N}} generating and discriminating 4x4 images. Just after, the GAN game consists of the pair ( ( 1 − α ) + α ⋅ G N − 1 ) ∘ u ∘ G N , D N ∘ d ∘ ( ( 1 − α ) + α ⋅ D N − 1 ) {\displaystyle ((1-\alpha )+\alpha \cdot G_{N-1})\circ u\circ G_{N},D_{N}\circ d\circ ((1-\alpha )+\alpha \cdot D_{N-1})} generating and discriminating 8x8 images. Here, the functions u , d {\displaystyle u,d} are image up- and down-sampling functions, and α {\displaystyle \alpha } is a blend-in factor (much like an alpha in image composing) that smoothly glides from 0 to 1. StyleGAN-1 StyleGAN-1 is designed as a combination of Progressive GAN with neural style transfer. The key architectural choice of StyleGAN-1 is a progressive growth mechanism, similar to Progressive GAN. Each generated image starts as a constant 4 × 4 × 512 {\displaystyle 4\times 4\times 512} array, and repeatedly passed through style blocks. Each style block applies a "style latent vector" via affine transform ("adaptive instance normalization"), similar to how neural style transfer uses Gramian matrix.