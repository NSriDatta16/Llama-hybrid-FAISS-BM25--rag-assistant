imes an "intelligent software agent" (that is, a software agent with intelligence) is referred to as an "intelligent agent". According to Nikola Kasabov in 1998, IA systems should exhibit the following characteristics: Accommodate new problem solving rules incrementally. Adapt online and in real time. Are able to analyze themselves in terms of behavior, error and success. Learn and improve through interaction with the environment (embodiment). Learn quickly from large amounts of data. Have memory-based exemplar storage and retrieval capacities. Have parameters to represent short- and long-term memory, age, forgetting, etc. Agentic AI In the context of generative artificial intelligence, AI agents (also referred to as compound AI systems) are a class of intelligent agents distinguished by their ability to operate autonomously in complex environments. Agentic AI tools prioritize decision-making over content creation and do not require human prompts or continuous oversight. They possess several key attributes, including complex goal structures, natural language interfaces, the capacity to act independently of user supervision, and the integration of software tools or planning systems. Their control flow is frequently driven by large language models (LLMs). Researchers and commentators have noted that AI agents do not have a standard definition. A common application of AI agents is the automation of tasksâ€”for example, booking travel plans based on a user's prompted request. Prominent examples include Devin AI, AutoGPT, and SIMA. Further examples of agents released since 2025 include OpenAI Operator, ChatGPT Deep Research, Manus, Quark (based on Qwen), AutoGLM Rumination, and Coze (by ByteDance). Frameworks for building AI agents include LangChain, as well as tools such as CAMEL, Microsoft AutoGen, and OpenAI Swarm. Companies such as Google, Microsoft and Amazon Web Services have offered platforms for deploying pre-built AI agents. Proposed protocols for standardizing inter-agent communication include the Agent Protocol (by LangChain), the Model Context Protocol (by Anthropic), AGNTCY, Gibberlink, the Internet of Agents, Agent2Agent (by Google), and the Agent Network Protocol. Software frameworks for addressing agent reliability include AgentSpec, ToolEmu, GuardAgent, Agentic Evaluations, and predictive models from H2O.ai. In February 2025, Hugging Face released Open Deep Research, an open source version of OpenAI Deep Research. Hugging Face also released a free web browser agent, similar to OpenAI Operator. Galileo AI published on Hugging Face a leadership board for agents, which ranks their performance based on their underlying LLMs. Autonomous capabilities The Financial Times compared the autonomy of AI agents to the SAE classification of self-driving cars, comparing most applications to level 2 or level 3, with some achieving level 4 in highly specialized circumstances, and level 5 being theoretical. Multimodal AI agents In addition to large language models (LLMs), vision language models (VLMs) and multimodal foundation models can be used as the basis for agents. In September 2024, Allen Institute for AI released an open source vision language model, which Wired noted could give AI agents the ability to perform complex computer tasks, including the possibility of automated computer hacking. Nvidia released a framework for developers to use VLMs, LLMs and retrieval-augmented generation for building AI agents that can analyze images and videos, including video search and video summarization. Microsoft released a multimodal agent model - trained on images, video, software user interface interactions, and robotics data - that the company claimed can manipulate software and robots. Applications As of April 2025, per the Associated Press, there are few real world applications of AI agents. As of June 2025, per Fortune, many companies are primarily experimenting with AI agents. A recruiter for the Department of Government Efficiency p