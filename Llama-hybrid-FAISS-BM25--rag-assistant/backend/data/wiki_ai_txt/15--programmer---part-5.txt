of new character voices. In a post introducing new character additions to 15.ai, Equestria Daily's founder Shaun Scotellaro wrote that "some of [the voices] aren't great due to the lack of samples to draw from, but many are really impressive still anyway." Chinese My Little Pony fan site EquestriaCN also documented 15.ai's development and its updates, though they criticized some of its bugs and long queue wait times. Peter Paltridge of Anime Superhero News opined that "voice synthesis has evolved to the point where the more expensive efforts are nearly indistinguishable from actual human speech," but also stated that "In some ways, SAM is still more advanced than this. It was possible to affect SAM's inflections by using special characters, as well as change his pitch at will. With 15.ai, you're at the mercy of whatever random inflections you get." Conversely, Lauren Morton of Rock, Paper, Shotgun praised the depth of pronunciation control—"if you're willing to get into the nitty gritty of it". Similarly, Eugenio Moto of Qore.com wrote that "the most experienced of users can change parameters like the stress or the tone." Takayuki Furushima of Den Fami Nico Gamer highlighted the "smooth pronunciations", and Yuki Kurosawa of AUTOMATON wrote that its "rich emotional expression" was a major feature; both Japanese authors mentioned the lack of Japanese-language support. Renan do Prado of Arkade and José Villalobos of LaPS4 remarked that while users could create amusing results in Portuguese and Spanish respectively, the generation performed best in English. Chinese gaming news website GamerSky called the app "interesting", but also criticized the word count limit of the text and the occasional lack of intonations. Marco Cocomello of GLITCHED remarked that despite the 200-character limitation, the results "blew [him] away" when testing the app with GLaDOS's voice. Spanish author Álvaro Ibáñez wrote in Microsiervos that he found the rhythm of the AI-generated voices interesting and that 15.ai was able to adapt its delivery based on the text's meaning. Technical reception AI researchers and practitioners provided more in-depth analysis of 15.ai's capabilities and limitations compared to other text-to-speech technologies of the time. Google DeepMind senior research scientist Alex Irpan wrote that when 15.ai launched in 2020, it was "arguably the highest quality voice generation model in the world" and superior to models developed by Google AI. In their explanation for why they plagiarized from 15.ai, Voiceverse wrote that "the best voice [their marketing team] could find was not [theirs] but 15.ai['s]". Rionaldi Chandraseta of Towards Data Science wrote that voice models trained on larger datasets created more convincing output with better phrasing and natural pauses, particularly for extended text. Parth Mahendra of AI Daily wrote that while the system "does a good job at accurately replicating most basic words," it struggled with more complex terms, noting that characters would "absolutely butcher the pronunciation" of certain words. Dan Ruta, the creator of a downloadable voice AI tool called xVASynth, wrote that in comparison, cloud-based tools like 15.ai had the benefit of being accessible on any device. Economist and AI commentator Tyler Cowen named 15.ai among examples of underrated talent in AI and machine learning. Chinese AI researchers also offered various technical assessments. Machine learning professor Yongqiang Li wrote that 15.ai "perfectly preserves the rhythm and characteristics of the speaker," and remarked that the application was still free despite having 5,000 people generating voices concurrently at the time of writing. Bai Feng of XinZhiYuan on QQ News highlighted the technical achievement of 15.ai's high-quality output despite using minimal training data and wrote that it was of significantly higher quality than typical deep learning text-to-speech implementations. Feng also acknowledged that while some pronun