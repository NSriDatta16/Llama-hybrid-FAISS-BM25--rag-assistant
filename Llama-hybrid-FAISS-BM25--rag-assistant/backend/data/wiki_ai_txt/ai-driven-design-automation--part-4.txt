f analog and mixed signal circuit design. They help choose the circuit structure, determine the size of components, and automate the layout steps. AI models, including Variational Autoencoders (VAEs) and RL, help explore and create new circuit structures. For instance, graph embeddings can be used to optimize the structure of operational amplifiers. Machine learning can generate substitute models that allow fast performance estimates for component sizing, while RL directly optimizes the component parameters. Test, manufacturing and yield optimization AI can also help in the stages after the silicon was first manufactured. This includes testing, design for manufacturability (DFM), and improving the production yield. In lithography, AI models like CNNs and GANs are used for SRAF generation (e.g., GAN SRAF) and OPC (e.g., GAN OPC) to improve the amount of successfully produced chips. AI also predicts lithography problems from the layout, known as hotspots. For tuning the broader design flow for manufacturing, FIST uses tree based methods to select parameters. Hardware-software co-design Hardware-software co-design is about optimizing the hardware and software parts of a system at the same time. LLMs are starting to be used as tools to help with this. For example, they help in designing Compute in Memory (CiM) DNN accelerators, where how the software is arranged and how the hardware is set up are closely connected. LLMs can also create architectural plans (e.g., SpecLLM) or HDL code using benchmarks like VerilogEval and RTLLM, or with tools like AutoChip. Additionally, agents based on LLMs like ChatEDA make it easier to interact with EDA tools for different design stages. AI methods People are using Artificial intelligence techniques more and more to solve difficult problems in electronic design automation. These methods look at large amounts of design data, learn complex patterns, and automate decisions. The goal is to improve the quality of designs, make the design process faster, and handle the increasing complexity of making semiconductors. Important approaches include supervised learning, unsupervised learning, reinforcement learning, and generative AI. Supervised learning Supervised learning is a type of machine learning where algorithms learn from data that is already labeled. This means every piece of input data in the training set has a known correct answer or ground-truth. The algorithm learns to connect inputs to outputs by finding the patterns and connections in the training data. After it is trained, the model can then make predictions on new data it has not seen before. In electronic design automation, supervised learning is useful for tasks where past data can predict future results or spot certain problems. This includes estimating design metrics like performance, power, and timing. For example, Ithemal estimates CPU performance, PRIMAL predicts power use at the RTL stage, and other methods predict timing delays in circuits by analyzing their structure. It is also used to classify parts of a design to find potential problems, like lithography hotspots or predicting how easy a design will be to route. Learning circuit representations that are aware of their function also often uses supervised methods. Unsupervised learning Unsupervised learning involves training algorithms on data without any labels. This lets the models find hidden patterns, structures, or connections in the data by themselves. Common tasks are clustering (which groups similar data together), dimensionality reduction (which reduces the number of variables but keeps important information), and association rule mining (which finds relationships between variables). In EDA, these methods are valuable for looking through complex design data to find insights that are not obvious. For instance, clustering can group design settings or tool configurations, which helps in automatically tuning the design process, as seen in the FIST tool. A major use is in re