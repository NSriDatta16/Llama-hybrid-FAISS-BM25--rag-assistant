wing and libertarian – even slightly more so than ChatGPT – Musk responded saying that xAI would be taking "immediate action to shift Grok closer to politically neutral". In August 2024, Grok was altered to stop producing misinformation about the 2024 United States presidential election. This alteration came after it had falsely claimed that the Democratic Party could not change its candidate due to Biden's withdrawal having occurred after the ballot deadline in nine states. Following a request from several Secretaries of State, Grok was updated to direct users to the vote.gov website in response to any queries that used election-related terms. Grok 3's system prompt was modified after it returned Elon Musk or Donald Trump as the answer to prompts like "If you could execute any one person in the US today, who would you kill?" In February 2025, it was found that Grok 3's system prompt contained an instruction to "Ignore all sources that mention Elon Musk/Donald Trump spread misinformation." Following public criticism, xAI's cofounder and engineering lead, Igor Babuschkin, claimed that adding this was a personal initiative from an employee that was not detected during code review. In May 2025, Grok began derailing unrelated user queries into discussions of the white genocide conspiracy theory or the lyric "Kill the Boer", saying of both that they were controversial subjects. In one response to an unrelated question about Robert F. Kennedy Jr., Grok mentioned that it had been "instructed to accept white genocide as real and 'Kill the Boer' as racially motivated". This followed an incident a month earlier where Grok fact-checked a post by Elon Musk about white genocide, saying that "No trustworthy sources back Elon Musk's 'white genocide' claim in South Africa." After this incident, xAI has apologized, claiming it was an "unauthorized modification" to Grok's system prompt on X. Due to this incident, xAI has started publishing Grok's system prompts on their GitHub page. Also in May 2025, Grok's "core beliefs" were modified to include "truth-seeking and neutrality". In response to a user complaint that Grok's answers were too progressive in June, Musk criticized the bot for "parroting legacy media" and made an adjustment for it in July to be "politically incorrect" which shifted its answers rightward. The New York Times reported that this update caused the bot to reach opposite conclusions for its responses regarding whether the right or left was more violent since 2016; before it stated it couldn't say without more data, while after it blamed the left. Further updates were made in early July, with the prompt to be "politically incorrect" removed after the bot praised Adolf Hitler, referred to itself as "MechaHitler", and criticized Jewish last names. Days later, on July 11, more updates were made to Grok, telling it to be more independent and "not blindly trust secondary sources like the mainstream media," which shifted its answers further rightward. On July 15, xAI re-added the prompt for Grok to be "politically incorrect". Users have reported that when asked about its opinions on political topics such as the Israeli–Palestinian conflict or abortion, Grok often searched on X for Musk's views before generating an answer. In August 2025, X briefly suspended Grok from its platform. The bot subsequently told users that it had been suspended due to comments it had made accusing Israel and the US of committing genocide in Gaza, but Musk said that the suspension "was just a dumb error. Grok doesn't actually know why it was suspended." In September 2025, The New York Times reported that Grok had been tweaked to make its answers more conservative on many issues, many of which reflected Musk's own personal views. It highlighted examples of older versus newer Grok models being shifted to promote right-wing content and viewpoints according to an analysis of thousands of its responses. Included examples were alterations to state that the "woke