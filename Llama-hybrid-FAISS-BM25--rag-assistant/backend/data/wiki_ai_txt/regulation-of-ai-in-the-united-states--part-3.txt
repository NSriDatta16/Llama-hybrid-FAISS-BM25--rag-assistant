esource (NAIRR), which aimed to expand public access to computing resources, datasets, and AI testing environments. Additionally, the Trump administration also signed Executive Order #14179 to initiate a national “AI Action Plan”, focusing on securing U.S. global AI dominance in a way in which the White House can seek public input on AI safety and standards. At the state level, new laws have also been passed or proposed to regulate AI-generated impersonations, chatbot disclosures, and even synthetic political content. Meanwhile, the Department of Commerce also expanded export controls on AI technology, and NIST published an updated set of guidances on AI cybersecurity risks. In March 2025, OpenAI made a policy proposal for the Trump administration to preempt pending AI-related state laws with federal laws. Meta, Google, IBM and Andreessen Horowitz have also pressured the government to adopt national rules that would rein in state laws. States like California, which is considering the most AI regulations of all states would be hit hard. California legislature is considering several AI laws that would require insurance companies to report the use of AI when dying healthcare claims, as well as regulations that requires the AI to be performance tested before making implementation on certain applications. In May 2025, House Republicans inserted into a tax and spending bill a clause banning state AI laws for 10 years, which was met with opposition from more than 100 nonprofit organizations, elected officials, public policy experts, and others. The Senate voted 99-1 to defeat the ban. In September 2025, Sen. Ted Cruz (a supporter of the AI state moratorium) said that the proposal would return for debate in Congress. State and local government interventions In January 2023, the New York City Bias Audit Law (Local Law 144) was enacted by the NYC Council in November 2021. Originally due to come into effect on 1 January 2023, the enforcement date for Local Law 144 has been pushed back due to the high volume of comments received during the public hearing on the Department of Consumer and Worker Protection's (DCWP) proposed rules to clarify the requirements of the legislation. It eventually became effective on July 5, 2023. From this date, the companies that are operating and hiring in New York City are prohibited from using automated tools to hire candidates or promote employees, unless the tools have been independently audited for bias. In February 2024, Senator Scott Wiener introduced the Safe and Secure Innovation for Frontier Artificial Intelligence Models Act to the California legislature. The bill drew heavily on the Biden executive order and had the goal of reducing catastrophic risks by mandating safety tests for the most powerful AI models. If passed, the bill would have established a publicly-funded cloud computing cluster in California. On September 29, 2024. Governor Gavin Newsom vetoed the bill. It is considered unlikely that the legislature will override the governor's veto with a two-thirds vote from both houses. On March 13, 2024, Utah Governor Spencer Cox signed the S.B 149 "Artificial Intelligence Policy Act". This legislation went into effect on May 1, 2024. It established liability, notably for companies that do not disclose their use of generative AI when required by state consumer protection laws, or when users commit criminal offense using generative AI. It also created the Office of Artificial Intelligence Policy and the Artificial Intelligence Learning Laboratory Program. On March 21, 2024, the State of Tennessee enacted legislation called the ELVIS Act, aimed specifically at audio deepfakes, and voice cloning. This legislation was the first enacted legislation in the nation aimed at regulating AI simulation of image, voice and likeness. The bill passed unanimously in the Tennessee House of Representatives and Senate. This legislation's success was hoped by its supporters to inspire similar actions in other states