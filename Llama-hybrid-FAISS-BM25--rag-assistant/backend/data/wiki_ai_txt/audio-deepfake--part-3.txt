of counterfeiting techniques. In general, deepfake detection methods can be divided into two categories based on the aspect they leverage to perform the detection task. The first focuses on low-level aspects, looking for artifacts introduced by the generators at the sample level. The second, instead, focus on higher-level features representing more complex aspects as the semantic content of the speech audio recording. Many machine learning models have been developed using different strategies to detect fake audio. Most of the time, these algorithms follow a three-steps procedure: Each speech audio recording must be preprocessed and transformed into appropriate audio features; The computed features are fed into the detection model, which performs the necessary operations, such as the training process, essential to discriminate between real and fake speech audio; The output is fed into the final module to produce a prediction probability of the Fake class or the Real one. Following the ASVspoof challenge nomenclature, the Fake audio is indicated with the term "Spoof," the Real instead is called "Bonafide." Over the years, many researchers have shown that machine learning approaches are more accurate than deep learning methods, regardless of the features used. However, the scalability of machine learning methods is not confirmed due to excessive training and manual feature extraction, especially with many audio files. Instead, when deep learning algorithms are used, specific transformations are required on the audio files to ensure that the algorithms can handle them. There are several open-source implementations of different detection methods, and usually many research groups release them on a public hosting service like GitHub. Open challenges and future research direction The audio deepfake is a very recent field of research. For this reason, there are many possibilities for development and improvement, as well as possible threats that adopting this technology can bring to our daily lives. The most important ones are listed below. Deepfake generation Regarding the generation, the most significant aspect is the credibility of the victim, i.e., the perceptual quality of the audio deepfake. Several metrics determine the level of accuracy of audio deepfake generation, and the most widely used is the mean opinion score (MOS), which is the arithmetic average of user ratings. Usually, the test to be rated involves perceptual evaluation of sentences made by different speech generation algorithms. This index showed that audio generated by algorithms trained on a single speaker has a higher MOS. The sampling rate also plays an essential role in detecting and generating audio deepfakes. Currently, available datasets have a sampling rate of around 16 kHz, significantly reducing speech quality. An increase in the sampling rate could lead to higher quality generation. In March 2020, a Massachusetts Institute of Technology researcher demonstrated data-efficient audio deepfake generation through 15.ai, a web application capable of generating high-quality speech using only 15 seconds of training data, compared to previous systems that required tens of hours. The system implemented a unified multi-speaker model that enabled simultaneous training of multiple voices through speaker embeddings, allowing the model to learn shared patterns across different voices even when individual voices lacked examples of certain emotional contexts. The platform integrated sentiment analysis through DeepMoji for emotional expression and supported precise pronunciation control via ARPABET phonetic transcriptions. The 15-second data efficiency benchmark was later corroborated by OpenAI in 2024. Deepfake detection Focusing on the detection part, one principal weakness affecting recent models is the adopted language. Most studies focus on detecting audio deepfake in the English language, not paying much attention to the most spoken languages like Chinese and Spanish