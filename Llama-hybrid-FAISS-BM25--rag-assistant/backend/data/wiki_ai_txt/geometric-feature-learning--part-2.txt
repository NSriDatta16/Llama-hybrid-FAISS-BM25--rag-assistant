 Learning algorithms There are many learning algorithms which can be applied to learn to find distinctive features of objects in an image. Learning can be incremental, meaning that the object classes can be added at any time. Geometric feature extraction methods Corner detection Curve fitting Edge detection Global structure extraction Feature histograms Line detection Connected-component labeling Image texture Motion estimation Feature learning algorithm 1.Acquire a new training image "I". 2.According to the recognition algorithm, evaluate the result. If the result is true, new object classes are recognised. recognition algorithm The key point of recognition algorithm is to find the most distinctive features among all features of all classes. So using below equation to maximise the feature f max {\displaystyle \textstyle \ f_{\max }} I max = max f max C I ( C , F f ) {\displaystyle \textstyle \ I_{\max }={\underset {f}{\max }}\ {\underset {C}{\max }}\ I(C,F_{f})} I ( C , F f ) = − ∑ C ∑ F f B E L ( F f , C ) log ⁡ B E L ( C , F f ) B E L ( F f ) B E L ( C ) {\displaystyle \textstyle \ I(C,F_{f})=-{\underset {C}{\sum }}{\underset {F_{f}}{\sum }}BEL(F_{f},C)\log {\frac {BEL(C,F_{f})}{BEL(F_{f})BEL(C)}}} Measure the value of a feature in images, f max {\displaystyle \textstyle \ f_{\max }} and f f max {\displaystyle \textstyle \ f_{f_{\max }}} , and localise a feature: f f ( p ) ( I ) = max x ∈ I f f ( p ) ( x ) {\displaystyle \textstyle \ f_{f_{(p)}}(I)={\underset {x\in I}{\max }}f_{f_{(p)}}(x)} Where f f ( p ) ( x ) {\displaystyle \textstyle f_{f_{(p)}}(x)} is defined as f f ( p ) ( I ) = max { 0 , f ( p ) T ) f ( x ) ‖ f ( p ) ‖ ‖ f ( x ) ‖ } {\displaystyle \textstyle f_{f_{(p)}}(I)=\max \left\{0,{\frac {f(p)^{T})f(x)}{\left\|f(p)\right\|\left\|f(x)\right\|}}\right\}} evaluation After recognise the features, the results should be evaluated to determine whether the classes can be recognised, There are five evaluation categories of recognition results: correct, wrong, ambiguous, confused and ignorant. When the evaluation is correct, add a new training image and train it. If the recognition failed, the feature nodes should be maximise their distinctive power which is defined by the Kolmogorov-Smirno distance (KSD). K S D a , b ( X ) = max α | c d f ( α | a ) − c d f ( α | b ) | {\displaystyle \textstyle KSD_{a,b}(X)={\underset {\alpha }{\max }}\left|cdf(\alpha |a)-cdf(\alpha |b)\right|} 3.Feature learning algorithm After a feature is recognised, it should be applied to Bayesian network to recognise the image, using the feature learning algorithm to test. The main purpose of feature learning algorithm is to find a new feature from sample image to test whether the classes are recognised or not. Two cases should be consider: Searching for new feature of true class and wrong class from sample image respectively. If new feature of true class is detected and the wrong class is not recognised, then the class is recognised and the algorithm should terminate. If feature of true class is not detected and of false class is detected in the sample image, false class should be prevented from being recognised and the feature should be removed from Bayesian network. Using Bayesian network to realise the test process PAC model based feature learning algorithm Learning framework The probably approximately correct (PAC) model was applied by D. Roth (2002) to solve computer vision problem by developing a distribution-free learning theory based on this model. This theory heavily relied on the development of feature-efficient learning approach. The goal of this algorithm is to learn an object represented by some geometric features in an image. The input is a feature vector and the output is 1 which means successfully detect the object or 0 otherwise. The main point of this learning approach is collecting representative elements which can represent the object through a function and testing by recognising an object from image to find the representation 