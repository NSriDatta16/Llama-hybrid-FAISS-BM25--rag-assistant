 Modelссвs. Training data for Gen-3 has been sourced from thousands of YouTube videos and potentially pirated films. A former Runway employee alleged to 404 Media that a company-wide effort was to compile videos into spreadsheets, which was then downloaded using youtube-dl through proxy servers to avoid being blocked by YouTube. In tests, 404 Media discovered that names of YouTubers would generate videos in their respective styles. Gen-4 In March 2025, Runway released Gen-4, a video-generating AI model that the company described as its most advanced to date. According to the company, the model can generate consistent characters, objects, and environments across scenes, using reference images and text prompts. Unlike earlier models that treated each frame as a separate creative task with only loose connections between them, Gen-4 allows users to generate consistent characters across lighting conditions using a reference image of those characters. The model introduced several key features designed to address longstanding challenges in AI video generation, particularly around visual consistency and narrative continuity that had previously made AI-generated content appear disjointed. Gen-4 Turbo Gen-4 Turbo, released in April 2025, is a faster, more cost-effective version of Gen-4. The Turbo model uses fewer credits per second of video. References With Gen-4 References, users can upload reference images as a baseline for characters, objects, sets, or environments across different scenes. The system can extract a character from one image and place them in different scenes, transform character elements or environments, blend visual styles between images, or combine elements from multiple sources. Aleph In July 2025, Runway released Aleph, which adds the ability to perform edits on input videos including adding, removing, and transforming objects, generating any angle of a scene, and modifying style and lighting. With the launch of Aleph, the Gen-4 model can now support various editing tasks including object manipulation, scene transformation, camera angle generation, and style transfer. Act-One and Act-Two Act-One, released in October 2024, enables users to upload a driving video and then transform that performance into realistic or animated characters. With Act-One, creators can animate characters in various styles without motion-capture equipment or character rigging, but still maintain important elements of the original performance including eye-lines, micro-expressions, and nuanced pacing onto generated characters. Act-Two, an expanded version, allows users to animate characters using driving performance videos, providing control over gestures and body movement when using character images, and automatically adding environmental motion. Game Worlds In 2025, Runway launched Game Worlds, described as “an early look at the next frontier of non-linear narrative experiences.” The tool allows users to play or create text-based adventures accompanied by pictures. Runway positions Game Worlds as "a first step towards the next era of gaming" and states it "represents the next frontier" for interactive entertainment and education. Partnerships Entertainment industry IMAX In August 2025, Runway partnered with IMAX to screen AI Film Festival winners in 10 major cities across the United States. IMAX Chief Content Officer, Jonathan Fischer, said of the partnership: “The IMAX Experience has typically been reserved for the world’s most accomplished and visionary filmmakers. We’re excited to open our aperture and use our platform to experiment with a new kind of creator, as storytelling and technology converge in an entirely new way.” AMC Networks In June 2025, AMC Networks became the first cable company to formally partner with Runway for AI-powered content creation. The partnership focuses on using Runway's technology to generate marketing images and help pre-visualize shows before production begins. AMC Networks plans to use the AI tools to cr