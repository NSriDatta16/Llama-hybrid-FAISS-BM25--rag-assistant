00 e R i / 400 + e R j / 400 = 1 1 + e ( R j − R i ) / 400 . {\displaystyle \Pr(i>j)={\frac {e^{R_{i}/400}}{e^{R_{i}/400}+e^{R_{j}/400}}}={\frac {1}{1+e^{(R_{j}-R_{i})/400}}}.} Plackett–Luce model A standard generalization of the BT model is the Plackett–Luce model, which models ranking N {\displaystyle N} items. In the same notation as BT model: Pr ( y 1 > ⋯ > y N ) = ∏ i = 1 N p y i ∑ k = i N p y k = p y 1 p y 1 + ⋯ + p y N p y 2 p y 2 + ⋯ + p y N ⋯ p y N p y N {\displaystyle \Pr(y_{1}>\cdots >y_{N})=\prod _{i=1}^{N}{\frac {p_{y_{i}}}{\sum _{k=i}^{N}p_{y_{k}}}}={\frac {p_{y_{1}}}{p_{y_{1}}+\dots +p_{y_{N}}}}{\frac {p_{y_{2}}}{p_{y_{2}}+\cdots +p_{y_{N}}}}\cdots {\frac {p_{y_{N}}}{p_{y_{N}}}}} The factor with i = N {\displaystyle i=N} is always just unity, so for N = 2 {\displaystyle N=2} this reduces to Pr ( y 1 > y 2 ) = p y 1 / ( p y 1 + p y 2 ) {\displaystyle \Pr(y_{1}>y_{2})=p_{y_{1}}/(p_{y_{1}}+p_{y_{2}})} . This can be imagined as drawing from an urn with replacement. The urn contains balls colored in proportion to p 1 , p 2 , … , p N {\displaystyle p_{1},p_{2},\dots ,p_{N}} , and one draws from the urn with replacement. If a ball has a new color, then that ball is placed as the next-ranked ball. Otherwise, if the ball has a color already drawn, then it is discarded. Given the proportions p 1 , p 2 , … , p N {\displaystyle p_{1},p_{2},\dots ,p_{N}} , the PL model can be sampled by the "exponential race" method. One samples "radioactive decay times" from N {\displaystyle N} "exponential clocks", that is, t 1 ∼ E x p ( p 1 ) , … , t N ∼ E x p ( p N ) {\displaystyle t_{1}\sim \mathrm {Exp} (p_{1}),\dots ,t_{N}\sim \mathrm {Exp} (p_{N})} . Then one ranks the items according to the order in which they decayed. In this interpretation, it is immediately clear that the PL model satisfies Luce's choice axiom (from the same Luce). Therefore, for any two y , z {\displaystyle y,z} , Pr ( y > z ) = p y p y + p z {\displaystyle \Pr(y>z)={\frac {p_{y}}{p_{y}+p_{z}}}} reduces to the BT model, and in general, for any subset y 1 , … , y M {\displaystyle y_{1},\dots ,y_{M}} of the choices, Pr ( y 1 > ⋯ > y N ) = p y 1 p y 1 + ⋯ + p y M p y 2 p y 2 + ⋯ + p y M ⋯ p y M p y M {\displaystyle \Pr(y_{1}>\cdots >y_{N})={\frac {p_{y_{1}}}{p_{y_{1}}+\cdots +p_{y_{M}}}}{\frac {p_{y_{2}}}{p_{y_{2}}+\cdots +p_{y_{M}}}}\cdots {\frac {p_{y_{M}}}{p_{y_{M}}}}} reduces to a smaller PL model with the same parameters. Inference The most common application of the Bradley–Terry model is to infer the values of the parameters p i {\displaystyle p_{i}} given an observed set of outcomes i > j {\displaystyle i>j} , such as wins and losses in a competition. The simplest way to estimate the parameters is by maximum likelihood estimation, i.e., by maximizing the likelihood of the observed outcomes given the model and parameter values. Suppose we know the outcomes of a set of pairwise competitions between a certain group of individuals, and let wij be the number of times individual i beats individual j. Then the likelihood of this set of outcomes within the Bradley–Terry model is ∏ i j [ Pr ( i > j ) ] w i j {\displaystyle \prod _{ij}[\Pr(i>j)]^{w_{ij}}} and the log-likelihood of the parameter vector p = [p1, ..., pn] is l ( p ) = ln ⁡ ∏ i j [ Pr ( i > j ) ] w i j = ∑ i = 1 n ∑ j = 1 n ln ⁡ [ ( p i p i + p j ) w i j ] = ∑ i j w i j ln ⁡ ( p i p i + p j ) = ∑ i j [ w i j ln ⁡ ( p i ) − w i j ln ⁡ ( p i + p j ) ] . {\displaystyle {\begin{aligned}{\mathcal {l}}(\mathbf {p} )&=\ln \prod _{ij}{{\bigl [}\Pr(i>j){\bigr ]}}^{w_{ij}}=\sum _{i=1}^{n}\sum _{j=1}^{n}\ln {\biggl [}\left({\frac {p_{i}}{p_{i}+p_{j}}}\right)^{w_{ij}}{\biggr ]}\\[6pt]&=\sum _{ij}w_{ij}\ln {\biggl (}{\frac {p_{i}}{p_{i}+p_{j}}}{\biggr )}=\sum _{ij}{\bigl [}w_{ij}\ln(p_{i})-w_{ij}\ln(p_{i}+p_{j}){\bigr ]}.\end{aligned}}} Zermelo showed that this expression has only a single maximum, which can be found by differentiating with respect to p i {\displaystyle p_{i}} and setting the result to zero, which lea