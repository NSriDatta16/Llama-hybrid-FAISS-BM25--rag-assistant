AI takeover—the idea that some kind of artificial intelligence may supplant mankind as the dominant intelligent species on the planet—is a common theme in science fiction. Famous cultural touchstones include Terminator and The Matrix. Background Fictional scenarios typically involve a drawn-out conflict against malicious artificial intelligence (AI) or robots with anthropomorphic motives. In contrast, some scholars believe that a takeover by a future advanced AI, if it were to happen in real life, would succeed or fail rapidly, and would be a disinterested byproduct of the AI's pursuit of its own alien goals, rather than a product of malice specifically targeting humans. Characterization There are many positive portrayals of AI in fiction, such as Isaac Asimov's Bicentennial Man and Lt. Commander Data from Star Trek. There are also many negative portrayals. Many of these negative portrayals (and a few of the positive portrayals) involve an AI seizing control from its creators. Reactions Some AI researchers, such as Yoshua Bengio, have complained that films such as Terminator "paint a picture which is really not coherent with the current understanding of how AI systems are built today and in the foreseeable future". BBC reporter Sam Shead has stated that "unfortunately, there have been numerous instances of [news outlets] using stills from the Terminator films in stories about relatively incremental breakthroughs" and that the films generate "misplaced fears of uncontrollable, all-powerful AI". In contrast, other scholars, such as physicist Stephen Hawking, have held that future AI could indeed pose an existential risk, but that the Terminator films are nonetheless implausible in two distinct ways. The first implausibility is that, according to Hawking, "The real risk with AI isn't malice but competence. A super intelligent AI will be extremely good at accomplishing its goals, and if those goals aren't aligned with ours, we're in trouble. You're probably not an evil ant-hater who steps on ants out of malice, but if you're in charge of a hydroelectric green energy project and there's an anthill in the region to be flooded, too bad for the ants." The second implausibility is that such a technologically advanced AI would deploy a brute-force attack by humanoid robots to commit its omnicide; a more plausible and efficient method would be to use germ warfare or, if feasible, nanotechnology. Philosopher Huw Price defends that "The kind of imagination that is used in science fiction and other forms of literature and film is likely to be extremely important" in understanding the breadth of possible future scenarios for humanity. Film journalist Mekado Murphy writes in The New York Times that such films can constructively "warn of the complications of relying too much on technology to solve problems". Hollywood films such as Transcendence are usually constrained to have happy endings, however implausible the human victory seems. Philosopher Nick Bostrom states fiction has a "good story bias" toward scenarios that make a good plot. In films such as Terminator, an AI goes from passive to murderous the instant it achieves something referred to as "self-awareness"; in reality, self-awareness in isolation is considered both trivial and useless. Physicist David Deutsch states: "AGIs [artificial general intelligences] will indeed be capable of self-awareness — but that is [only] because they will be General: they will be capable of awareness of every kind of deep and subtle thing, including their own selves." Some tropes are more general to artificial intelligence films, including to films without "takeover" plots. In films like Ex Machina or Chappie, a single isolated genius becomes the first to successfully build an AGI; scientists in the real world deem this to be unlikely. In Chappie, Transcendence, and Blade Runner, people are able to upload human minds into robots; usually no reasonable explanation is offered as to how this difficult tas