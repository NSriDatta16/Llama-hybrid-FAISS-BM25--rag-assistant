A conversational user interface (CUI) is a user interface for computers that emulates a conversation with a real human. Historically, computers have relied on text-based user interfaces and graphical user interfaces (GUIs) (such as the user pressing a "back" button) to translate the user's desired action into commands the computer understands. While an effective mechanism of completing computing actions, there is a learning curve for the user associated with GUI. Instead, CUIs provide opportunity for the user to communicate with the computer in their natural language rather than in a syntax specific commands. To do this, conversational interfaces use natural language processing (NLP) to allow computers to understand, analyze, and create meaning from human language. Unlike word processors, NLP considers the structure of human language (i.e., words make phrases; phrases make sentences which convey the idea or intent the user is trying to invoke). The ambiguous nature of human language makes it difficult for a machine to always correctly interpret the user's requests, which is why we have seen a shift toward natural-language understanding (NLU). NLU allows for sentiment analysis and conversational searches which allows a line of questioning to continue, with the context carried throughout the conversation. NLU allows conversational interfaces to handle unstructured inputs that the human brain is able to understand such as spelling mistakes of follow-up questions. For example, through leveraging NLU, a user could first ask for the population of the United States. If the user then asks "Who is the president?", the search will carry forward the context of the United States and provide the appropriate response. Conversational interfaces have emerged as a tool for businesses to efficiently provide consumers with relevant information, in a cost-effective manner. CUI provide ease of access to relevant, contextual information to the end user without the complexities and learning curve typically associated with technology. While there are a variety of interface brands, to date, there are two main categories of conversational interfaces; voice assistants and chatbots. Voice-based interfaces A voice user interface allows a user to complete an action by speaking a command. Introduced in October 2011, Apple's Siri was one of the first voice assistants widely adopted. Siri allowed users of iPhone to get information and complete actions on their device simply by asking Siri. In the later years, Siri was integrated with Apple's HomePod devices. Further development has continued since Siri's introduction to include home based devices such as Google Home or Amazon Echo (powered by Alexa) that allow users to "connect" their homes through a series of smart devices to further the options of tangible actions they can complete. Users can now turn off the lights, set reminders and call their friends all with a verbal queue. These conversational interfaces that utilize a voice assistant have become a popular way for businesses to interact with their customers as the interface removes some friction in a customer journey. Customers no longer need to remember a long list of usernames and passwords to their various accounts; they simply link each account to Google or Amazon once, and gone are the days where you needed to wait on hold for an hour to ask a simple question. Text-based interfaces A chatbot is a web- or mobile-based interface that allows the user to ask questions and retrieve information. This information can be generic in nature such as the Google Assistant chat window that allows for internet searches, or it can be a specific brand or service which allows the user to gain information about the status of their various accounts. Their backend systems work in the same manner as a voice assistant, with the front end utilizing a visual interface to convey information. This visual interface can be beneficial for companies that need to do more complex