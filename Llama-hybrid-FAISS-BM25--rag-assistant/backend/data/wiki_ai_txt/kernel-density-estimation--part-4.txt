i }}\int _{-\infty }^{+\infty }{\frac {1}{n}}\sum _{j=1}^{n}e^{it(x_{j}-x)}\psi (ht)\,dt\\[1ex]&={\frac {1}{nh}}\sum _{j=1}^{n}{\frac {1}{2\pi }}\int _{-\infty }^{+\infty }e^{-i(ht){\frac {x-x_{j}}{h}}}\psi (ht)\,d(ht)\\[1ex]&={\frac {1}{nh}}\sum _{j=1}^{n}K{\left({\frac {x-x_{j}}{h}}\right)},\end{aligned}}} where K is the Fourier transform of the damping function ψ. Thus the kernel density estimator coincides with the characteristic function density estimator. Geometric and topological features We can extend the definition of the (global) mode to a local sense and define the local modes: M = { x : g ( x ) = 0 ∣ λ 1 ( x ) < 0 } {\displaystyle M=\{x:g(x)=0\mid \lambda _{1}(x)<0\}} Namely, M {\displaystyle M} is the collection of points for which the density function is locally maximized. A natural estimator of M {\displaystyle M} is a plug-in from KDE, where g ( x ) {\displaystyle g(x)} and λ 1 ( x ) {\displaystyle \lambda _{1}(x)} are KDE version of g ( x ) {\displaystyle g(x)} and λ 1 ( x ) {\displaystyle \lambda _{1}(x)} . Under mild assumptions, M c {\displaystyle M_{c}} is a consistent estimator of M {\displaystyle M} . Note that one can use the mean shift algorithm to compute the estimator M c {\displaystyle M_{c}} numerically. Statistical implementation A non-exhaustive list of software implementations of kernel density estimators includes: In Analytica release 4.4, the Smoothing option for PDF results uses KDE, and from expressions it is available via the built-in Pdf function. In C/C++, FIGTree is a library that can be used to compute kernel density estimates using normal kernels. MATLAB interface available. In C++, libagf is a library for variable kernel density estimation. In C++, mlpack is a library that can compute KDE using many different kernels. It allows to set an error tolerance for faster computation. Python and R interfaces are available. in C# and F#, Math.NET Numerics is an open source library for numerical computation which includes kernel density estimation In CrimeStat, kernel density estimation is implemented using five different kernel functions – normal, uniform, quartic, negative exponential, and triangular. Both single- and dual-kernel density estimate routines are available. Kernel density estimation is also used in interpolating a Head Bang routine, in estimating a two-dimensional Journey-to-crime density function, and in estimating a three-dimensional Bayesian Journey-to-crime estimate. In ELKI, kernel density functions can be found in the package de.lmu.ifi.dbs.elki.math.statistics.kernelfunctions In ESRI products, kernel density mapping is managed out of the Spatial Analyst toolbox and uses the Quartic(biweight) kernel. In Excel, the Royal Society of Chemistry has created an add-in to run kernel density estimation based on their Analytical Methods Committee Technical Brief 4. In gnuplot, kernel density estimation is implemented by the smooth kdensity option, the datafile can contain a weight and bandwidth for each point, or the bandwidth can be set automatically according to "Silverman's rule of thumb" (see above). In Haskell, kernel density is implemented in the statistics package. In IGOR Pro, kernel density estimation is implemented by the StatsKDE operation (added in Igor Pro 7.00). Bandwidth can be user specified or estimated by means of Silverman, Scott or Bowmann and Azzalini. Kernel types are: Epanechnikov, Bi-weight, Tri-weight, Triangular, Gaussian and Rectangular. In Java, the Weka machine learning package provides weka.estimators.KernelEstimator, among others. In JavaScript, the visualization package D3.js offers a KDE package in its science.stats package. In JMP, the Graph Builder platform utilizes kernel density estimation to provide contour plots and high density regions (HDRs) for bivariate densities, and violin plots and HDRs for univariate densities. Sliders allow the user to vary the bandwidth. Bivariate and univariate kernel density estimates are also provided by the Fit Y 