e to frequent mistakes, primarily because it relies on its own feedback, which can compound errors. In contrast, non-autonomous models can be corrected by users overseeing their outputs. Furthermore, AutoGPT has a tendency to hallucinate or to present false or misleading information as fact when responding. AutoGPT can be constrained by the cost associated with running it as its recursive nature requires it to continually call the OpenAI API on which it is built. Every step required in one of AutoGPT's tasks requires a corresponding call to GPT-4 at a cost of at least about $0.03 for every 1000 tokens used for inputs and $0.06 for every 1000 tokens for output when choosing the cheapest option. For reference, 1000 tokens roughly result in 750 words. Another limitation is AutoGPT's tendency to get stuck in infinite loops. Developers believe that this is a result of AutoGPT's inability to remember, as it is unaware of what it has already done and repeatedly attempts the same subtask without end. Andrej Karpathy, co-founder of OpenAI which creates GPT-4, further explains that it is AutoGPT's “finite context window” that can limit its performance and cause it to “go off the rails”. Like other autonomous agents, AutoGPT is prone to distraction and unable to focus on its objective due to its lack of long-term memory, leading to unpredictable and unintended behavior. Reception AutoGPT became the top trending repository on GitHub after its release and has since repeatedly trended on Twitter. In April 2023, Avram Piltch wrote for Tom's Hardware that AutoGPT 'might be too autonomous to be useful,' as it did not ask questions to clarify requirements or allow corrective interventions by users. Piltch nonetheless noted that such tools have "a ton of potential" and should improve with better language models and further development. Malcolm McMillan from Tom's Guide mentioned that AutoGPT may not be better than ChatGPT for tasks involving conversation, as ChatGPT is well-suited for situations in which advice, rather than task completion, is sought. Will Knight from Wired wrote that AutoGPT is not a foolproof task-completion tool. When given a test task of finding a public figure's email address, he noted that it was not able to accurately find the email address. Clara Shih, Salesforce Service Cloud CEO commented that "AutoGPT illustrates the power and unknown risks of generative AI," and that due to usage risks, enterprises should include a human in the loop when using such technologies. Performance is reportedly enhanced when using AutoGPT with GPT-4 compared to GPT-3.5. For example, one reviewer who tested it on a task of finding the best laptops on the market with pros and cons found that AutoGPT with GPT-4 created a more comprehensive report than one by GPT 3.5. See also ChatGPT - Large Language Model-based Chatbot by OpenAI GPT-3 - 2020 Large Language Model by OpenAI GPT-4 - 2023 Large Language Model by OpenAI Artificial general intelligence - Hypothetical intelligent agent that could learn to accomplish any intellectual task that humans can perform Hallucination (artificial intelligence) - Responses generated by an AI that contain false information that are presented as fact. References Further reading Pounder, Les (April 15, 2023). "How To Create Your Own AutoGPT AI Agent". Tom's Hardware. Retrieved April 16, 2023. Wiggers, Kyle (April 22, 2023). "What is AutoGPT and why does it matter?". TechCrunch. Retrieved April 23, 2023. External links Official website Official repository at GitHub