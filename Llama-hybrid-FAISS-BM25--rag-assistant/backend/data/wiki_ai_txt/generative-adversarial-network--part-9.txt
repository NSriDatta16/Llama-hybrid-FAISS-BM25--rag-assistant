ter, L G A N {\displaystyle L_{GAN}} is the GAN game objective, and L c y c l e {\displaystyle L_{cycle}} is the cycle consistency loss: L c y c l e ( G X , G Y ) = E x ∼ μ X ‖ G X ( G Y ( x ) ) − x ‖ + E y ∼ μ Y ‖ G Y ( G X ( y ) ) − y ‖ {\displaystyle L_{cycle}(G_{X},G_{Y})=E_{x\sim \mu _{X}}\|G_{X}(G_{Y}(x))-x\|+E_{y\sim \mu _{Y}}\|G_{Y}(G_{X}(y))-y\|} The generators aim to minimize the objective, and the discriminators aim to maximize it: min G X , G Y max D X , D Y L ( G X , G Y , D X , D Y ) {\displaystyle \min _{G_{X},G_{Y}}\max _{D_{X},D_{Y}}L(G_{X},G_{Y},D_{X},D_{Y})} Unlike previous work like pix2pix, which requires paired training data, cycleGAN requires no paired data. For example, to train a pix2pix model to turn a summer scenery photo to winter scenery photo and back, the dataset must contain pairs of the same place in summer and winter, shot at the same angle; cycleGAN would only need a set of summer scenery photos, and an unrelated set of winter scenery photos. GANs with particularly large or small scales BigGAN The BigGAN is essentially a self-attention GAN trained on a large scale (up to 80 million parameters) to generate large images of ImageNet (up to 512 x 512 resolution), with numerous engineering tricks to make it converge. Invertible data augmentation When there is insufficient training data, the reference distribution μ ref {\displaystyle \mu _{\text{ref}}} cannot be well-approximated by the empirical distribution given by the training dataset. In such cases, data augmentation can be applied, to allow training GAN on smaller datasets. Naïve data augmentation, however, brings its problems. Consider the original GAN game, slightly reformulated as follows: { min D L D ( D , μ G ) = − E x ∼ μ ref ⁡ [ ln ⁡ D ( x ) ] − E x ∼ μ G ⁡ [ ln ⁡ ( 1 − D ( x ) ) ] min G L G ( D , μ G ) = − E x ∼ μ G ⁡ [ ln ⁡ ( 1 − D ( x ) ) ] {\displaystyle {\begin{cases}\min _{D}L_{D}(D,\mu _{G})=-\operatorname {E} _{x\sim \mu _{\text{ref}}}[\ln D(x)]-\operatorname {E} _{x\sim \mu _{G}}[\ln(1-D(x))]\\\min _{G}L_{G}(D,\mu _{G})=-\operatorname {E} _{x\sim \mu _{G}}[\ln(1-D(x))]\end{cases}}} Now we use data augmentation by randomly sampling semantic-preserving transforms T : Ω → Ω {\displaystyle T:\Omega \to \Omega } and applying them to the dataset, to obtain the reformulated GAN game: { min D L D ( D , μ G ) = − E x ∼ μ ref , T ∼ μ trans ⁡ [ ln ⁡ D ( T ( x ) ) ] − E x ∼ μ G ⁡ [ ln ⁡ ( 1 − D ( x ) ) ] min G L G ( D , μ G ) = − E x ∼ μ G ⁡ [ ln ⁡ ( 1 − D ( x ) ) ] {\displaystyle {\begin{cases}\min _{D}L_{D}(D,\mu _{G})=-\operatorname {E} _{x\sim \mu _{\text{ref}},T\sim \mu _{\text{trans}}}[\ln D(T(x))]-\operatorname {E} _{x\sim \mu _{G}}[\ln(1-D(x))]\\\min _{G}L_{G}(D,\mu _{G})=-\operatorname {E} _{x\sim \mu _{G}}[\ln(1-D(x))]\end{cases}}} This is equivalent to a GAN game with a different distribution μ ref ′ {\displaystyle \mu _{\text{ref}}'} , sampled by T ( x ) {\displaystyle T(x)} , with x ∼ μ ref , T ∼ μ trans {\displaystyle x\sim \mu _{\text{ref}},T\sim \mu _{\text{trans}}} . For example, if μ ref {\displaystyle \mu _{\text{ref}}} is the distribution of images in ImageNet, and μ trans {\displaystyle \mu _{\text{trans}}} samples identity-transform with probability 0.5, and horizontal-reflection with probability 0.5, then μ ref ′ {\displaystyle \mu _{\text{ref}}'} is the distribution of images in ImageNet and horizontally-reflected ImageNet, combined. The result of such training would be a generator that mimics μ ref ′ {\displaystyle \mu _{\text{ref}}'} . For example, it would generate images that look like they are randomly cropped, if the data augmentation uses random cropping. The solution is to apply data augmentation to both generated and real images: { min D L D ( D , μ G ) = − E x ∼ μ ref , T ∼ μ trans ⁡ [ ln ⁡ D ( T ( x ) ) ] − E x ∼ μ G , T ∼ μ trans ⁡ [ ln ⁡ ( 1 − D ( T ( x ) ) ) ] min G L G ( D , μ G ) = − E x ∼ μ G , T ∼ μ trans ⁡ [ ln ⁡ ( 1 − D ( T ( x ) ) ) ] {\displaystyle {\begin{cases}\min _{D}L_{D}(D,\mu _{G})=-\o