yle t=1,2,...,T} 1. Set p t = w t ∑ i = 1 N w i t {\displaystyle p^{t}={\frac {w^{t}}{\sum _{i=1}^{N}w_{i}^{t}}}} . 2. Call WeakLearn, providing it with the distribution p t {\displaystyle p^{t}} ; get back a hypothesis h t : X → {\displaystyle h_{t}:X\rightarrow } [0,1]. 3. Calculate the error of h t : ϵ t = ∑ i = 1 N p i t | h t ( x i ) − y i | {\displaystyle h_{t}:\epsilon _{t}=\sum _{i=1}^{N}p_{i}^{t}|h_{t}(x_{i})-y_{i}|} . 4. Set β t = ϵ t 1 − ϵ t {\displaystyle \beta _{t}={\frac {\epsilon _{t}}{1-\epsilon _{t}}}} . 5. Set the new weight vector to be w i t + 1 = w i t β t 1 − | h t ( x i ) − y i | {\displaystyle w_{i}^{t+1}=w_{i}^{t}\beta _{t}^{1-|h_{t}(x_{i})-y_{i}|}} . Output the hypothesis: f ( x ) = h f ( x ) = { 1 if ∑ t = 1 T ( log ⁡ ( 1 / β t ) ) h t ( x ) ≥ 1 2 ∑ t = 1 T log ⁡ ( 1 / β t ) 0 otherwise {\displaystyle f(x)=h_{f}(x)={\begin{cases}1&{\text{if}}\sum _{t=1}^{T}(\log(1/\beta _{t}))h_{t}(x)\geq {\frac {1}{2}}\sum _{t=1}^{T}\log(1/\beta _{t})\\0&{\text{otherwise}}\end{cases}}} Solving linear programs approximately Source: Problem Given a m × n {\displaystyle m\times n} matrix A {\displaystyle A} and b ∈ R n {\displaystyle b\in \mathbb {R} ^{n}} , is there a x {\displaystyle x} such that A x ≥ b {\displaystyle Ax\geq b} ? ∃ ? x : A x ≥ b {\displaystyle \exists ?x:Ax\geq b} (1) Assumption Using the oracle algorithm in solving zero-sum problem, with an error parameter ϵ > 0 {\displaystyle \epsilon >0} , the output would either be a point x {\displaystyle x} such that A x ≥ b − ϵ {\displaystyle Ax\geq b-\epsilon } or a proof that x {\displaystyle x} does not exist, i.e., there is no solution to this linear system of inequalities. Solution Given vector p ∈ Δ n {\displaystyle p\in \Delta _{n}} , solves the following relaxed problem ∃ ? x : p T A x ≥ p T b {\displaystyle \exists ?x:p^{\textsf {T}}\!\!Ax\geq p^{\textsf {T}}\!b} (2) If there exists a x satisfying (1), then x satisfies (2) for all p ∈ Δ n {\displaystyle p\in \Delta _{n}} . The contrapositive of this statement is also true. Suppose if oracle returns a feasible solution for a p {\displaystyle p} , the solution x {\displaystyle x} it returns has bounded width max i | ( A x ) i − b i | ≤ 1 {\displaystyle \max _{i}|{(Ax)}_{i}-b_{i}|\leq 1} . So if there is a solution to (1), then there is an algorithm that its output x satisfies the system (2) up to an additive error of 2 ϵ {\displaystyle 2\epsilon } . The algorithm makes at most ln ⁡ ( m ) ϵ 2 {\displaystyle {\frac {\ln(m)}{\epsilon ^{2}}}} calls to a width-bounded oracle for the problem (2). The contrapositive stands true as well. The multiplicative updates is applied in the algorithm in this case. Other applications Evolutionary game theory Multiplicative weights update is the discrete-time variant of the replicator equation (replicator dynamics), which is a commonly used model in evolutionary game theory. It converges to Nash equilibrium when applied to a congestion game. Operations research and online statistical decision-making In operations research and on-line statistical decision making problem field, the weighted majority algorithm and its more complicated versions have been found independently. Computational geometry The multiplicative weights algorithm is also widely applied in computational geometry, such as Clarkson's algorithm for linear programming (LP) with a bounded number of variables in linear time. Later, Bronnimann and Goodrich employed analogous methods to find Set Covers for hypergraphs with small VC dimension. Gradient descent method Matrix multiplicative weights update Plotkin, Shmoys, Tardos framework for packing/covering LPs Approximating multi-commodity flow problems O (logn)- approximation for many NP-hard problems Learning theory and boosting Hard-core sets and the XOR lemma Hannan's algorithm and multiplicative weights Online convex optimization References External links The Game Theory of Life a Quanta Magazine article describing the use of the method to evolutionary biolo