 recursive algorithm proceeds as follows: Initialize a list L with all asset indices: L = {1, 2, ..., N}. Assign initial weights: w_n = 1 for all assets. While any subset in L contains more than one element: Bisect the subset into two halves: L1 and L2. For each subset Lj, compute its covariance matrix Vj and define weights proportional to the inverse of its diagonal entries. Normalize those weights so they sum to 1, and compute the variance of the cluster as w' V w. Compute a split factor α = 1 - (V1 / (V1 + V2)). Rescale the weights of L1 by α and of L2 by 1 - α. This ensures that all weights remain between 0 and 1 and sum to 1 at all times. The following Python function implements this process, where sorIx is the list of ordered assets returned by Step 2 (Quasi-Diagonalization), cov is the covariance matrix: import pandas as pd, numpy as np def getRecBipart(cov, sortIx): # Compute HRP allocation w = pd.Series(1.0, index=sortIx) clusters = [sortIx] while len(clusters) > 0: # Bisect each cluster new_clusters = [] for cluster in clusters: if len(cluster) > 1: split = int(len(cluster) / 2) new_clusters.append(cluster[:split]) new_clusters.append(cluster[split:]) clusters = new_clusters # Update weights for i in range(0, len(clusters), 2): c1 = clusters[i] c2 = clusters[i + 1] var1 = getClusterVar(cov, c1) var2 = getClusterVar(cov, c2) alpha = 1.0 - var1 / (var1 + var2) w[c1] *= alpha w[c2] *= 1.0 - alpha return w #------------------------------------------------------------------------------ def getClusterVar(cov,cItems): # Compute variance per cluster cov_=cov.loc[cItems,cItems] # matrix slice w_=getIVP(cov_).reshape(-1,1) cVar=np.dot(np.dot(w_.T,cov_),w_)[0,0] return cVar #------------------------------------------------------------------------------ def getIVP(cov,**kargs): # Compute the inverse-variance portfolio ivp=1./np.diag(cov) ivp/=ivp.sum() return ivp This stage completes the HRP algorithm. It runs in O ( log ⁡ N ) {\displaystyle {\mathcal {O}}(\log N)} time in the best case and O ( N ) {\displaystyle {\mathcal {O}}(N)} in the worst case. The result is a portfolio allocation that respects hierarchical structure while being robust to estimation error. Numerical Example In this section, we compute HRP portfolio allocations on the sample correlation matrix used earlier, and compare them to two alternative standard methods: A minimum-variance portfolio computed using quadratic optimization, specifically the Critical Line Algorithm (CLA). This is the only solution on the efficient frontier that does not depend on expected returns. See Bailey and López de Prado (2013) for an implementation of CLA. A traditional risk parity portfolio based on inverse-variance weights (IVP). All portfolios are subject to standard constraints: non-negativity ( 0 ≤ w i ≤ 1 {\displaystyle 0\leq w_{i}\leq 1} ) and full investment ( ∑ i = 1 N w i = 1 {\displaystyle \sum _{i=1}^{N}w_{i}=1} ). The condition number of the covariance matrix used in this example is approximately 150.93, which is not particularly high and thus does not unduly penalize CLA. The table on the right shows several notable results. CLA allocates 92.66% of the total portfolio weight to the top five assets, whereas HRP allocates 62.57% to the same group. CLA assigns zero weight to three assets; without the non-negativity constraint, those allocations would have been negative. HRP offers an intermediate allocation structure between the concentrated nature of CLA and the equalizing tendency of IVP. The concentration observed in CLA is a result of its objective to minimize total portfolio variance. However, the resulting portfolios display similar risk profiles, with standard deviations of σ H R P = 0.4640 {\displaystyle \sigma _{\mathrm {HRP} }=0.4640} and σ C L A = 0.4486 {\displaystyle \sigma _{\mathrm {CLA} }=0.4486} . Thus, CLA reduces risk only marginally while significantly reducing diversification. In this example, the top five positions dominate the CLA portfolio, exposi