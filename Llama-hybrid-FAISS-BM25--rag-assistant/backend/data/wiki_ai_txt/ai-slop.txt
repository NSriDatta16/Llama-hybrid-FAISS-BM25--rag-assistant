AI slop is digital content made with generative artificial intelligence, specifically when perceived to show a lack of effort, quality or deeper meaning, and an overwhelming volume of production. Coined in the 2020s, the term has a pejorative connotation similar to spam. AI slop has been variously defined as "digital clutter", "filler content [prioritizing] speed and quantity over substance and quality", and "shoddy or unwanted AI content in social media, art, books and [...] search results". Jonathan Gilmore, a philosophy professor at the City University of New York, describes the material as having an "incredibly banal, realistic style" which is easy for the viewer to process. Origin of the term As early large language models (LLMs) and image diffusion models accelerated the creation of high-volume but low-quality text and images, discussion commenced among journalists and on social platforms for the appropriate term for the influx of material. Terms proposed included "AI garbage", "AI pollution", and "AI-generated dross". Early uses of the term "slop" as a descriptor for low-grade AI material apparently came in reaction to the release of AI image generators in 2022. Its early use has been noted among 4chan, Hacker News, and YouTube commentators as a form of in-group slang. The British computer programmer Simon Willison is credited with being an early champion of the term "slop" in the mainstream, having used it on his personal blog in May 2024. However, he has said it was in use long before he began pushing for the term. The term gained increased popularity in the second quarter of 2024 in part because of Google's use of its Gemini AI model to generate responses to search queries, and the large quantities of slop on the internet was widely criticized in media headlines during the fourth quarter of 2024. On social media AI image and video slop proliferated on social media in part because it was revenue-generating for its creators on Facebook and TikTok, with the issue affecting Facebook most notably. This incentivizes individuals from developing countries to create images that appeal to audiences in the United States which attract higher advertising rates. The journalist Jason Koebler speculated that the bizarre nature of some of the content may be due to the creators using Hindi, Urdu, and Vietnamese prompts (languages which are underrepresented in the model's training data), or using erratic speech-to-text methods to translate their intentions into English. Speaking to New York magazine, a Kenyan creator of slop images described giving ChatGPT prompts such as "WRITE ME 10 PROMPT picture OF JESUS WHICH WILLING BRING HIGH ENGAGEMENT ON FACEBOOK", and then feeding those created prompts into a text-to-image AI service such as Midjourney. AI-generated images of plants and plant care misinformation have proliferated on social media. Online retailers have used AI-generated images of flowers to sell seeds of plants that do not actually exist. Many online houseplant communities have banned AI generated content but struggle to moderate large volumes of content posted by bots. In 2025, the pejorative slang term derived from "AI slop", slopper, was coined to describe someone who is overreliant on generative AI tools like ChatGPT. In United States politics In August 2024, The Atlantic noted that AI slop was becoming associated with the political right in the United States, who were using it for shitposting and engagement farming on social media, with the technology offering "cheap, fast, on-demand fodder for content". AI slop is frequently used in political campaigns in an attempt at gaining attention through content farming. In the first five months of Trump's second term in 2025, Trump posted several AI generated images of himself on official government social media accounts, including him as the pope, him as a Jedi, and him as a muscular man. In August 2024, Donald Trump posted a series of AI-generated images on his social media pla