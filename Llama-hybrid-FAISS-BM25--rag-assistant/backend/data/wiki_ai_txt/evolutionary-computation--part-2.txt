t used by the two to successfully solve optimization problems in fluid dynamics. Initially, this optimization technique was performed without computers, instead relying on dice to determine random mutations. By 1965, the calculations were performed wholly by machine. John Henry Holland introduced genetic algorithms in the 1960s, and it was further developed at the University of Michigan in the 1970s. While the other approaches were focused on solving problems, Holland primarily aimed to use genetic algorithms to study adaptation and determine how it may be simulated. Populations of chromosomes, represented as bit strings, were transformed by an artificial selection process, selecting for specific 'allele' bits in the bit string. Among other mutation methods, interactions between chromosomes were used to simulate the recombination of DNA between different organisms. While previous methods only tracked a single optimal organism at a time (having children compete with parents), Holland's genetic algorithms tracked large populations (having many organisms compete each generation). By the 1990s, a new approach to evolutionary computation that came to be called genetic programming emerged, advocated for by John Koza among others. In this class of algorithms, the subject of evolution was itself a program written in a high-level programming language (there had been some previous attempts as early as 1958 to use machine code, but they met with little success). For Koza, the programs were Lisp S-expressions, which can be thought of as trees of sub-expressions. This representation permits programs to swap subtrees, representing a sort of genetic mixing. Programs are scored based on how well they complete a certain task, and the score is used for artificial selection. Sequence induction, pattern recognition, and planning were all successful applications of the genetic programming paradigm. Many other figures played a role in the history of evolutionary computing, although their work did not always fit into one of the major historical branches of the field. The earliest computational simulations of evolution using evolutionary algorithms and artificial life techniques were performed by Nils Aall Barricelli in 1953, with first results published in 1954. Another pioneer in the 1950s was Alex Fraser, who published a series of papers on simulation of artificial selection. As academic interest grew, dramatic increases in the power of computers allowed practical applications, including the automatic evolution of computer programs. Evolutionary algorithms are now used to solve multi-dimensional problems more efficiently than software produced by human designers, and also to optimize the design of systems. Techniques Evolutionary computing techniques mostly involve metaheuristic optimization algorithms. Broadly speaking, the field includes: Agent-based modeling Ant colony optimization Particle swarm optimization Swarm intelligence Artificial immune systems Artificial life Digital organism Cultural algorithms Differential evolution Dual-phase evolution Estimation of distribution algorithm Evolutionary algorithm Genetic algorithm Evolutionary programming Genetic programming Gene expression programming Grammatical evolution Evolution strategy Learnable evolution model Learning classifier system Memetic algorithms Neuroevolution Self-organization such as self-organizing maps, competitive learning Over recent years many dubious algorithms have been proposed, that are often just copies of existing algorithms (frequently Particle Swarm Optimization), where only the metaphor changed, but the algorithm itself is not new at all. A thorough catalogue with many of these dubious algorithms has been published in the Evolutionary Computation Bestiary. It is also important to note that many of these dubiously 'novel' algorithms have poor experimental validation. Evolutionary algorithms Evolutionary algorithms form a subset of evolutionary computation in that they