ore the crash did the car driver brake or initiate an evasive steering action. In addition, no driver-applied steering wheel torque was detected for 7.7 seconds before impact, indicating driver disengagement, likely due to overreliance on the Autopilot system." In addition, the NTSB concluded the operational design of the Tesla Autopilot system "permitted disengagement by the driver" and Tesla failed to "limit the use of the system to the conditions for which it was designed"; the NHTSA also failed to develop a method of verifying that manufacturers had safeguards in place to limit the use of ADAS to design conditions. Key Largo, Florida, US (April 25, 2019) While driving on Card Sound Road, a 2019 Model S ran through a stop sign and flashing red stop light at the T-intersection with County Road 905, then struck a parked Chevrolet Tahoe which then spun and hit two pedestrians, killing one. A New York Times article later confirmed Autopilot was engaged at the time of the accident. The driver of the Tesla, who was commuting to his home in Key Largo from his office in Boca Raton, dropped his phone while on a call to make flight reservations and bent down to pick it up, failing to stop at the intersection: "I looked down, and I ran the stop sign and hit the guy's car ... When I popped up and I looked and saw a black truck â€” it happened so fast", later telling the responding police officers that Autopilot was "stupid cruise control". When the driver of the Tesla called authorities to respond, he spotted only one injured man, who was unconscious and bleeding from the mouth. He told police at the scene that he was driving in "cruise" and was allowed to leave without receiving a citation. Emergency medical personnel saw a woman's shoe under the Tahoe, prompting a search for the second victim, who was found approximately 25 yd (23 m) away from the scene, where she had been thrown from the impact. The decedent's family filed separate lawsuits against Tesla and the driver; the suit against the driver was settled out of court. The lawsuit against Tesla alleged the company marketed a vehicle with "defective and unsafe characteristics, such as the failure to adequately determine stationary objects in front of the vehicle, which resulted in the death of [the victim]". On August 1, 2025, a federal jury found Tesla to be 33% responsible for the crash. If the verdict is upheld, Tesla would be required to pay up to US$243 million in compensatory and punitive damages. It was the first case involving Tesla's Autopilot ever to go to federal trial. Fremont, California, US (August 24, 2019) In Fremont, California on I-880, while driving north of Stevenson Boulevard, a Ford Explorer pickup was rear-ended by a Tesla Model 3 using Autopilot, causing the pickup's driver to lose control. The pickup overturned and a 15-year-old passenger in the Ford, who was not seat-belted, was jettisoned from the pickup and killed. The deceased's parents sued Tesla and claimed in their filing that "Autopilot contains defects and failed to react to traffic conditions." In response, a lawyer for Tesla noted the police had cited the driver of the Tesla for inattention and operating the car at an unsafe speed. The incident has not been investigated by the NHTSA. Cloverdale, Indiana, US (December 29, 2019) An eastbound Tesla Model 3 rear-ended a fire truck parked along I-70 near mile marker 38 in Putnam County, Indiana at approximately 8 a.m.; both the driver and passenger in the Tesla, a married couple, were injured and taken to Terre Haute Regional Hospital, where the passenger later died from her injuries. The driver stated he regularly uses Autopilot mode, but could not recall if it was engaged when the Tesla hit the fire truck. The NHTSA announced it was investigating the crash on January 9 and later confirmed the use of Autopilot at the time of the crash. The driver filed a civil lawsuit against Tesla in November 2021; it was moved to federal court in February 2022. Gar