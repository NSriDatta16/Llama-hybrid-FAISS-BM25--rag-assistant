rytelling, which at times resembled a thriller, "albeit one where the thrills come from the obliteration of literally everything of value". While finding the authors' astonishing and dire claims credible, he expressed hope that they are wrong due to the apocalyptic outcome, one that he himself can't see a way to avoid. Bill Conerly wrote for Forbes that the book persuaded him that the catastrophic risk to humanity was greater than he had previously thought. He noted that the book effectively used parables to argue that AI's self-improvement could lead to unpredictable evolutionary paths which may diverge from those of its human programmers and eventually cause the AI to view humans as a hindrance or simply not valuable enough to warrant resources. He concluded that he was "far more concerned" after reading the book. Kevin Canfield wrote in the San Francisco Chronicle that the book makes powerful arguments and recommended it. In The Atlantic, Adam Becker wrote that the book is "tendentious and rambling, simultaneously condescending and shallow. Yudkowsky and Soares are earnest; unlike many of the loudest prognosticators around AI, they are not grifters. They are just wrong...Yudkowsky and Soares fail to make an evidence-based scientific case for their claims." In an article titled "Why we must pull the plug on superintelligence", Paul Wood wrote for The Spectator: "If more and more people understand the danger, wake up and decide to end the 'suicide race', our fate is still in our own hands. If Anyone Builds It, Everyone Dies is an important book. We should consider its arguments – while we still can." Publishers Weekly said the book is an "urgent clarion call to prevent the creation of artificial superintelligence" and a "frightening warning that deserves to be reckoned with", but mentioned that some of the parables and analogies are less effective than others and that very few opposing viewpoints are presented. Kirkus Reviews gave a positive review, calling the book "a timely and terrifying education on the galloping havoc AI could unleash—unless we grasp the reins and take control." Booklist gave the book a starred review. It praised Yudkowsky and Soares for their analysis of the existential threats posed by artificial superintelligence, detailing a potentiality that is less about technological advancement and more the survival humanity. It likens the book to a "fire alarm" for anyone involved in shaping the future, emphasizing that it demands serious consideration and reflection from all stakeholders no matter their opinion on its conclusions. Steven Levy in Wired expressed skepticism regarding the likelihood of AI causing human extinction, finding the authors' proposed solutions for preventing devastation more improbable than their doomsday scenarios, but mentioned a study of AI contemplating blackmail and concluded "My gut tells me the scenarios Yudkowsky and Soares spin are too bizarre to be true. But I can’t be sure they are wrong." The New Zealand Herald called it the book of the day on October 21, 2025: "How many chances do you want to take with the future of our species?". Ian Leslie, writing for The Observer, said the authors wrote their story with "clarity, verve, and barely suppressed glee," making it "a lot of fun" for a book about human extinction. However, he was not convinced that superintelligence as described is imminent, or that if it emerges, it would likely lead to humanity's demise. Gary Marcus in The Times Literary Supplement wrote that "Things are worrying, but not nearly as worrying as the authors suggest" and that the authors "lay out this thesis thoughtfully, entertainingly, earnestly, provocatively and doggedly. Yet their book is also deeply flawed. It deserves to be read with an immense amount of salt." Jacob Aron, writing for New Scientist, called the book "extremely readable" but added that "the problem is that, while compelling, the argument is fatally flawed", concluding that effort would be b