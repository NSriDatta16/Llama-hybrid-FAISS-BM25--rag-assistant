# Copy to .env and fill as needed
OPENAI_API_KEY=
# If you'd like to use a local model via OpenAI-compatible endpoint (e.g., vLLM, llama-cpp-server, Groq proxy), set:
OPENAI_BASE_URL=
OPENAI_MODEL=gpt-4o-mini
# Retrieval tuning
HYBRID_ALPHA=0.6  # weight for dense (FAISS) vs lexical (BM25)